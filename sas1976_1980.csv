text,name
"tistical pack- ages in spite of the general difficulty of keeping reasonably current in more than one package. I have just a few remarks. I am not sure how to take the statements regarding the BMDP manual. I don't view a complete description of a program in an organized style as incompatible with a system being integrated. While allowing communication through Save Files and utilizing a common control language, the BMDP programs can each be run without wading through a large number of pages of introduction. While the BMDP control language and self-documented Save File are certainly important improvements over the old BMD programs, the improvements in the data ana lytic capabil iti es are much more important. Use of Br·1DP programs is suggested not so much because of ease but because of the information they provide. For example, the one-way analysis of covariance program tests equality of slopes, -prints slopes for each group and provides plots for each group_ Dr. James W. Frane UCLA (BMD, BMDP)  Coments on ""A Comparison of BMD, SAS and SPSS"" by Papa ioannou, Styan and Ward * This paper is confusing since it refers both to the older BMD programs and to the newer BMDP series. Unfortunately, the SMD programs are not all completely super- seded by BMDP programs so we cannot dismiss them even for IBM users. However, since the BMDP programs have been distributed to over a thousand facilities, it seems inappropriate to restrict discussion of certain statistical aspects to the BMD se",SUAD8A~1.txt
"1 GENERAL LINEAR MODELS HlOCEDURE J. H. Goodnight S.A.S. Institute, Inc. The General Linear Models procedure, GIM, is not as of this date complete.* It lacks MANOVA, OUTIUT, ME'ANS, ADJUSTED means, and TEST statements. These will be ready soon, however, since the bulk of the research activity on the new techniques employed by this procedure are completed. As it currently stands, the GIM has only the lROCEDURE, CLASSES, and MODEL statements. general form of these statements is The as follows: PROC GIM; CLASSES list; I ~ dependent list independent list options; MODEL The PROCEDURE statement has no options or parma. The CLASSES list contains cla8si- fication variables (if any) just as with PROC REGR in SAS 72. one MODEL statement will be allowed. This restriction was implemented to ~ facilitate the handling of missing values. GLM automatically groups the dependent variables which be analyzed together based on the similarity of their missing CM value structure. This guarantees that each dependent variable is analyzed with the maximum number of observations- coming into play. The list of independent effects is like that of the old ANOVA or REGR with the , addition of allowing continuous by class interaction effects, continuous within f ~ class effects, or continuous by continuous effects. A few examples follow (assume , A, B, C are CLASS variables, and X, Y, and Z are continuous): ~ MODEL a main effects model Y~ABC; f MODEL Y A B A*B ; 2 factor crossed model ~ t \ , MODEL Y ~ A X ; main effects with covariate t I MODEL Y = A X(A} fits separate slopes for each level of A = A X X*A MODEL Y here X*A tests homogeniety of slope = X Z X*X MODEL Y X*Z Z*Z a response surface model MODEL Y ~ A B(A} C(A B); nested effects MODEL Y = A A*B A*B*C; nested effects *(Editor~ This paper represents status as of February 1976)  2 Note that,although the parentheses have been retained for nested effects, they are not needed . . What an effect truly represents depends on what other effects",Sugi-76-02 Goodnight.txt
"40 THE DESIGN OF THE SAS MATRIX PROCEDURE John Sall S.A.S. Institute, Inc. THE NEED 1. ----- Tbe first exposure to computers that many students get at North Carolina State University is in the intermediate Statistical Methods course. This course concentrates mainly on analysis of variance and it would seem obvious that SAS be However, it was not SAS, but chosen as the statistical package for that course. OMNlTAB that was used for this course. The reason SAS was not used was that i t was too easy and automatic. OMNlTAB forced the students to become accustomed to specified. Later, when students became practitioners, the BAS analysis procedures would be far more desirable; but for learning statistical methods, something like OMNITAB is needed. Several writers have commented that statistical practitioners need to know two kinds of software to survive a statistical package for the routine work and a computational language such as OMNITAB or even FORTRAN with SSP to do the custom work. Several packages do combine these tasks to varying degrees. SOUPAC has a matrix manipulation package; GENSTAT, FSTAT, ESP, and other statistical packages have a few general matrix operators. Computational languages are often used in place of statistical packages: DMNlTAB with its statistical commands, FORTRAN and PLjl with SSP and IMSL, APL and SPEAKEASY with their library routines. BAS now has a MATRIX procedure. Several statistical methods courses at North Carolina State University now use it. It greatly expands the computing horizon of the BAS user: Now virtually any statistical method or numerical manipulation is available in BAS if the user is willing to specify the operations in enough detail.  41 II. DESIGN COOSIDERATIONS The general goals of"" computer software rema,in power and generality, accuracy, efficiency, and ease of use. Several more specific characteristics were deemed important for the MATRIX language and its implementation. 1. Syntax: The language should be algebraic. Us",Sugi-76-03 Sall.txt
"55 THE IN-HOUSE TRAINING OF NON-COMPUTER ORlENTED RESEARCH PERSONNEL IN THE USE OF SAS NEIL M. CASEY MISSOURI DIVISION OF HEALTH STATE CENTER FOR HEALTH STATISTICS By non-computer oriented personnel mean research analysts who are actively I engaged in the collection, analysis. and dissemination of health data. All are college graduates, some with advanced degrees, most of whom managed to traverse their entire college careers with little, if any, contact with the computer or computer programming. During the three year periOd that I have been affiliated with the Missouri Division of Health's Center for Health Statistics, we have had thirteen research analysts working at one time or another. We presently have nine analysts on our staff, seven of them are now able to at least write basic SAS programs, the other two have just joined our staff and will soon begin the training program which I will outline presently. Let me state at the outset that throughout this paper, I will be referring only to SAS-72. However, I believe that this training program can be adapted to whatever BAS system your installation has. Also, this training program has been developed to meet the specific needs of our own office, but I feel that this program can be modified· to meet the specific needs of your own shop. Orientation to the computer and SAS As I have just mentioned few of the newly hired research analysts have had any previous contact with the computers. Thus, I usually begin the training program by showing the new analyst some of our shop's previous computer runs, both of a quantitative and qualitative nature. While I am doing this I continually stress the number of cases involved in most of our work. To give you some idea of what I mean, Missouri has over the last 5 years been averaging approximately 70,000 births, 50,000 deaths, 50,000 marriages, and 20,000 divorces, and a new program just over a year old called the Missouri Hospital Discharge System, expects to average Over half a m",Sugi-76-04 Casey.txt
"71 STATISTICAL AND DATA SUPPORT TO A HETEROGENEOUS USER COMMUNITY Marion C. Carter and Richard C. Roistacher Center for Advanced Computation and Social Science Quantitative Laboratory University of Illinois, Urbana, IL 61801. 29 January 1976 The Multiple-System Environment in Data processing organizations engaged primarily production jobs performed by their own staff generally select a standard statistical and data management system. New staff members often bring experience with other systems, but are expected to learn the methods used by the organization. Such standardization allows organization ~he to use a single file type or a single family of file types. It also permits staff members to develop a single data processing vocabulary and set of operating conventions. The Social Science Quantitative Laboratory at the University of Illinois at Urbana-Champaign serves clients in the departments of Anthropology, Geography, Political Science and Sociology as well as several research institutes on campus. The Lab provides users with access to computer hardware, data archive services, consulting on University maintained software and on special software maintained by the Quantitative Laboratory. Users come from a wide variety of backgrounds. While many clients have obtained all their  72 Statistical and Data Support to Heterogeneous Users M. C. Carter and R. C. Roistacher computing experience at the University of Illinois, others, especially younger faculty members, have come from a wide variety of computing backgrounds. They differ both in the amount of their computing experience and in the sophistication of the systems with which they are familiar. The Quantitative Laboratory has had to respond to its diverse clientele with a mixed strategy of adaptation and ,. ~ r · standardization. Early attempts to persuade clients to change statistical systems met with almost uniform failure. Most clients were inextricably wedded to the system on which they had received their origi",Sugi-76-05 Carter Roistacher.txt
"escribe the evolutionary process by Which have come to use SAS in Our basic statistics course. We did not begin w£ our use of computing with SAS, and we have not yet fully converted to SAS, but I think you will find the story I can tell so far to be an interesting one. It began in 1970, When we modified our traditional two semester probability-and-statistics course to one that placed more statistical methods into the first semester. The topics covered in the new first semester became: 1) Bssic ideas of discrete probability, leading to a test for fairness of a coin. 2) Three nonparametric tests: the test of a 2 by 2 contingency table (Which we dubbed Pearson's test), the Wilcoaon-Mann-Whitney test, and the test for significance of Kendall's tau statistic. 3) Discrete and continuous rsndom variables, mean and variance, normal random variables, the central Ifmit theorem. 4) Known-variance methods for one and two populations. 5) Unknown-variance methods for one and two populations. 6) Regression and correlation. 7) Contingency tables. The above may seem like a lot of material for one semester, but we have been very successful at teaching it. We believe one reason is that the early introduction of hypothesis testing kindles the students' interest to an unusually high degree. To keep that interest strong, we have supplied the students with FORTRAN subroutines with Which to perform the major statistical tests and estimation procedures covered in the course. Also, we hsve sponsored c",Sugi-76-06 Spitanagel.txt
"90 TWO TOOLS FOR RESIDUAL ANALYSIS IN MULTIPLE REGRESSION Ronald B. Wiley Deering Milliken, Inc. Much of the statistical analySiS in our company is done under Experiment~ a tight deadline. can be well designed and measurements carefully made, but all the statistician has to do is to use his magic wand - the computer - and the results are analyzed presto! Then a , report with clear and unqualified conclusions can be written. This time schedule makes it difficult to look at the data critically. It is easy to accept a routine analysis and go on to>the next problem. Sometimes a few plots or tables would show up inconsis- tenciesor bad data and improve the analysis. Our main tool is multiple regression or analysis of variance. I want to emphasize some problems and suggest some aids for this technique. Since analysis of variance can be considered as a special case of regression, the remarks I make for regression hold for analysis of vsriance. Most statisticians realize that multiple regression is not a ""robust"" procedure. If the data does not meet the basic assumptions j the results can be incorrect and if no check is made, this is not j'. e noticed. Most textbooks state the assumptions in such a way that the ~: student is apt to believe that all data will meet these assumptions; hence, he can apply multiple regression to any data without thought. ~ Let us look at a simple 1II0del: To find the least squares solution, we do the following: yi-b 1xli-b 2XU- &1 (2) M M r (yi-bIXli-b2X2i)2 ~i=1 £i2 L F= (3) i-I M a E _ 2~ (I Ei 2)2=0 (4) :ib (Yi-blxli-b2XU) (-Xli) = 1 i=1 ab 1 i-I M M = _3_ (L &i 2) ;~2- ZI (yi-bIxli-b2X2i) (-Xu) =0 (5) ab 2 i=l i-I Giving the simultaneous equations: M M M b i L X1i2+b2 iIIXliX2i=iIIXli y1 (6) i=1 M M M ikIf(2.iZ=i~IX2i bliflXliXU+b2 y1 (7) Note that in (4) and (5) the derivative of the right hand side is set to zero, i.e. it IIIUSt be a constant. At this point the textbook us~ly II usual we assume that £i is a randolll normally distributed",Sugi-76-07 Wiley.txt
"126 MORE EFFICIENT USE OF SAS (OR THE EFFECTS OF INDULGING SAS) Robere L. Anderson Deering Milliken, Inc. MORE EFFICIENT USE OF sAS The purpose of this paper is not to expose any previously unknown or highlY sophisticated techniques for making mare efficient use of SAS. The author's intent is to discuss a collection of very simple methods he uses'for much greater efficiency. Hopefully, this will work as a catalyst to stimulate discussion and thinking among other users so that the total effect will be great savings to all. Many userS of SAS are not. systems analysts or even programmers and not aware of the effect that various uses (or abuses) of SAS :ar~ have on an Operating System. I have heard complaints from many of : ~ my associates in academia, government, and in business about the inefficiencies of SAS. SAS is not inefficient at doing wnat it is designed to do and with proper caution it can be used as a valuable tool for many non-statistical endeavors. Hopefully, through more consciousness in our .use of SAS we can generate a much wider acceptance of it as the valuable . tool that i t is. : My remarks will. be directed at some simple ways of reducing run time, conserving on line s.torage, and reducing abuse of the CPU. Since I workln a.business environment, my examples will be most directly applicable to business situatlons.  127 A. PRE-EDITING INPUT DATA One of the greatest abuses of SAS is in its use to edit large data files to obtain a relatively small amount of data. For example, in environment we quite frequently wish to draw on information ~ from some large data base or to select a small amount of dsta for analysis from a large file. Now the INPUT facility in SAS is stream su~ (edit) oriented and, as is very slow at reading a large data file. A strip program in PL/I or COBOL could quiCkly and efficiently edit the data for input to SAS. In the appendix :an example is gi.ven of a typical stri.p program (in PL/I) that I use for pre-editing data. As an exam",Sugi-76-08 Anderson.txt
"132 Using SAS for univariate time series analysis via the Box Jenkins Technique Mark J. Nicolieh Rider College r ; There are a multitude of reasons for relating a set of independent variables to a dependent variable; either forecasting, modeling, or determination of influences. The best known and widely used technique is regression analysis. Regression analysis is based on a model Yi = f(xil> xi2, ... , xij) + <i where Vi is the ith realization of the dependent 'variable, xir is the ith realization of the rth independent variable and ""i is an error introduced into the ith observation. The most basic model would be + Ei Yi = \1 where \1 is a constant. The standard regreSSion techniques go on to assume that the ""j are independent, identially distributed, have mean zero, and have constant variance. The assumption of identical distributions is reasonable, and zero mean and constant variance can often be achieved by transformation. The assumption of independence is usually overlooked. The assumption is violated when the dependent observations are taken serially in time and one of the independent variables is time, or a counting variable. When this is the case the analysis must be done via time series teChniques. Time series takes into account the dependent nature of a series of observations. This paper will provide a brief overview of time series analysis using the Box Jenkins technique, and some ideas on how to carry out some of the analysis using SAS-72, and how to do all the analyses using SAS-76 when it becomes generally available. The Box Jenkins technique will only be outlined, and readers should refer to the text, Time Series Anal sis Forecastin and Control, by G.E.P. Box and G.M. Jenkins 1970 for a full discussion. To apply the Box Jenkins method we must first have a station- ary sequence. If we view the present observation Yi as being pro- duced from some mean level, ]1, plus a shock which has a finite  133 memory of the past, then we have a stationary series.",Sugi-76-09 Nicolich.txt
"'r '>:',-._-'.'~""~""""'""""-"""""""""""".""~<I""'-,"",;""~,~~,."",,<,,,~~.n..,..,..""1'''''_ ''''~Y<''~'''~'''~4·.~'I'-_~'~.''U'''''''~' 'Cfl""'"" ·.....-u'""_"",··,·._c._ - ""0 -. -~~-~"".'~~-::~ft"",""""::<'::""'''''""M-i.''''~'''''''~:-<'';_,,-,,I'''';'.~,"",~~,,-:,,""'''' -0--' ~ ""Y · . _""'~~~r<""'o.~_'""""-- ,;·· ~_ ··,' """"':"",~""!,_-J'_-.""'-',·~e<"":;.n;;"""""",""~I.' .·'""""-""'--'l ......~-N _LT _( TIS TIC · l .~'LVSIS SYSTe"" 3:37 TUESDAY. """"'~U_~.Y ll ·. l911>_ .. ~.~_.. ') 'PROr llPrfK PG~.OC RC-OI PARIIICARO * P~INT OOF * . YTOtLl ~T-~nfLc.PfP . .... ,_"". · ~y TH~lC.L SE~y l.~tlL_ ~. ~"".u:-AJi' ~ Ices .A811OT_ · '""UTINE TO .f~D IEHlIST '.I'ITED ooTI'I.IT AND CREATE A FILE * ·· aF DUA Sf T EXTENTS, A ~ECORry IS III1ITTEN fO_ EACH EXTENT ON - THE vOlU~E; w..ETHER FREE. \l'TOC OR DITA. * · SU8SEOUE~T File IS ANAYlEO ev 'US'. * !fll n-I'!' UNITZ·OUT.onN~~E··rUTPUTt S' lIE-lOOO $ ~, SYMBOlSI DS ....OA.·----------DATA S'ET rtAME-------------. - - _ .. _ - - - ··,vO[lolf·· i - - - - - C O ' l f E N T S l l f yr-oftONYOL · 40 e~TeNT""S ~D LIJiII IC~Il"" _._ ,HlKDR-, "" _- t'FOllMAt5-' f!:[]RfiI'T 5 OS-C8 ' _ - -- -- ----. .. I';) .. _.. _ .·. .. ~--------""'- -··-··~=r SYM8""lS ISAWn-SAY.900-905.1 SVOIROL S I . DUl'IIEC-OU't .FHD · · !JSN -OUT.l""""""'44 · .~LJT · VOL .45-50. )- ~- -cut .51-Cji5. .. cRe-[)-f tIE )(1II)'T ""OU1.56-60 · -_ .. _--- --,---------,---------------_.- .. ttOEXT -OUT .61-62'. - .,,-- -~os""fiR~-;Ou-""- .63""=65 ~ ,REef"" -auT .66-61 · · 8 LKSllE - ~UT .68-12 · __ - -OUT.f3-JT. .--,-~.-.---. '.-_.-- - --_~n~ ~-. '·~L~""£Cl .ICEYl~'"" ~OtJ1 ..18-19. (HlOC L1lIk is an Abbott-wrtt""j;en prooedure ,AlllNT .OUT.8o-8~. .~uf .85-87 ~ use<l. to lillk to other languages such as UC/300· , ."" LUtrI) ,useOTK -OUT .88-93. u..ProPr1etary language of Cambridge Canput1ng» ~ -CUT _!-E )(.!NO .94-95_. ___ _ ---=""-'---- -OUT.96-100 · ,lOWTK -OUT .101-105. .... IGHT'< tOUT.I06:~_20,_ .... ~ ~ jFllll _._. __ . m_ _ ' _ _ _ ____ . ______ _ · __ """"CHECK"" STOO.IT 1 - 0_'_ - ~-.. ~----,rnjJ0T-TI'm:-T---.rm>-- IF .DSNHOR",Sugi-76-10 Trefren.txt
"166 , \' SUPER Sr~F SAS / REPORT P!l,ESF~TFD BY ,11M GUTHRIE CLFVFLIl,Wl TRIIST SAs/SMF JOB REPORT Since the dawn of recorded SMF, man haa had the desiI;e to get the informati(>n from the Step Record (TYPE 4) combined wit:h the data set statistics (TYPE 14-15). The problem is compli- cated by varicble fields in SMF 4 records, real ,time order of SMF records, EXCP counts not 'reset on reopened data sets, and missing records .. t., U,oi.ng the Da Man<1gement and Report Wri ting Capabilities of 2 7~j. SAS tht!:.ie probl('ms have been overcome and an easy ""to j read,comprehensive report is prodlu:ed. Additional enhancL!ments include selection Ily job information (in both record types) as well as selection by data in the Step Record only.  167 EROBLEMS WIIH SME nAIA RANDOM CHRONOLOGICAL ORDER. DATA SET RECORDS DO NOT CONTAIN INFO FROM STEP THAT CREATED THEM. VARIABLE LENGTH FIELDS WITHIN RECORDS. EXCP COUNTS NOT RESET ON REOPEN. MISSING RECORDS. DATA IN HEXIDECIMAL REPRESENTATION. VOLUME OF DATA.  168 SA SMA k irQ E A k 1 L 1 I Y. f1ACRO r'IACRNAME SAS STATEMENTS; % ,.-----------""-------.. MACRO 1''!ACROl DATA; HlFILE IN; INPUT; @ 2 RTYP PIBl. ; % MACRO MACR02 ! OUTPUT; % '---------------_./ MACROl MACR02 MACROl IF RTYP=4 THEN GOTO SAVE; DELETE; SAVE: f~ACR02 :- -~.'."",-""  169 SAS C.o.ILCAIINAIED. SYS.lN c=:::>i \ ...... _ - - - ( / t-----'I i / ~MFSEL MACRO ----'---"" 11 ~I ~~ DSN=SP. SASLIB IISAS EXEC SAS IISMFIN DD DSN=SMF TAPE,DISP=SHR IISYSIN DD DSN=SP.SASLIB(SMFSEU,DISP=SHR DD * II MCROI MACR02 IF RPROG='SORT' THEN GOTD SAVE2; RETURN; SAVE2: SELECT~4; MACR03 --, . .. . - ' ,  170 STEP DATA SET JOB , INFO INFO INFO j~ ,. ~ :-, SMF ] I I I DDl 15 ,. , I I I , DD2 I 14 , r , I ! I I DDl 15 } ~ I I STEP1 4 SELECT INPUT 4 14 15 [ STEPI 4I t I 15 I I DDl I f' [ I I 14 I DD2 SORT ~ r- , 15 I [ I' I DDl REVERSE i > ~ i j , f ~ ., !, r RETAIN ~, I , I I ,. DDl STEPI 15 j '. STEP INFO! r = ~4 I I DD2 .STEP1 . i FOR 14-15 t I [ DDl STEP1 15 I i t 0  171 r ! 15 STEPI DD2",Sugi-76-11 Guthrie.txt
"181 , SAS and System Measurement at COllUl1onwealth Edison Randall Drew Commonwealth Edison has started with the availabil- ity of SAS75.2 to use SAS in system measurement. Our cirrent operating system is MVS Release 3. At this point the use of SAS is still quite limited and very fundamental. Primary uses to date have been: ' 1. Reduction of MFI data to produce daily graphs of CPU wait time, TSO response time, TSO transaction rate, system paging rate, and chan- nel usage. 2. Analysis of GTF data to determine which modules are being loaded, for which modules BLDL,' s are being issued, and frequency of SYSEVENTS. The reduction of GTF data provides many opportunities to use SAS. 3. Analysis df disk pack usage, number at cylinders traversed"" etc., to determine best data set placement. Various analysis ot SMF data to determine 4. usage of system resources and to enforce stan- dards. While this is but a brief summary of our uses of SAS it gives an indication of our commitment to SAS for the analysis and reduction of data in the system measurement, performance, and tuning area.",Sugi-76-12 Drew.txt
"182 NEWPC~T tElltTE"" O."",E. NEWPORT 'EACH. CA. .&""AVCD FINANCIAL SERVICES /620 92 ·· 0 I January 26, 1976 l Jane H. Helwig SAS Project Insti tute of North Carolina State University Box.5457 Raleigh. North Carolina 27607 RE: SAS Users Group Dear Jane, Although I cannot attend in person, perhaps you would like to include the attached plots (ofpagfng data from our IBWIWS system) in the proceedings. The ability to produce th1s information has led to significant increases in performance for the AVCO Financial Services installation. /i/J ./ . Sincerely. 9-~1.CAML~ J. F. Chambers Attachment JFC: lew cc: M. J. Kirrene  , I , i , ·! :i . i I I I ;!!! .. ~ 1 ,,"", -l ,1 i ··J .o, ~I II' ! ' , i ~I I i ~1 i =~ -I lJ· ~! ., ~ ~.; , i · I i· ... t<-~ , i ~'"" .;i I ~- '.' 1 1./' -I .. i £~LI .,j ;1 :: f· ~I ~~ 0- · ~I I ~pi ft. r ~i I III '_. ,I ~-""'In 1- I ........ ! , I5flf ...... i"" '- ...... gUU i t I .<1"" « %%% · , UUU -. , ,. .. .,,. ;?~ ., ! ..... ... ; , .. z ... 1 ·· ..... ...., l.~ ! -"" l-- .- '"""" ·1 I 1 i , '1, I ......... I ......... .. co.!> a.'~o.. . I ~ , I , I I I I I- .. , 1- , I I I i ,  ..- "" _""""""'.'_',,.-_ '~~~~_'_~.~~""~C~=""==c""""""~""·,,,"",,,"",·-,,~.,,=-.r;.,,,..,..,...-:ro~,,_~~,,'-,;o'.'-r...-~:.""""\'-""""~"";~""~,."",,"",,,.., ,~.~, ,A ~Trz r:c. PAGING ANAlVSrs JANUARV 19. 1970 9'16 ~OHOAV. ,~ .'_ ··· ____ , ______,._DATf.7 ... 01~.·___ · _ _ · __ _ -------------~--- USEO IS CHAUCTER T - 'O,AL p.qc.E. R,A-l""E PLOT OF HOUR .. ,..GeRATe L-r.FNO: ~Y~ROL ,, _________ __________ PLOT. OF. HOU,R""SYSJRATE U5!O IS CMAutTER_ L."":_.LI.I-.I\(,.P~r."", MUll Pile;. IIJ ,.- ~ L~r.ENr"" 5Y~~OL S"",""''' "";)I>t.el.-Jc,: --- ... , -"".-- LfGEN(); SYI'I81lL uno IS CHARACTER S'- PLOT OF HOUR·SWPGRATE _. 'AG!RAT! I . --------- -_._- -----.- --_... __ . ""'_'. __ -::. ._.. _.c... ....·... _ _ _ _ · __ --,_._ .. ~_-; ~ -;--.- ... _ ... .... ""-~,- -~, ""-;'---~ .~-:.- ~--:--------- -,..----~ , r .' ----·-----1 . -----,_._------- _ _ .,., '""_ ,·.. _ ,._ .·__ ,_,., __ ,_,. ___ __ ·· _o __ ·__· _",Sugi-76-13 Chambers.txt
"185 ECONOMETRIC USES OF S.A.S. Max MOSl'er, Virginia Commonwealth University Martha S Shuler, Federal Reserve Bank of Richmond lhis assembly of S.A.S. procedures into a coherent and continuous package of daca analys1s haa been motivated by the probletnB of empirical economic research. It will meet the needs of analysis in other social sciences and in all areaa where experimentation relies on historical and non- laboratory data. This package will be helpful to the researcher who has only a minimum farni.liarity with the institutions, history snd other struc- tural characteristics of the study population. This include!! but is not limited to students working on term papers or other projects with restricted time and interest commitments. This program package will be useful to professional researchers since data points which are singular and un- characteristic of the average will be identified automatically. This is essential not only for explaining these atypical values but also for preventing these outliers from contaminating the general explanation of causality. These are important considerations since too often data collection and regressions precede thorough investigation of the sanple period. Often important contemporaneous events--strikes, natural disasters, political upheavals--becorne only dim memories in the near future. Researchers sifting through maSses of data may be unaware of the exogenous events \ which effected the economy. This package expedites the discovery of outliers and atypical events. 1J It should, for example, several years dra~J hence to a researcher's attention a aet of data points in tbe fall of 1973 as uncharacteristic of the sample. Subsequent recourse to history .!.IUe do not imply that an immersion in the data period is not neces- sary. It is well known. however, that too few practice this time and labor--- intensive procedure. The clBl~ is that this package will focus on outlying points permitting both the scholar and the novice a more",Sugi-76-14 Moszer Shuler.txt
"211 MAP CONSTRUCTION AND GEOLOCATIONAL ANALYSES WI'lH SAS AND A GEOZIP FlLE Steven R. Borbash West Virginia University 1. Introduction 1.1 Overview A system for attaching geolocationa1 data including coordinates, county and district names and numbers to a list of zip codes is described. This system is called the GEOZIP/SAS system because it uses the Statistical Analysis System (SAS) together with a specially constructed GEOZIP data file ·· The GEOZIP/SAS system is similar in purpose to the DlME/ADMATCH system developed by the U. S. Census Bureau, except that GEOZIP/SAS is not limited to Standard Metropolitan Statistical Areas (SMSAs). The two systems are compared briefly in this paper. The construction of a GEOZIP data file for the State of West Virginia is described. The file contains one record for each postal zip code within a state. Each record contains county and district names and numbers, the-place name of the post office and the latitude and longitude of the post office. Several GEOZIP/SAS applications are discussed and illustrated with SAS language statements. These applications begin by sttaching some or all of the GEOZIP file data to either a list of zip codes or to a list of place names covered by the GEOZIP file. By assuming the location of individuals to be approximately that of their post offices, a simple list of zip codes can (after GEOZIP/SAS processing) be converted to maps and totals by counties or districts. This provides a rapid and simple method for analyzing population distributions. : SAS-72 forms the basis for nearly all examples, but recoding into SAS-75 should , "" , present no problems. :~ 1.2 GEOZIP/SAS and DIME/ADMATCH Comparisons For Standard Metropolitan Statistical Areas (SMSAs) the U. S. Census Bureau has developed a computerized method for attaching approximate coordinates (usually of hlock centroids) to the street address portion of individual records. This is done with the DIME files [5] and the -ADMATCH soft~are package [4]. Ho",Sugi-76-15 Borbash.txt
"232 NON-STATISTICAL USES OF SAS Steven Ma.ys Un1Tersity of Texas Health Science Center a.t Dallas Introduction The everyday needs of a computer shop bring about new application of SAS. This has been particularly true for us at the UT Healtl Science Center at Dallas. I am in the general applications section of the computer center and am constantly in contact with people who need results. It is Obviously true that SAS can help qet these resul~ if they are statistical in nature. But wnat about ordinary applicat~ons, that are not necessarily statistical? It 2S the intention here to present some of these uses. Perhaps, something may be conveyed that will aid the reader. The following are several techniques and ideas, that have come about in the course of two years of experience. Using SAS to update non-SAS data sets There is often a need to update observations in a data set. If you are maintaining the data in the form of a SAS data set, then it is easy to use the MERGE statement. However, there may be a situation when the data is maintained in a standard 0.5. data set. This happened to us in a situation where the data had to be preprocessed with several programs before being handled by SAS and SPSS. Our client decided he wanted to correct some 200 or so observations. We decided to try SAS to update the data. What this meant was that even though we needed to forma SAS data set, ultimately we wanted to go back to the original pre-SAS format. We realized that· this may not have been the most efficient use of computer resources, but it was nice to have an existing mechanism to update, bypassing a program written from scratch. I believed it was an efficient use of computer software in the form of SAS to save valuable programmer time in a one-shot general applications environment. Here is a brief description of how we did it and comments on its effectiveness. IISTEPl EXEC SAS IlsAS.DOl OD DSN=JER.STAT1,UNIT=TAPE,DISP=OLO IlsAS.NEW D~ DSN=&&PASS,DISP=(NEW,PASS) , II UNIT=SYSDA",Sugi-76-16 Mays.txt
"2ft7 MEETING FEDERAL HEALTH MANRlWEl! STATISTICAL SYSTEM REQUIREMENTS WITH SAS steven R. Borba-sh West Virginia University Introduc tion 1. Th~s paper describes some details of a BUccessful attempt to utilize SAS for two purposes: (1) nearly all data processing work to create and maintain an original health manpower data base, and (2) statistical analysis of the data base. The system described is the West Virginia Health Manpower Statist~cal Systa. (WVBMSS). It ia felt that SAS is ideal for such applica- tions. It is easy to use, result-oriented and relatively economical to run. The WVDMSS application ~sprogrammed mainly with SAS-72 supple.ented by two special user-written procedures. BackgrounA on the Federal Comprehensive Health Statistics Syatem ia presented. Then the design of the WVIIMSS ia d:l.acussed with emphasis on the uae of SAS for data processing work. Financial support for this work waa provided by a grant from the West Regional Medical Prograa to the West Virginia University Departaent V~rginia of Industrial Eftgineer~ng. 2. The Comprehensive Health Statiatics System The National Center for Health Statistics (HeBS). within the U.S. Depart- ment of Health, I!ducat~on aDd Welfare launched a new progr.. , the Cooperative Health Statistica System (eBSS) in 1970. This progr.. _s authorized through Public Law 91-515. Its object~ve has been to des~ and implement a cooperative Federal-State-Local system for producing co.parable and un~form health infor- mat~on and statistics in the following saven areas (4}. 1. Manpower atatistic!! (inventories and surveys). Health facilit~es stat~stics (inventories and surveys). 2. 3. Hospital care stat~stics (short-stay hosp~tala). 4. Household interv~ew statistics. Ambulatory care stat~stics. 5. 6. Long-tera care statistics. 7. V~tal atatistica. Initial eRSS efforts haYS been concentrated :in the three areas of vital statistics, health manpower statiatics and health facilities statistics. In late 1971 a research and develo",Sugi-76-17 Borbash.txt
"264 MEDICAL DATA BASE MANAGEMENT AND RERlRT GENERATION USING SAS Richard H. Browne, Ph.D. University of Texas Health Science Genter at Dallas INTRODUCTION f, This paper is not intended as a demonstration of any new procedures in Y SAS. Rather, it is a case study in which many facets of SAS were utilized, where conventional programming might have rendered the project prohibitively expensive. Concepts, rather than precise details will be emphasized so that other users might easily adapt this schema to their data management problems. In August of 1973, a research team at the University of Texas Health Science Center at Dallas approached me to develop a system for storing and updating voluminous data on seyeral hundred normal and hypertensive patients. Other features desired were the ability to add variables to patient records at a later date, to get mean and frequency breakdowns by race, sex, decade, and other criteria, and to produce plots. They also wanted to able to gen- erate reports from this updated data set. It quickly became apparent that SAS. with its ability to update and add variables yia MERGE, to obtain breakdowns with the BY feature, and do line printer plots was the ideal choice. In addition, SAS would allow the user to translate the updated SAS sata set into a card-image format data set that could be used by report-generating programs. 1. Devising a Data Form The first step was to deyise a data recording form. The researchers were shown several fonns for other projects and asked to devise a form that was most convenient for their use, using the others as guidelines. The resul- tant form is shown in Fi gures lA and 1B (a two sided form). 5 i nee we en- deavored to make the form useful for the phYSician, as well as easy to key- the~ punch, the form also became part of patreltt's regular chart. Medical Record Updating with SAS 2. An Example of Updating with MERGE The following simplified example will be used to demonstrate how SAS can be used to update r",Sugi-76-18 Browne.txt
"ee 37830 i , ;:i , , , .~ C f lResearch supported by the Eastern Deciduous Forest Biome, US-IBP, funded by the National Science Foundation under Interagency Agree- ment AG-199, BMS69-0ll47 A09 with the Energy Research and Develop- ment Administration. Oak Ridge National Laboratory. 2Contribution No. , from the Eastern Deciduous Forest Biome, US- IBP. PublicationNo.' __, Environmental Sciences Division. 30perated by Union Carbide Corporation for the U. S. Energy Research and Development Administration. By acceptance of tni. oIIrtide, the pub""sher ,;:or uM:;ipient acknowledges the U.S. GU'Io'lIrnment.'1 right to retain a Allnlitxc.hJ1Iive. rOYlllty·free- liCllnuln and to anv coPVrloght CQwilllring the IIrticlfll.  278 INTRODUCTION The underlying principle of environmental data management is that data are a resource. Data resources play an essential role in facil- itating and integrating environmental research programs. ""Data re- sources"" is a phrase used to describe data which. when properly managed, constitute a valuable and reusable resource for environmental research. Data resource management. or more bri efly. data management. i ncl udes the planning for or the formulation of data needs, the standardization of data collections, the documentation of data sets. the efficient management of data files, and the coordination of data processing needs and activities. An active data management group consists of personnel skilled in data management methods and experienced in data ma",Sugi-76-19 Strand.txt
295 USE OF THE HARVEY PROCEDURE Walter R. Harvey Ohio State University Numerous computer programs have been written to analyze data under the fixed linear model. Many of these are available for a nominal charge. Most of these programs seem to have been written as ordinary multiple regression programs but some of them do contain options which allow the user to obtain sums of squares for discrete sets of effects and adjusted or least squares treatment means. The least Squares and Maximum likelihood. General Purpose program (lSMlGP) which is contained in the User-Contributed Procedure Library of the Statistical Analysis System (SAS) was written to handle both discrete and continuous indepen- dent variables directly. Estimates of crossclassified and/or nested effects. interaction effects and partial regression coefficients for continuous indepen- dent variables are obtained from a solution of the least squares normal equations. least squares or adjusted class and subclass means are then automatically computed by using appropriate linear functions of the estimates of the effects. Standard i: i errors of these adjusted means are also computed and listed. linear contrasts of treatment or interaction effects with tests of significance may then be obtained if desired by the user. Sums of squares for each degree of orthogonal polynomials through the fifth degree involving treatment effects may be obtained even though one has unequal intervals among levels and even though adjustment is being made for unequal subclass frequencies or for covariates. UNIQUE FEATURES IN lSMlGP Absorption of Equations: One set of equations may be absorbed into the equations for other effects remaining in the model under this option. This option is especially useful when one has one set of effects. either crossclass1f1ed or nested. which contains a large number of effects. The effects for classes or subclasses absorbed may be for either fixed or random effects. The estimates obtained for other effe,Sugi-76-20 Harvey.txt
"298 CCKlENTS ON ANOVA CAI.CUIATIONS FOR MESSY DIl.TAt S. R. SEABLE Biometries Unit, Cornell University* and Florida State University Introduction Data can be described as ""messy"" when each sub-most cell of the classifica~ tiona does not have the same number of observations. This includes the possibility that some, maybe lIlB1lY, of the cells m.ay have no data at all. lhus ''lneasy'' data are what are more usuaJ.ly called unbalanced, non-orthogonal, or unequal- subclass-numbers data, including the possibility of empty cells. Models for the analysis of variance (ANOVA) of messy data are usually represented by the familiar equation (I) where y is the vector of data, X is a matrix of known values, b is· a vector of unknown parameters to be est~ted and e is a vector of error terms. lhe reduction in sum of squares due to fitting such a model (either by least squares or, under normality assumptions, by maK.imum likelihood) is (2 ) where X'x{X'X)-X'X =X'X (3) _ .... -- -- II On leave, 1975-6. t Paper presented at the First International BAS Users' Meeting, Kissimee, Florida, Janll.ll.ry 26-28, 1976 .. BU-58o-M in the BiOl1lll!trics Unit M;iJneo Series, Cornell University. -  299 The normal equations are (4 ) with solution (5 ) Although (5) is pro forma a solution to (4:' the computational procedure for deriving (5) that is usually adopted is to amend the non-full rank ,equations (4) in some manner that yields a fUll rank representation of them. Then from the solution of this fUll rank representation a solution ~o can he easily obtained. Two used methods of amending the fUll rank. equations are those of COJlIIIlOnly making certain elements of the solution vector b O add to zero; Or of putting Ii certain elements equal to zero (see, for example, Searle [1971, Sec. 5.7). n "" £0, Having obtained it can then be utilized in (2) to give inner product of solution vector and right-hand sides of normal equations = (6) ~ i.p.o. solutions and r.h.s.·s A simple extension of R(2) is to",Sugi-76-21 Searle.txt
"309 UN""BALANCEDTWo-WAY ANOVA AND SAS University of North Carolin3 -at Greensboro William A. Powers David G. Herr We have two objectives for this paper - to exhibit. and explain Table 1 in i·, which are listed five pairs of exact tests for the hypotheses H : no difference r in main row effects and H : no difference in main c.olumn effects for ~ta from c unbalanced, a x b, two-way designs and to exhibit and explain Table 2 which indicates how SAS can be used to. calculate the sums of squares, F-ratios and significance levels of each of these tests. Each of these pairs of tests together with the test of the hypothesis Hi: no interactions, represents a possible analysis of data from. unbalanced, a x b, two-way designs. ""ch such analysis has advantages and disadvantages. To put these analyses in perspective the parametric hypotheses i· tested, the model comparisons made, the geometric foundation of the tests and the orthogonality relationships which hold between the sumS of squares for H, H, Hi r c for each analysis are given in Tabl,: 1. In order to fully und.:rstand Table I, it is necessary"" to explore the geometric foundations of the various tests. AN EXPLANATION OF TABLE 1 A general principle for testing a linear hypothesis in a Gaussian linear model is to identify the subspace G of the estimation space which corresponds to violations of the hypothesis and compare the squared length of the perpendicular proj ectlon of the data vector on this subspace wH·h a stochastically independent measure of the variabil- ity of the data by means of an F - test. y 4 x 3, For example, consider a two-way design with observations for pqr p=1,2,3,4; q=1,2,3, for and n a positive integer. r = 1 (1) n pq pq N En Let Suppose these observations denote the t,otal number of observations. ft pq y are modeled as values of random variables such that E Y - = ~ and e pqr Ilqr pq pqr = Ypqrpq identically distributed as N(O,~). In matrix form we are ind~pendent - j) have Y Tll +e Nx 1 where is th",Sugi-76-22 Herr Powers.txt
"318 !NOVA on Unbalanced Design with Unequal Cells Using SAS George C. Chao Abbott Laboratories North Chicago, Illinois Due to unequal cell frequency in the experimental design, the variations of overall main effects and interactions are nonadditive. .. Several different least squares methods, e.g., Grsybill (1961), : Searle (1971) snd Winer (1971), can be shown to yield identical results in the balanced design situation but will yield substantially different reSUlts when applied to data involving unequal cell frequency. Three least squares methods for the analysis of experimental data are of particular interest. Method I Method II Method III General Linear Model Experimental Design Fitting Constants Method AlB, AD AlB A BIA, AD BIA BIA ADIA, B AD lA, B ADIA, B Selection of.one of the three methods should depend upon conceptualization of the problem and the nature of questions to be asked. Actually, the selection depends upon who is ""the statistician"", or which computer'program is available. The goal of this presentation is not to argue which model should be used. There are a lot of papers of this nature, such aeOverall & Spiegel (1969), Frsncis (1973), Kutner (1974), Winer (1971), etc. Thete are different favored methods in these papers and even different method names. Rather, I consider how to use SAS '72 to analyze the unbalanced design with varied methods. In SAS procedure REGR, the ""Sequential 5S"" is equivalent to ""Fitting Constant Method"", Le., Method III in the previous table. (also called the ""Stepwise Forward Method"") and the ""Partial SS"" is equivalent to ""General Linear Model"", Le., Method I in the previous table, (also called ""lIackward Approach Method""). Io my knowledge, there is no major statistical package that will do Method II, directly. Contrary to Francis' negative comment on SAS, SAS-REGR maybe the only package that will provide all three methods without too lIWch trouble. Ibe generalization of Method II from the above two way factorial design is",Sugi-76-23 Chao.txt
"J23 DISCRIMINAlI'l' OR CLUgJ'ER ANALYSIS Harold. F. Huddleston Paul D. Ho}lkins Statistical Reportlng Service U.S. Department of Agrloculture DISClWIIlWIT OR CLUSTER AlIALYSIS this °p..p°er discusses the use of SAS for several types of pattern recognition probl~ which have been studied by the Research Division of SU. Some results for several small data sets are presented as a meana of indicating the type of data and the type of solution obtained. Specifically, we focus on two types of analysis: (1) The Maximum Likelihood Discriminant Function where the objective is to classify individual data points; in~ividusl (2) Techniques involving relationships between groups of data points which employ both ma:z;:ta. likelihood discrilniunt methods and clustering methods in a sequential manner. Maximum Likeliheod Discrimination applications, which our agency have, typically involve discrimi..., The nating between natural populations such as: (1) Fruit on trees from background noise Uke: leaves, limos, oark, sky, ground and shadows using ground (sideview) photography; (2) Fruit trees in an orchard from background noise like: hedge or border trees, ground, water, using aerial photography; (3) Identify individual field crops from background noisss like: woods, native pasture, wssteland, residential araas, parks, etc ·· uain& aerial photography or LANQSAT imasery. The first step involves obtaining mean vectors and covariance matrices for known samples of tbe target of intereat(s) and the individual cacegories af the background objects. If it appears advantageous to combine over- lapping or multi-mode background cstego-ries, this is done l'ri-or to dete_ining  actual discriminant categories to be used for unknown data points. ~he This decision is based on tests of significance for mean vectors and visual inspection of the marginal distribution to verify that a statistical aigu1.ficance implies ""practical"" importances. The variance-covariance matrices are also tested. for homogene",Sugi-76-24 Huddleston Hopkins.txt
"i CALCULATDfG COEFFICIENTS IN j EXPECTED MEAN :J\UAliES USING BAS , Henry K. Hess NUS Corporation Eoological Soiences Division Summary The method of ""synthesis"" used in calculating the coefficients in the expected mean squares is illustrated with the use of program statements. Introduction Methods of estimating variance components from unbalanced data are given in C.R. Henderson (1953). H.O. Hartley (1967) developed a method of calculting coefficients of cr 2 'swithout first requiring'the algebraic form of these coefficients in the expected mean squares. Hartley called it the method of i ""synthesis"". with the use of SAS program statements, Hartley's method of ""synthesis"" is illustrated in demonstrating several l of Henderson's methods of estimating varianc.e components. I Notation Let the general random model be: p 1 + Xb + e y; (1) where y is a N x 1 vector of observations N is the total number of observations in all subclasses. P is the overall mean and is a scalar 1 is a N x 1 vector of l's X is a N x p design matrix of zeros and ones determined by the data.  JJ5 b is a p x 1 random vector e is a N x 1 random vectar of error terms b includes elements that are random effects with zero means and zero covariances with those of every other effect. Let , b' = Ib'1.b'2.b'3 ·.... ' b q). = represent q random factors each with si levels and p E s· l. and let X be conformably partitioned. The model (1) is then written = 1 + (. xi bi y i l ·... ,q =)l l. Discussion The computational technique of Hartley's method of ""synthesis"" in estimating the coefficients requires having available or being able to generate the above unrestricted design matrix X, where each column of X is composed of zeros and ones. Once X is available each column of X is treated as a vector of data for an analysis of variance. SAS program statements can be used to generate X if it is not available for analysis. The sole program statement required to generate X is the comparison operator described in SA",Sugi-76-25 Hess.txt
"TUTORIAL rn PROCEDURE WRITING SESSION 3B, TUESDAY, JANUARY 27, 1976 by JOHN SALL SAS PROJECT Most of the lIl8.teria.l covered in this talk is from the ~ Programmer's Guide (version 75.2). The manual is available from the SAS Project for $2.00. }. The material presented at, the tutoria.l which cannot be found in the Progranmer' II ~ is also included in this paper. · It can be very easy to write a SAS procedure. When examllung the Programmer's Guide, you should keep in mind that you only need to learn just a few of the routines in order to start writing procedures. Most of the routines are safely ignored. The sample procedure presented here uses only 6 routines. However, if' you want to get fancy, you can do practically anythiDg in a BAS procedure if' you are willing to learn enough of the conventions in the system. BAS procedures can invoke the arithmetic compiler to compile program statements into an executable module which can be called from the procedure. (This is done in NLIN). BAS procedures can parse their own expressions into any format. (This is done in MATRIX.) BAS pr'ocedures can exchange control to other external pro~ grams. (This is done in BMDP, SAS72, and in the sample here.) The advantages of writing BAS procedures are many. We encourage the, use of EL/l. It is versatile and lends itself to more structured programming than FORTRAN. The main caution to observe in using PL/l is that actua.l addresses, not addresses of dope vectors, must be passed to the BAS routines in'a BAS procedure If you want to see many examples of SAS procedures, try taking a look at the source that we include on the distribution tape. ~-  BASIC COOTROL STRUCTURES (0:63) (0:19) available OPnONS (1:30) P.A.RAMETEBS (lilO) DATASET REFERENCES (0:10) VARIABLE LIS'lS CUBTOM FITTED lTEM3 P.A.RMCARDS FILES (e.g. MODEL statements) STATEMENT STRUCTURES (e.g. ~TRIX statements) OTHER CUBTOM STRUCTURES (e.g.""NLIN) COMPILED CODE CALLING SEQUENCE 1. Look up the Procedure on the library. Is the",Sugi-76-26 Sall.txt
"357 NPAR under SA.S'7:; Daniel ""M. Chillo West Virginia University and descrlptIgn gf nEAR Rrtef history NPAR Is a computer program to perform nonparametrlc or statistical tests. It was written ~dlstrlbutlon-free"" originally by the Computer Institute for Social Science Reslla rch In 1966 for use on a CDC computer at Michigan State University Computer Laboratory. Michigan State University. East Lansing. Michigan. The program was written to be of particular Interest to research workers In the behavioral sciences, where the distribution of responses to a questionnaire, or measurements along a scale, may be unknown or known to be extremely erratic. The nonparametrlc tests In NPAR may be applied to these data, which fall to meet the requirements of the more familiar statistical tests of significance. However, the program provides features that would recommend It to workers In every field of research. In particular, the proGram determines a precise probabll Ity or ""level of significance"" for the statistics It calculates. In addition, the program makes provisions for missing data Items. In the summer of 1974. the Computer Center at liest Virginia UniVersity acqul red NPAR-J60 (a version of NPAR for use on IBI1 >60 or 370 computers) for Inclusion In a library of statistical software already consisting of SAS, SPSS. BIOMEO, and DATATEXT. The purchase of NPAR was made at the recommendation of the Statistical Software Advisory Group at WVU, who had surveyed ~. our cOr:lputer center users. The survey Indicated an unanswered desire for a nonparametrlc statIstical analysis COMPuter pror.ram. The Initial response to NPAR was only slight use. In comparison to the Initial response to SAS. The computer center at WVU had Installed a version of SAS In early 1970 and SAS quickly became the most frequently used of our statIstical computer programs. In fact. It Is the most frequently used application program of any type. At this time, the author was writing a local SAS procedure to allow",Sugi-76-27 Chilko.txt
"Eiitor's Comments Copies of the next. two papers were sent to the authors of BMIJ, SPSS, SAS and OSIRIS for their comments. These comments were then sent to the original authors of the papers for their comments. This, we hope, will elilllinate some of the potential for misunderstanding of a peper of this type. , ? , .- f \ ~. ~. spstr A COMPARISON OF HMD. SAS AND by , T. Papaioannou, G.P.H. Styan, and L.L. Ward , MoGiU.Univ6'Psi-ty and BeU canada I' ! Three of the moat extensively used statistieal subroutine packages are BND (Biomedical Computer Programs), SAS (Statistical Analysis System), and SPSS (Statistical Package for the Social Sciences). These user-oriented packages possess routines which can perform various statistical techniques. Although they are generally similar in both cost and ease of use, they are often quite different in their scope, content, ,and presentation. The following notes illustrate some of these similarities and differences. Unless otherwise indicated the results reported below refer to BMV (lg73) and not to the more comprehensive HMDP (1975) series. 1. SIMPLE DATA DESCRIPTION AND TABULATION All three packages can perform various data descriptions and 0, S4S and SPSS have the sbility to d~ically call sny number tabYlations. of routines in a single pass and to produce various descriptions and COD- densations of the data. 8M.D does not have this capability; it requires tbe separate execution of its individual programs each of which is designed for a purpose. Therefore, from the point ef view of data deBcrip- sp~ific ta~ulstion tiGO and as well convenience and economy, BAS and SPSS are 8S better,thaa BMO. 1rart of the results reported harein are frOlll the c ....rses Mathe....tics l89-17a,,.\I679B Advanced Statistical Meti'lods I, 11 offend by the aUI:D.or · · , MCGill Uaiversity during the years 1'73-1915.  SAS has separate procedures to print, sort, rank, plot, produce in~ervals, frequency tables (at group chosen by the user and construc",Sugi-76-28 Papaioannou Styan Ward.txt
"380 1 The Relationship of SAS to Other Packages J. Philip Miller Division of Biostatistics Washington University Medical School St. Louis, Missouri 63110 Professor papapioannou has just presented a fine examination of the features for statistical analysis which are present in the SAS-72, SPSS and BMD packages. The question and answer session has, however, pointed out several of the difficulties in this approach. Because all of the packages are dynamic entities, comparisons become invalidated as new versions of the systems are released. Thus, all of the systems he described in his study, which is just a few months old, have had major new releases issued. Perhaps, however, the more important point to be considered is that the various systems were designed to meet differing design goals, and studies which make comparisons only in the area of overlap may bring inappropriate criticisms leveled against some of the packages. Because my experiences within the field of statistical com- puting span a period of over a decade and include experience with most of the major statistical computing systems, my own personal observations may help to place SAS in perspective with three other major statistical systems: SPSS, OSIRIS and BMDP. These three systems are chosen because they all include facilities for data base management and storage, as well as procedures for more formal statistical manipulations. They also all utilize a special ""progranming language"" for user specifications of operations, and all enjoy a fairly wide distribution, especially in the univerSity and in the research and development community. Unless other- wise indicated, all of my comments in this paper will refer to the most recent versions of these systems, SPSS, Versions 6.0 and above2 ; BMDp 3; OSIRIS-III4; and SAS_76 5 · 1 Originally presented at the First International SAS Users Group meeting; Orlando, Florida, January, 1976. 2 SPSS: Statistical Package for the Social Sciences, Second Edition, N.H. Nie, et",Sugi-76-29 Miller.txt
"398 A CONVERSATIONAL FRONT END TO SAS Julian Horwich and Mark !helps Abbott Laboratories AllSTRACT A conversational data entry and data management system for Drug Clinical Trial data has been operational at Abbott for the past year. It provides a direct interface into S.A.S., even though it runs on a DECsystem-IO computer. Data may be entered via various CRr or hard-copy keyboard terminals. INTRODUCTION Before a drug may be approved for entry into the marketplace, it must go through extensive animal and human testing. The latter is accomplished through what is called a clinical trial. Volunteers are given the new dTUg by physicians who record the data on ""Case Report Forms"". These forms are then forwarded to Abbott. The data is then entered into a digital computer to produce formatted reports, statistical analyses, and graphs. The system described below has been written to handle the entry and management of this data prior to its use in SAS, BDMP and other . statistical packages. Its aim is to eliminate much of the problems and human time involVed in handling this data. DICTIONARY BUILDING While the most efficient system (trom the computer standpoint) would be one that was coded by a programmer for a particular drug study, this is not practical from a human standpoint, Our aim is to eliminate the need for computer programmers in both the data entry and the analysis. In the case of the analysis, much of the work is now done by statisticians or data technicians with very little aid from· oomputer specialists~ The aim of the data entry system is to provide the same operating philosophy. A program was written to, conversationally, build a dictionary for each drug study. This is used to drive the data entry, control the data management and provide the dictionary input to S.A.S. The data technicians are.asked various 'l.uestions by the program about their data. 'i,uestions asked are based on the previous answers, The 'l.uestions are designed so that the most COllUJlon an",Sugi-76-31 Horwich Phelps.txt
"403 SAS USAGE AT ABBarT LA.BS Julian Horwi ch Abbot t Labs In the late 1960s much of Abbo tt's drug resea rch compu ting involv ed labor ious work by profe ssion al progra mmers to produ ce repor ts and statis tical analy sis using the tradi tiona l ""procedure-oriented-la.ng u~es"" of FORTRAN and COBOL. A typic al repor t, even with the avail abilit y of statis tical subro utines would take sever al weeks to month s to produ ce. Clear ly there had to be a bette r way. Sever al packa ges were bough t to help solve this proble m. stati stica l pack~es such as BMD and MANOVA were bough t to shorte n the time requi red to do stati stics . The Cambr idge Cross tabs and UC/360 packa ges were bough t to produ ce cross tabul ation s and forma tted repor ts. Initi ally SAS was bough t to supple ment the statis tical packa ges. It quick ly became clear , howev er, that SAS provid ed addit ional featu res beyon d stati stica l analy sis. It had exten sive data manip ulatio n featu res that our other pack1l;es did not have. It provid ed a f'ra.me work, much like IBM's l'1AN pack1l;e, to devel op our own compu ter langu age by writin g our own ""PRoo ·s"". It provid ed a means of linkin g betwe en our vario us pack1l;es, servin g as the :focal point of our data analy sis. Final ly, and most impor tant, it was a langu<l;e that could be used effic iently by peopl e who were not profe ssion al compu ter progra mmers . After some initi al pushin g by Jim Duart e, a forme r Abbot t statis tician , class es were held by Julia n Horwi ch to train Abbot t statis tician s and data techn icians on the use of SAS. Since that time, and contin uing into the prese nt, consi derab le perso nal aid has been pro'li dedto 'the'in div1d uaJ; user. For any langu1l;e to gain accep tance at an insta llatio n there has to be a person provi ding help when proble ms occur . Consi derab le modif icatio ns and addit ions were also made to SAS by Abbot t perso nnel (desc ribed in anoth er paper to be prese n",Sugi-76-32 Horwich.txt
"404 ABBOTT WRITTEN ADDITIONS TO SAS Julian Horwich, Jane Abel, George Chao, Jilll Trefren Abbott Labs The SAS language provides a vehicle for custom developing specialized computer sub-languages to fit a given application. At Abbott, SAS development first began with the modification of existing FROCs. Later our own FROCs were designed and written. The FROCs were developed by the four authors and by a summer worker, Carolyn Smelter. The first FROC, MEANSX, was a modification of the SAS72 FROC MEANS. It allowed the S.E.M. to be printed in addition to the standard statistics. It also allowed any of the statistics to be put into the output data set Another modification involved improving the scaling of FROC PLOT. PLOTX forced the axes to a mod-5 range and was a bit better than PLOT in selecting the labeling of the axes (e.g., less decilllal places when applicable). PLOTY was a modification of PLOTX. It allows the user to specify their own scaling. It also provides the ability to overprint vertical and horizontal lines through the plot. These are useful to specify ""normal"" limits and to divide time periods. Footnotes are also allowed by using the PARMCARDS feature. FROG STATX and STATY, new FROCs, allowed the user to create a new data set with additional observations every time a BY variable changes. The new observations provide the insertion of the following statistics. N, SUM, MEAN, Co=ected Sum of Squares, Standard Deviation, Standard Error of the Mean, Variance, Minimum, Maxilllum, CV, Median, Mode, Skewness, Kurtosis, Percentiles. While the initial intent of these FROCs was for statistics, STATX and Y . are used for business reports. Blank lines are provided between the original data and the statistics observations. While STATX and STATY perform statistics on ""columns"", CSTATX performs univariate statistics on ""rows"" across an observation. A new variable is inserted with the name of the statistic (s) that was specified as an option. FROC FORMATX allows data to be p",Sugi-76-33 Horwich Abel Chao Trefren.txt
"GENElIJ\TllIG A MAIN EFFeCTS DESIGN J. H. Goodnight Using the prunciples described appendix 9 of rul~s mai~ eff~cts .ppiy for any plan. in ~~ Guide~ ~ Useris any effects design in- wlving any nUlnber of factors at any number of Note~ A P;KQJU' main effects plan may always be in 1 + (p - 1) + (q _ 1) + (r - 1) c~structed levels may be constructed. observations. Since the underlying goal at a main effects plan is thet all simple differences for each factor With a little practice, you oan omit the inter- eettmabl~, estUpahl~ be the general fOrm of ttJe-diate step of writing down t~ design matrix funotions """",y b. written down and ... sily tr=s- and go direotly to the factor level list. lated into the design ~trix ~. for example, consider a 3 _x 2 x 4 main effects Consider a 2 x 2 x 3 1II!lin effects plan Example: plan in 7 observat:ions. in factors At B ~ and C. The general form of General Fa.ctor Levels FOHn estimahle functions would be; u L1 A B C u L1 ,1.1 L2 4. .3 2 ,1.1 L2 L3 1 2 4 A2 A2 L1-L2 2. 4 LI-L2-L3 2 A3 B1 ·L4 Bl L5 4 1 3 L1-L4 B2 LI-L5 B2 2 3 1 Cl L6 L7 Cl 3 2 2 C2 L7 L8 C2 2 3 3 C3 L1-L6-L7 C3 L9 , C4 L1-L7""18-L9 1- , f; The deaign matili X may now be constructed from ~ the gen;tl""al fom of estimable functions as shown i' f~ below. f V U At A2 Bl B2 Cl C2 C3 A II C ! Llgl 223 1 0 1 1 1 0 0 0 i 11--12-1 i '1 I} 1 0 0 0 1 1 2 3 Ll_L4-1 1 0 1 0 0 0 1 1 2 1 3 ~ ~ Ll.L6-l 1 0 1 110 2 2 I} 0 1 Ll..t7al 1 0 1 2 0 0 0 1 1 2 2 Bere the first row of X is genarated by setting Ll-I (all other L's = 0) the next row of X is 1 gen;trated by letting Ll and the next rree co- efficient ba one, etc. The same construction I",Sugi-77-02 Goodnight.txt
"ERl10R tERM FOR LATIN SQUARE WHOLE PLOTS Jolm Sa11 Consider a. split plot experiment Where the whole plot is arranged in a Latin Square. It is easy to find the whole plot error by hand--but how do you specify the error term as an effect- for a TEST statement in SAS7 Consider the keyout: Whole Plot: ROW COL VARIETY ROW*COL - VARIETY Split Plot: TMT 1MT*ROW TMT*COL 1MT*VARlETY residual ""~OW*COL The expression - VARIETY"" expresses the idea of VARIETY a. a portion of the RCM*COL interaction, with error being the remainder of the interaction. But there is no minus ( - operator in SAS mOVA. Consider the te:rm ROW*COL*VARIETY. mOVA compute. SS by obtaining the raw 55 I then subtracting out the IIcontained"" S5' s. The partition :for Rmr*COL*VARIETY is the same as that for R~OL I and thus the raw S5 is the sme. But the VARIETY 55 is subtracted from ROW*COL*VARIETY; i 1: acta as ROW*COL - VARIETY I the tem we -want. Consequently t we use ROW*COL*VARIET'l in our DIOdel and test with: TEST II=ROW COL VARIETY E-ROW*COL*VARIETY; 2",Sugi-77-03 Sall.txt
"KRUSKAL-IIALLlS AND FRIEIl'I!\N TESTS IN SAS John Sall SAS lost! tute You may not be a:ware that many non-parametric 'lMT, and T is the number of treatments~ Friedman's statistic F is tabled; it is approximately chi- tests can be performed using PRO:::: RANK with PROC ANOVA or PROC GiM. Frank Harrell and square with T-1. degrees of freedotn. Bill Gjertsen of the Lipids Program at UNC- Chapel Hill have pointed out several such uses. There are better ways of handling ties than a.veraging them as PROC RANK does. Also, you The Kruskal-Wallis test is a one-way analysis chi~square don I t have to convert to a test. The F tests that PRQC ANOVA produces are asymptoti- of variance on ranks. If' you have a balanced cally valid, and may be reasonable even in one-way layout, with Y as the response variable fairly small semples. and TMT as t~ variable~ classification run these SAS statements: PRIX RANK; VARIABLES Y; RANKS YR; FROG ANOVA; CLASSES lMT; MODEL YR=1MT; Then compute H.5ST*12j(N*(N+l» wheriS SST is the sum. of- squares for 'IM:r in ANOVA and N is the number of observations. Critical values of significance probabilities for H, the Kruskal-Walli9 statistic, can be found in tables, Or a approxiruate chi~square i' , fi value can be used. '{ two-way analysis of The Friedman test is a two~way variance on ranks. If you have a layout of blocks (BLOCK) and treatment. <TMT) with one observation per cell and Y the response variable, run these SAS statements: ~ROC SORT; BY BLOCK; PROC RANKi BY BLOCK; VAR Yi RANKS YRj PROC ANOVA; CLASSES BLOCK TM'l'; MODEL YRo= BLOCK lMT.j Then compute F~SST*12/(T*(T+l» where SST is the sum of squares for in MiJOVA 3",Sugi-77-04 Sall.txt
"RETRIEVAL AND REPORTING OF SYSTEMS DATA SETS John Sall We tried challenging SAS's retrieval capabilities contain all the information needed to reconstruct with same pretty tough system data sets. a linkage edit map and cross-reference for the module. And SAS is adept at retrieving this We wanted some reports on our program Ub""t'aries: Once it is in SAS it can be manipulated. data. what Wfilre the members? and reports can be generated. We have an appli- how many tracks did each take? list the members sorted by name, address, cation written in SAS that: 1) constructs a module map aLmost exactly and loading size.... We wanted something a replicating the one produced by the little more flexible than IEHLIST. linkage editor; , , 2) produces a cross-reference (both ways) So we coded up a brief SAS job to read the that we think is more conei se and inf'orma- directory of a partitioned data set and produce tive than that proOuced by the linkage the desired reports. The directoTY has fixed editor; length records, but you have to scan aver a it even reconstructs the linkage edit 3) variable numbeT of variable length subfields: control cards needed to specify the not a job .for just any retrieval package .... existing overlay structure of 'the program.. toIext assignment: generate reports on what data ;: , VTOC~- sets are on a disk volume (i.e. read the I enclose same listings of the code for doing "" volume table of contents). The VTOC is a mixed These &re alTeady distributed in these taska. file: the records are various types of DSCB's. SA'l. SlIMPLE on the distribution tape. 'Ihe big problem is that when a data set has more appli~ than three extents! you have to look for a A minor correction to t.he LOADMIIP Note: cation must be made if you work from SA'l. SAMPLE. ""fo:rma.t 3"" extension and match it with the i, t Change the MAXCOL logic to the statements original ""format 1"" DSCB in order to get all the , "" enclosed here. space allocation da-ta.. SAS ':$ sort and merge i i",Sugi-77-05 Sall.txt
"SAS - GLM PROCEDURE AND ANALYSIS OF VARIANCE F. M. Speed, R. Hocking, O. P. Hackney R~ Mississippi State University of a method would appear to be the appropriateness 1. INTRODUCTION of the hypotheses being tested. Other factors In the analysis of linear models for designed such as ease of computation and orthogonality of quadratic form cannot be justified if the experiments with balanced data, there is general agreement on the appropriate Analysis of Variance hypotheses tested have no meaningful interpretation. (ANOVA) Table. Or, stated uifferently~ there is To describe and compare the options, we shall a general consensus of opinion on the hypotheses tested under such headings as main effects and use the full rank, or p-model, described by Hocking and Speed [17]. This model allow5 us to intel""action. remove many of the sources of confusion as the Attempts at analyzing unbalanced designs are hypotheses can be stated simply in terms of parameters which are easily understood~ namely~ generally based on extensions of the methods for balanced data. Unfortunately, there are a number population means. Since several of the options of possible ways of generalizing the balanced can be related to the R( ) -notation procedure analysis, and they do not in general lead to to generate sums of squares, a brief review of this technique is provided. A more detailed unique results, The lack of agreement between the different analyses has led to much confusion account is given by Speed and Hocking [31]~ and has prompted a number of papers in the recent statistical literature. 2. THE FULL RANK MODEL The paper by Francis [9) compared the results of four computer programs and discussed the ra- Following Hocking and Speed [17]. we consider tional for making a choice. He concluded that a model for the analysis of variance in which it the program, BMD10V (BMDX64J [6] provided the is assumed that we have observations on each of most suitable analysis. Kutner [20] related the PJ normal, po",Sugi-77-06 Speed Hocking Hackney.txt
"SOME GRAH!ICAL A.'ID STATISTICAL DESCRIi'rION OF INTERACTION univerait~ Paul N. Hinz} IOWa State spaced equally along the abscissa and plotted IIIl'RODUCTION pOints representing data. from tbe smne block are A standard assumption in the analysis at data. connected with stra.ight ~ines. When interaction t'rC1Dl a randOllll~ed block design is tha.t the is present, the vertical distance between two b10ck and trea.tment effects are additive. Minor lines will not be const8Jlt at all treatments for departures fram. this al3,sUJDIltion can be to1erated a.t least one :pair of b.locks~ It can be diffi- without unduly affecting the validity of the a- cult to use sucb a. :plot to form. judgements on nalysh. However, when 1a.rge departures :f'rom the presence of intera.ction beC8.use the judge- the assumption are present the residual mean ments must take into account statistical fluc- square will be inflated leading to a. bia.sed es- tuations in the data.. tiJnate of' errOl' and an unambiguous definit1.on of treatment effects is not even possible. Thus} Althougb this type of plot is useful, it can be methods for detecting non-additivity B;[""e clearly improved by rearranging the poaition of the desirable. Same statisti~al methods for detect- treatments alang the abscissa.. The modification ing non-additivity have been given by Tukey invo1vea use of the same scale for the abBcissa (l.949) """"a Mandel (19/>1). Althougb these meth- as is used for the ordinate and use of the ods are ver,r usef'ul, they are not used routine- trea.tment averages (across all blocks) as the ly because research workers and data analyists horizont&l plotting positions far the data. have difficulty perfor.ming the necessary calcu- When no interaction is present} da.ta far eaCh of lations~ The pttrIIose of this paper is to pres- the blocks will be in para.lle~ straight linea ent a procedure for performing the caJ.cu1ations ~, with slopes equal to one ~ When interaction is by use of' SAS-76. In additicnJ so",Sugi-77-07 Hinz.txt
"REALLY GENERAL LINEAR MULTIVARIATE MODEL ANALYSIS USING PROC MATRIX AND THE UNC GlMM MACRO Ronald W. Helms and Alvin M. Best, III, University of North Carolina, Chapel Hill The statistical analysis of data by general ~ = S~~ linear models has been described by many authors where: such as Draper and Smith (1966), Searl. (1971), C is an axr matrix of constants, rank (C) = and Morrison. (1967). No attempt is made here to - asr. describe the topic of linear models. Instead, this documents a series of routines which per- U is a pxb matrix of constants, rank (U) = form linear models computations, within the - b~p. - framework of the SAS76 MATRIX procedure. The The rows of C take linear combinations of the excellent GlM procedure written by Dr. Jim model parameters in 8 which correspond to each Goodnight is one of several procedures within separate dependent variable and thus the C matrix SAS which perform linear models computations. However, GlM is not completely general and there can be termed a design contrast matrix. Since the columns nf the IJ perform transformations of are classes of hypotheses which the user is un- the model parameters between dependent variables, able to test using GlM. This greater generality it is sometimes called the dependent variable is the motivation behind the GlMM macros herein contrast matrix. Thus, one frequently wishes to described. These GLMM macros are actually a SASified version of a fORTRAN MGLM program test hypotheses of the form (Starmer and Grizzle, 1968). Ho: ~ =~ Still, the user is strongly advised to use ""2· GLM or one of the other SAS procedures and re- vs. Ha: ~ sort to GlMM within MATRIX only when the extra generality is needed. The standard SAS proce- The strong point of these GLMM macrOs is that the user has the ability to define the contrast ma- dures are easier to use and their output is bet- ter labelled. trices of interest. GlM and most other analysis of variance type programs will only estimate sec- General Linear M",Sugi-77-08 Helms Best.txt
"A User's Point of View of General Linear Models Procedure in SAS76 George c. Chao, Ph.D. Arnar-Stone Laboratories, Inc., Mt. Prospect, Illinois As an applied statistician working in the phar- The added test statement provides the option to maceutical industry, I have had several years test a factor other than the residual of a model, experience processing under SAS and other widely such as a split plot design. A typical eTinical used statistical packages: such as, IMSL, BMD and trial problem with repeated measurements is as SPSS. A comparison of SAS with other packages in follows: general [7, 8) was presented _t the First Interna- tional SAS Users conference. One new procedure PRoe GLM; in SAS76, [1) the General Linear Models, has been CLASS DOCTOR SEVERITY SEX AGEGROUP TREATMNT found to be particularly helpful in our routine PATIENT VISIT; MODEL Y = DOCTOR SEVERITY SEX /l.GEGROUP TREATMNT data analysis, and I would like to share our ex- perience in its use with you. DOCTOR*TREATMNT SEVERITY*TREII.TMNT SEX""TREATMNT AGEGROUP*TREATMNT I feel that the most successful feature of GLM PATIENT(DOCTOR SEVERITY SEX AGEGROUP is the flexibility of the model statement, which TREATMNT) is a modified version of the SAS72. The model VISIT VISIT""DOCTOR VISIT*SEVERITY statement accepts almost any valid statistical VISIT*TREATMNT VISIT*DOCTOR*TREATMNT model, and allows the specification of any degree VISIT*SEVERITY*TREATMNT/SSI SS2 SS3 and combination of interactions and nested ef- SS4; TEST H = DOCTOR SEVERITY SEX AGEGROUP TREATMNT fects. For example, the complete or incomplete erosSOVer design, in which the main effects are DOCTOR*TREATMNT SEVERITY*TREATMNT overlaid as a latin-square, cannot be obtained SEX'TREATMNT AGEGROUP*TREATMNT E = PATIENT(DOCTOR SEVERITY SEX AGEGROUP from most packages, unless you prOVide your own design matrix. It can be accomplished easily TREATMNT) HTYPE = 2 with GLM, however. The crOSsover design is of- ETYPE = 2: ten used in pharmaceutical bioav,ilabi",Sugi-77-09 Chao.txt
"PR~CEDURE WILC~X - A SAS-16 PROCEDURE FOR ESTIMATING THE RATIO OF TWO RANDOM VARIABLES',' K. Deva Kumar' and R. H. Strand' Section I. Introduction T~< and f~ have been tabulated for different sample sizes and different E'S (Owen 1962). The We have implemented a SAS-76 procedure, limits are then defined as: which obtains"" distribution-free esti- WIlC~X, \.1 \.1 mate with confidence intervals for the ratio of (7a) inf IT(p) - IT(e) - = two random variables. Thi< paper discusses the p options and parameters Of the procedure WILC~X. Results from a simulation study comparing the 1,~1 1 - r,>.1 (lb) inf IT(p) - T(p) small sample properties of the distribution- p free estimator and other estimators are pre- sented, .long with an application to environ- p and mental impact assessment. ~ Can be obtained using the modified ~guZa faZsi method as before. It is well known that Suppose (Xi' Yi) i = I ,2 ... n are n matched the statistic pairs. The rat,o p is defined as T - n (n+lj/4 + [n (n+l)(2n+l /24]~ (8) = pE[X], E[Y] p> 0 . T (1) = Thi< type of model is common in bioassay (Finney has an asymptoti~ N(O,I) distribution. Hence, one 1952). Bennett (1965) obtained a distribution- can approximate T~E and l,E in equation (7) by free estimate of p as follows: z (n+1)4 2 n+1))"" n (n+1) in (9) T = ---;r-- ± For a ~iven value of p define the n ~< l! JoE 2 ' pairs (Yi. Ui(p»), i = 1,2 ... n where Ui (p) = pXi . (2) z~~ where is obtained from the N(O,l). Fu~thermDre. let T(p) be the Wilcoxon signed rank statistic based on (Y;. Ui(p)). If p* is the In the following sections the distribution- true value of p, then the expected value of T(p"") free estimator will be referred to as Bennett is gi ven by estimator. =~ E[T(p*)] n (n+l) (3) Section II. Oescription of WILC@X It is readily shown (Sen 1963) that T(p) is a Besides the Bennett estimator discus<ed monotone decreasing function of p. Bennett de- earlier, procedure WILC~X computes the follow- fines the estimate p' as that value of p for",Sugi-77-10 Kumar Strand.txt
"PRODUCING KOLMDGOROV-SMIRNOV TYPE AND S~ATISTICS PLOTTING EMPIRICAL DISTRIBUTIONS ON A LINE PLOTTER WITHIN SAS Wil1Lam R~ Gjerts8TI and Frank E. Harrell Lipid Research Clinics Program~ Department of Biostatistics University o£ North Carolins t Chapel Hill in [1]. For our discuGoion aeeume that the obser- INTRODUCTION xl~ x2~ vations have been rearranged so that ···· Although SAS76 does not explicitly have pro- cedures which produce non-parametric atatistics~ xn. Distinct values among the observations are ~ it does amply provide the necessa~y tools for a denoted by zl< z2< ollo<zmo One way of calcula- user to create his own in ~st instances. At~ tention will be focussed on some examples of ting D correctly is to define D as +... statistics based on the empi~ical distribution n n (nn ,nn ) (3) D where: function (edf). Two features of &AS are essen- FIDaX n tial in doing anything with edf statistics. (4) D+osup (F n (x)-F0 (x» nx PROe RANK F provides the values for edf. F (x). n (5) D~ms~p (Fo(x)-Fn(x» and LAST.X senses when a jump in -an edf ia cQ1n- pleted. A second focus will be to illustrate Due to the mono tonicity and step function na- how a user written SAS procedure. PRDe PLOTTER J + ture or edfs the sups for Dn and D- are at tained makes it possible to produce plots on a line n plotter within SAS. These plots are of particu- points {Zj}. Since as. l:Ila:!!::ilnutns OVer all jump lar use in that· they can be directly incorpo- there are only two limit points at each Zj we can rated into reports. make the simplification: ~as~ly 1 AND 8 SAMPLE TESTS n:."". (""""'"" TWo statistical what p~obl~ ~tivate (4)' «Fn('j)-Fo('j»,(Fn(Zj_l)-Fe(Zj») follow's. Let Xl' (a) sample. soodness-ot-fit problem. ="". Qa~ (Fn(zj)-Fa('j» X ' .. ,. Xn be i.i.d. Tandom variables with con~ l.ikewise: 2 t1nuous distribution function F. The goodness- (5)' D--msx (F (Zj)-F (Zj 1» H(l):F'x)~ n jon - of-fit problem, is to devise a test of Therefore to calculate a one sample On within Hil):F(~)~ Fa",Sugi-77-11 Gjertsen Harrell.txt
"THE ANAL YS I S OF DI SSOLUTI ON OllTA US.ltIG SAS t"". tldll,o, John ,j, I'auger, St.ephen floward, Oaniel ,jest Virrclnia, University Dissolution profiles for solid dose leads to a set of parara-eters r~latec! to location, ann shape. forms represent severa 1 obse rvat ions scale; Alternatively, SOMe official dissolution OVer time an eXperlt7lental unit such On t.ests rely on a single, point on the as a tablet or capsule. The dissolution profile, designated as the phan,aceut ieal sc ient i st is interested in statistical comparison of these a~ount tiMe dissolved in a certaiM ~ period. 'profiles under a variety of conditions l relating to formulation characteristics, lot-to-lot, or brancl-to-brand variatior'l. These approaches each ' have' disadvanta~es, It May not be possltle exomple, Figure 1 illustrates to find a general Model to describe all For dissolution profiles resulting froc1 fl. r.:eneral curves in an experlrr:ent. ~odel ~ay conta1n ""many parameters, tablets from two dl ffercnt complTcatlng an overall Interpretation. t:1anufactLl re rs. The pharmaceut lea 1 scientist wishes to test the profiles The: analysis !'!:BY require an artful Interpretation of He p~ysical Meaning for {lJ ffer-ences in level and shape. Tfle of derived"" responses. A sIngle point latter characteristic 15 particularly may not adequately represent a curve. iMDortant ~ith respect to learning about diff~ronces In 'tne dissolution In selectln~ an approac~ to t~e analysIs ilech~nTsn. of dls,solutlon curves; \o;e ~r(jrose -U'ese Frrst, th~ data are used In n~jectTv~s. ~, t~eTr fnrm or In a sl~ple native to Second, t~e analysTs uses as trans~~rM. t nLlcr of the data as possible, but does r not rely on curve-fItting procedUre5+ last, the ~nalysis Is capable of showing i s d I ffe renees bet,!e""n prof 11 es C1 eve 1 and shape) ""cere realTstTc proflle-to-proflle variation exists. o I Sonetlmes a dissolution profile Is v available as a serfes of observatIons e Made at several intervals over tl~e",Sugi-77-12 Chilko Mauger Howard.txt
"DS 9~atistical concepts~ This paper stresses the educational value of the SAS package, particular- William A. Fowers ly in the teaching of advanced statistical methods. Nancy L. Elliott It is hoped that increased awareness of this as- pect of SAS will encourage more effective use of The University of North Carolina the package in instructional situations and elim- inate many of the difficulties associated with at Greensboro statistical-packages that have been discussed above. The features of the SAS package that will Introduction be emphasized are equally relevant to academic and industrial educational settings. Their value The widespread availability of statistical has been observed in academic statistical methods computer packages is viewed as a mixed blessing courses and in non-academic workShops with partic- by many statisticians. Among tne obvious bene- ipants from bUSiness, industry~ and government. fits are the tremendous time sav1ngs~ the in- creased accuracy, and the ability to perform The SAS Language complex analyses that would otherwise be com- putationally 1mpra~tlcal. However~ acccmpany~ng The most basic f~ature of any statistical the benefits of easy access are a variety of problems arising from the misuse of statistical package is the language or syntax of its contzol cgrds. The syntax employed by SAS is straight packages. With the aid of a manual, users are forward in that the lan8uage is composed of able to perform practically any type of analysis common sta",Sugi-77-13 Powers Elliott.txt
"/Ie GENERAL SAS MACRO FOR PERFORMING WEIGHTED LEAST SQUARES Wanda H. Burton Medical College of Virginia j situ~tion~ For this The SAS procedure GLM provides an excel~ lent means for performing least squares regres- o ~ion analysis wh~n th~ usual model assumptions can be made. The model referred to is Y Xa + £., !:o where ~ is no~ally distributed with mean 0 and variance a I. o The case to be considered here is that in which the observations remain independent~ but their variances are not all equal. The z and a' simple -transformation of the variebles is form of the variance-covariance matrix is cr V appropriate. These ~lculations are carried where V is a diagonal matrix with unequal diag~ out in the MACRO Wi REGR in statements 4-10~ nal elements, creating the variables Z,~O and ~l. o z Y 2 o ""n A unique nonsingular symmetric matric P can be found such that A transformation can then be made on ~~r 1 original model by premultiplying by P , x obtaining = p-lx~ p- 1£ p-ly + 1 or Z .= QS +f with obvious substitutions. This model satis- fies the necessary a:;;sumptions for carrying out the usual 1~a5t squ~res regression analy- -1 sis; that is, f-N(O,o I}. , X=Q=(Q....O.Q.J)= P The MACRO to be presented provide""iS a thorough analysis for a simple, linear ~egres sian rnodel j These transformations are made after the regression variables, X and YJ and the weights, WTJ are input separately and merged in state.., ments 27-65. An identification variable, ID, Let us use the following for the notati~n vari~ is included in each of the input data sets -and ance of Y: is necessary for -the merger. ~"" o PROC GLM is used· to c~mpute the ordinary least squares regression of Z on Q 0 and Q 1. Notice that the MODEL statement is-written-with NOINT option because the vector of ones normally Var (Y) present in a simple linear regression model has been transformed to a non-constant vector. Q O. o The OUTPUT facilities are used for access to-the predicted values and the residuals from the f",Sugi-77-14 Burton.txt
"USING SAS FOR MUlTIVARIATE ANALYSIS WIlEN tHE VARIANCE MATRIX IS SINGULAR W.J. W1lson, University of North Florida 2. Notation and Formulae 1. Introduction sUppose a mult:ivariate analysis is being__ The major objective in many multivariate perfor.med on a sample taken on a set of p var- statistical analyses is to explain the complex iables, relationship between groups of vector variabl- es in as £e~ terms as possible. Therefore, .... most techniques try to reduce the size of the 3[Xx:'p1j from q+l groups. A sample of ""i II set of variables concerned. Because of this J such techniques aa prIncipal component8~ factor analysis, cluster analysis and similar ones are usually included in the analysis. is taken from each grcrup with a total sample of in fact~ the primary objective of the exper- n = u1 - 1 observatiQns. Suppose that all p of bnent may be to explain the relationship be- the variables are not functionally independent. tween g~QuPS of vector variables ~ltb only That is, there exists a set of coefficients ~ one linear combination of the vector variable. such that~ In this type of experbnent, as many different for 1 f.~ f~ a!x 1s p-k+l, ··· ,p and a z variables may be included as CBn be feasibly ~- 1. ;L measured~ since any redundant variables will constSQt. This means that k of the p variables probably be eliminated early in the process. are combinations of some of the rest, or there Many techniques have been developed to re- are k redundant variables. The usual approach duce the n~ber of variables in an experiment to the problem""would require a transformation using Jl. variety of c:riteria. .. fr~ ~ to some other set of variables. The In some cases t the result desired is not matrix of transformation would be! .' necessarily that of reducing the dimensiona- lity of the problem, but rather of detecting -1 differences between groups (multivariate analy- where A'A=AA'=I; sis of variance), or of discriminating between 3 a' groups. In this type of analysis it is",Sugi-77-15 Wilson.txt
"[nterfacing a General Factoring Program with SAS: PROC MUFACT Richard J. Hofmann and Joseph C. Simpson Miami University* and how well the total composite of variables Part I Introduction represent a psychometric sample. The MUFACT procedure performs factor analy- Kaiser and Rice (1974) and Dziuban and Shir- ses and component analyses. The user may choose key (1976) suggest that this value should be greater than .50 in order for the data to be from a number of initial factoring methods, acceptable for factor analysis. The index assum- severa' transformation methods, and several ways of specifying S~S data set output files. es a maximum value of unity. This index has gen- erated some controversy and should not be accept- MUF~CT may be applied to an ordinary S~S ed in all instances without question as it can be data set (containing raw. data), a correlation matrix or a factor matrix. If the procedure is demonstrated that for certain types of correla- tion matrices the MSA indices will be lower than applied to raw data, MUFACT will exclude com- pletely an observation having a missingvalue .50 even with good factor recovery. for a variable in the analysis. If the user Initial Factor Matrix wants to build the correlation matrix different- ly, he can (for example) use the COR procedure and submit the results to MUFACT. Memory avail- Interestingly the initial factor ma- able is the only limit to the number of vari- trix is mainly of historical interest as it is usually rotated or transformed immediately after ables that MUFACT will analyze. MUFACT will operate with both singular and it has been obtained. One of the major problems in factor analysis is determining the number of nonsingular data sets as well as with small and large samples. Defaults are set internally for factors. The factor analytic technique name im- age analysis, alpha factor anlaysis, components Singular matrices and small data sets. Second order factor analyses are supported. External .nalysis (complet",Sugi-77-16 Hofmann Simpson.txt
"A PARSIMONIOUS APPROACH TO DATA TRANSFOl%l.'lION J. Bhilip Miller Division of Biostatistics School of Medicine Washington University St. Loui$~ Missouri A frequent problem confronring the applied Normal scores have not been widely utilized statistician is that of measurements which are by statistical computer routines because of tlie computational expense of direct computation uti- distributed according to a decidedly non-Normal lizing (1) or of the atorage of tabular1zed distribution. Conventional statistical methods values fOT each sample size. Blom (1958) became suggest a transfoTmatlon of the original variatea such that the new variable is appropriately dis- interested in the problem of plotting ~umulative tributed for conventional statistical techniques. frequency dist.ributions on ""probability paper. II He demonstrated that the approximation The present paper describes a new approach for the systematic choice of an appropriate trans- formation which is conveniently implemented 3/8) ""._l (~ - within SAS. The technique dQscribed haa probably z + 1/4 (3) not previo~sly been investigated due to its com~ r,n n putatlonal' complexity~ and it demonstrates both how new ,statistical methods are suggested by ad- where 4'-1 is the inverse cumulative normal dis- vances in computational technology and bow tribution functioDt is an acceptable compromise various components of s~s ~an:be, combined, in- a solution over_ a wide range of sa~le sizes~ Proc novel faShion. to facilitate nonstandard statis- RANK. of SAS allows the computation af this ap- tical analyses. "" proximation through the use of the NORMAL='BLOM option. (Refinements of Blom's approximation Normal Scores which depend on rand n are described by Hartner (1961) · ""Normal Bcores u were introduced by Fishel' and Yates (1938) for a powerful. di8t~ibution Conventional Approaches free~ 2 grQup test of difference in location. Hoeffding (1950) showed the loc.a.l opt_imum of In roost statistical"" texts the choice of-an",Sugi-77-17 Miller.txt
"MANAGING THE SOFTWARE/PEOPLE TRAOE-OFF Tbomas D. Lutz, Mayo Foundation The,_ Use of Softwa re. SYstems The objective of this paper is to give scientifi- cally and technically orLented individuals some fl.y .definition {stated above). a software system ~n.age:ment Insight Into the difficult process 'of should assist people with di ree-ting ~ computer to choosing between software packages and people. respond to thei~ information needs. Three types Although the management community wants to make of software systems will be considered here for sc.ientlfi~ decisions based on the analysTs of purposes of illustration: facts, maximizing resource productivity Is often the result of perplexing experiences and intu- 1. Compilers - Those collections of computer Itive judgments. Consequently, this brief docu- programs which translate people-like lan- ment wIll expose the reader to such nan-scientif- guages Into the ""mystical languages of com- it parameters as emotion~ enviro""me""t~ prof't~ puters"" ~ expenses. productivity. pride of authorship. 2. Dafa Management Systems - Prpgrams which verbal communication, etc. assist peop_te in storins data in some pre- As Dr. Gerald M. ""WeTnberg so aptly states, ""Com- de.termine-d structure so that people with poor memories can recall forgotten data which can Either puter programming is a human activity. 4 you can program or you cannot. Some have Iti be arranged according to new and different some donlt."" l As a result, an"" investigation Qf structures. the software/peopl e trade-off is reall y a -·ques- 3·. ApplIcation packages - A collection of pro- tton about' people - and using the peop~e resource grams which assist-£!£E!! in ana1yzing pre~ most effeGtively. rt should be realTzed t~at the viously stored information according to a term ""most effe(:tivelyli cannot usu~lly be-measured pore-determined methodology quite unique to a in terms of prodllctlvlty or tne best ·program for given application area. the least dollar"" For ex-ample, if th",Sugi-77-18 Lutz.txt
"ACCESSrl'lG CEIISUS SUI~""'AP,Y TflPE FilES III SAS ~. Vlr~lnla nan lei Chllto, Hest University The data prov Ided by the linlted States to this descrIptor is the census tract ·num!>.r. effectively, the RfTP cnmr:1and Bureau ofCensus in the form of census In the example specifies that any input 5uMmary tape files can be of ~reat use record fnr which the census sum~ary to planners and and to ad~lnlstrators tract number equals 001 Is to be However ~ resea rche rs in many areas. access to this Information by the selected. ""unsophistfcatedU computer user is difficult because of the large number of In ge'nerrrl, a sequence of RETR commands May be used. Each RETP co~anrl must data eler.lents and th-e many different a number. RETR co..,..,anrls .,1 th the hav~ record formats anrl sizes used to record sa"",e nunber are connecterl ....fIth a lorrrcal the data. fit tempts have been made to that provide RETR COMmands with different Min. write computer prOfframs nUMhers are connected with a 10,.lcal (1R. convenlent access to the census tapes. In partlcu!ar, /'0113 allows the user to se~uence: refer to data elements by a set of Oata Thus, the ·followl ... "" ~oscr i ptors. The user Can Ind icate, In conditIon 1 a hi gh-l evel cOl!l11and I aMUsr;e, '<h I ch RETR 01 contlltlon 2 fi 1es to access"" l·th I ch records RETR 01 to conditIon 3 retrieve, and ""hlch data elements to RETR 02 display. The '·OIl3 pr""pram, vIa a table be ' r~cord specifies that an Input ~echanlcs lookup, handles the of selected If condition 1 ant! con<'lt ion 2 locatlne the data In the fIles. are both Met or If conditIon 3 is met. The 11003 pror..ral1 Is distributed by CondItions are specified in the f'atlonal Data· Use and Access Laboratories IDUALabs), Suite 900, 1601 follo.,lng form: tlorth Kent Street, Rosslyn, Virginia data descriptor operation ·value 22209. The followln!"": ""re the operatIons \lhlch The followine is an example of ·the use May be specified as part of a conditIon of the nOD3 prOIl ram. and th",Sugi-77-19 Chilko.txt
"A SAS76 DATA MANAGEMENT SYSTEM DESIGN Ingrid Amara, University of North Carolina, Chapel Hill the two villages. An environmental health research project, based As in most survey research, form design and in Guatemala, presented tangible data management prob- The data is derived from a monthly influx from definition of data criteria were dynamit processes, lems. an assort~ent of surveys. These surveys are charac- Table 2 shows the major evolutionary sampling schemes terized by diverse sampling schedules: monthly, bi- and not the generations of form design. It should monthly, quarterly and annually. They also consider be noted that both the survey schedule and the tar- two different observational units, the family and get population categories refer to proposed goals the individual. The objective of a system design which were fulfilled at varying levels. However. for this study is the integration of the processing it is evident from these two categories that both of such datal with error detection and correction~ an individual file and a family file. encompassing in such a way that subsequent analyses can be read- all the monthly information would be ideal source ily completed on a timely and relatively accurate datasets for the subsequent analysis files. database. An estimate of the size of the database can The attempts to manage continuously the data- be ascertained by reviewing the numbers of records base in PljI and Fortran resulted in one-time pro- received as tabulated in the last column (cf. Table gramming for annual reports. Faced with a demand 2). The data listed reflect only those which were for additional sets of analyses. the data manage- actually utilized for three of the four years of ment was changed to that of SAS76. The motivation collection. for a post facto design lies in the efficiency dem- B. Detailed Data Description onstrated by exchanging the management systems. Impressed with an estimated minimum rat;{'! of Census was the crux of all other i",Sugi-77-20 Amara.txt
"PROWCING SAS FILES FROM LARGE MASTER FILES FOR A CLINICAL RESEARCH PROJECT Ca~olina Frank E. Harrell, Jr.,Lipids Research Clinics Program,.University qf North naffit'mative ll · Raeod.ing th~ blank with. E ailOWB The Prima~ P~evention Trial of the Lipids distinguishing hetween rlnegative"" and 11fQrm not Clinics Prog~am is & cl~nical interven- ReBe$r~h arrived yet ll · tion trial Q£ almost 4000 gubjeeta~ gathering For character variables, of Which there &re data for thousands of variables On each.fiubject. very few on our forms, value$ are merely changed The aubjects each sttent 60 visits to their to blank if the corresponding statuses are less clinic. Visits 1-5 are baseline vl~lte and data than 5. This could be modified to recode the forms for these visits are dissimilar. After c values to special characters instead of blanks. visit 5, clinic visits consist of only three Spacial programs are neQded t~ retrieve types: 2 month, 6 month, &nd ye~rly visits. So data for analysts from the m4ster file because for visits 6-60~ the vls1,t number and one of the data are eucTypted and because only a subset three system item numbers completely define each of the thouSQndB of variables for each subject variable for purposes of retrieval of data for are deSi~ed for analySiS. AnalyuiB file Bub set- statistical analyses. For visits 1-5, five· system tiog is initiated by listing the'mnemon1ce and itern numbers describe the address of each vari- visit number a of desired-1t-ems~ These are linked able~ Although data forms vary Be'ross clinic visits, there is much overlapping of variables with an item dictiQnary~ There are two separate item dictionaries - one: for visits ·1-5 and -One between visits tn termS of definitions, units of for visits 6-60. The item dictionary defines the IDeasurement_ and input formats. Therefore, we can system item numbers, decimal places, label, and reduce the problem of-data retrieval to its sim- answer type· for categorical items, given the p1ist terms",Sugi-77-21 Harrell.txt
"?ROC DAMOOE - SAS 72 PROCEDURE FOR LANDSAT REGISTRATION Paul D. Hopkins Statistical Reporting Service U.S. Department of Agriculture The Statistical Reporting Service (SRS) is Points with low residuals remain in the control net and points with large residuals charged with making U~S4 crop and livestock are removed. Check points that give low estimates. The agency 1s the primary source residuals may be added. of the acreage and production e-stimates, and forecasts. The Research Division of SRS The DAMOOE procedure may develop the looks for ways to improve these estimates and transformation coefficients from the input forecasts. The New Techniques section is currently investigating the Use of LANDSAT data set, punch them on cards if so desired, and even apply the transformations to the imagery to make acreage estimates, and to unknown point. the data set. The improve our area frame. in may also accept a previously ~rocedure defined set of coefficients and apply those Using current technology the estimation to the input data set. process using LANDSAT imagery can be outlined as follows: If the procedure is to develop the transformation coefficients, the input data 1. Obtain ground data for SOme random land set must have at least five variables. One areas. Specifically field size (acreage) and cover type (crOp). a CLASS character variable listed in statement 1s needed to flag observations as Accurately locate these areas on USGS 2. members of the set of registration points, quad maps, and on aerial photographs. points with corre3ponding geographic and 3~ Accurately locate these areas and fields scene coordinates accurately established. in the LANDSAT scene. Also required are four numeric variables Use half of the known fields to calibrate 4. listed in a VARIABLES statement. The first the classifier. two numeric variables on the VARIABLES 5. Have the computer classify the remaining statement must contain the values on the kna.m and unknown areas of the image. Relate th",Sugi-77-22 Hopkins.txt
"RETRIEVAL AND ANALYSIS OF CLINICAL DATA USING SAS 76 PROCEDURES H. S. Greenberg, M. S. Lajiness, G. L. Schooley and D. W. Johnson, The Upjohn Company Introduction combined all the statistics we wished to look at, There are several features of SAS that were found to be quite useful in optimizing code and con- the mean, standard deviation and the number of observations, into a single table for each solidating output to produce the desired analyses. This paper describes methods using these features variable (see Figure 2). The main advantage in doing this was to organize the statistics by drug at The Upjohn Company in the retrieval and analysis of clinical trial information. and by time period in such a way as to make any trends readily apparent. Retrieval of Clinical Information The program that we used in creating the table is Clinical data is routinely stored on magnetic in Figure 3. Statistics to be included in the tape in a sequential file containing multiple table were specified in the output option of the record types for each patient. A SAS program was means procedure. These results were then stored written (see Figure 1) to read information from in a data set via the OUT parameter for later merges and concatenations. It was necessary to the tape and create SAS files from one or a com- bination of different record types and then calculate the statistics separately for each drug store them on disk. by time period (cell statistics), over all time periods (column statistics), OVer all drugs by The SAS retrieval program used data statements to time periods (row statistics), and over all drugs designate which data sets were to be created and time periods (total statistics). The cell while the LABEL and KEEP statements described statistics were merged with the row statistics information to be included in those data sets. while the column and the total statistics were The INFlLE statement indicated that the data also merged. These two groups of statistics were conca",Sugi-77-23 Greenberg Lajiness Schooley Johnson.txt
"FORMATTED TABLES IN SAS76 M~ E. R. Oelong and A. Foulkes University -of_, North Carolina g~nerally The firgt step in constructing a formatted Several (up to 10) Title statements are used, as yell as the DATA _NULL_ and FILE PRINT table is to reduce the data to the desired cate- statements, which are explained in the prograIDc gories. This usually involves the MEANS Btat~ ming example. ment, mQst frequently with the options 'N' ,'MEAN', 'SUM' .'STD', and 'VAR', Indicator variables, a~ EXAMPLES long with the 'SUM' and 'MEAN' options. sometimes playa role here (for example, when a variable of interest is pulse rate (PULSE), the created vari- Tables on the next pages _are produced by 1~4 able, HIGHPR-(PULSE 100), will have its su& and the SAS program which follows. using the data set mean equal respectively to the number and propor- described 1n Appendix I. Notice that Tables 1 and"" 2 differ only in the variables involved (Pulse tion of subjects registering a pulse rate of over 100 ). At timea. two loIEANS statoements a.re u£led ~ Rate for Table 1 and Oxygen Volume for Table 2). Thus both are created from the same set of in- one with a by-group and the other over the entire structions with macrQ-supplied variables to the data set. and the two output files are con~ate and also to Title2 and TitlelO+ Pro~edure MEANS a~lows nated. This for the inclusion of marginal , The macro which con8tructs these tables is called information in the table. TABLESl2. the second step is tQ arrange the output of Table 3, which- requires additional JCL to al- the above atep to cad""apt fo, the format of the ta- low for a temporary output file, contains the last f~equently ble. Transposing the data Is involved lines from TabLes 1 and 2. Table 4 i8 included to calcal~t1on~ and additional are sometimes re- quired, as is the case when the standard error of illustrate the availability of marginal statistics a difference is reque""sted. The MATRIX procedure and inter-line printing. handles much of",Sugi-77-24 Delong Foulkes.txt
"CREATING A RUNNING MEAN OF THE LAST K-OBSERVATIONS LAGGED L-OBSERVATIONS Te1:TY M. Therneau and Glenn A. Augustine ~ May"" Clinic Certain problems, particularly in economics~ The fourteen statements can be divided into require lagging. In addltion~ the lagging of three groups. Statements 1 through 7 create a running, weekly average, for example, is often cumulative sums and negative cumulative BUms. useful in damping out dally variation. The Sta~ements 8 and 9 take these cumulative SUmB following example will 111ustrate the teehnlque. and. negative cumulative sums, comb~ne them by The important point 1s that it is not necessary a common BY variable, and create a running sum. to create 1agged varlables t and the number of StatQments 10 through 14 then create the running observations in the 1:u~lng average (K) and the means. lag (L) may be altered by only changing the lnput:ting Y is done at statement 2. Then value of K and L. First, we will look at the assign a value to K. Ihis is the only statement c.ode. necessary to (::reate a running mean. The. that has to ·be changed in order to change the basic statements needed are the following: number of observations in the running mean. No other statements have to be added or deleted. 1. DATA CREATE; Next we create a cumulative sum of Y stored in 2~ INPUT Y; TOTAL. The next two statements are the most. 3. K=2; (This is the only card you need to important and are the basis for the approach. change in order to change the'number of Statements 5 and 6 create two observations for observations in the running average.) each initial observation. In statament 57 we 4. TOTAL+Yi create a variable MATCH which represents a 5. MATCH'""_N_; RUNTOTAL:::TOTAL; OUTPUT; , certain observation. RIm1OTAL-'rOTAL assigns 6. IlATCH-_N_+LAG; RUNTOTAL--TOTAL; OUTPUT; ,"", the cumu1ativ~ sum of the Y-variables for 7. PROC SORT; BY MATCH; observation MATCH~ and this observation is out- 8. PROC MEANS NOPRINT; VAR RUNTOTAL; 2Y putted. In statement 6 MATCH",Sugi-77-25 Therneau Augustine.txt
"SAS 76 IN PUBLIC HEAL'IH RESEARCH RObIn Layland, SENIC Project The overlay feature of the scatter procedure In the field of public health research, used above allows the research to relate the pre- factors of availability and familiarity rather dicted and actual valLES of Y with ease, and re- than project's needs often dictate the choice af duces the cost of reporting resul'tS in tluLt the analytic and data management tools for use on a scattergram, in the format output from SAS 76, is given project. The research pmcess is often ready for presentation. This feature which al- hindered, i f not confounded, by pmgT!lJlUllers' and laws the user to save results of statistical pro- analysts I insistence on USing these familiar cedures, pernits complex analyses which hereto- packages despite their inadequacy in meeting pro- fore required mul tipl. steps, to be dene in a ject requirements. At the SEtlle Project (Study single operation. on the Effica,cy of NosocOlll1al In,fection Control) we have attanpted to evaluate and to choose a 2. DATA WINAGEMENT statistical package which mast closely meets aur TWo additional criteria used by the SENIC obj ecti ves and requireJOO!lts. We have found that Project in choosing SAS 76 as the project '5 pri- although SAS 76 falls short in some critical mal')' statistical analysis package are the sophis- areas, it conforms mast closely with what we tication and breadth of the SAS 76 data manage- want from a statistical analysis/data management ment facilities. Briefly, the SENrC data base is package. This paper outlines my view of the """""""",,sed of a nunber of vel')' large independent points on which this decision is based. files at varying levels of aggregation, some of which are hierarchically structured. It is cru- STATISTICAL ANALYSIS 1. cial to the project analyses that we be able to The data analysis requirements of the SEtlIC merge or relate the data across these files. Project, like those of mast public health re- search projects, ar",Sugi-77-26 Layland.txt
"'DAIALOOK', A SERIES OF ~CROS FOR DESCRIPTIVE STATISTICS William R. Gjertsen Lipid Research Clinics Program, Department of Biostatistics University of North Carolina, Chapel aill the Y2 mQdel are highly skewed and res~duals f~~ IN'J'RQDllCTION suggest that a log transfor.mat1on on Y2 may ,help. DATALOOK is a multipurpose series of SAs Similar residual plots of reSiduals VB. g%ouped macros which produ~e9 useful dQscript1vQ infor- ranked regressors can be obtained b~ forcing all mation ~ samples from univariate continuous the non-class regressors to be on the output data variables or discrete variables with a large set ~th an In statement within p~OC GLM. numbsr of values. The design for DATALOOK haG &B its cr1teTia; OTlIER IdFPLICATIOJ/S In a quality cont~ol situation suc.h as moni- i) a listing of both moment and percentile information by a by-vayiab,e list (BYVAR) toring noTmal ranges fo~ blood chemistries. it may be more appropriate to classify values as far- ii) an indication of possible farout values cut if they have Bome clinical meaning. For [1] instance. if a batch of values was constantly iii) a useful picture of the data being updated, a new value might be considered To accomplish i) - iii) in a typical run we would perform. the following operations Create phYSiologically farout if it was below the pth OL I above the ~th pe~centile based on the previous a data set which outputs selected momenta by a sample values. ln this case. farout val~s would by-variable list (BYVAR) and another which out- puts selected percentiles by ~~. Merge by be redef~ned apptop~iately and in addition to the BYVAR and print the res~lting data set with PRDC L-U interval which contains half the data two o~ mere plotting 8ymbo1e $ay. P and Q. could appear PIUNT. Next, put ID ufortllation and} QJ"" counts of faYout value. with PUT STATEMENTS. finally in the overlay plots. Furthermora. these plots produce overlay plots of mean, median and inter- over time on split samples taken at diff",Sugi-77-27 Gjertsen.txt
"HISTOGRAM CREATION WITH SAS PROGRAM STATEMENTS' M. L. Tharp' and R. H. Strand' Union Carbide Corporation, Nuclear Division Oak Ridge, Tennessee The SAS Histogram Procedure (HIST)', useful we specify below. Therefore, users should read for displaying and analyzing data, provides for and follow the input instructions very closely. vertical and horizontal histograms, but has the We recommend that the user become familiar with disadvantage that a numeric variable will be the description of the SAS-76 language before subject to grouping if it has more than 10 dis- trying to use this program. tinct v.lues. The DISCRETE parameter in this procedure is the overriding option for this maxi- INPUT ~~On mum number of 10 classes but it has some apparent input the user selects the type of histo- problems. gram desired by coding either V (vertical) or H (horizontal) in column 1 of the first data card. Since no histogram procedure currently The number of classes is coded on the same card exists in SAS-76,' a short code utilizing vari- in columns 4~5. The class value occurs in ous features of the PUT statement was developed columns 10-12 while the frequency for that class to produce simple frequency histograms with is coded in columns 20-25. The first class and frequency values are coded on the first data minor restrictions on the number of classes. .' These histograms can be printed vertically or card which, as defined above, contains the his- horizontally on the output page .long with togram type and number of classes. The rest of Single axis labeling and title information. The the class and accompanying frequency values are number of classes and the height of the histo- coded as described above, one pair to a card. gram are subject only to page limitations. No When all classes, as indicated in columns 4-5 of the first data card, have been printer plotted, specific graphic routines are required to pro- duce this type of printer plot. program execution allows for additional class",Sugi-77-28 Tharp Strand.txt
"s~.s IIiFORI'~TIO~J II ""ACRO SET TO PRODUCE ""APS OF SPATIALLY DISPOSFO ~. Paniel Chllko, West Virginia UnIversity CARDS; One use of the cOr.'Jputers at Hest VirgJnia UnIversity Is the production of 1 426.5 2 2E3.8 3 267.7 Inap5"" of spatially disposed 55 223.9 Information. That Is. the USer nas a · RM'K rOI.lI!TlES INTO FIvr GROUPS; number of areas In an x,y coordinate PROC RAllY. GROUrSoS DATA=DI\T~.l OUTmDnM; syste~ tnfor~atton and numeric VAR CVDP.60; associated \'lith each area+ A useful · I'ERGE ""IIP Mlr OliTPUT FPnt' p~nc RM!K; co~pute-r-prodLlccd repre5entatton of t,.,is DATA MAP: Is a l1ne prInter mal"" on inforMation ,'ERr,E ""AP IMTA2; whjcl, the areas are Identlflen with BY COIWTY; 5y~bols IF C('lfjTROl ~. 0 mEN RETURN; that convey the original numeric IF CVOR60 - 0 THE~ SYMHOl · In·formatlon. Sometimes tre synhols '.'; IF CVOR60 · 1 THE~ SYMBOL = '.'; chosan to represent the numerIc values l~densltyU IF CVDRiO · 2 THEN SY~BOl · '0'; vary In proportional to the 'il'; numeric value. The rC5ultinr, maps have IF CVDR60 · 3 nlHI Sn'BOl = ., IF CVDR60 · I, TllEfI Sn'BOl 'I""'; arcas, varying froM lightly shaderl to rlarkH' shaded, r-eprescntinr; the nUf:letic · READ SO""E lEGPm CARDS: Population dens tty ~aps inforMation. WV_Lf,'Ir.l: are fan"" iar e'a"",ples of this ~IEST VIR(JltJI"" application. 110RTAlITY RIITE - CMOIOVASClll~R COrlpute-r prorrrams (for example, SYMAP) specific to this application exist. In they funct i on as follo\:rs: r:eneral~ 1. Accept Iiser input of a serIes of · BOTTOII 20 % · = 21-40% deffned by map coordinates. The area5 o· ff = 61-80~ areas are Tdentlfied by an associated 1>1-60'; 1/ = TOP 2o,- code. numerIc 2. .~cccpt user input of ; i nforr.'lat ron associated III th the map · COI!CATEIIATE T11E IMP ArID LEGENDS; DATA flAP; areas. Sl:T ,11\P L[CEt'''l LEGF)'('2 i 3. OPtionally, accept Input symbols to · DPAtl TI·'£ ""IAP; ,- DR~,ICI""AP ; he used to represent the data and annotative Infor~ation. I! 4. Scale the data. attach appropriate .",Sugi-77-29 Chilko.txt
"SAf37~ IDSFITAL SlJRIIEY' DATA MANAGEMENT USING Phil Busby, UNC Departmen~ of Biostatistks SENIC is an acronym for the Study on the DITA SASOUT,fSV~f~ci Efficacy of Nosocomial (hospital-acquired) In- INI'IL!! ~~ SDlT!; fection Control, a large research proj ect span- UTLl! PSVS1 PDC :LNPUT TO SAS; sored by the Center for DiSease Control in t MPU"" At1an~. This paper will present several fea- , HOSPUl1 S 1-4 tures of SAS76 we have found effective in pro- PA TIl! lIT S 5-6 cessing da~ co1lected in the study. DeN $' 9- "" S 12 REnEAD The two basic goals of the SENIC Project REBl!lIDNO $ U are: 1) to provide statistical data that wi1l DUPSl!RNO S 14-17 describe the current extent and scope of in- lD!lTMII S 18-19 fection surveillance and control program acti v- $ 20-~,1 ll)~!TIlD i'ty in U.S. hospitalS ;2) to determine the S 22-23 lD~ITYY degree to .mich infection surveillance and DrSCRlIlI S 2U-25 control programs have lowered nosocomial infec- DrSCRDD $ 26-27 tion risks (i.e., incidence rates) over the DISCRYY $ 2a-2!' past ten yoors, S I!R'lICI!I $ 30 $ 31-32 AGE The proposed method of da~ collection, S 33 SEX . · called retrospective chart review, involves · reading a patient's hospital chart after the 88-89 SJ:TEQ $' dl.scharge to determine if an infection occurred. In order to validate the chart review method, four pilot studies were conducted in which chart R I!DDCq i 95 review results were compared with prospectively (Sq. +2) i 96 (ABDATPO - ABD!T!:S91 collected data. iii 100 11BCliIO - lB~n99 ) 1,112. HI STDITE S 696-699 SAS76 may be used to merge in addi tiemal Ii :zgQ-1Ql Sl'!:;U da~ such as that from ,the Iiospital Intervi..., UCCOllE S 102 SUrvey or the Regional Mldl.ca1 Program for 7QJ-106 aCllA:U i cross -studies at the hospital level. The hillb S 707-7f)B UCCNT level language features exemplified by the CVCQDIl ~ , 7r9-11C powerful file handling COInIJaIIds allow program- 111-11q CVDAT! $ mers to get out reports on subsets of a data I 7]:i-7]2 !;;i!:l!l:",Sugi-77-30 Busby.txt
"irect SAS to re-read a record (~) at' management, multi-files, report an~ to read more than one -occurrence of a writing using SAS.76. Attention will group of variables from the same be given to methods of reducing cOre record {@@J. and disk .pace as well as dynamically allocating report formats. Most of the Type II data I receive l1as been keyed into a disk file 0""'1 a 1?er paqe basis. The reason do-t..:1 is INTRODUCTION ent~[ed in this .... ay is to make it ~nalvze possible to the orcatest Clinical aata can basically be grouped. quantity of data - availablE"" (It any into two data classifications: point in ti'rne. Sinc-e various paaes repeat in differ-ent visit.s throu-qhout Type I a clinical trial, I produce '!tultinle data sets for easier access and file creation all data is At time of reportinq of data. present and in its antioipated is sequence. Type r data usually I is a sample coded module produced by a cl inical tr ial t.hat is DIAGRAM t.hat will process the various na-nes short in duration. is easy to It contained within 2! p-dtient visit. organize and report on Type I data since it consists of -complete It is obvious from this .,.mple that information on a sJrlall number of not only is data beinq manipulated subjects. into various datasets, but that we on1 y store in a da taset the va r iables Type II desired.. If there are paqes read that are not acceptable- to the narticular Clinioal trials of this type are visit being processed, a messaqe is in duration longer an",Sugi-77-31 Bronstein.txt
"8AS AS A PROGRnIMING TOOL AND CENTRAL DATA INTERFACE WIT'H OTHER STATISTICAL SOFTWARE Mike Foxworth, University of South Carolina Douglas Cookrell, University of South Carolina Gary Griepentrog, University of South carolina programs (mostly written in FORTRAN) of INTRODUCTION varing quality. THE FIRST PROBLEM This paper is about our attempt to solve a pair of related problem.. The problems are, first, how to encourage Most of the above mentioned use of the total range of softwear software prodct"" are · systems· · That systems ~ have available at our is, they deal, at least conceptually, instalation, and, second, how to with the whole range of statistical data implement new stand-alone programs in procassing problems. These include data sUoh a way.a to optimize their transformation, data selection and availability and usefulness. We have merging, and creation of a dictionary taken the approach of utilizing SAS to of variable naming and labeling solve both of these problems by first information. Generally a set of related cresting a single comprehensive software product. are used within the oommunication system with SAS at its systell\ to aocomplish a series of oenter and, second, by adopting a policy possible tasks, utilizing s more or less of attempting to put up all new coherent syntax for speoifying control stand-alone programs as SAS procedures infoJ:lt1ation. with conventional SASsyntax. · ····························· ** ····· 'l'!!E SITUATION TIl! TOOL!lOX APPROACH i As instruotors and User consultants SAS76 at the College of Business Administration, and the University of SAS72 South Carolina generally, we faoe many users. They are very diverse in their OSIRIS computing needs and desires. Our users have ready aocess to a large and SI'SS capably-run machine whioh· supports a wide range of statistical software. llMJ) (Canputer Services runs ~ IBM 370/168, with 5 MEG real storage, 36 disk TIlE BMDP spindles, 7 tape drives, and various peripherals, run under VS",Sugi-77-32 Foxworth Cockrell Griepentrog.txt
"SAS would have created a new BMDP File~ FRANE, J.W. 1978. The 1978 interface between SAS and BMDP, and some BMDP f~atUl'es of interest to Same changes were made in the BMDP source and SAS users. pp. 5 - 8. IN Strand, R. H. (ed.), overlays. The overlay changes entail placing the Proc. ~ Third Annual Con£ere:nce of the SAS Users subroutines SFTINP and SFDINP into the root segment. Group International. SAS Institute t Inc.~ The source changes were mDrror but necessary. These Raleigh, North Carolina. 318 pp. changes are included in the latest release of BMDP, called BMDP-77. The program revision dates for Recent changes in SAS-76 and BMDP-77 enable BMDP-77 are December~ 1977 or later. The necessary BMVP programs to obtain data from SAS files with- changes were not part of the April, 1977 release~ out the SAS file first being converted to a BMDP file. Thia new interface makes it possible for Formerly, a BMDP file output from SAS could SAS use'rs to ~conomically make use of many features have only one case label (alphanumeric variable) .. in BMDP that are not available in SAS. The new In the new FROC BMDP, two case labels can be interface also makes SAS an extremely attractive specified: lABEL: for the first and LABEL2= for complement to BMDP. the second. If SAS writes a BMDP file, missing values in the BMDP file are identified automatically by the BMDP ndssing value indicator rather than the",Sugi-78-02 Frane.txt
"USING SAS TO TUNE MVS H. W. Barry 1'1errill Sun Information Services P. O. BOK 47803 Dal1as~ TX 76247 214-630-6411 AESTRACT w. Barry. 1978. Using SAS to The raw BFM data is passed daily by 'SAS once. MERRILL, H. building nineteen SAS data sets in one 25 Lylinder pp. 11 - 34. Stra.nd~ MVS. IN R. H. tlIDe OS data set. Figure IV des~ribes the t~mporar1 PrQc.~ {ed.}., Third Annual Conference of SAS dat~ sets which are built in this phase. Note the SAS Users Group International. SAS that only 900 lines of SAS are required and less than North Carolina. Institute~ Inc.~ ~ale1gh, 3 CPU minutes of 168 are required to process the 318 pp. 120,000 SMF records daily in this phtls~. Using the Statistical Analysis System {SAS) To fully appreciate the power. flexibility. and SMF records (including RMF) can provide a and simplicity of SAS in this application, Appendix comprehensive source of information for the I gives the entire SAS code to axtract tlll of measurement of MVS. This paper describes a specific the information from the Type 4 and 34 SMF records. im~lementation of the data collection and reporting In only 131 linBS all of the reSDurce information portions of such a system. from those records is extracted~ condition codes are decoded into descriptive character strings, INTRonUCTION time stamps are consistently created and this data is stored as a SAS data set named STEPS I The major problem in computer system measurement The appendix should also point out the high and performance evaluation is the data collection maintainability of SAS systems, since the language system. SMF and RMF ar~ r~plete with valid and is so easily read and operates at the named needed data: the absence of structure in the data variable level, pi8c~a within SMF requi~es that comprehension be added by the data collection system. SAS data sets appear to the user as an O~ partitioned data Bet (although they are actually This paper desc~ibes the building of the direct access using BAS's own access m",Sugi-78-03 Merrill.txt
"control, and integration of selectable units (suls). HorTno~ M. M 1978. SAS - The Necessary Uti) ity .· o Expanded workloads that are now being for Computer Performance Evaluation and Control process~d by the computing ~ompleK, where (CPEC). pp.35 -40. IN Strand, R. H. (ed.), an MP complex may be operating TSO , IMS. and batch processes. Prac. r Thi rd Annual Conference of the SAS Users Group International. SAS Institute, Inc., o Extended requirements for such items as RaleIgh, North Carol ina. 318 pp. secur[ty, distrlbuted function, atc., that have grown along with MVS. INTRODUCT ION The point to recognize is that MVS repre- sents a larger, mOre ~omplex, and faster changing The role of Computer Performance and Eval- environment, and consequently has a greater re- uation (CPE) has increasingly gained attention in qui rement for management control. more organizations as CPE tools and techniques are called upon to solve critic~1 problems. Vn- Thi5 paper, therefore, introduces Computer fortunately, this traditional role of CPE has Performance Eval uation and Control (ePEe), a con- seldom been ex.tended in use beyond the ··sol ....e- cept based on CPE know how which includes report- this-crisis"" mode. ing and administrative procedures for management control. The CPH approach is designed to pro- The typical CPE process is more oriented to vide a frame-of-reference and processing system problem resolution rather than on~ after~the-fact that would serve as tne feedback system for co",Sugi-78-04 Morino.txt
"uipment class. and the unit of software being ABSTRACT measured. The value of the measurement in soft- This ~aper discusses the use of software ware physics will represent either one of ~e work vectors as the fundamental form for work- fundamental properties or a property derived in tsrms of these fundamental properties. For ex- load characterization purposes. Software work is one of the basic properties of software ample, if the rate of data transfer is measured physics, and has the property of being inde- this is equivalent to measuring the software w01:k pendent of processor speed, configuration de- W and the execution time Tx, and obtaining a value for software power P ~ W + Tx. sign, and is unaffected by other workload ele- ments. The genaral vector form of character- Software physics (or any other general ization is defined. Equations for calculating work are given, and examples of its uses con- theory concerned with the meaning and use of oom- sidered. The relation of this fo~ to the puter ~asurementa) must have what is called a "":precisely measurable notation"" with which to data used for synthetic benchmarks and work- represent the properties described. Such a nota- load analyses is briefly reviewed. tion has the characteristics that a value repre- * * sented in the notation will be unambiguously de- ill iii' fined. That is, two different people can be QUANTIFICATION REQUIREMENTS given the same· symbol, and they will be able to independently make measurements and obta",Sugi-78-05 Kolence.txt
"43 BACKGROUND ABSTRACT POTTER, M.B., 1978. History, Problems and It seems appropriate now, however, to Practical Applications of SAS in a Large present some background on the corpoTation~ its organization and use of computing resources. Industrial Organization. pp. 46 _ 49 In Strand~ R.H.(ed.), Prac., Third Annual Armco Steel is a multi-billion dollar company Conference of the SAS Users Group Inter- dealing not only in the making of steel but a180 SAS Institute, Inc., Raleigh~ in diversified bus1nesses~ with Corporate national~ North Carolina. 318 pp. Headquarters located in Middletown, Ohio. The company is organized into eleven operating divisions, thr~e of which are devoted to The purpose of this pap@r is to provld~ steelmaking. The8e d~v~8ions have nine basic some insight into the wide acc@ptance SAS bas s~~el-making facilities located across the enjoyed as a problem-solving tool in a large continental United States. Each of the steel industrial complex and to discuss certain problems p1ants have access, through some type of communication which can develop due to such acceptance. Various link. to the central data processing facility app11cat~ons, which exploit both the statistical and data management capabilities of SAS, are in MiddLeto'Wn. The problem areas addressed ate the discussed. possible pitfalls encountered upon implementation The other operating divisions are composed of a generalized, easy-to-use statistical data of diverse businesses, including the se~eral mana",Sugi-78-06 Potter.txt
"university of Missouri COlumbia, Missouri 65201 Moeschberger, M. L~ ~,d Ernest Hilderb~and, 1978. Use of SAS proceduree in estimating survival curves. pp.50-56. In Strand, R. H~ (ad.), Proc., Annual SAS Users Group Third Conference of the SAS Institute, Inc., Raleigh, North Carolina.3lBpp. International~ If a particular parametric family of distributions is assumed (as is often the case in ~uman or animal survival studies) then maximum likelihood techniques are appropriate to estimate the parameters of the life distributions of interest. From estimates of these parameters one can estimate the average life expectancy along with other pertinent quantities of interest. This paper will present an application of SAS procedures (viz~, PROC NONLINEAR and PROC MATRIX) towards finding such maximum likelihood estimates along with their estimated asymptotic exarn~le variances. An dealing with breast cancer will be used to illustrate the technique. INTRODUCTION (or, equivalently, the negative of minimizing the function). It assess is often desirable to statistically the life characteriatic of variQu~ types of individuals. These individuals may be POSSIBLE METHODS OF SOLUTION living organisms, i.e.~ interest may center upon making inferences-regarding the length of life Many optimization schemes exist for finding after soma treatm~nt has been applied or some the minimum of a function. A widely used scheme operation has heen performed on animals or human is Marquardt's method which is a co",Sugi-78-07 Moeschberger Hilderbrand.txt
"UNSYMMETRICAL PARALLEL LINE BIOIISSAY USING SI\S Dr. Ch iao Yeh Clinical Research De~tment leI Americas Inc. Wilmington, DE 19897 ANALYSIS OF VARIANCE AND ESTIMATION AllSTAACT PR!XEIJURES FOR RELATIVE RlTENCY Even in the most carefully conducted bio- assay exper~ent~ an accident circumstance or The:r:e are several reasons to analyze the data by the technique of Analysis of Variance unequal litt[ size may cause the loss of (A.O.V.). Fir-st, the estiTnate ofa 2, i.e., S2 observations and so destroy the symmetry of is easily obtained in this way and can be used the design. In this paperl testing for non- validity, point and interval estimation in the formulas for confidence lilnits. Secondly, tests of validity of some of the procedures of relative potency in an unsym- in the model are obtained and, assumption~ metrical parallel line assay will be discussed thirdly, the reslllts yield a simple s1..lIRl:iary to using SAS. A numerical example will be given. be used in the design of further assays.of the same typ'o INTRODOCTION 'Ihe total sum of squares sutrlivides into cOlTlpClnents ""blocks"", ""between doses"" and The technique of parallel line assay has been used widely in pharmacology for drug error. Furthenoore, the sub:iivision of the screening programs in the pharmaceutical C<lI1lponents for doses can be separ a ted (1) linear regression (2) deviation fram paral- industry. Potency estimation is a good way of lelism, (3) difference between SandT, (4) if telling how potent a new compound is relative there are more than four doses, the remainder to a standard drug. In additionr this assay can be lumped together as deviations from technique has been employed successfully in linearity. the clinical evaluation of analgesic effective- ness [c.f., wallenstein and HOude (1975)). Exact analysis of the assay, taking In most assays in the pharmaceutical account of the missing observations, would involve the solution of linear equations for industry, the responses can be assemble",Sugi-78-08 Yeh.txt
"4900l Table 1. Experimental data and description ABSTRACT Description Variable Name Lajinass~ M. 5"" and P. 1. Good, 1978, SAS and the evaluation of drug reinforeement~ Test compound TREAT pp.62 - 67. IN Strand, R. H. (ed.). Method of drug injection MOD Proc., Third Annual Conference of the SAS Dose in micro grams DOSE UG Inst~tute~ Users Group Internationa1. SAS Rat numbe.r NO RAT Raleigh~ Carol1na.31Bpp~ Inc ·· North ~ Number of inj ec.t:ions per HIDK (K 1 to 5) day for the five days on high dose (FR-I) INTRODUCTION Number of inj ec:tions per LIDK (K' 1 to 4) day for four days on low SAS proved to be an important tool in the dose (FR-I) evaluation of the reinforcing properties of drugs. L2DK (K' 1 to 2) The ver$stility of the tabulation and display NumbsT of injections per functions of SAS facilitated the development of a day for two days on the drug score. This score was based in part on a bi- low dose (FR-2) =I ~, L4DK (K to 2) variate confidence region and on ranking across Number of injections per day for two days on the several variables within an SAS observation. low dose (FR-4) Several measurements of reinforcement w~ra To get a better measure of reinforcement~ made on each experimental subj~ct& Tran~forma the number of injections is transformed to the tiona of the ~aw data were necessary to obt~in a total number of k~y presses. F~r example, the meaningful scale of measurement and to insure the raw FR-2 injection total is multiplied by two. normality of the data. The",Sugi-78-09 Lajiness Good.txt
"arch West Virginia University MOrgantown, West Virginia 26506 of less than 1000 inhabitants. nl Today, in 1977. ABSTRACT we are atill ~estl1ng with this same problem~ BOSANAC, E. M. 1978. A SAS-Based Small Area Pro- In West Virginia the development of ruxal Its Use in Primary Care Resource £il~ Syst~: primary care el1nlcs has been seen as a means of Development. Unpublished Report7 Office of solving the physician shortage in rural areas. Health Services Reaearch, West Virginia Since 1972, n~arly 50 new primary care clinics University. 318 pp. have been developed, with the majority of this development occurring in the southern part of the The development of rural prima~y care clinics State. Dur~ng the early stages of this activity, has be~n a dominant activity on the West Virginia site selection was not very cr~t1cal since the health scene for the last several years. Although vo~d was quite large. As development continued, much of this development occurred without an ade- however, increasingly marginal sites were selected. quate ~nitial examination, the situation was such Competit~on aros~ among clinic developers result- that nearly all these efforts were successful. ing in the construct~on of two clinics literally This proliferation of clinic development has closed across the street from one another. Plana ~hich off many of the choice sites, leading to increas- would have resulted in a similar a~tuatlon were ingly roarginal eite location. underway in sevQral othe~ areas. Face",Sugi-78-10 Bosanac.txt
"ngton University Lotlis~ St. Missouri 63130 ABSTRACT SPITZNAGEL, E. L., Jr., on leaving the operating room. The other important ~nd W. D. OWENS t tioD. 1977. Maintenance and analysis of anesthe- post-operative variables, length of stay in the hospital and deaths, are obtained by merging sia/surgery data with SASe PP.74-76. IN Strand. R. H. (ed.}t Proc., Third Annual admission-discharge records and death records with our data set. ThB three data sets arE first Conference of the SAS Users Group Interna- sorted by patient number and naru~ ano are then tional. SAS Institute, Inc., Raleigh, In theory, North Carolina. 318 pp. merged according to those two criteria. there should be only one patient name per number, but in reality a small fraction of patient numbers UniV8~sity Medical C8ntT The Washington will have been punched incorrectly. We thus include requires a form detailing pre-operative and the patient name (or~ rather. its first two operative information to be filled out for every characters) 80 that incorrect patient numbers patient undergoing anesthesia and surgery. Data will give missing information rather than incorrect from this form is later merged with d~te-of-di8- information. In merging the data, the length of charge and death information from hospital recDrds. stay is obtained by subtracting the date of surgery The result is a seventy-v~riable, 19,OOO-case-per- from the date of discharge~ The new date formats year data set yielding mu~h valuable information on the",Sugi-78-11 Spitznagel Owens.txt
"versity of Rochester Medical Center Rochester. NY 14642 Merwyn R. Greenlick Kaiser Health Services Research Center Portland, Oregon ABSTRACT QUICK. J. D., and M. R. GREENLICK. 1978. Multivariate Prediction _of Neonatal Morality With Emphasis on Health Care Inputs, pp.77-82. IN Strand. R. H. (ed.). Proe., Third Annual Conference of the SAS Users Group International. SAS Institute. Inc,. Raleigh. North Carolina. 318 pp. Using the SAS multiple regression procedure, Oregon vital statistics data from 1972 to 1974 were used to predict the ~lke11hood of neonatal mortality. Maternal sociodemographic characteristics, medical-obstetric risks, and health care inputs were used to predict outcome~ After selection of a ten percent random sample of all viable births and a 100 percent sample of neonatal deaths and appropriate transformations of nonlinear variables, the SAS GLM procedure was used to create a multivariate function predictive of neonatal mortality. The results of the analYSis are presented and discussed in light of recent national guidelines for perinatal services. The ability of SAS data manipulation capabilities to facilitate the multi- variate analysis of rare events in large sample populations is demOnstrated. With the enactment of the Health Planning demonstrate the economy and relative simpltcity and Resources Development Act of 1974 (pt 93~64l) of using the Statistical Analysis System (SAS) for the multivariatB analysis of vital statistics and subsequent increasing conce",Sugi-78-12 Quick Greenlick.txt
"tive ABSTRIl.CT SAS is run on an Amdahl 470 terminals. V/6 using the OS/MVT operating system. WILSON, W. J. 1973. Use of SAS in UNF has a student computer/statistics lab a Statistical Methodology Course. equipped with card punches, Monroe 1710 pp.83 -87. IN Strand, R. H. (ed.), calculators, eight IBM - 2741 and two Proc., Third Annual Conference of IBM - 3767 interactive terminals~ SAS the SAS Users Group International. jobs can be entered by batch entry SAS Institute, Inc., Raleigh, through a Data 100 reader and HASP or by North carolina. 318 pp. remote job entry from any of the termi- nals~ UNF also has a Harris S-120 mini- computer which can be used for remote job The use of SAS in teaching an inter~ entry. Hard co?ies of SAS programs are mediate level Statistics Methods course available through a Data 100 printer or is proposed as a viable alternative to through the Harris printer by using a the more classic approach. Problems ""route"" 5taterne:1t~ At this point in encountered in the three years this time, interactive SAS is not available at UNF. Students taking the course approach has been used at the Univer- sity of North Florida are discussed and described in this paper usually submit possible solutions suggested. Extensions SAS jobs using the interactive terminals of this approach to other courses are and remote job entry, routing the output also considered. to the printer. The necessary pro- gramming for this procedure is fairly simple. INTRODUCTION Students taking th",Sugi-78-13 Wilson.txt
"er, Oklahoma 74074 ABSTRACT MORRISON, Robert D. 1978. Use of SAS at students, who sometime in the future will be Oklahoma State University During the Fall using the system in their own country~ Semester 1977. pp.88 - 92. IN Strand~ R.n. {ed'}J Proc., Third Annual Conference of the Four of the nine professors in ou'r depart- SAS Users Group International. SAS Institute ment are users of SAS, The University Computer Inc., Raleigh, North Carolina. 318 pp. Center has one employee who uses the system regular~y. and the Agricultural Economics depart- The tape records for all jobs logged in the ment haa an e~ployee who. as the supervisor of Oklahoma State University computing center from thefr remote reade~-writer terminal, is involved August 1 to December 31, 1977 were searched for in the use of SAS. Ther~ are one or two profes- SAS usuage. CPU time, elapsed time and frequency sors in each of the departments of Accounting, ~ere of use summarized by type of user. Business Administration and Social Science who require thei~ students to use SAS to do some of This presentation was originally directed their classroom and laboratory assignments. Some professors use SAS to make examinations in such toward the use of the SAS system at southern universities. I would first like to give a short a manner that each student has the same type of review of the system as I have watched it evolve. questions, but a different set of data. Several years ago, the agricultural experi- Nearly all the SAS",Sugi-78-14 Morrison.txt
"rolina Columbia, South Carolina 29208 scheduling conflicts and the distance to the main ABSTRACT campus. Conversa~ GLENN. D. A. and 1. H.. CockrelL 1977. tional instruction in the StatisticaL Analysis The difficulties and inconveniences associated System. pp93-96 · IN Strand, R. H. (ed.l, with the SAS short cOurses have resulted in a Proc., Third Annual Conference of the SAS Users large amount of consultant time being inVEsted in Group International. SAS Institute, Inc.; teaching the potential SAS user on a one-to-one basis. The problems associated with this approach Raleigh, North Carolina. 318 pp .. are numerous. The amount of staff time taken is Teaching relatively unsophisticated users the excessivej it is impossible for the user to absorb Statistical Analysis System poses special diffi- all the necessary information; consultants are culties in a Large geographically dispersed computer often tempted to do the work for the userj and in network. An interactive SAS course has been devel- general, the results of such an approach are highly oped at the Computer Services Division of the unsatisfactory. University of South Carolina Which overcomes many of these difficulties. Students ~y sign on to the The statistical consulting staff at CSD-USC computer assisted course at anyone of approximately decided to investigate alternative training )00 interactive terrndnals throughout the network. mechanisms ~ch could be used in conjunction The course, which introduces the potential SAS.",Sugi-78-15 Glenn Cockrell.txt
"~OR,.'1AL GENERATnJG MULTIVARIATE DATA IN SAS Daniel M. Chilko and E. James Harner West Virginia University Morgantown. ~eat Virginia Let Y-- = (Yl, Y2, ... , Y ) be distributed AllSTRACT N(O, In) whf'r-e In :II'! th"",nidentity matrix I l f size n. Then X ~ C~y is distributed 1978. Gen- D.M.~ and E.J. HARNER. C~ILKO, erating multivariate normal data in SAS. N(O, C""'C) wher:-e C is ann)!."" matrix of fixed pp.97 -100. IN Strand, R.H. (ed.). Proe., ~lements. Third Annual Conference of the SAS Users Thus we need the decomposition ~ = C~C. Group International. SAS Institute, Inc., The Raleigh. North Carolina. 316 pp. matrix C is readily determined and unique if C is chosen to be up'Per triangular. If I: is not Computer random number generators offer a positive definit~, an ~rror message is print@d solution to the problem Qf finding suitable by, the procedure. examples of data for classroom use. A SAS proce- dure for generating multivarate normal data has The Control Cards been developed. This provides the instructor a single system to generate data. analyze them, procedure produces as output a SAS The &~G and display results. Its use in teaching multi- whos@ obs@rvations have values that are da~as@t variate statistics 1s illustrated. normally distributed. The procedure is called by a SAS statement of the form: I~TRODUCTION PRDC m""IG p&rarneters; use of computers to generate data for The teaching statistics is described by Carmer and The paramet~ra allow the user to initiali~e the Cady (l969). Computer random number generators random numb@r g@nerator1 to specify the number solve the frequently encountered problem of find- of decimal digits in the output dataset. and to ing suitable examples of data fo~ classroom dis- certain variab les. r~name cussion, homework problems, and laboratoryassign- ments by generating sets of data according to a A GE~ERATE procedure information statement model whose structure and parameters are con- is required. It specifies the names of th@",Sugi-78-16 Chilko Harner.txt
"versity Ames, Iowa 500ll covered in other courses. AllSTRACT Bubolz, T. A., and J. E. Gentle. 1978. Objectives and Topics applications in a three-course SAS sequence in statistical computing. The formal title of the first eourse in the series is Statistics 380, ""Sta.tistical Applica- pp. 101- 107. IN Strand, R. H. (ed.), tions of' Digital CompUters. II The purpose of Froe., Third Annual Conf'erence of' the SAS Users Group International. SAS Institute, this CQUl""se is to present all overview of' avail- a.ble methods that may be used in the f'ield Inc., Raleigh, North Carolina.. 31Bpp. loosel.y identified as ""statistical CQ'tlput1ng"". The role of SAS in & sequence of courses in This is .supplied by- a graded introduction to statistical computing is discussed. The three statistical analyais using a high-level algo- rithmic language (WA~V, nil), statistical courses, sponsored jointly by the statistics and computer scien~e departments, ~ocus on current subroutine libraries, and, finally, package programs. (SAS, sres). In a very general sense, topics in statistica.1. computing: programming and program development; statistical the course progresses from an ex~nation of the princip~es constraints imposed by hardware on the develOp~ numerical ana.lysis, particu1a.rJ.y with regard to ment of elementar,y statistical algorithms to an linea.r algebra.; compUting systems design; data. examination of ways in which available sortware management; and randOOl. number generation and may affect",Sugi-78-17 Bubolz Gentle.txt
"tate Unive~sity Columbus, Ohio 43210 U.S.A. thus the tests of for the single signi£ic~nce ABSTRACT degree orthog~nal polynomials both for the case of a single factor and for two factors HARVEY, W.R., and L.A. SWIGER. 1977. with interaction present. The procedure is Orthogonal polynomial fitting with applicable even though the adju~ted class or arbitrary spacing and correlated means. pp.108-112. IN St~and, R.H. subclass means have unequal variances and are {ed) ~ Proc., Third Annual Conference correlated and unequal class intervals are of the SAS Users Croup Int~rnatlonal. present. An orthogonalizing transform is not SAS Institute, Inc"" Rale1gh, North obtained that could lesd to the use of orthogo- Carolina. 318 pp. nal polyno~al coefficients. The,only value of such coefficients is to aid in the 'computa- Computing procedures for obtaining the tion of sums of squares and in- p-lotting t'he sums of squares and tests of significance for selected curve or surface. The procedure single degree orthogonal polynomials which is presented here utilizes differences of reduc- applic~ble to @ither bal~nced or unbalanced tions in sums of squares under different models and non-orthogonal partial regreseion coef- data and to a single factor or to two factors are presented. The method presented utilizes ficients to obtain the same results. thus weighted least squares procedures rather than avoiding the complex computations that would an orthogonalizing procedure, such as the Gram- be required",Sugi-78-18 Harvey Swiger.txt
"Uowever, it has been ob5erved (Greenhouse and Geisser, 1959) that this approach is valid only SANDERS, W. L. Analysis of a repeated when E is of the special form 1978~ ~eaBurement experiment with incomplete data. 1 p. pp. 113 -116. IN Strand, R. H., Proc., Fourth Annual Conference of the SAS * = {j 2 Users Group International. SAS Institute. 1. i: P""P Inc., Raleigh, North Carolina.31B pp. In many biological experiments (well designed and others) repeated measures over time on each experimental unit occur in patterns often uncon- 1 trollable by the researcher. However, various -' analytical strategiee may be employed when this where P is the correlation bet~een any t~o ele- problem type is encauntHred by chaining several ments in the s.ame vec.tor (Cole and Grizzle, 1966)"". features readily available in SASe Thus, unaer the assumption of uniformity of the An example using data from a ruminant nutri- correlation matriX, analyses of repeated measure- tion study is presented. Diurnal curves approxi- ment experiments are not different from those of ;: mated by fitting two ha~monicS of a Fourier series classical split-plot deaigns which makes available ~: were estimated separate for each animal in the to the analyst techniques developed for split-plot study via PROe NtIN. The vectors of coefficients analyses with missing data. were then inputted to GLM as 'data' and a multi- variate analysis performed to test hypothesis of UNIVARIATE APPROACH no treatment effects on ~he diurnal curves. One of Lhe earliest t~chnLques developed for split-plot analyses ~th missing data was by Ander-",Sugi-78-19 Sanders.txt
"NAKKASH, A.K., and B.T. GREENE. 1977. A Ridge Regression Algorithm Versus the Classical Least Squares Regression Model. pp. 117-122. IN Strand r R.H. (ed.), Proc., Third Annual conference ;.' of the SAS Users Group International. SAS Institute, Inc~r Raleigh, North Carolina. 318 pp. The unbiased least squares (L.S.) estimation procedure for deriving the coefficients of the linear regression model is compared with a biased estimation pracedure--the ridge regression technique. In the case of ill-conditioned data (i.e., non-orthogonal correlation matri~), a ridge solution provides a more stable set of regression coefficients than the classical least squares solution. Examples are presented to compare these two methods. This paper also utilizes the matrix procedures in the SAS program and presents a computer program for the implementation of the ridge solution.",Sugi-78-20 Nakkash Greene.txt
"USING BAS - GLM IN KINETIC MDDELING Irving 11:, Hwatlg Merck Sharp and Dobme Research Laboratories, Rahway, N.J. ABSTAACT o~ coefficients to be estimated. Then, it u$es a one of the chree ~tQrat1ve methods (1.e., HWANG, I, K., 1977. Using SAS - GLM in mpdif~ed Gauss-Newton method~ the Marquardt method, or the steepest-deste~t ~athod) to fihd kinetic modeling. pp. 123-126. In Strand, the nonl~near least ~quarea ~st1m~te~ of the R. H. (ed.) I Proc.. I Third .Annual Confer- parameters of ~oeffic1ents. e.nce -'of the SA!) Users Group International. SAS Institute, Inc., Raleigh, North Caro- Based on the linear least squares approach lina. 318pp. of Hwang and Yeh, the SAS procedures of GLM and A kinetic model is generally expressed in MATRIX are used to estimate parameters in a two- differential equations. These equations may not compartment open model in clinical pharmaco~ be salved analytically. To establish these kinetics. Numerical results compared to those equations the parameters or coefficients must be of SAS - NLtN indicate that the linear least squares approach using SAS - GLM is effective~ estimated directly from exper~mental data. In- numerable pr6ceduTes, such as nl;lnlinear h~_ast squares, absolute 1east deviation"" quasilinear- ization! and invariant imbedding have been pro- posed and used to solve the nonl~near estimation problems. Consider the following differential equa- tions which represent a two-compartment open mode1 follOWing art IV (intravenous) bolus admin- The purpose of this paper is to damanstrat~ that SAS - GLM can also be used ta prov1d~ good istration (Greenblatt and Kock~Weser. 1975~ Hwang and Yeh, 1971): parameter estimate9 through linear least squares, based on the estimatio~ procedure of Hwang and Yeh. Numerical exatnple in a, tl<l'O-compartment _open dC I dt - model in clinical -pharmacokine,tics is given and (1) ~ + k.,) C1 + k21 Cz (k 12 '. the results 9£ a comparison ,with the: SAS - NLIN are presented. dC 2 ~ = kl2 Cl - k21 C2 (2) I",Sugi-78-21 Hwang.txt
"economy of subjects--""By having One of the most common research designs in each subject serve as his own control/and hence the analysis of empirical data is the repeated Yet despite the frequency with increasing the precision of parameter estirua- ~a8UTes ANOVA~ tion!, the experimenter attempts to work with a which this type of design is encountered I SAS effers no ""automatic"" procedure for analyzing smaller sample Size!! (Winer, 1971., p. 517). such data. Consequently, the purpose of the pres~nt paper Is to show that repeated meaaures Given that the researcher is faced with the analysis of a R-M design, it becomes immediately . designs are indeed capable of being analyzed by apparent that SAS offers no t'l{utomatic"" proce- SAS. W~th a few relatively simple assignment dure for analyzing 6uch a design. By I'automa- atatements t a user can obtain not only an tic .. l1 I simply mean that no SAS procedure exists ""overall"" repeated measures ANOVAj. but can also test contrasts from among the repeat- whereby an unmodified data set can be directly spe~ified submitted, and an appropriate analysis can be ed measures. directly obtained. Despite this fact, it is the In terms of the overall analysis, the pa- purpose of this pap~r to suggest that SAS is in- per details how the user can (1) employ the deed capable of correctly analyzing R-M designs. OUTPUT statement to appropriately modify the With a few relatively simple assignment atate- :rIlE!ntB~ a user can obtain not only an ""overall""",Sugi-78-22 Courtright.txt
"harmaceutical Division ClBA-GE1GY Corporation~ Summitt ~ew Jersey 07901 (1) ABSTRACT Where y = (y"" ): n x 1 is a vector of response 1.J ··· pu PATEL, H. I., 1978. SAS procedure for the variables, u = 1, ..· , n ;l<i<R.· ij ··· p - - 1~ analysis of covariance with intra-clBSS 1'::'j.::.t2;···;1~p ~ n <:1.·n=~ model in one- end two-way classi- r~greBBion + v' (ij ... p) ij ··. pt In Strand ~ R. H~ fications pp. 132 - 136. A is a deSign matrix, Z= diag(x)A with x = (ed.), Free., third Annual Conference of (X ·.· pu ): n x 1 being a vector of ob;erved ij the SAS Users GroUPt International. SAS ~ ~(~.. values of a covariate, ): q x I and Institute, Inc., Raleigh, North Caroline. - 1.J ··· p 318 ppo ! =(e.. ..· p ): q x 1 are vectors of within-cell 1J intercepts and regression slopes~ respectively, This paper deals with a SAS procedure to with q = nj~j and £ ~ N(Qt Al n ). In terms of the analyze the covariance model in one- and two-way classifications with a single No mean- covariat~. means~ conditional this model can be written as ingful comparison of all levels of an effect can = ~ij + e'j ··· p x. The following E(YiJo · .· pulK) 1. ~ ·· p be made if the ~egression slopes in the classes lemma is due to Reeder and Carter (1976): of that effect are heterogeneous. Based upon the invariance property studied by Reede~ and Carter Lemma. A contrast of cell means is invariant (presented at the 1976 ASA annual meeting at to the value of x if the corresponding contrast of Boston), the mai",Sugi-78-23 Patel.txt
"del are AllSTAACT linearly d~pendent and hence the parameters of BOLOGNESE~ J. A. ~ 1977. ""Adjusted Meansrl the model are nonestimable (i.e., not uniquely From SAS76.pp.137-140.In Strand, R. H. determined). When the classical ANOVA side con- (ed.), Proc., Third Annual Conference ditions, namely Li (11""'0 and E.1j=O, are ~~sumed,. 0-£ the SAS Users, Group International. the Leparameterized normal eijuations (with ·the SAS Inst~tute, Inc., Raleigh, No~th side conditions) become linearly independent and, Carolina. 318 pp. therefore, provide the unique estimates of ~he model paramet~ra, Th~~H solutions are dependent Users of SAS76 have found that the: ""adjusted on the. side conditions; other side conditions can mean!;!"" available in SAS72 from FROC REGR, in provide different estimates. But with these ~., particular from the ADJMEANS statement, are not particular side conditions, the estimates of u + directly available in SAS76. This paper will OIl for i =' 1, 2, ··· , t are the Itadjusted means"" shO'W how to obtai.n ""adjusted tne:ans"" by 'Irlriting for the treatments. the appropriate linear full-rank model, coding its design matrix~ and choosing the appropriate· When ni"" = n for all i and j (balanced case) parameter estimates. A simple method for coding the ""adjustea means"" are a.lways equal to the this model using PROC MATRIX (SAS76) ""Ul be treatment me:ans (Yi ·· 'a). This may not be true It will then be explained how FROC p~esented. when the cell sizes are 'Qot all equal. T.he",Sugi-78-24 Bolognese.txt
"in this latter p~ocess will be documented later. BOLZER, J.B., and M. CONLON. 1918. Use of the stat~nt pp. 141-144. in SAS. ABSORB IN HOW TO CODE AN ABSORB STATEMENT Strand, R~H. (ed.), Proc., third Annual Con- ference of th~ SAS Ueers Croup International. SAS Institute, lnc.~ Raleigh, North Carolina. Correct use and coding of the ABSORB statement 318 pp. will be illustrated with several numerical examples drawn from Winer (1962). All runs were made with SAS 76.4 on an IBM 370/165 at the No~thea6t Regional Use of the ABSORB statement in PROCS GLM and ANOVA in SAS 76 1s illustrated for three repeated Data Center of the State University System of measures design examples. Coding procedures and Florida. limitations are discussed, and actual savings in CPU time and memory required are documented. ~o-facto~ Experiment with Example 1: Repeated Measurea The simplest design demonstrated is a two-",Sugi-78-25 Holzer Conlon.txt
"The GLM procedure was developed for the purpose of providing information on the st~ucture and meaning of results of linear models analyses of incomplete data. The brevity of descriptions of GLM in tne Users' Guide may make it difficult for the average user to properly understand the given results. A simple example is used to illustrate 1) what information GU1 provides and how to use ft, 2) the non-uniqueness of the Type IV functions, and 3) what the REGR procedure of SAS-72 did with the same data. ae ij + Bj + + E: ijk , II + :li",Sugi-78-26 Freund.txt
"MENDELSSOHN t &.C. 1977. The data base approach Figure 1_ BLS data processing 8:pproach at the Bureau of Labor S~atistics. pp.1Sl-155. IN Strand, R.H. (ed.), ?ROC., Third Annual Conference of the SAS Users Group Interna- tional. SAS Institute Inc ·· Raleigh. North Carolina. 318 pp. The Bureau of Labor Statistics (BLS) has gained ecoaomy and speedier results through the use of a data base manager as the central feature for most of its computer uses. Associated genera- lized systems are embedded in very high-level. nonprocedural languages that may be used by per- sonn~l not knowledgeable in the computer sciences.",Sugi-78-27 Mendelssohn.txt
"SAS has many features which make it a flex- File structures are restricted in SAS to rec- ible tool for the management and analysis of data tangular files, as is the case with other high from clinical reBea~ch projects. However, there level statistical systems. But implioit h1eratehi- cal structures are common in research data. For are many problema which at first glance do not example J some chemistry measurements might be made appear to be reasonably handLed by SAS. Some ex- amples are de~11ng with hierarchical files and on ~ subject at frequent intervals such as on~e A encrypted data, and editing and correcting data. week while other measurements such as height are Because of SAS's flexibility, methods for tack~ made only once. Thus each subject has a varying ling such problems exist. Some general- soLution$ number of measure:nents, will be discussed and SAS will be compared from It is not economical to Btore such dAta in a an analyaiB viewpoint with some packages deSigned rectangular file with some fixed maximum number specifically for handling hier4rchical fileS. of variables. Howeve~. the data can be stored ef~ ficiently in SAS by setting up a file havina one record per Subjeet with variables ID and height i ,",Sugi-78-28 Harrell.txt
"SAS AS A MANAGEMENT SYSTEM FOR ROUTINE EGHOCARDIOGRAMS Glenn A. Kenneth p. Offord, Vernon P. Emilio R. M.D. Auguatine~ ~eber, Giul1aal~ Mayo Clinic, Rochester, Minnesota To achLeve these SAS was selected. This paper will discuss how SAS ~s used in goala~ This system, originally written in SAS/7Z, a batch procEssing mode a~ a data man&gement and afforded ease in debugging, as well as the retrieval system to handle the collecting of necessary sort, merge, and update facilities. data from echocardiograma done ae the Mayo Only 35 programmer hours were r~quired to get Clinic. A discussion of the edit/update program the 700 statement edit/update program opera- wrLtten in SAS will be presented, as well as why tional , and a data clerk now spends about one SAS was selected t and the benefits it has hour each month handling the procedure with v~ry provided. little interaction with the original p~ogramme~. The SAS data set provides names for each variable Echocardlography is a non-invasive technique understandable to everyone involved. Each for examination of the heart by use of ultra- sound. It was used gpar~ngly in the late 1960's eight-character name consists of 5 characters and at Maya, but in 1970 when the ultrasound unit wAS 3 numbera~ The 5 characters are an alphabetic interfaced with a strip chart recorder, and new techniques were mastered, it gained in popularity Figur. 1. and usefulness. In 1971, only 188 echoes Were MONTHLY FLOW OF THE SYSTEM done, but in 1976, 4254 were done. The monthly average in 1977 through November was slightly over 400. WORKSHEETS ARE FILLED OUT IN As echocard1ography more reliable b~came and echo activity increased, echo lab ~he THE ECl:IO LAB decided that there was a definite need to edit the data thoroughly and be able to reference and retrieve it easily. DATA IS In 1974 work began on this system. The flow of the system is as follows and is flow- KEYPUNCHED charted in Figure 1. The information is FROM WORKSHEETS abstracted onto a worksh",Sugi-78-29 Augustine Offord Weber Giuliani.txt
"uri 63110 ARSTRACT answerS to the Same question. or (b) answers to other related questions. ACBTENRERG, J.~ and J, P+ MILLER~ 1~78~ Interfacing a MUMPS-based data entry sys- Pre-coding of raw data can be reduced by shifting som@ functions from clerical staff to ~ pp. 161 - 167 tem to SAS. IN Strand. , , R. H. (ed.). Proc., Third Annual Confer- the computer system. For example. data can be ., entered in the form of an equation ( 1T 3.14*4 1T ) ence of the-- SAS Uaer9 Group International. SAS Institute, Inc., Raleign, North whose result (IIILS6-1I ) is used as the input data, and values ean be entered in the Ilwronglf units Carolina. 318pp. (feet rather than inches, for eXBIDple) as long A discussion of the rationale for providing as the actual measurement units are indicated. mini-computer based data entry facilities inter~ Users of databases in wh~ch the same data are faced to established statistical analysis pack- obtained at different points in time can be of ages is presented along with the description allo'Wed to record values a9 ""unchanged"" leaving it up to the computer to retrieve prior data for one such system currently in use. inclusion in the current observation. Such fea- tures of interactive data entry can significantly INTRODUCTION reduce clerical errors and costs. This paper discusses the rationale for Critical savings in start-up costs by use of providing a mini-computer based data entry system interactive data entry can also be significant. with an accompanying",Sugi-78-30 Achtenberg Miller.txt
"Pinpointing data wi.th DARTS. pp.16-B-172.IN Strand, R.H. (ed4), SCHULTZ. M.lt ·· 1977. Proe., Third Annual Conference of the SAS Users Group International. SAS Institute~ Inc., Raleigh, North Carolina. 318 PP4 Modeling complex analytic systems using real data often involves large amounts of data reduction and processing to identify system parameters. The Analytic Sciences Corporation (TASe) has developed a pro- cedure using the Statistical Analysis System (SAS) to ""trac:k"" data through a processing cyc1f;~. with ths intent of reducing duplication of effort and eliminating the pitfalls of manual recordkeeping4 three re- quirements were considered of major importance in the system de8ign~ automation of the capturing of the tracking information to the greatest extend possible; design of the system to be user (rather than pro- grammer) oriented, and sufficient flexibility to allow the system to be used on other projects with a minimum of redesign and reporgramming. The Data Analysis and Retrieval Tracking System (DARTS) was implemented to meet these needs. In ad~ dition to SAS, several other components were aleo incorporated in this system; routines callable fram user programs to extract dataset information, interactive conversational procedures for data retrieval and updating~ and tracking of remote processing on another System/370. The choice of SAS for the data manage- ment aspects of DARTS had the added advantage of an easily accessible statistical and report generating capabili ty.",Sugi-78-31 Schultz.txt
"or~ H. E. 1978. Simulating a hierarchical master file structure usirg SAS. pp. 173-177. In Strand"". R. H. (ed.). Proc., 'Third Ann ml Conference of the SAS Users Group International. SAS Institute, lnc. t Raleigh. North Carolina. 318 pp. RICHIS, an integrated data managenent system, canbines the obj-E::ctives of prcgram monitorirg with an historical research data base. The conceptual design is that of a hierarchical or tree str~ture with one observation per person c.ontaining unlimited repetitions 0 f segments representing various events. RICHIS is in actuality organized as .separate fixed length files. for the root and each segment, loosely linked by an identifyirg variable which is unique for each prisoner. This organization minimizes processing· costs. avoid6 the problems of widely varying repetitions of events. and provides the fl~ibil ity neCEssary for monitoring a dynanic prcgram. SAS was selected because it provides a unique and power- ful combination of datamanagBDent. r~port writing~ and statistical analysis capabilities in addition to peDllitting this conceptual simulation of a single hierarchical maste.r file. Thus, RICHIS has to serve two functions RIGHIS (Resident Institutional Career and Which on the surface seem to be in opposition. History InfolI11.a.tion Systffll.) is a canputer based It has to be both current and historical and per- data management system currently bei~ imple-- son bas~d but ~vent oriented. In addition, the mented tn the Western Region of th",Sugi-78-32 Cavior.txt
"lated new merge function, it is hoped that the Existing data manipulation functions of SAS benefits of this new merge algorithm will be do not provide the user with a complete set of func- demonstrated. tions required for research data management. Cer- tain logical, data-set combining operations using The syntax and semantics of the proposed the SORT and MERGE functions require excessive pro- additional SAS parameters and new statements as gramming, and in some cases, extra passes of a data presented should be viewed as moTe of a metalan- set(s) must be made to produce the resultant compo- guage or a language used to describe the enhanced site file. merge capabi1ity. Only the SAS developers can best prescribe how to integrate this capability A hierarchical logical file structure 1s used with the existing SAS user request language and to illustrate how a user would combine physical SAS other data management functions. data sets to form output data sets corresponding to various analysis levels of the hierarchy. House- hold, family, person and work data sets are combined A Typical Research Data Base via I} existing SAS progra~ statements and 2) pro- posed n~w stat~ments. By enhancing the data mani- Most data generated and analyzed in a research pulation language of SAS, the utility of SAS can be environment requires that varying amounts of differ- incr~as~d and the programming now required to com- ent types of information be combined. Consider as bine logically compl~x, related data sets 1s reduced. an example survey data. A most logical model for organi~ing data in the computer for this type of information is to create a SAS data set for logi-",Sugi-78-33 Ellis.txt
"poriER. F. J .· 1977. SAS as a user maintained data base system. pp. 184-188 Tn Stnmrl, R. H. SAS Institute, Inc., (ed.)j Proc., Third Annual Conference of the SAS Users Group International. Raleigh, North C~yolina. 318 pp. The ratiouale, design, and implementation of SAS 76 as a data base management system for the pro- cessing of mod~rate scale clinical trials is presented in two phases. The first ~hase demonstrates SAS 76 fleKibility of design and ease of use which permits efficient user implementation with little reliance on a computer systems department. These two properties are the primary rationale for SASlg use by a medical research team. A multiple record type input was used in the construction of SAS file~ which comprise the subciv1- sions of the data base. Through the use of embedded key identification fields for each observation. all SAS files are available for merging. This maximizes the information available for analysis of each observation, while minimi~ing input and storage requirements. A flexible system of data input. updating and r~port generation is also demonstrated. The second phase involves modifications of the data base system to enhance data manipulation and to minimize input errors through the use of processing dictionaries for adv~rse exp~rience teams, labor- atory normal range standards, and drug therapy. A simple method of storage space optimization is also presented along with diagrams demonstrating the benefits that result from this modification.",Sugi-78-34 Potter.txt
"St. Louis, Missouri 63110 The first study is one on 80 fath9rs who ABSTRACT were part of a previous study of 223 black men POWELL. D.· MILLER, J. P. and CLONIN~ER, C. in St. Louis initi~lly studied in 1965-66 R. The use of SAS for the analysis of (Robins, et.al, 1975). They were followed up in 1970-73. With thi~ followup, information from family studies, pp189-l94.In Strand, R. B. (ed.}, Froe. _Third Annual Conference of school records and police records were collected the SAS User's Group International., SAS on their wives and children. Institute, InC. t Raleigh, North Carolina Three gAS data sets were created. The 318 pp. father data set contained approximately 800 vari- The ~naly5i5 of f~ily studies present sig- ables and 80 observations. The mother data set contained 90 variables and 88_ observations (there nificant prOblems with respect to the use of are more mothers than fathers because B of the $tandard statistical packag@s as the dat~ set fathers had been married twice). The child data does not conform to the simple rectangular observations by variables structure. The data set contained 180 variables on 159 children management facilitias of SAS, however, provide (there were 1 to 4 children born to the first the neceSsary tools to produce the desir~d analy- marriages of the fathers and either 1 ar 2 born ses. to the second marriages). The principal challenge of family.studies is The second was a family history 3tndy which the variety of ways in which the data needs to",Sugi-78-35 Powell Miller Cloninger.txt
"ipant has taken supposing h~ ~s on full dosage. At our clinic we refer to this a~herence as EGGERING, L. B., 1977. Adherence monitoring absolute adherence. When a participant is on at the clinic level with the uSe of SAS, reduced dosage - leBs than the 6 packets of medi- cation per day - his adherence to the clinical pp. 195-199. IN Strand, R.lI. (ed.), Prac., ThiLd Annual Conference of the SA5 Users dosage 1s referred to ~s the clinical adherence. Group International. SAS Institute, Inc., Absolute and clinical adherence is measured for Raleigh, North Carolina.3lB pp. every participant. One of the significant problems in the man- agement of long-term intervention trials is ADHERENCE MONITORING insuring patient compliance to th~ prescribed Monitoring pKrticipant adhHrence is done treatment, Basic to any program to enhance adherence is a monitoring system which tracks the through our Central Patient Regiscry in North adh~rence record of each study participant. Carolina and is highly encouraged at the clinic With the use of SAS at the clinic level, monitoring It is at the individual clinics that level~ and dat~ management are performed rapidly and adherence problems should be noted and solved. economically. With adherence now being the focal point of the trial, a decision had to be made at our clinic as to how to handle the task of monitoring",Sugi-78-36 Eggering.txt
"ak Ridge, Tennessee 37830 ! ABSTRACT , i , calculated (Klopatek et al. 1978) using the Environmental assessment and plan~;ng for energy development ongoing at Oak Ridge National Geoecology Data Base. In addition, the data base is being expanded to meet objectives of acc~ss Laboratory requires rapid to data at appropriate spatial and temporal scales. In studies sponsored by the National Science Foundation dealing with ecosystem productivity the Environmental Sciences Division we have developed, and are extending as needed, a and carbon budgets. spatial data base at the county-subcounty level of resolution. The data base contains informa- GEOECOLOGY DATA BASE tion on terrain, water resources, for~stry, agriculture, land use, wi1dlife, air q~ality, The data base has been compiled by select- climate, critlcal natural areas, human popula- ing data from extant data files created by tion, health, and energy. Each of these subject sectors is stored as a SAS data set. The SAS federal, state and other institutions. The data base has been organized into thematic sectors directory is used extensively to describe the 800 variables contained in the present 30 data where each sector contains dat~ elements QSso- ciated with different aspects of the environ- sets. The file currently occupies 10 million ment. Each sector has been edited to have bytes of storage for a 16 state area in the southeastern United States. The data base is identifiers compatible with other sectors and usually can be e",Sugi-78-37 Olson Strand.txt
"IN, R. J. 1978. Stability Scheduling maximum of seventeen times in a products data using SAS. pp.207-211. IN Strand. R. H. strea~. It contains information describing the (ed.), Proc., Third Annual Conference of the analytical procedure3 to be performed at a pre RAS Users Group International. SAS Institute, specified storage co~dition that is defined in Inc., Raleigh, North Carolina. 318 pp. file II. This file ~Qntains one observation or record with a maximum of seventeen specifications Federal regulations will soon be publ~shed of analytical procedureB to be performed. defining Geod Manufa~~uring Practices (GMP's). A portion of these regulations will specify pro- A basic queBtio~ regarding file structure ceduras that mu~t be performed when determining that should be more ~learly explained is the the shelf life or stability of a product. At USV reason why a multiple file environment was selected Pharmaceutical Corporation! a programming systam over a simple siugle file environment? The is being developed to handle these newly defined answer to this question is precipitated by the requirements imposed by the Federal Drug need for on-line storage of datasetS. By utilizing Administration. a multiple file environment approXimately 60% of the missing vHriabl~5 gen~ra~ed in a single file INTRODucnON An additional step envirOnm~nt ara eliminated. that was taken to streamline storage re~uirements The ptime responsibility of a s~ability program was pre coding of most entries in all thr",Sugi-78-38 Bronstein.txt
"usetts 01867 eliminating inconsistant and redundant informa- ABSTRACT tion and allowing quick access to the data. The BUCCI. S.A. 1978. Data base and analysis of flexible design of the data base structure per- mits efficient subeetting and retrieval, and power plant cooling systems. pp. 212- 216 IN Strand, R.H. (ed.), Froe., Third Annual facilitates the addition, deletion and modifica- tion of variable descriptors and data values. Conference of the SAS Users Group Inter- national. SAS Institute, Inc. I Raleigh, Such features allow frequent and easy updating of power plant Bnd water quality data, providing North Carol1fla. 318 pp. the most current information for analysis. This paper discusses a nationwide, coruputer- Th~ SAS management functions for imple- ized data base on cooling systarus and related menting and maintaining the data base are di- water quality characteristics for steam-electric rectly linked to summary and statistical pro- power plants in the U.S. with a generating capac- ity greater than 100 MWe. In the course of cedUT@S for analysis -- e.g~, data description and frequency distribution programs. multivariate assembling the data base, information was re- viewed and extracted froru major environmental analysis procedures and nonparametric routines. data bases, from existLng power plant data bases From these ""ana1yaes, lpformation about r~levant relationships and dependencies~ linear and non- and from document sources such as Environmental Reports and 316 Vari",Sugi-78-39 Bucci.txt
"DATA ORGANIZATION CALDWELL, E. N., SAS'e Vital Role in a Statewide Early in the study the decision was made Fuel Conversion and Energy Conservation to organi.ze the information into four separ.ate., but interrelated, databases, rather than one. pp. Study. 217 - 221 · In Strand, R.H. These four were: Admini6trative~ which was the (ed), Proe., Third Annual Conference of the Master; Monongalia County, which was the Pilot SAS Users Group International. SAS Institute~ Ine. Raleigh, North Carolina. Study; Campus Buildings, which included univer- sity and colluge buildings; and School9~ which pp. 318 included the secondary scho~ls, Their respec- SAS was used for the data tiv~ attributes are 8ummsrized below in Tab1e I. extensiv~ly management and analysis of the four separate databases in the first comprehensive coal con- Table I. Table of Data Bases and Properties version study for residential, commercial, and ADMN BASE institutional buildings in the United States. MON. CO. CAMPUS SCHOOLS SAS was very instrumental in the success of the PROPERTY project despite formidable handicaps. Contents Master Pilot Colle£es Schools Bu11din!!s 6 000 42 684 1 310",Sugi-78-40 Caldwell.txt
"3. compare groups using user supplied LAJlNESS, M. S'I Timon P. Tesar and Patricia A. contrasts. Kemp. 1978. SAS and the analysis of clinical data at The Upjohn Company. pp.222-228. IN In many applications of AOVMEAN, the RETAIN Strand, R. H. (ed.), PIoe., Third Annual statement is used to create several lagged Conference of thB SAS Users Group Interna- variables representing the initial value of the ~orth tional. SAS Institute Inc., Raleigh, variab1e (see Figure 2). The lagged va~iable Carolina. 318 pp. is used to calculate: the cbange from initial.",Sugi-78-41 Lajiness Tesar Kemp.txt
"and Cooperatives Service Washington, DC 20250 OUT=daoame This parameter may be used to I<BST\lJl.CT specify the dsname af the SAS data set being built by the procedure. The use PROC CODIN is a procedure to input coded data of OUT is optional t and if not specified~ directly into SAS. Codad data con$ists of a pair CODIN uses the default _DATA_ as the of fixed fields. The first field is a code desig- output file name. nating the item, and the s@~ond fi@ld is th@ valu~ of the item designated. The user specifies the correspondence between the ID codes and SAS variable CDMAX-k This optional parBIDBter will cause COD IN to reaerve table space for all names. Within a given input record, the coded pairs th~ valu~ may be specified in any order, and for every code codes up to k. This will guarantee that there will be space to not referenced, the corresponding variable will be assigned the missing value for that vbgeTva~iDn. count the unrequested codes that might show up in tbe input data set. Options INTRODUCTION This causes the minimum level of The use of coded data is a data entry tech- NOPRINT printed output to be produced. It may nique used to reduce the amount of time and materials b~ sbbreviated as NP. NOPRINT is the required to create a data set. With this technique default report setting. the minimum the user need only specify the non-missing items print out includes a count of list items for each observation. The system automatically requested, records read in. and obser~ gene",Sugi-78-42 Hopkins Woodworth.txt
"The default line type is the graph of a solid line The KWIKFLOT procedure is used as an interface with an event marker if an ID variable is present. b~t~en SAS and the software package for Houston The ID var~able may be used to identify points to Instrume.nt's COMPLOT increme.ntal plotter. It allows be marked. Because the plotter software is capable users to produee one or more. plots wlth a minimum of only drawing a Btraight line from one point to of control statements. This procedure is designed a second point, the user must provide sufficient for interactive use only. It will produce either a points to -plot smooth curves. A simple scatter simple scatter diagram or a line plot as output. diagram may be produced by specifying the N01INE Options and parameters can be used to vary the line option on the procedure statement. type. plot si2e, pen color, pen type, and the plot symbol to b~ used. PROCEDURE STATEMENT [DAT~d8nameJ",Sugi-78-43 Pearsall Hopkins.txt
"ty, Baton Rouge, LA 70803 individual should be classified. In the area of ABSTRACT the physical sciences many applications can be found. In exploring for offs'ore oil, certain KOONCE, K. L., and E. A. leaza. bottom formations are frequently associated with 197B. Some applications of oil deposits. Can physical characteristics of the discriminant function the water such as velocity, turbulence and depth procedure. pp.235-238pp. IN be used to determine subsurface formations? Strand, R. H. (ed.), Proc., Third Annual Conference of· These examples illustrate the wide range of the SAS Users Group Inter- problems w'ic' can be examined through discrim- national. SAS Institute, inant function techniques. In some respects the Inc., Raleigh, North Carolina. technique is similar to multivariate analysis of pp. 318 variance (MANOV~) procedures. In usual MANOVA models, a set of dependent variables is equated Essentially a multivariate statistical tech- to a set of independent variables. The indepen- nique, discriminant analysis has been utilized dent variables being the group Or classification primarily for deriving a linear function of p factor, while the dependent variables are assumed variables which maximizes the distance between to follow some distribution, usually the mu1ti- centroids or mid-points of the multivariate dis- lJarl ate nonnal ~ tributions of k groups. Such a function is fre- quently used as a classification criterion for When a set of data is collected, frequently decidi",Sugi-78-44 Koonce Icaza.txt
"usually a55umed to [ollCJW either the fi-J:st-order p<oe ··· AR(].): WHITE, K. J. 1978. Applicatious in Econo- metrics: ProbleIDB, programs, and Pro- cedures. pp.239 - 244. IN Strand, R. H. (ed.), Froe., Third Annual Confer- ence of the BAS Users Group Interna- or tne second-order process AR(2): tional. SAS Institute, Inc. J Raleigh, North C.arolirta. 318 pp. e~mples Thia paper surveys aome recent of where p reprsents an aQtocorrelation parameter statistical procedures in Economics. Studies and V is a ve~tor of white-noise disturbances. t with autoregressive errors, ARIMA models t dis- ~he use of ordinary least squares (OLS) clearly tributed lag coefficients, randcr.m coefficie~ts, does not yield the most efficient estimates of and nonlinear systems of equations are used to the vector ~ as it does not employ information demonstrate the procedure. A description of cap- about the autoregressive process. Furthermore, abilities of computer programs in Econometrics the estimate.d varianc-es of i3 are likely to be is included. biased dOW[IW""ard.",Sugi-78-45 White.txt
"PARKS, R. P., and M. E. MCBRIDE. 1977. Prin- components. The principal components are defined cipal component regression with PRQC CORR by: and PROC MATRIX. pp.245 -247. IN Strand, R. H. (ed.), Proc., Third Annual Confer- Z XW (2) = ence of the SAS Users Group International. where Z is the nxk factor score matrix and Wis a SAS Institute, Inc., Raleigh, North Caro- kxk matrix whose columns are the set of orthogan- l ina. 318 pp. olized and normalized eigenvectors of R. Thus, the principal component regression becomes The paper discusses a SAS prog-am that cal- culates principal component regression estimates. The program uses the SAS procedures CORR and Y=ZW'B+E=Z.+E. (3) MATRIX. An application of the program to a hous- Note that Wis orthoganol and W'W = I. The OlS ing price equation is given. estimates of. can be used to derive the implicit coefficients for B by:",Sugi-78-46 Parks McBride.txt
"Service Columbia, Missouri 65201 ABs;rRACT A SAS Macro tor calculating ROGERS, R., AND E. HILDERBRAND. 1978. coefficients of r~dge reqression. pp.248-254 In Strand, R. (ed.), Froe., Third Annual Conference of the SAS Users H. Institute, In~., Raleigh, North Group International. SAS Carolina.318pp. A SAS Macro (~ersion 5) is used to produce ridge regression coefficients which predict and extrapolate better than least squares when predictor variables are high""ly correlated. The method of selecting coefficient values ani variables using this macro are illustrated with an example from forestry. Forest site productivity is related to a selected subset of 80il factors. INTRODUCTION DESCRIPTION OF THE ALGORITHM Standard multiple regression models have The ridge regresaion algorithm i~ contained been and still are widely employed in forestry within a Macro called RlDGREGR (Appendix A}. and other fielde to deac~ibe the functional The ridge estimator is hased on the matrix x'x + relationships among variables. These models kI, k~O. The for.m of the equation used in the Macro to calculate the ridge estimator, ~..."" ~ frequsntly fail to adequately predict responses is tha.t uSed by Hilt and seegrist (1977) ~ ~ ... '"" when applied to data independent of those used for estimation, even though the explanatory ""A is a where matrix of A(D+kI)-lA'X'Y', power of the model indicated by the estimation eigenvectors of XIX and D ~s a diagonal matrix data is substantial (McQuil~in, 1976). of eigenval",Sugi-78-47 Rogers Hilderbrand.txt
"Department West Virginia University Morgantown, West Virginia 26506 In this paper, we describe an algorithm for ABSTRACT functional regionalization (Slater, 1976b; Leus- mann and Slater, 1977). The algorithm has been CHILKO J D. M., and P. lL StATER. 1977. IPFPHC: A SAS for hierarchical clus- procedur~ developed and implemented as a local SAS proce- dure (IPFPRC). It consists of two stages: tering using transaction flow tables. pp. 255 double-standardization of the flow table ~nd its -259. IN Strand. R. H. (ed.), Proe., Third An- nual Conference of the SAS Users Group Interna- subsequent hierarchical clustering. tional. SAS Institute, Inc., Raleigh. North Carolina. 318 pp. DOUBLE-STANDARDIZATION Transaction flow tables. such as internal Instead of using the recorded flows them- migration, input-output. trip distribu~ion, trade, and occupational mobility matrices. are selves as input to the clustering routine~ the flows are first adjusted by the iterative pro- frequently available to social scientists. They often assume large dimensions. A two-stage pro- portional fitting procedure (IPFP) so that the cedure for effectively summarizing this fo~ of total out-flow and total in-flow associated with all units are Lhe same. Rows and columns are data structure has been implemented in SAS. In the first stage t the table is adjusted 50 that alternately scaled so that all their sums aTe all its row and column sums are equal. In the eqnal. If the recorded flows are all positive, second,",Sugi-78-48 Chilko Slater.txt
"or a third order equation x 2 + b l11x3 + b x + b x2 +bx +b y=b Chilko, D. M. 1978. Response surface contour l l1 1l I 22 22 2 O plotting in SAS. pp.Z60-Z63. IN Strand, R. H. 3 2 2 + b 222x 2 + b12x1 x 2 + bl12xlxZ + b12i""l x 2· (ed.) Proc., Third Annual Conference of the J SAS Users Group International~ SAS Institute Inc., Raleigh, NQrth Carolina. 318 pp. The SAS procedure GLM facilitates estimation and testing of such equations by allowing the user to Response surface equations are frequently specify, for example: used to analyze data consisting of a dependent variable and a set of independent variables, all PROC GLM; measured on .continuous scales. The SAS procedure MODEL Z X X*X Y Y*Y X*Y; GLM f~ilitates the development of such equations. = A SAS procedure has been developed to facilitate the visual exploration of ""response surfaces by Using the estimated coefficients, it is possible contour plotting. to construct a response surface of predicted values. Frequently the experimenter is interested in deter- mining what values of the independent variables are optimum as far as the predicted response is con-",Sugi-78-49 Chilko.txt
"Oklahoma Department of Wildlife Conservation Norman, Oklahoma 73069 A1)S'fRACT Thus (1 ) C.L. and J.E. DUNN. 1971. A SAS E~AN) ~p- 6P. b b ~ Q.lnL &l,lL 6'nL ~ 1: ~ macro for maximum likelihood probit t -If': 0';;-- 5P. oYj j-l ow /i~ analysis with multiple predictors. j~l J J pp.264 -266 IN Strand, R.H. (ed.), p Proc~Third Annual Conference of the and (2 ) SAS Users Group International SAS In- b b Inc.~ stitute. Releigh. North Carol£na. ~ OP . /,y. · 61nt olnL dInt. ----1 _J 318 ~ pp. + oy- oe. 6P /i~k 5? j yak j J j=l j=l SAS mac~O statement fo~ ma~~ likeli- ~ hood probit analysi$ with multiple predictors is presented ~long with derivations of the equa- for k=112 ··· of :he choice of ~~p"" Regardl~65 tions used in the algo~ithm+ ~ attempt is made t:he metametric wJe have to arrive at a mathematical mcdel which will pre- pr~sence dict 'the of c:ertain species of zooplankton. (3) 1, =:0 INTRODUCTION Qualitative measurement of a re5pons~ is not pr3ctical. Some responses can be al~ays expressed only lIoccurringll or ""non-occurringlt .. Suppose a biologist wishes to predict the pre~ sence or conditions. In this case there are no ""pa.rtial occu~~ences'1. Th~ SAS p~ocedure MATRIX p~ovidBS a means b.a.t~h, where x is tl.e ktn predictor' in the jth jk far ~alyzing quantal response type data When lU'.11tiple pr:dictors are present. The method (n. - r .. J ~ Llsed is sim:ilar to that described by Finney J Jl (1971) for single predictors. P. 1 - P.- J J THE ALGORITHM 1.2, ·.. p. j Assu",Sugi-78-50 Bean Dunn.txt
". L·· Jr. 1977. K.W.I.C. The basic steps in creating the index are as fallows: indexes with SAS. pp.267-270. IN Strand, R.H. (ed.), Proc., Third Annual Conference of the SAS Users Group International! SAS 1. Read in the list of articles, prepositions~ Institute Inc., Raleigh! North Carolina. conjunctions, and other words that are not to be used as keywords. 318 pp. 2. Read in each title line, determining how many Specialized indexes such as the keyword-in- words it contains. context index are useful tools in information retrieval and display. For example, the author has developed a KWIC index to the routines avail- m~~'I1.y 3. Output copies of each title line as t:imes· as there are words in the title. able in major statistics packages with references eo the peckage, the routine name, and a bench- 4. Sart the title lines by keyword. mark CPU time for the routine. Although any number of KWIC indexing programs already exLst, 5. Merge the list of non~keywords with the title the author chose to write a new one in sAS to obtain precisely the form of index desired. The line, deleting all title lines for which a match is found~ program is short, simple~ and easily adapted to other UBeB. . 6. Print the remaining title lines as a KWIC index. K.W.I.C. INDEXES WITH SAS The powerful character hsndling~ sorting, and Although our computing facility possesses merging fe~tures of SAS have made it possible to implBment these six steps in less thsn seventy almost all the major statistics packa",Sugi-78-51 Spitznagel.txt
"conald J. Henderson SystEmS Application Division Data l\(Iricul tUlCal l<esearch Service U. S. Department of l\griculture Beltsville, Maryland 20705 k nir~ - 3n(n+1)2 12 E ABSTAACT H= _ _ _.c:ci=""'l""::;-_ _ _ _ _ _ __ (1) ~, D. J. 1978. KrUwalc, a rracro c 3 3 pp. 271- 275. fOr categJrical data~ n(n+l) (l-E (t. - t.)/(n - n)) IN Stran::!, R. H. (ed.) , Proc., Thin:l j=l J J Annual Conference of the Sl\S Users Group Int.ernational. SAS Institute, Inc., H is asymptotically distributed as chi-square Rsleigh, North Carolina. 318 [Op. with k-1 degrees of freedan. A general purpose macro which carrputes the COntrasts KrU.s.kal-w-aJ.lis H-test, incltrlinq the ties oor- rection factor, and Scheffe type oontrasts for We define contrasts in the usual way, ordere:l ca:teg:>ries in a one-way layout is pre- sented. .l\n example of its use On a set of A k ground beef taste panel data is given. (2) b=Ea.r. i=l l l l: a.=O · .mere 1 M:>st procejures for cat..eqorical data are 1 designa:l to test hyp:Jtheses a.rout cell prob9b- ilities_ However I when the categories are Tests of the hypothesis b=0 can be obtained ordered the need to test hypotheses concerning f.rom simulte.ne:rus confidence intervals, given by Klotz and TOng (1977), for all oantrasts described central ten:lency is cormon. Tests designal for cell probabilities have low pJWer for l:>y (2) aJ:ove. '!he chi-square distribution with tl1ese problans, and so, an alternative testing k-l degrees of freedan is used to compute p-values. procedure is needed. Klotz arrl Teng (1977) have proposed that the KrUskal-Wallis H-test be used. A Schaffe Usage type rrethx1 of contrasts was also presented. They derived an algori-t:hrrl r which can require KRUWAIC performs the analysis described. A large anounts of cpu tinE, to conpute the listing of the nacro is given in Figure 2. It can exact null distr.i.bItion of their test statistics. be used roth on batch and interactively. I f no oontrasts are desired r another macro may be A macro",Sugi-78-52 Henderson.txt
"on University ABSTRACT SAMPLING PLANS HILL, H.S., F.W. MORGAN, AND R. NELSON. 1977. There are two basic types of sampling that The LIFETEST Frocedure for Analyzing Relia- are considered, censoring and truncation. Cen- soring implies that a fixed number of n compon- PP4 27fr 278. IN St-rand J R. H. bility nata. ents have been subjected to testing until a (ed.), Proc .· Third Annual Conference of the fixed~ predetermined number, r, have failed. SAS Users Group International. SAS Institute) Truncation implies that n components are tested Inc ·· Raleigh, North Carolina. 318 pp. until a predetermined time to. For truncation, The procedure LIFETEST has been developed the number of items that fail~ r, is a random for estimating and testing hypotheses concerning variable just as are the life tim~s. In either the parameters of distributions commonly encoun- situation the lata consists of r<n times to failure. A complete sample ia merely a special tered in evaluating the reliability of system components. Currently, the procedure contains case of censoring with r=n. point and interval estimates. and lip!! values for If U = 0 then the distribution satisfies testing the parameters of the exponential dis- the lack-of-memory property associated with the exponential distribution. In this situation it tribution for a variety of sampling schemes. The sampling includes two types of censoring would seem plausible to consider th~ r~placement of worn out ,cOTIl.ponents with new ones. For such wher",Sugi-78-53 Hill Morgan Nelson.txt
"Donald J. Henderson Data Systens Application Division Agricultural Research Service U.S. Department of Agriculture Beltsville, Maryland 20705 The endpoints can not be harrlled this Wi'ly. 1\lkey has suggested. an 11en::1-va1ue rule!1 be used HENDEREXJN, D. J. 1978. M:icro conm:rnds fur instead of a) dl:<lJOping the endf""'mts Or b) leavin;; 'I\lkey type SIllJOthing. p[).279 -263. TIl them unchanged. His end-value rule is given by: Stran;'!, R. H., (ed.) , Proc., Third Annual CJ:>nference of the Sl\S Users Group Inter- The difference between the smoothed end- 1) national. SAS 1I1$ti tute, Inc., Raleigh, value and the next to the end srr=thed pp. lbrth carolina. 318 value should be between 0 and +2 times the differen:e between the next to the A set of macros is presente..i which enable end sm::othed value end the smoothed user to easily perfoIIn l1l:)st of the srmothing the value Erljacent to iL techniques presented by TLlkey (1977). The results are stored as two SAS data sets. One contains the 2} The srrrothed end-value is as close to the trend arrl the other contains the residuals. Their input end-value as f""'ssible. use on a set of insect count data is presented ~ TI.lkey denotes this component as a ""3"" srrooth. The SAS rracra is called MID3. It is often desirable to srro:>th a set of data .. ~ans R£peated of Three we may want to examine the trend so that we can get This o::wp:ment is nOOe up of repeated tI 311 a clearer view of sene overall pattern, uncluttered by the details. Or, we may want to ex,3Il\lne the 5mXlths lUltil an additional ""3"" sm:oth has no residuals so that we can gam insight into the effect. This occurs when the srroothed pattern is details. made up of the foU"""",ing overlapping patterns: steady 1l!M'lId, flat peaks, steady downward, and Until row, the only easy way to srrooth a set flat valleys. The flat psaks an;'! valleys Im.lSt be of data in SAS has been to do a regression an;'! at least two data f""'ints long. output the predicted values and",Sugi-78-54 Henderson.txt
"1 USE OF MATRIX FOR SINGLE Dl!I;REE OF FREEDOM CONTRASTS IN FACTORIAL EXPERlMENTS s. G. Camer ]epartment of .Agronomy.,. University of"" Illinois Urbana, Illinois 61801 J\JlSTRACT sources of a nutrient in fertilizere. A quan- CARMER, S.. G. Use 01' MATRIX for single de- titative factor i5 One for which the levels can gree of"" freedom contrasts in ractorial be assigned meaningful numerical values.. Exam- experiments. pp.284-289. IN Strand~ R. H. ples include length of stor~e or drying time, (ed.), Proc., Third Annual Con£erence of temperature, and any variable whose levels are the SAS Ussr5 Group Inte:rnational. SAS ra.te~. Inc., Raleigh, In~titute, No~th C~olina. 318 pp. For a quantitative factor,re~ssion anal- ysis is usually the best approach. With ""the use A SAS-76 MACRO has been prepared to compute of orthogonal polynomial coefficients the ortho- single degree of freedom linear contrasts on data gonal single degree of freedom"" contrasts for the from balanced factorial experiments. ~e MACRO linear, quadratic, cubic~ etc. effects can be utilizes MATRIX to perform a tabular W1alysis on computed. For tab-liar analysis the contrast the treatment totals~ An example involving a matrix"" for a quantitative factor, A, with four 3 x 2 factorial is given. equally spaced lev31s, for example, would be written as: LEVEL OF FACTOR A . lNTRODUCTION 1 1 E. i CONTRAST Factorial experiments are cornmon in 1IIIDJ,y Mean AD 1 1 1 1 areas of 8cientific investigation+ Appropriate 3 Linear effect -1 -3 Al 1 analysis of data from such experiments usually Quadratic e.ffect -1 A2 1 -1 1 incluaeEH 1) an analysis of variance whicr, par- A3 -3 3 Cubic effect -1 1 itions the total variation into the various over- all main effects, interactions and experimental The coefficients for contrasts AI, A2, and A3 error ter.ms, and 2) a further partition of the be found in ma~ statistical methods texts or m~ overall main effects and interactions into ""mean- in such tables as those provided by Anderson",Sugi-78-55 Carmer.txt
"y Environmental Research Laboratory Gulf Breeze, Florida 32561 AESTRACT OGLESBY, J.L., AND L.H. BAHNER. 1978. Nonlinear model for pesticide accumulation in selected estu- arine species. pp.288-292. IN Strand, R.B. (ed.)., Proc., Third Annual Conference of the SAS Users Group International. SAS Institute, Inc., RAleigh, North Carolina. 318 pp. Extensive testing has shown that pesticides, such a9 Kepone and endrin, are rapidly accumulated by estuarine animals from water, food, or sediment. AfteT initial uptake, a pesticide can depurate rapidly or slovly, depending on its chemical composition, the test species, and temperature. Chemicals that de- purate slowly can threaten aquatic animals and man in their movement through aquatic food webs. Simulated aquatic exposures of Kepone and endrin to estuarine shrimp and crabs were used to test our nonlinear statistical models for pesticide uptake, equilibrium, and depuration. The models describe biological data as a single equation, thus allowing variations due to many physical, chemical, biological. and random error factors to be analyzed simultaneously. INTRODUCTION ined. Therefore, we developed a generalized mathematical equation that: 1) describes the Aquatic animals accumulate and depurate available data and delineates rates; 2) dsscribes pesticides at varying rates due to their unique uptake from water, food, or sediments; 3) de- characteristics, length of exposure, temperature, scribes uptake singly; 4) describes depuration and s",Sugi-78-56 Oglesby Bahner.txt
"a AJlSTRACT L""5stE'd h!""1.1')W arR ~ll th.P_ optioTIo<:! and pars- REYNOLDS, W. C. 1978. SAS SupplQmental meters that:: may be included on the PROe SPSS Procedure SPSS. pp. 293-295. IN Strand, a. stat:ement. All are optional and may be spec i- (ed.). Froc., Third Annual Confer- ~. f:led in any order. ence of the SAS Users Group International. sAs Institute, Inc., Raleigh, North DATA"""" SAS data aet name Carolina. 318 pp. The DATA parameter gives the name of the Unquestionably, the two most important and SAS da~a set that is to be converted to an widely used general purpose statistical computer programs are SAS (Statistical Analysis System) SPSS system file* The SPSS file will have the same name aa the SAS data s@t-s minor and SPSS (Statistical Package for the Social n~e {unless otherwise specified with a Sciences). As the two Programs hav~ their o~ FILENAME paramet~r (see FILENAME b@low»). unique capabilities and limitations, clearly an If the DATA parameter is not specified, interface between the two would enhance the then no SAS data set will be converted~ utility of each. SAS procedure SPSS is such an interface. The procedure provides for the auto- TODD """" ddname ruatic conversion of SAS data sets tD SPSS system files, the ~xecution of SPSS statem~nts and The TODD (abbreviation~ TO) parameter procedures and the conversion of SPSS systero indicates the ddname of a job control files to SAS data sets. language (JeL) data definition CDD) state- This paper describes this interfa",Sugi-78-57 Reynolds.txt
"es I will show augment ex- isting FROCS; The third illustrates outputting Wooding, N. R., Jr. Improving SAS PROCS ~ithOut dOltB from GilL rewriting SAS pp. 296-302. IN Strand, R.H. Ced.), PROC. Third Annual Conference of the PRoe PRINTTO functions to direct SAS page SAS Users Group International. SAS Insti- output to some device other than the printer. For tute, Inc. Raleigh, North Carolina.31B pp. example. the following code causes PROC ANOVA output to be stored on d1ak. Printed output from SAS PROCS might some- //F120F001 DD DSN~rEMP,UNIT~SYSDA, times be more useful in reports if addic10nal "" SPACE: (CYL, (5,5) ,RLSE), information could be added to the standard out- // DCB~(RECFM·FB,LRECL~133.BLKSIZE·3990) put. Conversely. informa~ion not included in I ,. output data may be useful for further work. 88tS Heretofore, the information had to be typed on the output or copied and repunched for subse- PROC PRINTTO UNIT 20; quent processing. The new features, PROC PRINTIO PROC ANOVA; CUSSES DOSE; MOnEL RCOUNT DOSE; and substring handl1ng~ allow considerable capa- PROC PRINT1'O; bility in morlifying and using SAS printout. Por- tions of output may also be uSed as input for The second PROG PRINTTO sends the output back to further processing where there 1s now no out- the page printer. The ANOVA output may now be put capability. Siruple examples show ~he aug- read from the disk as 133 byte records and treat- mentation of PROC FREQ and FROC ANOVA and the ed as ordinary data. retrieval",Sugi-78-58 Wooding.txt
"statisttcs and Biomedical Computer Laborato~y Washington University Medical School St. Louis, Missouri 63110 disease, etc. The data for this situation can be ABSTRACT represented as a 2x2 contingency table with two parameters of interest. namel~ the probability MILLER. J. P, McCRATE, M. M., PROVINCE. M·· ¢o of the disease 9iven that the symptom is and WETTE, R. Max.imum Likelihood Estima- absent. and ~l' the probability of the disease tion of the Multivariate Logistic. given that the symptom is present. The infor- pp. 303-30S.In Strand, R. H. (ed.), Proc. Third Annual Conference of the SAS Userls mation can then be represented as in Figure 1. Group International, SAS Institute, Inc., Raleigh, North Carolina, 318 pp. D""ISE1'~SE A frequent problem occurring in the analysis o 1 of clinical studies is the construction of a risk function which allows the calculation of the o ""0 probability of some outcome such as death on the basis of a training set of observations. In this SYMPTOM I. training set, the observations are identified as 1 l' 1-""1 belonging to either population ITO or IT l · AS90~ ',., ciated with @ach observation is a vector X of length p which is composed of observations on various symptoms or laboratory measurements which Figure 1 are to be used to calculate the probability of membership in ITi. A common model for p{TIil~) is A common statistic to represent the degree of that of the muleivariage logistic i.e. association between the symptom and the disease is the od",Sugi-78-59 Miller McCrate Province Wette.txt
"USES OF &AS FOR CORPORATE O.~. R~ L~ Anderson, Milliken & Company INTRODUCTtON: This paper 1a a summary of an in- information se:rvir;;.es: for routi.ne da~a vited talk given to the Busines$ Session a~ SUGI proce~ai~g, DSS~ manpower planning and 79. Here I will briefly describe (1) ~ primary repo-rting1"" ac-counting and SHE' analysis, user of SAS in industry~ (2) the str'Uetl,1:ta or systems develQpme~t: for pilot p~ograms. characte:ristiC$ of .!m O.R. ,group~ (3),O .. R. at production aystems~ quality control systems. Milliken. (4) 'users of SAS at Milliken, (5) some siDl',llation'models: for_manufa~turin. operations -and DP- o-perat1-ons, areas of appl1cation, (6) some types of problems, and (7) a few applications in manufacturing, ec.onom-ic g,t-uCiie-s, marketing' and development. routiqe statist~cal.applications~ per5(,nn~1: -fo'r turn-over analysis, retention, THE COHPANY: Milliken 10 a large privately owned· wage auQ;d.ts, textile corporation with approximately 70 m3n~ facturing plan""ts located mainly in the southeast ~ p~anning ~odels! for MRP, seheduling, et~. with some in New Engl~nd and ~urope. The market- queueing applications: (see 3, cbapt~r .9-)': 1. A Survey of the OperatiQns Research·-Function, ing headquarters is in New York, but the central headquarters and rese~rch facilities ar~ in Cox, J.F-.~ Leclttetter,. W.N., Clemson Review of Spartanburg, S.C. We're very proud of our re~ Indu&tx-ial Man·agement~ Vol. XVII', No. 2~, :Fall search and information facilities a~_ is expressed 1978. Z. An Analysis of the O.R./M.S. Industrial"" by the slogan ""Textile Leadership Through Re- sea.rch u · Th-e major prod'i,lct;s are textile"", indus'- -Academic lntertaee; Cox,_ :J.Y!"".-"" Ledb-etter~ W.N.,· trials~ chemicals, and p~ckagins. Smith t J .M~,. 'rIMS IN'IERFACES, Vol-. 9·, No ~ '1, OPERATIONS RESEARCH: Operations Research can be Nov. In·S. broadly defined as ~pplying the gci~nti£i~ methQd 3. -O\\,ilu:'at:iQnB' ·Reaeareh,. 2ILd Edition, Hillier, (Research) tQ",Sugi-79-02 Anderson.txt
"A SAS-VSPC INTERFACE FOR HANDLING LIBRARY FUNCTIONS David J. Cowen. 'Social and Behavioral Sciences Laboratory Sandra T. Cowen, Bur~au of Governmental Research and Service : University of South Carolina ABSTRACT. orga.nizations· for· which verticle hanging' folders have pro""ven to'· be' a practfcal st.orage method ·. This paper describes the use of SAS prpced:u:res The func:t1onal cLassification system de.veloped c mai,~tenance ~:D.d for the creation, ;t""ec,ording of by the. 'International City Management Association materials -contained in a research or.ient_ed (1975.) was adapted to the ·library materials.. The library in the· Bureau·~f Gover.amental -Research system utilizes en alphabetical' arrangement of ~nd_ S~rvice' at the University of South Carolina. major subject· areas c:onunonly used in the field of SAS used in conjunction with VSFC.. thrqugh a CRT public. adminia.t.r-atiOl'I. Each subject is coded terminal ,located ·,in the ~ibrary has aided in the with the appropriate. letter, followed by a number, cr~at1.on· of a h1.ghly u,ser-o-r1ented- and flexible which""is determined by the' total numb-er of other bibl;f.ographieal, syst-em~ ,The- 'system handles a majo.r· subject headings beginning with that le.tter. multitude Qf'lnputting~ 'editing. 8ort;ing,l. se- For example, there ·are· only t·wo major 'subjects lect-iug ~d repQrting .procedures that; are common beginning· with the letter .II.:on. The number code to the. operation of any library. SAS INPUT, SORT, is determined' .'by· dividing one more than' ·the FORMS and. IF pro'cedurM il1, v.a.rious c~b.ina.·t1.ona numbeT of primary.categories into 1000. The provide .extensive. capabilitJes to g~ner.,ate. r.esultant interval .. is uaed·-for the first toplc~ specialized searches, and. output products. More and is cumulatively added· for the other cate- specifically~ FROC FORMS was used to create a gories in' their alphabeti.c. sequence. . McordiD.gly, card .ca-talqgue fo~.a pub.lic adm;[,nistratiOll the. cat",Sugi-79-03 Cowen Cowen.txt
"FILE DEFINITION ""MACROS"" FOR CENSUS PUBLIC USE SAMPLES Je~n ~ol~er, B. CIRCA, University of Florida INTRODUCTION storage is Increased over the hierarchical representation. ·In the househol d f11 e, space must be allowed for From the 1970 Decennial Censuses of a fixed number of persons In each record, even though a given housing unit may be Housing and Population, the U.S. Bureau or vacant occupied by less tha·n the of the Census provided a substantial volume of reports to the public on maximum number ·of Individuals. In the magnetic computer tape. Two kinds of persons file, data from the household machine readable data are available from must. be repeated for each r~cord the Bureau, summary tapes contalnln·g household member. tabulations similar to the printed A relational model can be Implemented reports, and the public use sample files In SAS to store these data In a usable of untabulated, or ""micro"", data (1),. form wi thout redundancy. 1 n. the relatIonal approacn, Public use sample files are available a complex data for both the Intermediate length structure 15 represented by multiple questionnaire form (fifteen percent rectangul.ar ent!tles -- In thisease,one sample) and the longest questionnaire SAS dataset contlllning the household form (five percent sample). For these data, and another for the person data. respondent populations, files are This should be a straightforward available by state and by SMSA or county appl icatlan. However, the Bureau fa! led group. (This paper will not address the to Inc 1 ude the hous""ho 1 d ser I a 1 number so-called neighborhood files.) One In and the geograph·i c codes from . the household record on the person. records OnE! hundred, one in one tho!,Jsand,- and one In ten thousand samples are available. wh leh follow. Thus, to accompllsli the relational implementation, the household serial number must be captured .from the The state and SMSA files have a two level hierarchy. For each sampled household record and app~nded to",Sugi-79-04 Holzer.txt
"otor Compall1 .I:earborn, Michiga.n 48121. Douglas M. Garber Education and Personnel Research Department Ford Motor Company ABSTRACT Sampling prooedures are used to identify Whioh employee. will be asked to· partioipate in In a large company"" employee surveys C30n-· the survey. A five percent random 'sample is earning individual ·attitudes toward work, super- vision, compensation, and other perso-nnel issues selected from the population of· Company Salaried This provides a Corporate- profile are needed to 1) evaluate· personnel polioies and employees~ programs, and 2) facilitate an uJl'o'!ll'd flow of having the desired accuracy at a relatively low communications through the organization. Prac- cost. Additional_amples are drawn for staffs/ 'tical application of survey findings requires divisions and offices/plants so that the corporate trend analyses for top management. reported results also >dll 00 representative at This must be followed by rapid feedback to the local lavels. smaller components so that local aotion planning can be initiated. SAS data managemant and Administration or the survey oocurs in report-writing capabilities are discussed in small groups throughout the Company during a t~-Yeek period. Survey administrators have connection with a recent slll""V""ey,...feedback e:.r.rQrt ooen oriented to provide standardized conditionS in a large, mu1 tiditriaional company. The i,. of administration. Procedures ensuring confi-- reports generated by SAS helped managers inte",Sugi-79-05 Curley Garber.txt
"ESTIMATING PASSENGER DEMANDS FROM TRUNCATED SAMPLES Franklin S. Young, United ALrlines THE PROBLEM distributed (Li.d.). This assumption tends to break down during periods of heavy The profItability of an airline is partly determined travel. by its ability to put seats where they are needed the most, to match capacity to demand over its ESTIMATION METHODS entire network. Criteria 1. The first hurdle in this challe.nge is to measure demand. The latter becom es. unfortunately, an Any estimation method must, of course, elusive and unobservable quantity when there is provIde reasonably aocurate results. In ad- a possibility of ""stockouts."" In the airline in- dition, it must meet two other criteria: dustry. stockouts OCcur stmply because an air- plane has .. finite and known capacity. The - It must be computationally cheap enough relationship between sales (passenger loads) and to estimate 1,600 demand parameters on a regular basis. With the acquisltlon m demand can be viewed as: SAS, we have decided to perform this analysis for each flight leg instead· m Sale.s = Min (demand, capacity) aircraft type. Our approach has heen to infer demand from pas- senger loads which are readily observable. The - It must be usable with 20 to 30 obser- distribution of passenger loads is a trunoated vations. The Inputs to this analysis proxy of demand. Or, In other words, we have are the daily loads by flight during a to esUmate the demand parameters from truncated particular month. samples,. t~o We have implemented methods and ex- BASIC ASSUMPTIONS perimented with a third. 1. Normality Graphical Approach 2, The frequency distribution of load data is be- Prior to the acquisition ofSAS, this estima- lieved by· the industry to be, among others, tion problem had been solved graphically. Its logic is quite straightforward. The fre- truncated normal. log-normaL negotive bi- .nomlal, or Eriang distributed. quency distribution of loads is plotted on namal probability paper. After ""discount- W"", h",Sugi-79-06 Young.txt
"PAMS: a project Activity Management System Implemented In SAS Wiiliam Ingram, University of Florida project, has a status (eg. active, complete, etc.) that is subject to The Division of Medical Systems, a change from time to time. The research division of the Pathology information pertinent to the personnel Department of the University of Florida model included available personnel College of Medicine, has been called project/task personnel allocation, 'and upon to act as a consultant in the area personnel utilization (time reporting). of automated health care systems to the ~he allocation portion of our moael Shands Teaching Hospital. This- new task permitted personnel to be allocated to a brought with it a requirement for an task within a project for a fixed organized accounting and reporting of portion of time/week + A person could be our activities to aid in sorting out the allocated to multiple tasks/project but funding of projects.. We must -be able to only once for each task ·for a given time report which portion of our time was period. Changing the level of hours a devoted to hospital consulting, person ~s assigned to a task may be education, research, and departmental accompllshed by allocating a person for In addition, our new obligations~ one level, for a period of time and then responsibilities to the hospital brought changing their allocation f.or a later an increase in our staff. Thus period of time. A person may be intradivisional problems in coordination allocated- more than once to a task , ""if and r~source sharing also increased. we the periods of allocation do not also discovered that although our overlap. This feature allows a project rnanpower.r7sources had grown, they were manager to establish his future manpower not BufflClent to handle the increase in requirements. projects being directed to us .. ' Once the conceptual model of how These factors led us to t-he- projects aha personnel were handled· conclusion that we needed a tool to aid ~~thi",Sugi-79-07 Ingram.txt
"TRACT .. calculate statistics of turnaround times (time ·between submission and retrieval) by job class. !eroote' ~obfJ1t.rY,·(RJEJstation statistics· are used in .c[eterminingillorkloads and . ' ... . The COBOL program wa.s written. to search distr.i,tluting cost. of. the facilities to the master. ""ccounting tapes created by the .departments. Summaries are generated to Houston Automatic ~ooling Pro9ram (HASP) on dlsplay the. number of users., types .of jobs· the ORNCmain computers. A-record is created process.edthrough the RJE fac jl it..)!, and the . by HASP on the accounting files for each job pers.o""s lor proje~t5)uti lizing, the J.acility, . passing through the main computers. The $.el eO,ted summari es b'yuser n.ame, jo~. n"""",~ . information (Table.l) recorded includes the RJE initials, and types. of jobs T~n are. pres.~nted facility number, the print and punch in tabular form. . destination codes, computer request number, , , date, job nam.e initials, and time in/time out figures. Other information recorded on the CSD INTRODUCTION master files was not pertinent to·our purposes ·. Selecting only· tilo,s records which In 1972, -the Environmental Sciences carried ourRJEfaci lity number, a subset file Division at Oak Ridge National LaboratorJ' was created. ·.This fi le was sortad by job name (ORNL) installed a remote job entry (RJE) initials and the sorted .file. placed on magnetic station for submission to and retrieval of jobs tape. from the main frame computers operated",Sugi-79-08 Strand.txt
"forward-updating procedures, less stornge cost, end faster processing times. However, for ad .hoc da.ta (Jnolys.is, Thecopobillti""s of the Statistical Analysis Sy<tem ($AS) severol of the file, mu.t often be combined to obtain the ere much greater than simply providit""l,Q statistical anal- needed do ta. ysis. At the North Cent"",1 Te""as Council of Govern- menls (NCTCOG), SAS i, u"",d primarily for Its data A Ithough the stoff hod not used a dolo base management system before, It was fehthat a dotq base manager was management and programming copobilities. The use of SAS has significantly reduced the prOlgramming time 10 n""""ded to reduce the amount 'Of software development respond to ad 'hoc re~uests and has consequently chc:mged required to handle the file' Md to neduce the ""perotiOlnal the Wr:JY in which data processin',Q support is provided at complexity of merging the file, as needed. NCTCOG. This poper will outline the process OIf select- data base mc:magement system ing SAS, provide a comparison of SAS versus other pro- r""e desired beneAts from 0 .. gramming language, from the slondpoints of program were to: development cost ond processing e-fficiency, and discuss the cast-sa.vings OIf using $AS. · Integ"",te dota files · Minimize dcta redundancies ( , ,. ,",Sugi-79-09 Parker.txt
"exful aspects of MARK IV derive from MARK IV is a widely available file-manage- hiera~chical records. Therefore, the hierarchi- ment and reporting system, capable of construct- cal record type is the only one we will consider ing and maintaining complex hierar~hical records. in this paper~ SAS) whQse abilities are largely complementary to As a simple example of a hierarchical record, those of MARK IV, can be made to read MARK IV consider the different positions an employee might files rather easily, providing a substantial ex- have held as he worked his way up the ranks of a tension in the kinds of reports that can be gener- ated from a single data base. company: SMITH, JAMES ·....·. + · · · · · · · · · · · · · INTRODUCTION MESSENGER ···················· SOLDERER ····················· MARK IV is a powerful data 'IIla.nagement and FOREMAN ······················ reporting system available at some 2000 ins-talla- MANAGER ······················ tions worldwide. At our university it serves a VICE-PRESIDENT··············· valuable function as a report writing tool used not only by our data processing department but Clearly, the number of positions any employee could have held is a function of both the employ- alBo by various people in the adffiinistr&tion and acad~lc deparbments. As often as needed, Our ee and the length of time he has worked for the company. MARK IV ,defines and processes records data processing depar~nt generates MARK IV cop- iee of impoTtant sect-ors of our on-l",Sugi-79-10 Spitznagel.txt
"plot of ABSTRACT 10,000 observations will be equally uni11uminating. If however we first group CHANNEL 3 BUSY into 10% SAS is widely used in business for computer percentage clas~e~ O-lO%~ ··· 90%-lOO% and then do performallce tunlng, market research, proJu...:1:. schematic plots of CPU BUSY for each 10% group, planning, operations research and MIS reporting Figure 2, a v.ery coherent plot indicative of a as well as for standard statistical applications. possible bottleneck in CPU BUSY whenev.er CHANNEL 3 Three examples are presented. The second example BUSY is gr~ater than 70% emergee. The simple uses the new ARRAY and DO ··· END capabilities of SAS program which groups the data and produces the SAS 79. slde-by-eide box pltos with PROC SPLOT is as follows: EXAMPLE 1: US ING BOX PLOTS FOR CHANNEL TUNING DATA; SET SASSPACE.S410 (KEEP-e9 CII): IF ell-lOO THEN CI1-99.9; Using schematic or box plots11s an excellent Cll-lO*INT(CII/IO); *GROUP Cll-CH3BUSY; way to view large batches of univariate or bi- *INTO 10% CLASSES: variate data (with s1d~-bY-Bide box plots) in an PROe SORT; BY Cll; exploratory manner. An example is shown which PROC SPLOT; CLASSES CII; VAH C9; illustrates its value in a channel tuning appli- TITLE SPLOT OF CPU BUSY VS CHANNEL 3 eusy; catiori2. Figure 1 illustrates what happens when we plot a weekrs worth of bivariate 5-second interval data. The data was extracted by a COMTEN 8016 hardware monitor and further condensed into a stored SAS data set. lE:I;EIDI ...",Sugi-79-11 Gjertsen.txt
"A SAS PRQGR.m TO CRAl'lUCALLY SCIIE!)ULE TIlE TASKS ASSIDNlID TO EACH· EMPLO""t'EE J~ Walter Guthrie and Jeffr¢:y W. ·Berno Cleveland Trust Company A SAS program. was written to schedule tasks for ~ 4\1a~t-e:rly ~eppr~. A group of SAS macros is IUn for each employee. Each employee has an available hours ca.rd with 12 values. Each value represents the. numbe~ ~ach of hours that employee is available to work in per:1od. Fixed. commitment cards suc:h as vacation and conferences,. subtract frotn: the amount of hours av.a.i1a.ble in each period. A group of tasks is inputed, each' has an estimated houra £ leld and a. priority. Eac.h task can be dependent on another task to finish before it. The highest priority task is scheduled for the first can pe~iod. If it be completed in the period the second highest priority task :l.S ~ , ling up the available hours. ~~ A graphical representation is produced showing the 12 periods the tasks scheduled for each period. The. program is useful for show1ng the effect on all tasks when priorities are changed or available hours are changed. 57  .:) c. H E. D I..,J I- INc;.. }' L-OG-IC-. 1ST QTR rw. AVAIl ABI E HOIIRS ill JAN 7.5 HR x NO WORK DAYS 173 150 165 ,. ! FIXED COMMITMENTS lJSER ASS [STANCE 40 30 40 ERROR REPORTS 16 16 12 SHARE 52 3L.5. 109 117 70.5 IAS.KS DESCRIPTION No.. 1:lBS.. 551-1 JQB VALID EXIT ;; 90 70 20 ,. ;; i ; f: 552-1 MODIFY SPOHP 30 30 ~; ~'. j '. :- 553-1 APPLY SU 63 17 3 20 f t 554-1 APPLY AMD RMS 50 !iL -ll i f 155 173 150 ~ i 58  FEATURES CHANGE DATE AND SCHEDULE MOVES DOWN, COMPLETED TASKS ARE EXCLUDED, MAX HOURS/MO,· CAN BE SUPPLIED WITH EACH TASK 75. DEFAULT , TASKS CAN BE DEPENDENT ON ANOTHER TO FINISH FIRST. A FIXED START PERIOD CAN BE PROVIDED. TASK HOURS NOT FINISHED IN 12 PERIODS ARE IN OVERFLOW· AREA. CROSS FOOT TOTALS ARE PROVIDED"" PROC IS NE~DED · ATOTALS ERRORS ARE PRINTED IF THE PROGRAM cANNOT FIND A DE- PENDENT TASK'S PREDECESSOR, OR IF·FIXED TASKS HOURS ARE GREATER THAN AVAILABLE HOURS;· OR IF TH",Sugi-79-12 Guthrie Berno.txt
"A CASE ~lANAGEMENT SYSTEM FOR THE NEW JERSEY PUBLIC EMPLOYMENT RELATIONS COMMISSION Barbara E. Kemmerer Nancy Begin Rutgers University N.J. Public Employment Relations Commission BACKGROUND AND NEED system to incr.e.,a.-se efficien'cy and accu- The purpose of the New Jer,sey Public- racy of retrieving his tarie'al case infor- Employment Relations Commission (PERC) ,is mation located in 'its· files' and of main- to promote,harmony and stability in pub- taining accurate control of currently lic sector labor, relations by 'serving as active cas~s. a neutral third party·to, minimize the ef- The ,1968 Act', in addition 'to estab- fect ,of employer-employ\!e disputes. The lishing the Public Employment Relations public sector in New J,e'rsey inc.ludes state. county lDUnicipal~: and school dis- Commission, included a provision estab- J trict; employers 'and employees. The seven lishing a relationship between the Com- member Commiss,ion ::is' 'tr.ipart'ite, that is mission end the 'Institute of Management and Labar Relations, Rutgers Unive.sit,y~ composed of two ,part-time representatives In part becaus-e of the statutory q)nnec- of publi<: employers, two. of ,employee tion ~ faCUlty in the Rese_arch Depa:rtment groups, and two representing the public interest. The seventh member"", ,the Chair- of the Institute have conduc'ted research concerni~g various facets of the Commis- man. _also represents the public but Serves full-time aa the chief administra~ sion's operation since 1969 and had, in tive offiCer,with authority over the fact, already assembled some of the in- staff which conducts the day-to-day busi~ formatie-rt ne-cessary for, the est;::ablishment of a data systell!. This unique relation~ nessof'PERC. ship led to a request that the Research PERC was created in 1968 when,New Depar,tment develop a proposal for a com- Jersey passed an ,employer-employee rela- 'This act w~s amended in puterized -system for re-,te.ntion and: re- tiOD§ act.! . trieval of case information",Sugi-79-13 Begin Kemmerer.txt
"A SAS PROCEDURE FOR AFTER TAX INVESTMENT ANALYSIS by K. Steven R. Borbash and Arup Mal11k Industrial Engineering Department West Virginia University 1. Introduction For each year k, k=l, 2, ···· N, let FROC ROR 1s de6cribed below. This procedure The interest payment on the loan I(k) processes the annual costs and revenues associ- UB(k) The unpaid .balance ated with a capital asset over the specified life of the asset. A financial report is gener- RP(k) The total loan repayment ated by the procedure. This report computes PRIN(k) The principal part of RP(k). capital gains and income taxes and produces a tabulation of the cash flows before and after Therefore, PRIN(k) RP(k) - I(k). ~ taxes, and allows for a portion of the initial capital to be borrowed at a specified interest For a uniform annual end of year repayment rate. plan, a t~e From cash flow after taxes I rate of RP(k) P*d'(A/p, r, t) ~ return is computed as well as the net present warth of the after tax cash flow for a range of where (AlP, r, t) is the well known capital intere.st rateS. recovery factor (1), and l(k) and PRIN(k) are computed recursively starting from UB(O) = P*d FRoe ROR is implemented using a Btanrl~alone FORTRAN program called ATXROR~ developed by the I(k) = UB(k-l) · r authors at West Virginia UniverSity for use in PRIN(k) = RP(k) - I(k) the classroom. The SAS lmplementation retains UB(k) = UB(k-l) - PRIN(k) the ATXROR program intact. Five parmcards are used with the procedure to provide parameters For each year k, k=l, 2, ... , N, the taxable in the for.mat expected by ATXROR. Annual reven- income is given by ues and costa are_read in using SAS and then converted to a format expected by ATXROR and TI(k) R - OD(k) - D(k) - I(k) = passed a:cing with the parameter data to ATXROR. where Background discussion of the rate of return method is presented below. This is followed by The operating expenses OD(k) details ·on how to run and interpret PROC ROR.- The depreciation charge, which may D(k)",Sugi-79-14 Borbash Mallik.txt
"A SAS-AUTOGRP INTERFACE FOR THE ANALYSIS OF HOSPITAL DISCHARGE DATA Daniel Freeman, Jr .· Michael B. Bracken, Robert F. and Jean L. Freeman, Ya-le University H~ Elia~ An alternative data system which has become 1. Introduction qui te -wide-spread is ·the ""mul ti-purpose survey"". Since the middle of the 1960 ' s a variety of This approach gatheTs data from a ·population health related data sets have become available through the use of probability sampling methods. The data gathering process is intended to pro- to the health analyst. Of particular importance is that these da~a sets are in ma~hine readable vide information for a variety of users. The form so that extensive computer assisted analysis best known of these, in the health field. is the is feasible. In this paper a typology of these National Health Survey (NHS). The NHS actually data sets is presented along with a brief summary includes a variety of sample surveys each of of some of their peculiar difficulties. Then a which have two important chaTacteristics. First system designed for this type of data is discuss- they provide data about a carefully deliminated ed. Finally, an example, which illustrates a cross-section of specified target populations. strategy for analysis is presented. It uses data Second, since they provide data to a variety of from the Hospital Discharge Survey (HDS) of the users their underlying rationale is sometimes National Center for Health Statistics (NCHS). less apparent than that of administrative or sci- entific data systems. .HoweVer, while these sur- Traditionally health data have been gathered veys are of great potential value~ their general- either as a by-product of administrative record ity and scope lead to a number of difficulties. keeping systems or as part of a well specified scientific study. The administrative approach The most immediate problem is the sheer has been quite successfully employea in such di- magni tude of the health survey. Typically they verse areas a",Sugi-79-15 Freeman Bracken Elia Freeman.txt
"sociation and several Abstract of the Computer Science and Statistics Inter- face Symposia. What I attempt here is very Comparison of computer programs is a very modest compared to their efforts. complex task. as there are many criteria which can be used and comparison under standard con- ditions may be difficult to achieve. Any eval- The Statistical Problem uation of statistical computer programs must consider three aspects: (I) definition of the Nonlinear ·regression is generally understood statistical problem, (2) possible numerical to mean the matching of experimental or algorithms for computing the solution to the observed data to a nonlinear mathematical model statistical problem, and (3) implementation by finding those parameters estimates which of the chosen algorithm{s) on a computer. gi ve a ""best fit"" .of the data to the model. Clearly all of these are reflected in the per- ""Best fit"" can be defined in several ways, but formance of a statistical program. Nonlinear is usually by minimizing a function of the regression or parameter estimation is a subset deviations between model and data, and mini- of the much larger mathematical area of function mizing the sum of Squared deviations is often optimization. Having picked the objective used. function to be optimized and the numerical algo- rithm{s) to compute the optimum, then the imple- More formally, we have N. observations of each mentation must be considered and the performance of M Functions 1 evaluated against one",Sugi-79-16 Metzler.txt
"porat~on, therapy and is therefore dropped by th~ investi- ABSTRACT gator. Sometimes a patient 19 dropped due to un- satisfactory therapeutic respouse. Whatever the reasons for dropouts, drug related or non-drug PATEL, H. I., 1979. Analysis of covariance related~ withdrawals of such patients from the of incomplete data in experiments with repeated measurements in clinical trials 1 trial result in incomplete data. We assume the In Littell, Ray (ed.), pp. multivariate normality for the distribution of the Proe., Fourth Annual Conference of the vector of observations~ Furthermore~ we consider SAS Users Group, Internat~onal. SAS a situation where a patient with missing observa- Institute, Inc., Raleigh, North Carolina. tion at time ti alao haa a missing observation at pp. Bhargava (1962, 1975) has studied time tj for j)i. In clinical drug trials, we often have to some hypothesis testing problems fur Buch incom- deal with incomplete data as SOme of the patients plete data after callIng them 'monotone samples'. Srivastava and McDonald (1974) have considered a under therapy drop out before completing the different approach known as 'growth curve analysis' scheduled treatment period due t~ several reasons. ~. In this situation, the multivariate normal density to analyze such incomplete data. In this paper, we consider a one-way analysis of covariance model for the distribution of the vector of observations and develop a procedure for testing the hypothesis obtained at success~ve time",Sugi-79-17 Patel.txt
"A OATA OICTIDNARY DRIVEN DATA ANALYSIS SYSTEM Doron Steger and Richard Enz, Hoechst-Roussel Pharmaceuticals, Inc. ABSTRACT: Because of the diversity and volume of data The pharmaceutical industry has been confronted encountered in clinical research, we developed with such difficulties for many years. Attempts a system allowing standardization for input and at solving some of them included standardizing flexibility for data management. The two main case report fonns and output, utilizing flexible components Of our overall system are SAS and a and comprehensive computer packages such as SAS, Data Dictionary. The Data Dictionary defines and introducing .data base management systems. the format and location of data for each study. SAS allows flexibility to manage and manipulate An additional step taken at Hoechst was to de- data. velop and utilize a system based on a data dictionary concept, The procedure we use is to The key to the system is an interface program create a file containing information about each (ODSAS), which links the Data Dictionary and record type (e.g. admission! labs, vital .sig~s, SAS. Through this program, an entire master efficacy, etc .· ,. In addit10n. informatlon 1s file of a clinical study is read into a SAS stored about each record types's data field such data base as separate data sets containing vari- as location, length, field format, minimum - ous types of data, e.g. admission records, lab- maximum limits, location of a decode file, 40 oratory values, etc., allowing access to the· character label etc. (see Figure 1). Defining data through SAS. all the fields provides complete mapping and structure infonnation for an entire study. It Many of our in-house programs have been inter- is rare that a data dictionary for a study ever faced with the Data Dictionary and with SAS. has to be developed from scratch since we have Several utility programs have been written for established many standard case report forms the management of SAS disk file",Sugi-79-18 Steger Enz.txt
"R1\NllOMIZATION SCHEDULES VIA SAS John Steedi', Abbott Labs* The MATRIX procedure also provides a conve- In drug research it is often necessary to produce a randomization schedule which a~s1gn8 nient method of computing the number of runs per treatment by block. The two different types of the treatment each patient is to receive. The purpose af this paper is to demonstrate,·via SAS~ objects for counting the number of runs associat- ed with treatment A, say, are: (I} treatment A the production of these tables using- Pro~edures and (2) not:. treatment A. Since, within each PLAN~ PRINIIO and MATRIX, for the Randomized Block Design (balanced). Then, a check for ""un- block, we have R objects of one kind (treatment usual u rand~izatipn8 is made by computing the. A) and P-R objects of the other kind (not treat- ment A) the mean number of runa is number of runs for each treatment by block. The concepts ~nd methods presentE::d herein + E(Runs) 1 ZR (P-R) can be applied to many statistical designs but = OUT discussion and example will trQat only the P Randomized Block DesIgn (ba.lanced) with -p.ara.- the standard deviation is met""ers B, P and T where B ~ number"" of Blocks, S.D.~[ZR = (P-R .2R P number of Patients per Block, (P-R) - "" T ~ number of Treatments. p2 (P-l). In OUr'"" example which ""follows B-3,. P=15 and T=3. Hence, the total number of pat~ents random- The minimum number of runs is 2 and the ized is PROD = B""P ,. 45 and the ""number of tTeat~ maximum is 2R + 1, (when T = 2 the maximum 19 ment repeats with~n a block 1s R = p/T""= 5. Tha 2R). These t~ parameters together with the mean output Qf PROe ~LAN, in this example, is read and standard deviation can be used to identify into a new data set"" via:PROC PRINTTO. Then the ""unusual II raridomizations. desired randomization schedule is produced via Returning to our example, with R=5 and P=15 PROC MATRIX. we ""have E (Runs)= 7.67 ana S.D. = 1.64 EXAMPLE (N~te: ~xpre9Qions that need to be changed fOT. different values of",Sugi-79-19 Stedl.txt
"A TUMOR REGISTRY INFORMATION SYSTEM APPLICATION ~lorida William Ingram, University of INTROOUCTION The Division of Medical Systems has were likely to change. (6) Not only developed a computerized Tumor Registry were standardized reports required (eg. Information System (TRIS) for the Shands alphabetic listing of all the cases in tumor registry) but also many varied Ad Teaching Hospital, a 450 bed acute care facility associated with the University Hoc reports and statistical data sum--- maries would be required to satisfy the of Florida College of Medicine. This registry is designed to provide high- research needs of the physicians. quality, standardized"" data, for the an- These needs suggested a computer- alysis of cancer treatment and diag- ized system"" developed within the frame- noses, that will (1) ensure that cancer work of a software vehicle that pro- patients receive annual physical examin- vided: (1) A high degree of data in- ations, (2) provide follow up data on dependence, which would allow: rapid the current status of each patients' dis- changes in the input format without ease and subsequent treatment, and (3) affecting the application programs, and aid the faculty in performing research permit application program development without conce~n for the physical data projects. The tumor registry maintains information on approximately 14,500 structure. (2) A full set of data mani- patients adding about 2,500 annually. pulation and management"" features that At the beginning of 1978, the Tumor would allow snrting, selecting, editing, Registry consisted of 1) two sets of and updating of observations in a wide manual card files, a patient file con- variety of applications. (3) Report taining data alive and deceased, and a generating capabilities that include follow up file containing information on both llquickie"" reports with formats de- termine'd automatically by the system, patients requiring follow up, and 2) an automated system. The automated system, and ""c",Sugi-79-20 Ingram.txt
"ence. It is only conc@rned about searching for trends in the ~ontinuous_ whether a true difference exists I no ,matter how and cateqQrical responses is very common in drug small. research da.ta' analyses.. In this paper. testing for ~rends in the ANOVA ""tables and contingency 'rh:e Type 'r estimab18 functions of GLM tables will be discussed using SAS. Numerical Procedure is considered as the most appropriate examples from Glinical and pre-clinical research for trend analyses. In this paper trend anal- will be given. yses for (1) orthogonal polynomials, (2) two- factor experiment with repeated measures on Introduction one-factor, (3) three-factor e)tperm.ent with repe'ated :measures, and (4) 2XK contingency Searching for trends is a very common table will be discussed using SAS. Numerical teohniq~ in drug research data analyses. This examples arisen from clinica1 and ~e-clinical technique is very useful to reveal time trends research will ""be given.. Data. were artificia.l in clinical trials with repeated measurements or derived from the literature. and to detect dose-respOnse relationships in pre-clinical expe~iment5 and clinical pha~co OrthOgonal Polynomials logical studies. , '. When the number of rep1ications for , Experupents with a quantitative factor, each level of a factor is not equal and/or the regression analysis or curve fitting is the most levels are not' at equal interval .. the coef- appropriate technique. The treatment Degree of ficients of orthogonal contrasts",Sugi-79-21 Yeh.txt
"TIlE SOUTH CAROLINA PAPMOBILE PROGRAM: A SAS APPLICATION Bonnie Pleasants Dumas, M~ Clintou Miller, III Department of Biometry Paul B. Underwood~ Jr~, Sue L. Stramm, Jan~t M4 Riggs Department of OB/GYN Medical University of South Carolina 1. IlACKGROUND The South Carolina PapmQbile proje~t. a pro- The South Carolina Papmobile is one of the spective study 'of canc~r in women, haa been in few successful Papmobile programs in the United ex.istence for mdre than three years. The stu-dy States. Dr. Paul Underwood, who heads the pro- is being conducted by the Departments of Obstet- ject, attributes the success to a concerted rics and Gynecology and Biometry at the Medical effort to make clear to the physicians in the various communities that the Medical University Two full-time Universit-y of South Carolina4 registered nurses travel in a specially equipped of South Carolina is not trying to compete with van from the Medical University in Charleston them. The Fapmobil~ V1S~tB a community by invi- to communities throughout th~ eastern part of tation Qnly and it seeks to provide examinations South Carolina. They conduct 85 to 90 half-day, to women who are not being seen regularly by one, two or three-day clinics each year. obtain- physicians. Women"" found to have abnormalitias ing over 3,000 Pap smears annually in these are not sent to MUSe, but are referred to local physicians. Each pati~nt is asked whether she clinics. has a physician, and if she does, a report of The Papmobile Study is typical of the kinda the clinical findings is sent to him. of collaboration and consulting projects with rI. POPULATION CHARACTERISTICS which the faculty and students of"" the Department of Biometry are involved. The 6749 records ""frcrm the first two years of Data on each patient are recorded On e. IIpap_ PapmobilR operation reveal the following charac- teristics. Patients ages range from 14 years to mobile Code Sheetll-H a four page form developed at MUse for this study. The first two paga",Sugi-79-22 Dumas Miller Underwood Stramm Riggs.txt
"PROCEDURES FOR ANALYSIS OF SURVIVAL DATA Terry M. Ther-neau, Mayo Clinic I. Introduction The logrank test is based on a sum of con- ditional 2*k tables (status (living or dead) va Survival analysis iB important in many groups (k», where one table ia formed at each medical applications, particularly in the area distinct death ti~ and includes the egmple at in which I have been working ~ chemotherapy risk for d~ath at that point~ From thes'e an trials in cancer - where time to death 'or time observed number of deaths 0i and an expected number of deaths Ei under Ha can be computed; to recurrence of disease are main indicators of reg~men. 1< the success of a drug In this paper I will present two SAS procedures which are and the formula 1: (Oi-Ei)2/Bi is used to obtain developed to meet this need: COXREGR, used in i=l a ch~-8quare statistic. The computing formula testing as·sociat1on with other independellt variables; and SURVTEST, for test~ng the equality used is equivalent to a Mantel-Haenazel proced- of distribution amongst k groups. They embody ure~ and is actually somewhat conaervative four different analysis techniques, three of compared to' the exact logrank statistic; the which are well known in the statistical I1ter~ conservatism is less than one percent of the exact chi-square i however. ature: the Gehan-Wilcmro.n test:t logrank test, Cox's proportional hazard model~ and P. OlBr1en t s The logrank test is the locally most power- 1ogit-rank procedure. I will try to discuss ful ranking test against Lehman-type (propor- both the technical and some statistical consid- erationS of tional hazards) alternatives. (Two survival thes~ teBte~ curves are Lehman alternatives if their intenaity Firat I should clarify what is meant by (O~ hazard) functions are proportional ~ 'l(t) ~ G~2(t)~ where the intensity is the like- survival data. Each of these procedures deals 1 hood of aying shortly after t given you are with data for which some of the observations may be right-cens",Sugi-79-23 Therneau.txt
"A MULTIVARIATE APPROACH IO THE ANALYSIS OF A RE~EATED MEASURES I\l(PERIMENT USING SAS David W. Johnson and Rocco L. ~runell~ Eli Lilly and Company Experiments with repeated measures oVer time Sanders [1] and applied to an animal science ex- are cammon in agricultural experiments, educa- periment, but they have been modified and expand- tional testing, and olinical tria1s. The usual ed to apply co the clinical situation. design involves the comparison of two O~ more treatments with, a aeries of measurements taken For pu~poses of illustration of the tech- niques in~ol~ed, data from a. parallel design over time on each experimental unit. The object , clinical trial we~e used. This particular study of this type of experiment is to compare the ef- fects of the treat~nts over time. involv~d the compa~ison of a new drug for the f treat~nt of rheumatoid arthritis with a marketed ~, drug. Patients entering the study were randomly. In clinical tria19~ comparisons between two treatments a~e often made using a parallel re- assigned to one of the two drugs, wh1ch for the peated measures design. Here. patients are ran- remainder of the paper will simply be referred to domUY assigned to one of two groups and each as Drug A and Drug B. group receives one· of the two treatments for a given period of time ·. In ita simplest fQrm no Prior to actually taking the study drug, other fa~tors are involved in a parallel design. patients were stabilized on their present therapy and then taken off the medication and given a The analySis of a parallel design repeated placebo to obtain a haseline measurement in the measures exper:iment can tak.e many forms.. A absence of active treatment. The baseline mea- sp11t-plot analysis is sometimee ueed with time surement occurred at the fourth clinic visit in this study. Observations were then taken On ~~ch as the subplot. Alternatively. a one-way ana- patient periodically over the cours~ of a six lysis of variance can be performed at each time point. M",Sugi-79-24 Johnson Brunelle.txt
"SAS USED FOR DATA MANAGEMENT AND MATHEMATICAL ANALYSIS OF A FLOW MICROFLOUROMETRY HISTOGRAMS Warren Curry, William Ingram, and Dennis Lezotte, Univeristy of Florida Figure 1 WHAT IS FLOW MICROFLOUROMETRX? DIAGRAM OF CELL CYCLE r ~ Presently the diagnoses of lymphomas S GL and leukemias demand a tedious and quali- ~~ . tative evaluation pxocess. Patients sub- jected to this protocol endure periods of uncertainty with respect to their condi- ~::J tion. A procedure utilizing Flow Microflourometry (FMF), which provides a rapid quantitative ·method for ,diagno,sing The relationship between cell age vs. and observing many cell disoraers, is DNA content appears as is shown in available at th'e University of Florida"" Figure 2. College of Medicine. FMF allows a quiGk Figure 2 quantative assessment of physical and DNA vs. CELL AGE biochemical cell,ular properties. DNA content and cell size are the primary elements of FMF quantification. FMF systems permit large numbers of DNA cells in suspension to be analyzed on~ at content a time a9 they flow singly across a laser beam. Each cell produces scattered light or flourescence depending on the stain used in production of the suspended Age cells. Measurements of each of these Age 0 - age after division parameters are obtained, and ele_c-tron- Age 1 - age j~st before p~lse ically recorded by the height analyzer which ultimately g,enet""ates fre- division quency data output. Light scatter deter- mination is the method of securing infor- mation on certain physical character- Figure 3 CELL FREQUENCX vs. CELL AGE istics of the cells. Flourochromes can provide information about cell size, DNA content and synthesis, or surface antigens. Simultaneous measurement of # of cellS any two parameter5 is possible, and is referred to as dual parameter analyses. HISTOGRAMS I-----~---y--. Background information pertaining to Age 1. the formation of the frequency distribu- tions might aid in understanding our course of analysis. Recall that cells in",Sugi-79-25 Curry Ingram Lezotte.txt
"A SEER COMPATIBLE TUMOR REGISTRY UNDER SAS M. Clinton Miller. III, Edmund Murphy, and Paul Underwood Medical University of South Carolina accession number is a chronological number which INTRODUCTION provides an immediate and constant inventory of cancer cases seen for the first time each year. A col1aborativ~ Tumor ~glatry for Cancer was developed for assessing as currently as possible, Next. a master card index is initiated. The the magnitude of the cancer problem in the Charles- master card index contains the patient's nama. ton region. A second purpose of the system is ,to sex, race, site of primary lesion. date of dia- identify factors related to cancer risk and patient gnosis, accession number, medical record number, survival. By combining special features of SEER and SAS, our new system has proven to be extremely birth date, age at diagnosis and/or date of death if appropriate. The medical record and master instrumental in the Buccessful management of the card are then placed in a tickler (suspense) MUSe Tumor Registry. These systems were selected file. This contains medical records of cases for several reasons, not the least of which were which have been identifi~d but not yet abst~acted. cost and reliability. The chart is removed from this file at the end or four months. The medical record is then abstract- SEER (a cancer ~urvi11ance, ~idemlo1ogy and ed and placed on the_ General Tumor Registry (GTR) !nd ~sults Reporting Program), was developed by summary form. The coding card is then sent to the National Cancer Institution. It provides data entry. The. data are ente.red into the comput- compreheos1ve and detailed 1nformation for coding er for an automated edit. If discrepancies are extent of disease and diagnosis. This system was ascertained the original record is Teferred back modified to include information concerning treat- to the Medical Records Office. ment. While retaining electron1c compatibility with existing SEER systems~ other modifications wre",Sugi-79-26 Miller Murphy Underwood.txt
"ronmental Sciences Division Oak Ridge National Laboratory Oak Ridge, Tennessee 37830 ABSTRACT Variables unique to a specific research paper were not included in the data base due to space requirements. Data were extracted from over 1000 toxicity references for inclusion into a data base with Details of the bioassay or field situation used in the paper were extracted when retrieval capabilities. Samples of the data available, as water chemistry and test base. constituents are presented. A sample conditions would be necessary for program for searching the file is shown. The reduction of a high volume of pages in the interpretation and application of the data. However, the details were freq""ently not report to a microfiche medium is discussed. Reproducing the entire data base with comments, inCluded in summary documents. Table 3 shows descriptions, and references on a microfiche the percent frequency of occurrence over all for portability and accessibility is presented. observations for which a value for each of the A sequential filing scheme is used for extending variables described in Table 2 was reported. These percentages are listed by element and the capability to other data bases. range from 0 to 100% depending on the element and the variable. Where additional INTRODucrrON descriptions of the research are deSired, the user is referred to the original references. A typical application of the data base for At least 30 trace elements have been determining the effects of certa",Sugi-79-27 Strand Cushman Hildebrand Anderson.txt
"This paper reviews the Impact of SAS at universities and colleges In the areas of research, teach- fng and admt""lstration~ A brief revIew of the association of University Statisticians of Southern Experiment Stations with SAS Is given. Results of a survey of educational installations of SAS are given. At present most of the uses of SAS appear In research and teaching. Increasingly; educatIonal InstitutIons are applying SAS to adm1nistratlve problems, including data bases for student records and record and file maintenance for comp . . te ... centers. An examp1e of a student records system-l,Jtlllzll""lg SAS at LSU I. given.",Sugi-79-28 Koonce Icaza.txt
"Fertilizer recommendations depend on soil and A soil test reporting system has been developed crop codes and on phosphorus and potassium for use by the Extension Service of Clemson levels. For each possible combination of these four University. The program inputs soil test lab variables, there is an entry in a stored table of results, determines appropriate fertilizer and recommendations. For certain crops, this entry limestone recommendations gives instructional I includes the recommended amount of nitrogen. comments, and prints all of the above in a report phosphorus, and potassium. For other crops, this to each farmer. entry consists of a comment number which indexes a verbal fertilizer recommendation.",Sugi-79-29 Hill Currin.txt
"(COURSE=1l3 OR COURSE-1l7 OR ro~ters COURSE=1l8 OR COURSE=217) THEN OUTPUT; From to the grading of examinations GO TO LOOP; to assigning courae grad~s, SAS has been an in- valuable tool in the management of our large- KEEP IDNO NAME COURSE SECTION; PRoe SORT; BY COIlRSE NAME IDNO; enrollment cOurses. It enables us to post exam- ination results the very n~xt day, complete with DATA NULL; SET; FILE PUNCH; NAME PUT $-41-65 IDNO 66-74 COURSE 75-77 tables, histograms) and rank-in-class. At the end of the course, we simply m~~ge the individual SECTION 78-79; scores_and compute letter grades by the appropri- At the sa~ tilne, we also print a r09ter for ate algorithm. Human effort is reduced, accuracy students tD check, to makB sure we have every~ is improved) and the students obtain better feed- ~: :-' one's name.: back on their progres6 throughout the course. PROC PRINT P; ID _ ; VAllIABUlS ~. BY COURSE SECTION;",Sugi-79-30 Spitznagel.txt
"ON-LINE SYSTEM REPORT GENERATOR Susan E. Bengtson, Clemson University Byron C. Lewis, Clemson University Richard Nelson, Clemson University participants are asked to give their department The on-line system report generator described in name or affiliation when enrolling for a course, this paper was developed with two purposes in the instructor has a good idea of the make-up of mind. First, as a pedagogical tool, and second, as the class before going in to teach. This is useful a much needed management tool for the Academic in a course such as the Itlntroduction to SAS"" Computing Support group at Clemson University. because examples appropriate to the disciplines of In addition to teaching regularly scheduled short the participants can be used. courses, staff members of Academic Computing Support are often invited to give presentations to Recording the participants' departments also provides feedback on the effectiveness of our various classe.s an topics ranging from statistical publicity. If, for example, there are few analysis to fundamentals of data processing. As a participants from a certain department or college, language, SAS is useful for many of these we try to find out why and remedy the situation. applications. The data manipulation functions of SAS make it possible, for example, to teach the For this system to be an effective management concepts of file updating and and to have students reports were deemed write programs to perform such tasks without the tool, the following necessity of teaching them COBOL or PL/I. This necessary: has been found to be particularly useful in manageme.nt curricula where it is desirable to give I) A daily printout of class lists for all the potential manager an idea of the procedures courses and sections. The class lists should include the department, address, and difficulties involved in data processing telephone number, and status of each without an extensive formal educatipn in the subject. - participant. 2) Upon demand",Sugi-79-31 Bengtson Lewis Nelson.txt
"PROJECT CONTROL SYSTEM Susan E. Bengtson, Clemson university Byron C. Lewis, Clemson University Richard Nelson, Clemson University The project control system described in this paper day on every project assigned, but would record was developed for use in the Clemson University work actually done thereby generating more Computer Center to meet the needs of the various accurate data. departments within the center for up-to-date information concerning the status of both on-going At the end of each day the employee fills in the and finite projects. A system was needed to names of the projects on which he worked and maintain records on the. amount of employee time, estimates (to the nearest tenth of an hour) the and its related cost, that was spent On the various time expended on each project. A set of projects undertaken. The system needed to ""dictionaries"" is supplied to each employee which include a relatively easy method of data entry and contains a list of codes and descriptions of verification, and reasonable flexibility in report projects and qualifiers to be used in filling out the format and content. To meet this need an data sheet. (See Figure 2.) A project name interactive system was developed for entering the consists of ten cllaracters broken down as follows: data. The analysis and report writing was done (1) a four character project code specifying a with SAS. general project, (2) a three character sub-project code qualifying the project, and (3) a three Since each department was interested in the data character task code describing the work done. As from different viewpoints, it was decided to collect an example DOCTUGDPRF would indicate that the data directly from each employee rather than work was done on documentation (project) of the from a supervisory level. To do this, a data sheet type ""users guide"" (sub-project qualifier) and the was developed that would be easy to Use for task performed was proofreading. The dictionary obtaining the type of data",Sugi-79-32 Bengtson Lewis Nelson.txt
"TIlE ROLE OF PACKAGE IRCGllAMS IN STATISTlCAL METHODS COURSES Thomas A. BUbolz and James E. Gentle State University I~ and if these topics are to be explored adequate- I. INTRODUCTION ly) the instructor must frequently resort to A substantial proportion of the effort of use of ~pecialized software systems or to use most academic de:partments of' statisticB is ex- of Bubprogram packages in an algorithmic ~ended on the teaching of what are called language such as FORTRAN~ Either alternatiYe .. statistical methods courses': These courses ~y requires more class time for instruction in use be taught at variolls levels within the univer- of' the system, Or B_Ise it imposes stif'f'er sity, but most deserving of the title c~ges prerequisites On the course. are taugh:. at the advanced mdergraduate :'-evel Additionally, the rigidity of many statisti- or at the graduate level. This is because cal ~rograms precludes demonstration of the understanding of' the eontent of such courses computations for the statistical analyses generally requires previous expOsure to investi- studied. Wben everything in the computations gative thinking and the maturity to appreciate is so automatic, memory of the fact that the role of statistical methodology in the B"""" (X'x)-l:<' y for example, is not adequately scientific method. reinforced. ~ny of' the instructors of begin- The oechniques taught in statistical ~!~o:7ai~::i~~lr::~~:Ss~~~~:' i~!~a~;dto methods courses should be those procedures go actually used by data analysts} and probl~ through the mechanics of the :formation of assignmen~s should simulate practical research X'X, x:y, and th: .sums of squares for analySis The impact of the computer on situQtions~ of' VarlallCe of l~near models. This accounts statistical methods courses has been substantial. for the popularity of the matrix-based. languages This is due to the profound impact of the of some of the statistical packages. computer on the statistical methods actua:ly Because of the ro",Sugi-79-33 Bubolz Gentle.txt
"IN COORSE FOR BEGINN.IIlG COI!PUTER USERS S~S ~ Philip N. G.allagher, Jr., University of North Carolina Introd u~ tion Most data-handlin-g exp-erienced scientists have their own horro~ stories of the terrible frust~a tions of thE scientist who opted for the second Several years of SA5 experience in choice, and then had to wait, totally our university setting have encouraged me wi~h helpless, his deadline racing tova~ds him like a juggernaut, whilst his to markedly restrncture my philosphy of what can and should be taught in a single over~orked prcgrammer(s) kept prowising a one semester terminal course aimed ""c~Eaned up data file"" or the stlecif~c customized output derranded by a committee primarily at non-computer science graduate students. Fot the purposes of chairroan. our cOUrSe we consiaer hstudent n to be synonymous with ""presumptive principal ~he preceding arguaent has presented only the scientist's view and has ignored .investigator"". Among my colleagues SAS (which ve frequentl y describe as ""t he the _frustrations of the p:tog""l'al'l1:roer who first of the ~hird generation programming must attempt to deal vith data collected lanquages"") is pe~ceived as having beg~n by a sc ientist who bas no sense of th-e a major change in the l~vel at which a mechanisms necess~rr to get data from non-computer buff can expect to make use original documents iDto machine readable of the facilities offered by a large form, to provide for editing and updatin9 of the data, and file-linkaqe, to say computing center~ Before SAS the average dis~ipline nothing of vreparing an analysis file graduate student in a not directly related to comput~r ~cience did with the proper structure for the not expect to and was not capable of contemplated analysis. d oinq lIuch more than performit'g pack aged progra~ ""In the remainder of this paper I -will analyses sucb as SPss or S""D provide upon either small card deck outline the topics which we teach and data sets or larger tape/disk filES fondly",Sugi-79-34 Gallagher.txt
"PROC MEANS NOPRINT; VAR FEMALE ···· In performing several full-scale simulation analyses, the State of Utah haa chosen tG use SAS OUTPUT OUT=TOP 3 MEiIN= PROPFMLE ··· ; rather than traditional simulation languages. The parameters computed in the fLrst macro The authQrs present a basic; structur,e. a brief can then be entered as the first observations in diecussion of the comparative advantages of a new data set in preparation for the second simulation using SAS, and simplified examples macro, i.e. EVEN~. from a faculty tenure Bimulation~ Example 3:",Sugi-79-35 Brewton Anderton.txt
"A RECODE PROCEDURE FOR SAS Douglas D+ Cockrell lone Cockrell H~ University of South Carolina Computer Services = NUMLEN integer value (abbreviated The researcher frequently needs to replace NL=) sets the default length of the values of some or all variables by new numeric values. 1his sp~Lification is values. Currently, the only way this operation llsed only when making character to can be performed within the Statistical numeric conversions. Analysis System is through use 01 multiple IF-TR£N statements. This approach is often CHARLEN = integer_value (abbreviated lengthy and inefficient as well as being C1=) sets the default length of inadequate for some types Df value changes. character variables. this specifica- RECODE has been designed and is being developed tion is used by SAS only when numeric as a comprehensive and e£ficient solution to the to character conversions are made. problem of value substitution, The RECODE procedure features a simple~ FUZZ= nurneri~ value (abbreviated SAS-like syntax and incorporates typical SAS F~) sets a range around certain values parameters and options such as the OUTPUT in the input data set su that points state'ment and a FUZZ parameter. Additionally; ""close"" to these values may be mapped RECODE is able to handle a wide variety of along vith them to their respective recoding situations, such as mapping a range destinat.ions. of values into a single value, converting numeric values to character values and The following examples are legitimate character values to numeric values, searching statements to initiate a RECODE procedure. for high and low values of a variabl~, and performing limited character string manipula- PROC RECODE; tion. The usual SAS lists are supported, as PROC RECODE DATA=IN.TOTALS2; well as tne special variable names ALL, PROC RECODE F=.5 OUT=EDlTED; ALLALPHA · and ALLNUM. An EXCEPT list is also available for use with variable lists to The RECODE statements give specific save coding time. information concerni",Sugi-79-36 Cockrell Cockrell.txt
"A CLASS OF INVERTIBLE FUNCTIONS FOR ANALYSIS OF CATEGORICAL RESPONSE USING LINEAE MODELS James E. Dmln and Gloria Cappy Department of Mathematics & Statistics University of Arkansas Fayetteville, AR 72701 com tent variables so that variation in x some- AlISTRACT how reaul ts in variation in the expected-r~le. tive abundancies in the categories of response. Assuming an intrinsically linear lOOdel of The statistical problem is to obtain a more pre- the form!(~) =~, the analysis of categorical cise understanding of this relationship through response using linear models is readily avail- specificat-;J.on of ~ a.ppropriate modt:i!1. able through use of the SAS procedure FUNCAT. In particular, it will be well if for any vector ~ This paper will be limited to c.onsider- of exogeneoos ""ar1.ah1es I we .are able to invert ation of the following special case of those in- f(·) in order to predict the expected relative ~omposition.!.O of the underlying multinomial pop-- trinsically linear models whose general form was described by Grizz.le. Starmer, and Koch (196!,J) ulation. A general class of invertible response and later extended by Amemiya (1976). Define functions is obtained and tested against two faur 8, 1 x·~ vectors ~ m (TIil.ni2'""'4'~ir)' Let fliar data sets and one relating the composition of freshwater algae samples to water chemistry. {f <1I.,): m· 1, 2:111.u < r-l} be a set of twice m-, - The effect of category order on goodness-of-fit differentiable response functions which aTe gs- is examined. sumed to be identical tor each of the S popula- tions , and collect these into $, 1 x u vectors r C14.), ... 1<1Lt) I = f1 ,fuC.!4.) 1. We then postulate ImroDuCTIoN that there exist. i(') such that i(.:':;.) - Xi~' The following sf tuation ""is familiar in for i = 1, 2. ~ ··· 5, where Xi is a u x v design bioassay and, we think, is recognizable in other ruatrix of rapk v < u conaisting of kn~ func- c.ontexts I notably statistical ecology and· survey t.ions of the elements o",Sugi-79-37 Dunn Cappy.txt
"SAS IN THE ANALYSIS OF CATEGORICAL DATA SbAwki A. Salem. Smith Kline & French· Laboratories rnent:loned above. This ia done simply by multi- Categorical data are often analysed by Xa weighted linear regression in the manne~ pro- plying each row of P - by the reciprocal of p~sed by Gr1zz1~, Starmer and Koch~* the corresponding standard deviation of Pij in A spec- ialised program (GENCAT) has been written for that row. Therefore each element in A is the es~ this type of analysis and is widely used variance for a Pij' 'rhe. following two examples in the pharmaceutical indu8try. The will show the use o£ GLM PROC and the WEIGHT pe~1al1y GENCAl program requires a reasonable amount of statement in SAS to generate results identical control statements' and a constant consultation to those generated by GENCAT but in a simpler with the us@r's manual. The purpose of this fashion. paper is to show that for one of the most fre- quently occurring cases, the an81ysis can Examples readily be obtained using SAS. 1. In this exa~le two drugs w@ra administered In clinical trials the GSK analysis of in each of four medical centers. The data categorical data receives its fre~uent use, are as follo-ws: perhaps,in its application to multicenter Not trials. In these trials several treatments Center ~ ~ Q!:!!& 1'.2E!l are being tested at Q3ch of a number of differ- ent centers. More specifically. let us suppose A 12 13 25 1 that each of r medical centers is testing a 19 1 6 25 B treatments where nij patients are treated at A 16 25 9 2 the 1th center with ~he jth treatment. If Bij 22 25 3 B 2 of the nii patients are SUCCQssfully treated 20 7 13 A 3 (cured) tne variable of intereat is ,the propor- Pil 16 20 4 3 Il tion (rij / nij). The GENCAT approach in A 10 7 4 3 the ana ysis of thesQ proportions is simply as 10 4 B 4 6 follows: The SAS statements needed to analyse data ~hese 1. Feed the data to the program in the form of are: contingency table of order rs x 2. The two DATA; columns in the t",Sugi-79-38 Salem.txt
"CODING SUBJECTS FOR ANALYZING UNBALANCED REPEATED MEASURES DESIGNS USING SAS Jerome R. Busemeyer & James E. Laughlin, University of South Carolina sufficient statistical power. For example, if The purpose of this paper is to discuss some the experiment employed 50 subje~t8 then the re- methods which increase the computationaleff1ciency duction in the number of elements in the sums of of analyzing repeated meagUr~6 deBigns - i.e. designs in which the. same subje.ct is observed under squares and crossproducts matrix will equal 2304: each of the different levels of an experimental One may ask at this point why there i8 no manipulation. More 8peclf1cal1y~ Bubjects are concern about the number of parameters needed to crossed with one or more of the independent vari- estimate th~ subje~t x training interaction. Es- timating this effect 1s never any ·problem because ables. For example trials is a repeated meas- ures factor since each subject is measured at it can simply be obtained from the residual sum each trial of training. of squares of a model which includes only the main In repeated measures deslgns~ the effect of effects of subjects and training. subjects is included in the analysis of variance Obviously, one could also recode the para- model. The focus of this paper will be on dis- meter T. in the same way as Si and further in- J . cussing different methods for coding subjects. crease the computational efficiency. However, There are two different approaches to coding sub- since the number of levels of T. is typically jects that will be considered. These two methods J ;1 can easily be illustra~ed by considering the sim- small (for example, a pre-post design has only 2 plest case - single factor repeated measures de- levels), the gain in efficiency may not be worth sign. The traditional method for coding this de- the effort of recoding. . sign can be represented by equation 1 shown below. The coding method represented by equation 1 will be referred to as the 'Istand",Sugi-79-39 Busemeyer Laughlin.txt
"SAS MACROS FOR ANALYZING GROWTH CURVES Carlos A. Gonzalez, EMBRAPA with as many colums as time points, INTRODUCTION at i.e., WiWIQ1q, and the (m,h) element In some fields of application, it Wi is the value of a polynomial of de~ is a common practice to measure the same ; ~ is a matrix characteristic on each individual over a gree m-l evaluated at t h period of time, thus generating data r of unknown parametersr and N=Lj=lNjO usually discussed under the title of Note that our WI matrix plays the role growth curves. Kowalski and Guire (1974) presented an excellent review of the of both Band Bl matrices of Grizzle and statistical techniques available for the Allen (l96g). analysis of ~uch data. Here we present two SAS macros that implement the method Model (1) assumes that a q-l poly- developed by Grizzle and Allen (1969), nomial is an adequate description of the which is one of the techniques discussed growth curve, and according to it, every by Kowalski and Guire (1974) under the individual in the jth group has the same heading of polynomial growth curve mod- , i. eO. , expected response at time t els .. k In the next section we introduce some formulae just to facilitate the description of the,rnacros, but no at- tempt is made to nescribe in any detail the theory underlying Grizzle and Allen's method. The user is strongly ad- where ""jO'~jl' ···'~j,q-l are the ele- vised to consult their paper J as a thor- ments of the jth row of ~, and the ele- ough understanding of their method is crucial to the efficient use of our ments WkO,W kl ' ·.· ,wk,q-l of the kth Wi, macros. columns of are the values of the polynomials of degrees O,l, .·. rq-1 eval- NOTATION AND FORMULAE uated at t · k Let W be the px(p-q) matrix whose 2 We shall consider only two of the colums are formed by the orthonormal six different types of longitudinal da- polynomial coefficients of order q,q+l, ta sets discussed by Kowalski and Guire 2 ~ .· ,p-l, such that W W =I _ ' and (1974), namely, the univari",Sugi-79-40 Gonzalez.txt
"The Statistical Analysis System (SAS) computer routine entitled General Linear Model (GLM) includes in its output four types of estimable functions that have certain arbitrariness (repre- sented by the letter L) in their coeff'iclents. This paper' shows how such arbitrary estimable functions are derived from the known, general expressions ror hypotheses tested by traditional- style in analysis of variance calculations that are often made ror unbalanced data F~statisticQ ~, (i.e., data having unequal numbers of observations in their subclasses).",Sugi-79-41 Searle.txt
"NEW FEATURES IN GLM AND VARCOMP J. H. Goodnight, SAS Institute (where 80 represents the intercept). To estimate Introduction l. 381 + 26 2 , the following L vector is needed: The GLM procedu~e and the VARCOMP procedure L=[O 3 2 0] have several new features that will be available in the 1979 version of SAS. GLM has been expanded The corresponting ESTIMATE statement would be: to include three new statements: ESTIMATE '3BI + 2B2' Xl 3 X2 2; ESTIMATE o o CONTRAST To estimate 130+ 61 - 263 the following L vector a RANDOM is needed: VARCOMP bas two new methods of estimating vari- 1.=[1 1 0 -2] ance components. One of the new methods, MIVQUEO, is now the default method and is extreme- The corresponding ESTIMATE statement would be: ly efficient with respect to core and CPU time. ESTIMATE 'BO+Bl-2B3' 2. GLM ESTIMATE Statement INTERCEPT 1 Xl I X3 -2; The ESTIMATE s'tatement is used to specify For models involving class variables such as an L vector for estimating the linear function of parameters LB. All of the elements of the L vec- MODEL Y AB A*~; = tor may be given; alternately, only certain por- with the parameters: as~ociated tions of the L vector may be given, in which case the remaining elements will be c.onstructed by GLM ["" ""1 ""2 ""3 Sl S2 aBl1 «B12 aB21 rrS22 oS31 from context~ aS32] The L vector is checked for Estimability in To estimate the least squares mean for aI' the either event. The estimate Lb, where b=(X'X)-X'Y, following L vector is needed: is printed along with its associated standard error, the square root of L(X'X)~~a2 and t-test I I L=[l 100 .5 .5 .5 .S 0 0 0 0] on the analysis of variance printout page. There is no limit to th~ number, of ESTIMATE statements, and the following ESTIMATE statement could be used. but they must come after the MODEL statement. ESTIMATE 'LSM(Al), INTERCEPT 1 The ESTIMATE statement is specified as: f AlB .5 .S A*B .5 .5; i ESTIMATE name l "" t Note in the above statement that only one element effect list of constants of L wa",Sugi-79-42 Goodnight.txt
"USING U-MODEL TECHNIQOES TO TEST HYPOTHESES IN T!fE LINEARM.OilEL E. A... Ica-z a and k. L. Koonce Stat~ Louisiana university In PROC Language, the model ~AT8~X INT[;:OIJUCTION is Tbe least-syuares FrocEdures ~ncorforated in Walter Harvey's 1960 Y=W*S+E pcogca. (PROC HARVEY) have been popular where for almost t~o dec~des among statisticians workin~ in the ani~al '{ is th~_ n x 1 vEctor of The ~[incipal reason fot their sciences. popularit.y is -Ii well de.fined relationshit? obseI""vations between the theory And its prdctical W is. the design matri.x which Dlaps thQ observations onto the application. U~e[s of this method paL4meters to be estimated, and understand wbat hap~ens to their measurements fr04 the translation of the B are the parameters model to a set of"" simultaneous linear usually the design matri~# W# bas to eyuations, to the p~rtitioning of the be because of rank deficiencies ··reduced'~ variation into the analysis of variance in the parameter space. the procedure is tanl--. to reduce the design matrix so as to eliminate t-he dependencies and still be the usual Unfortu~ately, able to estimate parameters wh _ ich are restrictions l.!Hposeo. 011 the design ma.trix easy to interpret. Tbus, the actual wake it difficu~t t~ handle ~inear contrasts .moD~ the estimates of the model used becomes parameter-s. The br-cak-down of sums of * s~~dre5 into specitic hypotheses which to = Iote Br + E y Illost researchers is of utmost impot'tance, and its soJ.lltion has had its u.ifficulties under the hormal. ledst-~qud~es ~et-u~, either because of * (wr' the rest~iction5 i~~osed on the design Bh = INY (H' .. lIr) · Yl watcix (HAEVEY,REGhj or becduse of the l'newne~SII of the techni]ue (GLM). th~ Sh (epresents a solution to system of linear equatioas, but because The oujective of this study vas to of the restrictions (mainly :El~;' -01' that ~t is possible to demonst~ate ~> TJ =0, It.. (~Y).j = c ..""J ~j (1:1 T)'j =0) ann estimate£ a subset of the parameters. simplify the",Sugi-79-43 Icaza Koonce.txt
"EXPLORING BIASED REGRESSION WIrE SAS Samuel G. CarmeT and Wen T. HSieh, University of Illinois are computed by MACRO CORR£IG. At the user's Statisticians I 1ntere'st in biased multiple option, the correlation, inverse, and eigenvector regression techniques has increased considerably matrices are printed out by MACRO PRNMAT along in recent years. Biased teehn~que6 provide a with a matrix in which the ij-th element denotes theore.tically attT""active alternative t.o least the proportion of the variat~oo io the i-th squares for _multiple regression problems involv- vr.1ginal independent variable accounte.d for by ing h1g~y correlated independent var~ables. This the j-th principal cDmponent. The ordinary least attractiveness, relative to least squares; is due squares regression analysis is requested with to the posaibility of greatly reducing the vari- MACRO OL5. For each b1ased regression analysis ance of estima.tes with only a small loss in the user supplies a short MACRO consisting of the accuracy. following: Interest in this topic 1s reflected in the MAGRO USERSPEC recent statistical literature whlch~ since 1975~ = pc: = RG; SHRINK = SF; RIDGE PRINCOMP includes papers by Hoerl at al. (l975), Hocking % BIASlILR et a1. (1976), Lawless and Wang (1976), Vinod (1976)., Dempster et al. (1977), Gunst and Mason where PC, SF, and RC are given speeific numeric (1977), Fomby et a1. (1978), and Carmer and Hsieh code values depending on the user's choice of (1978). At least three general types of estima- biased estimator. Four biased analyses, using tors -for biased regression are discussed in these different est~mators1 are requested in the papers; these types are: 1) principal component example in Table 1. estimators which can do an excellent job of reducing variance, but often at the expense of For reasons of convenience and simplicity introducing c_onsiderable bias; 2) shrunken esti- of calculations, most of the computations are mators which appear best suited to problems pe",Sugi-79-44 Carmer Hsieh.txt
"niversity of North Carolina Chapel Hill, N.C. B IDlnlmlzeB ABSTRACT the residual Bum of (i) squares, i.e. RSS - (y - xB)'(Y - XB) l'r[(Y ~ rilt(y - xB)] ia minimum; le~at Bquar~~ p~Qvide Ordinary (OLS) fails to Bi . satisfactory 'estimates for General Linear ~del BLUE and MVUE of B. (ii) parameters when the prediction vectors are not orthogonal. i.e., when the data are ill-condi- When the response and predictor variables are tioned. Th~ technique of ridge regreSSion pro- standardized, the mode1 (1) reduces to vides better minimum variance estimates in such + situations. This paper reviews the general theory (3) y* = X*B* 0'::., of ridge regression analysis for the multivariate general linear model and presents a SAS macro waere Y* and X* are standardized Y and X vari- able ·. f Then the correlation based OLS estimator which enables the user to ubtain both 015 and ridge estimates 'fo""r purp()ses of comparing the two of B* is g~ven by techniques and visualizing the effects of non~ orothogonality. (4 ) where OORX : (X*tX*)/n is the correlation matrix INTRODUCTlON of the predictor variables and CORXY = (X*'Y*){n The ordinary least squares (OLS) estimation is the correlation matrix of the predictor vari- procedure fails to provide satisfactory estimates ables with the response variables. of the parameters of the mult~ple regression ~d el when the data are ~ll-conditioned due to It is useful to examine the correlation ma- multicollinearity-of the regressors. MUlticol- trix CORX whe",Sugi-79-45 Sinha Hardy.txt
"USING GLHft5 rOB GENERAL LINEAR K~DBLS ANALYSIS -- A TOTORIlL I. A BRIEf OVERVIEW OF THE SISTEK of North Carolina Ronald W Helas and I_ogene McCanless, University .. 1. Intr-odllction Christiansen and Helms (19791 GLMMS is the the fifth version of a ""Analyzing: Laege Datasets Osing PROC se~ics of m~cros wbich ~~n under PROC GLM""5·~ HGskiDg and Hel.s SSCl' and MATRIX and which peLfoL~ a wide variety (1979) af univariate and multivariate lineae model analys2s. GL""6 has been under GL~!5 ""The ALgorithms"", HelDs, development for more ~han four years. Christiansen, and !lask,ing (1'1791 during ~hich time the various .e~sions ""using' a have b~en used by a vid~ variety of GLJlII5 as rool J:or of the Str~cture sophisticated statisticians in a variety Simulta.eoas Study of settings, including the National at the Covariance Matrix aDa l!Iu.lle~. Institutes of Health, Food and Drug Exp-ec-imental DeSign. Effects"". ~dministration. EPA. aSDA. pharmaceutical Hosking, and Hel':s {19191 companies, professors at a number af ~ni~ergities. ""GLKJI A.alysis af G~'01/tb. and Dose- and students in a variety Response C~ryes·. Stewart; HcCaaless. of linear JDode ls courses, including those As taught by one of the authors (B~H). and Helms (1919) far as know, of these ""friends of ~e nODe has been reluctant t.o qive us In addition. [k!lJlS, ~ser'~_~! (J;LI'II'III be available by tb.e tile tllis ~a~e~ feedhack ahout the GL~I'J. macros. we nave ~ill received a steady flov of questions# is published. comments, SU9~estions for improvements OL aiditions, and occasionally, a bit of pl:aise .. 2. What .ill GLKft5 Do? version 5 of GLftff is a substantially improved version of the previous me~bers GLftJl5 perforls general linear This is ~he first version univariate of the fami1t. and lIult.iv'a.ria1:e .odel computations, as described in aoCe detail wbich is not ""upward"" compatible. The Howeyer. siDce _anI pco~ra.s algorith~s have been changed and i.proved below. and now include mace than 3000 PROC peJ:",Sugi-79-46 Helms McCanless.txt
"USING GLMM5 FOR GENERAL LINEAR MODELS ANALYSrS--A TUTORIAL lI, TIlREE EXAMPLES I. McCanless and R.W. Helms) University of North Carolina The purpose of this paper is not to prQvide 1'11=E(Yllk1 for k=1,2,3,4 the reader with the analysis of three datasets J a 2·E (Y 21k) - Ull but rather to exemplify the power and flexibility of the GLMMS macro system, to provide the Teader ~2·E(Y12k)-)111 with a few examples of the output that is S3=E (Y 13k) -)111 produced when using the system, and to demon- (aB)22·E(Y22k)-~11-a2-B2 strate the ease with which GL~ may be used to provide statistical analysis of various linear (aB) 23""E [Y 23k) -)111- a 2 -S3 models problems. e is the sex main effects) 2 and S3 Note that a In this paper, three examples will be dis~ 2 cussed. The first is the analysis of an are the drug main effects, and (as) 22 and (aB)23 experiment that is a 2x3 factorial in the are the sex-drug interactions. It may be said, design with two dependent variables. The with these definitions t that \-1 1 is the vector· second example illustrates how GLMMS may be used 1 to analyze a multivariate regression problem of expected weight losses for male rats taking with four dependent variables, three concomitant Drug A. Other parameters are interpreted in a variables, and two sex groups, fitting sep~rate similar way. intercepts for the two sex groups. The third The first request given to GU.fM5"" in this example involves the analysis of a messy uni- example is that a model be fitted to these data variate data problem; the experiment is a 3x4 that includes the reference cell mean (REF_MEAN), factorial (unbalanced) design with four missing a sex main effect(SEX F M) I and drug main effects cells. ii)-;- (DRUG B A and DRUG C EXAMPLE 1: A 2x3x2 Factorial Experim~nt. The initia.lization step required by the The data for this example appear, "",loTI user is simply: !~ul tivariate Statistical Methods. Donald F, PROC MATRIX; Morrison~ Second Edition~ page 190. INITIAL LINMOD; Four ra",Sugi-79-47 McCanless Helms.txt
"PLOTTI NG GEIERAL LINEAR IIODEL PARAJlETEllS .lND CON FIDENCE BOURDS UTH GLnllS David H.. Christia.nsen and Ronald i. Helms, university of Horth Ca.rolina The confidence inter?al for Y is then: In certain applications of linear moaels the results can best be presented ! and interpreted graphically, rather than, 2-TS(Y) < <tHs(l) in termS of parameter estimates and where T is the student's t statistic ""ith mea Bures of precision. Th-is approach can n-p degrees. of fre~dom. be especially effecti ve, ""hen consulting ""ith clients ha ving limited statistical background or experience. Plots or The confidence region for the entire regress~on surface can ,be obtained using g ra phs of both primary and secondary the wor.king~ilatelling confidence bounds: parameters can a.lso be of -grEat value to the analyst in exploratory data analysis, A A ~ ~ ~ comparison of different models, anal.ysis .1-lIs(Y} <1 < HYs(11 of residuals, and plotting of different over where W is p times the P statistic with groups or treatments a range of p and n-p degr·ees affreedom (11. The use interest of one of the independent variables. of the farking-Rotelling bounds allows any number of mean responses to be g vectors. estimated from all possible This paper ""ill present a PBOC KATHI! macro for plotting expected mtian response for a given set of yalues of tbe independent variables. Tbe cQnf~dence PLOTTING RESPONSE COR'ES AND CONFIDENCE BANDS bounds for the mean resp,onse est.iItlat ES can also be plotted by specifying the In order to plot the expe""ted mean Examples of plotting· appropriate limits. both prima£J and seconda~J parameters response YS. a particular X v~riable, a vill be shoWII,. and inst.'I''Ilctiol1s for tbe matr; ix composed of k observational vectors is formed: use of the macro and a listing will be inc1uded. Dp 111 D2 · The vaS deSigned for Use witb rodcto tbe system but Can be used ~itb GL~ft-S any linear models program,. asswming the It ·· parameter estimates, error covariance and",Sugi-79-48 Christiansen Helms.txt
"ANALYZING LARGE DATA SETS USING PROC SSCP AND GLMM5 James D. Hosking and Ronald W. Helms University of North Caralina at Chapel Hill t Since the GLMMS macros operate within PROe servations are the (uncorrected) sum of squares MATRIX, they are subject to the limitations of and cross products matrix. The procedure has a FROC MATRIX aa well 8S benefiting from its capa- number of other options, which are detailed in the procedure user's guide. FROe SSCP is dis- bilities as a language for statistical program- ming. One such limitation is the requirement tributed by UB, as part of the GLMMS system. that the matrices on which it is to operate be Once ics load modules have been put in a library, small enough to be kept in core. In fact, the using it is quite simple. That library is given ~trix the ddname SASLIB in your JCL~ which ~he SAS su- practical upper limit on the size of a is 32.000 elements since many PROC MATRIX 0Fera- pervisor automBtically scans wh~n a requested tors and functions will not work with larger procedure is not in the main SAg library 4 matrices. Many practical linear models problems involve data sets larger than this. An example of the use of PROC SSCP is shown in Figure 2. The input data set, containing the independent and dependent variables is named Z. A second limitation of PROC MATRIX is the The output data set will be named SSCP1, and fact that the ar~thmatic operators and functions in SAS do not permit one to take advantage of stored in the file referenced by the ddname the symmetry of k'k in computing the sums of MYFILE. squares snd crOSB prOducts. If the ratio of the number of observations to- the number of vari- To use the data set with GLMM5, first FETCH the data set into memory. naming it SSC? and ables is large enough, computing only one trian- gle of Z'Z would reduce computational costs sub- using tne COLNAM! parameter in toe fetch state- ment to read the variable names into a matrix stantiall';'. named SSCPNM. The LtNK to GETSS create",Sugi-79-49 Hosking Helms.txt
"GLMM5 AS A TOOL FOR SIMULTANEOUS STUDY OF THE STRUCTURE OF THE COVARIANCE MATRIX AND EXPERIMENTAL DESIGN EFFECTS K.E. Muller, J.D. Hosking, and R.W. Helms University of North Carolina, Chapel Hill Conventional Residual Analysis of soldering iron and three techniGues -were studied in a factorial design, with roughly 100 When considering the general linear model, to 200 subjects in each of the six cells (soldering iron by technique combinations). the phrase !terror covariance matrix"" calls to mind a somewhat distasteful and unwieldy collec- Each subject was asked to assemble one of each of the 27 different circuit board types that IBM tion of mistakes. Even ""residual covariance matrix"" would seem to be something left over. Company produces in the course of their work. Be that as it may, this paper has been based on Roughly 70% of the subjects were females, and the assumption that in many cases, residuals 30% males. The Itty Bitty personnel people have a list of questions: 1) which soldering iron is from a linear model, and particularly the best? 2) which technique is best? 3) are the residual covariance matrix, may be of as much interest as, or more interest than, the model soldering irons easier to use with certain itself. Both the analysis of residuals and their techniques? Their statistician translates that into a multivariate analysis of variance, with covariances will be discussed, first in order to motivate the consideration Of the possibilities, 27 dependent variables and a cell mean.model. second to indicate the many convenient ways of Previous experience indicates that logarithms of doing so with GLMM5, and finally to sketch the the response times should be analyzed. The main capabilities of existing modules in GlMM5 effect and secondary parameters will be tested designed to analyze residuals. using GLMM5, natUrally. These are standard GLMM5 modeling issues addressed in the companion First consider the analysis of residuals papers .. ~. about a general linea",Sugi-79-50 Muller Hosking Helms.txt
"The general model incorporating both within-individual and across-inaividual Dose-Respon~e The Growth and analyses designs is expr~s~~d. in matrix notation proposea by Grizzle and Allen as follows .. Jun~ (Biometrics, Vol+25, No.2, 1969, pp. 357-381) have not been widely applied, in E(Y) = X'BETA'POLY part because appropriate software was not V(Y) = I @ SIGMA available. This paper shows how such analyses can be performed with GLMM5~ One of the GLMMS macros, GCMPROC, with Y(NxP), X(NxR), BETA(RxQ), POLY(Q,P) speci~lizes as a flexible growth-curve and SIGMA(PxP). The i.th row of Y, namel-y model procedure. GCMPROC 1 inks to other Y (1.,-*), is the· vector of P ordered ~s GLMM5 modules Subroutines to perform responses which observed. are The standard tasks and provide well documented printout with error messages correspond ing Cor times doses) of observation ar~ denoted when necessary .. TIMES= ( t t t · ·· t 123 P ~he expect~d value of Y(i,*) is expressed",Sugi-79-51 Stewart Helms.txt
"e, Tennessee 37830 computers for assistance in organlzlng and ABSTRACT collecting the facts and automating the lengthy and tedious tasks of sorting, merging and Environmental data are a resource of analyzing the collections of environmental considerable value for evaluating trends and data. This complex characterization and patterns in the environment in which we live. evaluation process requires a management scheme Since environmental data are such a valuable with systematic procedures which, when and irreplaceable resource, it is important implemented on a computer, remove most of the that these data be organized and accounted for manual accounting and bookkeeping procedures, in a systematic manner that retains the merging and collating activities, and filing representativeness of the sample and allows for requirements. The purposes of this paper are the proper application of the data to problem to: solving. This paper presents considerations involved in the management of environmental (1) paint out the variety of data in the data for analysis and evaluation. The purposes of this paper are to: environmental area and how the ~. variety of data puts emphasis on merging, sorting, and updating (1) point out the variety of data in the capabilities in a data management environmental area and how the variety of data puts emphaSis on system, merging, sorting, and updating (2) emphasize that a successful data capabilities in a data management management system requires a complete sy",Sugi-79-52 Strand.txt
"TIlE ""CRITICAL MASS"" CONCIl1'T John F. Duffy IeI Americas Inc. Introduction Today'a Environment The 'Critical Mass' concept 1s simply a Th~ first 3 phases of data processing are often cal1.p.d tht""_ day8 of f.eeods and spp,..,ds. different way of looking at traditioR81 data in this~ the 'Data Base Era'. It stresses the user's because the emphasis was on the machine's ability view of the data rather than a data processing to process batch jobs. The concept~ if properly understood and Today and in the future the emphasis will be view~ applied, can greatly simplify the task and improve toward on-line systems with heavy user involvement (see Figure 1). The cost of maintaining data the results of data management. The concept of ""Critical Mass"" can be processing support has swung from hardware to particularly important in the development and people (see Figure 2). Productivity is our goal. implementation of a research data management Management is constantly looking for oppo~tunities strategy. Research applications, data, data to substitute relatively inexpensive hardware to collection, maintenance and reporting differ reduce or eliminate manual effort. significantly froID traditional business applica- tions. This paper will describe the concept and Business va. Applications Resea~ch show how it might be applied in a research envir- onment. The typical business application can be 'Characterized as follows: Brief History o Repecative in nature (i.e. executed on a schedule - daily~ weekly~ monthly. etc.) The evolution of data processing might be o Relatively long payback period characterized as follows: o Consistent and i~entifiable data relationships and processing requirements. Phase I - Batch Byst~s with g heavy emphasis on accounting applications. Expensive Critical M8S8 - a definition hardware with little or no software support. The programmer was all MUch has been written abDut the subject~ but important. it is difficult to find a good general definition. For the pur",Sugi-79-53 Duffy.txt
"GRAPHICAL REPORT GENERATION US LNG PROC VIVIPLOT Michael p~ Farrell and ,A. bale Magoun Env1-ronmental Laboratory United StatsB Army Corps of Engineers E~eriment Waterways Station Vicksburg, Mississippi 39180 the efficiency of the routines not only in terms Al!STRACT of CPU, core, disk pack utilization, etc., but FROC VIVIPLOT is the first of a series of also in the amount of personnel time needed for SAS procedures that will produce copy ready production; the lack of generalized routines figures with some independence as to choice of that require little or no patches for ~ach pro~ ject application;, and finally, the lack of hard- The system has been developed by the plotter. McDonnell Douglas Automation Company (MCAUTQtm) ware and software compatibility among the major at the request of personnel at the U. S. Army graphic vendors with the subsequent need for Waterways Experiment Station. redundant application programs being necessary for each type of plotting device~ Th@ SAS procedu~e VIVIPLOT produces an In- termediate Plot File (IPF)_(MCAUTOtmj from IPF From a user's viewpoint, the key element missing from the current approach to graphiCS system routines that generate a data file which using SAS is the lack of a unified program and is post-processed to produce a file to drive support of graphical procedures by the SAS In- Calcomp (748, 663,. 960)·, Xynetlc.,g and Houston pen and ink plots, Glould 4800 and Varian stitute. This problem area has been recognized electrostatic. plots, and displays a Computek a.nd both by the members of SUGI (the need for Tektronix storage tubes. graphic. routines was voted second in current needs on the 1979 software ballot) and by the o£ PRDe Since the capabilities and gynta~ SAS Institute as stated, among other times, by VIVIPLOT are nearly identical to PROe PLOI~ line Goodnight at the 1978 American Statistical plots from PLOT can be easily converted to copy Association annual meetings (""Future emphasis ready figu~es using VIVIPLOT",Sugi-79-54 Farrell Magoun.txt
"time the programs will need maintenance as a result of changes in the SAS rou- Frequently it is necessary to write tines. a SAS PROC simply to interface previously written routines to existing procedures. The development of such procedures By waiving special features found in more can be broken into distinct steps; first, complex SAS PROC's simple versions can program revision and/or enhancement-- , be written using the tools available to which may mean writing a main line pro- , any beginning programmer. These tools gram if subroutine5 already exist or, if ! include a high level language such as the program is a main line, making , } FORTRAN or PL/I, existing JCL procedures changes in the code so that data can be and SAS macro's. interfaced with SAS data sets; second, additions to the JCL--which inClude The ease of developing such a proce- storage of the programs and aCCeSS to dure will be demonstrated by using a the data sets; and third, the writing FORTRAN subroutine implementing the Sande- of MACROs to facilitate usage. Tukey radix-2 fast Fourier transform. The points to be discussed inClude: As an example of program develop- writing the FORTRAN interface, making ment, I have used the Fast Fourier the necessary additions to both the Transform program, written in FORTRAN FORTRAN JCL PROC and the SAS JCL PROC, and presented on page 75 of Peter passing the data in the SAS program and Bloomfield' 5 (1976) book, Fourier Analy- finally assembling a SAS macro for use sis of Time Series: An Introduct~on. by non-programming users. PROGRAM REVISION AND ENHANCEMENT",Sugi-79-55 Partridge.txt
"IMPLEMENTING RELATIONAL DATABASE MANAGEMENT TECHNIQUES IN SAS William Ingram, University of Florida relation, Or ~ relation of degree n. Throughout history one principle All tuples of a relation are defined by ~eems to e~er~e: Gr~at ideas are simple the variable name or attribute~ ldeas. Th~s 15 partlcularly true in . The domain contains the range from data management. All too often, data- wh~~h a valu~ fOL an attribute, or base management systems run the danger varlable can be selected. The number of becoming cumbersome, inflexible, and l of values in a domain can be· extremely problematic. The logical interconnec- large or very restricted. Each tuple tions tend to muliply as new variables ~ust ~a~e a.key, or ruling part, which and types of data queries are added. [1] ldent~f~es It uniquely. The ruling part We must try to describe the data in can be composed of more than one attri- a way that will avoid the entanglements bute. The remaining attributes, the that can ~uild up in complex data struc- d~pendent part, describe the object de""""; tures. The desired data description flned by the relation. The ruling part techniques will (1) be understood easily should not contain any redundant by users with no training in program- attributes. Any att~ibute of the ruling ming, (Z) make it possible to add to the part ~hich, if removed still leaves the aat~base without changing the existing rul~ng part unique, should be placed in loglcal structure of application pro- a dlfferent relation or in its own sep- grams/ and (3) permit the maximum flexi- arate relation. bility in formulating unanticipated in- Thus, a relational database is quiries. Hierarchial, tree, or pointer- formed by assembling collections of linked logical data structures can often tuples into relations. The·process one inhibit changes that may be needed as follows in assembling the relations is the database grows. [1,2,3] called normalization. This process must The most natural way to represent be fol~owed so t",Sugi-79-56 Ingram.txt
"The Hole of SAS in tl1C! Support of Clinici'l Stuilies in H(-!oicinE: ,1. Phi1ir J'>1iller ~'flshiIl0ton University r""1cdic<1l School St. Louis. r.ti,O GJ1IO p the study's directors abaut such critical patient recruitment, protocol ele~ents as adberence, safety control ~uality and monitorin3, and t.he identificat.ion of"" SAS b.as become a populsr tool for the bottlenecks in the study's progress (rloore, et al, 1978). Organizing the data 8S a separate analysis of data from clinical studies, and i5 SAS d.ataset for each form allows straightforward increasingly being utilized for the management processing of the information. This data the research data. Particularly for of that described by structure is similar to large-scale stUdies, the challenge of effici~:.:'lt Ha<rell (1978). management aIJd analysis of vast Quanti ties of information is significant. In order to lt has been our philoBophy to Qecompo~e the minimize the cost of olinical studies, careful attention must be given to the allocation of separate tasks ao<l. then needs of the study into to determine which compute~ resources best meet information proces~ing tasks to appropriate the needs of particular tasks. The appropriate The achieve resources. objective is to computer resourCes differ from study to study effective utilization of hardware, 50ft~are and personnel. according to the needs of each particular study. This paper explicates some way~ we have found have approached the design of such SAS to be useful in solving particular tasks. ~le information sy$tem~ by capitalizing on locally available resources. A cost-effective solution lntrfacing ~ith separate is achieved for each subset of a study's needs data entry systems and appropriate interfaces between oomponents are pro.icted (Miller, et al, 1977). For almost For a number of 3tudies , we have found it all studies which we have approached in this desireablE- and fea.sible to implement a separate manner, SAS has been an lmpo!tant and integral data entr",Sugi-79-57 Miller.txt
"FORTRAN, COBOL, and the hoards of application d~ Often in ecological pilot field studies t programmers. What ~s diff~cult to understand is cisions as to data base mariagement, structure t the continuation of t.his RDBM strategy among ROB analysEs and report generatiori. can only be specu- managers today--the current generation of comput- lative ,since the data base requirements often ing. have to be developed in this phase of the study. In these cases, the lack of appropriate informa- Informal polla among RDB managers indicate tion prior to the study cannot justify detailed that an increasing number of RDBM systems are not and extensive pre-planning of research data base m~naseruent strategies. ~he potential liability being developed as outlined in many of the lead- ing references in this field. For example, flow of open-minded management of data bases bas to be minimized against the n~ed to be able tQ modify charting, one of the backbones of the industry, eontent and structure of large data bases. For has been shown to be an academic exercise wit.h many complex and large scale ecological field little application or help to real world comple~ RDB probl~s. Pert_ diagrams are v~ry informative studies being conducted at the Waterways Experi- ment Station SAS 76 under ISO provides the frame- after the final report is written. Dictionaries, fixed sorting strategies, cumbersome merging work for making open-minded research data base capabiliti:s, -data set recov~ry problems., etc., management systems practical and cost effective. are all dinosaurs, extinct but with varying de- grees of'belief by some RDB managers that they",Sugi-79-58 Farrell Magoun Daniels.txt
"THE USE OF SAS IN ADMINISTRATIVE COMPUTING AT BOTH THE UNIVERSITY AND FEDERAL LEVELS Herbert Kirk, SAS Institute Inc. Arnold Bragg, North Carol1na State University eRrs INTRODUCTION Figure 1. Information Con'tained in the Data Base There are 9-2 state agric.ultura.l experiment stations (SAES) J forestry schools "", and c.ooperat- Form AD-416 Research Resume ing institutions conducting agricultural research in the United States. Funding for research con- Year State and County ducted at these institutions is channeled through Principal Investigator(s) ·Accession Number the Science and Education Administra-tion, Coopera- Project Number Research Location tive Research (SEA-CR) for the United States Depart- Funding Type Status ment of Agric.ulture. The Current Research Informa- Contract/Grant/Agreement No~ 'title tion System, better known as CRIS has the responsi- Regional Project Number Responsib1e Organi~ation bility of keeping up with these projec.ts. eRrs I, Stet-ting Data Department which is supported by SEA-CR maintains a data base Termination Date City on all agricultural research projects dating back to 1967. One of the major objective,s of eRrs is to provide procedures for the interchange of Form AD-4l7 Clas6ification of Research information a.mong B-cieptis,ts and also provide information to SAES administrators for research Classification of Research: Type of Research: managemen t ~ Hatch Marketing (%) Acti.v1.ty To make CRIS as complete and useful as CODlIIIDdity Basic Research (%) each ,institution receiving federal funds possible~ Field of Scienc~ Applied Research (%) through SEA-CR submits project resumes to eRIS on Research Problem Ar~a Development Effort (%) all research projects. To enter this information Spacial Classifications Forestry into CRIS~ a Research Resume forru AD-416 and a Research Program classificat~on of Research Summary form AD-4l7 are submitted for each new or revisBd project. At the end of the fiscal year, accounting information Form AD",Sugi-79-59 Kirk Bragg.txt
"DEVELOPMENT O~ A SAS DATA MANAGEMENT SYSTEM ~R THE GERMPLASM COLLECTION AT THE ASIAN VEGETABLE RESEARCH AND DEVELOPMENT CENTER (AV1UJC) John N. Hubbell, Jr., AVEDC Research Environment From this examination of the AVRDC research The princlple objective of AVRDC is ta in- yi~ld vegetabl~ e~Qpa the requirements for a support sys- crease and quality of for environment~ the humid t~opica and 6ubtropics in order to im- tem for data management and analyses may be prove the quality of life for the large number of formulated. In early 1975, when I first formu- lated a system there were some very severe con- people at the low end of the income spectra. To reach this objective scientists from different straints. At AVRDC headquarters in Talwan~ there · disciplines have combined efforts~ Six crops ; was no large ccmputer in house. Only a small v have been selected fo~ improvement -- soybean~ Munroe 1860 programmable printing calculator was .' , } GZycine .m:IX, mungbeau. lfgna radia.ta, tomato"". available at AVRDC. If a la~ge computer was to Ly~operBic:on eBeuz.ent:um~ be used~ debugging would have to be done via the Chinese cabbage.,. Brosaica pekineneia.· , sweet potato'll IpomoeCi mail to a large computer .330 km away. The system batataa"", and white potato"", Solanwn tuberoaum. had to be initiated in the three months before I was to leave fo~ 8 two-year post in the Philip- Plant breeders have gathered germplasm from sources throughout the world. Pathologists and pines, thus leaving one BS~level staff member to entomologists screen the collections for resis- assist the scientists in the development of the tance to diseases and insects. Chemists identify system. accessions that are high in desirable nutrients With these constraints in our environment, and- low in undesirable compounds. Horticul- whatever system was selected would preferably turists, soil scientists, and economists evaluate have these following cha~acteri~ticg: (1) it accessions within the physical and socio-e",Sugi-79-60 Hubbell.txt
"NONLINEAR SIMULTANEOUS EQUATION MODELS IN DISCRETE TIME John SaIl, SAS Institute Models to be addressed Another type of dynamic model is run in CONTINUOUS TIME. These models can be described by a system of DIFFERENTIAL EQUATIONS. CS}fP is The model is a system of equations, possibly one softvrare product that handles these types of nonlinear, that are solved simultaneously for a models. The basic technique is to compute inte- set of variables at a given point in time. The model can be pictured: grals across time using variable stepsize methods that guarantee certain accuracy. Another type of dynamic model is EVENT ORI- output input ENTED. These models run in jumps of time that are variables variables not equally spaced. GPSS and SllfSCRIPT are popu- lar software products to handle these models. The ENDOGENOUS EXOGENOUS basic technique is to generate events that will happen at some time in the future, and manage these events in a next-event queue. lagged endogenous (feedback) Some processes are inherently one type or another. Sometimes the process may be one type~ Given values for the exogenous variables, the but be modeled by another type. For example, system determines values for the endogenous variables that uniquely solve the equations. consider raindrops falling into a bucket. The raindrops themselves are event-oriented. However, For dynamic models (across time), there is a since so many of these events happen, the process series of equally-spaced points in time for which of the bucket filling with water might be con- sidered continuous in time. However, if you mea- the model is solved. This is usually monthly. sured the filling of the bucket ~t equally-spaced quarterly, yearly, daily, or hourly. Sometimes intervals of time, you might want to approximate the results from one point in time are used in the continuous model with a discrete time model. the system after a delay of one or more periods. These are written in the system as !flagged endo- Translating bet",Sugi-79-70 Sall.txt
"PRoe REPT1FMD - A SAS PROCEDURE rOR REPEATED MEASUREMENTS.EXPERIMENTS WITH MISSING DATA ~1cNee William G. Jackson, Jr. and Richard C. Data Sciences USAF School' of Aerospace Medicine, Brooks AFB. Texas 78235 Division~ SECTION 1. Introduction Data Analyzed in Example 1 Table 1: The repeated measurements design' (2,) with subjects divided into several lc~atmenl,; groups Time I Group Subject 1 2 4 -2 is frequently used in experiments. Under cer- tain assumptions (2,4,8) a univariate analysis 94 97 22 1 1 41 of variance is appropriate and may be easily ob- 1 33 73 2 tained from ~idely available computer programs 67 81 1 50 31 3 such as SAS ANOVA (1,5) and BMDP2V (3) provided 54 51 78 37 1 4 there are no missing values. However, when mis- sing values occur~ the computation of all the 23 5 25 58 2 45 desired mean squares requires passing the data 2 27 6 17 35 32 more than once through a program such as SAS 80 87 13 7 2 GLM (l) or manufacturing a set o-f'dummy covar- 97 30 40 8 2 iates for a program such as BMDP2V. In either case the 'task is, relatively laborious and time 32 29 61 63 3 9 consuming. The SAS procedure REPTIFMn recog- 80 3 10 16 73 37 nizes mis-sing values in a SAS data set and auto- 60 53 13 65 3 11 matieally generates the dummy covariates, a set 48 18 12 51 57 3 of adjusted mean squares, and tables of adjusted meanS. Additional sunnnary statistics of in- terest in the repeated measurements model are Table 1. To run REPTIFMD the data are read into also produced. a SAS data -set with classification variables for group, subject, and time, plus any numeric var- The linear model upon which the analysis is iables to be analyzed. Once this is done, the based is given_ by only'necessary statements to run .the program are: PRoe REPTIFMD DATA= data_set_name; CLASSES list; 1, 2, g i 1, 2, Group, subject~ and time identifiers are named j in the list. The_VARIABLES~ BY, and TITLEn 1, 2. k statements are also available to be used in the usual way. whe're fixed me?-n 11",Sugi-79-71 Jackson McNee.txt
"THE PROCEDURE DURBIN M. £. McBride t - Clarkson College of Technology R. P. Parks, Washington University ""eil Testing the hypothesis that a sample of ob- = (3) CI servations xl'""'' x is a. random sample from a normal distribution nis possible through a vari- U(I) - ""(i_I) ci 1=2, ··· , "" ety' of statistical techniques. One of the earl j- er techniques was Pearsonls X2 test. Mor'e recent cn+I=I-u(n)' research has centered On the Shapiro-Wtlk test The c. IS are now ordered since it is their rel.a- and the Kolmogorov test. This paper describes tIve 'magnitudes which are of interest four such tests of- normal ity and presents a SAS procedure which performs the necessary computa- cell .:o:.c(2).:o:. ..· ~c(n+J)"" (4) tions. Three of the tests are due to a 1961 SioH metrika article by J. Durbin. The fourth tes~s Another transformation is made to set the ordered due to- a 1965 Biometrika article by Shapiro and c(i) 's into a more manageable form: \/i I k. The first section of the paper describes the = (n+2-1) (C(i) - C(i-I)) i=I ·...· n+1 (5) 9 four alternative tests. Each statistical test is 1 presented with the necessary information to un- o. c(o) = derstand the use of the test. The second section Note that each g. 2:.. 0 and tha-t provides a description of the procedure DURBIN, I its features, how to calf it, and an example run. n+1 0+1 The final section presents the results of a sMall I g, = IC(!)=I. monte carlo study to il Justrate the power of the I 1=1 i=l alternative tests. Durbin has sho...,rn the remarkable result that the THE TEST STATISTICS g., . .. , 9 J which depend on the ordered inter- v~ls have""Ine same distribution as the unordered The procedure DURBIN calculates four alter- native tests of normaUty. on a random sample of n intervals c 1P . q c + ' This is the key result nf deviates Xl'''' x _. Three of the tests, due to to Durbin's transformation. J. Durbin fBiome~rika 1961], are exact tests In that ,the tests yield exact probabi litfes of re~ Letting je",Sugi-79-72 McBride Parks.txt
"abIes and a list of functions to be An SAS macro is described .. hich applied. More specifically, the macro performs robust multiple regression. can process mUltiple datasets by setting the macro PASS LMT to the number of data- The technique is ·implemented as a macro sets to be passed, thus iteratively in order to provide the user with maxi~ mum access and flexibility of program executing the fetches ·in the regression execution. The macro is constructed in macro. Likewise, on each pass the user can select any set of the four functions a manner 'such that the user has the option of supplying both the appropriate described by setting the value of Fl-F4 weighting function and the algorithm to 0 or 1 depending on whether that function is tabe applied. Additionally, control information. Addi tionallY, -the macro is designed such that multinle the U5·er can --easily modify _the conver- datasets may be processed through a gence limit, the maximum allowable inter- single macro call; thereby enabling actions; and measure ·0'£ residual '~the the user to assess the performance of spread used (e.g. the median absolute particular weighting functions. Finally, deviation, or the inter-quartile range). the macro is demonstrated in an example The macro will compute for each pass by Drapper and Smith (1966) in order to compare each function's treatment of the executed, an initial least squares fit, the corresponding ANOVA table, and out- outliers. put a matrix of the estimated parameters. Likewise, for each function selected the macro will pring; 1) a matrix of weight",Sugi-79-73 McElrea.txt
"A SAS MACRO FOR A DISTRIBUTION-FREE TEST FOR THE PARALLELISM OF TWO REGRESSION LINES Robert Rogers, USDA Forest Service Sandra Novingert USDA Forest Service INTRODUCTION Parametric methods for testing equality of vations. A uniform random variate distributed slopes of two regression lines are commonly used on the interval (0,1) is generated for each in forestry and other fields to obtain informa- observation in the respective datasets. The tion about the nature of the differences, if observations are then sorted by the values of any, between the lines. These procedures are the random variate. If n is the largest even used in particular to test whether observations number of observations in the dataset containing from two or more populations have the same rela- the fewest number of observations, then the last tion between the dependent and independent vari- n. - n observations from the ith dataset are ables. However. these methods for comparing dtheted. regression lines under the usual assumptions PROC MATRIX is used extensively to calcu- (normally and independently distributed error late and print appropriate statistics. The sum of the positive signed ranks, r+ is calculated terms, with the error terms in the regressions h~ving equal variances) should not be used if as foLlows: these assumptions are not met. 1. Compute slope estimators u i "" after forming n/2 = m pairs of X~J"" with X.J J'~ such Several non-parametric methods have been that ~ ~tntl made available for comparing regression lines. Y. -Y One procedure by Potthoff (1965) is not distri- i j; line = 1,2; = 1, .·. ,m u ij = j+m 1., j =i bution-free but is non-parametric in the sense Xi, j+m - Xij that continuity is the only assumption made con- where Xil--:. Xi2'::·· ·.::X in · cerning the error distribution. Sen (1969) derived a method for testing the parallelism of 2. Randomly pair~ using the randDmization several regression lines tha't is not distribu- technique mentioned earlier, the u "" 's with the tio",Sugi-79-74 Rogers Novinger.txt
"due to the high cost or unavail- A Statistical Analysis System (SAS) ability of experimental material. This macro for constructing optimum experi- can also occur because of a need for a mental designs for full-rank linear ""quick"" solution. An unusual experi- models is described. Basically, the mental region is one that can't be macro selects an optimum set of runs described by a simple factorial struc- from a list of candidate runs specified ture, a hypersphere, ellipsoid or cube. by the user. The user has two choices Often the simplest way to describe these of optimality criteria, D-optimality and unusual experimental regions is by A- opt imali ty . enumeration of all possible runs. The The versatility of this macro makes third category of problems frequently it very useful in practical applications. occurs when an experimenter conducts a Since the user can describe the design poorly designed experiment only to find region by a list of candidate runs, the that it was not adequately designed to macro can be applied to any design answer his primary questions. In these region. Furthermore, not 'only can the situations, statisticians are sometimes macro be used to construct an initial called upon to recommend an additional experimental design, it can also be used set of runs to ""shore up"" the data. to augment a specified design with the An Example flbest tt set of experimental runs. In this way, poorly designed experiments The following example, which can be ""shored up;"" and exp",Sugi-79-75 Jones.txt
"Moacir Pedroso Junior, EMBAAPA The procedure CLMEANS attempts mate of the common variance. to split a set of treatment means into ho mogeneous subsets, according to the algo rithm described by Scott and Knott (1). - DF~ Briefly, the algorithm proceeds as fol 7 lows: given a set of treatment means, y This parameter must always be 1 ind~ present. It specifies the degrees 'of Y2'···'Yk' with Yi'vN().!i,,,2) ,and an freedom of the estimate of the common pendente estimate, 52, of the common vari variance. ance, we can discover if the means fall - into at least two reasonably homogeneous groups by the application of an F-test in L=. the usual way. So it is natural to consid LEVEL=. _ _ er a likelihood ratio test for this spe- cific alternative. As it was developed In This parameter specifies the the reference given below, we will consid level for judging the significance of er a test statistic A, whose percentage- the partition. When this parameter is pOints of the null distr~bution can be aE to omited, it is assumed to be equal proximated by those ofaX distribution, 0.05. with v=k/(rr-2) degrees of freedom. Thus, if we accept the partition of the origi nal group, the resulting subsets will be NAMED partitioned Similarly, in a hierarchical, way. When this option is omited,the procedure will assign the names ""MEAN#OOl"", ""MEAN#002"",,,a., to the means, in the order they appear. When this o£ OUTPUT tion is present,the procedure will as sign the names given by the user to the For each execution of the CLMEANS means. procedure, the following output will be printed: - the listing of the original PROCEDURE INFORMATION STATEMENT means in ascending order; - a groups map similar to a den PARMCARDS statement. dogram in a cluster analysis; - a statistical summary compri PARMCARDS; sing the value of A, the degrees of free dom and the probability of a greater va! This statement indicates that ue ofaX2 variate. the means and names{when the option NAMED was used) are given below. THE PRO",Sugi-79-76 Pedroso.txt
"RESPONSIBILITIES OF A SAS USER Richard E. Cooper, U. S. Department of Agriculture Many people have found SAS to be a most about SAS. This will enable us to optimize our valuable tool for the analysis and management effectiveness in using SAS, and will save our of data. Some of us use SAS to the extent that time, computer time, and money. We can find we would have great difficulty accomplishing our additional information in SAS Views, SAS Technical Reports, SAS Introductory Guide, SAS work without it. Conference Proceedings, SAS Programmer's Guide, SAS Institute is most willing to work with and the SAS examples distributed on SAS tapes. their users. Consequently, each of us becomes involved as a member of the SAS ""Team"". Those To make use of all the currently available who have a high regard for SAS, and expect to information, we should organize the information continue to use SAS must assume some responsi- in such a way that appropriate parts are together. bilities. Each of US accomplishes this in his own way. Some may find they are too busy to organize this information (I have fallen into this category We should encourage our colleagues and our clients to use SAS. With an increased number lately). We may want to maintain a working SAS of SAS users, comes more feedback, resulting in manual by continuously updating it with pertinent a higher quality version of SAS. Many of us examples and information obtained from the are in positions where we could provide previous1y mentioned sources, and our own experi- assistance to others and be able to establish ences. In some cases this may require punching and/or teach local courses on the use of SAS. holes in the current SAS manual and placing material into the appropriate sections. Regard- Our knowledge of statistics and its proper less of how we do it, we must keep our knowledge application to data is most important. Our of SAS capabilities current. understanding of the many and varied statistical methodologies is paramou",Sugi-79-77 Cooper.txt
"STATISTICAL APPLICATIONS OF SAS AT THE 3M CO~ B~ F. f.1cDonagh, PhD., Riker Laboratories, Inc. The 3M Company is a highly diversified manufac- applications, with heavy emphasis on biological turing company headquartered in St. paul, M~nne and medical applications. While our main involve- sota. Its 1977 Sales totaled 3.980 billion dol- ment has been with clinical trials of new pharma- lars and its Net Income was 413 million dollars, ceutics! ~~ have been recognized by many diverse ranking it 53rd nationally in terms of 'sales, and groups within the company as possessing skills 29th nationally in terms of profits. The' company and resources that could be applied to the solu- is organized into nine major product areas or tion of their problems. groups: It is with these various applications, and how o Abrasives, Adhesives, Building Service. SA$ has played a role in the data base, analytic- Chemicals al, and report generation aspects of work on Advertising Services and Protective Pro- these applications, that I would first like to ducts Secondly, I would like to make reference dwell~ to other groups that have found SAS and its var- o Consumer Products ious features helpful to their applications. Electrical Products Finally, I would like to discuss the future as o Business Products regards our use of computers and how SAS fits in- Health Care Products and Services to this future. o Photographic, Printing, Industrial Since our group was instrumental in bringing SAS Graphics, and Static Control Systems into the 3M Company, let me first describe our o Recording Materials group and its activities. o Tape and Allied Products My department provides statistical and computer The company employs 81 thousand people worldwide services to a number of areas within the 3M Co. (with some 33 thousand located outside the U.S.) ~ Our primary areas of expertise are providing the- se services to people involved in experimentation It has 35 U. s. divisions and 12 U. S. subsidi- whiqh is eith",Sugi-79-78 McDonagh.txt
"BAS PRJCEJ:lURES FOR ESTIMATING 1l!E PARl\ME:I'ERS OF 1l!E M2\KEHl\M MJIlEL Jarres P. Sunrne and R. Clifton Bailey, Naval Medical Research Institute The r.isk :function -for the the data (2). The Navy currently bas an aareement NIH to anaLyze a se~ of data on Vakeham model is .l~h aexp( - r't ) +6 patients who have received kidney whe,re the structaral parame'ter a: is the The bope Is to discover ~ransplants. hu. to increase kidney ara£t survival. l n l t l . l excess risk. the structural These transplants .ere between parameter T is the rate at .hich the perfor~ed initial excess risk is exponentially 1974 and 1976. Observed is the length washed out. and the struc tural para:ne tar 01 tlae the kidney gra.ft -functions whlch 6 Is -the lona: term risk. The Makeham may be either the time to faiLure or the modeL is related to several well ~nown The usual tIme to the end of the st:u«y. The exponential mode, is a way to analyze data of this type Is by models (1 ). speciaL case o£ the Makeham ~Qdet. (a or conatructln~ l11e tables (4). In a l1:{e The model 10rmed £~om mixing two T~O). tabl.e the time is divided into inte.rvat.s exponentlal models can be viewed as an and tbe conditional probabill~Y of approximation to the Wakeham model. survlvln~ the interval AS weLl as the [f a con~tant is added to the risk function cumulative probability of surviving that 0:1 the Pa.re to model then it also Interval and all previous intervals are approximates the ~akeham mOdel. To study the in£Luence of a C4lcu~ated. In order to study ~he e1fects of p variable on gra£t survival. the variable VAriables x1 ...... x p on surVival. the Is used to cate~orize the data and eeparate li1e tables are produced 1Qr structuraL p~rameters are expressed as 1unct}ons of the parameters ~nd 1£ one were each eate~Qry. E.~. studyin~ the influence 01 the ase of the variables .. i.e. a~exp(~O+alxl+ .. ··+apxp) recipient upon graft survivaL. one mi~ht 7~exp(YO+llxl····*rpxp) use ten year a~e intervals to catego",Sugi-79-79 Summe Bailey.txt
"A macro lS presented which enables the dropping the variables in DROPLIST and adding user to easily select a random sample (without DUMBY to insure that there is always at least replacement) of size n from a SAS database con- one character variable. taining N data points which can be either nu- meric or character. The program lists the DATACHEK then calls MATRIX. It reads the original database with interspersed records numeric variables into BI and the character which quickly identify the data points in the variables into Cl. It generates a random num- random sample~ The procedure is specifically ber, and calculates the corresponding row and adapted to SAS databases created through an column number (i,j), as well as the correspond- Inquire database. An example of its use on an ing matrix Bl or CI. If location (i~j) has been Inquire database is given. selected already, it is discarded. Otherwise, 9999 is put in that location and the hit counter is incremented by one. If the counter is less",Sugi-79-80 Cash Martin.txt
"tural Sciences of Philadelphia and Temple University Robert D. Small, Academy of Natural Sciences of Philadelphia ABSTRACT and other procedures are used. Because of the complexity of the situation none A biological model is usually repre- of these methods leads to estimates with sented by a system of linear differential completely satisfactory statistical properties, . The distributional proper- equations whose coefficients are to be estimated from observed data. Capizzi ties are seldom known and most of the and Small have developed a technique estimates contain bias of an unknown which can be applied to virtually all magnitude. For example, even the sim- differential models. The parameter esti- plest differential equation commonly mates are obtained directly from the used as a growth curve, dx/dt = kx, is not free of problems (Wilson and Small, unintegrated form through spline regres- sion and differentiation followed by 1978). The usual procedure here is to fit a line to the logarithms of the pre~ linear least squares. A measure of cis ion which is uncommon for most other observations. thus raising the question methods, is obtained by employing the of the distribution of the logs. Also, if the· errors in the observed data are jackknife. j. homogeneous"" then the logs will not have The purpose of this paper is to pre- this homogeneity and weighted least sent a flexible SAS macro which makes the squares should be applied. application of this technique simple and The preceding",Sugi-79-81 Kral Capizzi Small.txt
"N. J. ABSTRACT The purpose of this paper is to show how We study several meaningful aspects of the SAS can be llsed to perform stepwise procedures curves, such as mean growth, average growth rate for analyzing-repeat~d measurement experiments. and changes in growth rate using polynomials, These multivariate methods can be used to deter- although they may not fully explain the growth mine treatment differences when a single response We test each degree polynomial by trans- process~ is observed at successive equally/unequally £orming the data into orthogonal polynomials to spaced fixed time-points. Using orthogonal poly- produce ,new variables called score$. By this .ap- nomials, the response can be modeled in terms of proach {Dempster (1969) and Patel and Sylwestrowicz suitable degree polynomial scores which (1977)], we hope to reduce the dimensionality of adequately characterize the curves. This proce- the data w1thout sacrificing essential information. dure not only compares the overall treatment means but also compares the selected degree of The polynomial is fitted to growth curve polynomials in a stepwise manner. data with the aid of orthogonal pOlynomials in a stepwise 'manner. Each succeeding step gives We consider one-way classification models a I1better"" fit to t;.he curve than the_previous with and without covariate(s), the null hypoth- curve. The purpose of using higher order poly- esis being that the observations are a random nomials is to differentiate treatments",Sugi-79-82 Patel.txt
"tal number of observations and [X] denote the largest integer less than X A general purpose macro which computes we calculate the 100a% (0 < = a< = .5) trimmed BY trimmed means is presented. The macro has mean by giving the largest [100an] and the II II statement capabilities, will do multiple vari- smallest [lOOan] observations a weight of ~ and ables, deletes observations only for the the middle n-2[100ao] observations a weight of variables for which they are missing, and can 1/(n-2[100an]). The median can be viewed as a handle any number of trims. Any amount of trim- trimmed mean with a = .5. Macro TRIMMEAN ming between 0 and .5, inclusive, is allowed. computes trimmed means for all values of a between a and .5 inclusive. Another macro is presented that creates a data set which can be used as input to ANOVA(GLM) The k-level winsorized mean is calculated to obtain Brown and Forsythe's generalization by giving the k largest and k smallest observa- of Levene's test of homogeneity of variance. tions a weight of 0. the k+lst largest and the k+1st smallest a weight of (k+1)/n, and the I NTRODUCTl ON middle o-2(k+l) observations a weight of 1/0. TRIMMEAN can be easily modified so that windor- The results of past software ballots have ized means are calculated instead of trimmed indicated that SAS users place high priority means. on the addition of tests of homogeneity of variance to SAS. Such tests are available Both the Hampel and the biweight estimators thru the interfaces to S",Sugi-79-83 Henderson.txt
"j 1 pairs in which X. < y · and Type (2) II: The ""pair chartl! is a useful. graphical rep- j' 1 resentation of ordered data for two_sample prob- Type III: pairs in which X. = Y. (ties). 1 J lems. In addition, it provides a conyenient for- The Mann-Whitney statistics and U are mat for computing common two-sample, inferential U x y statistics such as the-Wilcoxon, Mann-Whitn~y and given by Kolmogorov-Smirnoy. The present paper presents a ux (Number of 'Iype II pairs) + ·S(Numher of SAS macro for plotting pair charts on the pen Type III pairs) (3) plotter at the UNC Computation Center (or the screen of a Tektronix video terminal) and also MN - Ux . Ii Y calculating ,the above two-sample test statist-ics. To compute the Wilcoxon statistic for test-",Sugi-79-84 Sinha Hardy.txt
"A NONPROCEDURAL QUERY FACILITY FOR THE CASUAL SAS USER Arnold W. Bragg Jr.) NQrth CarQlina Agricultural Research Service, N. C. State University have a ~ork1ng knowledge of tha~ subset of SAS INTRODUCTION most often· uSed and & familiarity with SOme SAS A number of SAS users have noted the basic procedures. similarities between and.evolving data man- SA~ Casual ~ mighi. 1.Jt:lSL 1.Je uescrll.n::d as iu- agement systems based on a relational data model. experienced, infrequent technical users who are Although SAS 16 not a true relational databa~e primarily concerned with information retrieval management system in- the strictest Codd/Chamber- and display. Casual users either (a) use SAS aD lain/StDnebraker.definit1ort, these similarities infrequently that ~ach interaction fosters a mtght-allow one to borrow features from the lea ring experience or lengthy ·and traumatic (b) have no prior knowledge of programming lang- prototype relational systems to add a ne~ dimen- sion to SAS as a tool for in£OLmation ~etrieval. uages and therefor a healthy mistrust (disrespect, fear~ loathing. hatred) of/for computers or We discuss- pre-processing rout.:ine foY' B. implementing a database query (mapping) language (c) have never mastered the differences between similar in complexity and syntax to IBM's SEQUEL MERGE and UPDATE, cannot remember THhe.n to sort, or INGRES r QUEL which translates a query such as forget semicolons, and think symbolic operators Range of E is Employee· are astrological signs. SAS (plus a smattering .Retrieve (Name Salary) Where E~Age>40 of OS370 Jet Bnd PLI for ~rocedure writing) is And E.Sex:c:Female Or ··.· well-suited for eBch user cl~gs except the latter. into SAS statements for proc~ss1ng. Human factors Unfortunately, we must either elevate the casual st~dies ove~helm1ngly support such a nonproced- user to the technical userla level· or provide a ural syntax·for the casual user over the more query facility better suited to his requirements. arcane pro",Sugi-80-02 Bragg.txt
"r to identify several ABSTRACT desirable characteristics for :m information system. They include the facts that it: RGS (Industrial Machinery The !ME and Equipment Report Generator Systam) is a (a) delivers' information time within staUstical report generator system implemented constraints, using SAS as foundation software. Its p~esent ia accurate and secure, (b) is limited to the areas of application handles volumes of data, (c) indust.rial pri~l! indexes. However, the .system is inexpensive to develop and maintain~ (d) is designed with one particularly important withstands a changing environment~ (e) objective, i.e. it ~an function as an integral deals with complexity (abstract vie'W . of (f) part of information systems pertaining to tbe stored -data). national economic indicators published regul~rly is @xtendable to cover a wider scope of (g) by Statistics Canada. information. In building such a report gener~tor $ystem, paper, using a statistical report In this this paper explores the following three aspects: as an example, tbe author gen9r~tor system wishes to present her solutions to some of the (1) the c.oncept -of foundation software, its problems inherent in building information advantages and drawbacks I systems with desirable characteristica. In (i!) SAS - its power as foundation software l particular~ the paper explores the concept of (ill) strategies involved in solving complex foundation software and the use of SAS as the problems inherent in information systems",Sugi-80-03 Gratton.txt
"ANALYSIS AND PRESENTATION OF STUDENT EVALUATIONS OF FACULTY DATA USING SAS Richard K. Ford, Eastern Kentucky University Steven F. Thomson, University of Kentucky Bruce R. Lewis, Eastern Kentucky University Kenneth E. Wagner, Eastern Kentucky University Eastern Kentucky University has recently needs within the University. The analytical pro- endorsed Student Evaluations of Faculty (SEF) as cedure developed within the constraints given to a concept. However, as with any agreement in the data analySiS committee constitutes the theme principle, the mechanics of actually implementing of this paper. such a plan creates many problems. TwO of the The data set committee developed a procedure concerns expressed by the faculty in discussing by which faCulty members would receive a deck of the principle of SEF were the rrethod of analyzing punched computer cards with the responses of each the results and the use of the results. The student to the SEF questions. These cards also contained coding to identify the instructor. The faculty was in al most total .£reemen""t that the evaluations would be worthwhile if they provided punching of the cards was automated with the aid feedback to the instructor and were not used in of · standardized test form and a photomechanical reader. This reduced the manual labor and short- promotion decisions. Therefore. having the evaluation results for each faculty member com- ened the time between administration of the ques- pared only to his own efforts was a des; rable tionnaires and the availability of the resultant quality of the analysis process. data deck. The task of data analysis committee was the Some faculty members were concerned about the wording of the questions that were ,sed ;n development of a procedure which would allow in- collecting the information from the students. dividual faculty members to analyze their results Still others were concerned with the method of with. minimum of effort and still maintain con- presenting the analy",Sugi-80-04 Ford Thomson Lewis Wagner.txt
"TRACT TRAN or- SAS 5tat~ HIghway Hi [eage data~ givi~g the number checkout faeil ities are adequate in SAS 4. of mIles of existing roadw~y for all publ io roads. was clas5ified by type of ~id program, is data set credtion and aooess Q.aaier 5. ill sAs functional 'SY:'Item. maintenance responsibility. or urb<l.t'l. r-esutting wh~ther ru,..~1 and The tross-olassifle~tion required an outp~t grid of HowelJ-er, 28 rous and 16 columns to pres9nt th&-data. Ho~ ever, the data is- quite spar-se, wit.h typically FORTRAN (with the FLEeS 1 preptoc~$sor) 1. 10-20% of the cells for a given county having any have been superior for implementing ~ouid data. Tnerefore. a row and column Index W~$ com- the deoision tables in the ~dit process puted for e.ach d<:lta value. to IOcat£) it on the- output page. using the ~'N~PS"" ~ful! page) option the FORTRAN subscripting faci I Ities would 2. under the FILE statement, Row and ~olumn head- have el iminated a few sorts in95 w~re generated in an an~logous fashion. including 6 S'!'S progratns. was This system. writte-n. in 'S-AS76.6D; it lJould've been easier and snorter to program in SA579. The paper describes 2. SYSTEM STRUCTURE the report writing program in detai I. whi~n uses the follot..Jin!l techniques: structured program- 2.1 SYSTEM DIAGRAM nllng. I inK routines. H=PS.. FIRST. and LAST. var- i~bles, calCUlated v~riables for line numbers and components we bro~en The system was into tne print posit tOilS. ""Inter-Ie.we"". 'S-ET statement see in figure",Sugi-80-05 Kuzirian.txt
"THE sToRAGE AND DISpLAy of GEOGRAPHICAL INFORMATION CSING SAS Grady B. Meehan, Kenneth A. Hardy and James D. Hosking The University of North Carolina at Chapel Hill and may be stored with the other data for that INTRODUCTION obse-rvation or in a separate file. However, Recent developments in statistical package since locations are often the same for a variety of variables of L""""lterest, l-ocation files are usu- design (e.g .· SAS) facilitate the easy management, -ally s-tored separately frOID variable value files. manipulation and analysis of multiple, la~ge scale lo1hen this is the case, a common geographic iden- data bases by users in a variety of application tification code or geocode (Berry, 1971) is nec- areas~ Data bases that contain geographical in- essary to link the two. Furthermore) location formation fall in a category that can be readily handled by SAS. While SAS has devoted mu~h effort files can have cOffiplex structures and, often, are not a single file but two or more interrelated to the development of a variety of useful graphi- files~ cal display techniques for SAS users, a facility For both these reasons (i.e., separate- ness and complexity) geographic data bases can be to generate statistical maps has not been devel- oped and is very important for the proper analyais a problem to hlork with. To make matters worse~ facilities for the m:magement of such data sets of geographtcal data. With this in mind the au- thors wrote an interface between SAS and CALFORM are not provided by most commonly available map- a widely used computer mapping package that pro- ping programs. duces choropleth maps on a pen plotter. CALFORM uses two data sets to describe the boundaries of Computer mapping programs that produce sta- the study area (e.g., counties) and a third that tistical maps generally use at least two separate includes a variable of interest. PROC CA~FORM can files con~aining data values and loeational in- formation. Most programs read these filesj mat~",Sugi-80-06 Meehan Hardy Hosking.txt
"~~veral ~ay$. For instance, i t was conducted using 24.192 BALB/C mice: which Every week during a clinical animal made it one of the largest such studies ~ver ~ondu~ced. experiment various observations relating Also the length of time condition of the ar~ to the anima19 scme animal were left on the: study ex- IheT~ recorded. are a total of 68 ceeded 33 months. Since animal possible conditions that may be observed observation d.2.ta is: collected weekly on any giv""""'n animal e~ch .... eek~ Each of ma.ny a.nimaLs: had more than 100 sets of assign~d these 68 conditions are a Each of the sets of observations data. codes~ consisted of unique character code. these codes are 7-byte string of nbso'!rVAticns ~on then recorded on the live animal data giving individual 7 base in the order that the care:::akers cerning the animAls. Seve.n is th.., maxi- ovservEd then. Up to l8even of these mum numbl"".r of observations that can be made on a given animal per week. codes are observed each week for each Sinel"". animal. Over the duration of the EnOl there may be less than 7 cbs..,rvatinns, a fill character of 9 is u~ed tc indi~atl"". I"".xperiment conducted at the National Center for Toxicological Research, the end of tbe observations for a given of cha~act(:'r Elet~ the number strings for instance if a given set of ob- (animal-weeks) reflecting the condition servations contained 2 valid ~odes then the remainder of the set would b~ 9'18 in of the animals exc~edcd two million. am 99999. pape~ approa~h The presence of seven 9~s in This de8cribes the utilized to obtain frequency a givl"".n set is considered to be a nor~al the d istr ib ution of the se animal cond i tion ccndition. normal condition This is considered to be one of the 68 valid codes. Dbservation codes which each of the",Sugi-80-07 Fleenor Clements.txt
"The Boeing Commercial Airplane Company has spill rate and diversion of full fare passen- gers while maximizing the stimulation of worked with several airlines during the past few years in eva1uating discount air fare additional traffic. plans, particularly for flights with surplus The evaluation Df discount fare plans requires seating capacity. Many analytical tools from the interaction of several diverse dis~iplines. various disciplines play a role in this Figure 1 provides an overview of the inputs and process: For example, survey sampling, design~ processes required to evaluate the impact of a experimental design, parameter estimation of discount fare plan. The three major processes truncated mathematical d;stributions~ involved are tne estimation of the available modeling"" simulation, general linear models, discount seats by the Surplus Seats Analysis and statistical computing. This paper will Program~ the estimation of diversion and stimu- provide an overview of the integration of these 1 ation by SAS, and the estimation of the impact methods in SOlving this difficult pro,lem and on profitability by the Profit Impact Program. show how the file handling.,. statistical, Inputs to the processes include historical load graphical, and report writing capabilities of data, survey data, revenue and cost data. and SAS are used to save analytical time, provide airline management policies. The remainder of the proper statist ical results, and prepare summary reports for upper management~ this paper will focus only upon the design and analysis of survey data using SAS as outlined I.",Sugi-80-08 Kuiper Erickson.txt
"REGIONAL ECOLOGICAL ANALYSIS AND DATA BASE APPLICATIONS I Martha K. Nungesser and Richard J. Olson, Oak Ridge National Laboratory Ahs tract a national level. Data recently added include wilderness areas, national parks, and water Tne regional ecological ana""lysis program quality. Otner thematic sectors have been at Oak National Laboratory requires the ~idge expanded: vegetation now includes both ability to access, manipulate, and analyze ecoregions (Sai ley 1976) and potential natural large qJantities of ecological data. The vegetation (KUchler 1964, Kuchler 1966). Geoecology Data Base provides diverse ecolog- Climatic data now include temperature and ical information on a county unit level for precipitation parameters for state climatic the conterminous United States. It includes divisions. Recently, the Data Base has been data on vegetatl0n, soiis, bedrock, wild1ife, converted to metric units of measure. climate, and environmental pollutants. Manage- ment of this extensive Data Base involves 5everal stages. SAS is used for compilation Date Base Management of data from existing sources, editing data The Geoecology Data Base is managed far errors or incDnsistencies, storage and using SAS (Barr et 01. 1979) (Fig. 1). retrieval. and data analysis and display. Cartographic display is often U5ed both for Currently 80 SAS data sets are stored on a editing and for di5playing analytical results. single OS disk file occupying 12 million bytes. In addition .. several larger data sets The Geoecology Oata Sase is used to are stored offline as SAS tape data sets. Each thematic data set is usually created assess energy-related impacts on ecosystems at regional (multi-county or multi-state) lEvels. from a single source such as a map or survey. The statistical analysis capabilities of SAS Most data sets contain observations for the 3071 county units in the contermlnous U.S. have been used frequently in regional analysis, as in assessfng the impacts of sulfur dioxide The data set",Sugi-80-09 Nungesser Olson.txt
"MISS AMERICA IN REVIEW George L. Miller, Northern Illinois University AllSTRACr rv.nbering 17, 17 and 16. These groups I'«lIBin fixed for all competitions so that a given entty This srudy of the Miss l<nerica Pageanc en- .ccmpete.8 against: the saroo: individuals in all ccmpasses the years of 1921-1979. The data set ccrnpetitioos. The grouping varies from year to consists of 2,214 observations with 32 variables year, but in all cases they are established so per observation in the original set and another that there is wide geographical distribution for 22 interl:la.llY geoorated """"""iab1es per observation. each group. Poise is evaluated in a short inter- The data are generally complete for 1959-1979, view with the different judges during the day on s~t complete for 1945-1958 and for 1921, and »hich the contestant participates in the evening I1I)st1y missing for the other years. The variables gown carpetition. """"inner. are annmJnCed for the given major arphasis in the, study are year. state nightly talent and swimsuit preliminaries, but represented, SlirI1a!JE, first~. rank in the m winners are ever revealed for the evening gown Pageant, prelimi.nary contest success, academic and poise ~etitions in order to heighten sus- major, talent used, class in school, type of pense and keep foll"""""""",s and watchers interes ted singing, type of dancing, beight, weight, bust, throughout the entire Pageant. In sinulating the , waist, hips, hair color, eye -color, and physical poise contest in MISSAM. the IIDdeler relied on s)'IIIIEtty. Race data are too limited to be of variables such as educational level and acadanic use. A prediction ITDdel, MISSAM, evolved as part major. of the analysis. All of the programs, including (b the night of the finals ten semifinalists MISSAM , are written in SAS76 for use on the ccm- are identified, who then compete in all of the puter facilities at Northern Illinois University, caq>etitions during the nationally televised which currently consist of",Sugi-80-10 Miller.txt
"USING-TRAFFIC ACCIDENT REPORTS fOR IMPROVING EMERGENCY MEDICAL SERVICES RESOURCE ALLOCATION Paul D. Krause, Univers.ity of New Mexico lntroduction FIGtH: 1 Every state in the United States keeps Traffic AccldeRt Record Layout by Type computerized recards of traff1c accidents. The quantity and quality of the information varies + IACCIDENT BI INCIDENT greatly from state to state but, potentially, a DATA a""ai1able~ wEalth of information 4$ Iii New Mexico, the Traffic Safety Bureau has funded the State Police to develop and maintain such a 1 I INCllENT + ICAR +I computerized data base. They will uSe the VEliIQ.E DATA system to help in the identif~cation of traffic safety prob1ems and to evaluate the effec- tiveness of counter-meas.ureS they implement. 2 I INCIDENT + ICAR +I The purpose of this paper is to describe how SAS IIlIVER DATA can facilitate access to the data in such a file and manipulate the data into a form useable in ,- the probl~m identification prDcess~ + ICAR +I 3 I INCIIENT ,- VICTIIIS 1-7 Problem identification involves fishing through a mountain of data looking for sta~ tistical relatlonships between mortalityJnor- bidity and modifiable environmental Dr behav- Attached to this paper. as Appendix I, is ioral variables. The causal/coincidental a listinq of the SAS code which restructures patterns d~tected form the basjs for a rudi- the data into a rectangular file with one mentary cost benefit analysis which deternines observation for each individual involved in how 1imitE!d resources are all ocated. an accident, eith~r as a driver or passenger. The first step of this process involves read- New Mexico has many traffic accidents. OnE! ing the data tape and creating a SAS f~le.fDr hundred fifty-eight thousand individuals, Or each of the four 'dnds of re-cords. Th1s lS a1most 15% of the state's population. were in- done by the code in lines 1-12 of Appendix I. voly~d in auto accidents in 1978 alone. ~he The record type is read in at 1ine 7 and accident re",Sugi-80-11 Krause.txt
"CLINICAL DATA MANAGEMENT AND SAS79 Michael S. Lajiness, The Upjohn Company takes just 2 statements, PROC COPY and the Introduction SELECT option, which requires just the one level SAS data set names. A 75% reduction in CPU time Whenever a major release of SAS arrives. the user is faced with a common dilemma: Should is realized by using the SAS79 program as shown he/she implement the new features into his/her in Table 2. This reduction is primarily the new and older SAS programs? It's sometimes all ~esult of much fewer reads and writes to tape [TXCP). COpy and TAPECOPY are also very nice too easy to 1eave we11 enough alone. when used to copy data· sets from 1 tape to With the latest edition of SAS, SAS79, this .nother. Previously, tape rewinding was neces- dilemma is certainly evident. Several new sary to react multiple data sets from one tape to statements and procedures are there for the another. Now in SAS79 all is accomplished in using. Should we? one pass of the tape resulting in a tremendous reduction of real turnaround time [and CPU time). In this paper I will answer this question by showing some of the advantages of using the Manipulation of SAS data sets prior to new commands and procedures of SAS79. I will statistical analysis is often necessary and fre- contrast the performance of SAS79 and SAS76 quently messy. One of the more frequent re- programs in performing typical applications in quests is to combine several observations into the clinical area. This wi11 include a compari- one, possibly for an analysis of covariance or son of the ease and efficiency of the coding as to take differences from initial. well as the associated CPU requirements. While this is not especially difficult to do when the number of variables and observations Typical Data Management Functions and Examples to be combined is large, the program in SAS76 becomes cumbersome. to say the least. SAS79 , In the course of a clinical study, SAS is however. makes life more Simple and reduce",Sugi-80-12 Lajiness.txt
"The design and impl,""""lIIt::llL~.:..ivn uf SAS 7942 as au .1Llformation system for the reg:i.t;ltration of volunteers at the Clinical Pharmacology Unit of Jefferson University Hospital is pres~nted in two parts. The first section describes the data base structure, updating procedures and report generation facilities. Concluding the presentation is a discussion on the instruction package and training given to the registry ~ys~em users. Following input from a minicomputer data entry and validation system; two record types are used to create the SAS files, with the first file containing information on demographic material of both former and current volunteers. The second file is dedicated to information generated from a ~linical trial, with each observation pertaining to a particular s~udy for a uniquH volunteer~ To facilitate the use of queries, at the c.onclusion of the update program to this data base a subroutine -is .called which. imbeds the most current clinical data into t~e demographic file. In this manner. for most queries only one file needs to be searched. Further simplification of query design can be seen in the use of macros to store all output formats, eliminating the time incurred in coding comple~ Dutput fo~ats using PUT statements. The presentation will end with a discussion on the instruction package given to all users which includes information on using TSO, a basic course in SAS(pertaining to query design)~ and a catalogue of allpredllfined reports and queries.",Sugi-80-13 Potter.txt
"STATUS REPORTS USING SAS Dagnlja V. Spuntel1s, Merck Sharp and Dohme Rahway, N.J. One aspect of pharmac~utical regulatory affairs The fi~8t step in solvin~ this problem is concerned with organizing and audltin~ 'Waa. to assemble as much relevant ln~ clinical project data which are to be used in formation as possible; the second, to decide ho~ to b~st organize tbe data dossiers submitted to regulatory agencies. ~en registratio~, such that manipulation would be subnitting a new drug for information .must be c~piled on the status faci1~tated. of all studies conducted on that project. For each project, clinical studies are conducted REQUIREMENTS following a prescribed protocol. When com~lete they are summarized domestically in a standard Outlining foreseeable requirements format~ the A to M summary. A to M merely de~ was a start. Broken down in system notes the sections. A~B,C.D ··· M of the summary. The A to M summary can be further classifi@d and information requirements, the i: ag either: SOLITARY; having the one study per most important of these seemed to protocol, INDIVIDUAL; a separate summary for be: each inve~tigator following a pa~t1cular protocol, System Requirements A. or COMBINED; which includes info~ation from all stGdies done under the same protocol. All 1. A simple input mechanism studies, including tbose cancelled or for which there are no data in bouse ~ must be accounted for. The SAS system described in this paper 2. Ability to add addi~ional waS used as a tool in organizing a large quantity study information (obser- vations) as new study of such DUlti-sDurce project data. numbers were assigned The ~articular project under discussion had been No underway fer a numbe~ of yeaTS and involved li~it on record and 3. ~~proximately 450 complete or on-going clinical var1abl~ length studi@s. This was B. formidabl~ amoun~ of infor- mation to orgainize much less manipulate by ~o 4. On-line access hand-log alone. The assignment required a information knowledge o",Sugi-80-14 Spuntelis.txt
"A MID-RANGE RAW MATERIALS PLANNING SYSTEM Patricia A. Hermes and Harold W. creech elBA-GEIGY corporation, Greensboro, NC I. BACKGROUND Intermediates for each plant and a This raw materials planning system was 2) total listing developed for CIBA-GEIGY's Agricultural a Division to help their Production Plan- 3) Raw materials for ~ach plant and a ning Cepartment determine the raw mate- total rials and intermediates needed to make listing~ their final products. Since many inter- It was also desired that the system be mediates are manufactured internally, it entirely user ~intained. Files could also enables them to estimate potential be maintained and requests for the plant capacity problems. necessary tables made through our opera- tions group. ~lthough cost was not a Primary products involved ,are herbicides, major consideration in the development insecticides and rnicronutrients. These of this system, it was realized that the products consist of an active ingredient system would be used more frequently if which controls the pest or supplies the the cost of producing reports was not nutrients to plants, and other inert prohibitive. chemicals which make the product easier for the user to apply.· Different formu- lations exist--wettable powders, granu- III. DETAILS OF THE SYSTEM lars, liquids, flowable powders, and aerosols -- which can be packaged in Because of the updating~ merging, and bags, can9, tank trucks or railroad cars. sorting capability of SAS, it was es- Customers range from the horne gardener pecially amenable to the development of with a small vegetable or flower plot, to the farmer who has thousands of acres this system. ?rocedure Format was used to translate codes to save storage space~ under cUltivation. Manufacture of these The system operates in batch mode with pesticides takes place at two major loca- card input on an IBM 3033 computer. tions in the United States and the pro- Macros~ contai~ing the program steps. duct line consists of roughly 40 pr",Sugi-80-15 Hermes Creech.txt
"A DIRECT ACCESS HETHOD FOR INFORMATION RETRIEVAL FROM SAS DATA RASES D. HO'sking, Frank C. DiIoriO', and Kenneth A. Hardy Jame~ The University of North Carolina, at Chapel Hill 1. INTRODUCTION PROC SELECT tak~s advantage of the fact that RAS diRk f[yc1llat dCltCl Flof'.tFl ~r~ rl i r-p.f'.t: .'H'_f'.oP:FlFI rl,qt<'l The capabilities of SAS as a data base man- sets (although no~ standard IBM direct access agemenc system aTe becoming well known. SAS pro- data sets). Unfortunately, the SAS user has had vides facilities for information storaze and re- no way of making use of this fa~t in forming trieval which are both powerful and easy to use. merged subsets. With PROC SELECT the user may However, in some situations, the standard SAS ap- employ direct access methods to simultaneously proach can be very expensive. In particular, subset and merge up to eight input data sets, when a small subs~t of caaes and variables is to forming one output data set. None of the input be selected from each of a number of large re- data sets needs to be sorted in any particular lated fil~s. SAS must process each of the large order, and only those blocks of data containing files sequentially at least once in O'rder to form observations to be included in the subset are the desired subsQt. In ord~r to allow such sub- read from the input data set(s). As is demon- sets to be extracted more efficiently, a SAS pro- strated in a later section of this paper, this cedure has been WTitt~n which uses dire~t aCFess -..ften results in cost reductions of over 75 .p~,r methods and ""keyHfiles and does not require se- cent in comparison with straightforward SAS ap-- quential processing or sorting of the large proaches. files. This approacb is tested using S~mulated data and shown to be a signifieant improvement Of course, in data management ""there ain't over tne usual SAS method for extracting such no such thing as a free lunch"". This increase in files in terrnB of computer reSDurces used. efficiency is",Sugi-80-16 Hosking DiIorio Hardy.txt
"MANAGEMENT AND ANALYSIS OF DATA FROM AN IN-USE FUEL ECONOMY TEST Gwendolyn H. Walton, Oak Ridge National Laboratory analysiS of fuel economy. Because the computa- Research has indicated that. even when all tion of miles per gallon (M~G) for a given ob- other variables are controlled, significant varj- ations in fuel economy exist which can only be servation i depends on the odometer readings of ascribed to the driver. Although several stud- observations i ~nd ;-1 ~ one cannot merely delete ies have been done to determine whether appro- an incorrect observation from the log data file. priate educational technique, could improve the Also, when the odometer reading or gallans con- fuel economy of the average driver, most have sumed is far out of line far no apparent reason, one cannot merely substitute a data paint based been tests of a small number of drivers con- ducted under very controlled conditions. While 01) an average MPG number for the vehicle unless the data from such tests is easily analyzed, the the computation of the average MPG does not use ""bad~' conclusions often cannot be generalized to actual One sohlt;on to this the data polnt. problem is to use the following type of algo- ~aper driving conditlons. In contrast, this discusses some of the problems a researcher may rithm to compute ""average MPG"": encounter when attempting to analyze data from a Let ODOM ' odometer reading, large test to determine the effect o~ driver GALL ga110ns consumed, ~ awareness training on the fuel economy achieved index for observation number, i = during on-the-job driving of company cars. K = index for vehicle; and · ~ symbol far missing values. Management and analysis of data from an in-use test poses special problems~ and the test re- For a given vehic:e K, sults are often difficult to quantify. However, results from thjs type of test can give an indi- _OD_O_M~K,.,:i,"",-..---O_DO_M""""K.!..,ic:--,-l cation of whether driver awareness training can MPG K, i ' GALl , i actually",Sugi-80-17 Walton.txt
"strlctions in the use of the FORMAT statement and the sort order of the labels in BY state- In complex studies using multip1e data ments or PRINT requests can be circumvented by bases composed of hierarchical file structures. using the PUT function to assign format values there is a high probability that errorS may be perpetuated into summary reports unless some to a new character variable. Furthennor~ an algorithm to convert format values of a nOn- form of quality assurance is integrated into SenSe code into a new nonsense numeric code for the research data base management program. In subsequent sorting would increase sorting effi- studies that substftute numeric codes for ciencies when long alphanumeric format vaJues variable values, this problem of error ~ropa are to be sorted and subsetted. This algorithm gation is even 1I10re acute. This paper add.ress- should be addressed in the next version of SAS. es the problem of error propagation in those studies employing a coding scheme to re~resent longer alphanumeric values.",Sugi-80-18 Farrell Strand Magoun Pennington Schramm Cobb Daniels.txt
"litter size, 3) seasonality of births and deaths, 4) longevity in captivity, Over the years, basic life history data 5) proven breeders and their current (e.g., date of birth and death, parent- location, and 6) age distribution of age and sex) of several subspecies of the captive population over years. This leopards has been maintained manually is only a partial list of potential in studbooks. A studbook is basically information in a studbook. Clearly, a list of animals that are or have been computerization was required to fully in captivity~ Using SAS, information exploit the data in the studbook. SAS such as age of first reproduction, was used to accomplish this task because seasonality of births t average litter of its data manipulation, graphics and size and age distribution of the captive report writing features. Studbook data population over years have been calcu- can be entered into the computerized lated. This data is helpful in International Species Inventory System managing individuals in captivity and {Seal et al. 1 19?6}, but a limited evaluating the status of the entire number-of-reports are available. captive population. The objective of this paper is to demonstrate that by usinq just a few",Sugi-80-19 Sharlin.txt
"atory U~iversity of South Carolina ABSTRACT The information system consists Df two main phases. Data entry and the generation of The purpose of an information system is to appropriate descriptive statistics relevant for provide decision makers with facts relevant to eva.luation are possible through a VS BASIC important issues~ The generation of this program and a set of SAS procedures respectively. crucial information usually requires individuals The interface between the compilation and de- with 8pecia11zed training in data entry. The scriptive phases of the system is provided by present paper describes a user-oriented inter- the Command List (C-List) processing mode active information system. Utilizing the Com- available through IBM's Virtual Storage Personal mand List (C-List) facility in Virtual Storage Computing (VSPC) system (IBM, 1978). The C-List Personal Computing (VSPC), input processes are facility of VSPC, therefore, provides the over~ simplified and pertinent statistical infor- laying structure. within which the VS BASIC mation is provided. program is run l the appropriate SAS procedures called and the input information is added to a The input program. written in VS BASIC, cummulat1ve. master file. It should be empha- creates a raw data file appropriately formatted sized that it is the C-List facility that for use by SAS. Through SAS~ the new data file allows the components of the information system is merged with a master file and the desired to act as an entity",Sugi-80-20 Rumpel Forsyth.txt
"IMPLEMENTATION OF AN AUTOMATED SURVEY CONTROL SYSTEM USING SAS Morse F. K.,<ilt Research Triangle Institute An impo~tant feature of survey operations Description VAP. at the Research Triangle Institute (RTI) is the maintainence of a system that can ef£ectively Respondent Identification Number ID CKDIG provide project staff with information concerning ID Check Digit the progress of study participants through the Individual's status on Questionnaire 1 S1'ATUSl various sta-ges of the survey process. For s.imple DATEl Date on which STATUS] was attained Location of Questionnaire 1 in RTI BATCHl operations with relatively few respondents and storage (batch #) only one document for each, manual check-in and STATUS2 Individual's status on Questionnaire 2 tracking procedures are $enerally sufficient. as the size and complexity of samples DATE2 Date Gn which STATUS2 was attained However~ BATCH2 Location of Questionnaire 2 in RTI and the number of documents associated with each parti~ipant storage (batch #) increases, an automated system be- comes a necessity. In response to this need, a lndividual's status on Questionnaire 3 STATUS3 series of programs was developed at RTI that DATE3 Date on which STATUS3 was attained BATCH3 Location of Questionnaire 3 in RTI permitted computerized monitoring of survey activities~l The software, while applicable to storage (batch #) surveys of any size and level of cD~lexity, was designed for large-scale studies, and as a result, it~ use in smalle~ efforts was rather cumbersome FIGURE 1. CONTENTS OF SAMPLE CONTROL FILE. and CQstly relative to the benefits derived. Therefore, when it became necessary to adapt the tional members are included in the sample, new existing programs for use on moderately sized projects (fewer than 10,000 respondents), alter- records are added to the control file. native approaches were considered. Of these, a SAS-based system was chosen, largely because of Between the time a questionnaire is distri- buted to a resp",Sugi-80-21 Kalt.txt
"SAS AS A CENTRAL STATISTICAL SYSTEM Peter Beutel, University of Heidelberg produce anew a proper data description I. Introduction for the further used system. Scientific computing centers are freq- uently confronted with the problem that their users must simultaneously work II. A concept for the linking of systems with different statistical systems, in order to fulfill the needs of proper Stimulated by the plenary discussion at data analysis. Therefore, the University the COMPSTAT meeting in 1978 (Leiden, Computing Center of Heidelberg offered Netherlands) of the five general statis- its users in 1978 the following program tical systems BMDP. GENSTAT. P-STAT. SAS packages! the general systems BMDP, and SPSS 1 the author developed at the OSIRIS, SCSS and SPSS, and the more spe- University Computing Center of Heidel~ cialized systems ALSCAL, CLUSTAN, berg (IBM 370/168, MVS) a concept for MULTIVARIANCE, NONMET, TEXTPACK and the linking of analysis systems, in ZUMAPACK1 furthermore, SOme stand-alone- order to reduce the mentioned above programs for test theory, factor analysis technical problems of the users. The cofiguration frequency analysis, Box- basic idea of the concept is to call Jenkins-method, and linear models. In from a central analysis system all the addition to these analysis systems and other systems and stand-alane-programs. programs our Computing Center offers Furthermore, access to the data bases of for scientific applications the data a data base system should be possible~ base system RAMIS. The data exchange bet- ween these systems is shown in diagram I. From these demands to the central system it follows that this system must have certain system technical features. Such Desintegrated System Constellation features are: the system logiCt the set of comrnands t preparation and management of data, and the strinsenCy of the sys- tem. Purther.more, such a system must con- tain the basic statistical procedures. Stat1d AloneProg.: The most important demand",Sugi-80-22 Beutel.txt
"SAS AT THE PHILA. PED: SEQUENTIAL, HIERARCHICAL AND RELATIONAL DATA STRUCTURES JILek Siler, Philadelphia F""-al Reserve Bank Introduetion b} The user- executes a TSO Command list request by the Economics Research A giving the dates and banks of interest. Department first brought SAS to the Philadelphia e.g. exec Brassets date (19a~Z4 190131) Federal Reserve Dank. It was to be used primarily baak (031800011) for data transfer, editing and organization, c) The C-list edits a SAS program, calculation of summary statistics, and regression incorporating the specified criteria. analysis. SAS was successful in these jobs and it data sets are The 9.[Jpropriate was soon noticed that there were applieatiOtlB for allocated, the SAS program is executed SAS in other areas of the Bank. The Computer under TSO and the report is printed Services Department has used it to analyze System at the user!s terminal. Monitoring Function (SMF} data for machine CommWld lists are currently available for efficiency information Wld to Wlalyze disk catalog balance sheet information, 5QurC!'es and uses of funds, data for data set storage and organization 1)nd financial ratios. Figure 2 shows a graphical information. Other departments that benefit from summary of financial ratio information - the six SAS are Operatlorn; Planning and Research, reporting banks can be compared at B. glance, the StatistiCS, Credits, Supervision and Regulation, and range of the weekly ratios for the year is shown Accounting. for each bank and the most recent figure Cor each In tnis p.~er I will describe how SAS is used bonk is highlighted. with two major systems developed by the Bank -the Integrated Statistics System (ISS) and tne Integrated BAS And The Integrated Aecoonting ~em . Aceounting System (lAS). The Integrated Accounting SystemlAS) keeps track of all transactions at the Philadelphia Fed. 8AS And Tbe Integrate<! Statistieal System These include check processing, coin and currency Federal Reserve Banks 'COllect",Sugi-80-23 Siler.txt
"ed Instrument$~ Dallas> Texas c. Willian! Cox. Jr. Texas Instruments, Incorporated Dal1as~ Texas ABSTRACT are inpatients in mental hospital and iii are being seen a staff member f~cm by the community mental health center, r~lies V~rU WbBn an institution ~utpati~""t ·· other clients are strictly he~vilg its ~eporting on 5AS for some ar~ parti,~pants in ~pe~ial and the qUlistion a-risss as to l'equiT""~ments~ as g~OUp5 ~etard~tion such mental the efficiency of SAS compared to a high and Communit~ ssrvic~ clinics. l~v&l p~ogramming language. It is educat~on ~~ ~l~o prcvid~d a by obviQUS that the ease 0' generating community ce-nteT'. mental health with BAS output utililing its ThereToTe it is diTficult to design One fC1""'matting. merging, sQrting and collection ~hich appli~5 to a~tR ~o~m (ap~bilitie5 is ver~ 9~Dnomical jn the all typ~s of tTeatment and sET'vice. In short l""un< S-AS is also economical when addition to form design probl~m$. output output will require m~ny periodic fermat design ffiCimmoth ts""5k. Many i5 aJso a How~v~r, th~ pTQgrsmming changes. if diffe~ent and unrelated questions need requirement~ ar~ ye~g co~pl~x, r.~viTe to be answered. lnPorm=ti~n aggregation much data manipulation~ and will bE' -u$ed One solution could becomes essential. period of time~ ~ program over a long be to build a data base of all wTitten in a high l~v@l languaQa might infomation collected an clients and then be more ~f'icient. query this data base for each peice of This can prove to be",Sugi-80-24 Deitz Cox.txt
"SCIENTIFIC DATA MANAGEMENT AND ANALYSIS Organized and moderated by Dr.- John J. Frey system INQUIRE was initiated during 1978, after Ffizer, N. Y., N. Y. several man-years of INQUIRE development. We used INQUIRE during 1978-79; however, we also AGENDA began to utilize SAS for data base management. It may af interest to note that our first SAS 1. Overview of Clinical Data Processing and job was executed in September of 1978. Analysis at P£i~er, New York - John J. Frey OUr experience with INQUIRE has been less than 2. SAS and High Lev8l DBMS in Clinical Data satisf~ctory and an analysis of certain aspects Processing GeOrge Griffin and John J. of this will be'presented in the next paper. Frey Therefore, we are embarking on a conversion effort which will use SAS as the primary data Interfacing with Various Software - 3. SAS base manag~ment system and will also use a John McKenna mini-computer for certain aspects of data base 1T'.anagement~ SAS Approaches for Formatted Tables - 4. Steve Dassin Figure 1 5. Open Discussion Further discussion of preBentati~ns Main Frame Usage An exchange of information on experiences % OF WORK with SAS in scientific data management: ~-------------------------, advantages, disadvantages, limitations, etc. 100 OVerview of Clinical Data Processing and 1. Analysis at Pfizer, New York - John J. Frey DEC- lO These presentations a~~ being made by staff members of the Statistics and Data Analysis 50 Department of the Pfizer Pn~rmaceuticals and Diagnostics Products Div., Pfizer lnc., N.Y.C. We are primarilY involved in cltnical research applications for new drug developmant and support of our marketed pharmaceutical prod- ucts. T~is entails statistical involvement throughout projects, including p~otocol design. YEARS case report form development and consultation during the studias. We ~re a190 responsible for data input f~om our clinical case record forms into our data base, for clinical systems for th@ data base, for statistical data pro- cessing",Sugi-80-25 Frey.txt
