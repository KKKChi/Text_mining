text,name
"F PROBABILITY PLOTT ING IN SAS Daniel M. Chilko, West Virginia University Gerry Hobbs, West Virginia University E. James Harner, West Virginia University Intr'oduction EBr charts or histop.:rams are th~ simplest and most fr~quently used ~raphlcal representation of data. reveal many oroperties of t~e data They th .. ra~ge of ~~ta values, the number of modesl whether the distribution is symmetric or skewed, th~ existence of outliers. Although bar charts reveal the g~neral shape of the distribution, it Is sometimes difficult to determine w~ethp.r or not t~e data can ~e viewed as a sample from some hypothesl~ed distribution. ProbabilTty plots arp a ~raDhical reoresentation of data that focus on the dIstributional aspects of data. Bar charts are easy to f'troduce in SAS usin~ PROC CHART and PROC GCH~RT. Prohability plots are also easy to produce using SAS. Probability plots A random varlable, x, is characterized by its distribution function ~r e~ample; the graph of F{x) for a Normal Distribution Function 0.9 0.' 0.' o. , random .variable with a standard normal distribution is shown In Fi~ure 1. This ~raDh can he turned Into a stral~ht linp. hy transformi""~ the x axis to F(x) (hoth ax.es woulrl be probabll ities) or by transformln~ the ~(x) axIs to x (both a~es would he quantities). A samnle rl'istributTon functTon can be oroduced in SAS using PROC RANK with the PERCENT option and PROC PLOT. See Fip;:urF. 2. For data from symmetric distrihutions l this function is characterTstically S-sha~~~ and its point of inflection makes it difficult to work with. If the orobability axis ls transformed,. thp. plot is now a pro,"",ability plot. That is, a prob~bility olot scales the probability ~xis of a sample distribution function accor~in~ to some probabt, ity distribution such that, if W~ chosp. thp correct distribution, the resultin~ plot is ~orp or less a straight linp~ Sample Cumulative Distribution Function f'EHCE.HT 100 ., 00 70 • ""' • 50 I C.5 "" 0, • .0 0, , 20 0, z kO • 0.1 D",Sugi-81-02 Chilko Hobbs Harner.pdf
"COLOR GRAPHICS HARDWARE; REVIEW Morris L. S~it, Polaroid corporation One of the most talked about and written about Bubjects of 1980 in the computer industry was color. The emer­ gence of coler as a useful tool will continue in coming years. The use of color display terminals and color hard­ copy output will become commonplace. . As IBM states in one of their bro­ chures, color can Rrovide us with important ~nformat~on. This is a,suc~ cinct reason for color use and its benefits. The reasons, of course, can be expanded, but color is important if it provides information. VISUAL PERCEPTION It has been calculated on the basis of neurological measurements that about 38% of all human sensory input is delivered through the visual mechanism. We obvi­ ously uSe our visual mechanism to receive and recognize data, even graphi­ cal data, differentiating objects by their size, shape, texture, etc. On computer displays, we differentiate items by blinking~ underlining, font changes, reverse video, etc. It is natural then to add color to this visual input. WOrk by psychologists and others involved in perceptual experience into the proper use and psychological effects of color, indicate that color is a com­ mon experience descriptor. Similiar descriptors include shape, size, position r texture, - function I etc. Color is just Qne of the many descriptors we use to differentiate objects in our environment. While it is generally accepted that color images are more pleasing to the eye, are more rapidly understood, and are capable of providing more informa­ tion, there is an increasing need for more work to be done relating the use of color to business graphs and the decision making process. color leaves a lasting and definite impression reqardless of the accuracy of the data presented. A 1975 study by Richard E. Crist of the Department of Psychology at New Mexico State University concluded that color may be a very effective performance factor under some conditions, but that it can be de",Sugi-81-03 Samit.pdf
"THE ROLE OF SAS IN INFLUENCING MAJOR TRANSPORTATION DECISIONS FOR A LARGE PRIVATE EMPLOYER Robert E. StamDer, Jr. t Transportation Center~ The Un1v~rsity of ~ennesaee Introduction Ihis paper describes the valuable applica­ tions of t.he Statistical Analys.:ls- System (SAS) in relation to a ~ajor transportation atudy tor the Union Carbide Corporation-Nuclear Division (UCC-ND) of Oak Ridge, Tennessee. A recent study performed by the Transportation Center of The Un~versity of Tennessee with the a~sLstan.ce of The Computer Applications Division Q£ OeC-ND accomplished the following objectives~ l. 2. 3. Inventoried existing transit services within and bC!!tween three UCC-NO plants; Monitored the travel patte~ns of approximately L,lOO company vehicles for one month; and Recommended trans~t improvements and fleet management strategies to trans­ port employees more effectively and economically and to conserve energy. The computer analysis used to accomplish these objectives was performed entirely by SAS. Procedures such as GCHART, FREQ. MEANS. PLOT, and others were used to present simple statis­ tics,8nd detailed g~aphics which were concise and-informative for management. Through these techniques 1 SAB has proven to be an effective facilitator of applied research in the increas­ ingly important area of transportation for private industry, while also serving as an effective managerial tool for transportation de­ cisions. Applications of SAS/GRAPH are parti­ cularly informative to management since color slides from SAS/GRAFH simplify data analyses and presentations while vividly portraying transpor­ tation facts in a very dlscernable format~ Background Information Transportation and related energy problems are not confined merely to public agencies or 1ndividuals. Employers are faced wi~h increas­ ing pressures to transport ~erHonnel And mate­ rials efficiently and econamically. Providing these transportation services is further compli­ cated by the rising costs and reduced av",Sugi-81-04 Stammer.pdf
",' ~' A SI.S IIOIlTIlII! FIIK IIDDInDIC 1'111! 0IITPIJr 0""' PIIOC CIWIr to IlEET SPECIAL BRl'OIlT BEQtJI1Il!HEIIrS Vill~ TayloT. Bla.etTic lesearch ln8tl£u~e •. Ine. 1. Abstract. A large medical device clinical trial requires reports to the Food and Drug Administ1""ation (FDA) concerning th~ safety aDd efficacy of th~ device under study. Thsge reports are frequent and must be clearly docum.ented and titled to be easily reviewed by the staff. FROe CHART c.an display informat.ion both in tables and graphs. 'ntis feature lends itself well to satisfying medical device trial repo~tlng needs. The output from PIlOC CHART contains all necessary numeric: infonoation, although a different format was desired and mora labels were necessary. The output from the procedure Ws directed to a file using PR,{)C Pll.lNtTO. A SAS program. then read this file and modified the print linea, adding vertical labels, page numbers. bla.nking c,\lIIIulatlve percents and frequene.iea and repeats of group variable values, and adding a. percenta.ge scale at the top of the. bar chart. The modified output was printed usiug a Xerox 9700 laser prin~er creating an acceptable fonnat that could be directly entered into the report. The modification of the out-put into an acceptable 1;'epot""t forma.t saved t.i..me and reduced errors that would. have lIkely occurred 1f the Slame report had been manually prepared. This paper describes the program used to modify the. PROC CHART output. 2 • Ill. t-roduc t.100. To detemlne the safety and efficacy of medical devices. the Federal Investigational Device Exemption Regulations require a clinical trial invesl;.:lgation. FDA exalllinas the results of these clinical trials to approve the device for: general public uSe. Pending this approval ~ all pot.i-@ut.s who receive a medical device must be followed and report.ed on periodically as part of .8 clinical study. To expedite the approva.l process, the presentation of data and an.alyses to FDA mcuat be clear, concise, and",Sugi-81-05 Taylor.pdf
"A SAS program is given which determines from a set of points representing animal sight­ ings or locations, the boundary points of the animal's horne range l computes the area of this home range, and displays the home range plot. The determination of the boundary points, points which form the convex hull of the observations, and the computation of the enclosed area are accomplished within a macro (RANGE) using PROC MATRIX. Graphical representation of the obser­ vations and home range are produced using PROC GPLOT. Illustrative examples and program listings are presented.",Sugi-81-06 Hill Grimes Krasner.pdf
"SASGRAPH HADE. EASY - AN INTERACTIVE APPROACH Robert F. Kramer, FMC Go~P~1 Industrial Chemical Group Sumi Kobayashi, FMC Corp., Indu.trial Chemical Group The in13tallation of a new oof'tware package can be a diffioult task in any. organization. During the inotallation phase, many technical problems can arise. The problems can comp11- cat. the in.tallation, but eventually, the system i5 ready for use. It is at this point that an even greater problem surfaces: achieving user acceptanoe. The factors that affect user acc.eptance are varied and may differ from one organization to the next. Two factors that aid in achieving user aceptance involve establishing and maintain­ ing the interest level of the user, and offering a system that i. easy to use. During the past year, the interest in computer generated graphics has increased significantly, particularly with the financial, marketing, and sales departments. Graphics moe viewed as an effecti-ve method of visualizing and repre­ .enting information thst might otherwise be reviewed by reading through a voluminous report. Management views graphics as a viable way of analyzing results and trends in a manner far lese time consuming than that of reviewing large reports. With this in mind, establishing and maintaining the level of the user COfIEunity was not a problem. Rather, the opposite was the ca:se, users wanted the graphs immediately, if not 5OOner~ The second fector affecting user acceptanoe deals with the ease with which a particular software- package can be used. Users have traditionally aVQided t or completely refUsed to get involved with, any ""program develop­ ment"". The fear of operating various terminals and the fear that they will do sometbing wrong with the software account for some -user's refusal to get involved. Others feel that thi. i. a waste of their time. In order to reduce the apprehension on the part of the user, MIS professionals must offer an alterna­ tive that 1s both technically sound and easy to use.",Sugi-81-07 Kramer Kobayashi.pdf
"RDBUIIJ MDDElJNG OF DATA USING moe MATItIX E. Jamellihrner, West Vrrginia Uni~rslty Ronald n King"" Morni.nJlside College Anthony A. BillingS, West ViIgiI1ia. University INTROOOCfION Regrei3lon, dbcrimJni!J.t, and principal oompone:nt analyseR are .among OW: mod u&8ful statistical tools for modeling data, Unfortun:nely the diIItrlbution of estimatots, as olass.ica.Ily defined, are often highly sensitive to deviations from the assumed underlying population model. The major diffICUlty :is due to statistical Ol,ltlieJ1 whic1t are -cau&ed by long-tailed distribution~ or are dmply bad data observations. lncreasinsJ.y, sta.tisticians- are becoming concerned about the effectll of outlier:!. However. these data po-intI are often difficult to detect if the number of variJblello jointly oo~dered ~ gn:.ater than two or three. Robmt techniques currently being developed offer an objective approach to detennining alternative models whi-ch are far leu. sensitive to outlying (influential) dala poinu. Unfort~nately. lhe nece;swy computing algorithms for these andyses are not readily lvailable. ]n this paper we present two PROC MATRIX I""""gams which help to fill thl. gap. The e:otimaton available in the 00 programs are generalizations of maxirnwn likelihood estimaion. In the literature they are .cilled M- est!­ matan to- diltiriguish. them from' otner cluses of robust estimatDrs. Eo"" (1979) gLves a lucid description of the principal robust meth(ldologies. The :fnl program handles multiple regression models. Th.e 8econd performs prlndpal oomponent and .d.iacrimirlant analyses:. li'l both pt08rams various methods of estimation are employed u wcl1 as variQ'U.!S- mean. of llSSe!llllng the !rtabili1y of these estimators. ROBUST REGRESSION The robdst l'egressi()D program lus a mabl conhol mod\lle and thtce oomponent modules.. This- design gives the user grea.t flexibility in choosing the- desired options. The speclficatlon of OptiDIIS f a description of the program, and the available output",Sugi-81-08 Harner King Billings.pdf
"er the past two years of Anno­ tate~ Computer OUtput for a number of analysis of variance routines has ~evealed situations whe~e linear mcde~ calculations for unbalanced data are sometimes a littie surprising or, at best, some­ what difficult to understand.. Sucb situations are illustrated with (i) faults in ion al<!orithm for repar~t~rizing with E-restrictions, (Ii) surna of squares rOT E-restricted models, (iii) least squares means and (iv) estimating variance components. L IN'IRODUCTION The recent preparation of JUlnotated Computer output (e.g., Searle et 0.1., 1978, 1980) for. variety of statisticalcomputer packages bas highlighted c~~ain quirks in linear mode2 calcu­ lations with unbalanced data (date. having uneg,ua.l numbers of observations in the subclasses). Awareness of these quirks provide! a basis for understanding relationships among output ootained from processing the same data on different com­ puting procedures. This paper illustTates some of' ""these relationsh.ips. The illustl""atione al'e in terms 01' the two­ way cross-classification model, specified by two factors which shall be called rows- and col:wrlns. The model equation is either or where E(Y ijk ' is the expected value, OYer re~ peated sampling, of the k'th observa.tion, Y. ''1..1 "" 1J.fi."" in the i'th row and j'th column of the data. In both (1) and (2), ~ i • • general mean, 0:. i. the 1 effect due to the :i 'th row, for i ~ 1, ••• , a, and e j is the effect due to the jlth column, for j = 1, .~', b",Sugi-81-09 Searle.pdf
""" ~ , 'Hissing Data in Kutivar-iate Linear Models: A Comparison of SeveraI ""Sstimation Tec.hniqllB.s James D. Hn8king~ University of Nortb Carolina at Chapel Hill INTRODUCTION One of the DOst common problems statistics is the issue of how to in applied dll!""l with ""mls&lng d.ata."" I'he term ""missing d.ata"" helll been uRad to daseribe a vast aS80rtmsnt of topics, same of which are only distantly related. The c~ae considered he~e involves: 1. missing values only in the dependent variables with independent variables assumed to be fixed, 2. ~alueB missIng at random. and 3. normally distrIbuted dependent variablaa. SpecIfically, the topic ~f this paper Is a com­ parison of alternative techniques for estidatiQn in the General Linear Multivariate ~del (GLMM) af full rank and wItb normality assumptions When some of the dependent variable vectors have some co.ponents missing at random. The standard tecbnique for dealing wi~h missing data of this type is what will be called ··liBtwise de.1etian,"" that iB, discarding any observation containing one ot more missing values. When the data ar8 missing at random, using listwiae deletion will not bias the estimates of the GLMM parameters! and!. However, listwise delQtloa invol~as dis­ carding informatian (contained 1n the obsetved componente of the incomplete vectors) which-may be useful for improving the precision of the es­ timates and the power of testa. This study focuses on three other techniques which nave been proposed in the last 10 years. These appear to be the only eecbniques applicable to the situation described above which have been proposed on ana1ytic t rather than heuristic grounds. The th~ee techniques we~e each deBe~ibed in a pair of related a~tleles~ 1. Hocking and Smith (1968) and Hartley and Rocking (1971) 2. Yoodbury and Ha ••• lblad (1970) Bnd Orchard and Woodbury (1972) 3. Kleinba ... (1970, 1973) Each of these pairs of papers prQSent8 a dif­ ferent approacb to the problem, And demonstrates various desirable pr",Sugi-81-10 Hosking.pdf
"Services is the necessity to produce and present short COurses which acquaint users with a variety of topics. Often times, these courses must be prepared with a minimum amount of time and expense. Utilizing the color.graphic$ capability of a Compu­ color II microcomputer and a 35 mm slide camera expedites this process both in terms of effort and expenditures. The Compucolor II, utilized in a local terminal mode, permits the produc­ tion of multicolor screens by persons with little or no ·programming knowledge. The screens are saved on 5-1/4"" floppy discs which allows immediate recall to photograph all screens which have been prepared during the session. Recall at a later date for modification of informa­ tion or design (and subsequent rephoto­ graphing) is also possible. 555 During short course teaching, it has been found that color slides enhance the transfer of information. While the slides are currently utilized as support for instructor taught short courses, plans are underway to prepare cassette driven presentations. Thus, users will have an opportunity to receive fundamen­ tal information without requiring addi­ tional staff support. Also, users will be able to view and review material as their needs dictate rather than only during scheduled short courses. Short courses utilizing the color graphics slides have been assembled covering such topics as: keypunching, Job Control Language (JeL), SAS, SPSS, Harris VULCAN, ahd Introduction to the Computer Center.",Sugi-81-100 Peeples Ticknor.pdf
"SAS macros are present;::d for computing matrices of several measures of similarity between ecological communites. Input data are read from a standard format matrix containing the number of individuals of each species (rows) in each community sample (columns). Calculations for Spearman's rho and Kendall's tau rank correltion statistics include all and only species which are present in at least one of the community samples for each pairwise comparison. This differs from PROC CORR, which includes all species present in any sample (with zeros in data) or only species present in both samples being compared (missing values in data). The basic macro structure is easily modified to compute other simple measures such as percent similarity. The normalized expected species shared (NESS) family has been proposed as a set of similarity indices sensitive to rare species in small samples, Another macro applies a two-sample jackknife technique to reduce small sample bias of the NESS estimators and to find variance estimates for the NESS similarities.",Sugi-81-101 Rinehart McCreight.pdf
"~, USING CMS SAS IN CONJUNCTION WITH IBM'S SYSTEM R RELATIONAL DATA BASE MANAGEMENT SYSTEM T. J. Vidmar and J. P. Maile, The Upjohn Company, Kalamazoo, MI USA One of the research units at The Upjohn Com­ pany experienced a problem with the large amount of time it took to analyze data generated from their research animals. In order to reduce their dependence on the statisticians and programmers a eMS EXEC was written to allow them the ability to process and analyze the data in a matter of min­ utes. The user need not have a knowledge of the workings of IBM's System R Relational Data Base Management System or knowledge of writing SAS programs. The user must, however, be familiar wi th some bas i c CMS commands, know how to use the Upjohn full screen editor which is available for editing CMS files and also the ability to inter­ pret the statistical output. The ""realu system begins with the drawing of a blood sample from a research animal. This sam­ ple is labeled with the animal identifier number, the experiment number, and other informati on re l­ evant to the study. The sample is then sent to the Upjohn Clinical Research Laboratory for anal­ ysis. Upon completion of the analysis, labora­ tory personnel enter the results into a System R Data Base which resides on an IBM 370/148 com­ puter. A hard copy report listing the results for each research animal is generated and sent to the resea rcher . An abbreviated example of the animal data in the laboratory data base can be seen in Figure 1. This listing includes only those values which are of interest to the researcher; all other values are ami tted. To use the EXEC, the user must first log to his/her VM computer. After the logging procedur~ the user enters ""RATS"", the name of the eMS EXEC which was created for the user. This EXEC uses terminal prompting to guide the user through the various routines. A few system messages will be displayed on the terminal, followed by the ques­ tion, ""DO YOU WANT TO RETRIEVE A NEW BATCH",Sugi-81-102 Vidmar Maile.pdf
"es Division Oak Ridge National Laboratory ~BSTR!\CT The complexity of regional water management problems necessitates the summarization of water resource data in a form that is easily analysed visually. Computer generated maps are well suited for displaying complex relationships since they are easy to create and modify and are relatively inexpensive compared to traditional techniques. Development of new display techniques creates questions about the most effective display of data used for generic assessments. Recent attempts at displaying bivariate data geographically have not been entirely successful due to numerous data categories and complex color patterns used in Ilcross"" mapping techniques. This paper offets an alternate method of displaying bivariate data which uses the degree of differences between two variables (e.g., water supply and water demand) to create a scale in which shades of two primary colors are used for positive and negative differences while a third color is used for the null case (i.ea, within the confidence limits of the statistical model) • *Research sponsored by the Office of Health and Environmental Research and Office of Environmental Compliance and Overview, U.S. Department of Energy, under contract W-7405-end-26 with Union Carbide Corporation. Publication No. 1702 Environmental Science Division, O.R.N.L. INTRODUCTION The complex problems faced in regional water management require geographical display techniques which provide information about sev",Sugi-81-103 Waterhouse Farrell Strand.pdf
"TIlREE APPROACHES OF DEVELOPING SUMMARY SOFTWARE IN SAS Frances Wilson Texas Instruments Incorporated Summaries of ""MEAN"" statistics over different combinations of BY variables are often needed in report processing and generating. SAS is an excellent language for calculating such statis­ tics; however, significant manipulation of data often becomes necessary to develop a dataset in the form needed for actual printing of the report~ Especially, when reports must be pre­ sented in a form consistent with pre-SAS gener­ ated forms. Three major methods of writing summary software were identified in attempts to better handle the data manipulation. The purpose of this paper is to discuss the usage, advantages and disadvantages of these three approaches. Approach number one is a straight forward approach to the problem. The programmer uses multiple PROC MEANS with appropriate BY variables to generate the statistics. Then he must perform multiple SET's and }1ERGE' s until he has a data­ set that he can uSe to produce the desired out­ put. Approach number two involves a subtle trick to the SAS MEANS. Records are output for all desired combinations of BY variables using dummy values for summary combinations. Then, a single PROC MEANS with only one set of BY variables need be executed. The result is generally a dataset that is usable for output generation since the dummy values are assigned with the report form taken into consideration. Approach number three is the usage of the FROC SUMMARY developed for SAS 79 in place of the PROe MEANS. One SUMMARy can replace multiple MEANS. The PROe SIDIMARY allows summary statis­ tics to be calculated over different combinations of variables without requiring dummy records. After execution of the PROC SUMMARY a SET is usually required to pullout desired combina­ tions. All of the above approaches to summary software have good application. Time, cost and software readibility are all important considerations in their use. Example problem: gi",Sugi-81-104 Wilson.pdf
"I I A TRIAO OF SAS MACROS TO CAPTURE THE OUTPUT FROM PROC GLM Roger S. Cohen Research Triangle Institute One -of tbe current 1 imitations of SAS's GLM procedure is the difficulty of using the statistics produced by that procedure in subsequent programming .. This paper introduces a triad of SAS macros which capture the statistics generated by PRDC GLM and place them into appropriate SAS data sets. We begin by setting forth the basic design of the macros. This is followed by a description of their usage in a program. Finally, some practical applications are highlighted. PROC GLM does not allow the programmer to retrieve many of the GLM statistics which appear on the printtout. These statistics must be read as data directly from the GLM output itself. The triad of SAS macros reads the GLM output into SAS data sets as follows; 1) the macro GLMOUT1 invokes PROe PRINTTO to direct subsequent output to a temporary OS data set instead of the printer. 2) PROC GLM is run. 3) the macro GLMOUT2 causes the temporary OS data set to be read as da.ta ~ Wi th jUdicious use of inpu~ statements, fields are identified, glven variable names, and placed into SAS data sets~ 4) optionally, the original GLM output may be printed by using the macro SPILL. which copies the temporary data set to the output file. This approach is merely an extension of an example given in the SAS Usert S Guide 1979, p.. 356. In that example, only one statistic, the mean squared error was captured. The macros described herein capture all of the statistics produced by the basic GLM procedure together witb most of those produced by the LSMEANS statement. Figure 1 demonstrates how the three macros are used .. The program in Figure I performs PROC GLM, prints the standard output, and then prints the contents of the SAS data sets containing the GLM statistics. This program provides a test of the macros and is recommended as a way to aquaint the user with the names assigned to all of the variables. The reader should n",Sugi-81-105 Cohen.pdf
"The use of the data management capabilities of SAS to effectively inde~ a reprint file is described. Publication data, key words and subject classification codes are stored on a SAS data set, with one observation for each reprint. Two programs~ one for updating the index, the other for retrieving references of interest, are described and displayed. A minimal time investment is required to develop and maintain the system. In addition, updating and retrieval use very little computer time. Although the particular application described is best suited for the needs of a statistician, only minor modifications of the general method are required for other uses. 1.",Sugi-81-106 Davis.pdf
"t : , , ~ I I I I I , CONTROL CHARTS WITH SAS AND TSO Dale F. Kraemer and Judy A. Stober U.S. Environmental Protection Agency Health Effects Research Laboratory Cincinna'ti~ Ohio INTRODUCTION Statistical quality control chart tech­ niques were originally developed in industrial settings to provide a quick yet efficient means of monitoring process control. Control chart techniques are now commonly used in a wide variety of research and production situa­ tions. The basic technique for control charts is to take a sample from a process, compute sim­ ple statistics, and then plot the reSUlting statistics on charts. The position of such points relative to predefined limits on the chart allow inferences to be drawn about changes in the process. In addition to ease of use and ease of interpretation, control charts are also an historical record of the ptOCBSS quality. More complete descriptions of control charts may be found in statistical quality control texts such as Burr, Duncan or Wetherill. SAS and SAS-GRAPH are used through TSO to set up very simple interactive sessions for entering data, displaying data and printing or ploccing control charts. Through TSO CLISTS and SAS MACROS. this automated system can be operated with little training by the tech­ nicians in charge of the process. The same automated system can ~e used by supervisors or managers to check short term or long term process control. The full control chart history is also readily available for process checks '"" TYPES OF CONTROL CHARTS One common type of control charts is the Shewhart chart. Shewhart charts are commonly used to examine means, standard deviations, ranges. propo-rtions ~ and numbers of defee ts. Control charts for the first three statistics assume an underlying normal distribution of sample observations; while for proportions a binomial distribution is assumed and for num­ bers of defectives a Poisson distribution is assumed. In all case's, the sample statistic (eg. the mean) is compared to co",Sugi-81-107 Kraemer Stober.pdf
""" SYSTEl! 2000 STATISTICAL ANALYSIS SYSTEM '81 Kirk l~ul Lafler~ Electronic Data Systems Federal 1.0 INTRODUCTION The SYSTEM 2000 Statistical Analysis System Interface (S2KSAS) provides a dir­ ect link between any SYSTEM 2000 (S2K) data base and Statistical Analysis System (SAS) ~ S2KSAS is currently being developed by Electronic Data Systems Federal (EDSF) at the U.S. Department of Energy (DOE) in Germantown, Maryland. It operates in an interactive multi-user environment on an Amdahl 470V!7A Computer System i.n which IBM's TSO is used as the communications monitor. Capabilities of producing sta­ tistical reports, plots, two or three­ dimensional graphics, and SAS GRAPH out­ put are possible. Additionally, S2KSAS provides an exceptional means of tapping large reservoirs of information in a result-oriented atmosphere. This paper is divided into three basic parts. The first part provides an over­ view of the technical operation of S2KSAS. The second part will provide a user's view of S2KSAS to describe the use of the system. The third part wi11 provide S2KSAS examples to describe the various types of output capable from the interface. Before we get started, a discussion on the current needs seems appropriate. 2.0 CURRENT NEEDS S2KSAS has created an interest among DOE users who recognize the potential of the complimentary features of the two systems. In its current state, the interface requires a high degree of technical ex­ pertise which presents a problem to most users. Since the interest among DOE users is definitely real) there is justification to c.ont:tnue the development of a user­ oriented interface~ The advantages of an interface of this nature are many~ but five key reasons stand out among the others: 1. Capability of producing statistical reports. 2. Reduced overhead costs since the data base is opened only for extraction of data, then closed. 3. Plotting as well as a full range of two or three-dimensional graphics are possible. 590 4. With the limited suppl",Sugi-81-108 Lafler.pdf
"Researchers characterizing ecological communities are often faced with the problem of collapsing large species lists into a single numeric expression of community structure. Historically, quantitative species diversity indices have been used to assess spatial and .temporal changes in ecological communities. However, other classification estimates, e.g., binary similarity coefficents, correlation coefficents, and Euclidean distances, offer alternative methodologies for delineating community composition that may be more robust to sampling error. This study presents 1) a series of algorithms developed using the Statistical ~nalysis System (Barr and Goodnight, 1976) fo!"" calc ula t ing ind ices of community structure and 2) an applied example of a multivariate analysis attempting to distinguish ecological communities and/or events. *Supported in part by the Office of Health and Environmental Research and Office of Environmental Compliance and Overview, u.s. Department of Energy, under contract W-7405-eng-26 with Union Carbide Corporation and u.s. Army Corps of Engineers, Waterways Experiment Station under the Environmental Water Quality Operational Studies, project VIIS, Waterways Field Studies. Publication No. 1703, Environmental Sciences Division, O.R.N.L.",Sugi-81-109 Polovino Farrell Pennington Strand.pdf
"MULTll'LE CCHI'ARISONS FOR FIXED EFFECTS m MIXED MODELS Judil.h Rosenblatt and Gary Regula, AppTech* Most advanced courses on general. regreaaion or anaJ..ys:ls .of varianae start out by applying the least squares prineiple to the general linear IIKJdel. Using partial differentiation the normal equations are der1'ved, and from. these, various. specialized fonnul.a.a for carrying out tests of hypotheses are deve­ loped. :!he SllKJunt of algebraic manipulation and the notational OOlIlple'O:i:ty or this approach are fomi­ dable. Furthe:nn.ore the tl'l.1II1er10B.l. methods for oarrying out oolutiDn of the oonnal equations have to be developed separate17 beoause they don·t seElll to have..""., special relation to the stati.t;lcal conoepts. A great deal of eff'ort is spent on estimation of' miflsillg data -- on ff1ll:i.ng inf the holes~ so as to preserve the fo:rmul.a.s that mok so much effort to develDp. 'lhis approach wae reaaonable so long as fomulas and hend computations were the pr:iloaq means of obtaining result.. Nonethele •• long barore the widespraad use of computers, Wald initiated an approacb lInlCh better suited to the developmeot of theory, end wich turned out to be just about ideal for computer implmentation. !!ather than attempting direct solution o.t the norma.l equations by some variant of Gaussian ellminat1on, the problems of estimation and testing are handled by converting to a IOOre suitable ooordinate system - one espeo1aJJy appropriate to the problem l.mder consideration.. This be.sieaJJ..y geom€ltric framework is a completeJ.y- natural one for handling situatio"""" of non-full rank and unbalanced design., as well as for dealing with constraints of the type I a:i ~ I ~j ~ I (a~)1j = 0 i etc .. that arise in the a.naJ.ysis of variance.. As you lIlBY have already conjeot-ured by this atage,. our discussion of the linear model problems ""'"" re interestsd in will extend along the Une. initiated by Wald. U'sual.ly these problems are phrased in tams of' teats",Sugi-81-11 Rosenblatt Regula.pdf
"One of the most important problems of population genetics is the understanding of multi-locus natural selection in the presence of all the realistic conditione that make it so complicated: truncation selection, linkage, and small numbers of major loci superimposed on a background of multi-locus minor effects. SAS has proved to be an excellent vehicle for exploratory simulations, with successive work data sets representing the generations of an evolving population. The saving of programmer time is substantial t and the SAS program forms an excellent outline for the writing of production programs in Fortran.",Sugi-81-110 Spitznagel.pdf
,Sugi-81-111 VonDoehren.pdf
"~~llaR and Rarville (1980) p.xpreRRp.d thp. best linear unbiased estimators for mixed linear models recursively. these estimators assume the v.!ft;'h.nce matrix: of the observa.tions is. known up to 8 scalar ~onstant ,,2, Frequently; the vqriance structure is not complE:!tely 'known ""'lnd depe~d8 on an unknown parameter vector e as well 8S "". Through the utilization of the computa­ tions involved in obtaining the best linear unbiased estimators recursiVely, aD on-line estimation procedure (sn algorithm for which no reprocessing of data is required) is develope~ for -animating simultaneously the effects, "" and e. 'nIe procedure is- shown to perform well in conjunction with a model for scores of Nationa.l Football League games for the '1968-1980 seasons. KEYWURUS: Recursive estimat ion'i Restricted maximum likeliboodi Variance components; Method of scoring; Prediction intervals; Foatball predictions. 1.",Sugi-81-12 Sallas.pdf
"This paper illustrates how recently de~ veloped statistical tools, inco!porated within SAS, ~an b~ used ~ffectively io linear regres­ sion model building and sensitivity analyses. the value of such techniques is highlighted w~th an analysis relating measures of air pollution to human mortality -- a topic of many published articles over the last decade and, at least qualitatively, a basis for establishing air quality standards. Two interrelated aspects of model building -- the deletion of ""atypica.l"" Standard Metropolitan Statistical Areas (SHSA5) from the data base and the choice of nonpollu­ tion variables in ~he model -- arB Bxplored systematically. Measures useful in identifying Uatypical. u and ""influential 1l SMSAs are calcu­ lated for a rather large data base. After deleting atypical SMSAs, a ntotal squared error l1 $tati5ti~ is used a$ a guide to construct equationa which appear to best represent the data. Us~ng these new equations the incremental contribution of the air pollution indices to explaining mortality rate"" variation is assessed. These analyses indicate that the association between the air pollution indices and mortality is substantially less than that reported in some early epidemio1ogi~al studies. 1. Background and",Sugi-81-13 Gibbons McDonald.pdf
"~ARAMETER ESTIMATION, HY~OTHESIS TESTING AND CODING Chip Kaliher, G. D. Searle & Co. Analysis of variance is concerned with estimation of the parameters of a linear model, and subsequent testing of statistical hypotheses, expressed as linear functions of the paramete[s~ Sums of squares attributable to the effects in an ANOVA table are computed by using least squares multiple regression with coded dummy variables, which represent the levels of the va[iou~ independent treatment or classification factors. Schemes for aSSigning codes to the dummy variables determine the parameter estimates obtained in the solution of the normal equations. Using a simple two by two factorial experiment, this paper demonstrates that the method of coding one of the factors determines the parameter estimates and hypotheses tests which are obtained concerning the other factor. This may seem counter-intuitive, and should serve to emphasize the point that dummy variable regression procedures, which arise from imposinq restrictions on the parameters of the overparameterized qeneral linear model, are only com­ putational conveniences for obtaining reduction sums of squares, R( ), providing no indication of which sta­ tistical hypotheses are being tested. Such problems are avoided through the use of the full rank, cell means model. Analysis of variance is a statistical technique involving statement of a linear model, in attempt to explain variation in some observed dependent variable in terms of concomitant variation in one o[ more independent, treatment or classification factors. Central tasks in the analysis of variance are estimation of the model parameters, and subsequent testing of statistical hypotheses, expressed as linear functions o£ those parameters. Sums of squares attributable to the effects in an ANOVA table are con­ veniently computed using least squares multiple regression with coded dummy variabl-es, corresponding to the para­ meters or linear combinations of the parameters of the",Sugi-81-14 Kaliher.pdf
"ESTIMATION OF FIXED EFFECTS IN MIXED MODELS WITH UNBALANCED DATA Walter R. Harvey, Ohio State University 1. ltJTRODUCTlON The theory involved in the estimation of fixed effects under the general linear model is well Known and is covered in considerable detail in many textbooks, e.g., see Graybill (1976) and Searle (1971). Efficient analytical procedures have been developed in recent years for the esti­ mation of fixed effects which allow researchers to obtain essentially the Same kind of informa­ tion whether the data are balanced or unbalanced. Some of these procedures, which may be considered as extensions of Yates (1934) ""method of fitting constants,M are as follows: 1. The fitting of individual constants for interaction effects so that the ""weighted squares of means"" analysis descrl bed by Vates (1934) can be obtained directly and can also be extended to more complex models. 2. The computation of adjusted or least-squares sums of squares by a direct method (Harvey, 1970) which makes use of the estimates of the fixed effects and segments of the inverse of the variance-covariance matrix~ rather than from differences in total reductions in SumS of squares when different models are fitted. 3. The estimation of partial regression coeffi­ cients, both for individual classes or sub­ clas.s.es or on a pooled basis, for continuous independent variables (Harvey. 1964 and 1977b). Actually, the degrees of freedom for the individual class or subclass regres­ sions may be partitioned in the same manner as the class or subclass effects. 4. Orthogonal polynomial fitting even when unequal intervals exist and/or the treatment means are correlated (Harvey and Swiger, 1978). 5. The computation of sums of squares for single degree of freedom contrasts among adjusted treatment means and the application of mean separation procedures (Kramer, 1957). When completing an ordinary multiple regres- sion analysis the X matrix of the underlying general linear model, y·X~+e, (1.1) is of full r",Sugi-81-15 Harvey.pdf
"MAKING SENSE OF TYFES I, II, III AND IV SUMS OF SQUARES IN SAS GLM Douglas C. Bolgiano l New Mexico State University Anyone who 1s faJDil:lar with the GLM proce .... dure in SAS knows it 1s capable of computing four sets 0,£ sums of squares with .any analysis. TIlf::!.e.e sets, kuown as TYPES I, II, III and IV Sums of Squares, each reflect a certain philos­ ophy or attitude toward hypothesis tesing in the gen~ral linear model. For a researcher this can be quite baffling and he might ask a statisti­ cian IIUha.t do the different types of SUIIS of squares mean and ~1ch is appropriate to my problem'?"" Often, this 1s not an e.asy question to answer. In the following article th~ author outlines a. practica'l method of illustrating the specific hypotheses being tested by the TYPES I, It~ III and IV Sums of Squar@s. It 1s hoped that by examining the ~pecific forms of the hypotheses being tested the researcher will be able to decide which, if any, aTe appropriate to his prob lern. Throughout the discuss~on we wQl1 considar a fixed linear model -of the form, :r' Xb+.\:. making the usual normality assumptions and assuming that the coefficient matrix, X, ia less fu11 rank. In this case a solution to-the normal equations can be obtained by the use of a generalized inverse. A solution can be written .!o: - GX':r where Q is a generalized inverse of !'~ i.e. X'XG:l'X· X'X Following the definition by-Searle (1971) .. a fWlC­ tian of the parameters, ~'b, is estimable if S'.!o: - .!'E(:r) - .!'Xb • This requires that the function be a liueaY combination of the expectations of the observa­tt-ona if it 1$ to be estimable. The following properties result from this definition (&earle, 1971), i) the expected value of any observation is estimable if) Ui) iv) v) any linear combination of estimable func­tions is estimable for ,.q'~ estimable th~..i' ::; .!.'.! for some t' for s:k estimable, S':£.- is invariant to the solution the B.Lu.E. of ..9,.',£ 1s..!l'i There is a simple test for estima",Sugi-81-16 Bolgiano.pdf
"r , , , ASYMMETRY AND REGRESSION Backgrl,mnd Philip ~rr18 Monchar, AT&T Long Lines Demonstration This papar 18 concerned with ~he assumptioQ of symmetry underlying both e.orre1ation and regression. In partlcular~ the paper examines some of the pTactl~al effects of violat1ng the 3ssnmpt 10n of Bynoe try in the independent variable. It 1s noteworthy that standard s""tatlst1.eal textbook$: in 8Ociolo-iY. psyc.hology ... and education seem to give scant expl~cl~ regard to the consequences of violating this assumption. In addltion, a computerized literature search of the statiatical and social science fields was able to identify very few articles dealing ~lth tnis issue, .nd not ona of them was dated prior to 1975. The problem addressed in this article was encountered in an analysis of telecommunications data that involved a hypothl;!:s1zed quadratic model. In the course of the analys1e an unexpected uon-orthogonal relationship (r(X -x ) (X -i1 )2 >.80) wa. found. Tho 1 1 I I I models to be de~onstrated below will show clearly that the failure to symmetrize my data led to the u~xpeeted non-orthogonality and 8 problem. in interpreting the re-sults of t.he an.a.lysis. Bradley and Srivastava (1977 and 1979) dlsr:.usfJ-9d 1;1 similar iaaue to the one being rel~ted here. In t.~e1r papers, they pointed to the d~leterloU8 effects of not centering an X about its mean in correlation and polynomial regression. In particular. they took issue with Harqu.~dt and Snee (1975) whom t.hey q-u~t.ed as saying t ""in .a quadratic model cente~ing reduces, and in certain situations completely removes, the correlation between linear and quadratic terms. II Bradley and Srivastava tben showed that as the values of the independent variable became less symmetrical the co~r81atioDS between the linear and quadratic terms approached unity. evan after centering the independent variable abo~t its mean. St1mson. Carm1nes, aud Geller (1976) agreed ~th Bradley and Srivastava and .added that nthe corTelation",Sugi-81-17 Monchar.pdf
"alanced ANOVA, althougn not clearly Te­ solved. 1s better understood than it was ten years ago. Although this problem technically includes, as a special case, the possibility of missing cells, the latter problem is not so clearly resolved. The purpose of this paper is to review some of the more common prQcedures u$ed with unbal­ anced data and to attempt to clarify the ~aaing cell methods currently used. Given an UDde~$tanding of the implications of existing methods, it ia hoped that futu~e comr puter packages will provide more flexibility and eneouragement to the user to preBer~be the an­ $.lysis most appropriate for the problem at hand. 1. INTR!lDUCTION Much has been sa1.d and wr1.tte.n in rec.etlt years about the disparate results presented by various ANOVA packages for the analysis gf data from designed experiments wirh unbalanced and/or missing data~ SAS GLM, for example, presents four different sets of sums of squares for the ANOVA table and there are potentially many others. The question of wh~ch, ~f any. of th~se analysea is preferable has led to a serious at­ tempt to characterize the results. Since the sums of squares in an ANOVA table may be asso­ ciated with linear hypotheses on' the parameters of the prescribed model, the natural approach has been to identify these hypotheses. The SAS GLM procedure is_ unique in that it provides the usar with a numerical statement of the hypotheses tQ8~ed by the. four sets of sums of squares. General algebraic exp~ession8 are als",Sugi-81-18 Hocking.pdf
"Two SAS p~oc.du~.s h.v. b •• "" developed to d •• l ~ith ~u.dr.t1c response sup'.ce .n.ll.l .. lt. of e.p."",i"",.nt .. l dolt... The RSDESION p~oc.du~. g.nlr .. t.. thr •• el ••••• of optim .. l Ixperi •• ntal d •• ignl .110.1nl tb. user to run e.,eriment. with al.os' .. nu numb.~ of f.actDTS. The • xperiment. m.y .a1sa be run 1n block •. Tb. RSANALYSIS p?ac.du~. .analvz.. the •• pert •• nt.1 m ••• u~.m.nt. cainc1ding with tb. I.n.~.t.d d •• ign point~. RSANALYSIS .llows th .• us.r to madll the .xp.rimental ~.~ult. .nd to d.te"",min. Ixperiment.l s.ttingl wht,h Jointl, Qptimizl m.n~ .... pon •••.",Sugi-81-19 Harrell.pdf
":'. , i' f PATH ANALYSIS: A MULTIVARIATE TECHNIQUE MMgMet A. Chmier.-IU, Toxa.\ MM U.uVVt5lilf Path analysis is a method for quantifying the c.ausal relationships between a set· of exo­ geQOna anli endogenous variables. A variable is said to be endo~nQus ~f ~t has a direct cause and exogenous otherwise.. The. first step in path analysis is to define the causal relationships by a causal diagram. Straight line arrows a~e drawn frOlD each variable to its direct effect. If no variable is both a cause and effect of another variable thea the system is said to be recuraive. Otherwige it is nOn-recursive. Un­ explained correlation between exogenous ·variables is indicat.ed by curved double headed arrCJW""8. Each direct effect has a re8idual, U. In Figure 1, ~ and X z are exoge.n.ous and Xl' X4 and X:; are endogeaous variables. the residuals U 3 , U 4 and U 5 are treat.ed as exogenous variables and can possibly be correlated. U 3 P3l 1 P3Q r ~ --#..) x3~ r 21 · r p43 v~ ~4Z"" J, ~ ~ ---, X 4 T P40 U4 Figure 1 p x~u 5 5 Pat.h coefficients ware ~ntroduced by Wright (1921, 1934, 1954) as a method for relating the correlation coefficients among a system of vari­ ables to the functional relations-hips moong the variables. Wright was interested in genetics and considered path diagrams which related the genetic constitution of parents to the genetic constitution of thsi-r offspring. For recursive systems he gave rules for decomposing the corre­ lation between two variables into direct, indi­ rect and spurious effects. Simon (1954) USQd a three variable system to determine 'Whe,ther the c:or-.;elat1on between two variables was spurious or genuine. He·discussed the following aspects of correlation. Suppose that we are interested in whether the signifi­ cant correlation, r t between cwo variables x ""Y and y means that ths-re is a causal relatio.n be­ tween x and y. To check this out, introduce a third variable. ~. compute r ,snd compare ""Y"" this partial correlation with r Ifr xy xy"" app",Sugi-81-20 Chmielewski.pdf
"I PATH ANALYTIC MODELS m IIIlMAlI QUANTITATIVE GENETICS John Rice, J~ Philip Mil1er~ C. Robert Cloninger Departments of Psychiatry and BloBtatist1cs~ Washington University. St. Louis, Missouri Introduction Pa.th analysis is a t.echnique. intro-duc'ed by wright (1921) for analyzing the corre~ational structure among a set of variables. ThE rela­ tionships among the variables are described by a system of regression equations (often given causal interpretations)t Where each variable is standardized to have mean 0 and variance 1. the: standardized regression e.quations are termed path equations and the corre.Spending standard­ ized partial regression c.oeffic.ients are termed path coefficients. The system Is usually dis­ play~ in a. path diagram ae- in Figure' 1"" where by convention a residual is not displayed if tt is uncorrelated with all other variables~ For a recursive system, the correlation between any two v.!lriAbles may be obta.ined by using a simple calculus to tl'ace the paths connecting them (Li~ 1975). Path analysis has been used exten­ sively in human population and quantitative gmetics and has proven useful in the formula­ tion and solution of a variety of prOblems (Li, 1975). Path analysiS ~s closely related to the techniques of structural equations analysis cnuncan~ 1975) used in other disciplines (although the use of standardized variables i8 often discouraged in these disciplines), and software intended for the analysis of struc­ tural equations may be used in genetic modeling. However~ there are several difficulties inherent in the genetic models and the type of data available. Fir8t~ ~he genetic models are in general systems of linear equations formulated in terms of latent (unobserved) variables. When these ~ystems are expressed In terms of observed quantities, the system becomes nonlinear in the genet~c p.arBIlle:ter.s, so that 1inear teclmique.s (such as those In PROC SYSREG) are not appro­ priate. &wever, t.hi::. di£f:k.ulty has _been obviated by",Sugi-81-21 Rice Miller Cloninger.pdf
"USING SPATIAL STATISTICS TO PRODUCE RISK QUALIFIED MAPS Richard A. Bilonick~ Consolidation Coal Company Int.roduction In everyday life, information Is often pre­ sent:ed in t.he form of a ""map"". A typical example. would be a map ahowins roads; cities. points of interest, etc. in a particular state. Another example would be a map that shows elevation above sea level for a given region. In both cas~s, for all practical purposes, ""the maps are ""deter­ ministic"". That is"" the information represent:ed in the map is knmm with certainty. However. in many cases, the information needed to produce determi.niBtic maps is not available - it is ei­ ther too expena1.ve or too time conswrlng (or both) to collect all the necessary data. For example. we may want to know how rain­ fall varies over a given region of the earth. However, we cannot possibly measure the amount of raLnfall everywhere within even a relatively small area (say a few ·square miles). Similarly, the thickness of a coal seam may be of great in­ terest because of its economic i~portanee for a mining company. But~ since the coal seam is buried within the ground (often at great de.pths), there is no practical way of measuring the seam thickness at every point in the deposit. As in many othe~ problems, sampling can come to the rescue. For mapping rainfall, sam­ pling stations (which essent1.ally consist of IIbuck.ets"") can be located throughout the region. For mapping the th1ckne~s of a coal seam, sam­ pling entails drilling ""coren holes,. removing the core and measuring. the thickness of the seam. The samples are located ideally on a (more or less) regularly spaced grid throughout the area af the deposit. ThOOe prOblems differ from. the more routine applications of sampling in that the location of the sample in space plays a majo~ role. Therafore, the usual analysis will generally not work. In what follow8~ I wil1 try to outline a general approach to producing maps based on limited sample information. It should be c",Sugi-81-22 Bilonick.pdf
"DISCRIMINANT ANALYSIS Tom R~ nohannon~ Appalachian State Univer9ity INTRODUCTION Under the title of lIdiscriminant analysis U are included some of the mOS~ powarful and use­ ful statistical techniques available to researCh­ ers~ Discriminant analysis is concerned with the problem of aasigning an observation veccor~ X, of unknown origin to one of several distinct groups on the basis of some classification rule. The assignment of an observation to one of sev­ eral groups may take into Recount such factors as prior probability of group membership and the coscs of misclassification. Other factors re­ ceiving consideration ~y be distribution assump­ tions, variable selection. evaluation of classi­ fication rule, and missing values. Koonce and lcaza (1978) discuss some QPp~1 cations of discriminant analysis using the pROC DrSCRIM procedure of sASe In their paper they point out some of the deficiencies in this pro­ cedure; with the newest release of SAS some of these will be eliminated by the PROC STEPDISC. As indicated in this paper, the strong points of PROC DISCRIM are the extensive output documenta­ tion and the test of equality of group covariallc­ es and then the selection of either the linear or quadratic function fOT classification. Hodges (1950), Cacaullos (1973), Lachenbruch (1975) and Kshirsagar (1972) are excellent references which contain many case studies of various applications of discriminant analysis. BACKGROUND INFORMATION The bas~c concepts Ln discriminant analysis will be presented from the stand point of the two-group problen and expanrled to consider the multiple-group problem. General assumptions followed by the assumptions frequently made by users of the packaged computer programs such as SAS will be presented. Assume X is an observation from one of two populations Rl and R2' with distribution func­ tiollS f1 (E) and f2 (X) ~ rsspectivl3:1y. The cri­ terion that ie normally used to constru~t the classification rule is to m1nimize the total probabili",Sugi-81-23 Bohannon.pdf
"A ""AC~O FOR TWO POPULATIO~ NONPARAMETRIC UNIVARIATE DISCRIMINANT ANALYSIS WITH EXTENSIONS TO HIGHER OIMENSIONAL SPACES Donald J~ Henderson~ ORI. Inc. William A. Blattner, ~ational Cancar Institute l~ Introduction Discriminant analy~ls is e w'd~ly used technIque. particularly in distin­ gUlsbing between normal and diseased in­ dividuals. If the distributions of tne populations are narmaI, procedure DISCRIM can be used. For data that is not nor­ mal, t~e SAS user is Ilmitad to pr~c.dure NEIGHBOR or one of several U5~r­ contributed logistic discrimination pro­ cedures. The~e are, howevg~, ~any methodologies in addition to logistic or nearest neighbor methods for disc-riminant analys is. Unfortunately, none are readily available in 5AS. The MACRO p~esent~d here was devel­ oped in response to th~ need for greater nDnpardm~tric discriminant analysis capability. It determines the point at whicb the difference of the two cumula­ tiue distribution functions for the two populatiDns is at its maximum. Overlayed plots of ""the twa cumulatlve distribution functions, ths plat of tne dlfTor&nce of the cumulative distributions and a print af the range(s) at ~hich tne maximum dif­ ference eccUrS are also produced. In se~tion II. we discuss the statistical bacKground of the algoritnm used in MACRO DISCRIH. Included Is 8 discU5$jon 'of mathod~ for sKtending this standard univariate procedure to multi­ ~ariate data. Section III gives instruc­ tions for using the MACRO and describes two elC8h1lJles. The first, a standard univariate application, and the second, an application utilizing a bivariate rank,ng algorithm to reduce the dimen­ sionality of the data to cne~ II. A Rank Based Discriminant Rule Consider the two population dis­ ~~imjnation p~oblem in which the pcpula­ tions have continuous real-valued cumula­ tive distribution functions F and G with corresponding densities f and 9. If the dlst~ibutlons are completely known, th@n the optimal di5crlminant rule 15 based on the ratio f/g.",Sugi-81-24 Henderson Blattner.pdf
"The prob1em of assessing the goodness-of­ fit of a random sample to some hypothesized distribution is cOQsidered for three i~ortant ~~actie.l situations: when the hypothesized distribution F(X) is continuous and completely specified and when F(x) is the normal or the exponential distribution, with parameters to be­ estimated from the data-. Sever.al of the more­ common typee of goodness-of-fit tests are briefly described and compa~ed; the strengths and weaknesses of methods currently available to the BAS usar are a1ao diacusaerl. MOdified tests baaed on t~ empirical distribution function (EDF), namely the Kolmogorov-Smfrnov statistic D, the Kuiper gtatiatic V, the Cr~er~on Mises statisti~ W 2• the Watson statistic U2 and th~ Anderson-Darling .tatistic A2, are recommended. kDF.statistics are ea~ily calculated, require only one line of 8ignifi~~nee points for each situatian and are competitive in terms of power. the usage of a SAS mac:=ro implementing these tests is illustrated through tvo examples. 1.",Sugi-81-25 Davis.pdf
"A COMPARISON OF SEVERAL APPROACHES FOR CALCULATING LCSO'S FOR BINARY RESPONSES OBTAINED FROM TOXICOLOGICAL EXPERIMENTS Jerry L. Oglesby and Charles M. Bundrick University of west Florida A common approach todyy when con­ ducting toxicity studies designed to investigate the effect of a chenical on the environment is to calculate an LeSO (the cOncentration required to produce 50% mortality) or an EC50 (the concen­ tration level that will produce a re­ sponse from 50% of the population) . Unfortunately. in this situation, measurement of response is typically quantal as opposed to continuous. This fact steers Us away from the uaual least squares regression analysis, since with quantal data. the values do not all have equal weights--even when the number of subjects in the variQus groups are equal. Asbton (1). If X measures the concentration or dose level and p the probability of response, then generally for small XI P approaches 0; for intermediate x, P is strictly increasing: and for large X, P approaches 1. Such curves are typically sigmoid in shape~ There are several transformations which tend to linearize curves of this type. The two that have been the most popu1ar over the years are probit (which linearizes the integrated normal sigmoid curve) and logit (whi~h 1inearizes the logistic sigmoid curve). Probit Analvsis The probit transformation became a popular tool in the statistical analysis of biological data in' the mid-1930·s due ,to a flurry of articles in that decade by Bliss (1), Fisher (8), Gaddurn (9), and Tbomson (13). A probit is simply the normal equiva­ lent deviate of a probability P + 5 (the 5 is added to insure that prcbits are positive numbers). Fo~ exa~ple/ the probit of .25 1s Z.75 + 5 ~ -0.675 + 5 4.325 and tbe probit of .50 is Z.5D + 5 ~ o + 5 = 5. The probit method is a parametric ap­ proach for analyzing quantal data which assumes that Y (the probit of P) is a linear function of X (or more likely log x). The parameters in the equation Y = A + B l",Sugi-81-26 Oglesby Bundrick.pdf
"PROC RANDOMT~ST: A SAS PROCEOURE PERFORMING RANDOMIZATION TESTS Robert M. Hamer, Medical Often, an experimental design may call for a one or two group t-test, but the data, although at least interval level, may not meet the distribU­ tional assumptions required for a t-test. For example, an experimenter may have two groups, each containing n rats. Each rat is a 1ltter­ mate of a rat in the other group; there are thus n matched pairs. This situation is one for which a matched-pair t-test is usually appro­ priate. Suppose, however, the dependent vari­ able cannot meet the distributional requirements, but is interval level. The usual nonparametric ranking tests would discard part of the informa­ tion, but a randomization test (Bradley, 1968) would use this information and not require normality assumptions. Consider two groups of psychiatric inpatients, each diagnosed as having endogenous depression, where patients in one ~roup receive one tri­ cyclic antidepressant (TCA) drug and patients in the second group receive another drug (0 not necessarily equal n2). Suppose further that the dependent variable 15 the response to a dexameth­ asone supression (DMS) test, and that it is known that these responses are not normally distributed~ There is a randonization test, too, for this situation. In the first situation, with n matched pairs of rats, there are 2n paired responses. Under a null hypothesis of no treatment effects, switching subjects (within a pair) from one group to the other should make, in the long run, no difference in the mean of the Rifference scores. For n pairs, there are 2 distinguish­ ably different ways in whiCh the 2n subjects can be arranged using within pair exchanges only. If the test statistic (for e~ample, a t) is c~lculated for each of the 2 permutations, the 2 t values comprise the entire population from which our observed t was drawn. We can then calculate the probability of drawing a t this large or larger (in absolute value) in any sample. An ob",Sugi-81-27 Hamer.pdf
"1 , ~ ! I ~, "" I . TYPE I ERROR ~TES FOR THE UNEQUAL VARIANCE T TEST J. Philip Miller, Reimut Wette and Robert p. PaTka Washington University The 8ehrenB~Fi sher problem of comparing two sample means from normal populations when the variances cannot be assumed to be equal is a statistical p~oblem wich 8 long and contro­ versial history. It is a p~oblem in which Fisher's fiducial inference theory and N~ym&n-Pear8on's confidence interval theory produce clear differences. (~endall & Stuart, 1973; pp~ 146-157). It is one of the classic problems of statistical inference, fOT on the surface it is a simple problem, yet no ~1m11ar region exists. The prasent report is not. however, ~oncerned with the theoretical aspects but rather addressee the problem on a more applied leve1 appropriate for those engaged in data analyaia activities. SAS PROC TTEST~ as practically all other statistical packages, routinely prints results for an ""unequal variance t test H • The current research was originally directed towards understanding the performance of that test when 1t was used with the F test on the aqual1ty of the variances as a pretest estimator. That procedure is explicitly prescribed by the SPSS manual (Nie~ et a1 1975, p. 270) and appears to be the one followed by many applied statisticians. It is charact@riz@d by performing an F test for equality of the two variances and applying the unequal variance t test if the F is significant Qt some l~vel ai, say; otherwise app1ying the regular t test which assumes the equa1ity of the two variances~ This procedure Is usually justified by a belief that the unequal variance t test is eonser~ vative when applied to samples which ~ctually have identical population variances~ As we began to perform some simulations of the procedure, we discovered that, although that contention was true for ssmp1es of equal size, it was not true for samples of unaqual size. This called for an examination of the test performed by SAS and t.he search far a test wit",Sugi-81-28 Miller Wette Parks.pdf
"al data using thH Grizzle-StanneJ:~Koch methodology. This method­ ology ~loits teat statistics which have asymp­ totic ~ distributions in arder to carry out tesLs of signifieanee. A simulation program was writt.en to investigate the effect of sample size On the true (] levels for var.ious 2 x 2 x k tables­ when the null hypotheses was true. This simula­ tion program exaruined two response functions~ log linear and linear. Many true ~ levels were much greater or much less than the nominal levels of 0.01, 0.05 and 0.10, unless the sample sizes were very large. The results indicate that this methodology may not be appropriate for a 100 patient clinical trial with 2 treatments, 2 responses and 10 investigators. Cochran-Mantel­ Haenszel analysis or ordinary X2 analysis, how­ ever"", of the sam-e simulated data achieved true a levels close to the nominal levels of 0.01, 0.05 and 0.10. The Model and Data Data from K 2x2 contingency tables were gen­ erated using the UNIFORM function. Within each table the rows r~f~r to two populations. A and B, and the columns r~f~r to the responses. success (+) and failure (-). Let PA - (Pat. Pa2, ••• , 'P ak) 1:lnd PB = (FbI' Ph2' • • ., Pbk) be the suc­ cess probabilities for the K tables. And let the sample sizes S ~ (51' 52' ••• , Sk) be equal with1n table for A and B. Thus, for example, con~ider simulating a clinical trial with three investigators (K ... 3) that have respective sample sizes of ]0. 20 and 16 (5 = (5, 10, 8»), and success probabil",Sugi-81-29 Stedl.pdf
"T N.w .n.l~tic.l c.pabilit1.. have b •• n addQd tQ BAS prae.du~.. LDQIST (fo~ loti.tic binarv regr ••• ion) .nd PHOLM (f~? Cox p~GPo?tiDn.l hAzard g.n.~.l lin""T model', The.e include 'he obilitg to t.st tho glabol hgpothesis Ho:8*O ~lthout 1te~ati4nc USing the efficient BCQT. statistic. and the .bi1itV to add and delete variables in tft. model in the o,..d,1'"" spectfied blj t:he- u ... ,... Thi. l~tt.l' SEGUENTIAL option ~ .. dHht •• tho un 0' incamplata p~incip.l component. lagi.tic and PTopo~tiDn.l hazard r.g"" ••• ion. FOT tihe PHGLM pTo(:.duT'et blockh'g ha. be.n iIIdded. Thi. allow'S the ""' •• 1' td abSDrb -the .f-fl-.ct. a' "".ctOl'. that a.,.e not modeled. A n.~ ind.x of model ftt h •• been inco~por.t.d into both pToceduTas. The~. n8~ f •• tu~.w ~ill .ppea~ in ... n.~ rella~. Qf the prQcedur.~. OLOBAL HYPOTHESIS TEST Who. u.i~g m •• imum lik.lihood I~' th.D~~. test. of ~~poth8.e~ using the likelihood T8tia otati.tic OT the Weld st. tl-stlc C i. e. par'il!mater est:l.m .. tel stand .. rd er~o~) can ba computatiDn .. II, expen .. ive. e5peciaJ I, blhen there are fHln, paT.meteT's to astitRAte. Quite often. the .tatiotician is int.reoted in to.tina the global null hQPo*hesi. tbat all regTe .. sion p.Jrameterl ""1""'1 zeTa, i. e, , thl~. 1 .. no agsoci~tion of .ny cQv.~i~tas witb the ,..spons. v~t""1.abl •. An -Q;It.alllpI • .Q.p .ucb • hQPotbosis i. the hQPothosis that all t~ • .atm.nt ITOUpS .aTe equal, when ttl."". are no .. dditi.on .. ] covariata •. Alsa, when the st.ti ..",Sugi-81-30 Harrell Lee McKinnis.pdf
"ly formatted two-way tables that are useful in displaying growth curve data. By creating variables through the use of program statements in a DATA step or through other PROCS, PRDC TABLES can produce statistical analyses that are very similar to a number of the standard analyses in the literature: Wishart (19}8) , Box (1950), Church (1966), Grizzle and Allen (1969), Snee (1972), Johnson (1976), and Snee, Acuff and Gibson (1979). Use of the Bonferroni-t leads to more specific and powerful tests that are simpler to interpret than usual composite interaction tests. Keywords: SAS PROC TABLES, Growth Curves, Two-Way ANOVA, Interaction, Bonferroni-t Introduction: PROC TABLES, Young and fraction (980), is a user written PROC that nicely formats tables of means and related statistics as well as computes tests of hypotheses of control versus treated comparisons. Although the PROC is directed toward the analysis of a one-way table, because it displays IIIlJltiple variables across the page, it can be usad to examine main effects and interaction in a two-way ANOVA. A Bonferroni-t is usad to control the error crate of the multiple com­ parisons in two-way tables. Growth curves are a special Case of two-way tables; treat­ ment beiog one dimension and time the other. Two Views of a Two-Way Table The examination of a two-way table is some­ what more complicated than the examination of a one-way table. As in the case of the one­ way table there are two maio objectives: examination of treatmen",Sugi-81-31 Young Fraction.pdf
", . !i I r I, ~ f , I ! AN ENHANCEMNT TO NPARIWAY: MULTIPLE COMPARISONS, Daniel M. Chl1ko, West Virginia Uni'ersity Gerry Hobbs, West Virginia University I NT'RODUCT ION The SAS Procedure ""GLM"" i ncl udes options such as IILSMEANS"", ""DUNCAN"", and I;WALlER Ii for perfonning the means separation procedures which naturally follow roost analyses of variance. Distribution free techniques of statistical analysis have gained in popularity over the last couple of decades and some such tests are availa­ ble for the global hypothesis of equal means in the one-way layout through the SAS Procedure ""NPARIWAY."" Unfortunately no option is provided whereby subsequent multiple comparisons may be carried out. The purpose of this paper is to provide an enhancement to NPARIWAY which allows two options to be specified. One option, ""DUNN"", causes SAS to perform a multiple comparisons test due to Olive Jean Dunn which is discussed in Hollander and Wolfe (1). The other option, RTRAliS, causes SAS to perform a multiple compari­ sons procedure which was first reported in (2) and may now be found in the text by Conover (3). RTRAliS refers to a rank transformation followed by LSD calculations performed on the ranks. Both procedures are designed for use in the one-way layout. That is, each observation Xij=J.I.+-rj+eij ;=1,2, ... ,nj j=l,2"". .. .,k where T~ is the effect due treatment j (ETj=O) and the eij s are independent identically distributed random variables. DUNN'S METHOD Let Rj' denote the average of the nj ranks assigned to the observations in the jth sample. Let N=Enj be the grand total number of observations ,and let zp be the (J-p)-th quantile of a standard normal distribution. Treatments a and b are judged to be different, that is 'a~'b, if 1""Ra-Rj,I~z [N(N?l]l;(..1.. + ..1..)\ p J na nb To insure an experiment-wide Significance level of a, p is ordinarily selected to be o/k(k-l). A good treatment of various multiple comparison philoso­ phies may be found in Miller (4) and (5). THE",Sugi-81-32 Chilko Hobbs.pdf
"i \ , t SOME REAL-DATA EXAMPLES FOR TEACHING ANALYSIS FOR EXPERIMENTAL DESIGN Kaye H. Fendt and Ronald W. Helms The University of North Carolina Introduction Sc~entific research is never conducted in the neutral environments (or condit1~nB) assumed by many textbook data examples. Thug the purpose of this paper is to provide you with two examples of real data which can be efficiently used in the classroom. envixonment to illustrate various statistical techniques and the advantages and disadvantages of these' techniques in the real research environment. Properties of Good Class Example Data Sets There are a few properties which one can state for good class examples. We feel that the mast important property is that the data set must exhibit the features which one wishes to exemplify. The next property, and one of equal importance, is that the data set be realistic~ This means that the variables will be meaning­ ful enough to provide som@ guid~lines or help­ ful aids to the studente as the analysis pro­ gresses. Another important property 1s that the data sets be small enough so as not to cause great data processing burdens on the student. With SAS data sets many of the data processing tasks can be handled by the professor and this problem becomes less severe~ Example Data Sets This presentation consists of two data sets from the Frank Porter Graham Child Development Center. Each of the data streams is stored in a standard SAS data fiLe with appropr~ate variable names and labelling information~ thus students would be able to refer to specific data fields using the variable names supplied by the pro­ fessor and the time consuming pLocess of explaining what columns contained various infor­ mation will be eliminated. Pulmonary Function Data The first data set is a slightly modified representation of ~nformatLon ~oll~cted from a Pulmonary Funct10n Study currently in process. This is a representative example of the IrDistributed Flat: File"" (DFF) strategy intro­ duced into t",Sugi-81-33 Fendt Helms.pdf
"<' .:. TWO-WAY ANALYSIS OF VARIANCE IN COMPUTER STATISTICAL PACKAGES: A COMPARISON OF SPSS, RXDP ANT RUMMAGE TO BAS GLM David W. Garton and Kenneth L. Koonce D~partment of Experimenta1 Statistics Louisiana State University Baton Rouga, Louisiana INTRODUCTIOlI The development of large-core, high-speed comput~rs has permitted the routine use of math­ ematically complex statistical algorithms. These statistical programs are written in higher order languages that are easy to learn. kesearchers that would ordinarily be lacking in programming skills currently have the ability to implement powerful statistical routines. This- has created the potential for misapplication of statistical analysis on research data. The analysis of variance 1s one ~echnique that is l~kely to be misused. The tests of hy­ potheses are -generally agreed upon by statisti­ cians in the balanced -case. However, unbalanced data (unequal nunber of obaervations in each treatment combination) is not uncommon in re­ seare:h situations~ There are no ""standard ll tests of hypotheses in this case. The analysis of variance can be further complicated by missing cells (incomplete data). For incomplete data there are many possible tests of hypotheses. Ideally, the researcher should have a '~reason­ able/~ or known test of hypotheses. Most statis­ tical packages provide only a sum of square table and no explanation of its computation therefore the hypotheses tested may not be of value to the researcher (Backing, Speed and Coleman, 1980). This study wag undertaken because of the widespread use of the analysis of variance in data analysis and lack of documentation inuserls manuals for tests of hypotheses. The first part of this papeJ: develops the ureasonableu tests of hypotheses for the unbalanced and incomplete cases, while the latter portion presents the re­ sults of the· data analysis on the four statisti­ cal paekages~ The statistical packages investi­ gated in this study are 1) Statistical Analysis System (SA",Sugi-81-34 Garton Koonce.pdf
"Analysis of data involving missing cells Is of major concsrn to many statisticians. This paper proposes ,an alternate method of dealing wit:h this pToblem. whQreby the null model is applied under a constraint condition, to data with missing cells. ""Instead of the traditional generalized inverse J a_partitioned inverse is utl1i~ed. The end ·product is a cell means solution vector which PrQvides an estimate for 411 cells including the missing Ones ~hen a constraint condition is imposed upon the model.",Sugi-81-35 Casanova.pdf
"~: , ., r i: "" DIAGnOSTIC TECHNIQUES IN MULTIPLE LINEAR REGRESSIon USING pRQC MATRIX O.J. Pendleton and R.R. Hocking U. of Texas Cancer System Texas A & M University Multiple linear regression is probably one of the most widely used statistical methods. Yet. like so many statistical method8~ it has its problems and pitfalls. Least squares estimates are known to be highly sensitive to problemS which frequently arise in multiple linear re­ gression such as influential observations and multicollinearity. The advent o£ high-speed computers and easy to use computer packages. like SAS , have made it all too easy to obtain statistical reBults without careful scruting of the data. For th.is reason it is impoJ:tant that diagnostics which reveal the nature and poten­ tial source of these problems be examined. Most least squares regression computer programs do not supply the user with sufficient information to identify these problems. While SAS GLM is among these, it is possible to readily compute numerical tndicaeors of these problems via PROC MATRIX~ The purpose o£ this paper is to present some of these indicators for two very common problema influencing the least Bquare~ estimates; (1) multicollinearlty~ or high dependencies a~ the independent variableB~ and (2) influ­ ential observations. An example is presented which will illustrate the use of these diagnos­ tiCG in revealing these problems and a sample SAS program ~ill be given to compute these diag­ nostics using PROC MATRIX. The data for this exampls consists' af 26 observations w1th three independent and one de­ pendent v3riable (Table 1). Examining the least squares regression output from PROC GtM we find ·no indications of potential problem~ (Table 2), There are thr~e ubHervatiou~ wLth fairly laLge residuals, observations ~ 11, 17~ and 18. Residuals are not the only indicators of influential observations. Indeed? au observa­ cion may be qu~te' influen~ial and have a very small residual. Hoaglin and Welsch (1978) sug",Sugi-81-36 Pendleton Hocking.pdf
"design has heen used ex­ tensively in clinical trials for two-treatment comllari'sons. The LJses of this design have Deen extremely controversial in recent years. However, one has to agree that when those highly restrict­ lve assumptions are satisf1ed, this design ismost attractive and useful. A maCro XSOVER is presented herein for the analy­ sis of data from this deSign, using both paramet­ ric and non-parametric methods for models with/ without residual (carryover) effects. This paper reviews these metnods and models, and exhibits the uses of this macro with two numerical exam­ ples. INTRODUCTION The two-period ""crossover"" design. al so tnown as the two-period ""change-over 11 design~ is simply a repeated 2 x 2 Latin squares. Therefore, the crossover des i gn combi nes the features -of sma 11 randomized blacks and small Latin squares. The principle of crossover design is very analogous to that of tournament bridge, in which the north­ south cards of one table are played as the east­ west hands at another table, so that the card ef­ fect is eliminated from the contest (Lee, 1964). ' The deSign consists of two groups of subjects: one group receiving treatment in the sequence A+B and the other in the ~ever$e order B+A. There may be (generally will be) a ""washout' period be­ fore each treatment to allow any effect of treat­ ment to dissipate. The uses of this design in recent years undoubt­ edly have generated a great deal of controversy. There are objectives and situations wne",Sugi-81-37 Hwang.pdf
"'~ , , ! ~ L I ~. Hi.na Mclrt:a, IJb::DB.s Capizzi and leonard Oppe:nhei.mer. »=::k Sharp & Ddme Research LaOOratories A procedure for estimatiJ')3 the area under a time-response curve in situations where independent observations are made at each tine point is presented.. 'll1.is technique utilizes the jackknife procedure 111 conjunction with spline regression and integration to provide an area. estinate, its standard error, arK1 a test for treat:1rl:!nt differences. A St\S macro which makes application of this method sirrpl(': .am versatile is discLissed. '!his technique is illustrated on data from a .tudy ctnparlng the pharmacokinetic behavior of a drug: in rats having either a 10 week or 44 week. old infec­ tion. At each tine mint, rats were sacri­ ficed and (l) the drl>1 uptake in the liver parasites of rats arXi (ii) ooncentration of the drug in t.ht= blccrl ~re rreasured. A least squa"""""" spline was fit to the data and the area under the- curve obtained by' integrating this function. Use of the jackknife procedure permitted conparisons to be made in the area estimates between the young and old infec­ tions. IN'IROIlOCTlOO 'Il1e problem of estimating the area under a time-response curve is encountered in vari­ OIlS fields.. In pharmacok.inetic studies a drug is given to several subjects r and the Clrug concentration in the blOCd of each subject is then obset:Ved at fixeCI tirre FOints. Each subject, therefore, has its arm. curve of the drug concentration versus time.. An. estimate of the area UI""rler each subject's t~ resp:mse curve can be obtained using, (1) an interpola­ ting procedure such as the trapezoidal rule (Metder, 1974), or (2) fitting a pbarnaco­ kinetic rr<lde1 (Frate and Yakaton, 1980). '!he esti.rrete of the average- area under the curve (AUC) for a group of subjects is the nean of the areas obtained for these subjects.. Dif­ ferences in the AU: am:mg distinct groups are then evaluated using an analysis which is suitable to the study design. In so",Sugi-81-38 Mehta Capizzi Oppenheimer.pdf
"The Michaelis-Menten equation, a rectangular hyperbola with two ~arameters ~o b~ specified, . occurs prominently 1n enzyme k,netlcs."" Often, ~n consulting situations we need to (i) obtain estl­ mates standard errors, and confidence intervals for the unknown parameters, which define this nonlinear model for one set of experimental con­ ditions and (ii) compare the parameter estimates under different experimental conditions~ Parame­ ter estimates for this nonlinear model can be obtained using least square normal theory~ the regular jackknife, the linear jackknife or the weighted ]jnear jackknife. In addition, the jackknife procedures allow one to evaluate differences in the parameter estimates across several experiments. The purpose of this paper is to demonstrate the ease in which these techniques are imple­ mented using several SAS macros. These tech­ niques are applied to an experiment which was run to determine if lipid concentrations selec­ tively affected the maximal velocity parameter but not the Michaelis constant for a partlcular enzyme reaction. Empirical results.are compared and the weighted linear jackknife for the non­ linear model seems to be the best procedure in achieving the objective of the data analytic probl em.",Sugi-81-39 Capizzi Oppenheimer.pdf
"~ElATIVE RISK ESTIMATION FROM EPIDEMIOLOGIC STUDIES OF MATCHED SETS Elizabeth J. Martin National Cancer Institute Judith H. Mopsik ORI, Inc. linda W. Pickle N.tional Cancer Institute Individual matching of controls to cases is a widely-used method of controlling for con­ founding in epidemiologic studies. It is a particularly appropriate method for small samples. One major advantage of the matched pairs design is its conceptua1 and analytic simplicity. The test statistic and the odds ratio estimate require no iteration and are easily computed on a pocket calculator. This computational simplicity disappears when the matching ratio exceeds one. This paper presents a SAS Macro, ODDSFMR, for analysis of individually-matched sets with a fixed matching ratio. Analytical methods for this stud1 design were developed by Miettinen (1969, 1970b). ODDSFMR calculates both point (Mantel-Haenszel and maximum 1 iken hood) and I nterval estimates of the odds ratio, along with an overall test of statistical significance. In addltion, a correlation coefficient and correlation chi are computed. The matching ratio may range from two to nine. and statistics may be obtained for an entire data set or speci-fied subgroups. The Matched Design It has been claimed that matching increases the efficiency of a study. However this claim has been based on comparison of a matched analYSis to analysis of two independent s.mples with no attempt made to reduce variation. A more useful comparison wou1d De of a matched analysis to some other competing technique. McKinlay (1977) pOints out some of the disadvantages of matching. She notes that in large studies~ where many cases and controls have the same values of the matching covariate, the results obtained are conditional on the specific sets of pairs that are formed. When many combinations of pairs are possible, individual matching is not the preferred method. Another consideration in the chotce between individually-matched and unmatched deSigns is the",Sugi-81-40 Martin Mopsik Pickle.pdf
"VARIANCE ESTIMATES FROM COMPLEX SURVEY DATA; TIlE St\LANCIlD HALF-SAMPLE REPLICATION PROCEDUBE By: J08ef~na A. Lago, WESTAT, Inc. 1. INTRODUCTION Although most current surveys are char­ acterized by complex designs involving multi­ Btage clustering and stratification, tbe procedures available in eoftware pa~ka@ea including SAS - generally assume simple random sampling in computing variance esti­ mates. However I ignoring the underlying sample design in variance computation might lead to gross inaccuracies in estimates of standard errors of sample estimates. This paper discusses a variance esti­ mation procedure -- balanced half-sample replication -- which takes into account the design features of the sampla and is appli­ cable to a certain class of stratified s~ ples. TbQ ?aper also introduces two macros LlNEsrs and RATIOEST - developed to implement the balanced half-sample replication ptO­ cedure. Macro LINESTS estimates the vatiance of a population total and macro RATIOES~ estimates the variance of a ratio &atimat~. 2. MllTHODOLOGY the method of balanced half-sample replica­ tion (BHSR), developed by McCarthy;] 19 applica­ ble to stratified sample designs involving the selection of two primary sampling units (PSU's) per stratum, whether one or more stages of Bub­ sampling are undertaken within a PSU. However, the 2-PSU's-per-stratum design can be obtained by either collapsing strata, in the case of a l-PSU­ per-stratum design, or by eombinin8 strata, if there are more than 2 PSUra per stratum. Another useful application of BHSR ~s variance estimation in systematic sampling where units can be logi­ cally assigned to one ot two pairs in a stratum. Ralf-9ample replication~ in Beneral~ is based on the idea that a 2-PSU's per stratum design y1elda two half-samples, each including one of the two units from each stratum. Instead of relying on the two half-samples originally cbosen~ which provide only one degree of freedom for variance estimation, new half-sampl~s can be",Sugi-81-41 Lago.pdf
"arch environment is to fit 1inear models to data obtained experimentally in the lab. The purpose of these models is usually to determine the extent to which some intrinsic variables affect a response of interest. The null hypothesis being tested is usually: if the intrinsic variables have no effect on the response, the coefficients are zero. The analYSis of variance for this problem is straightforward and well established. However, a special class of problems that often occurs, particularly in the chemical indu$t~Yt requires special handling by SAS. The special treatment required might not a first be obvious. Mixture problems involve situations where the sum of the ingredients, X's, totals 100 percent or 1. This constraint may be expressed as: x +x +X + ••• +X =1 123 n (1) The constraint equation reduces the form of the linear model so that no intercept term is required. However the null hypothesis must also change. The null hypothesis then becomes: if none of the variables have any effect on the response, the coefficients are EQUAL. Although the standard SAS GLM outpqt prints the correct coefficients when the NOINT option is used, the ANOVA must be performed in a separate GLM step to account for the changed null hypotnes is. This paper points out the dangers of miSinterpreting GLM's ANOVA for MIXTURE problems and how to properly handle the ANOVA for MIXTURE problems using SAS. 1.0 Statistics in the industrial research· environment. Industrial researchers usually use a liBite",Sugi-81-42 Tiede.pdf
"\. Sl>S OlITLIER MACRO, A BANKING PROBLEM William L. Sealol'.er James A. Calloway WLS Associates Louiaiana Tec~ University -r. Introduction In least squares analysis of data baaed on a full-rank linear regression mode.l. it is vary im­ portant to screen the data for extreme observa­ tions called outliers. However, no single out­ ller detection scheme has proven totally eff$C­ tlve because of tbQ masking effect of outliers 88 pointed out by Cook (2,4). Thus, an ar~~nal Qf techniques 18 needed where each one 1s sensitive to a different criterion. simil~~ly, savara! pro­ cedures are needed to evaluate the effeet of de­ leted out:llerB. Outliers are generally looked upon as obee~a­ tiona which p~oduce large r0siduals. T~us, out­ lier analysts usually begins_with plots of the re,gre88ion residuals against the inde.pe.w:lent 1I8r­ lib lea. x. and the fitted values i. SAS readily facilitates this oPQr~tlon using PROC PLOT. Re­ sidual plots of the standardi~ed residuals (re­ siduals/SQaT(MSE») are frequently revealing as well; this also can easily be performed using SAS. As a rule, these plots are just the starting point for evaluating the contamination of a regression model. Logically, tbe next step is examination of the studentlz:ed residuals (residual divided by its standard error) suggested by Bebnken and Draper (1), Prescott (10), and others. Seaver and Callo­ way {12} have programmed this atudentized resid­ ual test on SAS usi.ng MATRIX procedures but have carefully avoided automation of outlier delet1on. Ibis step was left to the discretion of the user. The BMDP-77 statistical computer programs report the studentized residual test, the standard error of the predicted value, the Mahalanohis distance, and Cook's index as aida to detecting influential observQtlcnS (5)~ Thi9 particular BMDP-77 p~o­ ""gram 8utomate8 the deletion of One ob,servation based upon tha largest cook index, II. The OUTLIER Macro Tha b.s1c objective of thia OUTLISR maCrO for linear models ia to bri",Sugi-81-43 Seaver Calloway.pdf
"SASGEN: A FaOGR1K TO WRITE SAS CODE FOB SIMPLE DATA ANALYSIS Morse F. Kalt~ Research Triangle Institute While S1.s is well knpwn for: its anil­ ity to sa.e programmers both time and effort. certain applicati~ns ~eDain both tedious and time-consuming even after SAS is employed. One such application waich aas frequently been encountered at BTI kas necessitated development of a program ""hi,ch is able to geD uate SAS code for lise i:a routine situation's. A description of the need for and development of tne SASGER program follows. After data haVE been collected and converted to machine-readable form,. pro .... ject leadErs frequently desi~e a upic­ tare"" of the data."" usually in the form of tl:8quencies (or descriptive statisticsJ far each -variable in the dataset. In Bach situations, PROC UNIVAItI1TE or P!lOC r~BQ is a simple vaJ to obtain the desired distributions with a minimum of progra ••• r ef£or.t. However. when the aqRber of va.Liables to he analyzed is Yet:'y la.rge r writing and entering the SAS code to per£orm th~ analysis can hecQme a very ti.e~cQDsuming task. The problem is f urUer cc)lIplicate-d .if recodes a['e to be done, Qr if variable labels a~e d€sited. I baSIl Dca a.s datasets containing upwards Q.f 500 yariahl:es al1e routinely encolln­ tered at Rtl. it became evident that the t.ia. d""""Gted to summar~z1ng the data could approach t.h"" t sp en t collect iny it. S~ryey datasets are generally accompa­ nied hy a .achine-readable codebool< (or dictionary) containing the name of each variable and its location in the file. :In many ca.ses; tae code.book will also specifJ variable types (character. real, integer) and provide variable la~els. In otlter 'ilords. if the user Ilas a -codebook, he/Ae .ill have. in machine-readable foea, most o.f the informat.ion necessary t.o create a SIS file and proceed with an a.na~l'si,s of each variable .. Consider the simple codeboO""k in Figure 1 belo.. The code book contains variable naaes, beginning and ending locations i",Sugi-81-44 Kalt.pdf
"THE STATISTlCI,L. CQNSULTt,NTS' DILEMMA; PROVIDING HELP AT TIlE LEVEL OF !'!JED OR TIlE LEVEL OF KNOWLEDGE John w. Ph11pot~ University of Tennessee Today's statistical consultants are compu~­ er consultants as well. since almost all ~eal data aualyses are being don$ on the computer. Consultants exist becalJ.l;;i~ no researc11er can understand his or her own field and in addition know all the statistical-computer tools that are available. The problem of resource management v1s-a~1a research is becoming more acute~ and division of labor and expertise are essential components of the solution. If you are a statistical-computer consult­ ant yD~ will have specialists from other fields that are your clients. These clients often perceive needs tha~ are well beyond their level of knowle4ge. Ov~r a period of time you will realize that there are many species of clients; spec~es that have evolved different approaches to closing the knowledge gap. Tne most common category, thankful1f, con­ sists of well-mativated, hard working users of statistics programs who want to master their analyses, and come to you only as a last reBort~ They are sensitive to your work load and take up no more of your-time than is absolutely neces­ sary. They lu't'n fast and never have co bring you t.ke same t.ype of problem twice. But you may not see that much of these users because their problem Bolving ability iF) so efficient. On the other hand there are some aberrant species of client that you may see more fre- . quently, deBp~te the fact ~hat their numbers are few. They range f-rom. those who expect you to de all of the work to those who think they have al­ ready done all the wurk, and just need a bit of advice4 I have begun a ~axonomy to help us identify these mutant sp~cies, and, ~ll describe"" them in order of descending expectations. The first type 1s called tiThe Prince lt • He has not only read the book by that n~, he be­ lieves in winning through intimidation. He has come to expect service bec",Sugi-81-45 Philpot.pdf
"The Research-Oomputing Unit supports com­ puting for 7 Ph.D. statisticians. Each consults on several projects in basic or c~inical scien­ ces. The projects vary greaUy in complexity and sh:e. Neverthele.ss, our most burdenBOIllE! data m;magement tasks for most projects are ini­ tial dafinition of the data (resolving input format specifications, variable labels r and value labels) and updating. If not carefully managed, these tasks oonsume an inordinate amo\mt of SAS programmers I time and cause sched­ ule slippaqe. We have implemented maJlaqement teclmiques and supporting programs that reduce the burden of data definition and updating. .Our data defi­ nition system employs a l?Ll program that con­ verts a keyed data codebook into a SAS program. All steps from codebook to SJ\5 data set, data listing. and summary statistics are handled by a data entry operator--in effect replacing a &AS programmer who would otherwise have to per­ form those tasks. Our updating system employs a SAS contants listing and a 'strictly formatted -u-anaaction file to reduce the tedium of gener­ ting a SAS ·update file. '111ia updating system is especially effective for· complex data sets. Both systems will be discussed.",Sugi-81-46 Calhoun Blavatnik Dorph.pdf
"SAS can be used effect1ve:ly by experienced progrslIIIlers to 80lve a variety o-f pr.()gr:amming applications. Rowaver, the approach to teaching these individuals is different than the Usual l'SAS Basics II course. This paper discusses the design philosophy, topic outline, and teaching materials used in an in-house SAS course for professional data processors. The applieations of SAS to data pro(!(l;ssing problems in a large­ government survey or8aalza~1on are discussed. Suggestions on how to organize a topic outline for a ""SAS Basics"" course for applicatiOTlB systems analysts in other organizations ,will also be discussed.",Sugi-81-47 Gleason.pdf
"SAS AS A PEDAGOGICAL TOOL IN CORPORATE MANAGEMENT EDUCATION Nelson M. Fralman, Internatronal Paper Company and Murray Mohl. Seton Hall University Introductron Management educ~t;OIl is but one- of several activities aiming at improving the effectiveness of purposeful organizatTons. It alms at developing a broad range of abitities. based on appropriate knowredge. attitudes and skills, to enabte participants to cope with a variety of tasks.- often HI defined. in many different organizational settings. The objective of trainfng on the other hand is to develop highly specific and Immediately useful skills. It is intended to prepare people to carry out well-known tasks in well-depleted job settfngs. Desired results can be achieved only if correct decisions are made. The key activity of good managers should be competent decision making. This should be based on sound Judgement. We are assur:ning here that decision making In an organitatlonal settln.g follows a rational and loglcar p.rocess. If this is the case~ some of what Is ratl.nal and logical can ultimately be translated into mathematfcal terms. These can be Incorporated into quantitative models and processed with the help of computers. Great value has been placed upon the development of analytical skills by the manager: the abilities to quantify. to build models to simulate alternatlves~ to assign pr-Qbabilitie;~ to evaluate.. to choose rationally among va rlou$ alternatives. The plethora of MBA programs is testimony to the belief that such skills can be developed _through formal educational proces$es~ This paper presents the results of what we believe to be a successful attempt to meet the needs of management education and develop managerial decision making skills. Approach A course in Quantitative Methods for financial personnet was to be introduced into the Financial Management Education Program (FI NMEP) at International Paper"" Company. The objective was to develop an understanding of the general theoretical const",Sugi-81-48 Fraiman Mohl.pdf
"This paper will discuss the SAS training techniques used -in the training program at Kentucky's Depart­ ment for Human Resources fOT all entry­ level programmers. These techniques include, A rso CLlST as a tutorial, an in~house written primer, and 3 sample SAS jobs as examples. Since SAS is such a powerful and useful tool for many applications, the Department for Human Resources teaches SAS to pro­ grammers, regardless of the responsi­ bilities they are to assume. These programmers mayor may not use SAS after training, but they are made aware of its applicability, simplicity, and quick result's. The eLlST tutorial forms the core of our SAS training with the primer and sample jobs serving as resource aids. Trainees are able, with a minimum' of personal assistance, upon completion of the tutorial to write SAS programs to fill most simple requ~sts we receive. OUr primary use of SAS is fo~ one-time reports on a wide range of file layouts.",Sugi-81-49 Wilson.pdf
"THE IMPLEMENTATION OF SAS VIA SUPERWYLBUR AT AIR PRODUCTS AND CHEMICALS, INC. T~ J, Cenna & 7. J. Bzlk INTRODUCTION A Dumbec u[ ~~o[eHslona16 at Air Products and Chemicals require the ability to conduct statls­ tl~al analyses via SAS, but do not want to learn a computer lansuage in order to do so. This paper addresses an approach to resolving that problem by making the user input as effortless 88 possible, while returning to him a vast amount of statistical information which he probably would not request were he coding a SAS program himself. The concept was implemented using both the text editing and remote job entry fa~ilitiea available in SUPERWYLBUR, in conjunction wlth SAS. WHAT SUPERWYLBUR DOES SUPERWYLBUR is an interactive computer system marketed by Optimum Systems Incorporated (OSI). As uSed herein. interactive means that SUPER­ WYLBUR interactively builds a set of code which is then submitted as one entity to the mainframe as a batch job. While all faatures of SllPER­ WYLHUR are used at Air Products and Chemicals~ only the following are of importance in the con­ text of this presentation. SUFERWYLBUR 1. Provides a cDmprehensive text editing facility at a CRT or typewriter terminal~ 2. Provides the ability to create~ modify, sto~et and retrieve text or data. This permitQ URer~ to have and maintain personal databases. 3. Allows macro progra~ng. the automatic processing of a sequence of SUPERWYLBUR co~nds. A SUPERWYLBUR macro. unlike a SAS macro, is an interactive program. 4. AllO'Ws remote job entry and retrieval from the computer's normal batch stream. these features can be integrated with SAS as described in Figure 1. ThQ user, Whil@ loggBd onto the SUPERWYLBUR interactive computer system~ calls up a SUPER­ WYLEUR macro program by the use of a keyword. This interactive program thBn queries the user in English text. Based on responses to these queries, the macro copies portions of a candidate set of SAS code and merges this code with ,8 data file to form a t",Sugi-81-50 Cenna Bzik.pdf
"O~9'tal computer applications 1n industries, in business and in higher education are ever in­ creasing. It is usual that available softWare packages of subroutines and subprograms in science and engineering dre written in FORTRAN. Recently, SAS became popular due to its data management capability and scientific computation capability. While applications of the software packages require considerable working knowledge of FORTRAN· in engineering and technological prob­ lems, beginners of the SAS applications to these problems find it easy and convenient to employ the SAS language in their analysis and design. Three examples SOlved by senior students in the College of Engineering at the University of North Carolina at Charlotte demonstrate the advantages over FORTRAN as one applies the SAS language to the technical problems.",Sugi-81-51 Kim.pdf
"CPMS: A PRUJECT MANroEru:NT SYSTFM IMPLEMENTED IN SAS79 James W. Bash, ~lS, University of Illinois at Chicago Circle David A. Merrill, ~IS, University of Illinois at Chicago Circle Linda J. Maher, CAGIS, University of Illinois at Chicago Circle Introduction The Cl'GIS Project Management System (CPMS) is designed as a flexible- and comprehensive set of tools for organizing and managing small pro­ jects. The system addresses resource utiliza­ tion and staff acti~ity and provides a structure for monitoring the statllS of projects. Data gathered for production purposes provide a rich source of information for evaluating productiv­ ity, distributi"""" workloads and as indicators for estimating time and cost for future projects of a similar nature. At the outset -of the CPMS project, a review of the literature pertainill9 to management information systems' waS urxlertak.en and based upon the results of this effort the basic CPMS model was developed. Th. syst .... evolved over a considerable period of time on an ad-hoc basis as staff were available for design and implemen­ tation and as needs arose. SAS79 is t.rlell suited for this kind of developnent process.. IIlltledi­ ately needed products could be o<eated within the broad structure of the general system design. Jldditional reports and analyses could be prepared as required. Including new data elements poses no great pr-oblem so that as design imperfections surfaced, modifications could be installed quickly. Some backgroW""ad on C1tGIS is necessary to understand the context in Whicb CP.MS developea. '!be Chicago Area Geogra(tlic Information stooy (Cl'GIS) is a part of the Department of Geogra­ ~y, University of Illinois at Chicago circle and is tied to the Office of. Health Information, Center for the Study of patient care and C0mmu­ nity Health, University of Illinois at the Medi­ cal Center. CAGIS eng~es in information research and service with special ernJ:hases on studies of customer/patient origins, tributary area de",Sugi-81-52 Bash Merrill Maher.pdf
"AUTOMATED MANAGEIIIlNT OF THE REGULATORY ASPECTS OF THE DEVELOPMENT AND REGISTRATION OF PHARMACEUTICAL PRODUCT~ D. K. Jackson I F. A. Adornato, Jr., R. A. Michalak, C. A. Simon, and C. s. Snoddy, Jr. Regulatory Affairs - International (aA-I). Merck Sharp & Dohme Researc.h Laboratories;jo Jolet'ck & CQ •• Inc. is active in the administrative aspects oft planning. obtaining clinical study authorizations. conducting clinical drug trials and the international registration of new pharmaceutical products. The past decade has seen an inCl'aasad interest in Good Clinical Practices with heavy emphasis being :plac.ed on the doc:=umentation of all aspects of clinical studies. As communications between worldwide regulatory agencies and the number of studies conducted by Merek have increased, the ability to respond in a timely, efficient and eff~ctlve manner to regulatory questions and reqLlirem~r.ltli! that continue to grow in number and compl~xity has become mandatory. To meet this need RA- I developed an automa~ed integrated info~t1on sys~eIJ.. Prior to the development of the system, each area wi~hio RA-I maintained numerous handwritten lags c.ontaining administrative information from documents received in the department.. These logs were used to dOCUlll-ent the. development of each clinical program. Aa a program is planned information is gathered on the number and types or studies to be conducted. and target dates are set for each step necessary to conduct the studies. process the data, summarize the results and file f01"" registration. Protocols are then wriu@n for each type of study to be conducted and clinical supplies are manu­ far:tured and packaged according to the protocol 8uide11nes. As investigators are solicited to conduct a study. a signed protocol along with 8 statement of education and experlenc~ is ob­ tained and clinical supplies ahipped to the investigator.. Patient data captured 00 case report forms b received in the. home office and the information contained",Sugi-81-53 Jackson Adornato Michalak Simon Snoddy.pdf
"IMPLEMENTING A SAS CENSUS DATA COLLECTION SYSTEM Alvin M. Best, III and C. Royce Claytor, Richmond Public Schools Stat~ law requires schoo1 distr~cts in Virginia to enumerate all school-aged children every three years. From these counta~ one percent of the state salea tax 16 dietributed to localities. During the three years between school censuses) the City of Richmond ~an acquire $25 million. The schoo1 census then 1s an undertaking with major economic repercussions. Not only is the money received from the state a sizeable amount, but also the expenditures required in collecting, mBnaging~ and analyzing a data base for a city of 90~OOO housing units are high. Therefore, questions arose as to how the process cou1d be done more effectively than the previous time. In 1916-17, the City Data Processing De­ partment (DP) designed and implemented a census sy-stem 1n ,COBOL which compiled an address list, input the keypunched data, processed 1t, and produced progress and summary reports. A number of problems were encountered in communication between user and analyst. timing of accomplishments. miscalcu­ lation of age for state reports. use of out­ dated student files, lack of a requested pilot, and cost overruns in the DP area. When plans began for the 1980 school census, the school system was eager to lower the cost of enumerating children, to have a tighter control over the entire prQcess., and to eliminate past problems ~n the DP area. In the interim~ the sehoal administration had acquired an Nes Sentry 7008 scanner and felt that data entry would be better handled through this medium~ Also, a new staff member (the first authQr) had arr~ved ~th sufficient programming expertise to carry out the project~ the ~mainder of the data processing· staff for the project (the second author) had acquired data processing and programming experience in two years of in.c.reasingly sophisticated S.AS programming. Our supervisor's optimistic at:t:itude was that 1f we could do the j~b l1in",Sugi-81-54 Best Claytor.pdf
"Research Information Management and Analysis System (RrMAS) is an interactive data management and analysis system.., utilizing IBM T-iJiLe Shar,ing Option (~SO), command procedures (CLISTS)I and the Statistical Analysts System (GAS). RrMAS tmplements a data security system while main­ taining a complete audit ~rai1 of all changes to the database. The maintenance and generation of reports can be acco~llshed by non-data prOQessing type personnel. Rl:MM 1s dir-e:et.ed by l,lBer interact.ion and by accessing data structures describing OS files cont.aining BAS da.ta sets I the SAS data set names in the OS files, the variable names on the data sets. and other pertinent information concerning the database. The management process is imple­ mented through macro libraries and the genera­ tion of files CQntaintng JCL and SAS eode. ~e RIMAS generated BAS jobs are subm1~ted thIough RIKAS via ba-ck.ground or foreground processin9 to perform the desired datil management task. This paper MI;IC.t'ibel;l how RINAS ts used to NnaC}e information for a research project by descrihing the CLIS~S. macro librllriee, format libraries, and data structures involved. The result of increased data processing activities b? non-data processing type personnel with leB& programmer intervention through the use of RLMAS will also be di8eu9liJed.",Sugi-81-55 Haupert.pdf
"READING DATA FROM AN IOMS DATABASE USING SAS Richard Nelson, cremson University John Trice, Clemson University Academic Computing Support of Clemson University has' developed an IDMS database application to record the information associated with the activities of tile Computer Center. Along wjth an onfine system to update the database, there was a need to develop a reporti ng system to generate a Variety of reports. SAS fnstitute does not provide a way to retrieve data from I DMS directly. Therefore, a procedure was developed at Clemson which will read the IDMS database, create a SAS dataset and allow processing by SAS on that SAS dataset. This paper will describe the database layout, the reports that are ge'nerated from the database and the procedure that was used to create the SAS dataset that is used in . generating the reports. AIJlR-CD( tUH'I1Iii ""'"""" IF I ZD I CR.C 2Z1 Iv I 1I2S I au: 0IlIWIIIEJt IB> AllR-ID-fUIIER ~ lIt6-IIIUL _IL The two areas that are currently in the Computer Center database are the address area and the short course preregistration area. The address area contains the mailing addres.s of people who want to be sent the Computer Center Newsletter, the Computer Center bulletins, or who are registered for one of the Computer Center short courses. The short course preregistration area contains all the Computer Center short courses, the teachers who are teaching these courses, and rnformation on the people who wish to attend the courses. The layout of the database is in the Bachman diagram that follows: TEACI£R STUEIfT IDlJF 7Z I CR.C ''IF I 12 I CR.C TKB-ID-fUIIER I~ B1UJ.. UHI.tI£R IIlN !HIlT -alJISE 6HlRT-alJISE / ~~ 1 8 i i: alUIIE: 6ECTIIlNB 6EC-8T\I-..CT ... IF I UlO I CR.C !XlllIi&&-&EI:TIIlNB aME£-IUEEII lit! N'O IIR EDnal 1HJIT-alJISE .... Iv 86 I VIR CIIlRIE-6ECTIIlNB I !HIIT-alJISE Figure 1 Database Diag ram 305 6ECTIDNB-Ct .... IF I Z4 I VIR N'O IIR SORIUl BECTIDNB-Ct I 1HJIT-alJISE ~I I: ;,' Doe report that is generated reads the pre",Sugi-81-56 Nelson Trice.pdf
"GEOGRAPHIC AREA PROFILING USING SAS John Blodgett. University of Missouri St. Louis INntODUCTlON The Geogzaphic Area Profiling System (GAPS) was originally conceived 88 8 tool for assisting urban ,transit planners in the evaluation of p~opo8ed alternative transit networks. The planners were interested in being able tg describe a specific route or set of routes. and wanted the system to provide them with a demographic summary of the geographic units adjacent to or witbin a .pecified distance of the route(s). It was assumed that a DIME-type geographic baBe file (GBF) wo~ld be available to provide the b~sic information about the street network and the associated geog~aphic units. D~mQgraphie information ~ould be supplied from U.S. CEnsuS suamary files. from survey s~ary files or from other loeally generated geographic summarieB. The system as developed p~ovides thes~ capabilitie~ and ie sufficiently general to handle many other area profiling ~equesta such as alternate site evaluations. SYSTEM CHARACTERISTICS The number mind .. were: GAPS system was designed with a of assumptions and eonstraints in Among the more important of these .A profeseional programmer. experienced with SAS. would be available to assist in creating and maintaining crucial system dBt8sets • • Tha typical user of the system would be a professional planner with only a modest knowledge of data processing. .there should not be any limit on the number of users who could access the system at any point in time. .The 'ystem should be usable both in batch Bnd interactivelj under 'ISO. .Ibe system should giv~ the USer as much flexibility as PQsaible. • Syntax rules for speCifying requests should be kept as simple as possible. .A GBF DIME fils interfae~ ""should be provided to assist transportation planners in creating th€ir geographie specifications. but thi~ interface should be an enhancement and not a required feature. 312 ~The system .bonld be implemented within three to six months at a ~Qst not to e.ceed",Sugi-81-57 Blodgett.pdf
"BIBLIOGRAPHIC INFORMATION STORAGE AND RETRIEVAL SYSTEM (BISARS) Manjeet S. Chhi •• ""., Department of Food Science Leonard C. Moon, Department of Agricultural Economics University of Georgia Georgia Experiment Station, Experiment INTRODUCTION All scient1sts, researchers! or investiga­ tors working ;n an educational or research in­ stitute encounter the problem of cataloging the bibliographic information they continuously collect in form of reprints, reports. research notes, journal articles~ etc. Everyone has their own method of filing and cataloging their collection enabling them to retrieve it as needed at a later date. It is difficult to file an article or a reference under one sub­ ject, category or keyword in the most commonly used systems e.g. that of index card catalogs. It can be very time consuming to have a card catalog system identical to the one used by the libraries which contain author, title, and sub­ ject catalogs. The purpose of BISARS is to develop a sys­ tem to catalog bibliographic information on the computer to update thi s catalog from time to, time and retrieve the fnformation from this catalog by logical use of keywords when desired. Cross-referencing and thus retrieval of in­ formation is easier in the proposed computer catalog system than the most commonly used cata10ging/indexing systems for personal 1i- 'braries. There are other advantages of this , computer catalog. Some of these advantages in­ clude the ability to obtain a listing of all the documents in an alphanumeric order of the assigned document identification code, a list­ ing of documents by the user assigned keywords and a directory of authors along with the iden­ tification codes of the documents associated with each author. Retrieval of information on • selective basis is done by logical use of keywords. These advantages will be easily seen after becoming familiar with some of the fea­ tures of such a system. The approach presented here to have a computer-based system for bibli",Sugi-81-58 Chhinnan Moon.pdf
",. AN INTERACTIVE $AS PROGRAM WRITER APPLIED TO MANAGING A SAS DATA BASE John B. Carney, Jr., USOA-ESS Guy C. Grenier, USDA-FAS INTRODUCTION Our work with the Foreign Agricultural Ser­ vice (FAS) of the U.S. Department of Agri­ culture provided an opportunity to lmple­ ment a $AS-based system for data manage­ ment, reporting., and analysis. The system was- made operational in a very short ""time., owing to the power of the $AS 1 angu age. Later, as we tried to make the reporting system more convenient for nan~techn;cal persons to use. we developed interactive $AS programs to interface the user wHh the reporting system. These Rrompting pro­ grams,. as we called them, make it unneces­ sary to enter any JCL or $AS program state­ ments, reduce the time required to prepare a job to run on the system, and catch most user errors before the job is submitted~ BACKGROUND FAS personnel stationed in U.S. embassies in same 70 foreign countries aid in expand­ ing U.S. exports by providing information on world crop production and supplies, trade conditions, and market opportuni ties. In addition to personnel stationed abroad. agricultural economists and market­ ing specialists in Washington, D.C. analyze the world agricultural Situation, and dis­ seminate infonnation to the agricultural community, Government poT icy makers, and the general publ ic. Data on the 1 argest number of commodities are managed by· the Horticultural and Tropic.l Products Divi­ Sion, one of whose primary responsibl1!ties is Monitoring trade of nearly 600 c"""",""odi­ ties. among 180 countries. As we were in­ troduced in 1979 to FAS. we found that in­ formation on most agricultural commodities was being tabulated and typed into reports by h and, as it had been for over twenty yea.rs. SU1l1l1ary data is presented in about 50 annual Foreign Agricultural Circulars pertaining to world production and trade along with many sp€!cial reports. However,. only a very few corrrnodities are studied on a regular basis because",Sugi-81-59 Carney Grenier.pdf
"A SAS program can be an effective planning tool for a manager with little or no computer training. If a SAS programmer gives a manager a completed SAS program. a cataloged JCL proce­ dure, a set of fl11-in-the-blanks macros. and an input data set, the manager will then have a complete Decision Support System. The macros and the data files allow the manager to play ""what-if"" games and test different forecasts and different sets of business conditions or differ­ ent allocation bases. PROC MATRIX, combined with a programmer-formatted report, facilitates spread sheet formats and thus presents the mana­ ger with the information in the form to which he or she is accustomed. Furthermore, if the user has a macro Which allows a variable number or repeated calls to a macro within the program, he or she can Use an iterative algorithm and test the amount of iterations necessary. finally, year-to-date totals and counters can be stored in SAS data sets in generation.data groups, thus increasing the efficiency of regularly rUn pro­ grams.",Sugi-81-60 Sloan.pdf
"UTILIZATION OF SAS SOFTWARE FOR MARKET-ORIENTEO OATA MANIPULATION James c. Becknell, Carl M. Peters, Michele K. Steigleder Marketing Information Data Systems, Dallas, Texas An Overview of M·I·D-S MOI""D""S 1s the largest interactive data base ever assembled for people in the marketing field. The Mor·n·S system contains a 166 variable data base composed of economic, demographic and sociological variables for every county in the United States Statist-ical package for data analysis Color graphics display package The M·I·D·S system was developed as the most comprehensive, user-oriented system of this type. The interactive features of MOl""Dog permit the retrieval of all data base variables according to the geographic units defined by the customer (e.g. regions, territories, etc~). The list of variables ranges from such com­ monly available statistics as population and households of the county to the more difficult to obtain statistics such as bank deposits f varying agricultural uses in the county, housing figures in the county, and voting records for recent elections. special features of the data base include the ability to index cur­ rent sales or prices back to any year from 1925 to examine real versus infla­ tion apparent gains. The complete breakdown of the Consumer Price Index is also included .. All M.I.D.S variables, which are custom­ ized to reflect the company's own geo­ graphic alignment, can be related to a company's proprietary sales data by using the SAS statistical package. ~he average of sales territories on either a per capita or per household or any otAer basis can be calculated. If more so­ phisticated analysis are desired multi­ ple regression programs can be used to predict the best and poorest sales ter­ ritories. Similarly, discriminant anal­ ysis can be performed which show which M'l-D-S variables define the high and low producing sales territories. Data can be graphically displayed in color. Taken together, the three components of the M.r.D.S syste",Sugi-81-61 Becknell Peters Steigleder.pdf
"i ! I , t ,. ~ , , '. PRODUCTION OF AN ANNUAL OPERATIONAL STATISTICS REPORT DSING SAS Wayne Cornel~us, Southeastern Cooper8tiva Fish and Game Statistics Project Introduction In 1979 the Southeastern Association of Fish and ~ildli£e Agencies decided to compile a docu­ ment containing operational statistics of inter­ est to the 16 member agencies, and to re~se it annually. The 1979 edition had 41 tables in 109 pages.. The Tennessee Wildlife Resources Agency com­ piled the 1979 report from each Stater~ responseS to a mail survey questionnaire, us1ng manual tech­ niques and the labor of many typists to produce the draft copy. After the 1979 report was circu­ lated, the Southeastern Cooperative Fish and Game Statistics Project agreed to produce all future reports using available computer re9ourcea~ espe­ cially the SAS system~ to reduce the human labor required and to allow more data summary (e.g., averages) to be included than had been' attempted. To produce a draft copy of the 1980 re.port, after reorganizing the report so as to-contain two additional tables~ I wrote 43 short SAS pro­ grams to read data stored in an os dataset, mod­ ify the data and produce summary statistics when necessary ~ then copy the infonnation to a print file. This paper describes these programs, Considerations Several guidelines for preparing this report came from the experience of people involved with the 1979 report. these are listed as follows~ * reproduce the style of the 1979 report a8 closely as possible K r~vise contents of the report as ~uggested by the UBeTB * produce totals or averages of data where appropriate * simplify the process of annually updating the data In addition to these guidelines, as they reviewed drafts of ~he 1980 tables I prepared, other staff members offered specific suggestions too numerous to be listed here; often these sugge8tions moti­ vated special programming which { will deacribe in this paper. Style. In the -1979 report almost all tabl@8 are laid out across",Sugi-81-62 Cronelius.pdf
"A MID-RANGE SENSITIVITY PLANNING·MOCEL FOR DYES AND CHEMICALS Patricia A. Hermes and James M. Watts CIBA-GEIGY Corporation Greensboro, North Ca~lina 27409 I. BACKGROUND This planning model was developed for CIBA­ GEIGY's Dyestuffs and Chemicals Division to help them prepare their sales budget each year. This division is the major supplier to the leather~ paper and textile industries of qyestuffs and chemicals that improve the performance of otner finished products. It;s also the leading producer of specialty chemicals for the detergent and cosmetics industry. Some 1,500 colorants and auxiliary products are marketed, The market is considered mature with approx­ imately 2% growth per year. Even the int~­ duction of a new fiber, such as polyester several years ago, doesn't cause market expansion, merely a shift in market share. There is little product differentiation so priCing plays a significant role in product choice, resulting in narrow profit margins. The market is cyclic in nature in that recessions that severely affect the pri~ary customers of the textile and automotive industry severely depress demand. Most dyes are manu­ factured by a batch process so production scheduling and inventory control are challenged by a forecaster's ability to predict what fashion will dictate 10 to 15 months in advance. II. SYSTEM REQUIREMENTS The ons~t of the recent inflationary period~ with higher inventory costs and nar~wer profit margins, p~mpted the D&C Division to seek ways to improve their sales budgeting p~cess. To develop a budget, different numerical values were manually prepared by product managers for approval by upper management. With such an extensive product line - nearly 1,,500 products - developing a strategy was a monumental task. It did not allow the product manager a great deal of time to develop scenarios using sensitivity analysis to see how a change in some values would impact on the overall budget, even on an aggregate level. Observing subtle changes in dema",Sugi-81-63 Hermes Watts.pdf
"SAS APPLICATIONS FOR PERSONNEL DATA ANALYSIS FRANK MARANGELL, TRES SYSTEMS, INC. The area of human resource management in the 1980l s win be especialfy dynamic and demanding in terms of data management and manipulation, owing to several contributing factors: External mandate$ from governmental agencies, bargaining units, and special interest groups necessitate both flexibility in data management and sophistication in data analysis. The increasing costs of both salaries and benefits I in relation to total operating costs, will escalate to the point that more rational analysis and control of these expendTtures becomes mandatory. Cost consciousness, heightened by dimin­ ishing returns on investment, neces­ sitates the maximization of return on all investments, including people. Historically, all analysis of personnel dynamlcs has been oriented toward a three-dlmensional time plane, with varying degrees of success: The Past -- What has happened to the organization in ter-rns of hires, - termin­ ations, proh'lotions I transfers, and :related dynamic movements and what are the implicatfons for the future. Automated tools for this sort of analysis have been imperfec.t, at best. The Present -- What is the intern.al composition of the organization by various breakdowns. These reports are typically line listings, providing few, if any, insights into the planning process. The Future -- Based upon both the past history of events and the current status quo, what are the predktiva factors which must be dealt with in order to adequately respond to future needs. In the broad sense .of manpower planning, this function has been dealt with very poorly, if at all, in most organizations. SAS can be an extremely effective tool in terms of analyzing and disp~aying inform ... tion of i) historical, current, and predictive naturE;!. Some of the features whLch are pilrticularly useful at""e: Bar Charts l Vertical and Horizontal Box Plots and Matrices X -Y Scatter Plots Pie Charts Treating the",Sugi-81-64 Marangell.pdf
"In order to completely describe the biological activity in a body of water~ it is often necessary to perform a wide range of sampling efforts. The diverse nature of the data result­ ing from activities such as trawl sampling, benthic sampling and mark/recapture studies presents serious problems in designing a data base which is both flexible and easily used. The Ecological Services Department of Texas Instruments Incorporated has designed and implemented a data system for fisheries data, based upon SAS data sets and SAS software. By making use of the ability of SAS to emulate a hierarchical file structure, it is possible to split the data into ""levels"" of data resolution, which can easily be recombined in a number of different ways to fulfill report and analytical requirements. The system naturally leads to the creation of a ""data dictionary II , which serves as a common base of communication between biologist and programmer. Significant. reductions in cost and time for report genera­ tion and training have been realized over previously used FORTRAN based systems.",Sugi-81-65 Watson Roth Pristash.pdf
"e a major source of data for crop and livestock estimates made by the Economics and Statistics Service (ESS). Frame construction errors can result in estimator biases, reduce sample efficiency, or both. To evaluate the quality of the frame, an Area Frame Analysis Package was developed which uses the Statistical Analysis System~ The analysis package is intended to be general enough to use for most ESS frames, and complete enough to require minimal programming. This paper briefly describes the area frame sampling methodology used by ESS and some problems encountered in frame construction. Examples of some modules in the package are included~ along with a brief interpretation of the output. Background ESS constructs an area sampling frame for each of the 48 conterminous states (some small states are combined into one)~ The area frame is a n'general purpose"" f.raMe intended to provide data on all aspects of agriculture - crop acreage, livestock inventory, agricultural labor, stocks of grain, etc. Using aerial photography and other supplemental material~ the entire land area in a state is grouped into several strata. The stratification variable for the frame is the extent of cultiva­ tion (0 - 100%). The number of strata varies by state. depending on the state's land use and geography. Each land use stratum is then divided into primary sampling units (PSU's). The PSU's are grouped into what ESS has termed flpaper strata"", which contain, to the extent possible~ adjacent areas of la",Sugi-81-66 Fecso Johnson Geuder.pdf
"The Biomathematical sciences Department in collaboration with the Environmental Sciences Laboratory, performed a survey on the general population of Micbigan. The purpose of the sur­ vey was to determine the health effects on the general population of a highly publicized con­ tamination of animal feed with polybrominated biphenyl {PBS). Measurements were made on a cluster sample of the population at 6 clinics over a 6 month period. The measurements ranged from simple questionnaire items to sophisticated blood and pulmonary tests. Over 2,000 respon­ ses were recorded on each of about 2~OOO people. Management of broad data bases of this type is always awkwardz especially when subsets of data from various laboratory tests trickle­ in for the duration of the survey and when reporting schedules are tight. Management is especially difficult in a research environment where both start-up time and data management personnel are in short supply. However,. rigor­ ous data management policies and powerful management features of SAS allowed the survey to be completed on schedule. In this paper, we discuss the problems encountered in this large medical survey and the solutions to those problems in the context of SAS.",Sugi-81-67 Calhoun Holt Dorph Anderson.pdf
"PROCESSING 1980 CENSUS DATA: SAS VERSUS CENSPAC Kenneth A. Hardy Frank C. Dilorio Judith M. Poole Institute for Research in Social SCience Universit1 of North Carolina at Chapel Hill INTRODUCTION Barring further delays caused by legal ac­ tions against the Bureau of the Census, the first Summary rape File Qf the 1980 Census of Popula­ tion and Housing should be released to the public in the next few months. The entire set of Census tapes will contain information on many character­ istics of the U,S. population for a bewildering array of geographic areas ranging from multi state regions of the United States to counties within states to block groups within cities. This data will need to be accessed and analyzed by govern­ ment agencies, public utilities~ marketing firms and researchers at colleges and universities. Thus, a major problem facing these organizations is finding the most effective software for ac­ cessing and manipulating this wealth of informa­ tion. Because the Institute for Research in Social Science is part of a designated Census Bureau State Data Center and will be the major disseminator of 1980 Census data access and use information to the North Carolina academic com­ munity, it also faces the problem of selecting software for Census tape processing. In this paper. therefore, we address the relative merit of two software alternatives for processing 1980 Census data--SAS and CENSPAC (Census Software Package). We recognize that these two systems are not the only ones that could be considered but after reviewing several other alternatives, felt that they were the two warranting considera­ tion for our particular needs. We will divide Qur discussion into several topical areas. First we will briefly review some important format differences between the 1970 and 1980 Census Summary Tape Files. Second. assuming attenders of this conference are already familiar with SAS, we will give a brief overview of CENSPAC's design and capabilities. Ihird t we will outli",Sugi-81-68 Hardy DiIorio Poole.pdf
"USING THE srR DATA BASE MANAGEMENT SYSTEM AS A GOMPLEMENT TO SAS Jonathan Arlook, University of Illinois Medical Center Researchers assume, I think quite readily by now, that a vast array of computer-based analytical tools will be available to support their research projects. The analysis of data is, assuredly. the researcher's primary responsibility. Yet the need for equally powerful facilities for the management of data is -also evident - certainly to those of us given that management tasK_ At a minimum, the ability to manipulate data for use with sophisticated statistical techniques must exist. Along with a greater reliance on computers in research has come an increase in the amount of data collected and the complexity of relationships inherent in the data. Because of the computer~s power, limitations on project design are less and less based upon data processing constraints. The problems of data integrity and security also add to the demands placed on data management. The Cooperative Study of Sickle Cell Disease (eSSeD) with which I have been associated is a fitting example. The cssen is a prospective study of the clinical course of sickle cell disease. Twenty-seven clinics are paticipating. and approximately 3500-4000 patients are being followed over a four and one-half year period. In addition, appro~imately 800 controls will be followed for a newborn cohort. Data is collected at the individual clinics, buc all processing and analysis of the data is done at a single statistical coordinating center. The information coll~cted includes demographic, historical, laboratory and physical data defined by over 3000 variables. It is estimated that approximately 150.000 forms will be processed during the course of the study~ The esseD project chose the Scientific Information Retrieval (SIR) [1J data base management system (DBMS) to meet its data management requirements. Our choice of SIR may seem contradictory in regard to my remarks concerning the researcher;s analytica",Sugi-81-69 Arlook.pdf
"ON THE ROLE OF REDUNDANT INFORMATION IN ERROR DETECTION Ronald W. Helms University of North Carolina 1. INTRODUCTION Redundant information has played an important role in error detection, and data processing generally, since the earliest days of mechanized data processing. The most obvious example, and one pertinent to error detection, is the use of verification in keypunching data. However, it appears that no one has previously made a formal study of redundancy in Research Oata Management, especially from a statistical point of view. The purpose of this paper is to present the beg­ inning of such a study and some preliminary results, which indicate that formal consideration of redundant information may produce surprisingly useful conclusions for data management. 2. CURRENT IMPLICIT USE OF REDUNDANT INFORMATION IN ERROR DETECTION All error detection in data management is based upon redundant information~ Familiar ex­ amples are briefly noted in the following para­ graphs. We have tried to find counterexamples; if a reader finds One we WOuld appreciate hearing about it. Deterministic tests are described by Naus (1975) and include both univariate and multivar­ iate tests. BaSically, a deterministic univar­ iate test checks a data value against specified conditions which the data value is required to satisfy. Values which violate the conditions are known to be incorrect. Example: The month in numerically coded ""date of birth!! must take one of the values 1, 2, 3, ... , 12. A deterministic multivariate test checks a combination of two or more data values against specified conditions which the data values are required to satisfy; values which violate the conditions are known to be incorrect. Example: the day of month, month and year, in a numerically coded ""date of birthU must satisfy the obvious conditions that the day of month must be an integer in the range from 1 to the maximum number of days in that month. (These examples are chosen for their familiar­ ity, not bana",Sugi-81-70 Helms.pdf
"al research, the volume of data is often large and the types er.countered vary diuely. Standard editing techniques (i.e. range checks, format checks) will assure that the correct type of data is in the right place. However, minor errors that pass range and for­ mat checks can drastically affect results of analysis .. To prevent this) we have developed some nonstandard techniques for editing data, using SAS. The flexibility of SAS allows us to pro­ duce specialized listings and scatter plots that point out possible errors and inconsis­ tencies in a fashion facilitating easy review. Some of the techniques used are: - listings that indicate the subject's adherence to the visit schedule - scatter plots that display large amounts of data on a single page - scatter plots that highlight ex­ treme deviations from the sample population - dosage listings that indicate whether subjects followed the study protocol - listings of related subject data from different records combined in an easy-to-read format to simplify checking for inconsistencies. With these techniques, many hidden errors are found and corrected before the analysis begins. This simplifies the review process and greatly reduces the need to rerun analyses because of subtle errors in the data. BACKGROUND - STANDARD EDITING TECHNIQUES Usually the first program employed for reviewing clinical data is a field-by-field editor. Variations of this program abound within the pharmaceutical industry, but most generate the following i",Sugi-81-71 Enz Steger Sanocki.pdf
"RULES WE FOLLOWED AND WISH WE HAD FOLLOWED IN MANAGING DATASETS, PROGRAMS AND PRINTOUTS K. E. i'kJller, J. Smith and D. H. Christiansen, Univ. of North Carolina. Chapel Hill ABSTRAC'f This paper presents ·rules used for managing datasets, programs and printouts in a SAS-based data analysis project. First, the limits and natur~ of the type of project are considered The rules discussed have evolved in working with very small projects to medium size projects. A number of definitions are included to help specify the problem. File naming conventions are oiscussed in detail. Although trivial to implement, adherence to naming rules provides a sound basis for high quality documentation. Rules for printout management, keyed to program rules, are presented. Only a small amount of time is devoted to discussing programming style and strategies. A few simple programming rules require little effort to follow, but automatically provide some useful documentation. Finally, archiving and documentation (in the traditional sense) are discussed briefly. Both can be done in a straightforward way if the rules discussed earlier have been followed. CONTEXT OF THE PROBLEM DatasetS· programs and printouts grow like well watered vegetables and weeis around any data analysis project. In this paper, we shall try to present rules for managing them in a SAS-based data analysis project. In order to do that, we shall first discuss the nature of the project to be considered. We :shall discuss naming conventions in detail. Strict adherence to naming .rules provides the basis of our approach ""to high quality documentation. We Shall also discuss rules of printout management, keyed to the naming conventions. A few Simple programming rules will be discussed which can be followed with little effort but which are important in producing useful documentation. We address ourselVes to what we consider a very common research environment. We would say that the type of research project considered is a middle sized",Sugi-81-72 Muller Smith Christiansen.pdf
"MACRO DATABASE 1s a SAS program for summar­ izing entire SAS databases. Unlike FROC CONTENTS which summarizes by dataset, DATABASE combines variable, device, OS attributes, and SAS sttr!· butes from each SAS dataset in the database into a single report. PROC JOIN is a SAS procedure which 'joins' two datasets in the relational sense. PROC JOIN is similar to MERGE except that one observation is produced for each possible combination of the BY variables. Eight SAS date functions and nine SAS functions which generate pseudo-random variates are also discussed, with examples. MACEO DATAllASE SAS MACRO DATABASE is a SAS program for summarizing entire SAS databases. DATABASE gives SAS users a rudimentary data dictionary/directory facility. Unlike PROC CONTENTS which summarizes by dataset, MACRO DATABASE combines attributes from all specified SAS datasets or SAS databases into a single output dataset from which reports can be generated. MACRO DATAMSE summarizes the follOWing attributes: variable attributes: variable name type device attributes: os a,ttributes: SAS attributes: length variable # position format informat label unit device type volser OS dataset name SAS dataset name date created # observations (disk) MACRO DAtABASE works for disk and tape SAS data­ sets and single or multiple dataset databases. Because JM,CRO DATABASE treads' the output from PROC CONTENTS invocations, changes in the physical attributes or layout of SAS datasets are essen­ tially user transparent. The dat",Sugi-81-73 Bragg.pdf
"PROC BACKUP David H. Christiansen and James D. Hosking University of North Carolina, Chapel Hill The INTRODUCTION BACKUP procedure produces an EBCDIC file of raw data records from a SAS dataset. The output file may be a punched card deck or may be written to a user-specified DDNAME. The procedure has several options for recoding missing values with blanks or user-specified values. It provides an easy to use method of creating a transportable copy of a dataset for transfer to a non-SAS installation, backup, or storage. This procedure has also proved useful in gen­ erating raw data files and decks for teaching and testing purposes. OUTPUT The basic output 0 f the BACKUP proce­ dure is the output dataset i tsel f. In addition, a document is printed describ­ ing the characteristics of the input SAS dataset and output EBCDIC file. Option­ ally, the format of the variables in the output file and their names, formats, and labels from the SAS dataset can also be printed. Ectch observation in the input SAS dataset will produce one or more out­ put records depending on the logical record length, the number the record format, and the fied.. Each output record header field containing of variables, options speci­ consists of a identifing and sequencing information, and a data field containing the variable values. The header field contains a mnemonic identifier and a version number that 412 identify the output dataset. Sequencing information used to identify each output record follows the mnenonic and version parameters. If the output dataset is being written to tape or disk, each input SAS observation will usually create only one output record of sufficient length to hold all the header information and data values. In this case the sequence number will simply be the observation number (OBSNUM) from the input SAS dataset. When punched output is requested, more than one output card is normally required for each SAS observation. In order to uniquely identify each output record, the",Sugi-81-74 Christiansen Hosking.pdf
"Environmental research involved in the assessment of new coal conversion technologies must evaluate many biological, physical, and chemical variables to determine environmental acceptability. Inherent in these studies is the use of quality assurance controls to evaluate data base entries, analytical procedures, and program productivity. However, quality assurance controls implemented at the project level are seldom known in detail and lor evaluated when making resource management decisions at the program level. This paper presents a computer based decision support system that assists in management level integration of complex environmental research. The DSS is modeled after an open-ended construct applied to data management systems developed for environmental research programs t i.e., minimal planning effort and a flexible system that can accommodate changing research emphasis. We have found that by interfacing the DSS with the research data base management system, more appropriate statistical measures can be formulated to provide management support for evaluating program progress, status reports of current findings, and comparisons of findings with standards. *Research sponsored by the Office of Health and Environmental Research and Office of Environmental Compliance and Overview, u.s. Department of Energy, under contract W-7405-eng'-26 with Union Carbide Corporation. publication No. 1721, Environmental Sciences Division, ORNL. 1.",Sugi-81-75 Farrell Strand.pdf
"USlllG SAIl ro IlAIUoIlE A lAIIGJ! CLIlIlCAL TIllA!. S'fIIII'f Wl11laa Taylor, Bl~trle Beseareh Iutitute. Inc .. Introduction In 1977 Biometric Research Institute, Inc. (SRI) contracted with seven independent manufacturers to conduct a clinical trial of intraocular lenses (lOL): plastic lenses surgically implanted in patients who have had their natural lens removed due to cataract surgery. This clinical trial required by The Food and Drqt Administration (FDA) to establish safety and efficacy,. is the largest prospective clinical trial ever undertaken. FDA considers IOL! s to be investigational devices that cannot be marketed until the safety and efficacy Is demonstrated and reported in a Premarket Approval Application (PMAA). Each manufacturer must submit a PMAA for each class of lens they intend to narket. Data is collected on two groups: sample of control patients who have only a cataract removed and all implant patients in the United States who elect to receive an IOL. The two groups will be compared for the occurrance of complications and the level of visual acuity achieved. A small group of implant patients {known as the Core Study patients} have data collected more frequently than the rell1ainder of the patients (referred to as Adjunct Study). BRI is serving as the study coordinating center for certain IOL manufacturers. Reports on data submitted to the manufacturers are then submi tted to FDA as part of a PMAA. To implement all computerized study requirements, SAS was chosen as the programt1ing language and data base system. A three-phase computerized da ta processing system was developed to handle the forms proce.$$ing and reporting requirements: - Data Entry Phase~ - Data Edit/Resolution Phase, and ... Report Generation Phase. Data Entry Phase Over 1000 forms received by mail each business day .are opened. sorted by form type, keyed, verified and transmitted as a batch to a computer file. Data is keyed exactly as recorded on the study fom slibmitted by the",Sugi-81-76 Taylor.pdf
"an IBM 3800 laser printer or an tBM 6670 Information Distributor (Word P'rocessor) can make use of many of the inherent features of these devices. Very few changes to their existing programming methods are required. This paper examines some of the features of these devices and demonstrates how these capabilities can be incorporated in SAS programs. I. THE IBM 3800 Many special features are standard in the IBM 3800 laser printer. This printer uses a modulated laser beam to produce an image of a page to be printed on a rotating drum. It can be printed at about 200 pages per minute at a constant speed. SA.S applications programs require no changes to make use of the 3800 when changing from a 3211 or 1403 impact printer. There are many other features that an imaginative user can make use of. These include: 1. Selection of character size and interline spacing. 2. Generation of multiple copies, with each copy an original. 3. Copy modification without program modification. 4. Forms overlay, allowing picture imposition upon output. 5. Inclusion of special graphics characters for plotting/charting. 6. User-defined symbols.. allowing corporate logos to be imposed on the output. 7. Output may be rotated 90 degrees on a page with an optional IUP (purchased prosram). 8: Upper and lower case output. 9. A choice of format characters, allowing the user to ""box"" in his outputs. However, the conversion from an impact printer is not totally transparent to the SAS user. The limitations include:",Sugi-81-77 Oleksiw.pdf
"tedious when there are numerous studies, record types, and variables. To make this prOCeSs more automatic and eliminate duplication of work efforts, we use the programm~ng featur~s in our data entry system (DATA 100 KEYBATC~ SYSTEM) and SAS to create our SAS files. clean and update our data, manage tape libraries, and generate reports. Using S~ col1ectixely and creatively with the DATA 100 KEYBATC~ System has proven beneficial to our data management requirements and our data processing time. INTRODOCTlON Essential to any project where there is a large amount of data to be entered, stored, and analysed, is a data entry system and a data management system that enhance the projects pro­ duction. We have accomplis~d this by using the software within the DATA 100 KEYBATC~ System, in conjuction with the flexability within SAS . to. streamline the creation of SAS files J clean and update our data, manage tape libraries, and generate reports. The DATA lOO® KEYBATCrf'll sya tem is a ""key-to-disk terminal system designed for data entry, data stifrage:, and telecommunication applications ll • User-written control state­ ments, called formats are used to guide the data being entered, and can also modify the data to be output. The formats for input (called JOBINs) define the data for entry, pro­ vide user-specified prompts, and validate the data through error checking tables. Output formats (called JOBOUTs) are for transferring the data to. a specified output device. Data can be inserted,",Sugi-81-78 Eggering.pdf
"l ! ~ ! I ! ! INSTITUTIONAL RESEARCH ~~D SAS Stephen Ahrens~ West Virginia University and L. Robert Kuhn. Louisiana State University Resul ts from a recent national survey con­ ducted jointly by sta£fs at West Virginia Univer­ sity and the University of South Florida indicate a growing dependence upon computerized analyses conducted by institutional research staff at in­ stitutions of higher education. These analyses are being performed for university administrators, state coordinating agencies, federal agencies, the press and general public. Although several computer languages are used by institutional researchers, a recent monograph in the Association for Institutional Research Professional File indicates that SAS is, or should be, the language of choice. The purpose of this paper is to enumerate the reasons for using SAS. as well as. to exem­ plify various SAS computer applications used by institutional research offices. Within the paper, an example of a typical SAS application, inclu--ting the various types of files used, will be documen­ ted. It should be emphasized that this paper is geared toward the users of SAS and not the compu­ ter professional~ Institutional Research (IR) had its begin­ ning as an entity within higher education in the late-SOls. Since its inception there has been no real definition of what IR means. At Association for Institutional Research Forums this topic has been discussed with the result being an agree­ ment to disagree; some argue that there is no de­ finition. Therefor8, one may _put :'::orth ·the state­ ment: ""Typically. there is no typical Office of Institutional Research."" Eventhough there is no widespread agreement as to its definition, there seems to be more agreement on what IR does, or rather should do. In fact, there are two basic camps: (1) Manage­ ment Orientated Research and (2) Scholarly Re­ search (Lyons, 1976). In the authors' opinion. the majority of IR offices are somewhere in between these two ideo­ logical camps.",Sugi-81-79 Ahrens Kuhn.pdf
"THE DESIGN OF A SAS TEST SCORE MANAGEMENT SYSTEM FOR RICI1MOND Pli13LIC SCHOOLS Ann S. Allen and Alvin M. Beet~ III Richmona Public Schools The Richmond Public School System collects and maintains a large volume of test score informa­ tion from a wide variety of tests for its ap­ proximately 30~OOO students. Collecting and managing this information~ integrating it with other sources of information. and producing management reports on extraordinarily tight deadlines is the responsibility of a very small staff. This year, instead of piecemeal systems designed around each individual test, a unified SAS system of test score management ~s designe~ This paper outlines the design of a SAS test score management (TSM) system and discusses its flexibility and its application to other school systems. The d~velopment of this system was complicated by needs; (1) to maintain an his­ torical information base on large numbers of students taking varying tests with different types of scores at many times during the school year and (2) to produce a variety of accurate reports for diverse uses, from management sum­ maries for administrative decision-making and program planning to comprehensive profiles for: counseling individuals and instructing groups of students. The turn-around times from scoring to reporting were usually a matter of weeks and reports using this information combined with in­ formation from other demogFaphic files were needed immediately~ SAS was seen as an optimal tool to manage these competing needs and to maintain the sanity of those responsible for the ~yfltem . PHASE I: PRODUCTION OF AN INPUT SCORE FILE The Item Response File The first phase in the SAS TSM system involved data retrieval through scanning or keypunching. Once the data on individual items was captured in machine-readable form. it was reviewed to verify the subject ID variables~ to edit for valid values and consistent data and to remove duplicate test results. BAS's random access of VSAM files was u",Sugi-81-80 Allen Best.pdf
"tistical computing committee within General Motors formulated design specifications for a corporate interactive sta­ tistical analysis system. In 1978, SAS was installed at the GM Research Laboratories to pro­ vide res_earch scientists and engineers with a state-of-the-art statistical computing facility and to serve as a possible foundation for a cor­ porate statistical system. Through facilities of the TSO command system and the development of several new procedures, the interactive nature of the basic SAS system at Gf'1 Research has been enhanced appreciably. This paper discusses these extensions and concludes with recommendations for SAS Institute on internal modifications to SAS needed to transform it into a truly interactive system. BACKGROUND Since the mid-1950s, the Computer Science and Mathematics Depal""tments in the General Motors Research Laboratories (GMR) have provided statis­ tical computing software for researchers in the Laboratories and for personnel throughout General Motors. While at first this software WaS devel­ oped entirely in-house. in time. subroutine libraries or mathematical and statistical abili­ ties became available. The most familiar of these libraries are the IBM SSP package [1] and. mor,e recently. the IMSL library [21. ])uring the 1960s and early 19708. systems of general purpose statistical procedures became available which could be obtained for at most a nominal fee. Two such systems implemented at GMR were the BMD [3.~J and SPSS [5] package",Sugi-81-81 Gugel.pdf
"1 "" , f: AOTOSAS - A System for Automatically Building and Executing SAS Programs Peter Errington, Agency for Intentational Development We at the Agency for International Develop­ ment have produced a prototype system called AUTOSAS, where a SAS application is built and executed by means of TSO and INQUIRE. There is nothing unusual enough about which to c~ent regarding TSO in the AID scheme of things~ Some points need to be made about AID and INQUIRE, however. INQUIRE was chosen in 1976 as the Agency's data base management system (DBMS) and a large number of our applications have since then used INQUIRE. One such application is the Agency's Economic and Social Data Bank, with which I work. As 1s typical with DBMS'st the organization of the data in an INQUIRE file is a proprietary secret, and one needs to use the INQUIRE query language to create a so-called SAVE file, before other languages such as COBOL or SAS can be put to work on the data. Some of you may have heard of the ""bridge"" between INQUIRE and SAS. It is called INQSAS and is sold by the SAS Institute. The job of getting the data ""out of INQUIRE"" to SAS takes place behind the scenes and is thus (to coin a phrase which I'm sure will catch on) transparent to the user. Unfortunately INQSAS doesn't work for my application, because for four out of the five files we have, the numerical representation is signed zone decimal. The INQSAS bridge does not handle this sort of number, and apparently there are no plans to change it so that it will. Thus one of the problems to be solved with AUTOSAS ~ where the emphasis is on ease of use, was automatic retrieval of data from INQUIRE • .AIrrOSAS also builds SAS programs which are then executed. Let us consider an example, to see how this all works. EX AUTOSAS WELCOM£ TO AUTOSAS WHAT FILE'!' SED[tIFS INQUIRE Ri:L!?:ASE 11 IJEf(Sl(JN 1 07/31/80 THIS lS S'fAIHUf'S FUNCT ION?> T IliEF-LOT WHAT COUNTfi:Y,?>JS6 WHAT VARIABLE'f>POP NOTEl THE JOB D520LC HAS DEEH RUN UNDER tlELEASE",Sugi-81-82 Errington.pdf
"STATAN, A CONVERSATIONAL INTERFACE TO FACILITATE SAS USAGE OR IT PAYS TO GET YOUR SAS IN GEAR Anne M. Parkhurst, University of Nebraska-Lincoln I. INTRODUCTION STATAN. statistical analysis to assist neo­ phytes, is a system of CMS EXEC procedures and FORTRAN programs that provides a psuedo-interac­ tive version of SAS and other statistical packages. STATAN's conversational nature facilitates the use of SAS by asking revel ant questions about data entry, data modification, and statistical ~roce­ dures. Users' responses are checked for spe11ing, syntax and context by a lexical analyzer. Errors are flagged with messages of assistance. This insistance on a technically correct response allows STATAN to produce SAS statements for imme­ diate processing~ giving the appearance of a truly interactive system. Furthermore, STATAN gives primary focus to basic statistical techniques, invoking a global procedure such as GLM under specific conditions such as Regression, ReB. Split-plot, Latin Square or MANOVA. Advantages to SAS users, in addition to the interactive mode, the primary focus, the help messages, and validity checks, are: reduction of SAS training for new users. elimination of recall for the more exper­ ienced, general availability of in-house $AS code, and the ease with which the researcher can compare the results of SAS procedures with those of other statistical packages. The purpose of this paper is to provide guidelines for prototypes and to describe the advantages of this approach. II. GUIDELINES FOR PROTOTYPES 2a. Previous Knowledge The principal value of STATAN is the minimal number of concepts the user needs to grasp before becoming productive. To use STATAN, the user must know: The case or experimental unit under investigation. The variables which were measured on each unit. The structure and location of the data matrix. This information is not always obvious and often it is desirable to focus attention on such pro­ blems. Some examples that come readily to mi",Sugi-81-83 Parkhurst.pdf
"f "" , f PROC EDITOR: A NEW DESIGN FOR THE 80'S Emilio A. Icaza, Louisiana State University INTRODUCTION SAS is a powerful statistical and data management tool which was brilliantly planned in the 60's for the 80's. Considerable.improvements have been made in the statistical and data management of SAS since its first appearances as a commercial product in Release 76. However. aside from the recent developments in the area of graphics, limited progress has been observed in the area of interactive computihg. Granted~ much of the efforts in this area have been hampered by the environment in which the developers operated during this period. That is. if the SAS programmers access to a computer there a remote job entry system (RJE). it could not be expected that they be sensitive to (or even be aware of) the large number of SAS users who had access to SAS through interactive termiRals4 But for SAS to continue to make strides commercially. it must also continue to adapt to the developments in the user enviroment. Online access to a computer using TSO, eMS and even IMS is becoming as American as apple pie and PROC MEANS. Since the evolution of· the software in SAS is due in part to the continued support of its users, and since the heart of an online system Is an interactive editor, this paper describes speci£ications that we would like to see implemented in a- TSQ-oriented Editor of SAS data sets. I have chosen to name this procedure the same as its predecessor. because even though the current PROC EDITOR has been pI aged by design limitations and other problems. its uses of our installation have been extensive and it deserves the credits of being the building block for future generations of PROC EDITORs. DESIGN OBJECTIVES The overall design objectives of the software in SAS are sufficient to develop good quality products for the batch environment. To accomadate online users, SAS must introduce additional objectives which are only of importance to the online environment. In",Sugi-81-84 Icaza.pdf
"A SAS JOB STREAM GENERATOR M* S. Hansard and M. L. Wray, Oak Ridge Associated UniverSities BACKGROUND A job stream generator can eliminate many trivial JCL and SAS errors from routinely exe­ cuted jobs. The job stream generator we devel­ oped is an interactive program which assists users in ""composing U a job for submission. The job stream generator supplies correct JCL syntax and uses data stored in a data dictionary and file log to insert specific file attributes such as data set names, volume serial numbers, and data format. When run on a front-end processor, the job stream generator is especially benefi­ cial in conserving mainframe resources; however, it could also be used to increase efficiency in submiSSion of jobs which are both composed and run on a single mainframe. The job stream generator we developed runs on a DEC PDP-lO (running TOPS-lO) which is con­ nected via two linea to an IBM 3033 (running MVS). Since throughput for batch SAS jobs can be slowed at several uncontrollable places (the line from the DEC to the IBM machine, within the IBM machine and the line from the IBM machine to the remote printer at our site), we could improve overall throughput by reducing programmer errors and minimizing the number of times a job had to be routed through the network. In addition, we wanted to encourage users who were unfamiliar with the rather complicated job submission pro­ cedures to submit their awn jobs~ The idea for a job stream generator evolved as a method for using the computer to do what the computer does best--repetitious work--while freeing the user to think on a p~ane higher than punctuation and JCL syntax. Currently, the user has six options or types of programs which he/she can build and submit for execution. These options are: 1. Run n-way tables using SAS PROC FREQ 2. Run n-way tables using Table Producing Language (TPL) 3. Dump the first n records in a file using SAS LIST 4. Create a .5% test data set on semi­ permanent disk from a magnetic tap",Sugi-81-85 Hansard Wray.pdf
"SAS UNDER TSO; IMPLEMENTATION AND APPLICATIONS Gail Jorgensen, EXXON Corporation Franklin Young, United Airlines INTRODUCTION SAS is a batch -oriented system. However, if implemented carefully under TSO, it can become a ClOS6 substitute to a contemporary interactive system. A contemporary interactive software should have at least these two qualities: - It spares the user from ""superfluous"" tech­ nical details. - It allows the user to control the degree of interaction. This capability is conceptually similar to a generalized implementation of symbolic parameters a la JCL. The majority of the TSO technicality can be re­ moved from the user, thanks to the CLIST language and IBM System Productivity Facility (SPP). Hence, we'l1 first give recommendations on how to write friendly and yet powerful CLIST's for SAS. Secondly I weill show how to implement SAS in the menU-driven environment of SPF. Finally, we'll·present a prototype of a pre­ processor for SAS which allows the user to control the degree of interaction. Our recommendations and proposals are best suited for on-line execution and program debug­ ging (as opposed to interactive research work) . I • CLlST for SAS The CLIST feature of TSO allows the user to execute a group of TSO commands stored in a file with a single statement. In addition, CLlST Is a programming language in Its own right. Its capabilities are Similar to PL/I and include prompting and symbolic param­ eters whose values are supplied at execution time. CLIST can be use:d to minimize the user's knowledge of both TSO and SAS internals. In this paper, we'll concentrate on the de­ sign aspect of eLIST's and not on how to write them. First, we'll review general purpose GLIST's. Seccndly, we'll show how CLlST can be used at times to make 8AB more interactive. We'll give examples 477 of such CLlST's. Finally, we'll present several programming techniques to increase the efficiency of CLlST. 1.1 General Purpose CLlST First, we'll review desirable options whic",Sugi-81-86 Jorgensen Young.pdf
"past decade has witnessed the tremendous explosion in the demand for informa­ tion. This demand, when played against data processing-s ability to respond, have often become a source of contention between users and the data processing personnel. The scenario that follows is usually one of varying levels of frustration as data processing f already overloaded, tries to accommodate this latest demand--albeit a major new system, a revision of an existing system, or simply a one-time ad hoc report--often at the expense of other development work .. Nowhere -is this dilemma more acute than in the case where the demaHd is for on-line/real-time information. Resolving this type of difficulty is not always simple, but the mess can often be mitigated by selecting the most appropriate software to do the job. In a growing number of these instances, SAS has proven to be an excellent tool. Here is how SAS resolved the information requirements of one such system. Background In late 1979, I \'las asked to serve as membership chairman for the Association for science, Technology and Innovation (ASTI), a newly charted independent non-profit organization of professionals who shared a common interest in the management of sclenct, technology and innovation. The purpose of which \'1as information transfer by providing various forums through which topics of special interest could be explored. With 155 initial members, it became obvious that an alternative to the manual maintenance of the club's roll ke",Sugi-81-87 Hoover.pdf
"The availability of non-sensor based measurement capability 1 as p.rovided by the MS-I08 Channel Event Monitor and the MS-I09 Communications Monitor, has added significantly to the volume of measurement data available to the analyst. Merging of this measurement data with measurement data from the host system, such as RMF data, has become a very desirable capability. This paper describes techniques for the transfer of MS Perfromance Data Files (PDFs) to the host system utilizing the Statistical Analysis System (SAS) for data transfer, analysis and reporting.",Sugi-81-88 Mullen.pdf
"USING SAS TO REDUCE COMTEN HARDWARE MONITOR DATA Mary Sue Dickerson and Roger Berry United Airlines INTRODUCTION Hardware monitors are a time consuming lIit::!thod of obtaining performance data; h.owev-er.,with the ACP (Airline Control Program) system at United Airlines, they are still necessa rye The available ACP software monitors do not IDBasure uti 1i""Zd tion S IO r channels, co n~rol units.. and devices. The data produced by hardware monitors is very accurate and ve.rifies sc.me numbers from the ~oftwar~ monitors. SAS has proven help­ ful in m.anaging the hardware monitor da ta. ;OTIVATION United 1-. irlines bas twelve COMTEN hard­ ware monitors. They produce approx­ imately 400,000 records each day f01:· offline reduction.. 'these tapes are reduced for fOtlr separate time periods which cQrrespond to report times for our software monitors. The previously u~ed COMTEN reduction software, DYNAPAR, required a tape pass for each monitor a.nd each time period.. AS a tesul t the offline reduction took approximately three cleck hours of I1on-prime computer time on the IBM 3033. We frequently have a need to reduce a different time Feri-cd ot' to obtain a more detailed analysiS of the data. Sincfdo DYNAPAR is ,t:aramete,r dti -ven, time was spen t to set up control cards .. aecause of long run times, timely resu1 ts could not be obtained.. These problms were solved by usinq SAS to reduce the hardware monitor data. Since the SAS program reads the data file only once"" our dail.y reductions taKe only 3D minut es e la psed time. 496 BENEFITS III addition to solving the above proble.s. SAS has other benefits. SAS is convenient tc use and its doeu.en ta tion is clearer to read than J)YNAPAR's documentation. The data from several monitors cali be merged by time for com­ parisons and calculations. DYNAPAR required all calcula­ tions to be from tne same mcnitor. The plotting capabilities of SA5 have been very useful in problem solving ... Once the data is in SAS format, all stati",Sugi-81-89 Dickerson Berry.pdf
"SASTRAK A CAPACITY PLANNING / RESOURCE MANAGEMENT SYSTEM by Malcolm E. McClain, Federal Express Corporation The name SASTRAK was chosen for our system to denote the fact that our Resource Manage­ ment, Capacity Planning group could use SAS for much more than regression forecasting of future capacity requirements. We planned to reduce the lead time required for fore­ casting by entering performance data daily. Then the function that we called ""tracking"" caul d also be automated. Hence SAS TRACK, or SASTRAK. That original scope has since been extended to several other areas. When I got the SAS User's Guide, and 11discovered"" the power of the Data statement, it became apparent to me that we could automate the data entry function. When I read about the SAS Oatabase, it became obvious to me that we could develop a complete system, with confidence that we could add or delete variables as the needs arose. We could pub 1 i sh Performance Reports, and chart and plot to show trends and relationships. From a start as a forecasting tool, we have expanded SASTRAK into a system to automate much of the menial work of Capacity Planning / Resource Management. As we see it today, SASTRAK is our gopher. SASTRAK gathers the data we need, organizes the data into an easy to use form, and pre­ pares working tools from which we make the decisions. In addition, we have programmed in SAS many of the functions required to keep management advi sed of the perf()rmance of the system, and the longer range resource needs perspective. To give you an idea of our approach to a Capacty Pl anning/Resource Management System, let us first look at a system overview, then look over each of the system eyc 1 es, wi th examples of how SASTRAK helps us keep on top of the performance of our Airline Control Program (ACP) based COSMOS (1) system. SYSTEM OVERVIEW: The major objectives of SASTRAK were to improve forecasting effectiveness l improve performance reporting, and reduce the amount of manual labor involve",Sugi-81-90 McClain.pdf
"read and analyze data. These features of the language make it a very desirable tool for the systems programmer. Most of the uses of SAS in systems programming have been, in the area of SMF/RMF data r.eduction. There at'e many other applications for SAS. This paper will present a few of these applications. PROBLEM: SMP RI;;PORTS IBM's Systems Maintenance Program, better known as SMP I provides an excellent application for SAS. SMP reports are long and it is difficult to obtain a concise report organized in a logical manner, Northeast Utilities Service Company (NUSCO) desired a brief summary of PTF's on its system, ordered by PTF number and also by date. The SAS data handling capabilites also allow listings of all SYSMODS applied and not accepted: SYSMODS received and not applied; PTF'$ that have been superceded; and PTF's applied for each FMID. The method of generating this report is quite simple. First ... an SMP run executes a LIST CDS. The output of the SMP is saved on a temporary disk dataset. SAS then reads the temporary dataset and inputs the pertinent information. The procedure to run this job and a sample output are contained in Figures 1 and 2. PROIlI..EM: ACF!VTAM NETWORK DESCRIPTION Management of large communications networks has become more difficult with their increasing size. NUSCO experienced problems in identifylng terminals with their locations; serial numbers; owners, cables and controllers. For example .. several devices in the same room might be interfaced",Sugi-81-91 Oleksiw.pdf
"GTE has made use of various computer usage reporting tools and systems to meet the information needs of managers and technicians at its sixteen MVS data centers and at the corporate level. In order to consol idate this reporting, GTE has expanded the concept of a SAS performance data base into an integrated multiple level Management Information System. The MIS addresses all aspects of tuning, planning and chargeback associated with computer usage and provides information to managers and technicians at all levels.",Sugi-81-92 Nicola.pdf
"ms that allow the user to compute and plot predicted values and confidence bands for a dependent variable in a linear model using PROC GLM or PROC REG. These estimates are computed as a function of one of the independent variables in the model statement, conditional on user­ specified fixed valUeS for the other independent variables in the model. The predictor variable may be discrete or continuous. The user may specify predicti9n at only particular values of the predictor, or interpolation over the range of t predictor. INTRODUCT I ON When doing research, one typically estimates the magnitude of observed effects or relationships between random variables. This estimation I however, has little meaning wihout an indication of the accuracy of the estimation. One typically satisfies this need by computing confidence limits or bands around one's estimates. The two programs presented here use PROC GLM and PROC REG (availabl in version 79.5 of SAS) to produce and plot confidence bands for linear models. The programs allow users with limited statistical sophistication to easily create confidence bands in SAS. The general approach used in these programs is to use the results of existing SAS procedures to create confidence bands. This approach has two important advantages. First, programs can be applied with a wide range of linear models (note; the program is not designed to be applied in cases inVOlving any random effects). Second, the programs do not require that the user supply an a",Sugi-81-93 Barton.pdf
"The first step in solving a nonlinear equation is to provide some initial parameter estimates and then iterate from these to a final solution. However. without prior infor­ mation~ these initial estimates may be hard to produce. In addition there is always the danger of iterating to a local solution. One way of obtaining help for these problems is to set up a grid of parameter estimates, calculate residual sums of squares (RSS) for each point and search the resulting surface. both for possible starting values and local solutions. For two parameter nonlinear equations PROe NLIN has the capability of calculating and printing the RSS for each point on the grid and produc­ ing a line printer contour plot~ This paper presents a methodology for getting the grid points into a SAS data set and a scaling tech­ nique that has proven useful for subsequent three-dimensional plots by PROC G3D.",Sugi-81-94 Bates.pdf
"S macro to generate random allocation sche­ dules of sequential patient/subject numbers for blocked or unblocked studies in clinical/precli­ nical trials with any number of crossed factors is presented. The rank transformation is used with SAS' UNIFORM function to produce a nicely formatted allocation schedule. The theoretic justification of the II randomness"" of the rank transformation is given and verified by a Monte Carlo example. In addition, examples of the use of the macro are presented. I NTROOUCTION In carrying out research studies in which many experimental units (patients, subjects, etc.) are given various treatment~, a random allocation schedule assigning experimental units to treat­ ments is needed. The experimental units entering a study are sequentially assigned identification numbers which have been randomly associated with each of the treatments. A study of n experimen­ tal units and t treatments (such that n is a mul­ tiple of t) requires nIt of the numbers 1, 2, ... , n randomly assigned to treatment group 1, nit assigned to treatment group 2, etc. Studies are often blocked by certain factors which require each subgroup of size b (such that n isamultip1e of band b is a multiple of t) to be equally di­ vided among the t treatments. Summarizing the problem, we need to generate a random allocation schedule for n experimental units in t groups blocked in groups of b, where n is a multiple of t, n is a multiple of b. and b is a multiple of t. Furthermore, we_~ish",Sugi-81-95 Bolognese.pdf
"the linear discriminant function is homogeneity of the within-group covariance matrices. In practice. this equal covarian<;e assumption is often not satisfied. The facility for quadratic discrimination, 'Which ~es not . require the assumption of equal covar~ances, 48 a major advantage of the SAS DISCRIM procedure. When the pooled covariance matrix is used in the discriminant model, the linear discriminant function is always printed. Unfortunately, when the within-group covariance matrices are used, the quadratic discriminant function (QDF) is not similarly available. A macro, utilizing PROC MATRIX and the output data set created by PRQC DISCRIM, for computing and printing the QDF is described. 1. INTRCDUCTION The basic problem in discriminant analysis is to assign, based on a multivariate observation~ an unknown subject to one of two or more distinct groups. Although methods of discdmination basErl on other assumptions have been proposed, in this paper the underlying probability distributions are assumed to be multivariate normal. Fisher1s linear discriminant function (LDF) is available in most statistical packages and is commonly used fnr discrimination. For a comparison of three programs, see Frazier (l980). The LDF minimizes the overall probability of misclassification when the sampling is from multivariate normal populations with known means and known, equal covariance matrices (Lachenbruch, 1975). In many applications, the assumption of equal covariance matrices is not j",Sugi-81-96 Davis.pdf
"The Geoecology Data Base represents a unique compilation of computerized county-level environment31 data for research and development. The data base contains selected data from extant sources on terrain and soils, forestry, veqetation, agri~ulture, land use, wildlife. air quality. climate, water resource'3 t natural areas, and endangered soecies. The 'Statistical Analysis System (S~S) is used for data storage, retrieval~ analysis and display. Visu~l output such as maps, graphs, and charts are ~,erv effective in conveying information. The benefits of computer-generated graphics for scientific analysis are enhanced by convenience, flexibility, ease of interfacing with analysis and data management systems, high quality resolution, multi-color capabilities. and raoid turnaround. Historically, several mapping programs were needed to display re~ults of studies using the Geoecology Data Base. S~SIS GM~P proc~dure combines many features of these mapping packages with its own capabilities. Data from the Geoecology Data Base will be utilized to evaluate the usefulness of GM~P in lieu of other mapping pac kages·'. IliTRODUCTION The Geoecology Data Ba""se of the Oak Ridge National Laboratory (ORNL) was developed to assist with regional analyses of man's impact on the environment, particularly related to energy use and development. The national county-level information in the data base is organized around environmental themes defined in the abstract (Olson et a1. 1980). The Statistical Ana",Sugi-81-97 Emerson Nungesser.pdf
"ROBUST MEASURES OF SCALE IN OUTLIER DETECTION Paul W. Fingerman, Boeing Computer Services Many modern survey and census systems require the processing of extremely large amounts of data on a recurring basis. In order to guarantee data val idity and at the same time keep the resource reqUirem~nts for survey processing within reason­ able bounds, most such systems have incorporated automated screening and editing procedures. These vary in capability from simple programs that merely detect keypunch mode errors (e.g. a1pha­ betics in numeric fields) to more sophisticated routines that automatically detect unlikely values based on context, and attempt to impute or estimate substitute 'values. In developing specifications for automated edits for the annual Common Core of Data (CCO) surveys conducted by the National Center for Edu­ cation Statistics, one particular kind of edit was proposed to take advantage of the recurring nature of the data being collected (Fingerman, 1979). The CCD program deals with data items like school enrollment by grade, per pupil expenditures by district and so on -- data that are distinguished by their tendency to remain stable over the period from one survey to the next. Thus, a reasonable way to test the val idity of a value from the cur­ rent survey would be to compare it with the value reported the preceding year. While this approach has some drawbacks associated with it (e.g. it tends to introduce a longitudinal bias, since old values are assumed to be IIcorrect""), it cao make a strong contribution when included together with other editing techniques applied to the same data (Fingerman, 1980). In particular, it may be used to identify potentially spurious values that require further attention; simultaneously, a less suspicious value is available (last year's datum) for substitution and use in interim analyses, until the current datum is validated or replaced. A natura 1 way to compare a current value with an archival value is to compute th",Sugi-81-98 Fingerman.pdf
"iller, Louisiana State University In the analysis of linear models with miss­ ing data, SAS GUM TYPE III and TYPE IV sums of squares are different for factor comparisons which contain the missing cells. To determine the hypotheses being tested for each type of sums of squares, GLM will print the estimable functions for the effects of the beta or over parameterized model; however, these ar-e diffieult to interpret. The cell means (full rank) model is presented as a tool for evaluating the hypo­ theses being tested in terms of linear combin­ ations of population cell means. These contrasts are easy to interpret but do not suggest which type of sums of squares should be chosen. The choice of which set of sums of squares are ap­ propriate is a task left to tbe researcher and should be based on the questions and requirements of the experiment. An experiment from the corps of Engineers Dredged Mat~rials project is given as an example. INTRODUCTION The analysis of linear models with missing data has always been a dilema for statisticians. Recently a number of statistical software pack­ ages have been developed to accommodate this sit­ uation (see Speed et.a1. 1978 and Freund 1980). Each program utilizes a different algorithm Which usually vary in the assumptions made concerning the missing data. The widely used General Lin­ ear Model (GLM) procedure of the Statistical An­ alysis System (&AS) exemplifies this problem by . offering the user four different ANOV tables denoted by the fo",Sugi-81-99 Miller.pdf
"THE IMPACT OF RECENT IBM HARDWARE AND SDFTWARE ANNOUNCEMENTS ON THE SAS PRODUCT LINE by WILLIAM H. BLAIR SAS INSTITUTE INC. How recent is recent? The impact of IBM announcamonts on the SAS product line started a long time ago. Many say that IBM's announcement of the unbundling of software and hardware pricing in 1969 led to the present proprietary software industry. That may be true, but it needn't have been. I think there would have been a strong market for quality software products in any event. Nevertheless, the fact remains that SAS grew up under the IBM hardware and as software umbrella. Only recently were we able to move slightly out from under the as softw'lre umbrella and under a similar one, VM. And we have just announced a DOS/VSE version of SAS. But we still remain under the hardware umbrella, and that is obviously the next area to tackle. Over the past few years, I BM has made several announcements that, in retrospect, appear to have had some impact on the SAS product line. I n some cases the effects are yet to be seen, but they can be recognized as significant now. First, I would like to review my list, briefly describing each one, and placing it in time with other IBM announcements and SAS products. Then, I will discuss the individual and aggregate effects of these announcements. 24JAN77: TSO 3270 Display Support & Structured Programming Facility (the old SPF) effectively started the I BM march down the full-screen product road. 3lJUL78: Session Manager (OS/VS2 MVS TSO 3270 Extended Display Support-Session Manager) provided full-screen support for the line-oriented TSO terminal message traffic, journaling of the TSO session input and output, and scrolling facilities similar to the already available SPF. JAN 79: SAS 79.1 available. 3OJAN79: The 4300 series of computers (4331 and 4341) with new levels of price/performance, and the 3310 and 3370 disk drives. 13FEB79: The 6670 Information Distributor, an IBM OHice Products Division product, essentially an",Sugi-82-02 Blair.pdf
"f TUNING THE TSO ENVIRONMENT WITH SAS Kenneth E. Levy, Mobil Oil Corporation lhe process of system tuning has long been shrouded in the mystery of bits, bytes, and program logic manuals. Practitioners of the art use skills which to the uninitiated look like those used by witch doctors and patent medicine saleSlOOn. Ihis paper will attempt to de-ill)'stify the art of system tuning by presenting the methodOlogy used in a large scale lSO system to improve response time. Key to the success of this methodology were the powerful facilities provided by SAS for the manipulation. analysis, and formatting of data. The power of such procedures as mART, PWT, and :mEQ provide an efficient means for quickly analyzing a large quantity of data. SAS allows you to reduce the plethora of data the MruS operating system produces to a managable quantity. The question is. then, where does one get started? What should you look at to determine response time and how do you find the bottle­ necks? Ibis paper will present one methodology used. Specific code will not be included because there are many SAS based packages on the mrket (such as MICS, Merrill's programs, and probably your own in-house developed databases) which will provide the data to you in the form of a SAS database. Each of tbese packages will undoubtedly use different names for the same data elements. The original sources of data used in the analysis herein will be given, so that you may duplicate the processes in your own installation. Mobil Oil Corporation's a,rtheast Computer Center is located at the Mobil Technical Center (MI'e) Complex just outside Princeton, N=,w Jersey. The center provides data processing services to the corporate headquarters staff in ~w York and the reseavch and engineering staffs located at the MrC complex. A wide range of services are available to the users of the center iocluding ISO, VM/GIS. APL, CICS, IMS DB/DC. a sophisticated IMS development and debugging facility, and a large number of soft­ w",Sugi-82-03 Levy.pdf
"GTE Data Services, Inc. has developed a number of computer performance routines using SAS (Statistical Analysis System). This paper will focus on one routine - the analysis of job accounting data from the Honeywell L6 mini­ computer. The Honeywell L6 Model 57 is the large scale model in the L6 series. The job accounting data recorded under the GECOS 600 operating system is less sophisticated than large mainframe computer data, such as IBM's S.M.F. (System Management Facility). However, this data represents the basic system perfor­ mance statistics. The analysis of these statistics involved a mixture of applications, which were time­ sharing, transaction and batch related. Elapsed and CPU timings were reviewed along with peripheral performance for disk, tape, printer, and card input/output devices. Memory swaps were also analyzed. The performance routines were verified by individual runs and validated during three comprehensive benchmark runs. Monthly statistics were reviewed from May and June 1981, to analyze total system performance. Also, these statistics were used in detenmining maximum concurrent user performance. These routines are now available for determining future applications based upon past experience.",Sugi-82-04 Hall.pdf
"CAPACITY PLANNING USING CAPTUREjMVSTM, BEST/ITM AND SAS Robert Ashton, Jeffrey Buzen and Leonard Lipner BGS Systems, Inc., Waltham, Mass. Tn this paper~ we present a method for ca­ pacity planning which illustrates the mutually complementary role~ of CAPTURE/MVS~ BEST/I and SAS. The first two of these are software prod­ ucts developed by BGS Systems, Inc.; they pro­ vide the ability to extract and analyze MVS measurement data, and to project the performance impacts of system or workload changes. In this study, SAS 1::; used in cunjunction with output from the BEST/l iteration facility to generate graphs that depict the performance characteris­ tics of several proposed upgrade strategies. The capacity planning methodology in this paper has been used in a large number of stud­ ies. carried out by BGS Systems consultants and by our clients. It has received widespread ap­ proval. and is routinely considered both credi­ ble and relevant in the minds of senior manage­ ment. The example shown is a stylized version of a specific study which employed this method­ ology. The focus of this illustration, from the banking industry, is an IBM 3033 8 megabyte system, which supports a variety of lluline and batch workloads under MVS/SPl. During prime shift the principal work comes from TSO and IMS, with some background batch work using slack ca­ pacity when it exists. At peak times on a nor­ mal day there are 30 TSO terminals logged in, almost all of them used for program development. IMS consists of 8 message regions, which collec­ tively support both inquiry and update transac­ tions. Strict response time objectives have been set for the thre_e online workloads (TRO, IMS Inquiry, I~S Update) ~ and none have been set for daytime batch. Standards do exist for overnight batch; however experience has shown that a system capable of meeting daytime objec­ tives is usually adequate to handle the over­ nighl work. This sImply means that when growth occurs, the principal questions (for th",Sugi-82-05 Ashton Buzen Lipner.pdf
"CAPACITY PLANNING WITH A SINGLE WORKLOAD MODEL HENRY STEI~1fAUER III - KEMPER GROUP Introduction This paper deals with a SAS applica­ tion using the MICS data base and a queuing model using the Buzen algorithm for solving a central server queuing model. This work was done from February, 1980 to April, 1981. The model was built in November, 1980. The work was started with a 168 MP, 88 DASD volumes. four DASD channels, seven controllers and 11 strings. We had been using the old method of spreading 32 spindles per string. We now have tWO 3033s, a 3081, 19 cD~trollers, 23 strings and 144 DASD spindles. History-Background Our prior way of doing DASD performance was to spread the 10 activity evenly across all the 10 strings and 10 con­ trollers. We did this by massaging the RMF data from the original config­ uration. Then as we added a 3033 processor to this complex, we combined data from both machines and spread the 10 load evenly across all the 10 strings. I knew that there must be a better way of doing this. But I had a hard time quantifying what the actual benefits would be. We, at that time, had all lBI! DASD. Some OEM vendors were anxious to get a foot in the door. One of the vendors offered to do a TO sub-system study for us. We supplied him RMF informa­ tion and workload information. He did a GPSS study of our 10 sub-system and reported that by dividing them up into an ideal sub-system, which we had also described, that we would reduce our average 10 time which would give us the effect of increasing our 10 rate. At that time, I still could not quantify what that would mean in terms of response time. Our management was basically saying ""so what if the 10 time is reduced, lvhat does that buy me in terms of TSO response or a batch job response."" It was at this tir.le that Arnold Allen's IBM course on performance measurement and the use of queuing theory came into play. I found out about using queuing theory models. These could answer those questions. Models were buil",Sugi-82-06 Steinhauer.pdf
"TWO-STAGE CYCLIC QUEUEING MUUEL OF MULTIPROGRAMMING FROM THE NICS DATA BASE GERALD STEPHEN HODGE ATLANTIC RICHFIELD 1. INTRODUCTION: THE DIS-:::::USSION OF THE nr,VELOPMENT AND USE OF PERFORHANCE MAPS FROM TIlE TWO-STAGE QUEUEING MODEL AS FOUND IN A. O. ALLEN (1) AND M. S. DICKERSON AND F. YOUNG (3) DEALS WITIl THE MODEL'S USE AS A CAPACITY TOOL. AN EXAMINATION OF OTHER INFORMATION DERIVED FROM JACKSON'S TIlEOREM (4) SHOWS TI!AT THE MODEL MIGHT BE USED AS A PERFORMANCE TOOL. THE MODEL COULD BE USED TO DETERMINE INFORMATION WHICH IS NOT READILY AVAILABLE FROM DIRECT MEASURamNT SOCReES. A REPORT COULD BE PRODUCED WHICH CLEARLY DEMONSTRATED THE EXPECTED \o,TAIT TTHE FOR EACH COMPONENT (CPU AND I/O), AND THAT REPORT CCULD BE OF USE IN DETERHINING WHERE TO FOCUS SYSTEM TUNING EFFORTS. A TWO-STAGE QUEUEING ~ODEL COULD ADDITIONALLY PRODUCE SUCH DATA AS, UTILIZATION OF 110 AS A SINGLE CONPONENT AS WELL AS THE UTILIZATION OF THE CPU COMPONENT, THE AVERAGE NUMBER OF JOBS IN EACH COMPONENT, THE AVERAGE SERVICE TIM}'; u~.w IN EACH COMPONENT AND THE AVERAGE RESPO;.JSE TINE EXPECTED FOR A TRANSACTION. 1.2 SOURCES FOR THE DATA: WHILE THE ACTUAL SOURCE OF DATA FEEDING THE MODEL WAS RMF, TIlE USE OF M.I.C.S. AT THE ATLANTIC RICHFIELD LOS ANGELES DATA CENTER ALLOWED TIlE ACCUMULATION OF THE DATA AT VARIOUS LEVELS OF GRANULARITY. FOR TIlE PURPOSES OF THIS PAPER THE RMF RECORD TYPES WILL BE REFERENCED, ALTIlOUGH TIlE M.I.C.S. EQUIVALENTS WERE USED. SINCE THE DATA WAS ALREADY IN SAS FORMAT, THE CODING EFFORT REQUIRED WAS CONCENTRATED ON THE ACTCAL HODEL ITSELF. IT WAS ALSO BELIEVED THAT THE M.I.C.S. DATA BASE MTGHT PROVTDE OTHER DATA WHICH COCLD BE USED FOR VERIFICATION OF THE MODEL. 2. THE MODEL, THE PROGRAM AND THE VALIDATION, 2.1 CONDITIONS OF THE MODEL, ---- A.) THE MODEL REPRESENTS A TRANSACTION AS CONSISTING OF SEQUENCES OF GPU AND I/O CYCLES. THE CPU AND I/O COMPONENTS ARE REPRESENTED AS M/M/C QUEUEING SYSTEMS. 29 B.) TRANSACTIONS ARRIVE AT TIlE CPU FROM OUTSIDE THE SYSTEM WITH A",Sugi-82-07 Hodge.pdf
"PREDICTING COMPUTER NEEDS FOR BANKING Robert L. Cofer, Bank of America Introduction Bank of America's World Banking Division (WBD) is preparing a Capacity Planning Method­ ology. WBD has over 100 computer systems in over 50 locations world-wide. Many of these computer installations are experiencing severe growing pains. Electronic data processing in banking has recently shown exponential growth. The business applications' projected rate of growth may soon exceed the capacity of many of these installations. Our Capacity Planning Methodology will allow us to provide timely and accurate planning tools for the EOP managers. We hope to provide an easy to use methodology for all WBO computer installations. Providing over 100 indiVidual Capacity Planning Analyses from a centralized source would be a quite timely and an expensive task. WBO elected to sample ten installations to help verify our Capacity Planning Method­ ology. Four groups of IBM systems are in­ cluded in this methodology: Systemi3, System/34, 4331, and 4341. (Because of time constraints, the 4341 systems were later omitted.) The Capacity Planning Methodclogy is intended to be a planning tool for use with any of these systems. Assumptions OUr Capacity Planning Methodology is based on several fundamental assumptions. These assumptions are necessary to focus the scope of our work and to provide some means of mak­ ing the methodology a general tool for the bank. 1. Bank of America's business applica­ tions are fairly standardized (e.g., savings applications in Hong Kong are very much like savings applications in London). 2. The same application (e.g., Time De­ posits and Loans) run on the same type of system (e.g., SystemJ34) will use roughly the same resources per natural forecasting unit (e.g., 2 CPU minutes per hour per account). 3. Samples of selected sites, within a computer systems group, can be gen­ eralized to the entire group. Sites must run a core group of applications as standard business practices. 4",Sugi-82-08 Cofer.pdf
"The high cost and long lead times of acquiring specialh:ed documenL prucessing equipment in Lhe Cunsumer Financial Services DivisiDn of American Express demonstrated the need for a Capacity Planning System. The system was de­ signed to aid management in anticipating changes in demand for capacity and in planning for ad­ ditional needs before they arise. Forecasts of future patterns of equipment utilization have been developed by combining: o knowledge of hi~tori~~l trends, o forecasts of basic business indicators, and o notices of planned changes in operations.",Sugi-82-09 Martin.pdf
"-:' ARCHITECTURE ALTERNATIVES FOR SAS/CPE SYSTEMS ARTURO G. MARIA, Peoples6ank The Statistical Analysis System (SAS) is perhaps the most appropriate vehicle for conducting ca· pac1ty planning and computer performance evalua~ tion studies because of its flexibility, ability to read different formats of data (e.g. binary, packed, zoned), RMF/SMF data functions (e.g. SMFSTAMP8., RMFSTAMP8., ETC.) and overall ease of use. There are many ways to structure your SAS programs which are intended to reduce SMF/RMF data and produce capacity planning reports. In order to facilitate the processing of data, and improve the index of maintenability of your SAS/CPE pro· grams, several architecture alternatives are available to optimize the many factors that will determine the structure and logic of your CPE modules. For example, whether or not to have an extract phase in your system 1s an alternative that should be evaluated. In some environments, it may be beneficial to structure large SAS/CPE systems in such a manner that an extract phase is run before all other analysis programs. The objectiYe of this short discussion, is there· fore, to explore some architecture alternatives and to enumerate the benefits and costs of such opt; ons. !!A-"".L T!J:E~RN~A'..!.T.!.!IVl!:EcJN""""O'--!..l -,-J'N~0---""oEX:rRACT PHA~~ The Simplest way to structure your program or set of programs (i.e. CPE system) is for each SAS program to read SMF independently. create its own dataset and call its own procedure. 37 Tnis simple architecture offers several adyanta· ges and disadvantages. If the objective is to create a set of programs which run independently of each other, regardless of the system overhead, then this approach is valid. Certainly, in cases where each program runs as part of its own job stream or in cases where the user is not concerned with the sophistication of the jOb-streams, this is a valid architecture. However, by using this approach, SMF/RMF datasets are read over and over, depending o",Sugi-82-10 Maria.pdf
"At the 1977 SUGI Conference, Goodnight suggested that the general form of provided by GLM.may be translated into main effects designs involving any number of and levels. An analysis of his method leads to the conclusion: estimable functions qualitative factors A necessary and sufficient condition for a design construction rule is that it generates a prototype design matrix X* which sat'isfies the identity X*(X'X) X'X=X, where columns of X* corresponding to swept rows of XiX are arbitrary. Selection of a particularly simple form of X* results in the following general rule for construction of design matrices to test specific effects and interactions among qualitative factors, using the general form of estimable functions and based on minimum sample size: (I)Generate the first row of X by setting Ll=l and all other L's to zero. (2) Generate all other rows of X by setting Ll and each succeeding free coefficient to one with the provision: If the free coefficient corresponds to an interaction, then free coefficients for the corresponding levels of all effects and interactions contained in this interaction must be set to one (all others set to zero). The resulting class of designs provides a useful supplement to those traditionally obtained by fractional replication. However, the power of any particular test may vary within the class of equivalent designs, depending on the particular choice of x*.",Sugi-82-100 Dunn Hirsch.pdf
"Abstract Suggestions are made as to the manrer i~ which the Type IV estimable functions are deter­ mined by SAS GIM, and how this is affected by- the sequencing of levels of the factors of the model. 1. Introd"".1ction 'IyJ>es I,. II and III sums of square:.:: in the output of SAS GLM are, in brief, the sums of squares (I) fL""om sequential fitting of factors, (II) from fitting each factor after all appro­ priate others, and (III) from effectively fitting models that have E-restriction:.::; e.g., in E(Y ij ) = I-l + 0:1 + i9 j using La i = 0 and r.~j = O. Searle (1979) gives details. Type IV S~ of squares, on the other hand, are sums of squares corresponding to hypotheses determined ty the computing routine itself. As such, these are hypotheses determined by an algorithm designed to act in accord with good statistical practice: set up a hypothesis and test it. To this extent the routine is mimicking reality, but orly as an algorithmic automaton looking at which cells o:f the mcrlel contain data, and not as a kncwledge­ able scientist thinking about the meanir.g of data. TYPes I, II and III sums of squares arise from a traditional analysis of variance ideology, based largely on the :fitting constants rr.ethod­ ology. Having once determined certain s~ of squares beca~se they tra~itionally have app~ent utility, one then aske IIwhat hypotheses do they test?"" This is just the reverse of good statis­ tical logic Which is, for a monel E(Y) = Xb, to decide first on a testable hypothesi",Sugi-82-101 Hudson Searle.pdf
"ANALYSIS OF EFFECTS ON VARIANCES USING GLM Ro.bert M. Hamer and Barry H. Schwab, Medical College of Virginia Recently, attention has became focused on means for assessing effects on cell variances as well as cell means in experimental designs. Such techniques have become known as the analysis of spread (AOS). This paper discusses a new technique for performing ADS, as well as a set of SAS PROC MATRIX statements which transforms data so that ADS can be performed using PROC GLM (or PROC ANOVA). This technique was developed by O'Brien (1979, 1981), and some of the brief literature review as well as the mathematics are taken directly from his work. Traditional tests for performing hypothesis testing on cell variances (e.9., F =Sl 2/ S/ Bartlett's test, F max, etc.) have many diffi­ culties. Some are usuable only for testing two­ group hypotheses, some are overly sensitive (will reject Ho: when very small differences are present) and nearly all are sensitive to viola­ tions of the distributional assumptions. Thus, in cases where the distributional assumptions cannot be met, such tests may do more harm than good. Because such tests are also restricted to the two-group (or at best the multigroup one­ way) situation, they are not helpful for the case where the researcher wishes to test hypoth­ eses regarding patterns of cell variances in factorial designs (e.g., main effects or inter­ actions). Consequently, jacknife-like tech­ niques have been developed for such situations. Why would a researcher wish to test main effects and interactions on variances in a multifactor experimental design? One important situation arises in Psychiatry in which the classifications may be agglomerations of Iitrue"" classifications. Although traditional psychia~ try, for example, viewed schizophrenia as one di sease (admi ttedly, with different ""types""), the modern view is that schizophrenia is really lithe schizophrenias"" a collection of diseases with a variety of causes, similar manifesta­ tio",Sugi-82-102 Hamer Schwab.pdf
"USING SAS FOR ESTIMATION AND HYPOTHESIS TESTING IN AN UNBALANCED REPEATED MEASURE DESIGN Dav;d D. Morris, Lou;s;ana State Un;ves;ty Charles J. Monlezun, Louisiana State Un;verstiy Kenneth L. Koonce, Lou;s;ana State Un;vers;ty The estimation of means and their associ­ ated standard deviations in an unbalanced, repeated measures experiment is a problem of practical importance in statistical consulting. In many cases the researcher is more concerned with the estimation of means rather than variance componentR. It is the purpose of this paper to present a numerical example and to analyze the example using various statistical computer packages. The General Linear Modelfl (GI,M) procedure of SAS, Harvey's LSMl76. and BMDP2V (1981) will be compared. In order to determine which. if any, of the packages provides the correct information~ exact results will be developed. The sample problem is a repeated measures experiment in which each subject is randomly assigned to one of two levels of a treatment (Factor A) and then measured at two time~ (Factor B) after application of the treatment. The data are shown below. ""1 (k) B2 3 (Y111) 10 (Y 112 ) Al 6 (Y 211 ) 12 (Y 212 ) 8 (Y 311) 16 (Y 312 ) (j) A2 22 (Y I21 ) 28 (Y ZZ1 ) 14 (Y122) 10 (Y Z22 ) Factor A is indexed by j, 1 < j < 2; Factor B is indexed by k, I < k <-2; subjects are indexed by i, 1 ~ i ~ nj -where n 1 '"" 3 and n 2 = 2. Each subject receives one level of Factor A and all levels of Factor B. It is assumed that each observation Y ijk is normally distributed with mean U jk and variance a~ + a~ with Cov(Y ijk , Yi'j'k') """"{ a~ i""""i',j""'j',k+k' o 1#1' or j#j'. The lOx} vector of observations is Y 111 Y - Y112 Y211 Y 212 Y 311 Y 312 Y 121 Y 1Z2 Y 221 Y 222 The variance-covariance structure can be expressed in matrix notation as COV(Y) """" 2 2 GEl + 0pJ. The matrix I is the lOxlO identity 533 matrix, and the matrix J is a block matrix consisting of submatrices, L 0,. ~"" ';""""l:~;""~""' The hypotheses to be tested with this dat",Sugi-82-103 Morris Monlezun Koonce.pdf
"APPROACHES TO ESTIMATION AND TESTING IN THE MIXED MDDEL Kirk Steinhorst, University of Idaho 1. Introducti on The author, in a previous SUGI paper (Stein­ horst and Everson, 1980), outlined a strategy which gives a theoretically sound, yet practical solution to fixed effects analysis of variance problems. In partially crossed-partially nested­ partially confounded designs with balanced or unbalanced data, one should start at th~ bottom of the analysis of variance table (i.e., with the highest order effects) and work up systematically. If an effect is nonSignificant at the .25 level, then pool it with higher order effects. If it is significant at the .D5 to .25 level, do not pool it. If it is significant at the .05 level, then explain the significance before asking whether or not lower order effects are interpret­ able. If one is interested in lower order effects in the presence of higher order effects which are significant at the .25 level, one must address the lack of invariance of the lower order tests and estimates. There may indeed be an interpret­ able definition of lower order effects in the presence of nontrivial higher order effects, but there is not a universally best definition; one must 100kiat the particular experimental setting at hand. For purposes of illustration of the strat­ egy, consider the common two-way cross classifi­ cation in a completely randomized deSign. FIgure 1 illustrates the operational decisions one would make in analyzing the data from such an experiment. First, one must consider the inter­ action using either ~ priori knowledge or a test of hypothesis. The main effects may be treated in one of three fashions depending on the out­ come of the interaction investigation. The top box represents GLM's type II sums of squares. The bottom box could be type III or type IV sums of squares or maybe neither. The middle main effect box presents the most difficulty and sug­ gests that the final disposition will depend on the interpretation of th",Sugi-82-104 Steinhorst.pdf
"When information from different sources is used to construct a matrix of correlation co­ efficients, the matrix may not be positive def­ inite. If it is not positive definite it is not a matrix in correlation form. A technique is described which will convert the matrix to correlation form by shrinking the correlation cDefficients. The method is such that the resulting matrix can be chosen so that it has a specified condition number. A weighting scheme is also described so that correlation coeffic­ ients which are known with more confid'ence will be shrunk less than those with less confidence. 1 .",Sugi-82-105 Milliken.pdf
"With the help of PROC BMDP and PROC SPSS it is easy within SAS to use BMDP and SPSS. Both of these packages have new multivariate analysis of variance procedures which are especially convenient for repeated measures, univariate and multivariate. Although BMDP already had a fine univariate repeated measures program, BMDP2V, the new BMDP4V has the ability to do simultaneous univariate and multivariate analyses of repeated measures on one or several variables. SPSS MANOVA shares this and also the ability to generate orthogonal contrasts between subjects and within subjects. In some repeated measures situations~ SAS GLM may compute inappropriate ~um~ of squares. This paper discusses details of repeated measures features and others which supplement those of SAS GLM. The three programs are compared with respect to documentation~ control language. and output. A special consideration here is the choice of output - what is automatic, what is optional, and what can be turned off. The importance of the package environment is emphasized with respect to flexibility in plotting. Computing Tukey's one degree ~f freedom for additivity is also a test for flexibility. In these and other respects GLM compares favorably. 1.",Sugi-82-106 Berk.pdf
"This paper covers the basic concepts underlying the multivariate approach to repeated measures ANOVA. There are two main reasons for using the multivariate rather than the univariate approach. One, the multivariate approach has some computational advantages on digital computers. Two, the multivariate approach requires fewer assumptions. The univariate model and its assumptions are illustrated by several examples. then the multivariate approach is illustrated for the examples. The multivariate approach involves two key concepts. First, the repeated measurements on each subject are treated as multiple dependent variables ~athe~ than as diffe~ent levels of one o~ more factors USing a single dependent variable. Second, by using suitable t~ansformations of the dependent va~iables. the ~sual ANOVA hypotheses can be tested. Finally. ~f the transformations are of a particular type (orthonormal). it is possible to obtain the results of the univariate approach from the multivariate approach. The paper concludes with a brief mention of existing SoftWare packages __ including SAS which implement the mUltivariate approach.",Sugi-82-107 Wright.pdf
"REPEATED MEASURES ANALYSIS FOR PROGRAM EVALUATION Garrett K. Mandeville, University of South Carolina Introduction As is well known in the community of con­ sultants, planned research strategies often go-­ as the ""well made plans of mice and men"" --, astray. This paper describes a situation of this type. The writer was requested, at the end of the ""experimental period,"" to develop a le­ gitimate post-hoc design in spite of the fact that data on the dependent variable(s) had DoL been collected on the control group. After lengthy discussions with the project staff it was determined that the only possible solution to the problem would be to use as the dependent variable(s), extant data which had been rou­ tinely collected for the experimental group and another ""substitute"" control group over a period of years. These data were available for a three year time period with the first year reflectIng the pre-e~erimental condition. Data for the second year were gathered after onset of the treatment and should provide estimates of the treatment effects if other confounding factors are properly controlled. Similarly, third year data should provide an estimate of the cumu­ lative effects of the exposure to the treatment for two years. Thus, the data could have been cast intu a rather abbreviated tIme serIes but. considering the number of data points. the so_ called repeated measures or mixed model ANOVA seemed more appropriate. ~tudents of ANaVA are well aware of the inconsistency of the literature concerning the proper approach to the analysis of data in a repeated measures design. Issues that arise include choices from among the various univariate and multivariate solutions~ the necessity of testing the model assumptions and the robustness of the univariate solutions, and the identification of a defensi­ ble sequence in the solution strategy. Considering the large number of comparisons to be made (to be described in the next section) the writer felt it advisable to create an """,Sugi-82-108 Mandeville.pdf
"l i , , ) EVALUATING LINEAR MODEL REPRESENTATIONS OF CUBIC SPLINES USING PROC REG Hina Mehta, Thomas Capizzi Merck Sharp & Dohme Research Laboratories 1. INTRODUCTION Spline functions, are defined as piecewise continuous polynomials of degree n with n-l continuous derivatives (1-13). The abscissa values corresponding to the join points of the spline are ~alled. knots. Quadratic and CUbLC sp!lnes seem to be the most popular among statistical practitioners because of their computational simplicity. At least five papers presented at previous SUGI conferences ~ave dis­ cussed applications of spllne functions (1-5). Once the number and location of the knots have been specified, the spline can be fit to data using ordinary least squares. There are several linear model representations of a sP~i~e func~ tion. They are: (a) + functlons (6;7;8) (b) ANW-sp1ines (9;10;11) and (c) B-splines (12;13.) The '+' function representation is the simpler approach both for under- . standing and statistical hypothesls testing. If the number of knots (i.e., polynomial pieces) is large or if the knots are placed close together, then this representation is thought to be an ill-condi~ioned linear system because of multl­ collinearity (cf. 7;8;11). However, no formal work seems to have been done in determining specific circumstances which will produce ill-conditioning. The other two representations are considered more stable and compu­ tationally efficient basis for fitt­ ing splines using linear models. Their motivation is analagous to that of orthogonal polynomials and transformations of the predictor variables in order to make the columns of the design matrix orthogonal in ordinary polynomial or multiple regression. The purpose of this paper is to show by applying diagnostic procedures for col linearity obtained with PROC REG to a published data set (14) that 1) the '+' function linear model approach suffers from degrading collinearity with just two in­ terior knots whereas the 'ANW' and IB'",Sugi-82-109 Mehta Capizzi.pdf
"nt tool in computer facility management and control. This paper presents a generalized approach to the design of a PMS and, as an example, the PMS designed by the MITRE Corporation for the Spacecraft Software D1v1s10n of NASA at Johnson Space Center. 1.0 INTRODUCTION Performance crises. workload characteriza­ tion, forecasting, capacity planning. system availability, resource management: these are problems which confront every computer facility management organization. However, the tools intended to solve these problems present problems of their own: diverse data sources, inadequate or inapplicable reports. insufficient data analy­ sis techniques. The solution for these problems is a comprehensive performance management system (PMS). Many computer facilities are beginning to develop PMSs by reorganizing their current meth­ ods of data collection and analysis [1-4]. They are constrained by both the inertia created by historical precedent and use of personnel for solving performance crises. The MITRE Corpora­ tion had the unique opportunity of designing a PNS for a computer facility before its installa­ tion. The Spacecraft Software Division (SSD) at Johnson Space Center (JSC) in Houston, Texas is responsible for the de~elopment and production of the on-board software of the Space Shuttle Orbiter. In FY 1981 SSD received permission to procure its own computer facility. Until then software development for the Space Shuttle Orbiter had been done on computer facilities managed by",Sugi-82-11 Linde Preston.pdf
"LINEAR MODELS WITH DOMINANT VARIABLES Peter S. Lufkin, SysteMetrics, Inc. 1.0 INTRODUCTION Most researchers experienced in applied re­ gression analysis have encountered problems with dominant variables. This is the paradoxical situation where one (or more) independent vari­ ables fits the model too well, or as Kennedy (1980) describes it, ~. (the dominant) accounts for so much of the variation in a dependent variable that the influence of other variables cannot be estimated."" Typically, the dominant has an obvious and very strong relationship with the dependent variable, so that the problem lies with estimating the equation rather than with theoretical difficulties. The statistical symptoms of the dominant variable problem are usually clear: a high multiple correlation coefficient (R2); a very efficient estimate of one parameter - the dominant - in contrast to estimators with large standard errors for the remaining explanatory variables; and parameter estimates often with inappropriate magnitudes and incorrect signs. Such results are virtually useless when the main purpose of the model is to provide specific pa­ rameter estimates. Traditional approaches to the problem in­ clude simply doing nothing, omitting the dominant, or redefining the dependent (Rao and Miller, 1971). These are relatively drastic solutions based on avoiding the dominant variable or ignoring its influence. New estimation strate­ gies may be forthcoming as it is understood that collinearity between the dominant variable and the other explanatory variables is the critical reason for the effect of the dominant. In this paper we demonstrate that such col linearity is largely responsible for the dominant variable problem, and discuss one alternative estimation method based on orthogonalizing the dominant. Attempting to estimate equations with dominant variables can lead to spurious conclusions re­ garding variable selection. Explanatory vari­ ables actually relevant to an equation may seem superfluo",Sugi-82-110 Lufkin.pdf
""" ~-, f , INFLUENTIAL CASES AND TRANSFORMATIONS R. Dennis Cook and Sanford Weisberg, University of Minnesota It is widely held that data analyses based on linear r~gression models should include the application of selected di­ agnostic technique~ LhaL can furnish use­ ful information on the appropriateness of the analysis and on the accuracy of conclusions. In the past few years. it ha~ been recugnized (see. Ior example, Cook and Weisberg 1980, 1982a,b, and Belsley, Kuh and Welsch, 1980) that in­ dividual cases in a data set can exert a substantial influence on the results or an analysis in the sense that the re­ sults based on the full data may differ dramatically from the results based on the data wiLhouL the cases in quesLion. The diagnostics for detecting such in­ fluential cases (and many diagnostics in general) are based on the implicit as­ sumption that the appropriate scales for the response and explanatory variables are known a pr-iol'i. This assumption can often lead to a confused interpretation of the resulLs of a diagnostic phase of an analysis. An outlying or influential case in the original scale, for example, may perfectly conform when the responses are transformed to the logarithmic scale. ThiR eould he because the logarithmic scale is more appropriate than the orig­ inal, or because the choice of the trans­ formation was influenced by the case in question, while the logarithmic trans­ formation is not appropriate. In either situation, it is surely important to know if the evidence for a transforma­ tion iR Rpread evenly throughout the data or rests only wi,th a few cases. The methods for considering transfor­ mations can be divided into those which assess only the need to transform and those which assess need and determine an appropriate transformation simUltaneous­ ly. An example of the former type is the famillar scatter plot of residuals or, preferably, Studentized residuals, versus fitted values or an explanatory variable. In these plots, a mega",Sugi-82-111 Cook Weisberg.pdf
"l I I \ 1 usm:; SPLINE EmCl'IOOS AN) TIlE 00CIl'STR1\P 'ID FIT DIE'FERENrIllL ~ICN ImELS 'ID DATA Ttoras Capizzi, ~ck Sharp and [k)hne Research Laboratories Ibbert D. Small, University of Pennsylvania l. INTRCDucrION AND SUM1ARY Many processes in the natural and p~ysical sciences are descrila:1 by a system of llnear differential equations. Exarrples include expo­ nential grcwth or dec:ay, logistic population growth, corrpartrrental rrodcls, and predator-prey rrodels. If the equations are integrable, then pararreter estimates can be obtained using such tecimiques as (non) linear regression and exp0- nential -peeling. In cases where the equations are nonintegra­ ble, they have been rarely fit to data because of the difficulty involved. Hc:Mever, a rela­ tively sinlple and flexible rrethod which has been shown to be a viable alternative for pararreter estirro.tion of integrable systcrrs (1-3) can be utilized. '!'his method. employs spline regression and differentiation techniques followed by linear least squares to estimate the pararreters of the system directly from the unintegrated form. The objectives of this paper are (a) to apply this :rrethod to a nanintegrable system, narrely the Vol terra-c.otka predator-prey rrodel, (b) ex­ tend the technique by employing the I:xJotstrap. to form the errpirical distribution of the est.:-­ nntes determine the bias, and calculate confl.­ dence'intervals, and (e) discuss the irnplercEIlta­ tion of the procedure using $AS_ The prooedure is illustrated by fittino;r the Volterra-Lotka equations to the Canadian nunk­ muskrat data (4). It is shcMn that these equa­ tions provide additional evidence that a mink­ muskrat interaction exists and further study of nure c:orrplicated predator-prey rrodels is war­ ranted. 2. VOLTERllA-LOl'KA EQUATIONS The Volterra-Latka equations are given by x(t) 5'(t) -a x(t)+bx(t)y(t) (predator) c y(t)-dx(t)y(t) (prey) (l.a) (lob) where x(t) (y(t» is scrre rreasure of the preda­ tor (prey) biorrass at t:irr",Sugi-82-112 Capizzi Small.pdf
"Weibull regression is suitable for analyzing survival data in a regression-like format. This alternative to the Cox ""proportional hazards"" model offers several advantages: The analyst can estimate survival probabilities for individuals, together with confidence intervals. These help him interpret and describe results. A single parameter describes whether individuals have decreasing, stable, or increasing risk (hazard) functions. This helps test theoretical predictions about rising or falling risks. • The method is an M-estimate (from robustness theory), which makes available several practical results. We have written SAS procedures to carry out Weibull regression and calculate the auxiliary statistics required for a satisfying analysis. Several of our procedures lead to novel graphical presentations (e.g. estimates of the combined hazard function of the sample). Our paper will describe these methods and our SAS implementation. The poster session will demonstrate our procedures in action, analyzing a complex breast cancer dataset.",Sugi-82-113 Rogers Hanley.pdf
", USING SAS FOR BOX-COX TRANSFORMATION IN REGIlliSSION ANALYSIS Ollie Frazier and Deepak A. Keshani, Duke Power Company In the regression analysis of data, it is assumed that observations yl'y2' •.•• yn are independently normally distributed with constant variance and with expecta­ tions specified by a model linear in a set of parameter S. In most applications this assumption is not satisfied. Many times, one uses a log model or a square root model in order to obtain a normally distributed error term. This manual process of trial and error can be auto­ mated with a proper procedure. The linear regression model is appro­ priate after some suitable transformation suggested by Box and Cox (1964). It involves using the maximum log likelihood function technique to estimate the para­ meter values. However, the authors have set up a SAS procedure to obtain these parameter values for an univariate model. This procedure is applied to load re­ search data at Duke Power Co. to estimate a missing value of electric energy use of a customer. Many utilities (applicable to other industries) are now or will be billing their customers either on the highest demand for electricity for a certain time period or for each hour of every day. Under these complex billing arrangements a continuous hourly (half-hourly) reading of the electric usage is required. This information will be gathered by either an electronic or an electro-mechanical recording device. With all due respect to the manufacturers of these devlces, a failure will occur at some point in history. During this time period when data is required and the recording device fails, there exists a need for a pro­ cedure to estimate any of the missing points. Our main interes-t at Duke Power Co. is being able to estimate our custo~ers demands at the time when the aggre~ate of all these customers causes peak generation (commonly called system peak). At the present time, this vari­ able is expensive to measure and ~s not known for the ent",Sugi-82-114 Frazier Keshani.pdf
"Four basic types of pharmacokinetic studies - absolute or relative bioavaila­ bility, dose proportionality, food or drug interaction, and multiple-dose stu­ dies - are required in a New Drug Appli­ cation to the Food and Drug Administra­ tion. In these pharmacokinetic studies we have to estimate the values of phar­ macokinetic parameters such as peak con­ centration (C max )' time-to-peak (t max ), area under cu rye (AUC), e 1 im; nat i on rate constant (K), half-life (tI/2), and amount of unchanged drug in urine, etc., to find the best pharmacokinetic model to describe the time-concentration data (optional). and to do statistical analy­ ses to evaluate bioequivalence, effect of food or a concomitant drug, linear kinetics, and drug accumulation. The purpose of this paper is to demonstrate how the uPharmacokineti.c Analysis System"" (PAS) accompl ishes the above-mentioned tasks of analyzing phar­ macokinetic studies. The system consists of a set of SAS macros and a main control file that varies from study to study. This system enables the user to take a umo de1 free u or ""model dependent"" approach in estimating pharmacokinetic parameters for parent drug and metabolites; the system utilizes analysis of variance, linear regression, pairwise comparison, and symmetric confidence intervals to do the statistical analyses.",Sugi-82-115 Chen Wildman.pdf
"1. ~ ,. i THE ANALYSIS OF ECOLOGICAL SURVEY DATA WITH SAS AND EAP Robert W. Smith, Ecological Data Analysis 1151 Avila Drive, Ojai, CA 93023 INTRODUCTION The Ecological Analysis package (EAP) is a set of user-written SAS pro­ cedures which are useful in the analysis of ecological survey data. These types of data are often collected as part of environmental impact or monitoring studies. Both biological (usually as species importance values) and environ­ mental data are collected at several pertinent locations. The first step in the analysis usually consists of finding the biolo­ gical patterns in the data. Although single species can be studied, the main emphasis here will involve the study of biological patterns at the community level. After the biological patterns are quantified and illustrated, they can be correlated with the environmental measurements. The results of this analysis can lead to hypotheses of cause and effect. These types of analyses can con­ veniently be performed with SAS and EAP procedures. As the methods are dis­ cussed, the procedures involved will be noted. METHODS FOR FINDING BIOLOGICAL (COMMUNITY) PATTERNS Agglomerative Hierarchical Cluster Analysis: This type of cluster analysis consists of two steps. I} 'Distances are calculated between all pairs of entities (the units being clustered, which can be observations or variables) These distance values are proportional to the dissimilarity of the entities. 2) The most similar remaining pairs of entities are successively fused to form larger and larger groups until all entities are in a single group. The path and levels of fusion are shown in a tree-like structure called a den­ drogram (Fig. 1). All agglomerative clustering methods are similar in this respect, but differ in the manner in which distances between groups of en­ tities are calculated as the groups are built. Some examples of clustering strategies are complete linkage (used by SAS PROe CLUSTER), single linkage, centroid (Sneath and So",Sugi-82-116 Smith.pdf
APPROACHES TO ESTIMATING COVARIANCE MATRICES WITH PARTIAL MULTINOMIAL DATA W. B. Smith and Mark W. Riggs Texas A&M University and Abilene Christian University 1. INTRODUCTION Canonical correlation analysis is a tech­ nique introduced by Hotelling (1936) to describe structural relationships between two sets of var­ iables. It can be considered an extension of multiple regression~ which describes a relation­ ship of one variable to a set of variables. Just as analysis of variance and analysis of covar­ iance are special cases of multiple regression~ many multivariate procedures such as discrim­ ination and multivariate analysis of variance are special cases of canonical correlation analysis. Multivariate vectors are frequently incom­ pletely observed in experimentation. and many techniques exist for using partial records in the estimation of population characteristics. We desire to extend estimation concepts which use partial records to canonical correlation. This research will consist primarily of two parts: (a) A method for testing the significance of the Akaike information contained in the in­ complete data vectors. (b) A procedure to estimate canonical cor­ relations that will utilize all data available. including partial observations. Estimation of parameters of a multivariate normal distribution when data are incomplete has been discussed by many authors. However~ none of these consider the estimation of canonicnl cor­ relations using incomplete data sets. Most have found maximum likelihood estimates of parameters for various special cases. Wilks (1932) con­ siders estimation for a bivariate normal pop­ ulation with missing data in both variables. as does Anderson (1957) who also indicates how to extend his results to a p-variate normal dis­ tribution for certain patterns of missing data. Srivastava and Zaatar (1973) use Monte Carlo sim­ ulation to compare four estimators of the covar­ iance matrix of a bivariate normal distribution. Edgett (1956) gives maximum,Sugi-82-117 Smith Riggs.pdf
"ROBUSTNESS OF DISCRIMINANT FUNCTIONS Peter A. Lachenbruch, University of Iowa The purpose of this review paper is to describe methods of discriminant analysis, Lo outline the assumptions that are involved, to discuss the SAS and BMDP programs for discrimi­ nant analysis and to focus on the effects on the discriminant fum:tions when the assumptions are violat_ed. 1. Fundamentals of Discriminant Analysis The basic problem of discriminant analysis is to allocate a multivariate observation x to one of two populations. The al10catioo- is accomplished on the basis of the value of the observed random variable and was initially proposed by Fisher (1936) as the linear combina­ tion of observations which maximize the between­ group variance relative to the within-group variance: (1) where x, is the mean in the i th group and S is the co~on covariance matrix. He showed that the coefficients A were determined up to a multiplicative constant by (2) This method led him to suggest assigning an observation to group 1 if ,,' ~ 1 - ; )' > 2(""1 - ~ -2 (3) ("" 1 - ~ ))' -1 - ~2) or 2(""1 i:l. (~1 - > O. ~2 In the example he gave, the famous Iris data I the classification was almost perfect on the basis of a few variables. Note that the same covariance matrix in both groups is assumed. In the Iris data, there is abundant evidence that the data has quite different covariance matrices in the two groups. In this example, the lack of common covariances does not affect the results because the groups are so well separated. In other cases, there may be major problems if the covariances are not the same. Fisher's approach to the discriminant function did not appeal to formal distribution theory for its basis. Welch (1939) noted that one could derive an optimal allocation procedure when the parameters of distributions were known by using the likeli­ hood ratio. He showed that the optimal rule was to classify an observation as population 1 if > 1 (4) 626 where p is the a priori probabi 1 i ty of a",Sugi-82-118 Lachenbruch.pdf
"This paper presents the enhancements in ALSCAL-82, the 1982 version of the ALSCAL multi­ dimensional scaling procedure. The enhancements fall into three general categories: • The range of scaling models has been extended by introducing two options to define dis­ tances according to the Generalized Euclidean Metric (GEM). The options are MODEL:GEMSCAL and DIRECTIONS=t. GEM is an individual differences model with many specific special cases. Specific GEM models include, among others: • • • Carroll's IDIOSCAL model and Harshman's PARAFAC model, a model which assumes that each individual weights the dimensions of an orthogonal rotation of the stimulus space, each individual having a different rotation and weighting scheme. • Tucker's three-mode scaling model, a model which assumes that each individual weights the dimensions of the stimulus space, but that these dimensions are not orthogonal. The obliqueness of these dimensions varies across subjects. • Young's PRINDSCAL model, a model which as­ sumes that each individual weights the di­ mensions of a subspace of the stimulus space, each individual using a different subspace. Two types of aids have been added to the out­ put to help the user interpret the subject weights in the INDSCAL model. • The WEIRDNESS index: ALSCAL-82 prints an index which indicates how unusual each subject's weights are, relative to the re­ mainder of the subjects. • FLATTENED WEIGHTS: ALSCAL-82 prints a transformation of weights which is amenable to tion by linear methods. plots and the subject interpreta- Input/Output options have been simplified and expanded: There is a new PLOTALL option that plots individual spaces and transfor­ mations. The PRINT option now prints dis­ parities as well as data. The READc op­ tions are generally no longer needed. The WRITE option is never needed. 633 ~ General Euclidean Model: An",Sugi-82-119 Young.pdf
"SDISDM, A SYSTEM DESIGN AND STATICIDYNAMIC MODELING TOOL SET Armen Gabrielian. Hughes Aircraft Company 1. INTRODUCTION A distributed computer system is a major component of many of the current command and control systems. Such a computer system may contain several minicomputers. hundreds of soft­ ware modules, a large number of consoles, a few buses, some disks and a variety of other peripherals. The operating system is often limited to real-time processing. but at times, must accommodate other modes of operation such as background processing and interactive pro­ gram development. Data bases may be distrib­ uted or replicated and there are strict req uire­ ments on recovery and automatic reconfiguration ""in case of failure of particular components. The load in command and control real-time process­ ing arises from three sources: internal clock­ driven events, communication input and operator actions. Internal clock-driven events consist of diagnostic programs. graphic refresh data generators, radar tracking routines and so on. These are often executed periodically, e. g., in case of tracking routines at a frequency matching the revolution of radars (except for some modern electronic radars). Communication input data cause processes to be invoked within one or more computers. An operator action at a console creates a transaction that may req uire a series of tasks to be performed in various computers and a response returned to the originating console. The design of the computer system archi tecture associated with a command and control system is a complex process. It requires an understanding of the operational requirements, hardware technology, software issues, human interface problems and logistics. The accept­ ance of the design requires quantitative evidence that the system will satisfy a set of performance requirements. The following two types of modeling are usually used in evaluating a system 1 s performance: • Static modeling • Dynamic modeling Static modelin",Sugi-82-12 Gabrielian.pdf
", ~- Multidimensional Scaling by Least Squares Cynthia H. Null, College of William and Mary Warren S. Sarle, SAS Institute Inc. (Invited) Introduction Most existing multidimensional scaling (MDS) programs use first-order gradient methods or alternating least squares (Schiffman, Reynolds &. Young, 1981. Chapter 16). Even a small MDS problem may require estimation of 100 or more parameters, so first-order methods that require storage proportional to the number of parameters have historically been preferred to second-order methods that require storage proportional to the square of the number of parameters. The development of vi rtual storage has made megabyte regions commonplace, so it is now practical to use second-order optimization methods for MDS. Takane (1981). for example, discusses maximum likelihood MDS in both the metric and nonmetric cases and uses Fisher's scoring algorithm. We will consider Gauss-Newton and related second-order algorithms for least squares metric MDS. MDS could be performed by the N LI N procedure, but the programming statements would be cumbersome. MDS can more easily be programmed using the MATRIX procedure. A wide variety of metric MDS models can be implemented in a few pages of MATRIX code, including the I NDSCAL, I DIOSCAL, and PDSCAL models, confirmatory MDS, and robust MDS. Gauss-Newton can be combined with alternating least squares for very large problems or nonmetric analyses, but we have not yet tried these methods. Gauss-Newton Lee &.- Jennrich (1979) compared several second­ order optimization algorithms for weighted least squares and maximum likelihood estimation in fac;tor analysis. The methods induded Gauss­ Newton, Fisher's scoring algorithm, Fletcher­ Powell, Fletcher-Reeves, and Newton- Raphson. The Gauss-Newton method was considered best because it converged rapidly, was robust with respect to poor initial values, and produc;ed consistent standa rd errors. Let the model be i = 1, ... ,n where )Ii is the value of the depen",Sugi-82-120 Null Sarle.pdf
"~- i f. ! I t I CLUSTER ANALYSIS BY LEAST MEANS Warren S_ Sarle, SAS Institute Inc. Introduction Most existing clustering methods have only heuristic justification. A more satisfying approach statistically is to define clustering models and to fit the models to data using criteria such as least squares (LS) or maximum likelihood (ML). The data analyst can then assess the appropriateness of the model and the fitting criterion for the data and the purpose of the analysis. ML estimation of clusters has been discussed by Wolfe (1970). Hartigan (1975), Oehlert (1979), and Symons (1981), with the multivariate normal mixture model receiving the most attention. For most clustering problems, however, it is difficult to devise a plausible probability model. LS methods often provide useful results when -a satisfactory probability model is not available and are especially valuable for summarizing large data sets. Clustering Models for Rectangular Data For rectangular multivariate data, the usual regression equation Y=XB+E becomes a clustering model if we treat the X values, as well as the R values, as parameter estimates instead of independent observations, and if we place appropriate constraints on the estimated X and/or B values. A model equation for rectangular data is thus: Y=XB+E nxp nxqxp nxp where Y = n observations on p variables, X, B are to be determined by LS, E = residuals, and trace(E'E) is to be minimized. The well-known k-means method for disjoint clusters of observations, implemented in SAS 82 by the FASTCLUS procedure, is obtained from the constraints: 1 651 where ""#"" is read ""the number of. "" For example: 2 3 1 0 0 0 3 2 1 0 0 0 2 -3 0 1 0 0 2.5 2.5 3 -2 = 0 1 0 0 * 2.5 -2.5 -1 2 0 0 0 -1.5 1.5 -2 1 0 0 0 -1.5 -1.5 -1 -2 0 0 0 -2 -1 0 0 0 X indicates the clusters and B gives the cluster means. X is simply a design matrix for a one-way deSign, and we can view the cluster analysis as an attempt to discover what design is most consistent with the data. Ward's met",Sugi-82-121 Sarle.pdf
"ardis, General Motors Research Laboratories ABSTRACT Continuous bivariate data are routinely ana­ lyzed with the aid of a scatter- plot and a corre­ lation. However, these tools have limitations: a scatter plot is not feasible if the data are weighted or grouped, and a correlation measures only the strength of ~ dependence. These limitations are overcome by a new procedure, referred to as SCAN, which was developed for the Statistical Analysis System (SAS). The SCAN Procedure implements a new graphical technique which displays detailed information about the joint distribution of a bivariate data set. The graphical display is referred to as a ""correlation fingerprint"", because it can be used to distinguish and identify correlation struc­ tures. For example, correlation fingerprints can reveal power transformation relationships and departures from bivariate normality. The interactive nature of the Procedure itself is also novel. Execution of SCAN can be con­ trolled by procedure options similar to those of most SAS procedures, or by an interactive inter­ nal ""command processor, or by a combination of these modes. Thus the user can invoke the Proce­ dure with a few specifications, and then interac­ tively modify these specifications with commands internal to SCAN. The two most basic tools for the analysis of continuous bivariate data are a scatter plot and a Pearson correlation. Both of these tools are provided in the Statistical Analysis System (SAS). Scatter plots can be genera",Sugi-82-122 Rodriguez DeNardis.pdf
"An experimental procedure common in applied biological research involves the use of a simple experimental design to observe responses on mul­ tiple variables, often correlated, at several intervals over time. The purpose of such experi­ mentsis generally to evaluate treatment effects on changes in the vector of responses over time. In many such experiments, the vector of residuals exhibit autocorrelation which is strongest for observations contiguous in time and which weaken progressively with increasing lag times. Thus, the error structure can be described by a multi­ variate autoregressive model. While attention has been given to the use of SAS to analyze re­ peated measures experiments in the univariate easel there is no obvious method for using SAS to perform a multivariate analysis when such an error structure is present. The purpose of this paper is to show how SAS can be employed to 1) estimate the autoregressive parameters of the error vectors and 2) use these parameters to perform a multivariate generalized least squares analysis on the data from such an experiment. PROC GLM is used to generate resi­ duals from which the autoregression parameters are estimated, PROC MATRIX is used to transform the data. A set of data collected to evaluate treat­ ment effects on changes in botanical composition over time for a range management experiment at the University of Nebraska-Lincoln is used for illustrative purposes.",Sugi-82-123 Stroup.pdf
"rsity ~d~cal ~hoo~* John A. McKillip. Department of Psychology, Southern IllInoIs UnIversIty ABSTRAcr Although Guttman's Coefficient of Reproduci­ bility (CR) is a widely-used statistic for asses­ sing scale reliability, its statistical basis is not we 11 established in ccmocm use. A minimum value of 0.9 for the CR has becorre the generally accepted standard for a reliable scale, even though the distribution of the CR has been shown to heavily depend, both on the number of items in the scale, and their marginal distri­ butions. The Minimum Marginal Reprcxiucibili ty (MMR) statistic, generally used as an expected CR, assuming a random distribution of responses to scale items, actually underest~tes this value. This paper gives the expected value and standard error of the CR based on the multinom­ inal distribution, as well as the Green's B statistic, an approxiIm tion to it. Expected values for the CR are compared to Green's Band the MMR for a variety of scale itern distributions and by the total number of scale i tans. Ad­ ditionally, a modification to the current SAS GUTTMAN procedure, which calculates the expec­ ted CR and its standard error, is described. These additions to mcx:: GUT'1MAN will increase the usefulness of the CR for evaluating scale relIability by providing it with a statistical basis. INTRODUCTION Gut1man scale analysis has been wi'dely used to examine the properties of carposi te scales in the fields of Psychology and S:Jci­ ology, and ITDre recently, Healt",Sugi-82-124 Weener McKillip.pdf
"I I ( , , PROC TETCORR: CORRELATIONS BETWEEN CATEGORICAL AND CONTINUOUS VARIABLES Michael A. Province, J.Philip Miller. Reimut Wette, Division of Biostatistics. Washington University. St. Louis Missouri In statistics one often encounters categorical, binary data which can be assumed to be a dichotomization of some latent (unobserved), continuous variable of interest. For instance. in a population with a certain disease, it might be postulated that there is some unobserved random variable SEVERITY, and some level of severity beyond which death occurs while below which individuals continue to live. Then DEAD/ALIVE would be a binary index to the variable SEVERITY. In order to monitor the progress of the disease (with an eye toward intervention). one would be more interested in the corre~ation between a laboratory test and the latent variable SEVERITY than in the correlation between the test and DEATH. As another example, consider the case of an infection. In the population as ~ whole, the diagnosis of AFFECTED/UNAFFECTED might be modeled as a a dichotomization of DEGREE OF INFECTION, since even ""healthy"" individuals will have some level of the foreign agent in their system. Again, one might prefer to estimate the correlation between a potential screening test and DEGREE OF INFECTION, rather than between the binary diagnosis and the te st. A latent variable may be observable in principle, but simply not available in our data. For instance, in a census survey. the question ""What is your gross income1"" may be a multiple choice one, The splitting income into groups. correlation between true income and some other variate may be desired. PROC TETCORR is a SAS procedure which can calculate correlations between dichotomized, latent variables, and other variables. It is essentially an extension of PROC CORR, and produces the same correlation estimates when latent variables are NOT involved. In addition to univariate statistics and the sample size upon which the calculations are",Sugi-82-125 Province Miller Wette.pdf
"SOME ASPECTS OF THE RANK TRANSFORM IN ANALYSIS OF VARIP.NCE PROBLEMS Ronald L. Iman, Sandia National Laboratories 1. INTRODUCTION A problem that applied statisticians have been confronted with virtually since the inception of parametric statistics is that of fitting real world problems into the framework of normal sta­ tistical theory when many of the data they deal with are clearly nonnormal. From such problems have emerged two distinct approaches or schools of thought: (a) transform the data to a form more closely resembl ing a normal distribution frame­ work or (b) use a distribution free procedure. The first method may include the log transforma­ tion, square root transformation, arcsin trans­ formation, and so forth. and may even be broad enough to include robust procedures that tend to give small weights to outliers, that is, to observations that may contribute greatly to the nonnormal form of the data. The second method includes a large body of methods based on the ranks of the data. There is a way of combining these two methods by presenting many non parametric methods as parametric methods applied to transformed data. Simply replace the data with their ranks. then apply the usual parametric t test, F test, and so forth. to the ranks. This is called the rank transformation (RT) approach. This approach results in a class of nonparametric methods tn.t includes the Wilcoxon-Mann-Whitney test, the Kruskal-Wallis test, the Wilcoxon signed ranks test. the Friedman test, Spearman's rho. and others. The rank transformation approach also furnishes useful methods in multiple regression, dlscriminant analysiS. cluster analYSiS. analysis of experimental designs, and multiple conparisons. Of course, there are several ways in which ranks can be assigned to observations. The following types are suggested by Conover and Iman (1981). RT-l. The entire set of observations is ranked from smallest to largest, with the smallest observation having rank 1. the second smallest rank",Sugi-82-126 Iman.pdf
"which of two populations is the correct population to which an observed item belongs, the observed item is compared with samples of observations known to have come from the two populations. The sample that resembles most nearly the observed item determines the population to which the item is classified. Procedures for making these classifications fall in the category of discriminant analysis. The most popular discriminant analysis procedures are known as the LDF and QDF procedures. They are available, although not by those names, under PROC DISCRIM. These procedures rely on the assumption of normal distributions for their theoretical basis. If the populations are not normal, the effectiveness of these procedures is enhanced by using them on the ranks of the data, after PROC RANK, rather than on the data them­ selves. This result in a lower probability of misclassification in most cases. This paper illustrates Monte Carlo comparisons between discriminant analysis on the data and analysis on the ranks. 1. I NTRODUCTI ON The procedure of statistical discrimination is simple in theory but not so simple in practice. ~n observation xQ, possibly multivariate, is to be classified into one of several populations 1fl,. •• ,1Tk ,which have, respectively, the den­ sity functions f1(~) , ••• ,fk(~). The deci­ sion procedure is to evaluate each density function at ~O to see which function gives the largest value fi(~O)' and then to declare that ~O belongs to the population corresponding to",Sugi-82-127 Conover Iman.pdf
"USING PROC ALSCAL TO ESTIMATE SCALE VALUES FOR UNIDIMENSION~L CHOICE MODELS Phill ip K. Wood, Search Instit""te Mark L. Dav;son~ University of Minnesota Introduct ion: Choice morlels are frequently oIsed in exper­ iments designed to determine individuals' pref­ erences for one product over another, or for assessing the deqree to which a qiven stimulus has more of a qiven ascribed attribute than another. For example, a researcher interested in assess inq the market demand for a cat may wish to determine the proportion of individuals preferring his company's vehicle over a compet­ itor's. The same researcher may be more specif­ ically interested ;n c1etermining onl.v the per­ ceived difference between his company's product and another alonq a specified dimension. such as economy, style, or ease of maintenance. In many such studies subjects are presented all or many possible pairs of a stimulus set. For each pair, subjects are asked to choose that member which in their judgment contains more of the attribute under study. The basic data of these experiments are probabilities, Pil' the proportion of trials in which stirm.lus j was chosen when the stimulus nair (i,.i) was-pre­ sented. These empirical probabT1Tties are esti­ mates of population values 11""i; defined over a universe of trials. . In this paper we will consider analysis of data from such experiments whose models satisfy equations 1-3 below. For a given stimulus pair C.,:!.. j) such models assume a parameter If i' the ' popuTation probability that stimulus j w~ll be chosen over stimulus i. For the choice models we wish to consider, - (1) ""ij = f[xj - xi1. where i is a monotone, nondecreasing function such that for sLimullls pair (.!,J,) and another stimulus pair (l:,l:), also, (2) (Xj - Xi) > (Xj' - Xi') + f(xj - Xi) ~ f(xj' - Xi') (3) f(0);.50. Models Fittinq These Reouirements: Thurstone's (1927) Law of Comparat ive Judqment, Casp: 5 is one example of such a model. In Thurstone's model, 1 J(X';-Xi~t2 (4) ""ij =",Sugi-82-128 Wood Davison.pdf
", , i L ~ COMPARISrn OF PROCEDURES FOR EXPLORATORY DATA ANALYSIS Randall S. Miller, Missouri Department of Social Services The purpose of thIs paper is to document the SPLOl' Procedure and compare it with the SAS UNI­ VARIATE Procedure for the purpose of exploratory data analysis. As researchers, we may feel quite over­ whelmed when we first look at a group of data. Frequently, In our need to get an understanding of the data, we start with techniques such as mean, varian-ce and standard deviation. Unfor­ tunately, though, these are sUDlIllary techniques that apply to normal distributions. The prob­ lem with starting with these techniques is t:hat: they are sensitive to outliers. (It is for this reason that we use median age instead of mean age of a group; and median income instead of mean income of a group.) Thus, it 'is best to start with order sta­ tistics, for they assume no underlying normal distribution. Median, mode, interquartile range, and percentile ranks are order statistics. They are called such because they all require the data to be ordered, or ranked. The first steps a researcher takes with the group of data at hand is to display it. Histo­ grams, graphs and bar charts are all ways of displaying data. A way with which many of us may not be familiar is the box-and-whisker plot. Background A box-and-whisker plot is a graphic means of displaying some basic descriptive measnres of a group of data. Box-and-whisker plots will dis­ play the mean, median, range, and interquartile range of a group of data. Additionally, box­ and-whisker plots will indicate outlying values. A box-and-whisker plot (or u!!.chematie plot u ! hence the term ""SPT,(J['"") is merely a vertically. oriented rectangle placed on an X-Y axis I with the vertical axis being marked off to encompass the values in the groups of data being studied. Under both the SPLOT and the UNIVARIATE proce­ dures the rectangle may have at either end a tail (or J'lolhislter"") made up of vertical dashes to denot",Sugi-82-129 Miller.pdf
"EFFICIENT STATISTICAL CONSULTING IN THE SMALL UNIVERSITY ENVIRONMENT David W. Smith, North Dakota State University 1. Introduction and Background The purpose of this paper is to share some information concerning the development and organ­ ization of statistical consulting at a medium­ sized, land-grant university where there is no Ph.D. offered in Statistics. North Dakota State University has a student population of 8,500 with about 1.000 graduate students. The state has a population of approximately 600,000. Note that this is a site-specific organization and can, in nowise, be advocated for other sites. However, some facets of this consulting organization may prove useful at other locations. The first task is to detail the statistical environment in which our program must function. As of three years ago there were no statistics programs in the state and relatively few courses. There were documented cases of state government agencies unable to attract even one applicant for a statistics position. The 1978 Directory of Statisticians lists 12 members of statistical societies in the entire.state of North Dakota. From a statistics viewpoint~ the situation was primitive. In the past two years, several positive changes in the situation have occurred. First, a Master of Science in Applied Statistics was approved for the Department of Mathematical Sciences at NDSU in the spring of 1981. Second, our consulting center in the Department of Mathe-· matical Sciences has grown to a fair size and shows every sign of a continued and sustained growth. Thus, we are now in a position to begin producing master's level statistics students with a heavy emphasis on Applied Statistics. Often a successful new enterprise is the re­ sult of an almost random juxtaposition of cir­ cumstance, personnel, and technology. It seems appropriate to point out that one of the most helpful bits of lecluwlogy 1s SAS. The single characteristic which makes SAS so useful to us is the wonderful property of al",Sugi-82-13 Smith.pdf
"PRac PARCAT is a SAS procedure which provides tests of average partial association in three­ way cont.ingency tables within the framework of the multiple hyper geometric probability model. Primary attention is directed at the relation­ ship between two of the variables, controlling for the effects of a covariable. This approach is essentially a multivariate extension of the Cochran-Mantel-Haenszel test to sets of (8 X r) tables. Scores can be assigned to categories which are ordinally scaled. In particular, if ridit scores with midranks assigned for ties are utilized, this procedure is equivalent to a partial Kruskal­ Wallis test when one variable is ordinally scaled, and is equivalent to a partial Spearman rank correlation test when both variables are ordinally scaled.",Sugi-82-130 Fleming Landis Schnautz.pdf
"The Mantel-Haenszel method is frequently used to obtain a SUll1l1ary odds ratio as an esti­ mate of relative risk for matched case-control studies. An interactive Fortran program calcu­ lates a Mantel-Haenszel summary odds ratio and chi-square statistics for any number of 2x2 tables, or subgroups. The information for each subgroup is entered by hand at the keyboard. When the number of subgroups is larger than ten, entry by hand becomes tedious. A SAS program was designed which passes crosstabulated infor­ mation produced by PROC FREQ to the Fortran program. The SAS program is generalized to allow easy manipulation of the variables of interest and handles missing data in such a way that the maximum amount of information is util ized. This paper describes the methodology used to create and pass i nformat ion from a SAS procedure to the Fortran program, as well as the prob 1 ems encountered indo I ng so.",Sugi-82-131 Truesdale Macera.pdf
"VARIABLE SELECTION FOR CATEGORICAL DATA USING SAS Susan HcGorray and Erik Bergstralh Mayu Clinic I. Introduction In a medical or epidemiological setting, frequently information is collected for a large number of categorical variables. The relationship between these variables and one response (or dependent) variable is often of primary interest. When the number of independent variables is large. it becomes necessary to select a subset of ""manageable"" size for further analysis. This paper briefly reviews criteria for measuring association across two-way tabl~R, and procedures based on these criteria for selecting an important subset of independent variables. SAS macros have been developed for implementing a categorical selection procedure for the situation where all variables are dichotomous; thus the following discussion is presented with the dichotomous case in mind. The use of the macros is discussed and an example based on the selection procedure proposed by Higgins and Koch (1977) is reviewed. II. Measuring association ace ross two-way tables Initially~ when considering the association between the dependent variable and each independent variable, a chi-square test of independence is often used. If we have observed frequencies Xj and expected frequencies mj' then <x.-,n·)2 test statistic X2 =- 1: ] 1 is j mj asymptotically distributed as X2 with (in the 2x2 case) one degree of freedom under the independence hypothesis. Another measure asymptotically distributed as X2 under the hypothesis of independence is the likelihood ratio statistic: G2 ::: 2 ~ x j log J One desirable property of this statistic, which the chi-square statistic does not possess is that it is minimized by maximum likelihood estimates. However, when both X2 and G2 are c~lculated, results rarely vary (Bishop, F1enberg, Holland (1975)). Since it is usually not practical to consider all possible combinations of variables, ~enerally ~ forward stepwise selection approach 1S us~d, W1th selection of the",Sugi-82-132 McGorray Bergstralh.pdf
"K) approach to the analysis of data from complex contingency tables Is readily accessible through the FUNCAT procedure. One of the examples of the use of this procedure provided In the SAS User's GuIde, 1979 Edition Involves the Ries-Smlth detergent preference data. This wei I-known data set was also analyzed using the GSK methodology by Johnson and Koch (1971). The relatively compl 1eated analyses presented by these authors Incor­ porated design matrices and response functions which, In some cases, are not directly ava! lable In FUNCAT. The purpose of this tutorial 15 to demonstrate how the .Johnson-Koch analyses can be performed using SASe The practical detailS of this example I I lustrate both standard and non­ standard appl (cations of the FUNCAT procedure. I. I NTRODUCT ION Studies In various fields (public health, SOCial SCience, market research) typically yield data on several qual Itative vari~bles. Until relatively recent times, the methods of analysis for such multivariate categorical data were lIm1ted to those assocIated with two-way contingen­ cy tables. Although these methods could be quite elaborate both with respect to the choice of measure of aSSOCiation and also with the use of stratification in order to adjust for covari­ ate effects. they did not do full justice to the multivariate nature of the data. Statistical research within the last twenty years h~s led to the development of methods for the analysiS of multidimensional contingency tables. methods that",Sugi-82-133 Davis.pdf
"ON It is often the case that graduate and undergraduate students emerge from their first stlltistjcs course convinced that the topic is boring and difficult. Many otherwise bright students seem to bog dov.:n in statistics courses. One reason for this phenomenon might be the way statistics courses are taught. Regardless of whether a practical. cookbook approach is used. or a more theoretical approach, the task of the student is to memorize or otherwise learn long strings of numerical text. There is a fair amount of literature in the field of cognitive psychology that would indicate many people learn and memorize better when the material to be learned can be visualized, or imaged, in the mind (see Paivio, 1971 for a review). Statistical distributions can be looked at as either abstract algebraic entities, or as geometric objects. With that in mind, we have taken the equations for a number of common and not so common distributions. and attempted to create pictorial representations for these distributions. These will enable us to observe some of the features of the distributions. We will also be able to examine the relationships between some of these distributions. While many statistical texts contain two dimensional pictures of distributions, we have used SAS/GRAPH to create a number of three dimensional pictures. Three dimensional pictures are especially useful for representing bivariate relationships, and how the parameters of a distribution change its shape. Distributions can",Sugi-82-134 Hofacker Hoffman.pdf
". Farrell Rodn~y H. Strand Environmental Sciences Oivision Lak Ridge National laboratory Oak Ridge, Tn. 3783[ ABSTRACT Acute to~icity tests (bioassays) estimate the concentration of a chemical required to produce a response (usually death) in fifty percent of a population <the lCSO). Simple conparisons of lC50 vaLues among several species are often inadequate because species can have identical LCSJ values while their overall response to a chemical may differ in either the threshoLd concentration (interce~t) or the rate of response (slope). A sequentiaL approach using a generaL linear model is presented for testing oifferences among species in their overall response to a chemical. This method tests for equality of slopes followed by a test for equality of regression lines. This procedure ~mploys the Statistical Analysis System's General Linear Models procedUre for conductirg a weighted least squares anal)sis ~ith a covariable. *Research sponsored by the Office of rlealth and EnvironmentaL Research, U.S. Department of Energy, under contract ~-74r5-eng-26 with tJnion Carbide Corporation. Publication No. 1888, Environmental Sci~nces Division, ORNL. Acute widely effect 1NTROOUCT10N toxicity tests or bioassays are used to asspss the potential of to~ic substances released into aquatic environments. Test species may b~ selected for their sensitivity to the substance, for their importance to the ecosystem or to the lccal community, or for their success and widespr~~d use as a Laborato",Sugi-82-135 Daniels Goyert Farrell Strand.pdf
"The statistical literature of recent years has included numerous advances which touch directly upon the analysis of epidemiological. e.g., case-control or follow-up, data. Many of the procedures are pertinent to categorical data involving linear, log-linear or more complicated functions of the various response categories. In this paper we describe the applicability of FUNCAT to a number of these problems. The paper is developed through three examples of case­ control data and one example of a follow-up study. The utility of FUNCAT is evident in each of these problems, and by logical exLension Lo a variety of others. Previously published data are utilized as illustrations.",Sugi-82-136 Woolson Clarke Amini.pdf
"What is Cognitive Complexity? Alternative Scoring Procedures for the ~lodified Rep Test Tom Trabi n, Abbott Northwestern Hospitals Phil1 ip Wood, Search Institute The way people think about and thereby act upon their environment is partly dependent upon how they differentiate between the various aspects of that environment. Individual differ­ ences along these lines help to explain how some people may overlook critical elements in dealing with a given situation. For example, a super­ visor must be able to distinguish between the several relative strengths and weaknesses of a job candidate in coming to a decision about employment. While a candidate's personal habits and likeableness may be kept in mind in making a decision to hire, these aspects should be kept distinct from other strenoths and weaknesses in order to come to a well-reasoned decision. Other ready examples come from education. In student evaluation of instructors. it is vital to under­ stand the degree to which student perceptions of some instructor traits, such as amiability, influence other ratings of the course, such as the fairness of grading and adequacy of course material. Clearly. assessment of an individual's construing of the environment is important for understandinq the actions of that individual in a given setting. In this paper we shall discuss various approaches to scoring an instrument which pur­ ports to measure the degree to which an indivi­ dual is able to perceive a given environment complexly. Two new approaches to scoring the instrument will be contrasted with the current scoring method. Individuals' scores under each of the three methods will then be correlated with scores from three other measures of comp 1 ex ity. Background The degree to which people differentiate between various aspects of their environment has been studied with respect to such diverse stimuli as paintings, types of bread, and various inanimate objects (Bannister & Mair, 1968) as well as cigarettes (Brotzge & C",Sugi-82-137 Trabin Wood.pdf
"SAS PROGRAMS FOR RATIO ESTIMATES AND THEIR VARIANCES FROM STRATIFIED RANDOM SAMPLING Wayne L. Cornelius, North Carolina State University INTRODUCTION A recreation use survey contiucted by the Georgia Game and Fish Division in 1977-78 (Padgett, unpublished manuscript) motivated the production of two versions of a SAS program for calculating a ratio estimate of a population to­ tal, and its variance. Itt randomly chosen work periods, an interviewer stopped vehicles enter­ ing one of two ~'ildlife Management Areas in northeastern Georgia and obtained data on which of several recreational activities the passen­ gers intended to perform, characteristics of the management area giving the most and least favorable impressions, and some personal charac­ teristics not of interest here. The interviewer recorded the number of vehicle axles and mechan­ ical traffic counters recorded all vehicles entering both areas during the study period. Total axle counts were determined for each area, each of 4 seasons of the year, and separately for weekdays and weekend days, making a total of 16 strata. The purpose of the study was to estimate the total number of visitors and the total number of visitors pursuing each of 7 activities. Also within each activity, the to­ tal number of visitors expressing each of sev­ eral motives for visiting and of several prob­ lems involved with visiting were estimated. ESTIMATORS Let the strata be numbered h = (hI' h2' h 3 ), where hI = Area 1, Area 2, h2 = Fall, Winter, Spring, Summer, h3 = Weekday, Weekend; let activities be numbered j = I, 2, .•. , 7; motives be numbered k= 0, 1, .•• , 7; and problems be numbered t = 0, 1, ..• , 7. Let the (known) total axle counts be ~ and the (unknown) total numbers of vehicles be N h , and the stratum user totals to be estimated be Yh , Y hj , Y hk : j ~nd Y ht : j (i)' i = 1, 2, •• ""~ and estimate as follows (ignoring the finite population correction for the variances): (1) Y hj l), l),j E ' 2 (2) (Y hj ) n h l),2",Sugi-82-138 Cornelius.pdf
"WEIGHTED SEQUENTIAL HOT DECK IMPUTATION MACROS Vincent G. Iannacchione, Research Triangle Institute 1. Introduction Item nonresponse occurs when questions from an otherwise completed survey questionnaire are not answered. Since the population estimates formed by ignoring missing data are often biased, nonresponse adjustment procedures to reduce this bias shoUld be considered. Hot deck imputation is a commonly llsed nonresponse adjustment procedure that replaces missing data with available survey data. Con­ ventional hot deck meLhods do not, however, con­ sider the weighted di stribution of the data in the imputation process. Weighted sequential hot deck imputation (Cox, 1980) replicates the weighted distribution of the available data in the imputed data by using the sample weights, or inverse selection probabilities, of item respon­ dents and nonrespondents. 2. Description of the Procedure The procedure takes account of the unequal probabilities of selection in the orig-inal sample by using the sample weights to specify the expected number of times that a particular respondent's answer will be used to replace a missing item. These expected selection fre­ quencies are specified so that, over repeated applications of the algorithm, the expected value of the weighted distribution of sub­ stitute, or imputed, values will equal the weighted distribution of respondent answers. This imputation strategy is based on the presumption that, over repeated initial samples, the weighted answer distributions for respon­ dents and nonrespondents have the same expec~ tation. This assumption is more plausible when the respondents and nonrespondents with simi liar known characteristics are partitioned into subclasses refered to as imputation poststrata. The algorithm is then applied separately within each poststratum. The sample of respondent answers are sequen­ tially drawn and matched to nonrespondents within a poststratum. Therefore, additional control may be gained by purposively s",Sugi-82-139 Iannacchione.pdf
"TRAINING STATISTICAL CONSULTiL~TS IN A UNIVERSITY BIOSTATISTICS CONSULTING CENTER Ronald G. Marks 7 University of Florida Introduction r,s-ta:ti.J.,.ti..c..i.a.n6 Jte.ce.ive li.ttle Oil no plle.paJla­ :tum 6oJz. COn6uU:a.ncy woltk, e..i..thVl. wiXJt lle6Pe.c.:t .to cthe MJU: 06 p!W.c-tietti M;du,Uetti pM blemh cthd aM.6 e, M . .the Mie 06 eo"","",U;an.t. Th.iA .u.. a de6-inUe &IwJLtcom-i.ng -i.n .the edu.<."",tum on &.wu.UcUw"" upeci.aay -i.mpo,'vtant be­ ca.""""e On .theUt -i.n6iuence on cthe comma on mecUc.al. fLe6 eaJtc.h. II Vo""slil& G. Ae.tman [1980) The purpose of statistics and bio~t~ti~tics programs is to provide students with a comprehen­ sive overview of theoretical and applied statis­ tical methods. The emphasis of each program is quite varied, ranging from very applied with lit­ tle theory to very theoretical with little dis­ cussion on how these theories can be used to solve real world problems. However, graduates of statistics and biosta­ tistics programs who became consultants either in academic institutions or industry quickly learn that their coursework did not adequately prepare them for what they faced in their new careers. Only a handful of programs offered some type of instruction on consulting, either formally or in­ formally, a few years ago. Today, more programs are adding instruction in the area of training consultants. Teaching Versus Apprenticeship Programs I'Comu£t.i.ng fA a ctut6.t, an aJU, .6C1VLCe.C.y a &c-i.ence, wlUc.h Cilnnoct be mugU b<tct m""""t be teaJU1ed, aequ.iJled, by a plWee&& alUn .to cthd 06 ,f.ea;m(.ng ;to .6w.Urr, U¥la.64-iA-ted and -i.n de..e..p wa.teJt oJr., 6oJ<. cthe molLe 6M:tunde, a p!UJeu& o.IUn .to p!UJgMM.i.ve appJLen.t-i.euh-i.p MdeJt .the glLi.d<t,"",-e 06 a mo.HeJt."" C. Ph-i.Up Cox (1968) There are two basic approaches to the training of statistical consultants, (1) classroom educa­ tion and (2) an apprenticeship program. Of course, a combination of the two is a possibil­ ity. Certain information that a consultant nee",Sugi-82-14 Marks.pdf
"i MACROS FOR SYSTEMATIC SAMPLE SELECTION AND VARIANCE ESTIMATION FROM ORDERED FRAMES Josefina Lago, Westat, Inc. 1. Introduction Systematic sampling is one of the most commonly used methods of sample selection, particularly at the second and latter stages of selection of a multi-stage de­ sign. Systematic sampling's greatest advantage is its sim­ plicity. Another advantage is that, under certain conditions, systematic sampling variances are often smaller than those from alternative designs. (As survey practitioners well know, it is safe to use systematic sampling only when one is sufficiently acquainted with the data to deter­ mine when systematic selection is not appropriate, as for example, with data that are periodic in relation to the order of the listing and the selection interval is equal to or a multiple of the period.) The major shortcoming of systematic sampling--with a sin­ gle random start--is that it does not yield an unbiased estimator of variance. A systematic sample may be viewed as a sample of one cluster, where a sample of size two or more is generally needed to construct an unbiased estimator of variance. However, several biased estimators are available that provide satisfactory vari­ ance estimates for many situa­ tions where systematic sampling is used in practice. This paper focuses on systematic sample selection and variance estimation when a frame has been ordered on the basis of an auxiliary variable presumed related to the population charac­ teristics of interest. A systema­ tic sample selected from such ordered list provides a kind of implicit stratification with equal or unequal sampling frac­ tions, depending on whether equal probability or probability pro­ portional to size (PPS) systema­ tic selection is used. In this situation, a variance estimator commonly referred to as the ""successive differences"" estima­ tor may be constructed by regard­ ing each sample unit as selected at random from a stratum. 764 This paper discusses both equal",Sugi-82-140 Lago.pdf
"I I STATISTICAL REVIEW OF INPATIENT SERVICES: A SYSTEMATIC APPROACH Jennifer Anderson, Gregory Lenhart and Janice Weener, Boston University. Int.roduction Data bases made up of hospital inpatient claims may be used to compare hospitals' use of resources for specific types of inpatients. The aim is to reliably screen for fairly aberrant situations such as the presence of hospitals where use of particular ancillary services is only half as great or more than twice as large as that of most hospitals, or of hospitals whose length of stay for similar patients is of the order of 2 or 3 days different from standard practice in an area. A reasonable approach is to use analysis of variance incorporating covariance adjustments for demographic and illness severity factors that can be derived from information on the med­ ical claim. Some exploratory data analysis is necessary, however, because of the existence of errors, outliers and mixtures of populations as well as Skewness and heteroscedacticity. The methods we' have adopted take advantage of accu­ mulated knowledge of the general properties of medical claims data, including problems with data quality. Thus we avoid the extra walk in­ volved in using the more generally applicable techniques of robust regression (1) and regres­ sion diagnostics (2). OUr analysis makes use of available SAS software. The scheme described here is for an analy­ sis of covariance in the presence of possibly many deviations from standard conditions. We have incorporated data checking and modification steps into a sequence of SAS procedures in order to routinize the process, while also providing reports on the overall properties of the data set results under consideration so that the model may be properly interpreted. The SAS Routine The routine has four main steps: set-up, outlier removal, data display and mOdellingl conclusions. a) Set-up: This includes the listing (via macros) of variables to he included in the anal­ ysis, the dependent variable",Sugi-82-141 Anderson Lenhart Weener.pdf
"lIACJlOS FOR MATCHING AllALYSIS William taylor, Biometric Research Institute, Inc. Introduction: In some investigations it is necessary to restrict a sample by matching subjec.ts. Experimental and control groups are often equated in some respects while seuding the effect of some varying condition upon a measured outcome. Some frequently used matching variables include chronological age, mental age, IQ, and socioeconomic level. It is worthwhile to match sampleR only on variables that correlate with the measured variable (the variable we note the experimental outcome). Matching may be by pairs of individuals or by groups. 1 'l1te Prable.: In an analysis of the safety and efficacy of a medical device in this case an intraocular lens used to replace a cataractal lens it is necessary to match subjects who have had an implanted lens wi th subjects from a control group. The matched pairs can then be examined for differences in complication rates and final visual acuity. Matching needs to be perfonned wi th binary or categorical variables by selecting all subjects in the control and experimental groups with respect to these categories. Once subjects in the experimental and control groups are selected it is necessary to match them wi th respect to age. If no exact age match can be found then the next closest age may be used wi th an age difference limit of ±5 years. Af ter the ma tched a data set 1s needed pertinent variables. matched also need assessment of the matching. A Solution: subjects are identified, for the analysis of all Subjects that are not to be examined for an effectiveness of the Subjects in the experimental and control data sets can be easily selected on binary variables using a subsetting ""IF"" statanent. A SAS program using nested macros is then used to similarly match subjects wi th respect to age. Three macros (see Figure 1) perform the major work in the matching. One macro (-USN) creates the primary matching data set that the other macros will use. The s",Sugi-82-142 Taylor.pdf
"IOWA SURVEY OF DENTAL HEALTH: STEPWISE REGRESSION RESULTS J. Jakobsen*. J.D. Beck, B. Introduction Over the years states have suffered from a lack of information about oral health conditions and utilization of dental care suitable for statewide planning. In 1980 the Department of Preventive and Community Dentistry, the College of Dentistry, the University of Iowa developed a survey instrument to help provide this infor­ mation. The survey was in two parts: (1) A telephone interview that asked questions about util ization of dental care, attitudes toward dental care, reasons for going or not going to the dentist and sociodemographic data; and (2) an oral examination done in the home by a local dentist who was trained and cal ibrated In survey exam rnation techniques. The purpose of the Iowa Surve.y of Dental Health were: 1. To assess the prevalence of dental caries, perIodontal disease, oral hygiene and oral lesions in the state; 2. To assess and estimate dental treat­ ment needs in the state; 3. To estimate the util ization of presently available dental services; and 4. To assess the social, economic and behavioral characteristics of the population regarding utilization of dental services. North Carolina was the only other state that had attempted a similar survey. A state­ wide survey had been conducted in 1960-63 and repeated in 1976. One of the major differences between the North Carolina survey1 and the Iowa survey was the source of funding and personnel. North Carolina had state funding, Kellogg Foundation support and the use of state employ­ ees while Iowa used small grants from several sources and volunteer help. The sources of funding and participation in Iowa \.-/ere: 1. The Iowa Dental Association for funding 2. 3. 4. 5. Methods and volunteer help; College ef Dentistry faculty for volunteer help; State Department of Health for planning; Department of Biostatistics, College of Medicine for sample selection; and Dews Institute for Dental Research for funding",Sugi-82-143 Jakobsen Beck Townsend.pdf
"SAS TUTORIAL: TRANSPOSING DATA Don Henderson, ORI, Inc. 1. Problem Statement This tutorial topic illu~trate<; pror.edurEl<:; for transposing data, i.e., converting observa­ tions into variables Dr variables into observa­ tions. This concept is illustrated in figure 1. The observation to variable transposition is rep­ resented by the transition from la to lb. Varia­ bles to observations is represented by 1b to 1a. The transition from 1a to Ie and vice-versa re­ quires transposing subsets of the data separate­ ly. The data structures illustrated by la and Ie will be referred to here as linear data sets and rectangular data sets 9 respectively. a. 1 2 b.1112h141 3 4 c.lli] C3:EJ FIGURE. 1 The ability to transpose data is important in that it provides a measure of independence between data set structure and the structure re­ quired by applications programs. For example, if data is needed in a rectangular format for analysis, but the data is sparse, the data may be stored in the transposed linear format to save space. The applicability of transposing data is illustrated for two examples. Each example is accomplished using PROC TRANSPOSE and then ARRAYS (in a data step). 2. Row by Column Reports For this example, the data is linear and a raw by column report in which one variable deter­ mines the rows and another the columns must be produced. Specifically, there is an INCOME value for each EMPLOYEE in each YEAR. A report in which EMPLOYEEs are the rows and YEARs are the columns is required. This is accomplished by transposing the data from its linear form to a rectangular form (with each YEAR value becoming a separate variable). The use of PROC TRANSPOSE is illustrated first (figures 2 and 3). The data is read in (lines 4-6, figure 2) and the EMPLOYEE (row) sums 7BO are computed (lines 16-20, figure 2). These two data sets are then interleaved (lines 22-26, fig­ ure 2) with the resulting data set transposed to the required rectangular form (lines 33-36, fig­ ure 2). PROC",Sugi-82-144 Henderson.pdf
", , , 5A5 TUTORIAL: CONDITIONAL EXECUTION OF DATA AND PROC STEPS Don Henderson, ORI, Inc. 1. Problem Statement This tutorial topic illustrates procedures for conditionally executing DATA and/or PROC steps in the same job stream. Conditional exe­ cution is defined to mean that the DATA and/or PROC steps are only executed if specific condi­ tions are met. For example, a master file is updated only if the input data passes all edits; otherwise, the input file is printed. The three methods of conditionally executing DATA and/or PROC steps are: 1. Structuring the program so that the subject DATA/PROC steps execute on empty (085=0) data sets if the condi­ tions are {are not} met. 2. Preceding the ""conditional"" DATAIPROC steps by a data step which checks the conditions and executes an ABORT (caus­ ing OPTIONS OB5=0), if appropriate. An ""OPTIONS OBS=MAX;"" statement can be used after the ""conditional"" DATA/PROC steps to resume normal execution. 3. Using %INCLUDE. In certain cases, approach 1 may not be possible or may be inefficient. Approach 2 also may not be possible for a given situation. In addition, the use of ""OPTIONS OBS=MAX;"" may have undesirable side effects. For these reasons, the following examples use %INCLUDE for conditional execution. 2. Generating SAS Code In the first example (figures 1-3), the 5AS program generates and writes SAS code to an ex­ ternal file. The statements in this external file are then executed using %INCLUDE. The objective is to compute a measure of central tendancy for each GROUP. If the data is symmetric, the mean is adequate. For groups that are asymmetric (as measured by skewness), the median is desired. The mean and skewness are computed for each group (lines 25-30, figure 1). In the next data step (lines 33-48, figure 1), groups with too large a value for skewness are selected for further analysis. If at least one group is selected, the statements to compute the medians are written to ddname PROG (lines 40-48, figure 1). A %INCLUDE is",Sugi-82-145 Henderson.pdf
"f f r t i- t SAS TUTORIAL: TABLE LOOKUP TECHNIQUES Don Henderson, ORI, Inc. 1. Problem Statement This tutorial topic illustrates procedures for table lookup. Two major applications for table lookup are: 1) replacing a coded value with another value such as an alpha label; and 2) recoding, e.g., replacing some value or a range of values by a code, for example coding age in years into age groups (0-9, 10-19, etc.). Various methods of performing table lookup in SAS are illustrated in the following sections. The first five examples operate on the data set used for the multiple output frequencies examples in the Transposing Data tutorial; for this topic, the variable REGION has been added to the data set. Methods for replacing REGION codes with names are presented. In the last section, sev­ eral of the table lookup methods are combined to perform complex recoding. 2. Output Formats In this example, the REGION code only needs to be replaced by its name on output (print). Therefore, it is not necessary to add a new variable to the data set. All that is required is the creation of a format library (lines 5-13, figure 1). A FORMAT statement (line 21, figure 1) is used to cause the REGION name to be printed instead of the REGION code itself. 3. IF Statements IF statements can be used to add a new vari­ able to the data set whose value is the REGION name. The IF statements used to create the vari­ able REG NAME (lines 4-13, figure 2) illustrate this technique. There are two drawbacks associated with the use of IF statements for table lookup, especially for data sets with many distinct codes. First. the IF statements are tedious to code and tend to ""clutter upl1 the program. Second. their use can be inefficient. 4. Merging Data with a Translation Table The MERGE capability is frequently used for table lookup. It requires less coding than IF statements; however, it is also less efficient (in terms of machine time) and less flexible than most of the other methods presented here.",Sugi-82-146 Henderson.pdf
"SAS TUTORIAL: SELECTING SUBSETS OF DATA Don Henderson. ORI. Inc. 1. Problem Statement This tutorial topic illustrates procedures for selecting subsets of data. A data file exists. either as a SAS data set or an OS file, from which only some of the observations and/or variables are needed. For any given observation, a decision to keep the observation is implemented using one of the following: the 5ubsetting IF (IF condition;), the OUTPUT statement or the DE­ LETE statement. This tutorial addresses methods of minimizing the amount of work that must be done (either by the programmer or the computer) in selecting these subsets. Many of the techni­ ques discussed in the table lookup tutorial are applicable here, and with minor alterations. some are reconsidered here. Several techniques specific to selecting subsets are also illustra­ ted. The data used in these examples consists of counts, represented as variables CNT1 - CNT17 for each SEX, RACE and state economic area (SEA). Subset selection methods, based on SEX and RACE Dr SEA, from both OS files and SAS data sets are illustrated in the following sections. 2. The Trailing @ The tra i 1 i ng @ can be used to ""prevent"" reading excess variables on observations that will not be kept when selecting data from OS files s as illustrated in this example (figures 1 and 2). In the first DATA step (lines 5-9, fig­ ure 1) all the variables are read on every obser­ vation with only the data for black males (RACE = 2 and SEX = 1) written to the SAS data set. By contrast, in the second DATA step (lines 13-18, figure 1), SEX and RACE are read with the input record held by the trailing @. The remaining variables, SEA and CNT1-CNT17, are only read on the observations that meet the selection criter­ ia. Note that the first DATA step took .89 sec­ onds, while the DATA step using the trailing @ only took .33 seconds. This reduction, attribut­ able to the use of the trailing @, is the result of reading all the variables on fewer observa­ ti",Sugi-82-147 Henderson.pdf
"SAS TUTORIAL: SIMPLE GRAPHICS Cynthia Deitz, Texas Instruments PROBLEM STATEMENT For the inexperienced or infrequent SAS user, there are graphics techniques that often are not discovered. The following are examples of such techniques. EXAMPLE 1 Often it is desired to capture as much on one graph or chart as possible without confusing the displayed information. One technique ;s to use the SUBGROUP option as illustrated in the SASGRAPH Userls Guide. Another way is to use the GROUP op­ tion instead. The same result ;s is achieved but in a clearer format. See Figure 1 for the SAS code and figures 2 and 3 for the output. In addition, using both GROUP and SUBGROUP options will allow for a different pattern for each group. Figure 4 gives the SAS code and Figures 5 and 6 the output. EXAMPLE 2 Another example of capturing as much data as possible or one plot is to overlay several plots on the same axis. This can be done with the OVERLAY option on the PLOT statement. If this method is used, the plots are not labeled so that it is hard to distinguish one from the other. In order to get SASGRAPH to produce a le­ gend, you must plot using a third variable. This may require reorganization of the data set. Figure 7 illustrates the SAS statements to do the data reorganiza­ tion and Figure 8 is the output generated. EXAMPLE 3 If several graphs or charts are to be contained in a report, one way to conserve space is to place more than one graph or chart on a page. The way to do this ;s to use the HSIZE and VSIZE options in the GOPTIONS statement. For example, to place 2 graphs per page of 8112 by 11 paper, specify HSIZE=5 and VS1ZE=7. EXAMPLE 4 You may want to superimpose a plot over a previously created plot. The only way that this can be done with SASGRAPH is to specify the VAXIS and the HAXIS param­ eters of PROC GPLOT as nearly as possible as those you are trying to replicate. Then specify the option NOAXES. Al' that wi 11 be drawn is the curve. The deter­ mination of where to pla",Sugi-82-148 Deitz.pdf
"I !-: SAS TUTORIAL: USE OF EXECS IN FILE MANAGEMENT ANO REPORT GENERATION Cynthia Deitz, Texas Instruments Problem Statement Dataset management in a eMS environment can be a very time-consuming effort. One way to help in the organization of data sets and report generation ;s to use EXECs. EXAMPLE 1 The following example (Figure 1) ;s an EXEC which contains all data sets that pertain to software personnel. The EXEC controls which data set gets created. In this way it is not necessary to store separate SAS files for each of the data sets to be created. Lines 2-3 will enable the help information if the EXEC is incorrectly executed. If the command: DATALOAO SKILL ABC were entered, lines 28-37 of the EXEC would be executed which would cause those lines to be placed onto the eMS console stack. Then the SAS command would be executed which would cause the SAS commands to be read from the console stack. The SAS dataset SPIDER. SKILLS would then be created. EXAMPLE 2 Figure 2 is an example of using an EXEC to generate reports. Lines 40-58 give the syntax for generating the necessary report. The EXEC is self-documented. Notice lines 1-11 as an example of editing a file to reflect the appropriate terminal number. This illustrates how batch reports can be generated by building the appropriate file to pa~s to SAS from the EXEC. The appropriate FILEDEF's are defined in lines 20-26. The macros are stacked in lines 30-32. Once again, these macros are defined from the input parameters. The SAS command is then executed, the SAS commands are read from the console stack. report is generated. This single EXEC is capable of generating any report from the set of all Performance Analysis reports. This saves a tremendous amount of ""housekeeping"" tirr,e. Figure 3 ;s the list of SAS statements that comprise one of the possible reports. EXAMPLE 3 Another method of report organization is to use the SYSPARM option to indicate some feature to be passed to a SAS program. Figure 4 ;s a listing of an",Sugi-82-149 Deitz.pdf
"some generalized computing consulting services that are avai lable to al I users. When a depart­ ment finds that it needs more consulting support than the computer center can reasonably provide, the department may decide to hire its own com­ puter consultant just as it would hire a pro­ grammer. The departmental computer consultant can be available at al I hours, can specialize in the computer knowledge most useful to the department and can provide continuity and guid­ ance for a computer project. When a department hires a computer consul­ tant. the computer center also benefits. The departmental consultant relieves the consulting service of a substantial consulting load, adds expertise and energy to the consulting pool, helps the computer center to understand the needs of a large group of users and encDurages greater computer use. If the departmental consultant has a formal link such as a shared appointment ... lith the com­ puter center, the department can benefit from the knowledge and experience the departmental consultant gains by working for the computer center, and the computer center can share in the specialized knowledge and expertise the depart­ mental consultant gains by working for the depa rtmen t . Introduction The User Service group of most university computer centers provides some general consult­ ing services to al I users. As the use of com­ puters increases on campus, consulting must expand to cover new packages, operating systems, new computers and to hand",Sugi-82-15 Driscoll.pdf
"SAS TUTORIAL (FOUR TOPICS IN STATISTICS) Ruuolf J. Freund~ Texas A&M University tion: There are four tutorials in this presenta1. Detecting Outliers in Regression (Influence Statistics) 2. Heterogeneity of Slopes 3. Contrasts 4. Proper Error Terms for Split Plots. Except for a brief introduction, this presentation consists of transparencies used in the tutorial. Full size copies suitable for making transparencies are available from the au­ thor. DETECTING OUTLIERS IN REGRESSION Outliers or unusual observations can bias estimates and invalidate statistical tests. Therefore we must try to detect outliers. (What to do with suspected outliers is another ques­ tion). A number of statistics which may be use­ ful in detecting outliers are discussed in Belse~ Kuh and Welsch,Regression Diagnostics (Wiley 1980). Many of these are available in PROC REG. The ""Classical"" Method for outlier detec­ tion is to compute residuals: (y-y) and plot against y (or the independent variables): RESID = ACTUAL - PREDICTED Such plots may not be useful because (i) residuals do not all have same vari­ ances (ii) outliers tend to pull regression line towards themselves. An alternate set of statistics, the standardIzed residuals: ST RESID = RESID where s2 residual mean square (estimate of 0 2 ) hi diagonal element of X(X'X)-lX' This helps, but usually not much. An outlier may cause residual variance to be overestimated· hence the standardized outliers do not look bad. Solution: When standardizing a residual, estimate variance based on a regression estimate using all other observations. Sounds difficult. but it isn't. The variance estimate, omitting observation i, s2(i) = (n-m-2)-' (SSE-(RESID)2/1-h .) 1 This is used in place of s2 in standardizing, the resulting ""STUDENTIZED"" residual is STUD-R RESID Is2(i) (l-h.) 1 Outliers may also pull the estimated regres­ sion plane towards themselves thus their resid­ uals may not be large. Solution: re-estimate each residual using regression model estimates",Sugi-82-150 Freund.pdf
"I , I l f ! SAS Tutorial: Hierarchial Data Peter L. Rikard Introduction Hierarchy - a body of entities arranged in a gr aded ser ies. Hier archieal data appears everywhere. We are just able to ignore its problems because of relative size. A conventional hierarchical set of data is the census data. There are re­ cords at many descending levels of size of the geographical areas in the coun­ try. Each lower level belongs to a level above it. In its own, a companies week­ ly payroll records and its main master payroll dataset form a hierarchical da­ tabase. The sum of all an individuals weekly records are related to the single record for the individual in the master database. Clinical studies are often hierarchical, with individual test re­ ports, monthly observations and a master demographic dataset. A raw data file of clinic data may ap­ pear as mixed types of records; the first record (s) in a group contains the demographic information for an individu­ ala The next record(s) contains the re­ port for a monthly observation followed by record(s) containing individual tests. IJohn Doe 2288 male white 34 12/10/80 2 2288 1/3/81 112345666 3 2288 1/3/81 111 3 2288 1/4/81 231 3 2288 1/6/81 918 lJane May 2311 fern white 16 01/31/79 2 2311 2/4/79 443122226 3 2311 2/2/79 878 3 2311 2/4/79 515 Or there may be separate files for each record type. In any case, a normal first organization of the data is in different SAS datasets, one for each type of record, each sorted by the 10 and other variables that can be used to merge the datasets together. All the considerations below are concerned with the SAS datasets, not the original nrawn data files. Coping with the Problems Given either of the two collections of data above, for efficiency sake (yours and the machines), you should analyze needs BEFORE the data is stored. your (1) (2) (3) What is the most frequent analysis to be performed. What other analysis will be performed. (you will miss a bunch) will any analysis be done interacti",Sugi-82-151 Rikard.pdf
"SAS Tutorial: Set Merge and Update Peter L. Rikard Introduction This tutorial was presented as a set of examples to demonstrate the combining of data sets in SASe In the interests of trees and cost of the Proceedings, the examples are not printed here. Instead, at the end of the text is the SAS code to produce all of the examples. An exam­ ple consists of the print of each data­ set used to build the output dataset and the print of the result. Combining Oatasets A major power of SAS over distant rivals lies it its ability to manipulate data. Taking in information in many forms, in different order, and in different quan­ tity and being able to put it together in a coherent form EASILY, astounds us­ ers of that other package, not to be named here. The three tools for this process; SET,MERGE and UPDATE will only be introduced. The possible combinations of things that can be done are huge. Enough puffery. Definit.ions SAS oper ates on n rectangular data ar­ rays"". Admittedly jargon, but a very simple concept. It is a normal table of data .. NAME SEX RACE AGE 1 Peter 1 W 13 2 Frank 1 B 11 3 Jane 2 W 14 4 Susan 2 W 12 5 Trinity 3 W 12 6 Adele 2 B 10 7 Bob I W 18 The columns of the table are VARIABLES, things that can take on one or more va­ lues, as SEX could have 3 values l~male, 2=female, 3=unknowno. A row of the table is an OBSERVATION, the collection of all the values of variables pertaining to a single entity, a persons NAME, AGE, SEX, HEIGHT, WEIGHT etc. The whole table is a dataset, a rectangular data array, the collection of all the observations. 831 SAS can read in many types of data in many forms. Reading in data from non SAS datasets is done with INPUT statements and transforms the ""rawn data into a SAS dataset. Once this process has been done SAS handles all the chores of WHERE the data is and WHAT does it look like. You may now treat the SAS dataset as a reo­ tangular data array, no matter what its n raw"" form looked like, and no matter the form it was stored",Sugi-82-152 Rikard.pdf
"SAS Tutorial: Arrays Peter L. Rikard Introduction Arrays as implemented is SAS are good or bad depending on your prior programming experience. Fortunately for most SAS us­ ers(non programmers) they are good. Arrays do NOT provide subscripted varia­ bles. Rather they provide the SAS pro­ grammer a single name to reference in programming statements that imply the use of a list of variables. Note: all techniques are using SAS79.5, later versions of SAS may change the as­ sumptions and methods. The Array Statement ARRAY arrayname (index) list of variables: Where arrayname is a SAS name NOT used as a variable name, index while not re­ quired, is recommended and the list-of­ variables is any list of variables of the same type. EK: A dataset with numeric variables Xl-X20 Yl-Y20 ABC R M Q could have any or all of: Notes: ARRAY Z (J) Xl-X20; ARRAY ZZ(K) Yl-Y5; ARRAY ZZZ(L) Xl Y2 A B X3-X9 M ARRAY ABC X6-X9 Xl-X4 X15-X20; ARRAY ABCD(J) Yl-Y20 ; (1) Variables can simultaneously be used in more than one array. (Xl in Z,ZZZ, and ABC) (2) Variables can be specified in in any order in an array. (Xl-X4 following X6-X9 in ABC) (3) Arrays without an explicit index have the implied index, _1_. (array ABC) (4) More than one array may use the same index variable. (J used in Z and ABeD) (5) Arrays of different length MAY use the same index variable, however DON'T do it. Using Arrays Arrays are used as indirect reference to a variable in the list. If you wish to reference the third element of the array Z, you CANNOT say Z{3}. The index vari­ able for the array must have the value of 3 and then a reference to Z is a re­ ference to the third element of Z. 835 EX: J=3; (setting the index) IF Z=99 THEN Z=lOOO; (liZ"" references the third element, X3) Common use of arrays involve using DO and END statements. The DO/END pair of statements form a loop in the program, with statements between the two being executed one or more times. When execu­ tion of the loop stops, SAS goes to the next executab",Sugi-82-153 Rikard.pdf
"r I I 1 I SAS Tutorial: Unconventional Merges Peter L. Rikard SAS Tools This started off being a set of unusual ""merge ll applications. Then it became I'tricks"" and now it is a set of tools. (Some source code is at the end of the paper for demonstration) There is no in­ tention that these are ""THE"" ways to do things in SAS, rather methods that can be useful. All of the methods shown are using SAS79. 5, newer releases may dis­ pense with some of these tools. Merging One Observation with All If you have data that you wish to put with every observation in a dataset, us­ ing obvious methods in SAS you run into several problems. EX: PROC MEANS DATA=MAIN NOPRINT, VAR Xl-KID, OUTPUT OUT=NEW MEAN=MEANI-MEANIO, DATA TOTAL; something MAIN NEW; (so that MEANI-MEANIO are now with every observation) To MERGE, there is no matching variable in every observation. DATA TOTAL; MERGE MAIN NEW, without a BY MEANs are only on first observation. with a BY we must create a dummy CONSTANT BY variable. To SET, var iables mentioned in THE SET statement cannot be retained. DATA TOtAL; SET NEW MAIN; RETAIN MEANI-MEANID, (doesn't work) TOOL: Conditionally executed SET state­ ment. DATA TOTAL, SET MAIN, IF N =1 THEN SET NEW, Variables mentioned in SET statements are set to missing values and bring in new values when they are executed. By only executing the SET statement on the first Observation, all variables are ""retained"" until the SET statement is executed again. In this example that never Occurs and all variables from NEW will be in every observation in TOTAL; 838 Selective Merginq of a SAS Dataset. In a merge application where two data­ sets have sometimes slightly differ ing BY values a simple merge doesn""'t work. If with logical statements you can det­ ermine that you have the ""matching"" ob­ servation you can perform your own merge. EX: Dataset ONE has variables VI-V4 Dataset TWO has variables VI-V4 A normal MERGE would be BY VI V2 V3 V4; But in TWO, V4 is sometimes missing, in which case",Sugi-82-154 Rikard.pdf
"procs can be manipu-lated to meet the needs and/or desires of the user. Simple programs are presented for creating concise summaries of analyses by reducing and enhancing output. INTRODUCTION SAS contains many useful statistical procedures. One of the few drawbacks is that the output frequently is cumbersome and hard to control. Proe Printto makes it possible to read the output so it can be treated like any other SAS data set. This means that the user can control what is printed. Reducing or reorder­ ing output has received many votes on the SAS balloting, and the macros depict methods for acaieving these goals. The following examples are presented: 1 - suppressing the carriage control 2 - reordering the output 3 - enhancing the output 4 - compressing the 0utput 5 - rerouting the output. The following data set and macros are used in all examples. The macros used for reading the carriage control (INCC), reading the.output line (INL), printing the line (PUTL) and reading the by var­ iable (INBV) are listed below. The data set used in all examples has variables Y and X (dependent variable and covar­ iate). 3 treatments. 5 blocks and 3 levels of the by variable (BYVAR). DATA DATA,DO BYVAR~l TO 3,DO TRT=l TO 3, DO BLK=l TO 5, DO REP=l TO 20, X=NORMAL(O) , Y=X*S+NORMAL(O) , OUTPUT, END; END; END: END: MACRO DSNIN DATA DSN,INFILE FT20FOOl LENGTH=L, % MACRO PPT PROC PRINTTO % MACRO PPTN PPT UNIT=20 NEW % MACRO INCC INPUT @l CC $CHAR1. @ % MACRO INL L=L-l, INPUT @2 LINE $VARYING64. L",Sugi-82-155 Barry Ko.pdf
", , •• • ~' EDITING AND REFORMATTING CHARACTER DATA: TWO NEW FUNCTIONS FOR SAS Stephen M. Beatrous, Research Triangle Institute Although SAS currently has numerous built­ in functions for editing and reformatting charac­ ter data, it does, for the most part, lack functions that deal with these data as words rather than as individual characters. This paper will present two new built-in functions to meet that need. The first function removes extra blanks from a string, while enabling the user to preserve a sentence or phrase structure. This function differs from the COMPRESS functIon currently provided by SAS in that the user n~y leave behind an optional number of blanks (de­ faulting to one). The second function. allows the user to remove or replace all occurrences of a word in a character string. This paper will do the following: 1) describe how to use each function, 2) compare these functions with similar character functions already provided by SAS, 3) present a concrete example using both funct ions ~ and 4) describe the algorithms for both programs. I. Description and Use A. COMPBL COMPBL removes the unneeded blanks between words in a character string. All occur­ rences of two or more consecutive blanks are translated into a single blank. COMPBL removes blanks from a string while preserving a sentence or phrase structure. COMPBL is called as a built-in function from SAS. The call must be in the following format: DEST STRING = COMPBL(SRC_STRING); where, SRC_STRING = the source string being compressed. DEST STRING = the output buffer cuntain­ ing the compressed string. The followIng example removes extra blanks frum the variable string: STRING STRING 'HEY DIDDLE COMPBL (STRING) ; DIDDLE' ; STRING now has the value 'HEY DIDDLE DIDDLE' . It is important to note that COHPBL will not adjust the length of an output variable. If the length of the output is not explicit]y de­ clared then SAS will allocate the number of bytes in the input string to the output string. The u",Sugi-82-156 Beatrous.pdf
"t , , , PROC CRYPT: A Procedure to Encrypt and Decrypt SAS Oata Sets George Howard and James D. Hosking, University of North Carolina Introduction SAS provides relatively limited facilities for insuring thl:! ~1:!L:ul-iLy aud cuuIidentialiLy of information stored in SAS data sets (namely, read and write passwords for the entire data set), While this protection.would deter casual attempts at a-ccess, it would not withstand attacks by experienced programmers familiar with SAS and the operating system. It also does not allow different levels of security for different variables within the data set. The CRYPT procedure encrypts and decrypts SAS data sets using a software implementation of the Data Encryption Standard (DES) published by the National Bureau of Standards (U.S. Department of Commerce, 1977). The data is encrypted using a user-supplied key of ). to 8 EBCDIC characters. The algorithm provides a level of protection which is, for all practical purposes, unbreach­ able by anyone who does not have access to the key. The encrypted data set is a copy of the input data set, with the values of the specified variables encrypted, except for the addition of an overflow variable. Decryption is performed using the same procedure and key, and results in an output data set which is an exact copy of the original input data set. The procedure allows multiple subsets of variables to be encrypted with different keys, using multiple invocations of PROC CRYPT. This offers the capacity for different levels of protection in the data set by letting users have the keys for only those subsets of variables that they have a ""need to know. 11 Overview of the Algorithm The DES algorithm consistens of a complex trans­ formation of the bits of the input data and key; a detailed description of the algorithm can be found in U.S. Department of Commerce (1977) or Katzan (1977). A simplified discussion is pre~ sented in Meushaw (1979). The DES algorithm requires that the data be processed in grou",Sugi-82-157 Howard Hosking.pdf
"PROCS COMPARE AND HEADER FOR EFFICIENT DATABASE MANAGEMENT IN SAS Michael A. Province, Martha McCrate. J. Philip Miller. Division of Biostatistics. Washington University, St. Louis Missouri This paper describes two SAS procedures that have little in common other than the fact that they are both straightforward solutions to problems that often occur in database management. The first problem is that of easily documenting and indexing changes that are made in SAS databases which are constantly being updated- that is, the prOblem of providing a complete audit trail for successive generations of SAS databases. While SAS automatically stores much of this information in the HISTORY records of a dataset, those records are not complete. In particular, the changes made by PROC EDITOR are not stored there. PROC COMPARE solves this problem by producing a machine-readable (SAS dataset) version of the difference between two datasets. The second problem is that of accessing the names, labels, formats, etc. of variables in a SAS program, for easy recoding. While the RENAME, LABEL and FORMAT statements in a DATA step are easy enough to use, they are not executable statements, in the sense that they cannot be used with ARRAY statements. Thus each recode must be written out explicitly. This process can be tedius when many variables are involv~d. and can be especially annoying when the same thing is to be done to each variable, e.g. prefix an ""M"" to each variable name, or ""MEAN OF ""to each label. PROC HEADER solves this problem in two steps. First, it produces a SAS dataset version of the output from PROC CONTENTS (called a HEADER dataset), in which the variables are now OBSERVATIONS. The attributes can then be recoded in a regular DATA step, accessing each attribute as just one variable. Second, PROC HEADER uses that recoded HEADER dataset to replace the variables in the original dataset. HEADER even has options that can streamline the process to one step, in those cases where Simple",Sugi-82-158 Province McCrate Miller.pdf
"CONSTRUCTING AN INDEX FROM HARDCOPY DOCUMENTS USING SAS Bob Sturqeon, B.C. Hydro ABSIRAl:I This is ii technique for"" creatinq an index from a tvpewr1 tten preelS of off; c; a1 'Rate He ... r; nQ Aoollcatlon' documenis. The 1200 o~ae precis con51StS of pace references and descriptive para­ Ql""apns ref err; no to the mil i n hei;lr; nCi documents whi ch OJre coni.: i ned ; n :;0 volumes _ An; nde)( W<::IS reauired lor a Quick reference to previously dis­ cussed i te~!;.. A three step <::Ipproach W;;lS uoo:;ed. Inll:1allv, the precis was ooticallv scc:nned Clnd recorded ~n a word prOCeSSlnQ dis.l<ei-te. Atter mInor editlna, the data was tr<olnsmitted to <;In 16N mainfr~lr.e. 5A5 was then used to create an index trom the dataset. ltlJROO= Rate Hearinq aoplicatiqns are an onaoina fac't of life for ut11itv comp~nles. A method was reau1red to p~ovlde a QUlck index to statements or deci­ sions on an ;ssue~ made in previous hearinc:s, in order to deare~se time ~nd costs involved 11""1 manu­ allv searchina the records. Rate hearinQs can be aUlte lenathv <lnd, for current rate he<:irinQs. an upda""ted 'indp.x was reQui red dai Iv to replace the index from the previous dav's hearinas. For previously completed hear.inqs, ill tvpewri tten precIs was .. v~IIClble for optIcal sc~nnlna. For' current hear1nos~ notes were tClken d'<l:ilv, keyed Into a d~taset via a oorto::ble termInal and an updated index created tor the next dav's heClrinQs. A facility was proviced to search a file of common words that were no\ reQu'i red <ilnd to delete them trom the index. _n addition, a listina wes reouired of soecified phrases (e.a. cost of livlnql that miaht not be all on one lIne but wrap ~round the end ,nsteCld. The Statistical Analvsis System was chosen to 01""""0- VIde thiS index for severa re~sons: 1. SAS lencs d~ta and selected ince'\(. 11selt to readinQ tree form lines of the 'MERGE' feature would ~llow keV~Jords to be dropped from the 2. ISM' 5 ' STAIRS' w~s ~va ilable to us but 1 twas not a",Sugi-82-159 Sturqeon.pdf
"arge stgte-supported school located in northwestern South Carolina. Administrative personnel at Clemson are increas­ ingly in need of up-to-date information in order to manage their resources, but the administra­ tive programming group is already overbur­ dened with requests for computer-generated reports. As a result, colleges and departments must wait months or even years for the reports they need. Beginning in the spring of 1981, the Clemson University Computer Center began to offer a series of computing workshops tailored to admin­ istrators. These workshops taught general concepts of computing, the use of time-sharing terminals, and SAS. Because of these work­ shops, a number of administrative staff members became confident users of the computer, able to generate their own personalized reports using SAS. This paper will describe the problems encoun­ tered by admin istrators before the workshops became available, the methods used to organize and publicize the workshops, the outline of material covered in the workshops and how the material was pr'esented, the reasons for choos­ ing SAS as the language to be taught and the successes and failures of the workshops already completed, Background Clemson University is a large state-supported school located in northwestern South Carolina. Clemson has over 11 ,000 students, 9 academic colleges, and a graduate school, and therefore requires a large supporting base of administra­ tive personnel. Because of the recent state of the ec",Sugi-82-16 Smith.pdf
", f "" , t GBllElArIlI: C<HIBlRED LlrK1lATOU IRDIGBS V111i_ Tay1or. Bla.etrle b_reh IDatitotel' Inc. Barbara Taylor, MAlCOK Sigaa Data Coaputiug Corp_ Introduction Information is being published at a rapid and voluminous rate in todays world. As people have increasingly less time to read or even browse such material, a great emphasis has been placed on the development of indexes, especially master or composite indexes covering a specific body of knowledge. The purpose of this paper is to describe one such index developed using a SAS program to cover all major literature concerning macrobiotics, a dietary approach used to resolve health problems. Procedure Each macrobiotic book was indexed for all key concepts. A controlled list of terms was developed for this purpose. Non-valid terms were cross referenced to valid terms (e.g.oncology SEE cancer). The specific steps are outlined below: (1) The initial file was built using text editing software. Each record entry contains the index entry, and page number( 8). Any given index entry can have three segments: broad tenn, narrower term, narrowest term. For example, ""Kidney disorders - stones cause of"" would represent a typical entry. To minimize keystroking, certain shortcuts were employed. Assume that the following records must be entered: Health statistics cancer incidence 72-8 Health statistics heart disease 33 Health statistiC8 (stomach) 41-2 Uni ted States Uni ted States Japan - cancer The actual data file would contain those records entered as follows: Health statistics - United States - Cancer incidence 72-8 x x heart disease 33 x Japan cancer (stomach) 41-2 As can be seen, ""x's"" mean repeat the major term, sub-term 1 or sub-term 2 as appropriate. (2) All cross references were entered into a second file. Two types of entry were permitted: A SEE reference to direct the user from a non-valid term to a valid term in the systEm; and a SEE ALSO reference directing the user to similar terms (I.e. heart disease SEE ALSO 869",Sugi-82-160 Taylor Taylor.pdf
"I ~- G~aph;cs on the IBM 3800 and XEROX 9700 Printe~$ John Austin and Roy Hammond Systems Development Division Statistics Canada Ottawa, Dntario, K1A OT6 Introduction The primary computing resource within Statistics Canada consists of a pair of Amdahl computers running MVS with TSO and JE52. Our time-Sharing population numbers in excess of one thousand users who have access to several hundred terminals. Each of our machines supports a maximum of 70 concurrent T50 sessions, restricting the accessibility of T50 during normal working hours. Our rec~nt acquisition of SAS/GRAPH, which supports only on-l ine graphics devices. presented an additional demand for access to TSO. Our data analysts, who submit large number-crunching batch jobs which usually run overnight. had to log on to TSO during prime-time to view their graphical data. Indeed, there was a loss of productivity for those who sat watching a pen plotter creep along only to find that they had made a mistake. For these users, it was obvious that a ""draft"" plot. produced on a standard print device by the batch job would be a vast improvement. This batch facil ity would be universally accessible and would eliminate the need for new users to learn how to operate a graphiCS terminal before they could use SAS/GRAPH. Users of both computers have access to both the IBM 3800 and the Xerox 9700 laser printers through the shared spooling facilities of JES2. These printers, and a number of others on the m'arket, provide support for installation defined character sets. While neither device was designed specifically for the product10n of computer graphiCS, it was generally felt that they might be used far the type of draft work we had in mind. SAS/GRAPH Devices The SAS/GRAPH system supports a wide variety of popular graphics devices through the use of system modules known as device drivers. In order to al low field installations to support additional devices, SAS have provided their Universa1 Device Driver as a link-editable",Sugi-82-161 Austin Hammond.pdf
"The Friedman (1937) Test for a randomized complete block design has been generalized by K.M. Patel (975), along the lines of Gehan (965) and Breslow (970), for a randomized block design when observations are subject to arbitrary right censorship. The distribution of the censoring variable may vary among the blocks. Patel (1975) has shown the asymptotic null distribution of the test statistic to be chisquare. A SAS macro for this nonparametric test is presented. (Keywords: Macro, Friedman, Nonparametric, Censored)",Sugi-82-162 Hirsch.pdf
". Senate CompuLer CenLer ABSTRACT Two multivariate statistical models probit and discriminant analyses, are compared as tech­ niques for two-group classification. The stan­ dard classification technique, linear dis­ criminant analysis, assumes the complementary groups are distributed multivariate normal with equal variance-covariance matrices. However, probit analysis assumes nothing about the structures of the variance-covariance matrices ar.d requires only that a linear combination of the explanatory variables be normally distributed. Utilizing the Statistir..:al Analysis System, these two appraches are compared on the basis of their misclassifi­ cation rates utilizing various actual and simulated situations. DISCRIMINANT ANALYSIS CLASSIFICATION This statistical technique for classifying multivariate observations was introduced by R. A. Fisher in 1936 (61. In order to review the procedure, consider two groups that are normally distributed with known mean vectors ul and u2 and equal variance-covariance matrix ""f:"" A multivariate observation, x is classified as being in group one (GI) or in-group two (G2) depending on the relative values of the discriminant function (1) and the weighted cost of misclassification (2) given below. (w2) c (1/2) where (2) (wI) c (2/1) , w2 and wI are the known prior proba­ bilities and c(1/2) and c(2/1) are the costs of misclassification. Classify the observation into G1 if (11 2 1n(21 G2 if (1) <. In(2) In practical problems the parameters u~,u2",Sugi-82-163 Klemm Gust.pdf
"SAS PROCEDURES FOR ANOVA OF REPEATED MEASURES DESIGNS Carolyn J. Oakley, Richard C. McNee, and William G. Jackson, Jr. USAF Sc~ool of Aerospace Medicine, Brooks APB, Tx. Frequently in experiments subjects are di­ vided into several treatment groups and then measured repeatedly over time. For this type experiment a univariate analysis of variance of repeated measures may be appropriate. Four SAS PROCEDURES have been written to obtain univariate analyses of repeated measures designs. SAS PROCEDURE REPANOV REPIW2F REPIW3F REP2Wl GROUPING FACTORS 1 1 1 2 REPEATED MEASURES FACTORS 1 2 3 1 Even though an experimental design may specify the same number of subjects per group, this is not always th~ (.:8:::;e aftt:!r the uata has been collected. Also missing values are often present. All four procedures handle missing data. Source lines are adjusted for missing data by the covariance technique. A set of dummy covariates is autumatically generated. In performing tests for main effects and lower order interactions involving repeated measures factors we prefer adjusting for higher order interactions over buildin.g models in a hierarchical manner. To make the adjustments, it is necessary to incorporate some restrictions on the parameters of the model. All of our programs use the unweighted constraints in which the sum over all levels of a repeated measures factor of the main effects or interaction effects involving that factor is zero. Con­ straints associated with sums across levels of grouping factors are either unweighted (REP2 T rllF), weighted by the number of subj ects in the groups. (RRPUt3F), or both ways (REPANOV and REPIW2F). DESCRIPTION OF PROCEDURES REPANOV ANALYSIS OF A ONE-WAY DESIGN WITH REPEATED MEASURES AS A SINGLE FACTOR. THERE ARE FOUR SEP~~TE OPTIO~S. 1. A UNIVARIATE ANALYSIS OF REPEATED MEASURE­ }~NTS. CONTRASTS ON THE TIME AND GROUP*TIME MEANS CAN BE REQUESTED IF THERE ARE NO MISSING DATA. 2. HISSING DATA ESTIMATES ARE GENERATED BY AN ITERATIVE RECRESSION T",Sugi-82-164 Oakley McNee Jackson.pdf
"Paired comparison experiments involve treatments compared pairwise by several subjects, with a binary response. For example, subjects may be asked to taste two samples of a particular fooo product, and choose the one with the better taste. The extension to the BradleY-Terry model presented by Rao and Kupper (1967) is used in this paper. This method allows for ties, where subjects may declare that no difference between the two samples can be discerned. This paper presents a SAS macro which performs an analysis of the results from a paired comparison experiment. First of all, maximum likelihood estimates of the Bradley-Terry treatment parameters and the tie parameter are found iteratively. From these, estimates of the pairwise preference probabilities and probabilities of ties are produced for each pair of treatments. Finally, the asymptotic variance-covariance matrix is estimated, and an asymptotic chi-square test for treatment differences is conducted. 1.",Sugi-82-165 Offen Littell.pdf
"kages including SAS provide limited methods of Multiple Comparison Procedures (MCP). There is a need for some convenient way to perform a variety of MCP. Many authors including Dunnett (1980a, 1980b) described several useful parametric MCP for three cases: and (III) nij,nj, ai2j,ai Rank analysis of variance by Kruskal and Wallis (1952) with correction for ties is described. Also, MCP based on ranks proposed by Dunn (1964) is described to compare treatments with a control and all possible comparisons. The purposes of this paper are to describe how SAS may be used to perform the computations for the above parametric and nonparametric MCP including the Kruskal-Wallis test with ties corrected, to provide macros using the MATRIX procedure for performing these calculations, and to illustrate them with a numerical example. PARAMETRIC MULTIPLE COMPARISONS Consider one-way fixed effect ANOVA model: Yij=~i + e;j; i=l ••.. k. j=l •..• ni Where eij ~ NID (O,a 2) random variables and the Pi and 0 2 are unknown parameters. Let Vi be the estimate of the sample mean for the ith group and s2 be the Mean Square Error (MSE) estimate with v=n-k degrees of freedom (DF)~ where n=Eni and ni is the number of samples per group. The problem of simu1taneous estimation of the entire class of k*=k(k-l)/2 pairwise comparisons Ui-~j of the k means are divided into three caseS: and (III) nij,nj, ai 2j,aj2 For each case~ selected Multiple Comparison Procedures (MCP) are described. 893 CASE I: ni=nj, ai2 = aj",Sugi-82-166 Patel.pdf
"USING SAS IN A (NON-STATISTICS) FRES~~ MATHEMATICS COURSE Thoma~ A. Carnevale, Virginia Commonwealth University INTRODUCTION This paper describes how SAS can be used as an auxiliary aid in a fresham mathematiC8 course. In this approach, SAS is used not only to re­ lieve computational drudgery, but also to actu­ ally demonstrate mathematical concepts. The approach that is described is used in a setting in which no previous programming experience is assumed. THE COURSE BUS 111-112, Basic Mathematics and Elements of Calculus for the Behavioral, Management and Social Sciences, is a two semester sequence re­ quired of all majors in the School of Business at Virginia Commonwealth University. These two courses examine the elements of Finite Mathema­ tics and Calculus with particular emphasis on applications to economics, management and social sciences. It is accurate to describe each course as a survey course in which few, if any, topics are treated in the detail that would be present in mathematics courses for engineers or students in the physical sciences. Also. stu­ dents are expected to attain an intuitive under­ standing of concepts with rigor and theoretical formulations de-emphasized. Specifically, the major topics of each course are: I II III IV V BUS 111 Function~ and Graph~ Linear Systems Matrices Linear Programming Mathematics of Finance BUS 112 I Limits and the Derivative II Differentiation of Polynomials III The Integral IV Calculus of Logarithmic and Exponential Functions V Multivariate Differentiation USE OF THE COMPUTER An objective of the course is to solve some realistic (albeit elementary) problems. Thus the need for some sort of computational aid is apparent. Since this course does not have a programming prerequisite and sinoe the teaohin.g of computer- ppogpamming is not an objec-dve of ~he c~rseJ an easy-to-use library of ppograms ~s de3~rabZe. SAS together with a MACRO library meets this need. INTEGRATING SAS INTO THE COURSE Early in the course stude",Sugi-82-17 Carnevale.pdf
"A MACHINE-READABLE MASTER INDEX TO THE 1976-1981 SooI PROCEEDINGS A. W. Bragg, North Carolina State University A master index to the Proceedings of the First (1976) through the Sixth (1981) SUGI Conferences is being compiled and will be available from the author in both printed and machine-readable form after June 1, 1982. Each paper has been revie~ed and indexed based on descriptors selected from the title and body of the text. The printed index will be similar in scope and content to that published in the SAS User's Guide. The machine-readable index will be available on magnetic tape and will consist of two files: the first file contains fields indicating the year, paper index, descriptor or descriptor phrase~ and page number(s); the second file contains fields indica ting the year, paper index, names of the first three co-authors, and the paper title. For example, YEAR PAPER 76 11 76 11 76 12 76 17 76 19 76 28 DESCRIPTOR =::::::1======= system measurement tuning MVS empirical economic analysis PAGES 181 181 185-186 medical database manage- 264 ment PROC RARVEY evolution of statis­ tical packages 295 380-387 69 and YEAR PAPER AUTHOR TITLE =""'''''== 76 1 JHGoodnight General Linear Models Procedure 76 2 J SaIl The Design of the SAS MATRIX Proce­ dure It is hoped that the master index ~ill fill the gap in documentation of user-written macros and procedures and will offer readers a concise reference to the myriad of applications for which SAS has been used. Distribution details have not been finalized although there will probably be a charge for postage and tape duplication. Additional information may be obtained from: A. W. Bragg NC State Univ PO Box 5847 Raleigh NC 27650",Sugi-82-18 Bragg.pdf
"PANEL DISCUSSION Mason B. Nichols, SAS Institute Inc. The fo!lowing transcript of the 1982 Education and Consulting panel discussion has been edited for clarity. Jim Nelson: For the second half of the Consulting and Education Session we are holding a panel discussion in hopes of solving your problems and answering your questions on consulting and education services which the SAS staff provides you, On our panel today, we have John Boling, Director of Video Education; Mason Nichols, Manager of Consulting Services; Harriet McLaughlin, Senior Technical Consultant; and Herb Ki rk, Di rector of Education. My name is Jim Nelson, the session chairperson, and I will be the moderator. First we will turn this over to Mason Nichols for a few opening comments. Mason Nichols: Thank you, Jim. I want to take this opportunity to briefly discuss the consulting services at SAS which will hopefully open up some areas for discussion. As the number of sites and products increase, so does the number of technical tails. And, as Harriet will point out in a few minutes, the number of calls we have been receiving can be answered by simply reading the documentation. So you may ask, ""When should I call?"" You should call SAS if you need to report a bug in the system; if you need clarification of documentation; if you need to val idate a procedure's output; if you need help with new undocumented features; if you want to make a suggestion about the design of SAS; or jf you need clarification of error messages. Our technical support staff cannot provide consulting for special interest applications, nor do we have the necessary staff to provide statistical consulting. What we do recommend is that each installation provide consultation services. Then users could direct their questions to them and they, in turn, would contact us if they have a problem they could not handle. If your company provides in-house consulting, we recommend that you contact them first. They maintain a list of existing problem",Sugi-82-19 Nichols.pdf
"ere was only one produc1, it was a batch processing system, and most applications were statistical. Therefore, a single course was sufficient to train new SAS users. SAS in 1982 is no longer a statistical package with a single audience. SAS can be used in batch and interactively under different operating systems. It contains a high-level programming language with functions, data management and report writing capabilities, along with an extensive library of p1'ocedures. There is also the optional products SAS/GRAPH, SAS/ETS, SAS/FSP, and SAS/IMS. SAS today is used by individuals in almost every profession, regardless of educational background or experience: computer professionals; scientists; econometricians; managers; secretaries; accou ntants; engi neers; administrative assistants; and the list goes on and on. Training this mass of users is a real challenge, since some of them have no previous exposure to data processing, while others have ten or more years of experience. [t is necessary for the Education Division of SAS Institute to be as versatile and varied as the users themselves. For this reason, we are developing a curriculum approach to SAS training. Figure 1 outlines the ten courses which form the basis for a SAS course curriculum for 1982. SAS Course Curriculum Intro to DP Color using SAS Regression Graphics and ANOVA ... / Advanced Time Series Input/Output Basics and Forecasting • Computer K ~ Performance Exploratory Evaluation Multivariate SAS Analysis / Procedure",Sugi-82-20 Kirk.pdf
"SAS VIDEO TRAINING ..• AN EDUCATIONAL PERSPECTIVE John C. Boling, SAS Institute Inc. I ntraduction There is no question that today we are living in an age of electronic communications with television as the primary delivery system. Our population, especially those under thirty years of age, have attained adulthood immersed in a daily bath of electronic messages of all types - entertainment, information, spi ritual, patriotic and commercial. The result is a changed population. One of the leading banks in this country ,'ecently repol'ted that their new employees were not good readers. Thus, a new mode of communication was needed, something with visual impact. That something turned out to be television. It would be hard to overestimate the importance of the pervasive TV culture in which we live. Video applications in the private sector is simply mirroring the growth of television in American society at large. Consider the following facts. gathered this past decade by the research dp-partment at CBS and the Gallup Poll. • In 1970, there were approximately 95 million TV sets in the United states. That was an average of one television set for every two people. That was a higher per capita ratio that any other consumer product or household applicance -including automobiles, bathtubs, and toilets. • The average daily viewing per person was six hours and fifteen minutes. • Watching TV was the preferred leisure time activity for 46% of the American public. Sixty percent of the American public received its news from television. Approximately 50% of video applications concerned the area of training. Why is Video Training Effective? Before discuss the advantages to video training, let me first answer the question ""Is video training effective?"". Since video training is a relatively new phenomenon, there is a dearth of available research in this area. However, in the great majority of those comparative studies that have been done, there was no significant difference in learning fr",Sugi-82-21 Boling.pdf
"go Gas & Electric Company Joe Bellew, San Diego Gas & Electric Company ABSTRACT A prevalent challenge for many of today's industrial computer facilities in satisfying the support, service and expertise levels demanded by the user. The programming staff is often back­ logged and engaged in long-term projects, where­ as the user is typically confronted with short­ term computer applications. This paper addresses the successful approach taken by the San Diego Gas & Electric Company (SDG&E) in responding to the needs of its computer user community. SAS (~tatistical !nalysis ~stem) was adopted as one of the major SDG&E user languages, principally because of its breadth of applicability. A SAS fundamentals course, designed for non-programmers, has been offered to SDG&E employees in support of their growing needs for computer sophistication. The SDG&E SAS fundamentals course is inte­ grated with a prerequisite course in TSO and SPF. Our SAS course is comprised of ten lecture and workshop periods which cover a five-week interval. Over 15 programming problems are resolved by the course participants in order for them to gain ex­ perience and confidence in their abilities to use SAS effectively for report writing~ graphics, file manipulation, data modification and elementary statistieal analysis. The suceess of this course design is now evident both in the high quality of the SAS programming projects being completed by the course graduates, and in the general recogni­ tion of SAS at SDG",Sugi-82-22 Glaser Roberts Bellew.pdf
"""The Top Ten"": Frequently Encountered Errors of Beginning SAS Programmers Debby Vivari, Westat Inc. Learning any new language, computer or otherwise, involves a period of trial and error. Because SAS is relatively easy to use, beginning SAS programmers get ambitious quickly, and problems can result. This is often worse for pro­ grammers experienced in other high level languages, because of preconceived no­ tions about the structure of a computer language. Those for whom SAS is a first language do not have this prejudice. Some of the 'errors' that occur are impossible to ignore--they produce error messages from SAS and the program does not execute successfully. However, a SAS program can execute with no errors and still be 'wrong' in terms. of effi­ ciency, because it does not make good use of the unique features of SAS. These kinds of errors can cost the most in terms of time and resources. The following list consists of some of the most commo.n errors encoun­ tered by new SAS programmers. It was compiled after a number of years of de­ bugging other people's programs. It is by no means complete and the order is not necessarily significant. 1. Confusion between procs and data steps. This is especially true for expe­ rienced programmers, who are used to printing out a few results, or computing a few statistics during the course of inputting and reformatting the data. This certainly can be done in SAS in a data step, but frequently proc prints or proc means show up in the middle of a data step. It is important to stress the two-unit structure of data steps and procs and how these units con be ordered within a program. It is not a matter (as in Fortran or Cobol) of reading a record, converting it into a useful form and then accumulating to­ tals, etc., and printing. First the data is read and converted. The file is then passed again in the proc and acted upon. A common example of this kind of confusion might be: Incorrect data dl, infile x; input abc; proc print; if a=l",Sugi-82-23 Vivari.pdf
"rammer/analysts is an essential and necessary objective every data pro­ cessing manager wishes to achieve. But we all know that it is not always possible to give that training due to project constraints, funding, etc. The end result is clear, the whole project suffers due to improperly trained programmers. Recognizing this need, we have developed a computer assisted instruction package (CAl) to train new SAS users in the syntax and structure of SAS. This paper discusses the method of design, module descriptions, and gives a course out line used in developing the SAS/CAI. INTROOUCTI ON In pointing out how projects suffer from not having a proper programming tool we provide a scenario of an en­ vironment which led us to developing the SAS/CAI. SAS has been available at the Department of Energy in Germantown, Maryland for several years. But even with the length of time it has been at this installation the package has experienced a low usage level. The reason is that the software at the Department of Energy (DOE) has fa 11 en into the famil i a r pa th of system deSigners using familiar tools. A system design team can only use standard software in their designs in which the programming team knows. At DOE. the majority of the applications are designed using SYSTEM 2000 (S2K), COBOL. TSO Command Language (Clists), and the on-line data entry package called OMEGA. In the appl ications where SAS has been used, it has proven itself to De an effective and powerful tool for data manipula",Sugi-82-24 Lafler Stewart.pdf
"At many installations there are at least three levels of SAS users. At the top level are a few SAS experts. At the second level, are the majority of users, people who regularly use SAS, but often with brute force techniques. The third level includes beginning users. This paper pre­ sents ideas for a course to raise the level of data management expertise among second level SAS users. Such courses should emphasize understand­ ing rather than syntax, and be organized around a series of examples which address common data processing problems. The key idea is to present multiple methods for solving each problem and to explain the similarities and differences between the methods.",Sugi-82-25 Sharlin.pdf
"Using SAS to Bridge the Gap between Computer Science and Quantitative Methods David R. Dolkart, American Hospital Association Introduction The degree of specialization within the fields of com­ puter science and quantitative methods presents a gap in analyses. The concentration of computer scientists on efficiency of design and detailed documentation oftentimes roadblocks quantitative analysis. On the other hand, researchers' orientation toward quick results leads to inefficient program designs and scarce documentation of data sets and program operations. To avoid the extremes found in this interdisciplinary gap, a balance between efficiency, documentation, and turnaround rime is crucial. This balance rests heavily on five factors: the underlying analysis characteristics; the nature of the project deadline; computer resource needs; staff requirements; and, the probability of repeating an analysis. Failure to fully assess the weight of each of these factors is a shan cut to detours and dead ends. Underlying Characteristics The data processing segment of a research project in­ volves one or more of the following operations: 1. Data Edits 2. Data Manipulation 3. Report Generation 4. Statistical Calculation S. Graphing Generally, a programming language-FORTRAN, COBOL, or PLll, for example-or a package like SAS handles projects involving the first three operations. However, when edit, manipulation, or report opera­ tions dominate a project, the balance sways toward the efficiency found in a programming language. In proj­ ects where these five operations are equally-important, the balance rests on a l::ombination of a programming language and SAS. With few exceptions, projects involving extensive statistical calculations and graphing require the use of SAS alone. Defining the Project Deadline When external forces determine a project deadline (for example, a corporate officer requests an analysis to support a critical decision). snatching the detail of the quantitative ana",Sugi-82-26 Dolkart.pdf
"INFORMATION-~APPED SAS: TEACHING SAS FOR RETENTION P. L. Olympia, University of the nlstrlct of ColuMbia INTROD~CTION In SAS training courses, as in most other courses, a student really begins to learn the material when he is faced with an application problem that needs solving, not while he Is listening to the lecture. If, for one reason or another, his lecture notes are insufficient to help him solve his application problem, he needs a handout or manual that will allow him to locate the material quickly and will allow him to retain the material better. Now, while some of us learned SAS exclusively from the User's Gul~e, many first-time SAS users are not so fortunate. Prior to the publication of the Applications Guide many users failerl to aPFreciate the full po,,,er of some !=;AS statements. How many S-.S beginners, for example, can tell you after reading the User's Cuide that • a ~ACRO can be used for other than simple string suhstitution • a colon has two distinct uses (he cannot find any reference to the colon in the Inde~) • an array can be character as w@ll as numeric? This is not meant to disparage the user's Guide in any way. It is, clearly, meant as a reference manual; that is why SAS Institute publishes both the Introductory Cuide and the Applications Cuide. The point here is that in present ing technical info rmation to a learner, conventional way of writing has its problems. Consider for a moment the fact that while the amount of technical inforBation with which we have to cope increases exponentially fro"" year to year our manner of communicating these inforllation via the pr inted page really has remained unchanged. The trouble wi th conventio nal prose is that paragraphs and unnecessary transitional phrases get in the way of essential ideas. There is a good lesson to be learned from spe@d-reading courses. Here, we are taught not to read the way we write - not to read sentences word by word - but rather to scan paragraphs for main irieas. Rut, if we ar",Sugi-82-27 Olympia.pdf
"TEACHING PROGRAMMING AND DOCUMENTATION TECHNIQUES William D. Phillips, Trenton State College Roger C. Race, New Jersey Department of Labor and Industry The Division of Systems and Communications of the New Jersey Department of Labor and Indus­ try is committed to the use of high level ""produc­ tivity aid"" systems in new applications wherever feasible. As part of that plan, SAS was install­ ed several years ago and made available to both professional programmers and users. The use of SAS has decreased the time required to implement new applications, but has led to some problems that we are now in the process of solving. Among the problems: Our professional pro­ grammers are proficient in COBOL and assembler language, but often have little or no familiarity with languages which syntactically resemble SAS. The user community members often have no program­ ming experience at all, yet the desire to get answers to questions quickly has led large num­ bers of them to teach themselves SAS. Both the professional programmers and users have had dif­ ficulty learning on their own from the SAS User's Guide, especially in adapting the information to their particular tasks. Another problem is that the free-format nature of SAS, while helpful in some respects, has led each user to develop his or her own programming style. The stylistic dif­ ferences make it hard for programmers to under­ stand one another's work and for our consultants to provide assistance to users. AN APPROACH TO A SOLUTION The Division has attacked these problems in three ways. First, a standardized coding style and technique has heen neveloped. Second a local SAS user's manual is being produced which illus­ trates the programming techniques we want people to use and which includes information on state­ ments incorporated in Release 79.3 such as DO­ WHILE and DO-UNTIL. The manual will eventually include chapters on creating data sets, selecting re~oTds, recoding variables, data management, produCing custom repor",Sugi-82-28 Phillips Race.pdf
"THE EVALUATION OF FEDERAL PROGRAMS IN EDUCATION Garrett K. Mandev111e~ University of South Carolina Introduction Beginning in about 1973 the federal govern­ ment developed an interest In the evaluation of the effects of monies provided to support public education. In fact~ loosely written evaluation requirements were included in much of the legis­ lation such as The Education Amendments of 1974 to Title I of the Elementary and Secondary Edu­ cation Act. One of these federal programs, initially referred to as Title III and later amended to be known as Title IV-C. focusses on the development of innovative programs. Title IV-C projects generally run for three and one-half years, with the first six months being used to complete the proposal including the evaluation design, the latter being prepared by an external evaluator hired by the project. Once the proposal is approved~ project staff generally spend a year developing the products~ and a second year field testing them. Although the evaluator has some limited involvement in monitoring these developmental activities, his or her primary task is to conduct the evaluation during the third year, when the project under­ goes a full implementation. Although educational evaluators are gener­ ally competent individuals with appropriate backgrounds in research and evaluation, measure­ ment and statistics, at times projects evolve so that it is difficult or impossible to conduct the evaluation as originally planned. It has been at times like this that the writer has been called upon as a consultant to either (1) write the code to conduct the analysis as originally planned, or (2) identify a reasonable alterna­ tive analytic strategy and code it. This paper provides a description of a project for which the writer served as a consultant, and the algorithms developed to perform the analyses. A General Description of CBE Programs The program to be described reflects a recent movement in education towards assuring some (possibly min",Sugi-82-29 Mandeville.pdf
"HELPFUL HII!TS FOR HARMonIOUS DATA J\}!fu,YSIS ?hilip Hanser, Sacramento Municipal Utility District Please excuse me if I stray sonewhat from discussing the software in SAS, which is the annoW1ced topic of my teJ.1.k. I prefer to speak today about some ways to avoid problems in dOing forecasting using SAS. My remarks will be directed towards individuals who find Lhemselves largely concerned with giving numerical information about a murky future, a not necessarily happy enterprise. Further, I will assume that these individuals are USing, or will be uning, polynomial represp.ntations of their time series, that is, Box-Jenkins, ARHlIA, transfer function or whatever you wish to call tllem, for dOing their forecasting. If you don't fit this description, fear not, for I think you also might find what I say useful. Let me begin by stating that the moaels for time series that Box and Jen­ kins put forward in their classic volume are among the most useful tools availa­ ble to the forecaster. Dave DeLong and his cohorts at the SAS Institute have d.one a fine job implementing into soft­ ware tile procedures wLich Box and Jen­ kinl:3 advocate in their book. I think the problem that arises with ARIMA modelling is that no matter how good the software, the techniques themselves are neither simple nor automatic to use. Frankly, I have ottunbled arcund a great deal when using their techniques myself, so what I am going to tell you will hopefully allow you to graduate from the time series analysis division of t:-le school of hard knocks with a few less bruises. Thus, herewith are my ""Helpful Hints for Harmonious :,lata ALalysis."" 1) 't Forccastcr, know thy data! !'I There is no substitute for knowing the origin of the data which you will be using to forecast. If it is a cor­ porate data set, you must be willing to dig into the history of the accounting procedures used by the company. If it is a medical, biological, or physical data s~t, you must be willing to under­ stand the instrum",Sugi-82-30 Hanser.pdf
"BASIC TIME SERIES TOOLS FOR BUSINESS FORECASTING Mary Sue Dickerson and franklin young United Airlines Introduction This paper deals exclusively with time series methods for forecasting .. We'll approach the forecasting problem from the viewpoint of a practitioner in the business world. Forecasting company-related activities (at the micro level) has its own set of requirements: The type of data The number of observations is often small. The data is usually seasonal and commonly contains noise. The type of environment Forecasting is often performed by non­ statisticians. Any technique should be largely 'transparent' to the user, intuitive, and yet easily understood. The technique and the results must be sold to the user. We have found the XlI and ARIMA methods a vail­ able in SAS quite helpful. For a lucid and brief exposition of their underlying logic, see Salzman (10) and Jenkins (7), respectively. For each method, weill illustrate its applications and limitations, then show how they interact syner­ gistically. 1. XlI; Applications and Limitations The Xl! method wa s developed by the Census Bureau to remove seasonality from a time series. Its applications, however, extend well beyond seasonal adjustment. The method requires at least three years of data and operates on monthly or quarterly series.. Through moving average filters, it decomposes the actual series into three maj or components: - trend cycle seasonality - random noise or irregular As suming a multiplicative model, the XU identity is defined as: Actual = Trend-cycle x Seasonal x Noise In addition, XII provides an option to estimate through regression the effect of trading days. A forecaster must examine the components of a series to interpret them correctly, other­ wise, for example, he might mistake non- 128 recurring fluctuations for a change in the trend. The 'true' level of the series once the effect of seasonality and random fluctu­ ations has been eliminated is displayed in trend chart (table D12 f",Sugi-82-31 Dickerson Young.pdf
"STRATEGIC ANALYSIS FOR COMMODITY HEDGING Ross Dennis, Nelson M. Fraiman, International Paper Company Murray Mohl, Seton Hall University A. Introduction InLiu:Hr-idf or-Ydlli.£aLion:::; pun,;ha::,t:;: lht:ir- t:;:1It:r-­ gy requirements in several forms. Oil, coal, natural gas and electricity are the most widely used sources of purchased energy. All of these energy sou rces have shown price in­ creases In the past few years. The industrial grade fuel oil (number 6 residual fuel) has ris­ en to $24.50 a barrel in July 1981 from $16.00 a barrel in July 1979. This represents an annual­ ized increase of about 26%. Although oil prices have stabil ized in the past year increases of this magnitude are still possible. In those in­ dustries where energy constitute a large portion of the manufacturing costs financial performance and market position of the company could be adversely affected by sharply rising energy costs. Companies have instituted programs to alleviate the rising cost of energy. Some of those programs are: 1. conservation 2. boiler conversion to multiple use fuels to take advantage of the currently lowest price fuel 3. long-term energy contracts (when avail­ able) 4. hedging future fuel requirements This paper discusses the appl ication of the SAS ARIMA procedure to forecast oil prices for the purpose of hedging future fuel require­ ments. B. Description of the Hedging process 1. Background The discussion of commodity hedging will be limited here to a buying hedge and to long posi­ tions in the market. Understanding the hedging process requires an understanding of the commodity futures con­ tract. A futurcs contract is' simply an agrec­ ment to take delivery of a specified amount of a commodity, of a specified quality grade, during a specific month in the future. The unit price is establ ished at the time the buyer pu rchases the contract. For example, a large candy manu­ facturer would have constant requirements for the commodities of cocoa and sugar. Rather",Sugi-82-32 Dennis Fraiman Mohl.pdf
"NEW TIME SERIES FEATURES IN SAS David M. DeLong, SAS Institute Inc. I. INTRODUCTION Additional time series capability has been added to the procedures AUTOREG, MATRIX and ARIMA for the 79.6 release. The additions to ARIMA will be available in test form in a procedure called TARIMA for the 79.6 release and will be added to the ARIMA procedure for the 82 release. The AUTOREG procedure will iterate the correction for autocorrelation and the calculation of the residual autocorrelation until convergence is attained. The iteration is requested by specifing the ITER option either on the MODEL statement or on the PROC statement. The iterations will be printed if the ITPR1NT option is specified. Three additional MATRIX functions have been added. They are: o ARMACOV: autocovariance of an ARMA model a ARMALIK: likelihood function, sum of squares and residuals for an ARMA model o MRATIO : inverts matrix generating functions. Subset ARMA models, intervention and transfer function models can be fit using the TARIMA procedure. II. PROC AUTO REG Currently the AUTOREG procedure does a two stage fitting sequence. Ordinary least squares is used to compute estimates of the residuals which are in turn used to estimate an autocovariance function. Based on this autocovariance function and the specified lag structure the regression model is refit using generalized least squares. In SAS 79.6 this process may be iterated until the estimates of the regression model parameters and the autoregressive parameters are consistant. Because the estimates of the autoregressive parameters are based on the Yule-Walker equations the resulting estimates of the parameters are not unconditional least squares estimates. However, for long series they will be nearly identical to unconditional least squares estimates. The equations which are iterated can also be derived by considering the minimization of a quadratic form. This quadratic form is obtained by using a finite portion of the inverse of the infinite v",Sugi-82-33 DeLong.pdf
"ESTIMATION OF A TRANSLOG COST FUNCTION USING SAS GEORGE M. MC COLLISTER, PACIFIC GAS AND ELECTRIC COMPANY INTRODUCTION One of the most difficult tasks to perform with an econometric package is to estimate a trans log cost function and test it for concavity. This paper demonstrates how this can be done easily with SAS. To illustrate the methodology, a $AS program is 1; sted and used to estimate a translog cost function. One of the highlights of the program is its ability to test the estimated cast func­ tion for local concavity in the range of the data. The next section of the paper briefly describes the trans10g cost function. Then we discuss the program and some results obtained from estimating a model for some data. THE MODEL A cost functi on can be used to model a manufacturing process. The cost of pro­ ducing output (goods or services) is given as a function of the amount of output and the prices of inputs to production such as capital labor, energy and materials. Given a level of output the producer is assumed to minimize cost by choosing an optimal mix of inputs. The cost function is given as 1n C "" ~o + a Q 1n Q + ~ a QQ (In Q)2 + E E f ai 1n Pi + ~ i j ""l ij 1n Pi 1n P j + f \q ln Q 1n Pi I,J""K,L,E,M, [1) where Q, K, L, E, M are symbols for output, capital, labor, energy and materials. Shephard's lemna implies that input quan­ tities qi necessary for cost minimization are given by ..1L so that: ap i a 1n C = ~ "" Si (2) a 1n Pi C where Si is the fracti on of cost used to purchase input i. Then The E 0, i rij a E i + j ""l ij 1n P j + Y iQ 1n Q E restrictions 1: (li = 1, i Y Qi "" 0, 3 ""lij "" 0 and ""lij = ""lji are imposed. To allow for errors in cost minimization. an error term is added to each share equation (3) and to the cost function (1). (3) 146 Since the cost shares must sum to one, the cost share equations are not independent. Using the parameter restrictions, one share equation can be eliminated. The cost equa­ tion is estimated in two steps. First the p",Sugi-82-34 McCollister.pdf
"INTERIM MULTIPLIERS FOR SYSTEKS WITH LACCEO VARIABLES Arbi Ben Abdallah and Robert P. Parks, Washington University In a dynamic multiple equation model. there is interest in deriving the period specific dynamic multipliers <in­ terim multipliers). The value of such a multiplier ia the effect of An exogenous variabla lagged a certain number of per­ iod~ on the current value of an endoge­ nous variable. Specific analysis of these multipliers yields information about the speed of adjustment to an exo­ genous change <possibly a policy change) 1. 2, 3. periods into the future. PROC SIMLIN does provide an option tN~ERIM=n, to calculate these multipliers but thev are correctly calcul~ted only in the case the model has no lagged eKoge­ noue v~ri~bles and only a one period lag for any of the endogenous variables. The E'Hi manual does state that the INTERIM= option will not yield correct results for models with lags greater than one, but incorrect multipliers are calculated by INTERIM~ when there is a lagged exogenous even if it is only lagged one period. The aim of thiJ; paper tJ; to explain a technique of reforming the model so that the interim multipliers may be ob­ tained from the INTERIM: option of PROC sIMLIN for any model, i.e. any laqqed exogenous or endoqenous variable may be in the model. and for any number of per­ iods. The pa~ar is divided into three se~tion5. The first section presents a ~imple simultan~ouJ; model, d~rivE5 th~ interim ~ultipliers, and shows how the INTERIM... opt ion of SIMLIN incorrectly calculates interim multipliers if there is a lagqad exogenous va~iable in the model. The second section presents our technique of reforming the model so that SIMLIN will yield correct multipliers with the INTERIM:; option. The third ~ection oontain~ the SIMLIN example in tho ETS sample library modified to con­ tain lagged exogenous and multiple pEriod taggEd endogenous to 11lustrate the SAS cod~ needed to implement the technique. S'gtion 1..... ~erlvatlon ~ Int.",Sugi-82-35 Abdallah Parks.pdf
"The biplot is a graphical display of' points representing the n rows and m columns of a data matrix. Besides conveying information about each row and colunn as a whole, this simultaneous display of row and column markers also conveys information about the n x m individual elements of the matrix. Biplots are useful for visual in­ spection of data, because they offer a succinct sunmary of the data (conveying n x m numbers with n + m points). They permit detection of clusters and outliers, and they allow discovery of patterns and regularities that can be used to diagnose models for the data. This paper presents a ISO eLlST which can produce a variety of different types of bi­ plots. The capabilities and use of the CLlST are described, and illustrated with an example.",Sugi-82-37 Tsianco.pdf
"se such as breast cancer with multiple test modali~ies (palpation, mammography, and thermography) will ordinarily have several distinct strategies optimal over the typical range of risk profiles and costs. Computer graphics haa played an important role in viewing the complexities of t~e problem and in making simplified screening recommendations. INTRODUCTION The basic process of breast cancer detection is as follows: Several different screening tests arc currently available to detect the presence of suspicious masses and/or formations in breast tissue. Those in common use are simple palpation, mammography (film radiography or xeroradiography), and thermography (which produces a map of temperatures within the breast). When one or more of these tests produces a result that suggests the presence of cancer, a biopsy of the lump or region is performed. The resul ts of the biopsy are held to be definitive, and if they are positive, therapy is begun. While these three screening tests are relatively inexpensive compared to the high cost of a cancer le-ft undetected, they nonetheless do have costs associated with them. First there is the cost of the tests themselves multiplied over the large number of subjects who might be involved in a mass screening program. Second there is the cost of biopsies performed on a certain number of cancer-free individuals as a result of the test outcomes. Third there is a cost associated with the accumulated dose of x-rays used in mammography. For these",Sugi-82-38 Spitznagel Gohagan.pdf
"A new procedure based on classical equations is used to graphically characterize large volumes of coordinate points without drawing them. The construct, called the Standard Deviation Ellipse, is described and derived, and examples show how it is easier to recognize subtle differences in the data and how it makes presentation of the data more esthetically pleasing. A SAS procedure is described that can be used with SAS Proe PLOT or with SAS/GRAPH and two examples are given: one from CADAM statistics and one from professional sports showing height versus weight for various sports.",Sugi-82-39 Shipp Margolin.pdf
"This paper describes a hybrid technical-financial procedure for allocating cost in a large data center. It is designed as a modeling tool to permit IIWHAT-IF"" analyses for various configurations, levels of costing. etc. The use of modular programming, independent tables, and matrix output allows the modeler maximum flexibility in allocating cost according to changing technical and financial considerations. The first segment of the procedure focuses on a technique for determining primary system capacity. The second segment generates the cost-allocation mechanism, which assesses cost to users based on their individual impact on capacity. 1.",Sugi-83-02 Zambruski.pdf
"lly backs up SAS data libraries and partitioned data sets to tape. These OS data sets are cataloged as members of generation data groups. Only SAS data libraries that have been modified since the previous backup are copied to tape. This feature not only provides the user distinct backups, but reduces both tape space and the number of entries on the system catalog. Partitioned data sets are not copied to tape unless they have been accessed since the previous backup. AlIOS data sets and their attributes are included in a SAS data library {DMSSASDLj. This library contains separate SAS data sets for SAS data libraries, partitioned data sets, and other OS sets. Inactive SAS data libraries and partitioned data sets are deleted from diSk by the disk management system, but maintained in the DMSSASDL. T~is data library, in addition to the attributes contained on the disk's volume table of contents (VTDC), includes for each SAS data library and partitioned data set, a unique numeric code, creator identification, last modification date, and the dates of the three most recent backups. Users easily can access a tape backup after a simple modification in the data set name {DSNAMEj. The system also includes a keyword-driven facility for producing special reports and managing data sets. I NTRODUCTON Three-hundred-ninety million bytes of on-line disk space for storing clinical data should be sUfficient space for a company submitting one new drug application per year. For example, a recent SAS",Sugi-83-03 Hoffman Tanis.pdf
"A data communications systems analyst needs to provide accurate, timely information to those who operate the network. A valuable but often overlooked source of data to help accomplish this is the systems source code which defines the network. This paper describes a SAS job stream which transforms this data into useful information. A SAS program is used to decompose the heirarchical data structure present in VTAM and NCP macros. From this, SAS files are created and information is disseminated through summaries and listings. On-line inquiry is available through SAS/FSP under TSO, and SAS/GRAPH can provide visuals. The job stream also passes SAS data to the Network Communications Control Facility (NCCF) for access through that system.",Sugi-83-04 Cook.pdf
"gor 1.0 ABSTRACT This paper describes the design and implementation of a large SAS production billing system developed at Hewlett-Packard's Corporate Data Center. The design considerations for implementing such a large system in SAS will be discussed along with advantages of im­ plementing this system in SAS, such as: quick pro­ totyping and implementation, ease of use, adaptabili­ ty, efficiency and the additional feature of graphics. Also described are a few problems that were en­ countered and overcome: conversion problems for users, problems with being the first SAS production system, disk capacity problems, SAS limitations, in­ terface problems with the center's HP 3000 minicomputers, and code integrity. The system implemented was a Computer Resource Management System based on the Merrill CPE database, using SAS as the implementation language and using SASIFSP and SASIGRAPH for additional support. This system allows data center staff to per­ form computer utilization research, as well as capaci­ ty management and hardware planning, though its primary function is for user billing. , ., BACKGROUND Hewlett-Packard is a large electronics manufacturer with corporate headquarters and a data center located in Palo Alto, California. The data center runs 2 Amdahl 470 V/8s, an Amdahl 4 70 V16-II, and a large network of HP3000 computers. A worldwide com­ munications system is also based at the center. This could be described as a typical large corporate data center. '.2 THE PROBLEM",Sugi-83-05 Case McGregor.pdf
"Evaluating the Performance of VM/SP Systems with SAS Peter L. Jobusch, SAS Institute Inc. This report describes a system of SAS® programs for first level analysis of CP Monitor data collected by the VM/SP operating system. This self-contained system calculates a complete range of standard performance variables and archives them for further SAS based capacity planning analysis. Before discussing specific examples of how SAS can be used to evaluate the performance of a VM/SP computer system, let us see what data are available from which we may extract performance information. CP monitor data VM/SP Release 2 trace table recording CP accounting records VM Realtime Monitor (SMART, 5796-PNA) CPWATCH, etc. on the Waterloo tape A description of CP monitor data is in Appendix C ""VM/sP Monitor Tape Format and Content"" of the IBM VMISP~ System Programmer's Guide. Appendix C is particularly useful because it describes the data fields and gives a cross reference between the variable name in the DSECT and the name of the CP variable stored in the records. In the IBM VMISP: Dota Areas and Control Block Logic the DSECTS describing the records are listed. CP Monitor data collection can be controlled in two ways. The SYSMON macro in the DMKSYS file establishes the default parameters for automatic monitoring, and the CP MONITOR command can ,be used by a privileged user to dynamically alter the classes of data being collected, and to manually control the data collection process. The SYSMON macro is documented in the IBM VM/SP: Planning and System Generation Guide while th.e IBM VM/SP: System Programmer's Guide and the IBM VM/SP: Operator's Guide document Use of the MONITOR command. Copyright © 1982 by SAS Institute Inc. All rights reserved. Printed in the United States of America. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, or otherwise, without the prior written permissio",Sugi-83-06 Jobusch.pdf
"In the past few years, there has been a grow­ ing controversy in the literature over the util ity of many Operations Research pub lica­ tions. Some readers argue, and rightfully so, that most of the art icles are authored by re­ searchers, statisticians, and mathematicians who have little knowledge of or regard for the true fabric of management. As such, mathe­ matical rigor and abstract thought are often emphasized to the exclusion of real world practicality. Consequently, the gap continues to widen between the academic theoretician who structures the methodology and the working manager who has to 1 i ve with the daily prob­ lems. To help bridge the gap, this paper focuses on SAS as a practical decision support system. At the outset, the authors would 1 ike to make ;t clear that there will be no appeal to rig­ or~ elegance~ or mathemat-ical gymnastics. The principal thrust of this paper will be on con­ ventional managerial problems of productivity, absenteeism, forecasting, compensation and equipment proClJrement. The authors will dem­ onstrate that in the absence of staff, time, and other resources, SAS is a powerful method­ ology to employ to generate quick and dirty solutions to practical problems. The paper is action or results oriented with particular em­ phasis placed on queueing models, ANOVA, 80x­ Jenkins, X-ll, Monte Carlo methods, regres­ sion, and cluster analysis.",Sugi-83-07 Gibley Schoen.pdf
"A user oriented interactive computer system has been recently developed using SAS to deterministically model long term inventory proje~tions for a multistage inventory to inventory production process. Alternative sce­ narios faT commodity supply and demand can be selected by the user to model the resultant inventories. Supply scenarios are further classified into known or committed sources and those that may be considered desirable sources of supply. One of two different models may be selected either to simulate inventory levels based purely on input data (descriptive model) or to generate unprescribed additions to inven­ tory (and the resulting inventories) needed to maintain existing policy requirements on minimum inventory levels (normative model). Inventory statistics are generated, printed and stored by a SAS background program based on the user's responses to several on­ line program input requests. A separate menu option provides foreground SAS color graphics reproduction of stattstics generated in the background job. The specific application dis­ cussed involves the simulation of the uranium inventories resulting from the procurement process at an electric power utility.",Sugi-83-08 Bauman.pdf
"Application of Pareto (Lorenz) Curves in Modelling Logistics Systems Ross Dennis - M&M/MARS, Inc. 1. Introduction The Italian economist and sociologist Vilfredo Pareto (l848-l923} studied the distributions of incomes for individuals in many countries. As a result of these studies he formulated a ""law"" about how income and wealth is distributed within populations. His findings became known as ""Pareto's Law."" He found that a small fraction of the population accounted for a large fraction of the income. This fractional relationship between two variables occurs with great frequency in many social. economic and business activities. It has become known as the ""20/80 rule"" implying that about 20% of some group of items account for 80% of the contribution from another variable. The relationship rarely occurs exactly at 20/80 but more likely is found as 10/90, 13/87, 5/95 ••• etc. Some CamBOn examples are: Items Contribution Inventory items Customers Customers An occupational group Energy-using facilities Geographical areas Sales revenue Customer demand OVerdue receivables Income Energy expenditures Sales revenue The relationship has particular significance when a scarce resource must be deployed or allocated. It is obvious that the resource should be allocated to the area from which the greatest benefit will accrue. For example, if 20% of the customers account for 80% of the sales revenue then a proportionate allocation of the sales resources should be directed toward the top 20% of revenue producing customers. There are, of course, many other practical examples where proper identification of the small fraction can lead to more efficient allocation of resources. Since the ""20/80 rule"" occurs so frequently it is of interest to have a standard a methodology to compute and display the relationship for the popUlation under study and to compare simi lar populations. 2. Creating the Curves The ""20/80"" rule exists because the popUlations from which the rule is derived tend to be l",Sugi-83-09 Dennis.pdf
"Introduction to Linear Programmiq with SAS Msrc-.david Cohea SAS IDstitute The purpose 01 this paper is to introduce PROC LP. a Dew SAS procedure that solves linear programs. To demonstrate the features ofPROC LP I will present an ex­ ample or a JiDeal' program and !Show how the LP procedure is used to solve tbe problem. Table I shows the plan of presentation. PROCLP Plan of Presentation • Introduce Product Mix Example • Represent the Model witb a SAS Data Set • Solve with PROC LP • Interpret Procedure Output • Geier. Primal and Dual Output Data Seta • Price Sensitivity Analysis • RHS Sensitivity Analysis • Larger Problems Table I The problem or determibing aD optimal product mix oll'ers a straigbtrorward introduction to linear programming and is a problem that frequently occurs in prllCtice. Table II 6bows data that summarizes the production potential of a company that i& r!I.Cing this type or problem. 53 PRODUCT MIX EXAMPLE Product FreDeh Fries Hash BrowDI Fides Proat Sal .. Source 1 Source 2 LimitstioDs .2 .2 .3 5.0 .3 .1 .3 6.0 Table n 1.8 1.2 2.4 . Tbe company produces thm!! products: rreDch fries, hash browns, and fides. It has two 80urees of potatoes, Source 1 and Source 2, ror use iD producing these products. The potatoes from these sources are substantially differeDt. One unit of potatoes from Source 1 produces a mixture of the three products that is dill'ereD& from that produced by one unit of Source 2 potat0e5. The table shoW! the product mixtures produced tram a uDit of esc' type of potato aDd the proat the company realizes from selliDg the produced mixture. The table also lihows t)le upper limit aD tbe amouDt of each product that caD be sold. The problem is to identity the quantity at Source 1 a.nd Source 2 potatoes that maximize the profit while not exceediD8 the product sales IimitatioD8. This problem, taken trom Wagner (19705), can be tormu· lated as a linear program. The objective is to maximize the linear (unctioD o5.OSQURCEl + 6.0S0URCE2 sub. ject",Sugi-83-10 Cohen.pdf
"SPOTPLUS - COAL MARKET DATA MANAGEMENT Robert M. Neil, Virginia Electric and Power Company Introduction The Virginia Electric and Power Company. like many eastern electric utilities, spends more on coal than any other fuel. The coal is purchased through long-term supply contracts and from the spot market. Each month up to several hundred vendors submit spot market bids for delivery the following month. Vepco must decide in about six working days what offers to accept and where each lot of coal should be shipped. To further complicate the situation, no two lots of coal are the same. Different physical properties of the coal can greatly affect its value to Vepco. Each power station has its own quaH_ty requirements and tolerance for impurities. Also, the coal vendor's ability to perform must be considered. The Spotplus system has simplified the coal procurement process. Spotplus is a TSO command list that ca11s SAS to permit edi,ting or adding spot coal offers, freight rates, or long-term supply contracts. It also submits background jobs to produce various reports. migrates older data to mass storage, and can interface with a linear programming model that helps select and allocate coal offers. Recording Market Data A. General Coal market data is divided into two types, contract and spot. The same data is kept for both types. The pnly difference is that the contracts have already been accepted and allocated to a power station. Because the contract data is almost the same from month to month. the same SAS dataset is used. Spot market offers are completely different every month so a different SAS dataset is ¥sed each month. Spot coal offers are entered as they are received. A new SAS dataset is used for each month. The SAS name is determined by the mon'th, such as I' 198301"" for coal to be delivered in January 1983. Two system datasets are used to store coal market data. A disk dataset has spot market data for the three or four most current months contract data and graphi",Sugi-83-100 Neil.pdf
"RACT An extended version of SPSS*, named SPSS-X, will replace the existing SPSS release in early 1903. The new system files are substantially different from older SPSS files and they cannot be read by PROC CONVERT. Thus, conversion of the new files will require writing the file in raw data form, constructing SAS control cards, and reading the file into SAS with all the associated problems and cost of debugging, typing variable names, input formats and labels for hundreds or even thousands of variables. To avoid this arduous process, we have written a program, named SPSSXSAS, which will read the dictionary in the SPSS-X file and use that information to create. automatically, a $AS dataset. SPSSXSAS will convert variable names, labels, print formats arld missing values; and, in a valuable extension of the capabilities of PROC CONVERT, it will convert value labels and documents. II. CONTEXT OF THE PAPER SPSS has achieved wide use as a statistical pack­ age, but it has always been hampered by its primitive data management capabilities. An extended version of SPSS (called SPSS-X). containing capabilities s~ilar to SAS's SET and MERGE statements as well as other enhancements, is scheduled for release in February 1983. When SPSS-X is released, all older releases of SPSS will be superseded and no longer available from SPSS, Inc. The system files used by SPSS-X are substantially different from older SPSS system files and they cannot be read by SAS's PROe CONVERT. This means that progr",Sugi-83-101 Blank Norton.pdf
"A SAS PROGEAH TC SCORE THE MICHIGAN TESTS OF ENGLISH LANGOAGF PROFICIENCY AND AURAL CO~PREHENSION Charles E .. Ilich .. Chio University 'Ihis proqraBl scores r~.Epons.,s to the Michiqan Test of English language Proficiency (~TELP) (PetErson, 1971) and the Michiqan Test of Aural Co~pIebcnsion (!'1T~C) (Upshur. 1969).. ~t the teqinning and end ~f each academic quarter at Ohio Universty, the program is uSEd to SCaLe these tests (totalinq 190 items) taken by 50 to 350 international students. On the basis of the initial testing, the students are assiqn~d to apfropriate levels of instruction iJ, English, and the final testinq ferlits assessment of progress made over the quarte~. In all, thirteen answer keys are possible, and, because ~f the number of iteratiVE stEpS in the proqram, a large numb~r of SAS macros are used for scoring and printinq the results.. Standard summary statisti=s are produced for the group as a whole, while taw and ""equated"" scarf'S (based on norms) ar,.; producE'.d for each individual. Output also includes ~TELP subscale scores en qrallmar, vocatulary, and readinq, se~arat€ composition scores, student names, and codes to indicate test forms used.. A eMS Exec is used to construct the 1cb, specifyinq dates, number of copies, and the particular ans~er kEyS to UE useo. Oa+a is q~li&r~ted frcm NCS answer sheets by an NCS 7003 op!ical scan~er and is sent to the useI:' IS virtual machine for use in this SAS proqram. Thi:::: program has rE:sulted il; sul'stantial savings in time, sincE"" the scoring was pt""eviously done by handa Further Information information ~l~as€ contact Ccmputinq and l~arninq university, AthEns, Ohio Fo r further thE author:, services, Ohio q5 70 1. RE:ferenC€5 Peterson, J., Upshur, J., Palmer, A. S., & Spaan, 11. It .. , tlicl!ig~.!! !§.§1 Q! ]ag!!§h 1~DS~~9~ l~~~!£b~D£Y~ University of Michiqan Press: Ann lI.rb:>r, 1971 .. ~pshurf J .. , spaan, 11 .... t; ThrashEr, R., lliQnig1)ll l§.§.! ..Qi Ayt::!l ~Q~~£~hgnsiQ'!!~ Ur.iversity of Mic",Sugi-83-102 Rich.pdf
"I ~ i f I I , ~ A SAS TES1SCOFING AND ITEM ANAlYSIS EROGBAM Charles !. Rich, ChiD University Introduction This SAS program, referred to as ~COR, scores multiple choicE tests and provides item analyses with the qoal of illlprovinq classroom tests and minimizing the routine record-keeping work of instruct::>Ls. SCOR is tased on the SAS PROC ITEM, a version of which was first prcsentei at SITGI (Deitz £ Smith. 1980) and vas later published as SAS Technical Report N:). 5-126 (Smith, 1980). SCOR is cur~ently the standard pLoqram used by the Testscoring Office at Ohio University to perform testscoring fUDctions and produce various raw data files.. The staff operator uses eMS Exec's to build and edit SCOR according to features requested ty each user. Typically five to ten tests are process€':i in one multi-step job, run in batch on an IBM 370-158. In each job step SCOR is tailored according to requested featUres and a particular data file.. The data files are created by processinq NCS computet answer sheets on an NCS 7003 optical scanner. For each test a maximum of 200 questions with two to five possible choiCES per question may be processed. summary statistics and Item Analysis PRoe ITE~ produces such statistics as the mean score, standard error, reliability indexes, and point biserial correlations, to name a few. Beyond the summary statistics provided by PROC ITEM, SCOR provides the median, mode, and measures of skewness and kurtosis by using an outpu t data set from PRGe UN IVARIA.TE. The iteOJ analysis is expanded by providing raw frequency counts per choice per guestion for the total class and for the uppec and lower 27% scoring sub-qroups.. The indexes of difficulty and discrillination are then calclllated usioq theSe: :5ub-gr:ollpS, as recommenled by Ebel (1919) .. A fiVe-page jescriptiv~ teKt is also optionally PI' ir. ted, def ini ng SCOR terminology and including- suqqestio[Js frcIIl Ebel P97Q) for using portions of the output to im prove tests. scoring and Recor",Sugi-83-103 Rich.pdf
"ANALYZING CONGRESSIONAL CARt;}!;R PA'I""l'J::RNS USING SAS Robert G. Brookshire & Claudia C. Putnam, North Texas State University This paper demonstrates the usefulness of SAS in solving unusual data problems, computing new variables, creating new data sets, and performing statistical analyses. The Inter-university Consortium for Political and Social Research (ICPSR) has compiled a data set containing biographical information on every member of both houses of Congress since 1789. This data set has a variety of uses for studying ~hanges in co~gressional career patterns. but it presents the researcher with a formidable set of methodological problems: 1) The unit of analysis in the ICPSR data is the individual congressman, while that used in congressional career research is typically the Congress as a whole. 2) The common measures of legislative professionalism must be calculated for each Congress. 3) These measures, Brookshire and Duncan's career coefficient (Brookshire & Duncan, 1983), and Polsby's percent first term and mean terms of service measures (Polsby, 1968) are calculated by greatly differing methOds, requlrlng a restructuring of the data set for the computation of each index. Brookshire and Duncan's career coefficient is calculated thrdugh the fitting of a nonlinear regression for each freshman class of congressmen. This regression function describes the rate of ""decay,"" that is, the rate at which members of a freshman class end their congressional careers, and is expressed as: x y = 130 + 8,8 2 where Y is the number of each term of Congress, X served by the members of freshmen remalnlng after is the number of terms the class, DO is the number of congressmen from this class remaining at the end of the observation period. 81 is the difference between the number of freshmen in the class and EO' and BZ is tile career coefficient, which descrlbes the percentage of the class members which will remain after the next term. To arrive at this coefficient using the IC",Sugi-83-104 Brookshire Putnam.pdf
"rgery, University of Toronto and Toronto General Hospital; and University of Toronto Computing Servi~es, Toronto, Canada Abstract Toronto General Hospital is one of several teaching hospitals affiliated with the Univer­ sity of Toronto. The Cardiovascular Surgical Division of Toronto General Hospital uses the SAS package installed at the University of Tor­ onto in many of their research projects. With technical support from the SAS instal­ lation group at University of Toronto Computing Services 'U.T.C.S.), and the versatility of the SAS package, the division is able to per£ram sophisticated statistical analysis on its Metro­ Toronto adult op.en heart data. Monthly and qucq'­ terly reports on morbidity and mortality of pat­ ients undergoing routine surgery have been com­ piled and generated. The ability of the package to extract and analyse from a large volume of patient information collected at various inter~ vals helps in isolating factors associated with post-op morbidity and mortality. . It is anticipated that the SAS package's ~nherent ease of use, the ability to perform complex calculation and equally important, the strong local support, will combine to attract numerous new applications and an increasing us­ age from various hospitals in the area. Project Scope and Organization The City of Toronto, as one of the major adult open heart centres in Canada, performs about two thousand open heart operations a year. In 1981, three hospitals in the Metro area, Toronto General,",Sugi-83-105 Tong Mitchell Weisel.pdf
"EXPERIENCE WITH A LARGE CLASS, GRADE DECISION SUPPORT SYSTEM Marvin D. Troutt, Southern Illinois University at Carbondale Eric Poon, Southern Illinois University 1. Introduction The authors I academi c department ; 5 charged with delivering the basic business statistics course requirement in the College of Business. This course has enrollments of up to 400 per regular semester. At present the course is de­ livered by way of two large lecture sections of approximately equal size, along with one hour labs in smaller sections. Thus each lecturer is responsible for assigning approximately 200 grades each semester. Due to the large number of students per lecturer and to tight constraints on graduate assistant help (this available support is needed ;n test preparation and laboratory leadership), the manual scoring of tests and manipulation of final grade records is all but precluded. Thus as a first step towards an automated grade reporting system~ all tests were designed to have one of up to five multiple choice answers per question, and all tests were scored using an Opscan 1000 optical scanner. A campus office processes the test response forms and creates a card deck, along with raw scores and various reliability, error analysis, and summary reports for each test. Thus what was needed was a pro­ gram to process all of the individual test data sets for fi na 1 grade ass i gnment dec; s ions and permanent record keeping. 2. Some DeSirable Features of Outputs The first requirement of the information output was taken to be a presentation of letter grades (A. B, etc.) for each student on at least three bases of determination. Thus the OM would be ab 1 e to look at a vector of 1 etters on each student at the end of the course, and combining other nonquantitative information, select a sat­ isfactory letter grade to report for the student. Generally the author has picked the best letter score shown for each student except when one of the scales is experimental in nature. The s",Sugi-83-106 Troutt Poon.pdf
"INFO MENU Russ Hackett, Blue Cross of Massachusetts, Inc. Info Menu was developed as an end user tool. It is designed using the System Productivity Facil­ ity (SPF) product of IBM. It allows the new user the ability to write a simple SAS report, while giving the more knowledeable user the abil­ ity to create new variables, and do sub-totals and grand-totals and format elements on the out­ put report. Features The major features of the system include: 1. Ease of use. All that 1s needed is a basic underHtanding of what the screen is re­ questing you to enter. 2. Little knowledge of SPF, SAS or IBM JCL is needed. If the user c~n logon to the sys­ tem, he can use Info Menu. 3. Menu driven system. There is a main menu, as well as a screen for creating JCL and a screen to create a SAS program. The system is run under TSO on an IBM mainframe. You begin by executing a eLIST to allocate and concatenate the system SPF files and user source, panel, message and table libraries, and to call the main menu. Example: 'INFO.JCL.D.(ICSPF)' - See Exhibit A The main menu (Exhibit B) has many of the SPF options along with two options developed for the use of SAS. The first option developed is OPTION 0 - PRINT. This option allows the end user to write, modify and/or submit a simple SAS print program from an existing SAS database. It consists of·two screens. The first screen (Exhibit C) creates the job card with all pertinent accounting in­ formatiun, cundition coues, job class, message class and a time parameter. The second screen (Exhibit D) allows the end user to fill in such variables as data set names and program name, as well as the variables for the Proc Print. It also allows the use of formatting of output variables, and the ability to calculate new variables. Upon completion of this screen, a bateh joh will he Ruhmitted. On subsequent uses of these screens the variables will be mapped back to the screen from the user profile. The second option OPTION 1 SAS is currently under deve",Sugi-83-107 Hackett.pdf
"flost software systems are capabl e of generating random nUQbers to assist in simple random safJpli n9. I f a r.lore cOr.Jpl ex sar.Jp li n9 scheme is required, such as stratified randomization, a cOr:Jplicated program r:Just be generated to acconplish this task. SAS is able to simp1 ify this task a great deal by combining various PROCedures with prograr.u-:Jing statements such as DO loops and IF-THEN-ELSE conditionals. ~~thods and codes for obtaining numerous randor:Jizations will be presented in this paper, but emphas i S Hi 11 be on Strati fi ed Randor:Ji zati on scher:Jes. Sar:lple programs will be presented which can be developed by a SAS user ~ to sat i sfy a variety of randomization formats. Use of several PROCedures and functions, including UNIFORf,l, RANK, and SORT J will be discussed.",Sugi-83-108 DiPietro Tu.pdf
"tably enhanced in many applications by an interface to a data base management system (DBMS). Several such interfaces exist, usually implemented by writing a SAS procedure that makes appropriate program language interface (PLI) calls using the subroutine library provided by the DBMS supp 1; er. 5; nee the DBMS is an ; ndependent commercial product, changes and enhancements in the DBMS or PLI library are made without regard to the SAS interface, and maintenance becomes a problem. Recently, Boeing Computer Services installed a new release of RAMIS II which rendered the existing SAS/RAMIS interface (distributed through the SUGI SASWARE Index) inoperable. Lacking source code, we could not upgrade the existing interface. Because of time constraints, a new interface was constructed using EXECs and SAS itself. By having SAS read a data dictionary written by RAMIS, and then itse If writing SAS code to read RAMI S data, a very flexible interface was constructed quickly, and with no native language or PLI programming. SAS is being used more and more to analyze data collected and maintained in large-scale production environments. In such environments a data base management system (DBMS) is often the software primarily responsible for the data, but access to the data by SAS is desired for analytic applications. Several routes are possible for providing such access. In low-to-medium volume situations, the DBMS or a special-purpose program might be used to dump all or selected data into an",Sugi-83-109 Fingerman.pdf
"MULTI-TIME-PERIOD NLIN REGRESSION William J. Harrison, Fireman's Fund Ins. Co. I. Introduction and overview. This paper reports upon techniques used to develop a non-linear equation to model and predfct a varfable subject to several differ­ ent time-based cycles, along with non-cyclic and random-like factors. The development of the equation from the base data is done in a two-stage manner: 1. First, each of the cycles to be evaluated 1s repeatedly run through the SAS NLIN procedure until the results-testing pro­ cedure indicates a suitable fit. (A pre­ liminary STEPWISE may be used). 2. Then, all the resulting equations from the first set of runs are joined addi­ tively to form a new starting equation. This is then run through NLIN against the same base data using the same results­ testing procedures until a final SUitable fit is found. At this paint a final pre­ dictive equation exists. The final predictive equation is used in a new SAS DATA step and time periods are simu­ lated for the period to be predicted. The IICase Study"" portion of this paper illus­ trates actual results and an example of how well the predictive equation matched the actual events predicted. II. The Problem Assume a measurable variable Y, which occurs on a regular basis both in the past and in the future. Past data is known, and it is desired to estimate future values. Y is known to be effected by many different fac­ tors, some clearly cyclic, while others are seasonal, lagged, or unpredictable (random). The general equation desired is: where Xl' Xl' etc., represent different time periods: years, weeks, etc. III. NUN Preliminary Runs. Each of the time periods should have an NLIN run of its own, disregarding the other time periods. Two items are needed for an NLIN run: a model equation; and first estimates of the coefficients of the terms. 1. Model Equation. The model equation is simply one of the Sigma1s shown above. 61 2. Initial Coefficients. An initial value of the coefficients: a.,a""a1,aJ",Sugi-83-11 Harrison.pdf
"5 AS enjoys widespread acceptance as a data management system. Most applications, however, involve the writing of sometimes lengthy and complex 5 AS programs. These programs are usually spec i fie to the data management problem at hand and do not easily generalize to other data management situations. The writing of ad hoc SAS programs to salve changing, often unforeseen data management problems results in heavy demands on programming staff and computer resources. The relCltiunal approach to the management of data provides a comprehensive and integrated solution to many data management problems. Although 5 AS currently has elements of a relational system, it most importantly lacks a systematized way to manipulate SAS data sets in a true relational manner. R AQL is a new relational query language which brings a full relational processing capability to 5 AS. The higher level language of RAQL permits the relational processing capability to be expressed clearly and very concisely. Information in SAS data sets becomes more accessible. Queries on the data are much more easily formulated. Manipulation of SAS data sets becomes more precise and systematic. The query facility of RAQL combined with the statistical, editing, report writing and graphics capability of SAS results in a very comprehensive data management package.",Sugi-83-110 Burrage Gilman.pdf
"A new procedure, PROe M204, is presented. This procedure allows a SAS user to build a SAS data set from data extracted from a Model 204 file. PRoe M204 couples the powerful data retrieval facilities of Model 204 with the data management, statistical, and graphical procedures of SAS. With this procedure, a SAS user can access data stored in a Model 204 database with little or no knowledge of Model 204. PROC 204 does not allow a SAS llser to access Model 204 data that he would otherwise be forbidden to access. defined through Model unauthorized access. The access controls 204 are used to limit A data dictionary facility is included as an integral part of PHOC M204. The dictionary is a SAS data set built and maintained by PROC M204 which maps Model 204 field names to SAS variable names for a particular Model 204 file or subfile. Performance data is presented which compares the various modes in which PROC M204 can be used.",Sugi-83-111 Gimarc.pdf
"c > ( I ! j. I ! I t i i Intelligent Financial Plannine; Modela U.ine; PROe LP Intr04uet.lolll: FiIlLllCliJ. .a.all( .... t nq.1r •• pl.lollal.1 b ... d em toh. delllt.Uleg .. oou1<11""'I.101_ of tlle lay,.we.t.. ~i~~L ':.t:~'=~, O~O::~4~~' '~1""a. lillear prop' .... ln. ~l t.at. ,.U111. tJali ••• 4. 1ft t.1I11 repon \It lat.l'QCIac. tlI. WI!C'p""t IioIbUIIl ~!""!=!.~~t!1:.~::C ~ l!:~C=~:I' ~::~~: ~ l: ov .o:l r!:!r:-::r!:f.n:~Cltl Elaapll': COll.lder • UTa 'i'll1c1i ••• to decid. 11011 allCh to tllV.1t 111' borrow 11 1.h. CCla1q p.r. LIt. I "" .'"" lart.f. ... ' 1. ,HUOD. ot dollar. J "" ""V borr0'l1ll1 II a1lUau: ot dollaTII. ........ : 1. Aya11&1I1. iDtI.tuat. opport.ult1 •• CM .,lllOrb • 1 tl11110a at .,.t.. 2. Ill. lave.ta8Ilt. apport. •• U, .... r.tA •• 1.11; pr.""at. rlJ.a, or -, 0.10 per la""n.ed dollar. 3. lev debt. I. Ualtecl \0 40 pllc.at. or HII 1Il.VlIt""Ilt.. 4. the UTa hU • 800,000 1a C""b. S. *rllnl cof1Kl1'at.. 10U nt.. 1 •. 5. O. TI.. UT ...... decino ... oa au:1IIlzinl u., VlJ. •• 01 Uri (vUel!. lliciade. t.1II pr ..... t It.lv of ttl tu IlIt,ldII. w. R. GJertna, M. Cohea, and A. Eatoa 8M ladHIl"" 586 nl qUllttoa of t.tArllt 11: \/11.\ 1.,.11 of uv t ...... t ... t aad lion_till aulaln till val .. of \lie t'tTa' If till carreb.t '.1111 of tile UTa tl Y tle. tal tile ,.11111 of s: pet , tbt .. tstu V-O.ts:tO.SJ .Dd nt.tlf, till coaltntlltl illPOllId "" \III Uluapttolll _s:t.tu the ,.1111 01 the UTa. TIlt, OUI b. IIOln vtt.. PlDC 1J>. Till LtIleI.r Proll""uallll FOTa1l1.tloll tl: -4. t 1 + 0.5, SUbJlct. to till CDaltr.tlltll: .""\IIIpttoll t: 1.II\IIIpttoa 8: U8\111ptlOIl 4: <= 1 <= 0.4 s: <= J ... 8 GEOMETRIC REPRESENTATION OF PR,OBLEM : ~~j--"" i .3 LJ 1.11 L0~ j / f / / / (/) 0 4 9 J l I- C ~ .. ,-""'""' 0.8& (/) (L5 +-' Q) II) 0.4 II) <0: 0.3 () .. 00 / 0 4 0/.) / '/ I / / ! ! x~.8+y "" ~-- i y.::.4x I' / .. / / .I ! / / , / / / , ; / .. ( ,"" / / j , -' , 0.18 0.24 / 1)2 ! i ./ i I , , , , , , .' , , , , .' } , OPT1MAL , S?:EUTION,' .// / \/~/ , , , I , , , I j ! /",Sugi-83-112 Gjertsen Cohen Eaton.pdf
"I I ! f f t , t , GENERALIZED PROGRAM FOR STRATIFICATION & STRATA DETERIORATION ANALYSIS - GPSSD Bonnie Brown Jacobson, Northeast Utilities Service Company Most utilities use load research data collected from load research studies of various subgroups of their customer population. It is hoped that the results of these studies will yield accurate profiles of the demand patterns for these sub­ groups for use in ratemaking. forecasting and load management. This program is a generalized routine for the calculation of the required sample size needed to satisfy the confidence limits of 90% ± 10% and 95% ± 5% [or rive separate sampling designs all of which are currently utilized load re­ search designs. Each design is further explored through the calculation of the approximate de­ terioration of data for each stratum. Summary tables are also generated for quick reference. The sample sizes required [ur Lhe appropriate operation of each of the following sample designs are automatically calculated in GPSSD, based on the assumption that the population size is large. OVERALL SRS: This design requires a simple random sample to be drawn from the total population without regard to strata boundaries. This would yield data relating to the means that ure statisti­ cally reliable (for the chosen confidence limits) for the total popUlation. No estimate of reliability can be made for any individual strata before the sample is chosen. The formula used for the sample size is: Where: t is the Student'S t-value associated with the desired confidence interval. a is the standard deviation of the population. e is the percentage of the mean relating to the fiducial limits. SRS WITHIN STRATA: This design requires a separate simple random sample to be drawn from each of the pre-assigned stratum. The design would yield data relating to the mean that are statistically reliable (for the chosen confidence limits) for the individual strata as well as a more rigorous reliability for the total populatio",Sugi-83-113 Jacobson.pdf
"ach to the management of a simple interactive session involving novice computer users was to use a menu display format. The question that arose however was which of several techniques should one choose to facilitate the menu selection and subsequent program execution. INTRODUCTION"" This poster is concerned with some of the program choices available to a VM/CMS user and to share some of the experiences gained in an application at the Upjohn company. The basic program choices included the following: I. CMS/SAS Alone II. CMS EXECS and CMS/SAS III. SAS/FSP and eMS/SAS IV. ISPF, eMS EXECs and eMS/SAS Ie eMS/SAS Alone lJescription Program I illustrates the basic construction of a CMS/SAS program to control interactive execution of a program. An Upjohn written CLEAR command is used to initialize the screen prior to display of the menu and graphical displays. SAS FILE and PUT statements produce the menu and an INFILE statement defines input from the terminal. Input can include up to ten option numbers with an array being used to represent all input option numbers. A check of each element in the array first looks for a termination request and if it is not found then the terminal display is either turned on or off with a CP SPOOL command. The use of macros allows one to perform a sort of IF-THEN­ DO-PROC command by checking the option values and then creating a file of SAS commands based on those values. The MACRO PROCl invokes the GCHAR'l' and/or CHART procedure depending on the optio",Sugi-83-114 Lajiness.pdf
"of SAS data sets. Although the corporate computer operations at Sandoz backs up clinical data sets weekly, we, as system userS, realized that to provide for data integrity we needed to backup data sets daily. Commercial backup software is costly and so we decided to use SAS to create the backups. The automated backup facility implemented at Sandoz uses SAS to read the system catalog and generate the backup job stream. The UNIX operating system is used to automatically send the job to the IBM mainframe at a predefined time and to store its output in a prenamed file. 2. ENVIRONMENT Clinical Research systems at San­ doz, Inc. operate under the constraints of FDA regulations which require data security and integrity. The clinical data management system which is used at Sandoz requires the daily changing of large numbers of data sets and the fre­ quent addition of new data sets. At Sandoz, all clinical files are stored in SAS data sets. They are stored on disk as SAS data libraries organized by compound identifier and study number. Each data library is named by a structured name in the following format: RAD.CLINICAL.SAS.CCCCSSSS where eccc is the compound identifier and SSSS is the clinical study number. The number of data sets which are active at a time can exceed 800. The SAS data library backup pro­ cedure which is described below was developed because of the desire to auto­ mate the daily backup of data libraries so that the procedure does not require constant attention. In a",Sugi-83-115 Belasco Ives.pdf
"I ! I l r ANALYSIS OF TWO-PERIOD CROSSOVER TRIALS USING SAS Roqer D. Sa {ll L. M. Lorie PERHAPS ONE OF THE MOST USEFUL OF AL.L DESIGNS IN CUNICAL. TRIAL.S IS THE SIMPLE TWO-PERIOD CHANGE--OVER DESIGN_ THIS DESIGN IS WIDELY USED IN PHAMACEUTICAL TRIALS INVOLVING THE COMPARISON OF A DRUG TO PLACEBO_ EACH SUBJECT ACTS AS HIS OWN CONTROL. THUS REMOVING BIOLOGICAL VARIABILITY OR AMONG SUBJECTS VARIABILITY FROM ERROR ESTIMATES. A LINEAR MODEL IS WRITTEN CONTAINING DIRECT AND RESIDUAL TREATMENT, PERIOD, AND SUBJECT WITHIN SEQUENCE EFFECTS_ WHEN THE USUAL NORMALITY AND HOMOGENEITY ASSUMPTIONS ARE MET. THIS ANALYSIS HAS BEEN PRE-­ SENTED ACCORDING TO GRIZZLE (1965). KOCH (1972) DESCRIBED THE TWO--PERIOD CHANGE-OVER ANALYSIS WHEN THE USUAL. ASSUMPTIONS DO NOT SEEM PLAUSIBLE. WHICH IS OFTEN THE CASE WITH SMAL.L SAMPLE DRUG-PLACEBO CLINICAL TRIALS. THESE NONPARAMETRIC PROCEDURES EMPLOY REPEATED WILCOXON TESTS ON WITHIN·· SUBJECT LINEAR FUNCTIONS CORRESPONDING TO EFFECTS PRESENT IN THE MODEL. APPROPRIATE HYPOTHESES AND F STATISTICS ARE PRESENTED USING PROC GLM FOR TESTING (A) EQUAL RESIDUAL. EFFECTS, (B) TREATMENT EFFECTS IN THE PRESENCE OF RESIDUAL. EFFECTS, AND (C) TREATMENT EFFECTS IN THE ABSENCE OF RESIDUAL EFFECTS. THE NONPARAMETRIC COUNTERPART OF THESE TESTS IS ACCOMPLISHED USING PROC NPAR1WAY TO TEST (A) RESIDUAL EFFECTS. (B) DIRECT TREATMENT EFFECTS WHEN RESIDUAL. EFFECTS ARE ABSENT, (C) PERIOD EFFECTS WHEN RESIDUAL EFFECTS ARE ABSENT. AND (D) DIRECT EFFECTS WHEN RESIDUAL EFFECTS EXIST. FINALLY, IMAN'S SIGN RANK T-TEST FOR DIRECT EFFECTS WHEN RESIDUAL AND PERIOD EFFECTS ARE ABSENT IS DEMONSTRATED. Ai tch ison Gi tOIlU,H"" S)(a L land 608 opnONS L1=76, 1* ***""****1********************* * liRIZZLE PARAttETRIC APPROACH t • TO ANAllSIS OF IlIH'ERIOD • • CilAia-IIVER DESlGH • • .... tll .. l .. flllll .. n .. llIl1 .. lII lHPtlT SEQ SUBJECT I VI V2, CARPS; I CII 1.75 .55 I CI2 .3& 1.&5 I CI3 .35 .63 I CI4 .2& 1.55 I CIS .3& B.2& 2 e2i 7.21 .35 2 C22 7.1& 1.55 2 el3 .75 .25 2 C",Sugi-83-116 Aitchison Gitomer Skalland.pdf
"~. ,. PROC fo(;STRAT James M. Naessens, Kenneth P. Offord and Susanne L. Daood Mayo Cl inic Introduction In the design and analysis of a case­ control study, several methods are available to control the effects of additional factors on the exposure-disease relationship of interest. In the design stage, one can 1 imit outside effects by restricting the study to a subset of the population (e.g. women or ages 45-60), or one can use matching to control additional effects (e.g. men matched on age, marital status and neighborhood). In the analysis stage one can remove some confounding effects by the use of stratification or through mathematical modeling. For the val id analysis of a matched design, one must use a stratified technique that maintains the matching scheme. A stratified conditional 1 ikel ihood approach using a logistic model is one such technique which can incorporate both categorical and continuous covariates. This procedure is currently in development. When completed in mid-1983 it will be submitted to the SAS Institute as a supplemental procedure. PROC MCSTRAT The MCSTRAT procedure is the Mayo Clinic adaptation of the STRAT program described by Breslow and Day (1980) and Smith et a1. (1981). It estimates the relative risk (odds ratiO) of a dichotomous disease state associated with a risk factor ""adjusted"" for confounding variables (if any) in a matched case-control study. The program performs an iteratiVe conditional maximum likelihood fit using a logistic regression model. The procedure uses the maximal amount of data by allowing a variable number of cases (k i ) and a variable number of controls (m.) in each set. Alternatively, one can restrict analysis to complete matched sets by specifying the minimum number of cases and controls per set. Theoretical motivation as well as basic computing algorithms and several examples are provided by Breslow and Day (1980) and by Kle1nbaum et a1. (1982). MCSTRAT will provide information on the number of matched sets u",Sugi-83-117 Naessens Offord Daood.pdf
"ADVERSE REACTION INCIDENCE TABLES FOR CLINICAL TRIALS Donna R. Park and Stephen J. Ruberg Merrell Dow Pharmaceuticals In the drug development process, pharmaceutical companies need to provide summary information as to the number and percent of patients reporting adverse reactions in each clinical trial. Typically this is provided in an adverse reaction incidence table where the reported adverse reactions are coded, according to a dictionary, co form rhe rows of the tableBe Patients are grouped, most commonly by treatment group assignment, to form the columns of the table. For each column (group), the number and percent of patients reporting each coded adverse reaction are then displayed In the incidence table. A sample incidence table is found at the end of this report. (Figure 1). The data for clinical trials usually are collected on case report forms specifically designed for each study. In addition to patient identification there are questions concerning demographic characteristics, medical history, entry conditions, treatment information, efficacy variables, etc. Adverse reactions reported by the patient are recorded at each evaluation. At Merrell Dow Pharmaceuticals the ""old"" method for handling adverse reactions for each study Was to build a sequential data file which was rigidly defined. All st.udies were forced into the same format, and then a standard PL/l program was used to generate an adverse reaction incidence table for any study. The biggest drawbacks with the old system were: 1) The ""front-end- problem of forcing all studies into a rigidly defined structure. This time-consuming step involved hand-coding the data and was the rate limiting step in creating the computer data base for each Eltudy. 2} No flexibility with regard to definition of groups (columns) in the incidence table. 3) The need for supplemental data listings detailing the summary results found in the incidence table. 4) Isolation of the adverse reaction data frOm many other data of inter",Sugi-83-118 Park Ruberg.pdf
"In a multicenter trial, the centers are independent sources of information regarding the therapeutic activity of a drug. Hence, like the between-drug comparison, the within-drug compari­ son should also be evaluated after examining the homogeneity of centers first and then removing the center effects from the responses. This approach will give a more valid and powerful test for test­ ing the hypothesis of no drug effect than that based on pooled data after ignoring the centers. For each patient, let X and Y denote the measure­ ments at baseline and a follow-up visit, respec­ tively. The methods are developed for the follow­ ing three cases: (1) when the vector (X, Y) has a bivariate normal distribution, (2) when the vector (X, Y) has a bivariate continuous distribu­ tion, and (3) when X and Yare ordered categorical response variables. Some applications of this methodology are given and macros using PROC MATRIX are written to analyze the data. 1.",Sugi-83-119 Patel.pdf
"ich PROC NLIN may be used for quick and convenient ex­ ploratory function optimization. Although not as precise as exact codes and programs for non­ linear programming, many of these are less than user friendly. especially for casual model ex­ ploration. The proced~re is useful for overde­ tenmined systems of equations in particular. Some possible remedies for its theoretical shortcomings are mentioned. 1. Introduction Frequently the operations researcher neeqs a tentative solution-to an optim1zation problem. For example the author recently was studying the possibility of obtaining solutions to an overde­ termined nonlinear system of equations. While well tested, exact codes, such as the popular MINOS. could have been adapted to the problem. codes such as these often require careful coding of FORTRAN subroutines. Hence there is a seri~ ous question of the value of becoming involved in an exact solution while the research idea is still conjectural as it was in the above men .. tioned research. The procedure mentioned below was applied to an objective consisting of the total sum of squares of the reSiduals for the overdetenuined system of equations. Whil e the results of this approach have some error possi­ bilities, those may be largely overcome by re~ fining the grid search procedure when needed. 2. Adapting PROC NLIN Several codes and packages are available for least squares regression of nonlinear models of the form y = f(l'. • .!?) where vector l'. and scalar y form the da",Sugi-83-12 Troutt.pdf
"EFFECT SIZE AND POWER IN TWO FACTOR NONORTHOGONAL AKOVA: A MONTE CARLO INVESTIGATION Margaret J. Martin and William A. Powers The University of North Carolina at Greensboro 1. INTRODUCTION In the last decade considerable research has been done on the analysis of variance of unbalanced data (nonorthogonal ANOVA). In general, this research has focused on (1) the problems inherent in the lack of a unique analysis of unbalanced data, (2) the delineation of the differences in the methods of analysis, (3) the selection of a ""best"" method of analysis for a particular settIng, and (4) the comparison of the methods of analysis employed by the major statistical computer packages. Relatively little emphasis has been given to the power characteristics of the various methods of anal­ ysis or to the effect of the degree of non­ orthogonality on the power of the analysis. The present research will, through Monte Carlo methods, compare the power of the three differ­ ent methods of nonorthogonal ANOVA and examine the power of each method as a function of the degree of nonorthogonality of the design. Be­ cause of the preliminary nature of this research and the complexities of the problem, the present research will be limited to an investigation uf the power in the 2x2 (two factors, each at two levels) nonorthogonal ANOVA without interaction. Clearly, this limits the applicability of the research; however, it is hoped that the results obtained will provide direction for the more general problem of the effect of nonorthogon­ ality on the power of the ANOVA tests. 2. THREE METHODS OF ANALYSIS FOR NONORTHOGONAL ANOVA Consider the following 2x2 ANaVA layout Figur~ 1 ""11 ""12 nU n 12 ""21 ""22 n 21 n 22 where ]..lij and n ij i = 1,2 ~ j = 1,2 are, respectively the population mean and sample size for the cell ij. In such a layout, the hypotheses commonly tested are H , r H: c no rov main effect no column main effect no interaction between row and column effects 630 The difficulty with ANOVA fo",Sugi-83-120 Martin Powers.pdf
"~ MULTIVARIATE ""E1HODOLOGY FeR EXPLCRATOHY RlSEARca Chdrles F.. Rich, Ohio Unive~sity Illtr-oductiun Tbis paper describes a multivariate research m€thodology in .. hieh factor analysis is performed usinq PRCC FACTOR to create factor scores subsequently used as predictors in a stepwise diser iminant anal ysi s usinq PROC STEI?DISC This type of analysis is qreatly facilitated by SAS's cafahility to easily create and pass output data sets from one procedure to another. Tbe approach is illustrated .. ith a SAS proq:Lam us€<l in d study (Wltflle:L, ~! .2!~ ,198]) inve3tigating psychosocial constructs whict might mediate tetween environmental st:Lessors a nd one IS psychophysiological responSES to thEm .. In this study a factor: analysis redUCES a large set of variabl~s to a smaller set of factors which are then interpreted as thE psychosocial constructs.. It is hypothesized that one or !Dore of these con~trlJcts will significant.ly predict. or.e's ability level in coping with the stressors .. preparatory Analyses In an in itial run of SAS (not shown) three qOdls are accomplished.. First. a factor analysis is performed usir,q PBOC FACTOR. specifyinq Varinax rotation. Based on theSE results, rotated factors with eiqenvalues of at lEast 1.00 are kept, and f;)r those factors all variables loadinq at least .40 are retained. The purpose in using such cutoffs is to reduce chanCE va~iation in the factors. Althougb thE use of cutoffs is common, the cutoffs tnemselves may vary according to one's purposes.. secondly. these screened factors are interpreted as ccnstructs. Rummel (1970) is recommended as a general referen=e for factor analysis. The thirJ purpose of the initial proqram run is to identify the: :LElativEly good and poor capers in the samfle and classify them with a qroupinq variable which could be used later in the stepw is€ discI:iminallt ana.lysis. 'I'hc two qroups of subjects arE identified by usinq an extreme qroups approach. In this approach those ~hose anxiety and",Sugi-83-121 Rich.pdf
"The analysis of covariance in a univariate repeated measures context can be handled easily in PRoe GLM. The analysis can be of two basic forms. In one case, the covariate is essentially a between-subject measure, while the other possible situation involves obtaining several measurements on the covariate along with one or more of the within-subject factors. This paper will present a method in which PROe GLM can be used in a multi-step fashion to partition the sums of squares and perform the appropriate tests for all effects of interests in both types of designs.",Sugi-83-122 Roberts Laughlin.pdf
"ising from Latin-square designs has posed a problem for marry experimenters who rely on statistical programs to analyze their data.. Tht:! major reason seems to be due to the confounded VAriance components in­ volved in certain Latin-squares and a lack of an algorithm for dealing with such designs in the commonly used statistical packages. This paper will look at many of the frequently cited Latin­ square designs and also present a very general proce~~ for analyzing such data in PROC GLM. This method allows the analyst to partition the variability of all the effects in the design in­ cluding the variation due to any partially reflected interactions that may exist. Between-subject Designs One of the most appealing aspects of a Latin-square design is the ability to reduce a large, factorial experiment into a smaller number of cells. However, this decrease in the amount of experimental effort required is also coupled with an increase in the number of assumptions which must be made about the resulting data. Consider the following between-subject design which utilizes a Latin-square: C2 Cl C3 C3 C2 Cl Cl C3 C2 This design is one possible reduction of a 3x3x3 factorial design. We may think of factors A and B as being crossed, with factor C being a con­ founding variable. To Arriv~ at any information concerning the effects of these variables, we must first make some assumptions concerning factor C. Namely, we must assume that the effect of factor C is additive and thus, no interacti",Sugi-83-123 Roberts Laughlin.pdf
"In marketing research,AID(Automatic Inter­ active Detector) analysis developed by Survey Research Center of Michigan University is wide­ ly used to identify clusters of observations having similar attributes under interaction. We have developed an AID algorithm together with SAS interface (AID/SAS). Our AID/~ao ~tart~; PROC AID; MODEL y= X1 x2 X3; RUN; Y dependent variable X1,X2 : independent variables Written in FORTRAN IV with uptodate function, AID/SAS is compact and portabl~. Cucc~nlly it runs on an IBM compatible machine.Facom M160 in our institute.",Sugi-83-124 Kimura Shitomi Saeda.pdf
"Conventional methods of curve fitting, particu­ larly least squares, often have the undesirable property of destroying the a priori density of the predicted variable. That is, given a set of ordere~ pairs {(x:,y)} and ... an estimated function of x, f. the density of f(x) will in many cases di ffer markedly from the density of y. The method of curve fitting proposed in this paper is designed to force the density of f(x) to be nearly identical to that of y, in cases where the expectation of y given x ;s monotonic in x. An example of the application of this technique, using several SAS proc-edures, ;s provided. In developing a simulator of the Landsat data collection system as a part of the Inventory Technology Development project of the Agriculture and Resources Inventory Surveys Through Aerospace Remote Sensing program, the proportion of sky cover recorded by ground ob­ servers is modeled as a function of radiometric readings from National Oceanic and Atmospheric Administration polar-orbiting meteorological sate 11 ites.",Sugi-83-125 Smith.pdf
"E.tiaation of economic relationships subject to the theory typically requires imposition of both linear and nonlinear restraints. For ez­ ample. the behavior of a competitive profit­ m8%i_izinl producer can be represented by a profit function which is linear homogeneous and convex in product and input prices. The first derivatives with respect to prioes are the pro­ duct supply and input demand equations which are homoleneous of delree zero. Appro:zimatins the profit function by a second-order Taylor's e:z­ pansion in price ratios"" the parameters of the system of supply and demand equationl compriae the Hessian matrix of the normalized profit function. The parameters are symmetric by Youna's theorem, and the Helsian is positive definite. Homogeneity is maiutained by normal­ ization, symmetry can be impoled by a set of linear restrictions, but convexity requires nonlinear restrictions. To maintain convexity. the problem il converted to a penalty-aulmented unconstrained minimization problem. An alloritbm (written in PROC MATRII) based on the variable metric method with a golden-section line search has been desianed. Some gradients are analyti­ cally differentiated while nuaerioal appro:zima­ tion is used for otherl. This method is more efficient and gives a lower SSE than the alter­ native Cholesky factorization. It is applied in an analysis of agricultural supply response.",Sugi-83-126 Talpaz Shumway Alexander.pdf
"MULPOOLS: ANALYSIS OF PERSONNEL PRACTICES IN EMPLOYMENT DISCRIMINATION LAWSUITS Timothy Wyant and Jon Chalfant-Walker, Econometric Research, Inc. Underselection of minorities to fill job vacancies, Or overselection of minorities for layoff, is a common complaint in employment discr1mination l~wsuits. Where defendants advertise job vacancies individually, the res­ pondents to each advertisement form a distinct applicant pOOl. The consult­ ant must then as seSE tbe extent of under selection, if any, of minorities over these multiple applicant pools. Similarly, if layoffs occur in dif­ ferent jobs or different divisions, the extent (if any) (of overselection of minorities must be assessed ac­ counting for the minorities available in each ""rool"" of napplicants."" Despite the importance and frequent occurrence of this problem, consultants often mishandle it. Accepted methods for analyzing selec­ tions from multivle pools exist, but have been developed in fields far removed from the courtroom. Until recently, t.o c,ur knowledge, no com­ puter program has collected methods from diverse fielc1s for analyzing applicant selections and cast them in a form Buitable for use by the court­ room expert. The absence of such a program has doubtless contributed to the confusion of approaches advanced by different consultants. Econometric Research, Inc. (ERI) frequently provit'{Os €}<lert testimony in employment discrimination lawsuits. We use a SAS procedure, 14ULPOOLS, to analyze selections from multiple applicant pools in these lawsuits. MULPOOLS does collect aFpropriate methods for handling the applicant selection problem, and thereby gives the consultCl.nt irl employment dis­ crimination analysis a tool for addressing what may be the client If:. Trost r-ressir,g need. In addition, careful design of both input and output of HULPOOLS with empJ oyment oiscrin.ination laWBuits in mind alleviates other consultant burdens-­ those of provicU nq not only an ap­ propriate analysis, but also",Sugi-83-127 Wyant ChalfantWalker.pdf
"SAS MACROS FOR F-TEST POWER COMPUTATIONS IN BALANCED EXPERIMENTAL DESIGNS Andrew J. L. Cary, Syntex Research Introduction The SAS Supplemental Library contains distribution functions and inverse distribution functions for the non-central F-distribution which can be used in a SAS datastep to compute power for tests of hypotheses in analysis of variance. To demonstrate how this can be done a set of SAS MACROs has been constructed which compute power for main effect tests in balanced, fixed effects on9- and two-way classifications with and without repeated measures. Statistical Methods The statistical methodology to compute the noncentrality parameter for hypothesis tests in analysis of variance is well presented in a general linear model framework as a matrix expression of the design and hypothesis matrices by Searle 1 and are derived from the expected mean squares by Graybill'. The method presented here is straightforward, and consists of computing the critical value of the test statistic at a given alpha level under the null hypothesis computing the probability value 15 exceeded under a alternative. and then that this specified From the many possible alternative hypotheses which exist for a given test, it is necessary to select a useful alternative, recognizing that each has a different non-centrality parameter. One alternative hypothesis of interest is that producing minimum power, This is the alternative which produces the lowest power for a given test. An excellent explanation of this hypothesis can be found with the tables of Bowman and Kastenbaum 3 , With respect to the null hypotheses being discussed here, the minimum power alternative is obtained by specifying the difference between any two means (M) to be delta (measured in standard deviations) and setting the remaining means equal to the grand mean (GM). ie.; HO: M(i )=M(2)=M(3)=M(4)= ... =M(k)=GM; HA: M(I)=GM-DELTA!2 ; M(2)=GM+DELTA!2; M(3)=M(4)= ... =M(k)=GM; TABLE 1 DEGREES OF FREEDOM AND NON-CENTRALITY",Sugi-83-128 Cary.pdf
PROC AUTO REG was used as the technique to analyze the data from an experimental septic tank filter field system. The \\'ater level within the system was seasonally dependent and the error terms serially correlated. The predicted lagged variable was included among the regressors after an instrumental regression used the other independent variables and their lagged values as predictors. The results from the autoregression analysis will be used to indicate the expected frequency of system failures from climatic stress.,Sugi-83-129 Hirsch Rutledge.pdf
"While baseball fans are known for their penchant for statistics, the application of rational statistical methods to the results of baseball games is apparently a new phenomenon (James, 1982). The lack of sophisticated analyses is all the more suprising when it is considered that almost every aspect of the sport has been religiously tabulated for over 100 years. SAS was used to enter and analyze published data fo~ tile American and National baseball leagues. Various econometric, time series, and simple descriptive techniques were used to look at a number of questions of interest to baseball fans, and perhaps those interested in the developement and structure of competitive systems. The first topic considered is the relationship between offense and defense. Is it indeed true, as Casey Stengel has said, that ""good pitching beats good hitting and vice versa?"" Other topics looked at include hitting, fielding, speed, pitching, and the relationship between the two major leagues.",Sugi-83-13 Hofacker.pdf
"SAS Methods for Standard Error of Estimate in Maximum Likelihood Factor Analysis Douglas B. Clarkson, University of Missouri-St. Louis Susanna P. M. Clarkson, Washington University 1. Introduction The jackknife has been used by Pennel(1972), Clarkson(1979), and others to obtain standard errors for estimated rotated factor loadings in exploratory factor analysis. As an alternative to the jackknife, Jennrich and Clarkson(1980) have proposed a computationally feasible jackknife-like method. The purpose of this paper is to illustrate the use of these methods in SASe The jackknife will be implemented via the SAS NACRO language, while an experimental SAS procedure will implement the Jennrich and Clarkson method. The two methods will be com­ pared and the advantages of each will be des­ cribed. In the following the method given by Jennrich and Clarkson will be referred to as the method of differentials. 2. Exploratory Factor Analysis The standard exploratory factor analysis model assumes a linear relationship x=Af+ )J between a p_vextor x of observations, a p by k matrix A of factor loadings, a k vector f of COIDmon factors, and a p vector 11 of unique factors which are uncorrelated with f. This leads to the relationship L=/i.(l/i.'+'¥ between the covariance matrices r, ~, and ~ of x. f, and ~ respectively. After a !ample~of size n has been obtained, estimates A, IP, and ~ may be obtained from the sample covariance (or corre­ lation) matrix S (or Pl. providing that some additional restrictions are first placed upon t. These restrictions are required because without them the model is overparameterized so that ""unique ll estimates cannot be obtained. General­ ly, the estimates are first obtained using computationally convenient restrictions. The factor loadings obtained will be denoted by a matrix A and will be called the unrotated factor loadings •. After this initial estimation, the factor loadings are ""rotated ll via a new set of restrictions (often provided by a criterio",Sugi-83-130 Clarkson Clarkson.pdf
"PRoe PAIRED Jon L. Kosanke, Bradley J. Dain l , Kenneth P. Offord Mayo Clinic StatistlClans are often interested in performing paired analyses on numeric variables defined for each observation. An example is systolic blood pressure before and after a stimulus. The common SAS approach would be to create a difference variable and then execute FROe MEANS with the T and PRT options, or PROe UNIVARIATE. PRoe PAIRED was developed so that one needs onLy to name the variables to be paired. The procedure constructs the difference variable (internal to the procedure only) and gives descriptive statistics for it, 8S well as for each variable in the pair. The procedure then performs a normality test, a paired t-test, a sign test, and a signed rank test on the difference variable. The PRoe PAIRED Statement PROC PAIRED options; The following options may be used: DATA=data set name If omitted, the last data set created is used. NOMISS If used, an observation will be omitted if any of the variables in the COMPARE statement (see below) have missing values. If not used, observations will be omitted only for the calculations involving the pairs with missing values. Statements Used with PRoe PAIRED BY variable names; The BY statement may be used if the data set is sorted by the variables in the BY list. Each BY group begins printing on a new page. COMPARE pairs; The pairs of variables to be analyzed are listed in the COMPARE statement. Only one COMPARE statement may be used. Examples: COMPARE A*E C*D; Th.is calls for analyses on the differences A-B and C-D. COMPARE (A B) * (C D); This caLls for analyses on the differences A-C, A-D, B-C, and B-D. Whenever a list of variables appears on either side of an asterisk. it must be enclosed in parentheses, as in the second example above. Lists may be defined in the usual way: using spaces, dashes, or double dashes. A difference 685 variable is always defined as the variable to the left of the asterisk minus the variable to the right of the aste",Sugi-83-131 Kosanke Dain Offord.pdf
"PROC PAIRED: PARAMETRIC AND NONPARAMETRIC TESTS OF PAIRED OBSERVATIONS Joseph R. Fischer Jr. and William G. Jackson Jr.~ USAF School of Aerospace Medicine INTRODUCTION In most areas of research. situations arise in which a number of paired comparisons may be desired. In repeated measures designs where subJ ects are being observed at intervals over time, or in randomized complete block designs where several treatments are being studied, the investigator may be interested in certain speci­ fic comparisons of the t~e periods, or of the treatments. For various reasons, it is not always appropriate to use pooled variance esti­ mates from the analysis of variance, and a test such as Student's t then becomes a viable alter­ native. It is also not unusual for many vari­ ables to be under investigation, which increases the number of tests to be calculated. The need therefore exists for a procedure which is con­ venient to use, and which provides compact sum­ maries of results. PROC PAIRED is particularly suited tn the typeR of problems just mentioned. Further, it gives the user the choice of per­ forming parametric (Student's) and/or nonpara­ metric (Sign, Wilcoxon Signed Rank, Pratt's, Differentiated Sign) tests. GENERAL FEATURES The procedure has the standard SAS Features (eg, BY, FORMAT, LABEL, etc.) Other features of the program are: 1. CONTRASTS. There is no limit to the number of contrasts that may be requeRted. 2. MISSING DATA. Missing data observations are deleted on a per contrast basis, thus allowing maximum use of the data for each contrast. 3. ALTERNATIVE HYPOTHESIS. One or two-tailed testing may be requested. 4. TRANSFORMATIONS. The user may apply one of eight commonly USE'_d transformations to the ori­ ginal data prior to analysis. S. EXACT TESTS. For N ~ 30, the nonparametric tests are exact. 6. OUTPUT. For each numeric variable, the out­ put is printed in two parts: a. basic data and associated descriptive statistics (optional). b. test results, probabilities",Sugi-83-132 Fischer Jackson.pdf
"Standardization of rates is a frequently used descriptive technique in epidemiologic studies when certain factors, such as age, race, or sex, vary within the population of interest. A SAS program was written to compute age adjusted rates, by race and sex, for any categorical variable. PROC FREQ and PROC MATRIX were used to compute the rates, which were adjusted using the direct method, followed by a DATA step to format the output. The results are in crosstabular form, one cell for each combination of values of a classification variable and the categorical variable under study, including totals. The output includes, in each cell. the frequency, the crude rate, the adjusted rate, the adjusted stan­ dard deviation, and a 95% confidence interval for the adju~t~d rate. The data file being examined for illustrative purposes consists of alcohol consumption information as well as health and descriptive personal data collected on 56,443 Kaiser Health Plan mambers who voluntarily took a Multiphasic Health Check-up (MHC) from January, 1978 through March, 1980. 1.",Sugi-83-133 Armstrong.pdf
"tended. Mantel-Baenazel pr,ocedure •• :V be uaed \0 teat ror t.rntlDl!Ilt rrouP dirferencea wben data are obtained acrosa at-rata. Thia DOIIparuetdc procedure is appropriate for response level. that are either diehotOlllOulII, ordinal, or contiououa . Input t.o our SiS prerro •• If be a1 ther C!ODtincenC1f tables or the obaerved data tor each lIubJect. Scora uelped to each re&poa::I8e level uy be either interer, urrinal ranlt, •• rfillal. percentile, tlOllbina:\ rank, or uaer ape!lirled scorea. .&. output. in add! tion to the extended Mantel-Keensze1 atatistics, the prc:eram provides the user with IUlIIIIlr:v atatistics tor each stratum alODf with. ncmparametrlc teat ror treatment dirrerenC!N. For dichotomoua reaponaea the extended Mantel-Baenazel proc..:\ur. with either inte,er, •• r .. ine1 pereentile, or com­ bined rank ecariDl 11 equivalent to the standard Mantel­Baena .. el procedure. For a alICIe atrat1.Ul, using rllll1t or per­C!entile aC!orine. it i. equivalent to the WileoxOIl-Mann-Nhitne:v 'tea't, The extenc1ec1 Man'tel-Haena!llel procedure t.herefOre allOWS Jeneralhation ot standard nonparnetric teata to IIUlti­ stratUII aituatiOll&. INTRODUCTION We use the extended. Mantel-Raenszel pro­ ced~e, originally proposed by Mantel (1963), in clinical trials to test for treatment group differences when data are obtained across stra­ ta. We employ this procedure when response levels are either dichotomous, ordinal, or con­ tinuous. For multi-center clinical trials, each inv",Sugi-83-134 Fisher Wildman.pdf
"ract. A simple, user friendly method for estimating missing values with the correct error sum of squares is presented. Using the least squares method, the missing values are computed so that their residuals equal zero for the specified model. The necessary SAS code is provided, along with a TSO CLIST which prompts the user for all necessary information, then writes and submits the appropriate command file. 1. Introduction. A statistician commonly receives data from a designed experiment and finds missing values because of an accident or error during the course of the experiment. If repeated measures were collected on experimental units, then one is faced with the possibility of excluding from sophisticated analysis all of the data collected for an experimental unit if only a single observation is missing. Exclusion of valid data from analysis always places one in an uncomfortable position. An alternative to excluding data, if relatively few values are missing from an experiment, is to fill in missing value estimates, and then proceed with the analysis. Several ways of estimating missing values exist. One of the oldest is Yate's method of least squares missing valUe estimation (1933), extended by Rubin (1972) to any analysis of variance. This method naturally fits in with the least squares method of PROe GLM, and provides a convenient method of determining missing values for SAS users. 2. Description of Algorithm. Rubin presented a method whereby the vector of least squares mi",Sugi-83-135 Hamilton McCray Palmer.pdf
"Physiologic data from human subjects was collected for six dependent variables. There were four recording periods: baseline, pre-feed­ back vOluntary control, biofeedback training, and post-feedback vOluntary control. Each experi­ mental period was five minutes in duration and the physiologic data was printed at fifteen second intervals. SAS statements were used to transform the raw data and. then, SAS multivari­ ate analysis of variance with repeated measures design was used to determine an optional data recording time interval to be used in future re­ search on migraine headache pain.",Sugi-83-136 Hirsch Hirsch Rau.pdf
"OBTAINING PART AND BIPARTIAL CANONICAL CORRELATION ESTIMATES FROM PROC CANCORR; A BIOMEDICAL APPLICATION David A. Ludwig and Steven N. Blair University of South Carolina Introduction Large numbers of variables are often col­ lected and examined during observational investi­ gation. Statistical techniques that can uncover possible empirical relationships based on all the variables under study would be beneficial in de­ termining the dimensionality of large data sets. Recent advances in statistical computing have made available once near impossible multivariate manipulations. Theoretical models used to define empirical multivariate structure require addi­ tional consideration due to the added complexity associated with modelling the interdependence of more than two variables. Timm and Carlson (1976) have noted that the choice of a correct multi­ variate model should be based on pragmatic reasoning and not statistical outcome. Incorrect modelling may result in spurious statistical conclusions which do not honestly reflect the underlying structure of the data. Therefore, the ability to manipulate key parameters of a multivariate model ;s essential for correct interpretation. The multivariate general linear madel pro­ vides numerous avenues for simultaneously analysing large numbers of intercorrelated variables. Specifically, canonical correlation is becoming increasingly popular as a data analytic method. Two reasons for the increased interest in this technique may be (a) part, partial, and bipartial adjustment. which adjusts estimates based on comitant varition, and (b) redundancy analysis. which provides a more mean­ ingful interpretation of shared variance between two sets of variables than the overall squared canonical correlation. Although the most recent version of PROC CANCORR provides a statement to perform partial canonical correlation, no specifications or examples are given to aid the researcher in accomplishing part or bipartial analysiS. By utilizing a larg",Sugi-83-137 Ludwig Blair.pdf
"The analysis of linear models with non scalar covariance matrices has focused. primarily, on the estimation of the parameters of the covariance matrix known as 'variance components'. These 'mixed models' are usually developed by designat­ ing certain terms in the overparameterized model as random variables whose variances are the var­ iance components and thus are inherently PQ~itive. Confusion often arises when the analysis yields negative estimates for these parameters. In this paper, we discuss a class of mixed models and present a numerical and graphical dia­ gnostic procedure for assessing the model as well as detecting questionable data. A slight extension of the model allows us to entertain the possibility of negative variance components and the diagnostic procedure allows llS to evaluate that possibility. A numerical example is presented to illustrate the concepts. 1.",Sugi-83-138 Hocking.pdf
"TREATING MULTICOllINEARITY WITH SAS William J. Wilson, University of North Florida 1. Introduction A problem that must be considered in almost all multiple regression analyses is that of multicollinearity among the regressor var­ iables. Many authors even suggest than an examination for the existence of multicollin­ earity should be routinely performed as an initial step in regression analysis (cof. Mansfield and Helms. 1982). Simply determining the existence of multicollinearity often is not enough to obtain effective remedies.' The nature of the multicollinearity must often be closely examined. Further, explanation of multicollinearity either in a classroom setting or in a consult­ ing situation where the experiment~r has limit­ ed training in statistics, usually requires an indepth exploration of the relationship between regressor variables. This exploration is easily accomplished through various procedures in SAS, especially PROC MATRIX. This paper is primarily concerned with the exploration tech­ niques which can be used to detect the nature Of the multicollinearity using SAS. The gen­ eral objective is tutorial -and several examples are presented that the author has found effect­ ive in classroom situations. 2. ~tection of Multicollinearity The presence of multicollinearity is first felt (sometimes to the surprise of the investi­ gator) when examining the statistics concerning the regression coefficient estimates. Since the least square estimates have inflated var­ iances in the presence of multicollinearity, some unusual results can occur. For example, a signifi~ant overall regreSSion equation with a large R may have none of the individual coefficients significant. Many numerical examples exist in the literature, one is a four variable problem given by A. Hald on page 647 of his book Statistical Theory with Engineering Applications published by Wiley, New York in 1952 and used extensively in Draper and Smith (1981). This problem will be used throughout this p",Sugi-83-139 Wilson.pdf
"Office Productivity Evaluation with SAS Nachtm Finger, Ben Cllrion Uni versi ty of the Negev Nelson M. Fraiman, International Paper Company Sheldon Kutnick, Sheldon Kutnick Associates, Inc. MJrray Mohl, Morgan Trueman Associates, Inc. Introduction Before undertaking an evaluation of office productivity, it might be worthwhile to define what we mean by productivity, whether it is de­ sirable and how it is traditionally measured. We will then define the problem at hand for our office productivity evaluation system and how we propose to measure it in the context of a Word Processing Genter. Defining Productivity One definition of productivity describes the concept in terms of units of factor inputs and units of product or service outputs. Solo­ mon Fabricant refers to productivity as a ""com­ parison between the quantity of goods and ser­ vices produced and the quantity of resources employed in turning out these goods and ser­ vices."" In this regard, two concepts of pro­ ductivity are generally accepted: (1) output per labor-hour, and (2) output per weighted combination of different input factors used. The first, output per labor-hour, also called labor productivity, is the simplest to measure and the most widely used in comparing produc­ tivity levels and rates of growth between time periods and between national economies. The second concept is more comprehensive, and is called total factor productivity, or TFP. IS Productivity Desirable? When productivity is defined within this framework, the importance of produtivity growth is explained in many different ways. John Kendrick states that a rise in productivity re­ sults in conservation in the use of scarce re­ sources per unit of output. That is to say, to produce the same amount of output, we need to use a smaller aJoount of scarce resources. Pro­ ductivity growth has also been related to a higher standard of living, since more output is produced per capita, and it has been correlated to inflation control. Besides pro",Sugi-83-14 Finger Fraiman Kutnick Mohl.pdf
"which pieces together polyno­ mial regressions of different orders. These polynomial regression segments are connected at join pOints or so-called spline knots where the number and location of these knots are estimated by the program. I. Introducti on Suits et al (1978) and Smith (1979) have presented clear and quite useful approaches to estimating spline functions with known knot locations. Their work was at least in part based upon the development of this method by such authors as Fuller (1969), Poirier (1973, 1975, 1976), and Buse and Lim (1977). In his dissertation and subsequent journal article Robison (1964) discusses estimating the points of intersection of two polynomial regres­ sions. He outlines maximum likelihood methods for estimating the regreSSion coefficients and the location of points of intersection of the two regression equations. Hudson (1966) provides further insights into this problem. He examines four types of join points for joining two polynomial regres­ sions depending primarily upon whether each join point is at an abscissa data pOint or between two-such points, and whether the regressions have equal or unequal slopes at the join points. Hudson suggests that in some cases a constrained least squares regression search routine could be used to estimate the location of the join points. Gallant and Fuller (1973) make an important contribution in dealing with some of the issues raised by Hudson. Using the continuity and differentiability conditions they r",Sugi-83-140 Marsh.pdf
"ROBUST REGRESSION AND PROC JACKREGR Gerry Hobbs, West Virginia University Daniel M. Chilko! West Virginia University INTRODUCTION One the most common of all statistical techniques and certainly the most common of the predictive techniques is linear regression. The least squares regression coefficients are computed in many SAS procedures. Some of them are the procedures named NLIN, REG, RSQUARE, RSREG, STEPWISE, and GLM. The estimates are also contained in Some of the SAS-ETS software. It has long been recognized that the estimation of regression coefficients by the method of least squares can lead to results which are not altogether satisfactory. In simple (one independent variable) linear regression situations the problems generally arise when one or more outliers exist in the data set. The nature of least squares calculations are such that extraordinary observations exert an undue influence on values of the estimates. In multiple linear regression problems outliers are also a problem and of course it is harder to identify outliers when several independent variables are present than it is when there is only one. In addition, multiple regression estimates are often unstable even in the absence of outliers due to a condition called collinearity. The crux of the problem lies in the approximate linear dependence between certain sets of independent variables. In this situation relatively small perturbations in the data can cause very large changes in the values of one or more of the estimated coefficients. It is clear then that OLS regression is not robust. One way to ameliorate the problem is to study the individual cases (observations) so that influential observations can be identified and their effects observed. Cook and Weisberg have studied this approach extensively. Given the aforementioned problems it is not suprising that a good deal of attention has been given to alternative methods of performing regression analyses. Some of those involve definitions of ""best""",Sugi-83-141 Hobbs Chilko.pdf
"~: ANALYSIS OF VARIANCE AND SUBSET SELECTION Paul N. Somerville. University of Central Florida 1. INTRODUCTION In analysing data from several treatments, the usual first step is to test the null hypo­ thesis that the treatment means are all equal. If the null hypothesis is not rejected. then there are no further real problems. If the null hypothesis is rejected, then many legitimate questions arise. Is treatment A really better than treatment B? Is there a difference in means between treatments B, C and D, and so forth. It is customary to use multiple comparison proce­ dures such as Tukey's W. or Duncan's New Multiple Range to determine which population means differ. There are many cases in which we are inter­ ested in determining which treatment is best (say that one which has the largest (or smallest) population mean. In those cases, the above pro­ cedures are inappropriate. or at best inefficient. If one treatment, through its sample mean, stands out as best, then there is no real problem. If no treatment is ""obviously"" the best, then an experimenter may be willing to settle for a sub­ set of the original treatments, particularly if he can be assured that the subset contains the best treatment with probability equal to some pre-specified value of P*. Such a procedure was proposed by Gupta (1965) for the case where there are k populations (treatments) with a common known variance 0 2 , and n, the sample size is the same for each population. 2. GUPTA'S SUBSET SELECTION PROCEDURE Based on a random sample size of n observa­ tions from each of k normal populations with a common known variance a 2 , the subset consists of all populations whose sample means are between the value of the largest sample mean and da/n~ less than the largest sample mean. The constant d is a function of k and P*. Values of dare given in Exhibit 1 and are abstracted from Table A.l of Gibbons, Olkin and Sobel (1977). p* k .90 .95 .99 2 1.812 2.326 3.290 3 Z.230 2.710 3.617 4 2.452 2.916 3.797 5",Sugi-83-142 Somerville.pdf
"UNIVARIATE AND MULTIVARIATE REPEATED MEASURES ANALYSIS THROUGH PROC's REG, GLM AND MATRIXl Robert S. Barcikowski & Randall R. Robey Ohio Introduction: Mode of Analysis A design in which the same subjects are observed under all k levels of one or more treatments is termed repeated measures (see Winer, 1971, Chapters 4 and 6). In this design the repeated measures or treatments are frequently called 'trials' or 'occasions.' There are two main reasons for using a repeated measures design: 1) data naturally e~ists in this form, i.e. we frequently take more tha·n one measurement wi th the same or a commensurate measure on the same subject, at different points in time, and 2) it allows us to use the subject as his own control, and therefore reduce that part of error variation which is due to subject heterogeneity. The same repeated measures data may be analyzed using either a univariate or multivariate approach. The choice of method is dependent on the nature of the data, the research questions, and/or the statistical assumptions involved. Here, given single and multiple groups, we briefly discuss each method or mode of analysis and suggest appropriate SAS procedures. Univariate Mode Given a single group of subjects, the univariate analysis may be easily understood as a two-way, subjects by occasions, mixed model design. In this two-way design the subjects are consider~d as a random factor and the repeated measures are considered a fixed factor. Here there is only one observation per cell, and so the subjects by measures interaction must serve as the error term. If two or more groups of subjects are present in the design, then the data are treated as a split-plot design with subjects (considered random) nested within groups (cons ide red fi xed) and both groups and subject·s crossed wi th the repeated measures (considered fi~ed). Here, the group effect is tested using the variation among subjects as the error, and the group by measures interaction and the repeated measures",Sugi-83-143 Barcikowski Robey.pdf
"ional vieW]oint of an extension of analysis of variance and as a special form of linear mouel. SAS GLM output is illUBtrated for the analysis of covariance of completely randomized designs, randomized com­ plete blocks and latin squares, including both single elope and intra-class slope models. 1. Introduction Analysis of c_ovariance might well be one of the most misunderstood and inadequately taught of all applied statistical methods. Many methods books deal with it not at all (e.g., Guttman et al., 1982), or but sparingly (e.g"" Br~TIlee,- 1965), and those that give it substantive treat­ ment such as Federer (1955), Snedecor and Cochran (1980), Steel and Torrie (1980) and Winer (1971), concentrate on well desig~ed and well executed experiments that produce what is nowadays called balanced data, namely those which have equal numbers of obseryations in the subclasses. Moreover, these texts are mostly confined to the case of a covariate being given the same coefficient (slope parameter) for all iata points, one exception to this being the intra-class regress:'on model f'or the completely randomized design. The application of standard procedures :'n linear model theory to analysis of covariance models does, however, greatly broaden the variety of' such models that can be considered, and it also contributes to our understanding o~ them. Furthermore, today's computing power makes light of' the resulting arithmetic. (Under­ standing somethir.g that has been computed is much more of",Sugi-83-144 Searle.pdf
"• , ~ t , , t 1. f. power Comparison of the Weighted Squares of Means Method (Type III) and the Method of Fitting Constants (Type II) in Unbalanced ANOVA. by Ramon C. Littell and Richard O. Lynch university of Florida 1. Introduction. This paper deals with the comparison of the so-called Types II and III sums of squares (SS's) that are computed by the GLM procedure in SAS. We specifically address the two-way classification with factors A and B, both fixed, with a levels of A and b levels of B. It is assumed that we have n ij observation Y ijk , k~l, .•. ,n .. > 0, from the population correspond 1J ing to levels i of A and j of B, i=l, ••• ,a and j=l, ... ,b. Let U ij denote the mean of the ij population. We assume V(Yijk) = 0 2 , independent of i and j, and that all Yijk are mutually inde­ pendent and normally distributed. We may then write Y ijk = U ij + e ijk , where the e ijk are independent and normally diseributed with variance 0 2 • Defining ~ = U B. J. 1-1. j - 1-1 •• , and Y ij we have where 01 '"" f\ """" y. = Y .= 0, i=l, ••• ,a, j==l •••• ,b, L .J k=l, ••• ,n .. 1J The parameters ~i' a j , and Y ij measures A main effect, B main effect, and A*B interaction, respectively. In general terms, we are concerned with testing whether there is a main effect of factor A. Specifically, we wish to test ~: a l = aa= 0, or equivalently ~: ~l. u Note a. that we are considering a main effect test in the possible presence of interaction. In many applications this may be irrelevant; it may be more meaningful to analyze simple effects. There are, however, situations in which main effects are important even with interaction, e.g., if b is too large to feasibly separate all simple effects, if practical considerations require a single overall judgement, or if inter action is small relative to main effects. Several papers have addressed the topic of hypothesis testing in unbalanced data, notably Yates (1934) in the early years. Textbook dis cuss ions are offered by Bancroft (1968)",Sugi-83-145 Littell Lynch.pdf
"ON THE VIABILITY OF SOME ANOVA-BASED HIXED HODEL ESTIMATES W. G. Warren and K. L. Koonce Department of Experimental Statistics Louisiana State University, Baton Rouge, LA 70803 INTRODUCTION ~~~~-- Becaus~ so much has been written concerning estimation in unbalanced mixed linear models, it is not without trepridation that we embark on this paper. Nevertheless many llsers, and potential users, still find the situation confusing; they are confronted with various techniques that, when applied to the same data sets, rarely yield the same results. We believe that there is a need to define a strategy. that is to set up criteria, for which values caD be readily calculated, and which, if satisfied will more or less guarantee that estimates obtained via a specific and simple estimation procedure will be adequate for practical purposes, and, if not satisfied, will point towards the more complex procedure that is most suited to the circumstances. We do not pretend to have attained this objective; indeed) this is perhaps no more than a few tottering steps along a chosen path. We also restrict ourselves, here, to the estimation of the variance components. Although estimation of the variance components is rarely an end in itself, it is a vital preliminary to determining the precision of estimates of the fixed effects, to testing hypotheses and to the determination of the best linear unbiased predictors (BLUP) of linear combinations of fixed and random effects. BASIC CONCEPTS Historically estimation in fully random and mixed models appears to have its roots in fixed­ effects linear model analysis, and it is here also that we shall begin. In the classical ""treatment-block"" situation, if for the time being we omit the possibility of interaction, we write Y ijk = g T ti + b j + e ijk where the e,. are considered independent random vari~~~es with mean zero and variance cr2 • In the mixed model, the block effects, b., a~. also considered independent random variables with mean zero anLi",Sugi-83-146 Warren Koonce.pdf
"TRACT Consider an experiment where a nonlinear continuous function has been fitted to the data frcm several treatments or populations where the function depends upon a random variable-with un­ known mean and unknown covariance matrix. A two-step procedure. based on asymptotic theory, is developed to obtain estimates of the elements of the covariance matrix. The procedure is then applie& to a nonlinear one-way classification mocel and an example is presented. 1. INTRODUCTION To describe various economic, demographic. or physi~ctric relationships where the coeffi­ cients of the model are affected by unobserved variables. the following linear model is fre­ quently used, z = ~~ + f where E(~) = ~o' Q. and V(~) = ~. (1.1) If the columns of X are measured independent variables, model (1.1) is a random coefficient model. If. instead, ~ relates to an experimen­ tal design such as a one-way or nested classifi­ cation, model (1.1) is a variance component ~del. For both of these cases. there are well­ known methods of estimating ~o and ~ in the linear case. However. there are many situations where the relationship between the observed ran­ dom variable, y, and e is not linear but is better described by s~e nonlinear function. This paper deals with the problem of estimating e and V for the nonlinear model -0 I = f(~. ~) + f where E(~) = ~o. E(c) = Q. and V(~) = Y (1.2) considered as either a random coefficient or vari~~ce component model. As an economic example. consider a Cobb­ Douglas",Sugi-83-147 Johnson Milliken.pdf
Perlottlc phemoueua «re studied toy scientists in naoy fields* Analysis ot coaplez cycles often Involves a representation by Fourier series and tests ot slanlllcane* o± e&ch tern by means ol analysis of variance. The analysis of variance table provides a useful summary of the regreaalon results and helps the data analyst to select an appropriate aodel by deternlninj how Many terms should be included and whether a given model is a. good fit to the data* The SPECTRA procedure computes Fourier coefficients but does not provide an ANOVA table. This paper describes a set of SAS macros for ANOVA on results from the SPECTRA procedure and denonstrates Its use.,Sugi-83-148 Hilfiger.pdf
"a popular approach for developing or improving product formulations. A mixt~re experiment is used in applications where the response is a function of the proportions of the q components and not the total of the mixture. Mathematically this results in a constraint that each proportion, X., must lie between zero and one and that the sUm of the proportions must equal one. The most widely used model to describe the response from a mixture experiment is the Scheffe canonical polynomial. This model does not contain an intercept term. Also, hypothesis testing cannot be done by simple t-tests. An F-ratio test must be used to test if all main effects equal the average response or if all quadratic terms equal zero. Because of the above requirements, standard regression programs cannot provide the correct coefficients and the correct statistics in a single run. This paper outlines how PRO_C REG can be used to determine coefficients, provide correct statistics and run appropriate hypothesis tests in a single execution of the program. The use of PROe REG for model reduction is also outlined. Introduction A mixture experiment with q components is characterized by the restriction Xl + X2 + ••• + Xq o < X. < 1 , 1 (1) In the case of a quadratic response, the model has the following form: E(y) = ~o + P l ~. Z,. i=1 1 (2) where each Z. is a linear or quadratic function of the q components. By applying the rcstri~tion in (1) and combining like terms, Scheffe (1958) proposed the following as a",Sugi-83-149 Showers.pdf
"SAstETS What Isn't and What Could Be Robert P. Parks Washington University Let me say at the outset that three caveats must be made about this paper. First, I am not an empirical economist (much less an empirical macro economist) in most senses of the tenn because I do not publish empirical work. Hence most of what I say here comes from consulting with students and faculty. or from my avocation of fooling around with economic models and computers. Second, I am described as a KNEE JERK SAS FREAK -- TRANSLATED, I only program in SAS (on mainframes, anyway), and if a problem is not solvable in SAS, then it probably does not deserve to be solved. I would like to maintain that description, and so what I say here is an attempt to ask SAS to let me remain a knee jerk SAS freak. The third caveat is that Phil Miller suggested that T write this paper, and I might not have without his asking-although I think he wanted ""what could be"" and NOT ""what isn't"". But we users of SAS must complain sometime in order to improve the product. For both parts of this paper, I must say that SAS's motto is that SAS SAVRS TIME. If it does for would be COBOL programer's doing data management, then it also should for the econometrician who would use PEC, TSP, ESP, TROLL, SHAZAM or some other package. SAS does save time in some places but does not in others. What I would hope to accomplish here is to describe some of my troubles, some of my desires, and to get the users to demand more from SAS. Now for this first part of the paper- What Isn't- I contend that the users of ETS deserve better than what they have. I view the problem as a lack of programming time, and the type of programmer. The ETS package probably generates $500,000 revenue or more to SAS but only Dave DeLong and John SaIl program on most of the procedures. and then only a part of their time. Neither is an empirical researcher, and this biases how the programs are written and what 'bells and whistles' are given to the user_ I think w",Sugi-83-15 Parks.pdf
"i. OVERVIEW OF CATEGORICAL DATA ANALYSIS METHODS Gary G. Koch. Ingrid A. Amara and Susan Atkinson, University of North Carol ina, Chapel Hill William M. Stanish, SAS Institute 1. Introduction This paper is concerned with describing currently available methodology for the analysis of categorical data and related computing pro­ cedures. For this purpose, attention is given to 1. Randomlzation methods for testi ng hypotheses under minimal assumptions; 2. Weighted least squares methods for investigating the variation among proportions, functions of proportions, or measures of association; 3. Maximum likelihood methods for fitting log-linear and logistic regression model s. The nature and use of these methods are con~ trasted with respect to objectives of analysis, underlying assumptions, and data structure. Several examples are used to give a specific foundation to such discussion. 2. Methodology Statistical analysis can be viewed generally as being directed at one of three types of i n­ vesti9ations from either (or both) of two per­ spectives. The three types of investigations are A. Sample surveys with probability random selection (e.g.~ national health surveys; See Section 3.4); B. Experiments with probability random allocation (e.g., medical clinical trials; see Sections 3.2 and 3.5); C. Observational/historical studies of samples obtained by convenience or provided by nature (e.g., administrative data bases like motor vehicle accident records; prospective medical studies without randomization; see Section 3.3). The two perspectives are i. Design based inference to the local population direct1y under study through the sampling and measurement procedures by which data are obt'ained; ii. Model based inference to a conceptual target population which data are assumed to represent through a postu­ lated probability structure. Relative to this classification, randomization methods are often used to obtain design based inferences for experiments and observational studies,",Sugi-83-150 Koch Amara Atkinson Stanish.pdf
"The purpose of this paper ;s to describe a useful and readily implemented macro in PROC MATRIX for fitting log-linear models to small arrays of counts by maximum likelihood. Under­ lying distributions can be either Poisson or multinomial. Model parameter estimates are produced by applying the Newton-Raphson itera­ tive solution to a set of initial estimates based on weighted least squares. Goodness-of­ fit statistics are calculated, and a capacity exists for testing hypotheses concerning the model parameters. Examples are provided to illustrate a broad range of applications. 1.",Sugi-83-151 Stokes Koch.pdf
"A common problem in the analysis of censored failure-time data is the comparison of several treatment groups. Typically, covariables which are presumably related to the failure-time response must be accounted for in the desired treatment conparison. For the proportional hazards regression model, tests may be constructed from an appropriately specified partial likelihood, and computations may be performed using routines such as PHGLM. In certain situations only the covariate ranks are known, or the ranks are more appropriate than the actual covariate values for analysis. In these cases a modified rank analysis of covariance may be used to test the desired hypothesis. The requisite computations are also performed relatively easily using SAS. This rank covariance procedUre and the SAS computations are described in this paper; additionally, the SAS program for a complete example is included as an appendix.",Sugi-83-152 Woolson Lachenbruch Amini.pdf
"t f: I t l t r t , ~ The SAS MACROS for Nonparametric Analysis of Repeated Measures Designs P. K. Tandon and M. L. Moeschberger The Ohio State University INTRODUCTION Quite often we are confronted with data, arising from a repeated measures design, which does not necessarily satisfy the usual assumptions of the analysis of variance; namely, those of variance-covariance homo­ geneity and normality. Sometimes these situations can be handled by transforming the data with log, arc-sin, or square root transformations. However, these remedial steps do not always give one a satisfactory analysis. The main objective of this paper is to present and apply the SAS macros for a non parametric approach to a repeated measures design which follows a slight modification and simplification of the approaches given by Koch (1970) and Koch and Sen (1968). Three examples of re­ peated measures designs are presented to illustrate the use of the SAS macros and to present the results of the nonparametric tests along with those of the usual re­ peated measures analysis of variance. Winer (1971) defines a repeated measures design as an experiment where the same experimental unit is observed under more than one treatment condition or time point. Let us assume we have a two-factor experiment in which there are repeated measures on factor B. The data at level a i (i=l, •• -•• p) of factor A may be represented as follows. Subjects b l b 2 •••. b q I X ill X i2l ·• ,X iql .~~- 2 X il2 XiZZ "" 'X iq2 a 1 N Xiln K i2n X. 1qn 808 Here q repeated measur~ments X·lk,· .. ,X. k (i=l, ••. ,p; k=l, .... n) aie obtain~3 frOID each subjecL corI:""ecpond­ ing to q successive time point~ or q distinct conditions. One of the assump­ tions is that the vector (Xilk"""",Xiqk) has a multivariate normal distribution with /Dean (]..I1'"" ']1q) and variancecovariance matrix L. The response vec­ tors corresponding to differe_nt subjE'r_ts are independent. From these data onc may obtain the estimated q x q variance-covarian",Sugi-83-153 Tandon Moeschberger.pdf
"RANDOMIZATION TESTS Robert M. Hamer Medical College of V;rginia~ Virginia Commonwealth University In order to use the usual parametric statis­ tics (the kind that most of us were taught first, and the kind that most of us use most of the time), two related sets of assumptions regarding the data must be satisfied. First, the data must meet the measurement characteristics assump­ tions (measurement level and type) (type means continuous vs.discrete). Most common statistical techniques require that the data be at least in­ terval level and be continuous. Second, the data must satisfy the distributional assumptions of the statistical technique. Most common, usual, parametric statistical techniques require that the data be normally distributed or amenable to a transformation which will make them normally distributed. (Many other statistical techniques have other assumptions. specific to the techni­ ques themselves. which I will not discuss here.) When these conditions are not satisfied, a data analyst has three choices: (l)perform the test anyway, (2) transform the data, and (3) find another test. If the data analyst chooses the first alter­ native, he or she must be satisfied that the statistical technique is robust to such viola­ tions. that is, that the technique performs ""reasonably well ' ! when the assumptions are viola­ ted in the manner specified. If the data analyst chooses the second technique, he or she must be satisfied that the transformed data are tracta­ ble for analysis. If the data analyst chooses the third alternative, he or she often then has a variety of nonparametric tests from which to choose. If the measurement characteristics are not met, a usual approach is to transform the data to ranks, and use a rank-order statistic. Many common ""nonparametric"" statistics, are rank order statistics (e.g., Wilcoxon tests, Spearman and the various Kendall correlations, Mann-Whitney ""U"" test, rank-order ANOVA, etc.). When we make the rank order transformation we",Sugi-83-154 Hamer.pdf
"~. , A MULTI-EVALUATIVE APPROACH TO THE ANAL YSIS OF CLINICAL LABORATORY DATA William A. 1. Archambault Jr. and James J. Tiede Bristol-Myers Coo, Pharmaceutical Research and Development Division INTRODUCTION Clinical trials ore scientific experiments carried out in human subjects to test new drugs and treatment regimens. Phase II and Phase III cI inical trials are usually designed to establish efficacy and monitor the safety of a new drug or treatment regimen. A major part of the effort to monitor the well-being of the patient consists of the collection of clinical laboratory data. In short term trials for the treatment of acute disease or discomfort, it is not uncommon that clinical laboratory data be collected only twice, once before therapy and once after therapy. Long term trials for treating chronic disease are characterized by multiple dose treatment regimens intended to alleviate the signs and symptoms of disease, induce response, evaluate the duration of response, extend survival time, or extend the disease free interval. Such studies will be months in length, with laboratory data collected prior to the beginning of therapy, at one or more times during the course of therapy, and at least once following the conclusion of therapy. The fact that the laboratory data may be collected at irregular intervals in such trials complicates the evaluation of these data. This nonalignment of clinical laboratory data collection times, coupled with the fact that many of the parameters do not exhibit a normal distribution, indicate that the ""usual"" types of analyses, such as repeated measures analYSiS, may be inappropriate. This paper deals with on alternative approach to the evaluation of clinical laboratory data accumulated from clinical trials. This approach is currently in use at Bristol-Myers Pharmaceutical Research and Development and is termed a multi­ evaluative approach since the data are analyzed by more than one method. These methods will be il­ lustrated using da",Sugi-83-155 Archambault Tiede.pdf
"CONDITIONAL LOGIT ANALYSIS FOR CASE CONTROL OR EMPLOYMENT DISCRIMINATION STUDIES Timothy Wyant, Econometric Research, Inc. INTRODUCTION Econometric Research, Inc. (ERI) uses a SAS procedure, MULQUALS, in employment discrimination lawsuits to study the filling of job vacancies. Recent court decisions in employment discrimination lawsuits have made the presentation of a thorough analysis of the filling of job vacancies critical to a competent expert witness's testi­ mony, but until now no generally ap­ propriate statistical or computing methods for this problem have been sugges ted. The methods sU9gested here, and used by MULQUALS, draw on elements of proportional hazards analysis. In particular, a special case of the conditional logit models used in epidemiological case-control studies is extended to employment discrimination analysis. The Problem Much analysis presented in em­ ployment discrimination lawsuits is ""static. D The percent of blacks (women, Hispanics, etc.) in an insti­ tution's labor force at a particular date may be compared to some relevant percentage in the labor force at large. Alternatively, the salaries or positions of an institution's labor force at a particular time may be re­ lated through regression analysis to employee characteristics such as race, sex, seniority, education, and so on. Recent court decisions in law­ suits brought under Title VII of the Civil Rights Act of 1964 have empha­ sized not how an institution looks at a particular date, but how it came to look that way. Current interpretations of the Act emphasize that there is a statute of limitations covering an in­ stitution's behavior. In most cases, an institution is legally liable only for actions taken during a time period defined by the dates of complaints about those actions. If these actions were administered fairly with respect to minorities, it is usually consid­ ered irrelevant what the firm's labor force at a date looked like compared to some other theoretical notion of",Sugi-83-156 Wyant.pdf
"BSTRACT This paper describes an estimation and sam­ pling.errors package for use with survey data consisting of two SAS procedures (NASSTIM and NASSVAR) and a SAS preprocessor. Survey esti­ mates and their associated sampling error sta­ tistics are computed for user~specified charac­ teristics using balanced repeated half-sample replications (BRR) of the full sample. The SAS preprocessor prepares the input survey data file for use by PROCS NASSTIM and NASSVAR. The preprocessor defines the half­ sample replicates to which an observation be­ longs and optionally incorporates user-specified ratio adjustments into ""weight"" factors which are permanently affixed to each survey obser­ vation. The procedures NASSTIM and NASSVAR perform the actual estimation and sampling error compu­ tations upon the survey data file. Both PROCS allow the user to specify arithmetic expressions to create ""computed estimates"" for which the full complement o[ sampling error statistics are produced. PROC NASSTIM computes estimates and missing value statistics for specified characteristics while NASSVAR computes sampling errors and asso­ ciated statistics in addition to the estimate. INTRODlJCTTON A knowledgeable statistician can use this package as an effective tool. The user must be familiar with the sample design and the methods of ~urnputing sampling errors; specifically, the user must determine: (a) the appropriate methods of defining half samples that, except for the sample size, simulate the origina",Sugi-83-157 Binzer Morganstein.pdf
"Modern sampling techniqup.s frequently involve complex strategies that are far removed from simple random sampling. Recent ievelopments in variance estimation take account of these complexities, but there is little in the way of generally available statistical software implementing Lhese methods. This paper ~hows how to implement the three phases of the balanced repeated replication (BRR) method in SAS. To be discussed are: 1) Generation of the BRR codes through the MATRIX procedure, 2) Bui~ding the unit-within-stratum configuration and attaching the codes, ani ) Variance estimation and hypothesis testing.",Sugi-83-158 Spitznagel.pdf
"VARIANCF: ffi'1'IMATTON l'I1OM MULTT_'lTAGE SAMPLE SlJR1IE'{ DATA: THE JACKKNIFE REPEATED REPLICATE APPROACH James Rochon and William D. Kalsbeek University of North CP~olina 1 • INTRODUCTlrn Practi tioners have generally been .'iwm""e of th~ need to provide measures of precision to qu~lify estimates :forthcoming from multi-·'~t'1ge sHIllple survey data. 'oJl'dle the methodology h8S been known for some time, it is only within the 11St ten years that 8oftW':ll""e has become av'll lable to perform these comput~tione. The expressions 'for dp.scriptive m~sures. su~h as me~s, distribu­ tions, and totrlis are relatively s~r_<:>i$tf0rW3l""d; yet, it is a curious fflCt th8.t non~ of the ""rn~­ jar"" statistic81. softtom.:re vendors (e.g., SA::;, Er<IDP, SPSS, etc.) support routines to ~rform these calcul~tions. The expressions for complex non-linear statistics, such as cov'lrionoes an.i correlations, tak~ on an ~de1 dimension af mathematicAl BIld com:putational difficulty. As'l result, there is C'l, chronic need for canputer soft~re to provide measures of pre~ision for both lineflr and non-linear statistics. In this paper, we describe a collection of SAS macros, written in PROC MATRIX, to perform v~i­ ance estimation using t':te JACkknife Repe8.ted Re~ licate approAch (Frankel, 1971). Jqc~ife Re­ peated Replicate (JRR) is R. ~,rticul~.r applic8.tion of the f~iliar"" jack1rnifin~"" method of vE'xiance estimation. It ts canSBerl;!n hert'~ in the special case where there are two (ffild only two) priI!l;u""y sampling units (PSU's) per priIllL'l.ry str~tum. This ap?roac.h ~Bpit~lizes on vArintion observed betwe9n th~ two PSG's in ev~rv strA-tum, across all stratn in the design. This vgriabiJity is used to impute the variance of any population statistic of interest. A more formal discussion of the method is proyided belOW. Software h~ been written to calculate e:sti­ mates for nine different sample survey stqtis­ tics, plus their standard errors. T~ese include not o~ linear statistics, s",Sugi-83-159 Rochon Kalsbeek.pdf
"THE IlEVELOIMENr AND IMPLEMENI'ATICN OF A CXMPLEl'E FDRECl\STm:; SYsrElI! ENl'IRELY wrm SAS D. Beooit Sorhaiooo, M&M Mars U. V. Subba-Rao arxl Dr. R. Suhir, Warner Lambert Chnpany This parer has two objectives. First, it seeks to highlight the crucial steps in eoonametric model buildin:J and their successful execution wOOlly within a SAS environment. Second, it pr~s a way to exploit collinearity amorg explanatory variables with the aid -of factor analysis. The moo.el building exercise was umertaken to provide forecasts and market analysis £Or a major oon­ sumer proouct line. Figure 1 depicts the resulting sequence of events. Step one was the creation of a SAS data base containing (a) the dependent var­ iables (manbers of the product line) and (b) the irrlependent variables such as retail sales, Pig-. 1 TIle Modeling Cycle, CrtNIt.1cm 0.( aU. b .. e AnalySU of tbe ~ta • Graphical analy.!. • CorrelatiOll aaa1yw • hctDr --.l~. Speci:fic.t.ion of the -.del • Delta trane!OZlllltian • Bquat1CJa ~ ee1ect1on Par_ter BOtaluation • ~ criteria • statilJt1c:al ~ Model Val~tiOl1 • Stn1ctural analysis • Beancal1c An&lyd. Iluild. teat and a;pply _eb to toncaat. indepe_ dant .,,,,,iable. I 1Ipp11cat1<m of tIU! lIOdel • policy """"l1. .. Ucm - &re""' .... t.1r"" 85 retail prices and retail inventories which were outside the control of the firm, am promotional frequency, price discounts, etc., which were clearly subject to o:mpany marketing pJlicy. '!he other steps fell into the following categor­ ies: - Data Analysis - Construction and Validation of Product lOOdels - Dynamic Models of Independent Var iables - Application of the Model DATA ANALYSIS Since the goal of the project was a search for a mathematical relationship between each product in the line and variables suspected to have caused its historical movements, a first step was to generate plots, scatter diagrams and correlation natrices. The ~ prcx:::edures GIM am CORR proved helpful at this p::>int. An additional procedure A(J'l",Sugi-83-16 Sorhaindo SubbaRao Suhir.pdf
"PROC SURVFIT and PROC SURVTEST: An UIJdate 1 Kenneth P. Offord; Thomas R. Fleming Mayo Clinic Introduction The general topic is estimation and comparison of survival curves. The survival curve is simply the estimated proportion surviving from time a to t. time a may be birth. the time of diagnosis of a particular disease, time of assignment to treatment. time of kidney transplant, etc. Subsequent to time 0, we record the time to the event of interest. This may be death, remission of symptoms, tumor shrinkage. another diagnosis, etc. Not all persons will necessarily be observed until the event of interest has occurred. We refer to these observation times as right censored. The methods addressed below, Which estimate and compare survival curVe!l, allow the utilization of persons who have censored observation times. If one is interested in estimating the proportion surviving 5 years following some surgical procedure, for example. it is not necessary to exclude patients who had surgery less than 5 years ago. The aim is to utilize all the information. Below we describe twa SAS procedures to estimate (PROC SURVFIT) and compare (PROC SURVTEST) survival curves. I. PROC SURVFIT In a previous SUGI presentai}on we described the proposed SURVFIT procedure 1 • since that time, we have completed the procedure and have had it in use for over a year. There are some minor changes between what was proposed and the final product. It has recently been submitted with ample documentation to SAS Institute as a supplemental procedure. The SURVFIT procedure estimt9Js the survival curve by either th, Kaplan-Meier (K-M) or actuarial method 2. The Kaplan-Meier method is also called the product limit estimator. ~I1RVFIT produces a life table and optionally an arithmetic or l- or 2-cycle semi-log plot of P (the estimated probability of survival from t~me a to t) vs. time. Optionally, an output data set of the life table may be created. One unique feature of SURVFIT is th~ ahUity to compute the e",Sugi-83-160 Offord Fleming.pdf
"tc MISSING EVENTS IN SURVIVAL ANALYSIS Peter A. Lachenbruch and Robert F. Woolson, The University of Iowa Introduction In some retrospective analyses of survival data, there may be questions about the complete­ ness of lhe daLa particularly regarding the recording of all of the events. For example, in a tumor registry, have all deaths been recorded? In a medical record review have all rehospitali­ zations been found? In a follow up of psychi­ atric patients, it was not certain that the rehospitalization took place at the original hospital. Thus, Lhe disease free interval could have been shorter than it was reported to be. These problems all lead to estimates of survival or disease-free interval longer than the patient actually had. The purpose of this paper is to study tbe effect of attributing longer survival to the patient than is actually the case by studying two examples in detail. Models We consider two models: the ""censoring-in­ place"" or elF model and the ""censoring-to-Iast­ place"" or CLP model. In the ClF model, a failure at time t is changed to a censored observation at Lime t. This model is not realistic, but is studied because it provides some insight into this problem. The eLP model assumes that there is a maximum period of obser­ vation associated with each patient (e.g. a patient first entered on a registry 2 years ago must either fail within 2 years or be censored). If that person's failure is missed, the survival time will be the maximum period of observation and the observation will be censored. There are, of course, intermediate possibilities. We are concerned with several problems: 1. 2. 3. 4. In the exponential case, what are the effects on parameter estimates of CIP or CLF? In the exponential regression model using a proportional hazards (ph) fonnulation, what arc the effects of eIP or CLP? In the Weibull case what are the effects on the parameter estimates (hath shape and scale) of CIP or CLP? For the Cox partial likelihood, how are parameter e",Sugi-83-161 Lachenbruch Woolson.pdf
"PROC DISCRETE;* A Procedure for Fitting Discrete Probability Distributions James P. Geaghan, Louisiana State University Charles E. Gates, Texas A & M University George D. Williams, louisiana State University The DISCRETE procedure fits discrete probability distributions to count data. The eight distributions available in the procedure are the Poisson, negative binomial, positive binomial, Thomas double poisson, Neyman type A, Poisson-binomial, Poisson with zeroes and the logarithmic distribution with zeroes. Data may be entered as either raw data or as classes and frequencies for an observed distribution. All of the eight distributions, or any subset, may be fitted to the observed data set. The PROC DISCRETE statement PROC DISCRETE options; The options and parameters below may be requested in the PROC DISCRETE statement. NOSIMPLE NOSIMP Requests the program to not print the simple statistics section of the output. NO INTERMEDIATE Non Requests the program to not print intermediate results (iteration series or initial values). NOPRINT Requests the program to not print any of the normal output. Notes and error messages are transferred to the SAS log. TRUNCATE TRUNC When used with a value specified as MAXClASS=, the TRUNCATE aptian causes values in classes exceeding the maximum specified class to be deleted instead of being pooled into the maximum class. Individual distributions may be fitted by requesting the following options. If no distributions are requested, all eight distributions will be fitted. POlS - Poisson distribution POSB - positive binomial distribution NEGB - negative binomial distribution THOM - Thomas double poisson distribution NEYA - Neyman type A distribution POIB - Poisson-binomial distribution POIZ - Poisson distribution with zeroes LOGZ - logarithmic distribution with zeroes PARMEST Causes a SAS data set to be created which contains the values of parameters estimated by PROC DISCRETE. The values are contained in a data set called ""PARMEST"". When b",Sugi-83-162 Geaghan Gates Williams.pdf
"Multivariate outliers often have pronounced effects on the interpre­ tations and conclusions of principal components and discriminant analyses. Their influence. however. is rarely examined due to the difficulty in dis­ covering them 1n high dimensional indi­ vidual space. This paper reviews Huber's tech­ niques for determining robust M-esti­ mates of mUltivariate location and dis­ persion. This allows principal compo­ nents to be computed which are less sensitive to outliers than those ob­ tained from the ordinary covariance matrix estimate. A robust discriminant analysis then is based on combining the location estimates from g groups into a between-groups covarinace matrix and the dispersion estimates into a within­ groups covariance matrix. The resulting generalized eigenvalue problem is solved to obtain the discriminants. A SAS program has been written using FROG MATRIX which allows classical or robust discriminant (and/or principal components) analyses to be selected. This program consists of a control module and three computational modules. A limited simUlation study was performed for the three-group bivariate case. Outliers were introduced by con­ taminating bivariate normal distribu­ tions. The means were arranged in either a collinear or triangular pattern. The results showed that the distributions of the robust test statis­ tics, based on those of Wilks and Roy, are changed relative to their classical counterparts.",Sugi-83-163 Harner Billings.pdf
"Multiple comparisons in univariate ANOVA have received continuous research interest for many years. Many practical methods exist. Powerful software has led to the common and increasing use of multivariate ANOVA. Al­ though the issue of multiple comparisons in MANOVA has received a great deal of theore­ tical interest, few practical results have been provided. Methods which can be computed are reviewed and evaluated. Issues include 1) whether the response variables are in a common metric, 2) the design of the study, 3) where to set type I error rate, 4) power, and 5) the type of comparisons of interest. Useful methods include 1) purely multivariate (larg­ est root) methods for unplanned comparisons, 2) Bonferroni corrected univariate for planned and unplanned comparisons and 3) Banferren; corrected multivariate step down for planned comparisons.",Sugi-83-164 Muller.pdf
"PROC MATRIX Ml\CROS FOR GENERALIZED lNaNI'LEIE (GIM) AND MJLTIPLE DESIQiI (MDM) MlJLTIVl\RIAm MJlEIS Diane L. Fairclough and Ronald W. Helms University of North carolina Kleinbatm (1970) developed theoretical methcxblogies for the estimation am hypothesis testing for generalized linear multivariate models. In these gere-ralized models, the constraints of canplete data am a c::xmtOl design matrix for all resp:mse variables are relaxed. In many research settings, especially the clinical research setting, incx:mplete data is not an unccmnon problem and multiple design models occur ... While the theoretical basis for the analysis of these More General Linear Multivariate (K.iI,M) rrodels exists, the lack of available software l:imits its application. In this paper we describe a series of BAS macra:s, written in PRX MA'lRIX statements, for estimation and hypothesis testing of these generali~ linear multivariate rrodels. The approach consists basically of three steps. The first step estimates the error variance-cxJV'ariaroe matrix (1:) based on the pairwise complete data... 'lhis estirrate is then llSed to produce ""I'timates of primary and secondary parameters which are unbiased and best asyIq?totica1ly nomal (BAN) • Finally, test statistics for the general linear hypothesis, in general form of wald, are generated. These test statistic are asymptotically distributed as a central chi-square. Kleinbaun (1970) described a 'More General Linear Multivariate'"" (MGIM) model in which different design matrices correspond to different response variables and observations may be missing wi thin the resp:mse vat"" iables. A special case of the MG[M model is the Multiple Design Multivariate (MDM) model which corresp::>nds to the situation where each res:p:>nse variable may have a different design matrix, so that they are seemingly unrelated, arxl yet the response var iables are correlated according to the error variance-covariar£e, t. The secord special case of the MGI:M model is the Ge",Sugi-83-165 Fairchlough Helms.pdf
"MULTIVARIATE DATA ANALYSIS LIBRARY: ""FRENCH METHODS"" SYSPAD J.M. GAUTIER, COREF COREF, in collaboration with SAS Institute Europe provides the diffusion of SAS in France for it is presently considered as the most usefull packa­ ge for statistical studies. For this purpose, COREF wrote a French documen­ tation for SAS, organized SAS courses in France and introduced SAS at universities and at the French statistical Institute. Nevertheless the specificity of French methrds for multivariate exploratory data analysis 12d COREF to develope by itself a library of SAS procedures called SYSPAD. The first version of SYSPAD contains correspon­ dence analysis. principal components analysis, hierarchical clustering, graphic representation for factor analysis with quick computinq algo­ rithms and aids to interpretation. With those one can study important populations and easily in­ terprate the results. The next version shall contain new discriminant analysis methods: one fo-r qual itative data and one based on density estimation with Kermel function. Here some more details on SYSPAD In the last 20 years or so , some particular methods and statistical practices have been developed in France in the fields of data analy­ sis. as for example: Correspondence analysis in contingency tables and multiple correspondence analysis. Hierarchical ascending clustering based on aggregation strategies according to variance and essentially using the Chi 2 metric or the Euclidian metric. Techniques of the interpretation of the ana­ lysis into a main component of the correspon­ dence analysis with the help of particular tables and graphs. But : The French methods are presently available only in the form of specific programwes that are scat­ tered and not very compatible among themselves. This situation is particularly harmful to the spread of these techniques outside France. and even to their large-scale use in France. How many firms. calculation centers and French laboratories have only a very inc",Sugi-83-166 Gautier.pdf
"for preparing presentations, and its usage will continue to increase as lower cost output devices become more available. It is important that the presenter take advantage of SAS/GRAPH's full potential for preparing presentation material particularly PROC GSLlDE's ability to generat~ briefing charts. PROC GSLI DE combines simplicity with considerable flexibility allowing the user to ea,sily create different vugraphs. The purpose of this paper is to provide several tips and suggestions for using GSLlDE, as well as to provide some general ideas concerning the preparation of presentations. INTROOUCTION One might ask, ""What makes a good briefing chart good?"" Most people's first thought might be that a good briefing chart must be pleasing to the eye. After considering this question for so,!!e. time, w,e have concluded that a good brl~~lng chart I~ one which is able to quickly and effiCiently put Into the minds of the audience the single message or idea intended by the presenter. The fact that the chart is pretty or pleasing to the eye is of secondary importance. Further, in briefings, lectures and other occasions where briefing charts are' used rarely do you find a single ch'art or slide displayed. A g<?od briefing. chart is one which when integrated With other briefing charts, forms a constant and even flow of ideas. These visuals combined with the proper narrative form the basis of an effective presentation. BRIEFING CONSIDERATIONS When beginning to prepare for a briefing you sh",Sugi-83-167 Blaschke Madison.pdf
"ime !el'ies related procedures currently available to the user or SAS JETS release 82. Speci6cally by example, a diversi&ed group of techaiques will be introduced ranging from inex­ pensive, automatic rorecasting pr«edures, to more com­ plex, powedul, model based approaches. The variables examined in this discussion are ex­ traded. from -the CIT [BASE T AI: Citibank Economic Data Bue U5in~ the SAS procedure PROC CITmASE. CITIBASETAljs the economic data base distributed on magnetic tape by: Citibase/Citibank EeoDomic Department Citibank N .A. 399 Park Avenue New York. NY 10043. -1- These SAS PROCs perrorm the rollawinS tasks: FORECAST Fits univariate time series aDd automati­ cally produces forecasts. XU Seasonally adjusts moathly or quarterly time series usin8 an ada.pta.tioa of the U.S. Cense Bureau X·ll Seasonal Adjustment Program. ARIMA Analyzes aDd rorecasts uaiva.riate time series data., transfer runction da.ta, or intervention data. using the Bar. a.D.d JeDkins autoregressive integrated mov· ing avera.ge model. STATESPACE Analyzes and forecasts multivariate time series data including transfer function models tha.t bave ra.ndom inputs. -:I- 904 How the .. Interrelate Time , , Series Procedures I nee OT6IISPACt I nee .. ,111 H""""'tw .. ,,,. _,. I (Ia ............. _""0) I ""«.R_I.,,,,«) I I I I I I I I I I I I I I I I I I (! ............ "".... I I I """"""',) I I I I I I I nee xu I II u.s. c-........... I IS_IMJ ......... )! , , PROC~ ....., .... ""'UG !IE'JlIODooEIPO (Au.' ....",Sugi-83-168 Brocklebank.pdf
"DATA REDUCTION AND SUMMARIZATION Joshua SharI in, ORI Inc. INTRODUCTION One of the most common data processing tasks, -besides printing data is to calculate summary statistics on a collection of data. Selecting the best method in SAS requires the evaluation of several factors: what summary statistics are to be produced; the size of the data set; - the number of times the program will be executed; - the level of SAS skill required to code the program. Depending on the statistic. there may be many Nays or only one way to get results. For example, PROC UNIVARIATE is the only Procedure that calculates medians, quantiles and modes. But if the task requires counting subgroups of observations, Procedures MEANS. SUMMARY. FREQ, or UNIVARIATE can do the job; or the SAS programming language can be used to calculate subgroup counts in a Data Step. The efficiency of a SAS program becomes more important as the size of the data set and the frequency of program execution increases. If weekly means are c~lculated on a data set of half million observations, then efficiency becomes a significant factor. But with a data set of only 100 observations, differences in efficiencY between methods would probably be undetectable. As the users SAS skills improve, they can begin to take advantage of more methods. Five methods of c~unting observations were listed earlier, but a new SAS user should only learn PROC MEANS. The objective of this paper is to co~pare the SAS Procedures and the Data Step in calculating: 1) counts; 2) sums; 3) means; and 4) counts, sums and ~eans simultaneously. In addition, ~he effect on efficiency was measured for the following factors: - the number of BY groups - the number of values within a BY group the number of variables the number of different statistics calculated. 912 METHODOLOGY Depending on the summary statistic being calCUlated, different numbers of methods_ were evaluated. Six methods were compared in the efficiency tests for record counts, PROCs FREQ, MEAN",Sugi-83-169 Sharlin.pdf
"AN ALGORITHM FOR PRODUCING EXACT MAXllllU1II LIKELIIlOOD ESTIMATES FOR AN ARMA(P,Q) MODEL Carol M. Reilly. Syracuse University Box & Jenkins (1976) have devised a three stage process for the identification, parameter estimation. and verif'ication of fit of a time series model. Using their notation, a stationary stochastic process z~ is to be described by the appropriate autoregressive-moving average model of finite order (p,q), Zt = <\1.~t-1 + ... + ~~t-p + at - E~at_1 - ... - Sta t _ q where ~;;:; z~ - Z. and the alB (or white noise) are assumed to behave as normally and inde~endently distributed random var­ iables Wl th mean zero and variance cr~. Given N observations of the infinite series. the appropriate model is identif­ ied; estimates of the model parameters are computed in the estimation stage, and diagnos~ic tests in the verification stage check adequacy of' model 1'i t'. In recent years Box & Jenkins modelling teChniques have been improved and refined to yield more exact parameter estimates, more pow­ erful tesu of fit. This paper acquaints the SAS user with improved techniques; the program, written in PROG MATRIX, of"" fers alternatives to the estimation pro­ cedure and diagnostic test used by FROe ARIMA (which are based on Box & Jenkins ~odelling techniques). Initial estimates for the time series parameters ( the ¢'s &els) are input into the program. along with a SAS data set containing the appropriately differenceci series. :n order to ascertain that the estimates satisfy, the requirements for stationarity anct70r invertibility, an al­ gorithm which approximates the ratio test described by Box & Jenkins (p. 50) pro­ vides a rough check o~ the parameters. In the event the test fails, the prograrr. is terminated. Given the likelihood function for the N observations of' Lhe seL'ies: p(~ ,S ,,,,') = (Z'tfJji Inr*.xp( -0. 5~'<l:W) , the~{~TqT1) maximum likelihood estimators of the parameters are sought. PROe ARIlV,A uses a ~onlinear conditional least squares",Sugi-83-17 Reilly.pdf
"COMPARING SAS TO TRADITIONAL PROGRAMMING LANGUAGES Claude JlIckson, ORI, Inc. INTRODUCTION This tutorial wi II dis­ cuss some of the features of SAS ~hlch differentiate SAS from tradi­ tional programming languages such as, PL/I, COBOL, and FORTRAN. By studying these unique features of SAS and seeing how the same fun­ ctions are coded In traditional programming languages we should gain a better understanding of when SAS should be used Instead of a traditional programming language. It should also aid us In Justifying the use of SAS to others. Ex­ perience dictates thet sooner or later all of us will probably have to do this. Finally It should also aid us In using SAS more effectlve­ I y. The I mportance TO tl1e SAS programmer of understanding what Is unique about SAS should not be underestimated. There ~re many SAS statements that are s 1m II ar I f not Identical to statements In PlII, COBOL, and FORTRAN, e.g., GO TO, IF, and DO statements. It Is this similarity between SAS and tradi­ tional languages that causes many programmers to underestimate SAS and not fully utilize Its capabili­ ties. I have often seen a program­ mer or have myself used statements In SAS similar to statements In traditional languages instead of statements with the features about to be discussed. When th I sIs done many of the advantages of SAS are lost. Obviously programmers with experience In traditional languages are prone to this tendency but very experienced SAS Programmers overuse statements drawn from traditional languages In their efforts to use all of SAS. The point here Is that often a unique SAS feature will be much better than SAS statements drawn from traditional languages. This fact should not be overlooked. UNIQUE SAS FEATURES • A single numeric data type • ""Smart"" defaults • Data independence • Nonprocedural capabl I Itles • Powerful ""programming environment"" 920 This list of unique features Is certainly not exhaustive and the features are not equal In Importance. They do all sha",Sugi-83-170 Jackson.pdf
"THE SAS SUPERVISOR Don Henderson. ORI. Inc. INTRODUCTION This tutorial discusses the function of the SAS SUpervisor in the process of executing a 5A5 progra~ (particularly DATA steps). An earlier tutorial. ""Comparing SAS with Traditional programming Languages,"" discussed why and how SAS is different from languages such as Fortran. Pl/! and COBOL. In the earlier tutorial. particular emphasis was given to the SAS ""programming environrnent ft which is a direct result of the existence and functions of the SAS Supervisor. This tutorial will expand on the functions of the SAS Supervisor; the major ones can be categorized as follows: - Compiling SAS Source Code - Executing Resultant Machine Code The actions of the Supervisor during both the complle and eKecution phases of a SAS job will be illustrated. When we write a SAS program, we are in fact writing a ""module"" which must be integrated Nith the SAS Syste~. This integration is done by the SAS Supervisor (a progra~ itself). Gaining a more complete understanding of what the Supervisor does and how our -program- is controlled by it is crucial to using SAS more effectively. COMPI LE PHASE There is a distinct compile step for all SAS jobs. This fact is not readily apparent since a single program handles the compile and execution (including linkage-editing) steps of a SAS job. In fact, there is a distinct compile step and execution step for each DATA or PROC step in the SAS job. The DATA and PROC steps are compiled and executed independently according to their sequence in the program. In particular, the first DATA/PROC is compiled and then executed which is then followed by the com~ile and then the execution for the next DATA/PROC step, etc. The SAS Supervisor ~ontrols all of this processing. During the compile of a DATA step, the Supervisor creates both permanent and transient (in that they ""disappear"" after the execution of the current DATA step) entities. The primary permanent entity is the directory or header portion of th",Sugi-83-171 Henderson.pdf
"f· , , I I i~ f f t TABULATE Tutorial Alan Eaton and Ken Howell PROC TABULATE displays descriptive statistics arranged in hierarchical tables. This overview illustrates many features by using them in examples. The tables and the SAS program statements that produced them appear in figu res th roughout the text. All examples use hypothetical survey data on New Orleans restaurants and entrees. The following SAS code creates the input data set and formats for TABULATE. DATA; INPUT REST ENTREE SEX TASTE PRICE TIME; CARDS; 1 1 0 3 8.31 77 2 1 0 5 5.55 100 , 2 7 6.35 68 PROC FORMAT; VALUE RESTF = ANTOINES 2 = GALATOIRES 3 = ARNAUDS; VALUE SEXF 0 = MALE 1 = FEMALE; VALUE ENTREEF 1 = TROUT VERONIQUE 2 = SEAFOOD GUMBO 3 = SHRIMP CREOLE 4 = STUFFED FLOUNDER; The variables contain the following information; REST ENTREE SEX TASTE PRICE TIME the restaurant where the respondent ate the entree eaten sex of the respondent a measure of how much the respondent liked the entree the price of the entree how long the respondent was in the restaurant. We emphasize that the data is hypothetical and make no guarantees that the entrees mentioned are in fact served at the restaurants mentioned. SAS Institute 932 Furthermore, prices and taste measurements were randomly generated and do not necessarily indicate the true price or taste quality of any entree. TABULATE makes tables organized into classification hierarchies. Later we will show how to specify the items in a hierarchy. For now notice that the table in figure 1 displays the number of responses and the mean response value of TASTE. There are categories for male and female respondents for each entree at each restau rant. The table has three dimensions -- a page (only one for TASTE), rows, and I;olumns. Fou r element;; define each of these table cells: classification levels (of REST, SEX, and ENTREE) • a single analysis variable (TASTE) • a single statistic (N or MEAN) a format specification (described later) . The principal statements us",Sugi-83-172 Eaton Howell.pdf
""" i: , SAS TUTORIAL: PROC PRINT REPORTING James M. Watts, elBA-GEIGY, Inc. Introduction The purpose of PROC PRINT is to produce a printed report using ollar part of a SAS dataset. Options and information statements help control what variables are printed, how values are displayed, the sequence of obser­ vations, paging, column and line headings and many others. Information statements also provide the user the option to accumulate totals of all or some numeric variables. This tutorial presents examples USing a sample of these options. The simplest use of PROC PRINT is to write: PROC PRINT; When invoked this way, PRINT will display all observations and variables for the last dataset created in a columnar form as follows: ~ I 2 3 variable names for headings Columns of data Val ues PRINT will fonmat each page according to the values of the variables to be placed on the page. The pages printed in this way will not necessarily look the same. In fact, PRINT may display the variable names in a vertical form. OBS is not a variable in the SAS dataset but is a column inserted in the output l1sting by PROC PRINT. Adding More Detail to a PROC PRINT Report Many reports have the following general form Titles (I) (2) II Column Headings Row Row Labels Body of Data Totals or Line Columns of Information 1 Headings (3) (4) (If Any) (6) (3) II Column Totals (If AnY)(5)11 (5) The numbers in the following statements relate to the skeletal outline above. The statement or option can be used to affect some change in the correspondingly numbered section above. 943 PROC PRINT DATA"" SAS Dataset (4) LABEL (2) SPLIT"" spl itchar (2); VAR variables (4); 10 variables (3); SUM variables (5); TITLE 'text' (I); FORMAT variable format (4) I (3); LABEL variable"" labeling text (2); Section (I) TITLE statements, numbered TITLEI-TITLEID. can be specified with the PRDC PRINT locally or outslde PROC PRINT. If specified outside the TITLE text remains in effect until a Similarly numbered or lower numbered TITLE",Sugi-83-173 Watts.pdf
"~ :- j I ~ I t , [ f I SAS TUTORIAL: REPORT WRITING WITH FILE AND PUT James M. Watts, elBA-GEIGY, Inc. Introduction This tutorial illustrates the use of FILE and PUT statements to generate customized reports. Although FILE and PUT statements can be used to write as tape and disk files. we shalT discuss only printed output files. A user may elect to write a report ""line~by 1 ine"" or format an entire page at one time. The mas t CORmon way of writ 1 09 is"" 1 i ne-by­ line. 1I Therefore, this tutorial is limited to features useful in ""line-by-line tl report writing. FILE and PUT statements are used in a DATA step to generate lines of output using observations from an existing SAS dataset. Report writing in this way leaves the control of the printed page in the userls hands. Whereas PROC PRINT automatically centers output. spaces to a new page, sums variables, provides column and line headings, in ""l; ne-by-l i nell report wri ti""g, these functions must be controlled through SAS programming statements and certain FILE statement options by the user. The FILE Statement (with a sample of useful options) FILE PRINT HEADER = label NOTITLES LINESLEFT = variable LINE = variable; Option Description PRINT: Indicates that lines are to be written to the printer file defined by t~e DO card I/FTl2FOOI. HEADER =: The ""label"" defined by this option is linked to by SAS anytime a new page is begun. This happens when the last line written exceeds PAGESIZE or the user can invoke this by executing a PUT_PAGE_ statement. This option is very valuable for writing titles and headings. NOTITLES: Tells SAS not to use any previously defined TITLE statements. LINESLEFT ': Specifies a variable to which SAS automatically assigns a number equal to the lines left on the current page. LINE:: Specifies a variable to which SAS assigns the value of the current line pointer. 946 The PUT Statement There are three different styles of PUT statements.We shall discuss only the formatted style. In this style, the",Sugi-83-174 Watts.pdf
"EFFICIENT TECHNIQUES FOR LARGE DATA FILES Judith H. Mopsik, ORI, Inc. In an average EDP organization, code is used for a period of ten years or more before it is discarded (Reference 1), and a 51Jlall program that 15 run each day becomes as important to optimize as a large program that is run once a month. Today, as more and more programmers are using SAS to solve both large and small data management problems, it is important to learn how to use SAS efficiently. We are all fami liar with IoIhy managers prefer SAS - SAS is easy to learn, easy to use, and helps get results to clients quickly. Because SAS is especially convenient to use on a very large data set. we must now address the major criticism of SAS it can be inefficient and consequently expen5ive. In this tutorial topic I will of the literatUre which review some addresses efficiant SAS programming techniques for working with large data sets. I will then examine alternative ways of programming in SAS with large volumes of data and evaluating these techniques for efficiency. REVIEW OF THE LITERATURE Efficient SAS techniques for proceSSing large data sets through the use of working files, random samples, sufficient statistics and careful planning wer~ explored in detail by John SaIl (Reference 2) several years ago. Additional techniques have been detailed in the SAS Applications Guide (1980 Edition). Using procedures that do not require sorted data. and saving the output of a procedure and using it in later DATA steps are detailed in both references with e~cellent e~amples. Both references emphasize working with just the variables you need to get the job done. AnalYsis of a random sample, a stratified random sample. or a direct access random sample can often almost as good statistical precision a dramatic reduction in cost. give for Often, however. we are asked to do more than provide descriptiVe statistics on the data base. Several topics presented at the 1982 SAS Users Group International (SUGI) Conference eva",Sugi-83-175 Mopsik.pdf
"Tutorial - Variable Length Records Peter L. Rikard, Virginia Commonwealth University Reading variable length records is a pain in most computer langauges. Most programmers background is in dealing with fixed length records and the features in most languages provide no help in working with strange length records. **************************************** Definition Variable length records are records in non SAS datasets whose ACTUAL record length is not constant. A fairly circular definition, but it does EXCLUDE SAS datasets, and variable length record datasets where the records are really all the same length. ******************* Notes Records that are all the same length in a variable length file may be read as if they are fixed. SAS datasets are/are not variable length records. A SAS dataset has ""fixed- length data records. Examples; SOME SMF records are really variable in length. 4 - step record, is 5 - JOB record, is sort of 6 - output writer, is 7 - data lost, isn~t 8 i/o config, is Hierarchical Files Some is Some ain~t SAS on the other hand gives you a number of tools to easily handle some of the most difficult records. If you learn the capabilities of each tool, you can read any file. *******-*************** TOOlS Pointers trailing @ trailing @@ @variablename 956 INFILE parameters MISSOVER!STOPOVER LENGTH= COLUMN= END= DO - END groups Trailing @ EX: The single trailing @, holds a record within the current execution of the DATA step. The double trailing @@, holds a record until either you input past the end of the record OR until YOU release it. DATA J INPUT xxxxx @ ; (read from first record) INPUT YYYY1 @ ; (still on first record) INPUT zzzzz : (STILL on first record but not held anymore) INPUT qqqqq , (read next record) *************************** Pointer - @variablename INPUT @37 99999 , moves the pointer to column 37, so the next input item is read beginning there. INPUT @variablename gggggg moves the pointer to the column of the current value of the variabl",Sugi-83-176 Rikard.pdf
"f , SAS Tutorial Regression with PROC REG R. J. Freund Texas A&M University Many procedures in SAS can be used to perform regression analyses. Each procedure has special features that make it useful for certain appli­ cations. However, for most applications, PROC REG is the preferred tool. The options included are as follows: The paper consists of 18 pages of annotated output describing the results of implementing a number of options available with PROC REG. The individual pages are suitable for making transparencies. Copies are available from the author. 959 28 PROC REG; 29 MODEL WT RL Wl RNl NWL W I 30 S51 $1 SS2 32 STB 33 VI F 34 SEQB 35 COLLIN 36 P 37 R 38 CUI 39 INFLUENCE 40 PARTIAL : 41 TEST1: TEST RNL-O. NWL=O: 42 OUTPUT QUT-A 43 P=PW RaRW 44 195M:L095 U95M:UP95 4S CQOKD=COOK;",Sugi-83-177 Freund.pdf
"Reading and Interpreting GLM's Printout of Estimable Functions and Sums of Squares by Ramon C. Littell University of Florida Author's note; This writing is a portion of a handout for a tutorial presented at the 1983 SUGI meeting. For further illustration. see Freund and Littell (1981, section 4.7, pp.143-153). Assume a linear model y = X~ + C. Is the usual framework, a linear function L'a is estimable iff there exists a linear function t'y of the data vector such that E(i'y) : L'a for all a. The coefficients in the L vector for estimable functions can be printed by SAS-GLM. Consider a 2x3 layout with factor SEX (levels 1, 2) and HORMN (levels A, B, H) and response variables WTl, WT2, WT3, WT4. Execution of the SAS state­ ments PROC GLM; CLASSES SEX HORMN; MODEL WTl WT2 vi'T3 WT4 : SEX HORMN SEX*HORMN/E El E2 E3 E4; gives the general form of the estimable functions and the specific coefficients for each type of ss's. pertaining to the model the general form is L1U + LZll l + (L l -L 2 )1l 2+ L4 BA + LsBB+ (L I -L 4 -L S)B H + LZYlA + LSY1B+ (L2-L7-LS)YlH + (L4 - L7 h 2A + (Ls-La)y 2B + (LI-L2-L4-LS+L7+L8)Y 2H provided The n .. > 0 for all cells. 1J coefficients of an estimable function expressed in terms of the ~ij must agree with the coefficients on the Y ij when the function is expressed in terms of Il i , B j and Y ij . For example, consider 1\1-Jl 12 = ().l-f'J. 2 + ""(11- Y12 · Therefore, the coefficients printed on the interaction para­ meters can be used to express estimable functions in terms of cell means. Consider, for example, the Type I F test of the SEX effect for variable WT2. The coefficients printed are 960 PARAME'IER COEFFICIENT INTERCEPT 0 SEX 1 L2 2 -L2 HORMN A 0 B 0 H a SEX*HORMN 1 A 0.2857*L2 1 B 0.4286*L2 1 H 0.2857*12 2 A -0.2857*L2 2 B -0.4286*L2 2 H -0.28S7*L2 Thus, setting L 1 = 1, we see that the hypo­ theses tested in terms of cell means is HO; .2857~lA+ .4286VIB+ .2857VlH- .2857V2A - .4286~2B- .2857~2H= o. These coefficients derive from th",Sugi-83-178 Littell.pdf
"INTERACTIVE TECHNIQUES TUTORIAL J.D. Young, Texas Instruments, Inc. Cynthia Deitz. Texas Instruments, Inc. PROBLEM STATEMENT This tutorial topic illustrates techniques in interactive processing that can greatly aid produc­ tivity. SAS running under eMS offers the user much flexibil ity and power, which if not used properly can be very detrimental. It is the intent of this tutorial to present information that will enable a SAS/CMS user to become more proficient. The following examples range from quite simple to relatively complex. ENVIRONMENT INFORMATION It is informative during an interactive session to determine what resources SAS ;s uSing. This can be Jone by issuing the SAS command PROC OPTIONS SHORT; as follows: 17 proc options short; run; SYSTEM PARAMETERS AND OPTIONS BAUD=IZ00 NOBLOLTABLE BLKSIZE=2048 BUFNO=1 CAPS C=MAX C60 NOCENTER NOCHARCODE CHKPT NODATE DEVAODR= DEVICE= DISK=SYSDA NDDQUDTE NODUMP NDDYNALLOC NDERRORABEND ERRORS=20 FIRSTDBS=1 GEN=5 FILSZ GRAPHICS INCLUDE INVALIDDATA=. LABEL LAST = NULL LEAVE=60535 LOG=FTI1FOOI NO LOWERCASE LS=132 NOMACROGEN MISSING='.' MODECHARS='?;"" NONEWS NOTES NON UMBER OBS=MAX DFFLINE=0.0040 ONLINE=O.OI20 NDDPLIST NOOVP P=MAX PARM="" PARMCARDS=FTI5FOOI PROCSIZE=16776192 PRDMPTCHARS='110AOI0009000000'X PS=24 REPLACE S=80 S2=S SEQ=8 SKIP=O NOSNP NOSNPPROG SORT=O SORTDEV=SYSOA SORTLIB= , SORTT , NOSORTLIST SORTSIZE=SIZE SOURCE SOURCE2 NOSPDDL SYSIN=SYSIN SYSPARM="" TAPE=SYSSQ T=MAX TLS=80 TRANTAB=GTABCMS UNITS=11 12 13 14 15 16 17 18 19 20 USER=WORK WDRK=WDRK NOWORKINIT NOAUXOIR CMSSVC=255 CPSP ERASE NOFILCLR FDRTG="" LTYPE NAME="" NDNULLEDF PLIF=SPLILIB PLID=PLILIB PSEG=OFF PTYPE SASLIB="" SERIES="" SIODISK=A SSEG=OFF NOT LOG TMSGLEV=ERRDRS TXT LIB VIOBUF=5 Some important i nformati on conta i ned above is: l)Where the log files are being sent; in this case to FTllF001. 2)What 110 units SAS is using. This is important if it is necessary to call a FORTRAN program from within SAS. or any other software that might allocate I/O units",Sugi-83-179 Young Deitz.pdf
"TIME SERIES ANALYSIS OF HIGHWAY ACCiD~NT DATA scott O. Starks, David W. Elizandro, and Ronald J. Classen Department of Computer Science and Engineering University of Texas at Arlington ABSTRACT: This paper presents results obtained from the ap­ plication of SAS time series analysis techniques to fatal highway accident data fOL- the time peri­ od of ,Tanuary 1975 through December 1980. Special attention is given to data for the state of Ar­ kansas, although results from selected neighboring states are presented. During thie time period, many states, including Arkansas adopted programs incorporating countermeasures for the purpose of reducing the occurrence of alcohol involved ac­ cidents. This pap~r presents time series models for the preliminary analysis of the effectiveness of such programs. The paper contains background material for the problem considered, as well as a description of the data base and methodology used in the study. Motivation of study Any comprehensive program designed to decrease the number of fatal highway accidents must ad­ dress the problem of drinking and driving. Dur­ ing the past, many states including Arkansas have adopted programs incorporating countermeasures for the purpose of reducing the occurrence of alcohol involved accidents. In order to ascer­ tain the effectiveness of such programs, the Ar­ kan~d~ Highway Safely Program office maintains data on fatal injury accidents which occur within the state of Arkansas. This information includes data on the environment, the vehicle and driver involved in fatal accidents. In addition, the National Highway Traffic safety Administration, Department of Transportation maintains a data base which contains information on fatal crashes in a uniform format for all fifty states. In this study. the National Highway and Traffic Safety Administration data is used to determine seasonal time series models for alcohol involved fatal motor vehicle crashes occurring within the state Of Arkansas as well as in",Sugi-83-18 Starks Elizandro Classen.pdf
,Sugi-83-180 Reel.pdf
"The Federal Aviation Administration publishes a number of forecasts of aviation activity for its various facilities: airports with FAA control to­ wers, air route traffic control centers, and fli­ ght service stations. The evaluation of forecast errors as actual data become available has been a primary concern of the Office of Aviation Policy and Plans, which is charged with producing and publishing the official FAA forecasts. Consequen­ tly, APO has implemented an FAA Aviation Forecast Error Analysis System by taking advantage of the many versatile features in the SAS data management techniques. This system has the following parts: 1. Sobering Diagram. 2. Actual Values and Yearly Forecast Series for Endogenous Variables. 3. Rela­ tive Forecast Errors (%) and Summary Report of the Latest Forecasts. 4. Relative Yearly Forecast Va­ riation. 5. Turning Point Analysis. 6. Elementary Forecast Error Statistics. 7. Theil Inequality Co­ efficient and Related Statistics. 8. Ex Ante Fore­ cast Evaluation. SAS statements for each part are orgaaized in macros in such a way that either all or selected parts may be run in batch or inter­ active mode to produce reports with any desired level of detail. Updating the the forecasts on the basis of the results of the error analyses, with a new series of forecasts and additional data) is extremely easy because of the well-known data management features in SAS.",Sugi-83-19 Kalyandrug Kondo.pdf
"S is taught as part of the sophomore level Information processing course at Southern Connecticut State College. The students study a text with sections on computer technology. programming, systems, and computers in society. Interactive BASIC pro­ gramming is taught the first half of the term and SAS the second half. SAS is presented as an example of a modern problem oriented soft­ ware system. Its ease of use, good documentation, standardization, modularity, and continual updating are used to demon8~rate good programming practice. 1 - BACKGROUND Southern Connecticut State College is located in New Haven, Connecticut. It has an enroll­ ment of 7,000 undergraduate and 3,400 graduate students. In early 1983 the achool will be­ come known as Southern Connecticut State University. Last year the Computer Science Department was accredited by the State of Connecticut to offer the Bachelor of Science Degree in Computer Science. There are current­ ly over 300 Computer Science majors. The college has its own DEC 11/70 computer with 18 VT100 tenninals available for student use. A Harris remote job entry station is used to transmit hatch jobs. There are also many microcomputers available including TERAKS, APPLES, and TRS-80's. SAS jobs are usually created on the VT100's using DEC's ED2 full screen text editor. The jobs are processed at the University of Connecticut on an IBM 3081 running under the MVS operating system. They are returned to the sender's terminal. Most of the academic year",Sugi-83-20 Workman.pdf
"he software development life cycle and its associated products have emerged in response to the problems co~puter professionals were having in delivering correctly fUnctioning applications on time and within budget. To deal with these problems a number of techniques were introduced to bring greater structure and discipline to the co~puter systems development process. These techniques have been labeled structured methods, and they cover all phases of the system's life cycle from analysis through design, coding, testing. and into implementation. The essence of these techniques is that one must try to understand the problem as completely as possible before one tries to solve it. Furthermore, one's understanding of the Problem must be documented in such a way that others can read and validate that understanding. Structured techniques emphasize graphic presentations of the problem statement befare any solutian is cansidered. They recognize that you must understand what is to be done befare you decide how to do it. Separating the act of solving the problem from the definition of the problem offers the opportunity to consider and reconsider what really needs to be done. It also allows for comparing the results of the application with the problem statement for correctness. The idea that each product of the systems development process should be measured against its requirement to certify correctness is at the heart of the movement to standardize and document the way computer applicatio",Sugi-83-21 Trimble.pdf
"oach to data management is fundamental to university database courses. Unfortunately, very few relational systems are available at a price most universities could justify solely for teaching purposes. R AQL is a relational query language which operates in a SAS environment providing a low cost relational teaching system. The language of RAQL is based on the syntax used in the popular textbook by C.J. Date _ Introduction to Database Systems, Edition Two, Chapter 6. RAQL offers all the facilities in Date's book, and much more, and is implemented so as to M..Il at reasonable expense on any teaching database. Although no knowledge of SAS is necessary to use R AQL, it was found that the data management features of SAS reinforced and complemented the teaching of the relational approach. SAS used with RAQL at McGill University has completely transformed the undergraduate database courses. INTRODUCTION This article is not an argument for the relational approach for which a case has been strongly made by Codd(l), rather it is a case for the use of a database system with a query language on introductory database courses. If a choice is available,a database instructor must decide whether to introduce data manipulation using a query language or using a language,based on subroutine CALLs,imbedded in a host language. Having used both methods,we found that the improvement in the course through the use of the query language was striking. USING A DATA MANIPULATION LANGUAGE WITHIN A I-OST LANG",Sugi-83-22 Burrage Gilman.pdf
"ute of Tec:lmology ABSTRACT The effective use of statistics is an impor­ tant part of the problem-solving process in in­ dustrial and engineering research. This paper identifies those aspects of the training and education of statistical consultants, that con­ tribute to their success in the industrial envi­ ronment. A number of issues regarding the professional practice of statistics are also discussed. 1. INTRODUCTION The purpose of this paper is to discuss several aspects of the training of statisticians, the role of the statistician as consultant,and some principles of professional practice that lead to successful statistical consulting. The focus is on the industrial, academic, and the government systems environments. I exclude any discussion of the life or social sciences because of limited experience in those fields. However, I believe that the principles that apply in the industrial and engineering environment are highly portable. We will discuss the type of academic background and training that is likely to produce a suc~essful statistical consultant, and present some suggested guidelines for how the statisti­ cian can most effectively operate in the consultant's role. Many opportunities for statistical consul­ ting exist. I believe that these opportunities are expanding, in part because of the recent emphasis on quality and reliability in ~nufac­ turing, and because of the increasing general awareness of the usefulness of statistics in business decision-making. There",Sugi-83-23 Montgomery.pdf
"PROC MATRIX AS AN INSTRUCTIONAL TOOL IN A MULTIVARIATE STATISTICS COURSE FOR SOCIAL SCIENTISTS Randall R. Robey and Robert S. EarcikOl~·ski Ohio University Introduction In the following remarks, we will describe an approach to the instruction of multivariate statistics for social scientists which we have found useful. An integral aspect of this approach is the insight to hypothesis testing afforded to students by PROC MATRIX. The course itself consists of the ten teaching modules found in Figure 1. As you can see, the first module concerns an introduction to matrix algebra. Additionally, figure 1: Teaching Modules. 1. Matrix Algebra 2. Univariate Regression Analysis 3. Multivariate Regression Analysis 4. One-Way MANOVA 5. Stepdown Analysis 6. Discriminant Analysis 7. Factorial MANOVA 8. MAN CaVA 9, Repeated Measures Univariate Approach 10. Repeated measures - Multivariate Approach this module introduces the student to the application of PROC MATRIX statements for solving matrix expressions. Appendix A represents an example problem found in the first module. Later, we will examine the one­ way and factorial multivariate analysis of variance (MANOVA) modules more closely. The statistical tests in modules two through nine utilize the full rank model described by Timm (1975), and Timm and Carlson (1973). The null hypothesis for the model can be written as Ho: ABC' '"" D. Here, A is a q-l x q matrix of coefficients representing the between group hypothesis to be tested, B is a q x p matrix of unweighted cell means, and C' is either a p x p identity matrix, as in the MANOVA case, or a p x p-l matrix of coefficients representing the within group 113 hypothesis, as in the repeated measures case. D is a q-l x p-l null matrix. Fortunately, a core of only seven matrix expressions provide the basic information necessary to solve all of the multivariate and univariate tests of interest. These seven expressions, or steps, form the foundation of this instructional approach. In Appe",Sugi-83-24 Robey Barcikowski.pdf
"niques to document their programs. The styles. idioms and formats are frequently so diversiried that it is often difficult to maintain programs developed by several different individuals. Additionally, good documentation practices can ensure good progrrumming practices. This paper presents some guidelines for documenting SAS programs for easy mainte­ nance and comprehension. Guidelines are based on principles from diversified fields from systems design to graphics design. The guidelines discussed have been used by the author and several oth­ ers at the Hewlett-Packard Corporate Data Center with great success. Guidelines for Writing Easy to Read SAS Code and Documentation This paper is designed to provide SAS programmers with a guide to writing easy-to-read SAS code. It covers how to format raw code. choose names, decribe fields and provide additional documenta­ tion text. SAS's step orientation lends itself to structured documentation prac­ tices, so be sure to take advantage of this feature. The guidelines described below can be easily extrapolated to other programming languages. In addition. the comments given here include some hints on machine efficiency, to demonstrate how easy to read code can peacefully coexist with efficient code. Of course, these are guidelines, not com­ mandments carved in silicon dioxide; they represent some of the experience and prejudices of the author. However, these guidelines all have good reasons behind them. and if you follow them closely the",Sugi-83-25 McGregor Nelson.pdf
"eries of Superwylbur macros has been written which allows SAS users to submit jobs without JCL and to retrieve SAS output and automatically report SAS and JCL errors. We have taught SAS workshops to our -faculty both before and after these macros were implemented. Their effect on novice users has been positive and dramatic, far more than we originally anticipated. BACKGROUND Over the past five years, we have offered SAS workshops for the faculty and graduate students at Rutgers Medical School. We usually schedule three half-day sessions, typically one week apart, to introduce the fundamentals of SAS and our data entry/editing system, Superwylbur (a supar set of Wylbur marketed by Optimum Systems Inc.). Our new SAS users were often uncomfortable with writing the necessary 3 or 4 lines of JCL. Even though the users were told to copy the JCL lines carefully, they tended to make errors. In addition, the fetching of jobs by DD name in Wylbur is difficult to explain to a novice user. Before we created our SAS macros, we would teach SAS by demonstrating a simple program. Then we would say, ""We have to precede this program with a few lines called JCL, which give the computer information about your account number, etc."" Half an hour later, we would be telling paople about ramote numbers and bin parameters, and be looking at a classroom of blank faces. Beginners are frightened by JCL. They do not see the difference between ""IISAS.SYSIN DD o· and ""II SAS.SYSIN DD *."" What we gain in usi",Sugi-83-26 Cody Bernholc.pdf
", k '. [ ! I i I Julie RtrF!lle'. Manville Cbr:rorat.i.on Acquisition of srus at Manville Cbr~ation was initiated in the cap3.city Plannim at""ea of Data Processirg. Ib....ever, users througoout the canpmy heard of the cap3bilities of S/\S am wished to use SAS in atplications such as statistical analysis, reJ.Xlrt writing, grafhlcs, etc.. '!he R3n0t.e CJ:np..rting Services group, also tmder Data Processi.ng, was designated to train and supp::>rt users in Sl\S and eAS/GRAFH. R::S, an Infonnation Center group, trained users througl""out the ccmp:my in several aspects of Data Processim. '!hese are : usin:J '!'SO to canrmnicate to the IBM 3033 mainframe: using ~""""A ANA.LVZER as a report writing langmge: and, usin:J FDRFSIGHT for financial IOCJdelirg. An eval mtion WiS done on how to meet user trainirg requirements for SAS. T...o key topics were examined in detenninin:J an a:r;propriate edtrat.ion strateqy~ Oourse Presentation Alternatives; Scope of the course. Course Presentation Alternatives Trainin:J in the other user laI""gmges has usually been conducted in a classroom environment using an instructor from the REnote Canp.rt:.ing Services group. 'Itlis method had pt:""ooerl cunberscme in aspects such as course crlministration, tutor FCep:l.ration, etc . • 'lhus, several factors \Yere analyzed in detennining an effective W3.y of teaohin:J SA.c) to the user camnnity. '!hese factors were: - Cost Servicirg Remote ~ations - Ease of Administration - Ability to Randle an Initial Surge of Stooents - Cost Expmditures on materials outside the canpmy were to be kept to a minimun. TIlis!tas dtE to the company experiencing a recessionary pinch in sales, thus a push was on to keep outside costs da,.,n. ~er, a o:mple<te <rlvertisin;J departmalt, copy oenter, video and audio production facility, and stationery supplies were available within the canpmy. - Servicing Rerrote Locations Manville has CNer 100 plants across the U.S .• Traditionally, if rerronnel within the plants wishe:l to tak",Sugi-83-27 Stremel.pdf
"Eilee~ Driscoll •• ISSILB cornell O~il'ersit-y lBS7BlC7 A SAS course for beginning co.puter users should cover lore than the fundalentals of using SIS. The course should teach skills that are useful beyond SIS - what a cOlputer can and cannot do. what a statistical package is and what a statistical package can and cannot do. In addition to learning basic cOlputer skills such as editing files and sublitting jobs, students should be able to read a COlputer printout, know where to look for errors lessages in SAS and in their JeL, and learn to ask intelligent questions when they need help. Discussion of COllon concepts in statistical packages and guidelines for choosing statistical packages help stUdents to see SIS as one vf many ways to accolplish a goal and makes thel inforled users of statistical software. Data managelent and cost effective use of the cOlputer helps students to understand the organization of a computer and how cOlputers should and should not be used. Integrating these concepts into a basic SlS course producEs users who are confident in their use of SIS and in their use of the cOlputer because they learn basic principles of using both statistical packages and the cOlputer, users who can apply their knowledge to areas not covered by the course. DO IOU BEBE8BBB WHAT IT iAS LIKE ~ BB A BBG:rnBB7 Learning a skill which is totally unrelated to your past experienCES is difficult and frightening. lIany beginning SIS users are proficient in their fields.: ihey have heard that the cOlputer can help thel in their work and now they turn to you for help. Soae new users have little trouble learning hQW to USE a cOIPuter but sale are totally he1pless. These ~eople are totally d 7 pendent upon the teacher or the good w~ll of o~her users while ~hey try to a~sorh the new inforaation and put the p~eces of knowledge together into a coherent picture. By lelories of the traumatic times I went through ten years ago whi1e I tried to learn to use the cOlputer were jarred by",Sugi-83-28 Driscoll.pdf
"TEACHING SAS AS A FIRST COMPUTER LANGUAGE Jean Ussery, SAS Institute Inc. This paper discusses Introduction to Data Pro­ cessing Using SAS, the initial course in SAS/ Curriculum offered by SAS Institute. It de­ scribes the basic philosophy of the course, its design, content, and flow of instruction. The paper concludes with recommendations for any­ one developing a similar course. Introduction When the educational program of SAS Institute was established, most SAS users were experi­ enced in using computers to manipulate data. In the past, training offered by SAS Institute began with SAS Basics, a course which sets as part of its prerequisites at least three months experience in data processing, knowledge of an operating system, and the ability to exe­ cute SAS jobs on the computer. Today, many new users do not meet these prerequisites since SAS is the first (and perhaps only) software package they learn. These new users look to the Institute to provide SAS training for everything from logging on to sophisticated techniques for data analysis. The Institute has responded to this change in the user community with a curriculum approach to SAS training. There are three core cour­ ses in the Institute's curriculum: Introduction to Data Processing Using SAS, SAS Basics, and SAS Processing. While SAS Basics and SAS Processing are concerned with teaching the user SAS statements and techniques, the introductory course is concerned more with teaching the new user how to perform neces­ sary activities on the computer to create, exe­ cute, and debug SAS jobs. Design Considerations Before being able to do much work in SAS, a user needs to be able to perform certain tasks on the computer. Although specific cases may differ, these tasks include: 1. Log on to the computer. 2. Use a text editor and appropriate system commands to create and modify files. These files may contain data or SAS code. 3. 4. Issue a system command to associate a DDname with a raw data file. Perform general",Sugi-83-29 Ussery.pdf
"EDUCATION/CONSULTING PANEL Staff of SAS Institute, Peter Rikard, and Earl Nail The session moderator was Chapman Gleason, USDA. Five panelists answered questions from the audience. Two of the panelists were SAS users - Pete Rikard, Virginia Commonwealth University and Earl Nail, Union Carbide. The remaining three panelists were SAS Institute staff - Herbert Kirk, Director of Education and Technical Support; John Boling, Director of Video Training; and Mason Nichols, Manager of Technir.al Support. Mason Nichols: I'm just going to take a few minutes to discuss the developments of Technical Support during the last year. Last year we announced the availability of the Usage Note tape up to three times per year to the SAS representatives. Beginning with SAS 82.3, the Usage Notes will be back on the installation tapes. If you are also interested in obtaining a hard copy of the Usage Notes, this can be obtained from Bill Taylor at Biometrics. It is a service he is providing, and it costs $36 per year for a hard copy every other month. It contains the entire Usage Note file as we distribute it. So, if you are interested in getting that, you can fill out the form he has left at the registration desk and give it to Bill or any of the SAS staff and we'll pass it on. For those of you who were not at the General Session on Sunday, I announced two new systems that we have incorporated during the past year; one is a computerized mail system for call-backs and another is a tracking system that we enter problems under investigation into. If you call the Institute to report a problem, we'll be giving you a tracking number that you should keep until the problem is resolved. We are encouraging all sites to set up a support group to be the interface between SAS Institute and the user community, A lot of companies have already done this and feel that it benefits them substantially. Last year you asked for a mechanism to tell your users that there was a local support group and that use-J;:",Sugi-83-30 Rikard Nall.pdf
"CALIS - SAS COURSE AUTHORING LANGUAGE P. L. Olympia, Dar""i~ Systems, INTRODUCTION A course authoring language is a tool for developing computer-assisted instruction (CAl) lessons that normally takes care of managing the delivery of lesson frames, assessing student responses to questions and branching to appropriate segments of the lesson. Although a CAl course can always be written in any computer language. a course authoring language allows the author to concentrate on his lesson contents by taking over much of the drudgery of frame delivery, response assessment and branching. Some examples of authoring languages commonly used today are PILOT. lIS SCHOLAR­ TEACH, and GNOSIS. Of these, GNOSIS is not only easy to learn but also affords the author more power than PILOT or SCHOLAR-TEACH. However , GNOSIS is written in ALGOL and produces a lesson in ALGOL - a language that is not used or supported by many computer installations. CALIS is a course authoring language that is generally compatible with GNOSIS. It 1s a SAS program that writes SAS programs. The programs that it writes are CAl courses that are directly executable by students. We designed and created CALIS for these reasons: o to permit us to migrate many ot our GNO~IS lessons created in DEC installations run­ ning ALGOL to IBM installations running SAS o to create an authoring language that is extendible and just as powerful as SAS o to allow analysis SAS/(''RAPH us to take advantage of the data and graphics capability of SAS and to extend CALIS in the future. CALIS is only the first in a series of course authoring languages that are compatible with one another in terms of the CAl lesson scripts that they translate. When all the compatible course authoring languages are in place, a teacher need only create a lesson once. This lesson can then be translated by anyone of the authoring languages into a runnable CAl course in different high-level programming languages that will run in a microcomputer as well as in",Sugi-83-31 Olympia.pdf
"a large demand for new application programs. The backlog of requests for programming is growing in most companies. The best way to solve this problem is for end users to write many of their own programs in an end-user language. This paper examines several properties of good end-user languages and evaluates SAS against these criteria. Several areas where SAS can be made more user friendly are noted and the way the Federal Reserve Board is addressing these difficulties is discussed. The Problem In many organizations, the demand for computer services is growing at an extremely rapid rate. As machine costs decline (the cost per byte is cut in half every 18 months on the average), companies buy larger and larger computers. This new capacity should permit many more applications to be automated each year. The problem is that the demand for application programming is increasing faster than data processing organizations can supply additional pro­ grammers. There just are not enough skilled programmers to go around. The backlog of applications grows larger each week. Because of the inability to service all of the requests brought to them, data processing organizations often have to set up criteria to decide which projects will be done and which will be left unprogrammed. As a result, some computers may sit idle part of the day even though there are projects that could use this extra capacity but which are waiting for data processing to be able to get to them. There are three possible",Sugi-83-32 Schacht.pdf
"as been implemented which enables SAS consultants to impart in:formation to users in a timely f'ashion. Users can retrieve any information file, or script, with a simple SAS procedure or any uL.lll ty, program, or command ca­ pable- of' 14sttng a source partitioned data set member. For retrieval with SAS, a replacement for the default NEWS mod­ ule and a SAS procedure have been written. Scripts are ea::;lly maintained as members of a single source partitioned data set with standard system utilities and edi­ tors. Maintenance activities only in­ volve the scripts and no modifications to programs are necessary. Scripts may be maintained concurrently with produc­ tion processing activity in a large \.lser environment. Scripts are assigned names s'lggestive of their content. An INDEX script lists individual scripts and other indices, and serves as the derault script ror the SAS procedure. T~is facility is easy to install, main­ tain, and use, and permits efficient access to scripts rrom a variety of en­ vironments. The SAS procedure can be installed with minor modirication to support Help. Sample, or Usage Notes libraries. Program listings and instal­ lation procedures are available upon request. INTRODUCTION T~e need for a consultant-to-user com­ munication system is widely recognized. E~rl NaIl, SAS Technical Report Gl02, amply described the common problems of disseminating timely inrormation to the SAS user. Information such as local JeL, available documentation, known sys­ te",Sugi-83-33 Dickstein Shaughnessy.pdf
"A ProPOSAL FOR EVALUATING Sl\S SKILLS OF POTENI'IAL EMPIOYEES C & Royce Claytor, Virginia Electric & PcMer COOpany Ann S. Allen, RichJrond Public Schools Al M. Best, l-Edical College of virginia Rationale SAS has beca'!e a tool widely used in industry, ,government, and service organizations as well as research and education. It is in the fonner sectors thet Sl\S has enjoyed the nest growth as ""cxmverts"" trained .in AIrerican colleges and universities ~ out to bring the ease, brev;ity and enonmus capability of SAS to real-'i«>rld problems. There are many large ""DP shops"" where the virtues of SAS are widely appreciated and others where it is the pri.mal:y programuing language. Still, there are otrer shops where sareone was hired claiming to be a SAS programrer 'but what skills he did have made SAS perform far from optimally. The need for identifying catpetent, or at least pranising I SAS progranners continues to grow. Thus, many managers are faced with the task of inter­ viewing a nunber of job applicants and deteJ::mining in a short anDWlt of tine their programming capabilities. In this proposal we assune that an ""inter­ rrediate"" kncwledge of SAS is strongly desirable, if oot required, in the job descrip­ tion for the position in question. Other areas of cc:npetence such as managerial skills, proficiences in other languages, systems analYSis, and operations research are not addressed. other sources of infonnation exist for assessing cc:npetence in these areas, and this proposed technique would usually be but a part of an intel.View addressing all the points ena:rrpassed in the job description. Further we assume that the jab interview:rr (s) have a limited anount of tirre to devote to this task and. would therefore like to get it over with as soon as possible without running too great a risk of overlooking a premising individual. Fran this latter assumption proceeds the assertion that there must be key concepts or experiences which would separate the sheep fran the g",Sugi-83-34 Claytor Allen Best.pdf
"SAS has become one of the most widely accepted data management and statistical analysis packages in the United States. Furthermore, SAS appears to be in the process of achieving a global acceptance as one of the premier software packages in the world. A recent issue of SAS Communications ( Summer, 1982 has listed SAS distributors in many parts o~ the world. For example, SAS has now over 200 products installed in Japan, a very important market in the global competition. This paper examines how SAS is thriving in Japan, a vastly heterogenous culture where a software package written in English has been accepted as a major tool in an applications package arsenal. There are somc formidable obstacles to be overcome between the two cultures. For example, SAS manuals must be translated into Japanese versions to make SAS generally accessible to Japanese users. SAS will have to be modified and enhanced to accommodate the Japanese alphabet and Chinese characters which are integral parts of the Japanese language. Japanese managers can hardly be expected to read routine management reports annotated with English titles without grumbling. This paper focuses upon aspects related to cultural transitions of SAS from the Occident to the Orient.",Sugi-83-35 Kondo.pdf
"Bullcllng a Networl' of SAS Users for Education and Technical Support David R. Dolkart, American Hospital Association Introduction The evolution of SAS usage within a corporation falls into three, basic stages: beginning, middle, and advanced (figure 1). The beginning stage follows the installation of the SAS Basics package and is characterized by first time users who depend largely on individual efforts to design and debug their programs. The emergence of experienced users who train and provide technical support to others marks the middle segment. Advancing beyond this segment requires a corporate effort to centralize SAS education and technical assistance by hiring a full-time: support staff. When it is difficult to fund a full-time staff, the user network is an alternate educational and support vehicle for moving a cor­ poration toward the advanced SAS level. The Education of $AS U •• r. within a Corporation A fundamental corporate goal is to shrink the relative time and effort necessary for SAS users to reach beyond the novice level and grow to the experienced and expert levels (figure 2). The SAS user network supports this goal by rein­ forcing SAS cowsework1 with tutoring, seminars, and brief­ ings (table 1). SAS Institute, Inc. products provide valuable support to net­ work~ lacking sufficient manpower and expertise to meet users' educational needs. Depending on subject material, cost, flexibility, and versatil­ ity requirements, a corporation can arrange for SAS in-house training 2 or for SAS video training. J On the other hand, net­ works with the ""right""4 size and background have the ingre­ dients to provide SAS training at a corporate or one-an-one level. For SAS users to evolve, a network must plan for continuing education through seminars and briefings. In-house seminars provide the right atmosphere for cross-fertilizing knowledge: • Through the Sharing of Novd Approaches to Problems • By Disseminating Information on Companywide and Other Data Bases SAS",Sugi-83-36 Dolkart.pdf
"DISCREPANCY ANALYSIS: USING SAS TO MJNITOR PlIDGRAM PARTICIPATION Richard Williford Texas Education Agency INTlIDDUCfION Statutory law as well as regulatory rules often require local governments and private businesses to monitor discrepancies in minority employment and/or participation in federally-funded programs. State Education Agencies (SEA's), for example, must monitor vocational education program student enrollment by equity category. Equity categories and their subcategories include SEX Male Female ETHNICITY White Hispanic Black Asian or Pacific Islander American Indian or Aleutian HANDICAPPED DISADVANIAGED LIMITED-ENGLISH PlIDFICIENCY (LEP) PlIDBLEM STATEMENI Federally-funded vocational eilllcation programs exist in over 950 Texas local education agencies (LEA's), or school districts. Mbre than 1,000 campuses are involved with usually two or more major vocational programs offered. In the con­ text of this paper, a major vocational program is one identified by either the fiTst two or digits of a six-digit code. Examples of major vocational programs include Agriculture, Distri­ butive Education, Useful and Gainful Homemaking, and Office Occupations. MJst campuses offer at least two programs, while many offer more. The combination of campuses and programs currently exceeds 30,000, although the LEA/program combinations is nearer 4,300. All of these LEA/program combinations must be monitored for equity. A tradeoff exists in trying to optimize monitor­ ing efforts, too. Which programs are less equi­ table: those with a greater proport; on of stu­ dents being discriminated against or those with greater absolute numbers of students being dis­ criminated against? The problem is to try to account for both factors while at the same time ranking individual LEA's according to the apparent amourrt. of dlscrlminatlon present. The higher ranking LEA's will be examined more closely be­ fore the lower ranking ones. 184 Thus, limited staff. time, and resources can be used most",Sugi-83-37 Williford.pdf
"SAVING THE BEST FOR LAST? FIRST? IN THE MIDDLE?: Alternative Approaches to Teaching SAS and Beginning Data Processing James D. Hosking and David H. Christiansen The University of North Carolina at Chapel Hill For more than a decade, the Department of Biostatistics has taught a one semester service course (BIOS 111, Introduction to Statistical Computing and Data Management) designed to teach graduate students in the School of Public Health sufficient computing skills for the completion of their degree requirements. The course has no prerequisites, and is taken primarily by first semester graduate students with no prior exposure to computers. The contents of the course. described in detail below. include: an introduction to computers, using the facilities of the operating system (currently MVS JCL and TSO), an introduction to data processing concepts and techniques (using SAS) and an introduction to statistical computing (again using SAS). A major problem in organizing such a course is the complex network of interrelationships among the concepts to be learned in a short period of time. For example. running the simplest SAS job requires the student to have a basic conceptual understanding of computer hardware, an operating system, and data sets and data representation. as well as SAS itself. The optimal depth of coverage and ordering of these topics is not obvious. Although the course is popular (70-100 students three semesters a year) and generally well received, we have never been completely satisfied with any of the orders of presentation of the material that we have tried. This paper will present four of the approaches that we have tried over the years. These include: teaching the operating system control prog~ams (JCL, TSO) before, after, and in the middle of teaching SAS; teaching SAS programming and data set manipulation before, after, and in the middle of teaching data input; and teaching statistical computing before, after, and in the middle of the other topic",Sugi-83-38 Hosking Christiansen.pdf
"URBAN SPATIAL STRUCTURE AND GASOLINE CONSUMPTION Robert M. Ray, Research Triangle Institute Introduction This paper describes a study recently conducted at the Research Triangle Institute for the U.S. Department of Transportation. The primary objective of this research was to identify spatial patterns of urban develop­ ment strongly correlated with rates of gaso­ line consumption across existing U.S. cities. Both statistical and graphical analyses were conducted. Several new spatial measurement methods were developed by the auth.or. All statistical analysis was done using SAS. The GMAP procedure of SAS/GRAPH was used (along with other mapping software) to display ob­ served urban land development patterns. Study Rationale Why is it that people in Houston, Atlanta, and Grand Rapids use more gasoline than people in Buffalo, New Orleans, and Milwaukee? To explain such differences we must consider numerous factors such as local economic conditions, public transportation availabil­ ity, climate, terrain, and urban spatial structure. By urban spatial structure we mean the physical layout of cities, i.e., how close people's homes are to their work places, schools, shopping centers, restaurants, and recreation areas. Since one of the goals of urban planning is to gUide city growth along socially desirable courses, uncertainties surrounding long-term gasoline supplies make it important that planners understand rela­ tionships between urban spatial structure and gasoline consumption. Since the 1973-74 fUf'l Ct""1S1S, a number of studies have attempted to explore these relationships statistically. (For examples, see Watt, 1978; Stewart and Bennett, 1975; Keyes and Peterson, 1977.) However, all of these studies have encountered two sets of difficulties: (1) problems stemming from the lack of comparablf' data acros~ cities describ­ ing non-residential spatial structure, and (2) problems related to the difficulty of measuring numerous important aspects of spatial structure in gene",Sugi-83-39 Ray.pdf
"I. SOFTWARE FOR STATISTICAL GRAPHICS - AN OVERVIEW P.M. Caporal and G.J. Hahn, General Electric Company INTROOUCTION AND OVERVIEW Output devices, such as CRT dis­ play terminals and special plot­ ters, which are now available for high-quality graphics, pro­ vide the analyst new opportun­ ities for presenting and explor­ ing data. In addition to sum­ marizing data and performing statistical evaluations, the computer can be used to present the results through attractive and meaningful graphical dis­ plays. These displays are fur­ ther enhanced by the increasing accessibility of color graph­ ics. As a result, individuals with limited statistical train­ ing can obtain simple, but in­ cisive, graphical presentations of the data, while a trained an­ alyst can gain an improved un­ derstanding of complex data by using graphical tools for ex­ ploratory data analysis. More­ over, obtaining such displays on a computer, rather than manual­ ly, can significantly reduce the elapsed time to get the desired graphics and allows the analyst to operate in an iterative man­ ner. The marriage of statistical data analysis and high-quality graph­ ics has become possible through the development of statistical graphics software by software houses, graphics hardware sup­ pliers, universities and oth­ ers. Two previous papers (Caporal and Hahn [1981a and 1961b]) described software for high-quality graphical dis­ plays. These papers dealt prin­ cipally with offerings for pres­ entation graphics, many of which have only limited capabilities for statisitical data analysis. In this paper, we concentrate on software that permits the user to integrate the data analysis and data display functions, i.e., offerings that have non-trivial statistical, as well as data display, capabilities, for a wide variety of computers, ranging from desktops to main­ frames. We will, however, deal 199 only with software that provides high-Quality graphical output. Thus, we will not, for example, consider programs that",Sugi-83-40 Caporal Hahn.pdf
"I~TERACTIVE CONTROL CHARTS USING SAS82 David C. Schlotzhauer, Union Carbide The demand for some American products is begin­ ning to ebb as foreign competition increases. Quite the opposite is occurring in Japan, where in many cases higher quality products are being produced at lower cost. How do the Japanese do it? Many business leaders today are trying to find the answer to this question. One of the more important factors seems to be the widespread use of quality control tech­ niques. American businesses are beginning to see that pairing these techniques with statis­ tically designed experimentation provides a key to increasing the productivity of our pro­ cesses. The computer also has an important role in business today. Its speed and accuracy could be of great help in applying quality control methods. For instance~ an interactive. prompt­ driven system to produce control charts could be a very useful application. This paper dis­ cusses the development of such a system. CONTROL CHARTS Perhaps the best-known quality control device is the control chart. Control charts are graphical tools based on statistical theory that allow us to monitor the performance of a process. The process can be anything from the baking of bread to the production of parts for nuclear weapon~ tu the generation of paperwork in an office. While the process may be complex, starting a control chart on the process is very simple. Whatever the product~ consecutive samples (generally of fixed size) are taken. If some feature of interest can be measured on a con­ tinuous scale. then the average and range of each sample are obtained. The average of the sample averages and the average of the sample ranges are calculated. and are used to compute upper and lower limits. We then plot the sam­ ple averages and ranges with their respective limits. If any of the values fall outside of these control limits, the process is said to be ""out of control."" In other words, the process is not behaving in a consisten",Sugi-83-41 Schlotzhauer.pdf
"GRAPHIC COMPARISON OF INSECT POPULATIONS Lawrence W. Grimes, Clemson University Hoke S. Hill, Clemson University INTRODUCTION SAS-GRAPH GMAP procedures were used to provide a visual apprasial of level of infestation and movement of boll weevils in cotton fields. The initiative was generated from a study designed to evaluate the effect of winter trap placement (infield vs boarder trap locations) on subsequent summer populations. During July and August, pheromone bated traps were placed in fields at a density of three traps per acre and weevil counts were taken at weekly intervals. Both surface and choropleth maps were produced to depict weevil activity during four of the intervals. The data and maps presented here are meant to demonstrate the graphics used and are not necessarily representative of actual data collected. Standard statistical procedures were used to compare weekly summer catches for the two winter trap placements. PROCEDURES The x,y coordinates for field boundaries and trap locations wer('. entered using a digitizer and read as separate SAS data:;ets. The count data were coded as 0 = none, 1 = 1 to 3, 2 = 4 to 6 and 3 ::. greater than 7 weevils and merged with the trap location coordinates . ., Generating surface maps (Figure 1 shows the accumulated levels), then, was straight forward in that boundary and trap data were combined and plotted according to the program statements given in Table 1. Although dispersion and relative magnitude were obvious from the surface maps, absolute magnitude was not and change from week to week could not be shown easily without separate maps for each week. By using the choropleth map (Figure 2) with various PATTERN statements, week by week catches were combined in one plot showing rate of infestation as well as movement within the field. Data were entered as before, however, for each trap location, a polygon (in this case a square) was computed. The polygon was divided into as manv seoments (triangles for these plots) as",Sugi-83-42 Grimes Hill.pdf
"A MACRO FOR INCLUOING A RESPONSE GRIO ON SAS/GRAPH G30 PLOTS John O. Hackman, N. C. State University SAS/GRAPH PROC G3D produces a good picture of a response variable (z) as a function of two independent variables (x and y). However, the plots are hard to interpret because of the difficulty in comparing values on the response surface to the z-scale given on the lefthand side of the plot. Interpretability is enhanced by adding a reference grid of z-values around the plot. The algorithm used by PROC G3D was written to plot a complete x*y matrix having a unique value for z. The plot can be quite strange in appearance when multiple z's are present for identical x, y values. In order to facilitate plotting of the grid, all x, y points must be unique with the grid slightly larger than the response surface. The reference gri d resembles a square football stadium about the response surface, with x,y values farther from the center for larger 2'S. Although the reference grid and the perimeter of the response surface have dif­ ferent x~y values, these values are so nearly equal that the difference cannot be distin­ guished when they are plotted. A macro RESP has been written to generate a response surface and a reference grid (Table 1). This macro uses 2 user defined macros whose names and variables must be as described below. The macro produces a SAS data set WORK.E which contains the variables X~Y and Z. This data set can then be sorted. stored and plotted. MACRO XYZMM XMIN=nj XMAX=n; XING=n; YMIN=n: YMAX=n: YINC=n: RU=.OOl: ZMIN=n: ZMAX=n: ZINC=n: DROP XMIN--ZINC: where n is any number. This macro gives the minimum, maximum and increment used for gener­ ating x,y and z values. The variable RU is needed to account for rounding errors when non­ integer increments are used. MACRO EQUAT Z=K + f(X,y); % This macro contains the equation(s) for the response variable (Z) as a function of X and Y plus a constant. A general format of using macro RESP is given in Table 2. Table 2 also",Sugi-83-43 Hackman.pdf
"rgy (DOE) Health and Mortality Study maintains a large dynamic data base on a DEC PDP-IO. Demographic, employment, exposure, health, and vital status information is being collected for approximately 600,000 individuals who have ever worked for DOE or DOE contractors (or their predecessors) at 76 faci­ lities nationwide. The epidemiologic research using these data involves many scientists work­ ing on a variety of projects concurrently. The scientific investigators continually need to monitor items such as the status of data col­ lection, error correction, and vital status deter~ination for their projects. The quarterly report of the status of the data base by faci­ lity is in itself quite extensive, up to 200 pages in length; an example is shown in Figure 1. Since this information is usually needed for progress reports and scientific presentations, the research scientist has to abstract data from the report and have the data prepared by a secretary, technical illustrator, or graphics programmer for visual simplicity. As the size of the study data base increases, the need for informational reports increases; and as graphics hardware and software becomes more readily available, graphics programmers are becoming increasingly involved in this preparation. It was determined that, since most of the requests for graphics are repeated frequently, an auto­ mated system should be developed to abstract the data and construct the graphics programs. To maximize its usefulness, such a syst",Sugi-83-44 Worrel Hudson.pdf
"-Packard Company Abstract Business graphics systems such as SAS/GRAPH have made high quality graphics available to business professionals of varying levels. Many of these profession­ a1s have never had any graphics training, and yet in using the easily accessable new software they are preparing important graphics presentations. The persuasive­ ness of these graphics may be enhanced by use of basic graphics design principles. Some of these principles have been described in SUGI proceedings before (notabl¥. the selection and use of color was discussed at length at SUGI '82); however, principles of composition are rarely taught to business professionals who prepare business graphics. This paper will describe three elements of composition in ter.ms of three para­ digms and will illustrate their use ,n examples culled from the art world and as applied to Computer graphics. Use of these principles in selecting type fonts and graph types should allow profession­ als to prepare more persuasive graphics, without suffering from conflicting mes­ sages from subliminal sources. Principles of Composition How frequently we hear the old cliche of two people in an art museum, standing front of a piece of modern art and saying ""Yes, but what does it mean""? Graphics, which is the basis of visual art is like music; just as you must develop an ear for music to be a good composer and evoke desired feelings, so must you develop an eye for graphics if you wish your graphi­ cal presentations to achie",Sugi-83-45 McGregor Nelson.pdf
"FROM BASIC TO UNUSUAL SAS/GRAPH APPLICATTONS C. Royce Claytor and N. H. Wooding, Jr. Virginia Electric & Power Company The advent of color graphics to computer technology has made a significant impact on the business world. SAS/GRAPH was introduced in 1980. offering a graphics package with the additional benefit of all the programming capabilities of SAS. At Virginia Electric & Power Company, we began using SAS/GRAPH in the late summer of 1980 in conjunction with a 1051 CALCOMP plotter. As the usage of SAS/GRAPH increased and as IBM color terminals and print­ ers came on the market. it was decided to acquire them and to enlarge our potential in the graphics area. In the summer of 1981, the first IBM 3279 tubes and 3287 graphics printers were purchased, leading the way for wider usage of color graphics in the company. The graphs were used [or slide prt!l:ientations, monthly Teportl:i, and ba~dC'. informational purposes. As the need for slides increased, we moved from photograph­ ing the screen in a darkroom to using a MATRIX INSTRUMENTS Color Craphic Camera :Hodcl 4007 which connects to the tube by cables and takes color photographs on many types film in size up to B"" x 10."" The graphs presented in this paper origi­ nated from different departments and SAS pro­ grammers at VEPCO. None of the graphs, however, will portray actual corporate information. Though some of the graphs are related to a utility and may utilize electrical terms, the concepts of manipulating data and using graphics opti ons to achieve a desired result should all hold true. In order to create color graphics that suit the needs of any organization, the person responsible needs to have a fairly clear concept of the graph to be created. Next, that person should know how to program the graph with SAS/GRAPH. Third, knowledge of SAS as a pro­ gramming language allows the data to be manipu­ lated into the shape necessary for execution of the graph. And, last, knowing some of the finer points and tricks o",Sugi-83-46 Claytor Wooding.pdf
"USING SAS/GRAPH TO PRODUCE SCHEDULING CHARTS Ron Boehm, Sandy Hemphill, ACT Computer Services Ltd. Mike Atkinson, University of Victoria INTRODUCTION In most organizations or industries, it is necessary to carefully plan and moni­ tor involved projects. These projects often consist of a number of tasks which must be completed within specific time frames. To effectively manage such projects some type of sCheduling chart is required - something that will give an accurate overview of the lifespan of the project. computer Ser­ vices had a requirement for such a sched­ uling chart. The chart was currently being done by the client by calculating the coordinates for all task start and One of our clients at ACT end dates, grid lines, titles, and task positions, then using a BASIC program to drive a plotter. The entire process took up to two weeks to complete using this semi-manual method. In response to this need, the Information Centre staff at ACT developed a full-screen application which guides a non-data processing person who is unfa­ miliar with SAS through the steps of pre­ paring such a scheduling chart. With the use of dialogues, the user is prompted on the types of tasks to be performed, the time pe~iods involved for the tasks, and any special notes or titles that are to appear on the scheduling chart. An addi­ tional feature of this system is the abili ty to overlay a ""cash-flow"" plot upon the project grid. This option graphically displays the fUnding of the project throughout the effective time period of the scheduling chart. A com­ plete grid is displayed in Figure 1. THIS IS THE MAIN HEADING 91-1983-18 DESCRIPTIVE TITLE II DESCRIPTIVE TITLE 12 DESCRIPTIVE TITLE 13 DESCRIPTIVE TITLE I~ PHASE 1 SYSTEM IMPLEMENTATION DETAIL DESIGN CONSTRUCTION AND TESTING INSTALLATION AND TRAINING CUTOVER TO PRODUCTION \It PHASE 2 SYSTEM IMPLIEMENTATION DETAIL DESIGN CONSTRUCTION AND TESTING INSTALLATION AND TRAINING CUTOVER TO PRODUCTION ~ PHASE 3 DESf'RIPTION PHASE 4 DESCRIPTION",Sugi-83-47 Boehm Hemphill Atkinson.pdf
"With the increasing variety, features and low cost of graphics hardware. it is becoming critical that general user software be device independent. SAS/GRAPH provides this advantage. This paper describes a software frontend to SAS/GRAPH which allows users with access to an interactive graphics terminal with 1 ight pen, joystick or crosshairs to construct nonstandard SAS plots incorporating text, lines and shapes. This software generates a SAS/GRAPH procedure which constructs the plot on the desired device. Both SAS and nonSAS users will find this software to be a productivity enhancement tool since it permits the rapid development of word slides, flowcharts and Gantt charts - to name a few.",Sugi-83-48 MacDougall.pdf
"A major responsibility of financial analysts is to present the organization ' s financial picture to management in a concise and descriptive manner. At Texas Instruments, this responsibility has been translated into a Financial Plotting System for the collection, calculation, and graphing of monthly and year-end financial data. Designed for the non-programmer, the system functions in an in­ teractive environment and produces graphs according to user specifications. This paper out­ lines the development and structure of the system, its use by the financial analyst and business man­ ager, and the advantages of its operation.",Sugi-83-49 Vendeland.pdf
"radio-telemetry studies of animal location and movement are made, the re­ searcher wishes to display animal sighting loca­ tions, home range, and habitat utilization, and relate these to maps of the study area. Since it is virtually impossible to scale PROC GPLOT out­ put to exactly match the scaling of available area maps, the researcher needs to be able to create a map with the home range and habitat ut­ ilization superimposed on the study area map. This can be accomplished by digitizing the key features of an available map of the study area, giving a map dataset which can be merged with the animal sighting location and home range boundary point dataset. Then PROC GHAP can be used to generate a comprehensive choropleth map of the study area showing habitat types with home range characteristics superimposed. I NTROOUCTI ON Wi ldl ife biologists are freqqently inter­ ested in describing animal location and movement patterns within a study area. Many studies are made in which an animal is caught and a radio transmitter is attached in order to monitor the animalls movements. By taking directional read~ ings of the animal 1 s location from two or more fixed reference points, approximale ""map"" loca­ tion can be determined. Each of these locations can in turn be translated into (X,Y) coordinates relative to a chosen origin. From a sequence of such location points, the wildlife biologist is interested in determining the animal IS approxi­ mate home range, describing its movement,",Sugi-83-50 Hill Grimes.pdf
"The u~e of radio telemetry technique3 in tracking fish and wildlife in the fiela generate3 research data which are langely geographical in nature. A time ordered series of location fixes can be used to study, for example, animal behavior patterns, habitat preferences, ana responses to environmental ohanges. This information i3 most easily interpreted visually when represented as location fixes plotted on a map of the study area. SAS/GRAPH mapping procedures, designed for area response maps, are not directly applicable to mapping single point locations. However, SAS MACROs can be prepared which use the GPLOT procedure to produce labeled maPS of the study area overlain with telemetry research data in a variety of formats. Examples include dis_crete and time-ordered plots of individual subject location fixes, plots of all location fixes for a class of subjects (e.g.- species), and color/symbol coded plots used to distinguish location fixes made under differing enviro~ental conditions or in different time periods. The use of GPLOT to draw custom outline maps is discussed, as is the HACRO technique which provides easy, interactive mapping for the researcher. 1.0",Sugi-83-51 Rinehart.pdf
"EXPEInENCES OF A SAS GRAPflICS USEf< John L. Hall, Jr. GTE Data Sen-vices, Inc. has installed SAS 79.6 with the SASIGRAPH op t i on. This paper shall describe Dllr introduction into coLor graphics .nd the creative uses we have developed. AIIl()""tIg th~~ top ics to be discussed are the following appt ieat ieHls: (1) A cUn-tHlt <lPpli~:<ition tt;S""es Proc GSLIDE to provide data for presentations. lhis procedure is very adaptable to providing a variety of instructional foils where color emphasizes the key points_ The c:ost of l-epl-oduc i ng these fo i loS"" i.s: st i II E.'xpens i ve and the demand fOl- COlO1 r~produc:ing e'tuipmemt is not as prevelent as we wDulel like. (2) Another application uses Proc GPLO\· to provide color plots. The information can be pLotted for presentation effec t i Vf;m,""~S;5""., (3) A popular use is th"" 'Pi,,' chart .produced ~y Proc GCHAR1. ThiS chart shows the information for multipLe appLications. Introduct ion. General TeLephone & Electronics COl-poraticlll (GTE) IS .d Large, muLtinational company with business enterprises that incLude telephone Clperaticm.s-, cOfflmunicdtions products, electrical and electronic P1Moducts, and telecommunications services. GTE is the parent company of more than 60 comMunications, products and service subsidiaries with operations in 40 states dnd 19 cOllntries, and sa les aPPH)<.'""Ich i ng $i 0 b i I. l i (m dnnualLy. GTE's w(Jl""·ldwi(h .. oPf.'IMaticlns .:.re divided intn fum:tion.ll grt..1t!ps, incluclil1<I' GTE Telephone Operations, ~. E COffimmunications Products, G·rE ELectrical Products, Gl·E Telenet and GT~ Laboratories. The GTE T(>le-~ph()nE! Upe-~rati()ns qn)up i n(: ludes 19 te lepllone COMPanies, comprising the largest I ndepen(1ent (non--Bel.l) telephone system. GTE Data Services provides a Variety of data prorf.'ssing 5prvicE's to these ie l(-?l~horH~ c:ompan i e.s through a network of :strategic<1lly located qata centers. These centers have <:lCC(~.S""5 to SAS. GTE Data Service.~;, Inc. 265 GTE",Sugi-83-52 Hall.pdf
"Congretis ABSTRACT A graphics package designed for production of finished output from high­ level commands can't be expected to anticipate every feature visualized by a user for a particular graph. Neverthe­ less, small changes in the standard product would often make a hi~hly acceptable graph out of an unuseable one. This paper describes computer methods we are using to ""customize"" SAS graphics produced on Tektronix devices. One method involves interception and modification of graphics instructions generated by SAS/GRAPH procedures. Other methods involve manipulation of the SAS user interface. Examples of customized graphics methods and results are included, and problems overcome, and not overcome, are discu~Bed. Tllrough computer-customized SAS graphics we are often able to save the time and expense of manual methods or extensive graphics programming. RESEARCH FOR CONGRESS At the Library of Congress, subject specialists in the Congressional Research Service (CRS) are using SAS graphicS to an increasing extent to help present the results of their research to Congress. The results must be presented with clar­ ity and accuracy, and witllout any trace of unfairness. Anything that may lead to misunderstanding even on casual inspection is avoided. A g~aph is exam­ ined closely to see whether the point it illustrates comes through clearly enough or whether a misleading impression may be created. Often modifications are needed, with truth in graphics as the goal. Given the emphasi",Sugi-83-53 Fromme Bury.pdf
"Since its acquisition, SAS/GRAPH has proven to be a useful tool for professional, non­ professional, EDP and non-EDP persons alike. Some of the experiences gained so far have been both unexpec ted and profound due to the quantity and diversity of data involved. This paper is intended to share these experiences by describing how SAS/GRAPH seeded ~ grew and became recognized as a valuable software product within Statistics Canada. The topics will include: introducing SAS/GRAPH to the user community, providing information and education needed immediately, creating an awareness among potential users. supporting ""key"" preparing for applications. projects, the wider",Sugi-83-54 Gratton.pdf
"CONSTRUCTION AND MANAGEMENT O~ A MEDICAL RESEARCH DATABASE USING RAQL AND SAS Ted G. Van Rossum Jacob V. Aranda McGill University - Montreal Children's Hospital Research Institute INTRODUCTION The Developmental Pharmacology and Perinatal Research Unit (DPPRU) at the Montreal Children's Hospital, supported by a grant from Health and Welfare Canada, undertook an intensive prospec­ tive study on the epidemiology of drug utilization and adverse drug reactions in the newborn infant. The DPPRU monitored 1200 babies in the neonatal intensive care unit over a 5 year period, recording pot-ient and mother history, medications given, lab tests taken, feedings, intra­ venous sol utions, and physical examina­ tions. The data totaling over 200,000 records, stored in 5 large SAS files, was designed to be an ongoing source of information for the determination of incidence, types, patterns and factors influencing drug utilization and adverse drug reactionsa The statistical analysis focused on the calculation of crude incidence rates and relative risk factors for toxicity to the newborn's sensitive organs when certain drugs were given. This type of analysis required that for each drug under study, the survey population would be divided into 3 sub_populations: study, control, and exclusion. Since the criteria defining each sub-population were different for each drug under study, it was recognized that a powerful and flexible method for sub-population retrieval was essential. Gi ven these data management require­ ments, it was decided that a relational database system, because of its flex­ ibility, simplicity and power would be optimal. Since SAS was chosen to handle the statistical analysis, RAQL a new relational query language embedded in SAS, was chosen to perform the sub­ population retrieval. Together, SAS and RAQL provided a comprehensive relational database management system. This paper , using examples from our study, will cover three important topics. The first topic is a disc",Sugi-83-55 VanRossum Aranda.pdf
"The terms Management Information System (MIS) and Decision Support System (DSS) have been used for severa 1 years. Recent ly, however, they have been given new emphasis with the advent of user-oriented database management systems (DBMS), personal work stations, computer graphics, and information management. This paper describes the basic components of MI S-DSS and discusses thei r benefits to an organization. The importance of a planned approach toward MIS-DSS is discussed along with several approaches toward the planning process. The use of various tools and techniques for the rapid development of MIS-DSS systems is described. The use of SAS as an aid in the development process is then discussed. Finally, an approach being taken by the Pharmaceut i ca 1 Research and Deve 1 opment Division of The Upjohn Company toward the development of MIS-DSS is described as well as the role that the Statistical Analysis System (SAS) plays in the process. 1.",Sugi-83-56 Johnson Sinkula Schultz.pdf
"SAS provides a powerful implementation language for systems which are designed to be extensible, that is, where the users may extend and customize the capa­ bilities of the systems by writing and then executing new functions. SAS is easy to master and can handle high-level constructs. This makes SAS ideal for writing and executing extensions in real time. SAS 82 will further enhance this capability. This paper will investigate some areas where the extensible features of SAS may be put to greatest benefit. Suggestions for additional enhancements to SAS to further facilitate these kinds of systems will be made. In particular, the paper will focus on the use of SAS in (l) an extensible edi­ tor, (2) a dynamic graphics program, (3) an operations research system, and (4) an automated documentation generator. This paper assumes the existence of SAS, SAS/GRAPH and SAS/PSP in the working environment.",Sugi-83-57 McGregor Nelson.pdf
"A DYNAMIC REPORT WRITER. FITTING ONE STRUCTURE TO MULTIPLE OUTPUTS Ann K~nnedy Handl~r. Bureau of Labor Statistics Jesse Gary, ORI. Inc. One of the problems t~at occurs when varicus users desire multiple windows on the same data is how to frame their different requirements to avoid a redundancy of applications. Th i 5 paper proposes one approach 11 J to the solution of that problem--a Dynamic Report Writer (DRW) program which meets the following objectives: 1) to generate a set of customized reports which present essentially the same data from different perspectives; 2) to generate the same or similar reports using different data; and 3) to reduce duplication of'code w~ile retaining the fleKibility to produce variable output. The strategy employed to meet these objectives involves deter~ining t~e common structure among the various reports, ""constructing"" the data to fit the report structure and designing a program structure which although static appears to function dynamically. The DynamiC Report Writer program conditionally selects and constructs different configurations of data by accepting user-specified parameters through an interactive query and job submission facility. The DRW then builds the report-writer module corresPonding to the specified report or set of reports from prewritten components allocated and modified at run time and e~ecuted with a %INCLUDE statement [3 J. STRUCTURE OF THE REPORT T~e DYnamic Report Writer was developed to prodUce the application called the Initiation Control Report tIeR) which is used to monitor the collection of data for the Rental Equivalency Housing Survey. The ICR is composed of a series of tables ~t v~rious levels of aggregation. Each cell in the two-dimensional tables contains the number of housing units according to type of TENURE and type of RESPONSE. The TENURE of a housing unit is one of three types: ""Renter"", ""Owner"" or ""Undetermined""; 295 the RESPONSE code given a is one of more than thirty as: ""Interview Complete",Sugi-83-58 Handler Gary.pdf
"re useful for producing simple descriptive statistics, the appearance of their output is not suitable for most publication standards. The CAMTAB system, on the other hand, enables camera-ready tables to be produced directly within SAS. This system eliminates the need for data to be transcribed from printouts and then retyped. The main elements of the CAMTAB system include a cataloged JCL procedure, a SAS FROC (LMSTAB) that summarizes the data, and a generalized SAS DATA step (TABPRINT) that does the actual formatting and printing. Counts, vertical and horizontal percents, means and medians may be produced and mixed within a single table. Among the other features offered by CAMTAB are subtotaling, selective underlining of portions of titles and footnotes, and rounding and formatting cell values. II. BACKGROUND Westat is an employee-owned research corporation providing contract research and survey services both to U.S. Government agencies and to institutional and business clients. For the past several years, Westat has provided the data management and analytic support for the Department of Labor~s Continuous Longitudinal Manpower Survey (GLMS). The CLMS is an ongoing study designed to evaluate the effects of the Comprehensive Employment and Training Act (CETA) by conducting and analyzing periodic national surveys of program participants. As part of the eLMS project, Westat has published more than 20 reports detailing the demographic characteristics, earnings and employment expe",Sugi-83-59 Rhoads.pdf
"Large multinational corporations have a great deal of difficulty in consolidating financial information. This problem is com­ pounded in organizations which change manage­ ment unit reporting frequently. Harris Corporation has developed a system used both for production reports and ad hoc inquiries which allows for frequent change in accounting structures and is driven by nonprogrammers on the accounting staff. The key is the use of PRoe FORMAT and a SAS code generator. In an interactive session. an accountant builds a PROC FORMAT containing a hierarchy of accounts or corporate entities. A file or series of hierarchical files may then be built merely by specifying the row, column, and file (page) variables. The system then generates the SAS code, using the previously built PROC FORMATS. which will roll up the hierarchy and produce the report files. The system has eliminated dozens of manual reports, improved the response to changes in reporting require­ ments. and eliminated the need for a costly and complex hierarchical general ledger. Only the detail accounts are required in this system. Background Creating SAS programs with another program is not a new concept. The Proceedings of the Seventh 'Annual SUGI Conference contained several papers on this topic. Dennis LaRue's paper most closely parallels the concepts discussed in this paper. l What the reader may find to be unique about this application is the ease with which SAS can be coded to produce complex hierarchical files for financial appli­ cations. Add this capability to an environment in which accountants are working directly with an electronic spreadsheet and the result is a powerful and flexible analytical tool.",Sugi-83-60 Gochenouer.pdf
"Computer-generated reports need not be dull and difficult to read. The IBM 6670 laser printer has considerable flexibility, hut. i~ ~um­ manly llsed for text processing. With the use of some simple techniques SAS can be made to produce high-quality reports that appear to have been professionally typeset. For applications wherein SAS output would normally be retyped to produce final drafts of reports, it is usually possible to eliminate t.hi~ step. thereby saving much time and completely eliminating transcription errors. Sample applications are presented below to demon­ strate the use of the DATA step and the PUT statement to control the operation of the IBM 6670.",Sugi-83-61 Ransen Mills.pdf
"A Data Base for Reporting on Putient Flow in a Clinical Group Practice of Medicine Priscilla VanGrevenhofl • Ronald Anderson, Philip Reilly, Susanne Daood Mayo ClinIc A data base was developed to track patient activity within the Mayo Clinic, a large group practice of medicine. The data base, comprising information about patient visits within over fifty clinical specialties, is updated monthly. Statistical Analysis Systems (SAS) produced by SAS Institute, Inc., was selected to edit and manage the data base and to generate periodic administrative reports. Background The Administration of clinical practice at the Mayo Clinic required information on patient visit statistics on a Clinic-wide basis for future planning. Although tied together in one group practice, each clinical department is a separate unit. These departments, along with AdministratiDn, would benefit from the reporting of this information. Some elements of the data base were historically handled by manual methods of tallying for departmental use and then entered unedited into a data set for administrative reports. This data was incomplete, insufficiently edited, and the distributed data collectiDn resulted in cumbersome data base management. The use of moJ~rn data base management was sought to provide more complete, more accurate, and more current patient visit information. Patient tracking is used within the Specialty groups to: 1. Maintain appropriate levels of staffing 2. Improve scheduling 3. Improve departmental procedures. Patient tracking is used by the Group Practice Administration tD: 1. Improve the interaction of departments 2. Analyze work load variations; i.e., seasonal, economic, etc. 3. Plan space utilization 4. Plan staffing needs The success of the system depends on its ability to produce complete, accurate, and current reports for the monthly meeting of various committees. System Overview The 'Patient Visit Analysis' data base was designed by the Administrative Services and Systems and P",Sugi-83-62 VanGrevenhof Anderson Reilly Daood.pdf
"SAS macros has been written which allows users to evaluate the data acquired from a stability program. The package first reads the data from an ASCII disk file, prints descriptive reports, and creates graphs using SAS/GRAPH. Next, the packag2 fits several linear models to the data and determines which model fits best. If the chosen model is a straight line and if the slope is significantly different from zero, a shelf life will be estimated. Finally, a report is written which summarizes ~he results corresponding to the appropriate model. Background To quantify shelf life, characteristics indicative of that particular product's deterioration are monitored over time. Collectively, m2asurements of deterioration are referred to as stability measurements. The goal of shelf life estimation is to predict the time when some measure of stability will no longer be within preset specification limits. These limits demarcate a range, and provided the measure of stability is within that range, the identity, strength, purity, and quality of that drug can be assured. Commonly used specification limits are the standards established by the United States Pharmacopeial Convention (USP). The USP is a nonprofit organization that sets standards which are recognized by the Food, Drug, and Cosmetic Act as the minimum standards of strength, quality, and purity. If a drug fails to meet these standards, the Food and Drug Administration can seize it or ask the manufacturer to recall it. Shelf Life Estima",Sugi-83-63 Dietrich Weiner.pdf
"M. Roberts. San Diego Gas & Electric Company ABSTRACT The role of the Transmission Engineering Section of the San Diego Gas & Electric Company (SDG&E) is to enable the provision of overhead and underground power systems. Such systems satisfy the energy demands of a growing consumer base. An assigned project engineer is responsible for the installation of a given transmission line. The project engineer, therefore, is concerned with the engineering and design of the line. as \/e11 as overseeing the procurement, construc­ tion, and inspection phases which pre­ cede placing the line in service. The measures of project success are accom­ plishing the performance specifications of the transmission line on or before the scheduled deadline and within the budgeted cost. A crucial factor associated with these three determin­ ants of project success is material. Specifically, deviations from avail­ ability of the right material in the necessary quantity at the proper time invariably contribute to project delay, cost overruns, and possibly deficient energy transmission. This paper de­ scribes the SAS based materials track­ ing system developed at SDG&E to assist the project engineer in favorable ac­ conplishment of transmission line pro­ jects. SAS was selected as the computer language appropriate for the SDG&E ma­ terial tracking system due to several reasons. SAS enabled the modeling of this prototype system in a time and cost-effective manner. Moreover, the language's ability for inf",Sugi-83-64 Glaser Carr Roberts.pdf
"MANAGEMENT INFORMATION SYSTEMS: AN ENVIRONMETRICS APPROACH Karen L. Daniels, Michael P. Farrell Oak Ridge National Laboratory Oak Ridge, Tennessee 37830 Jonathan C. Goyert, Rodney H. Strand SCience Applications, Inc. Oak Ridge, Tennessee 37830 Introduction Our concept of environmetrics has evolved out of a research enVironment, speClt'1cally researoh in the environmental scienoes at Oak Ridge National Laboratory. At Oak Ridge, we have identified eight phases of a research project: 1) oonceptualization of the problem, 2) study and experimental design, 3) data collection, 4) data base development, 5) data base management, 6) applications program development, 7) integration, and 8) synthesis of' the resul ts (Fig. 1). Environmetrics is a discipline that attempts to integrate these phases by offering an alternative approach for planning, conducting, and analyzing research. This paper describes the environ­ metrics concept, how it can be implemented, some of the tools used in its implementation, problems in development, and solutions. Problem Statement In a research environllent there is usually a hierarchical arrangement of personnel with the research scientist on top who is in turn assis ted by a da ta processor and a statistician (Fig. 1). The research SCientist is responsible for the tasks of conceptualization, study design, and data collection. The data processor is responsible for data base creation and management while the statistician assists the data processor in applications program development. In this framework, there may also be hierarchies within each level (Le. there may be a principal investigator, a researcher, and a laboratory technician in the first level, a data entry clerk and data manager in the second level, and a statistician and programmer in the third level) . We have found that the major problem associa ted wi th this type of organizational structure is a lack of communication among the various levels resul ting in an overall loss of inf'ormati",Sugi-83-65 Daniels Farrell Goyert Strand.pdf
"The Business Consulting Group in Du Pont's Information Systems Department offers consultation in operations research, quantita­ tive problem-solving and small systems devel­ opment to all operating and staff departAents within the company. Typically, analytical models ann computer programs are developed to facilitate decision-making. In many of these projects, the Statistical Analysis System (SAS) was chosen as an appropriate high-level programming language for implementin9 or contributinq to a solution. Three such studies connucted during the 1980-82 period were: o Simulation of Sales and Earnings - A SAS proqram was written to simulate the occurrence of possible events in the near future which would have an impact on forecasted sales and earnings of a product line. These are now being used by management to estimate future business trends. o Product Profitability Study - A SAS proqram was developed to help select a product mix which will maximize profits while satisfying limited capacity con­ straints. The program will be used on an ongoing basis by management to determine profitable production strategies. o Rail Fleet Si~ulation Data Preparation System - SAS programs were written to summarize and characterize data before being input to a fleet simulation model. The simulation model is then used to evaluate rail car fleet sizes for a particular Du Pont product line. The Data Preparation System will enable other analysts to operate the simulation with minimal user intervention. These projects demonstrate the effective use of SAS in helping to provide quantitative information to Du Pont management. The use of SAS in these projects will ultimately assist management in making more informed business decisions ana developing effective and compe­ titive business strategies.",Sugi-83-66 Milstein.pdf
"USING SAS FOR THE MANAGEMENT OF RESEARCH RESOURCES. Rosalind L.R. Ibrahim, Kuwait Institute for Scientific Research. 1. INTRODUCTION. The uncertainties associated with carrying out resear~h projects, coupled with the complexities of project management create a situation where systems and tools to support research managers become vital. One major aspect of research mana­ gement deals with resources an~ their utiliza­ tion. Sy~tems that provide infermation on rese­ arch resources can help managers responsible for research projects and activities to deter­ mine, for example, what~esources are required, what resources are available, whether resources are being fully utilized, whether actual reso­ urce utilization deviates significantly from the plan, what corrective measures can or should be taken. At Kuwait Institute for Scientific Research, a SAS-based information system has been imple­ mented to help in the management of research resources, especially manpower and money resour­ ces. This paper describes that resource manage­ ment support system and experiences acquired in using SAS. The next section presents background information on the system that was developed and the deci­ sion to implement in SAS. Then an overview of the system is provided including a discussion of special system requirements facilitated with SAS. The.paper concludes with post-implement­ ation considerations and a discussion of sctivities related to the use of SAS at the Institute. II. BACKGROUND. 2.1. The Research Environment. Kuwait Institute for Scientific Research (KISR) is a non-profit public institution entrusted with the mission of promoting scientific and applied research for national economic and social development. Founded in 1967, there are currently about 1000 employees~ including some 100 Ph.D's employed at the Institute. The lifestream operation of KISR is the execu­ tion of research projects which broadly fall in the domains of the five research division : Engineering; Environment",Sugi-83-67 Ibrahim.pdf
"At the Texas Instruments Lewisville Interactive Computer Center (LICC), a SAS-based accounting system has oeen developed to process accounting data for the purpose of billing in-house users. SAS was chosen to implement the accounting system for simplicity and ease of modification. The LICe IS VM/CMS operati n9 system automatically generates accounting records for many of the sys­ tem resources used. Additional accounting records are generated by special utility programs to allow billing for those resources not included in the basic accounting records. The SAS-based account­ ing system processes the records from the various sources, merging the data with additional informa­ tion such as division, cost center, and account number in order to produce a record for each re­ source used by each user. These records are then processed to produce journal entries to be sent to the Group Accounting System to bill the users. In addition to generating these records, the system produces many statistical reports and graphs to aid management in financial planning and resource allocation. A number of reports and notices are also produced for users to a1d them 1n efficient use of resources. The SAS-based account i ng system has sa~ed TI thousands of dollars by reducing er­ rors, ma~ing reports and graphs available to management and users. and mak; ng the account; ng system flexible and maintainable.",Sugi-83-68 Hill.pdf
"SAS - DL/I, SAS/FSP - TIIEIR USE IN LARGE SCALE DB OPERATIONS Richard H. LaRue & Clayton D. Stewart Federal Home Loan Mortgage Corporation In June 1981, the design for the system named the ""Mortgage Information Direct Access Source ll (MIDAS) was completed. The following month development began with the implementation of an IBM 4341 processing environment with CIeS, T50, SPF/PANVAlET, DMS, IMS, COBOl-Dl/I and SAS. By January 1982, the MIDAS development which would convert a half dozen major systems into one of the most state-of-the-art on-line. integrated systems, was in full process. There were over 4,000 programs in COBOL, DMS and SAS to be com­ pleted and over 50 IMS data bases to be develop­ ed. This development environment produced four major tactical problems which other corporations doing major system renovations would mutually find, regardless of the applications. The first pro­ blem involves the conversion of any files from current systems. The second problem evolved with milestone deadlines, achieving a productl time ratio with quality programming. A third problem was tracking the inventory of more than 15,000 pieces of developed software. The fourth tactical problem was the project tracking of more than five dozen software technicians. This paper explains how FHlMC solved these problems with the assistance of SAS products. PROBLEM 1: Large Scale Data Conversion SOLUTION: Burroughs to IMS through SAS The corporation was faced with a significant problem in converting the business from a com­ bination of Burroughs based application systems and manual procedures to an IMS environment. The IMS environment contained some dozen or so major data bases plus several supporting data bases. Writing COBOL programs to collect and manipulate some 3000 data elements from the Burroughs and manual environments. then loading them into the problem IMS data bases required more programming resources and time than was available. The strategy which was adopted used SAS and the S",Sugi-83-69 LaRue Stewart.pdf
"A USER'S VIEW OF SAS/IMS-DL/I Emilio A. Icaza, Louisiana State University The Louisiana State University Computer Center is the nucleus of computing activity on the campus. A large IBM processor supports a variety of needs for the instructional, academic, research, and administrative user of the Baton Rouge campus. In addition, other campuses of the LSU System complement their computer needs with services provided by the Baton Rouge campus. At last inventory there were about 95 different software products installed on the main computer and well over 2500 programs which service the administrative computing needs of the university. Among all the software, SAS is by far the most widely used product. In terms of executions it ranks second only to the Linkage Editor. In terms of volume, it is said to consume one month out of a year's supply of computer resources. The Information Management System (IMS) is the only large scale data base management system in use at LSU. Thus, the announcement of avail­ ability of SAS/IMS-DL/I brought a world of , interest from all quarters of the LSU user com­ munity. This paper describes a Support Center's view of SAS/IMS and our experiences introducing the product to the LSU users. Who Uses SAS? Whenever a product like SAS/IMS-DL/I becomes available, someone in the organization has to identify the potential users of the product and then justify to the budgetary officers its acquisition. Invariably the question that gets asked is, ""Who uses SAS""? In the earlier years of SAS, its use was limited to research. The Department of Experimental Statistics acqUired the basic product and continues to support SAS for the rest of the University. But as SAS Institute expands its product line, many more non-research applications of SAS are surfacing. A detailed list of users is beyond the scope of this paper. However, an understanding of the SAS user community needs and capabilities is fundamental for the success of a product such as SAS/IMS-DL/I in t",Sugi-83-70 Icaza.pdf
"PASCAL SPEAKS TO SAS: A SIMPLE INTERFACE 0.1. Hopp & R.W. Staley. A.H. Robins Co. I. STATEMENT OF THE PROBLEM This pape~ addresses the use of a micro­ computer-based data entry system that accumu­ lates, edits and prepares data for subsequent analysis on a large-scale computer using SAS. The microcomputer uses the UCSD p-System (1) operating system, with Pascal as the implementa­ tion language. Emphasis will be placed on the details of the interface developed to move data from Pascal to SAS. The specific setting is that of clinical trials in the pharmaceutical industry (2). Briefly stated, clinical trials are carried out in accordance with a protocol, using data entry forms specially prepared to gather the neces­ sary data. This is not a high-turnover setting. such as order entry; it does require very care­ ful entry and on-line editing is of great value. It also requires the ability to initialize and carry out data entry in many different clinical trials on a weekly basis. Once it was decided to use microcomputers for data entry. it remained to choose the lan­ guage, operating system and hardware, and then find an easy way to provide all the information that SAS needed to read and manipulate the data passed to it. II. BASIC REQUIREMENTS OF AN INTERFACE In order for a SAS interface to be useful, it should require a minimum number (hopefully, one) of encounters between the person who speci­ fies the characteristics of the data and the process of characterization. To the extent possible, the process of characterization should take place on one side of the interfacej which leads to the observation that characterization information might well be treated as data, it­ self. The process should be complete and the translation of the characterizations into SAS syntax should be automatic. III. A BRIEF DIGRESSION - WHY p-SYSTEM PASCAL? The data entry application under discus­ sion was obviously going to be quite complex and lengthy. It would have to utilize a variety of input",Sugi-83-71 Hopp Staley.pdf
"s of information with different format and schemas must be processed easily and efficiently. Cer­ tain tools, such as data entry instruc­ tions, editing criteria, and data set creation and maintenance programs are usually created by the user. We have used UNIX and SAS for the past two years to generate these tools as well as secu­ rity and backup procedures. SAS genera­ tion pro9rams are written once and do not requ1re new programming effort to handle data with new formats or schemas. The use of generation programs provides increased efficiency and data set stan­ dardization. A commercially available data dic­ tionary has been implemented that con­ tains information essential to the pro­ cessing of clinical data and is used as input to the program generators. Other software, e.ga operating system files, also could be used as input to the gen­ eratorS. The information is read and processed1 the output from the program generator is executed and/or passed from one computer system to another. This technique may be useful in any research application where data sets and formats are numerous and changing. 2. ENVIRONMENT Several clinical studies concerning a number of compounds may be active at anyone time at Sandoz. Each study uses case report forms (CRF~s) to collect data on a patient~s status. A study may require as many as 15 CRF*s to collect a variety of information at different time points. Each compound requires its own relevant variables. Therefore, Clinical Research at Sando",Sugi-83-72 Belasco Ives.pdf
"f , DBASE; AN EFFICIENT INTERFACE BETWEEN THE USER AND LARGE SAS DATA SETS William Ingram. Info Tech. Inc. Russell Gilbert. Santa Fe Community College James W. Parkes. Northeast Regional Data Center INTRODUCTION As we enter the 1980' G. the importance of information, its organization and access­ ibility is being realized. This realization 1.8 reflected by the preponderance of articles discussing data base management systems (DBMS). Decision Support Systems (DSS) and information centers (IC) in the trade litera­ ture. We feel that SAS with its combination of data management, analyses and presentation capabilities is ideally structured to satisfy the need for information management. Thus. we see SAS playing a central role in corpor­ ate and governmental information centers. In order for a DSS to be successful. it must be available to the decision makers. These individuals require a simple, yet powerful, user-friendly interface. Further, for a DSS to be widely utilized in the cor­ porate and governmental setting, it should be able to access large amounts of data efficiently. As we examined SAS with these requirements in mind, we concluded that SAS needed enhancement in two respects. First. as SAS has grown tremendously in power, it has necessarily increased in complexity. Consequently, the complexity of the documentation has also greatly increased; a fact that may deter the naive or casual user from learning SAS (Bragg, 1980). This would ultimately limit its usefulness in the DSS or IC environment. In our opinion, the most formidable aspect of SAS to learn involves manipulating and coordinating multiple SAS data sets to create the collection of variables required for an analysis or report. The successful use of the MERGE and SET with their associ­ ated SORT procedures, BY statements, and FIRST and LAST variables to extract data from a complex SAS data library requires a consid­ erable degree of sophistication in SAS and in programming techniques. This becomes parti­ cu",Sugi-83-73 Ingram Gilbert Parkes.pdf
,Sugi-83-74 Boro.pdf
";-. THE S~S (===) MICROCOMPUTER CONNECTION P. L. Olympia, Da~win Systems, Inc. IIITI.ODUCTlOB Only a few years ago a professional or manager who needed data and graphs for an important meeting in the morning had to do without them. To get both he would have had to make a request to both central DP and the Graphics department. a process that easily required a turn-around time of days, if not weeks. No more. TIle advent of microcomputers changed all that. Managers who have micros at their desktops now have control over their data. And since these machines are multifunctional, managers tend to do a lot of things with them - even wrong ones. And that is the point. Although some people consider micros to be the greatest things since sliced bread there are some aspects of computing that are better left to a mainframe computer. Today, micros have at least one major shortcoming - its as-yet immature software base. The immaturity of micro software comes 'in two forus: (1) easy-to-use software does not always mean easy-to-learn software primarily because many otherwise excellent micro software systems suffer from below-par documentation; indeed, software documentation has long been regarded as the ""armpit of the microcomputer industry""; (2) due mostly to memory limitations many of today's micro software pale in comparison to those avai­ lable in mainframes such as SAS and SAS/GRAPH. This paper describes GRAF/S, a system that brings the power of mainframe computers available to micro users by providing an optimal mix that takes advantage of the strength of both machines. Although GRAF/S provides a hook to SAS/GRAPH. its design philosophy is general enough that hooks to other mainframe software, otherwise unavailable in micros, can be made easily. OVERVIEW .!!! GBM/S Imagine a manager or professional who main­ tains one or more data bases on a micro. He needs summary information on his data bases in the form of charts for an important meeting in the next few hours. He knows tha",Sugi-83-75 Olympia.pdf
"f I ~ , I l , f ~ AN ECONOMICAL APPROACH TO VERIFYING THE ACCURACY OF KEYPUNCH OATA Nancy N. Goodyear and Steven N. Blair School of Public Health, University of South Carolina Introduction The cost of keypunch verification is often prohibitive on large data bases. especially for projects with tight budgetary limitations. With­ in the University setting, gratuitous keypunch services are sometimes available for faculty research; however, it is often the case that time and monetary constraints do not allow for subsequent verification. Without this verifica­ tion, the researcher is left with no tangible evidence as to the accuracy of the data entry. Several faculty members, including ourselves, have encountered this situation at the Univer­ sity of South Carolina. Our particular problem involved analyzing 13,000 questionnaires pro­ vided by the Institute for Aerobics Research in Dallas, Texas. The questionnaires were part of an Aerobics Center longitudinal study designed to examine risk factors associated with various chronic diseases. Each questionnaire contained 119 variables and required three keypunch cards. Although the University would provide the initial data entry. the size of the job and the low priority given to strictly research projects meant that it would take at least three months to complete the first keypunching. Although verification was available, it would have, cost more than $4,000 and another 3-4 months of waiting time. In order to determine whether a complete re-entry of all the questionnaires was justified, a 10% duplicate sample of coded questionnaires was intermingled with the original coding sheets and sent to keypunch. A SAS program was then developed to compare the duplicate coded ques­ tionnaires for variable value discrepancies. The SAS program calculated an overall keypunch error rate, along with an error rate for indi­ vidual variables. Additional SAS programs pro­ vided descriptions of the types of errors made. Output from these programs",Sugi-83-76 Goodyear Blair.pdf
"that reports be produced at reqlJlar intervAls dally, weekly. monthly. Ate. To ensure that personnel reports A.re produced On schedule, a SAS based monitor system has been imrlemented ·'Jt the Aqency for InternationaJ Development. This system generates th,e JeL for all reports that are dlJe each day, slIbmi ts the jobs, and advances the due-date as each report is complet.ed. The user can access the -database to modify the due-date, destination, or number of copies for a particular report, as well nS indicate which non-periodic reports should be submitted. SAS features illustrated by the programs include dAte-value manipulation, interActive transaction editinq throuqh terminal prompts, SAS/FSP, SAS programs generated by other SAS proqrams, and character manipulation (to build the JeL and SAS stRte@ents). Simplicity and flexibility are ,pnhanced by utilizing JeL proc~dure parametprs. THE PRObLEM Wi th OVer 1 ~() reports being produceo at various intervals, therA are too mAny opportuni ties for a Job to be ,5ubmi tted on the wrung date, or to be skipped entirely. There is also the necessity to verify that e.ach job has completed successfully~ and there is the schedule to maintain so that the job run~ again the next time it is dUe. To make the problem a little more interesting, there Bre a few more requirements. Each job has th.e capability to produce a variable number of copies of up to f01Jr reports~ and each job can ca 11 for up to three tape volUmes. Th~ User must be abl~ to",Sugi-83-77 Merlin.pdf
":;..: AUTOMATIC SAS GENERATION OF DOCUMENTATIO~ FOR A LARGE PUBLIC-USE SAS DATABASE Judith L. Coh~n. Social & Scientific Systems. Inc. Abstract: ---- Social & Scientific Systems, Inc. has been, for 3 years, providing data processing support to the National Center for Health Services Research (NCHSR) of the Public Health Service in the editing, analysis, and presentation of data collected in NCHSR's National Medical Care Expenditures Survey. As analysis files are developed from the large SAS database, some will ultimately be made available for public use. Since the files are numerous and may contain up to 800 variables each, it became desirable to automate the production of detailed, error-free, easily-readable codebook documentation to accompany the data files as they are released to the public domain. This paper presents a system which was deve loped to meet this documentat ion requirement. The system incorpor-ates such features as: macro usage j SAS code which dynamically generates other SAS code; unique concatenation and formatting of Proc Summary output; interleaving data from multiple files; and formatting a publication-quality codebook which can be printed on 3-hole, 8 1/2 x 11 paper. The codebook includes, for each variable on each file, Proc Contents-type information, expanded free-form descriptive text, and both raw and weighted formatted frequencies. Objective : The traditional approach to documentation of a data file is to provide three documents: 1) a codebook with information for each variable on the file such as variable name, position on the file, length, etc., and valid codes for discrete variables or valid ranges for continuous variables; 2) a set of frequencies on each variable; and 3) a document which describes in detail what the variables represent, how they were constructed, what effect is created through ~ ighting, etc. Our objective in approaching a potentially massive documentation effort was to combine all of the above information into one d",Sugi-83-78 Cohen.pdf
"neapolis Star and Tribune Newspapers uses FORTRAN as its primary programming language. We have developed a SAS application that analyzes FORTRAN programs in terms of overall program structure. The program produces three outputs: (1) A matrix of CALLING to CALLED routines; (2) a chart showing the program hierarchy; and (3) a list ofroutines external to the program. While the program we use is restricted to analyzing FORTRAN programs, it could easily be modified to analyze any hierarchy that is defined syntactically in terms of owner/subordinate pairs. Thus the same method would be useful for the study of dominance hier­ archies in behavioral studies, or for analysis of reporting relation· ships in a large company. In our environment, this program is use· ful in that it reduces the time needed to document new programs or analyze old ones, thereby increasing the productivity of a small stair. THE PROBLEM Program documentation is a chronic problem in data·proccssing departments. Documentation is generally out·of-date, often lost, and almost certainly inaccurate in some of the details. Furthermore, time spent by the staff in documenting programs is time spent away from programming or design. Any method of automating part or all of the documentation of a system should improve productivity by making that part of program documentation accurate and instantly available, streamlining both the documentation and the program maintenance processes. This paper describes a SAS program that ge",Sugi-83-79 Lewis.pdf
"SAS and a database management system (Model 204) have been linked to form an integrated information system called a Data Analysis System (DAS). DAS's have many~the processing capabilities that characterize traditional MIS's and Decision Support Systems (DSS). Like traditional MIS's, they are capable of fulfilling requests for rapid access and display of individual case data. In DAS's, however, the emphasis is on capabilities to perform ad hoc analyses across selected case data. Like DSS's. DASts~apable of fulfilling requests for sophisticated analyses. However, in DAS's the types of analyses are less limited, and can be performed with actual internal transaction data and a variety of external source data. SAS extends the analytical and graphical capabilities of Model 204, the core database management system. The SAS-Model 204 interface, EXTRACT/M, links these two components. This SAS procedure enables users to read selected records and fields in MOdel 204 data files and create a SAS data file. A data dictionary provides the variable attribute information for the data transfer. A generalized data entry system facilitates the entry and validation of data no new input programs are required for new source data. only new dictionary entries. A SAS procedure, PROC REPORT, was created to provide an easy-to-use generator for ad hoc presentation-quality tables.",Sugi-83-80 Smith.pdf
"offers potential productivity gains by effectively supporting end user computing to satisfy demand processing requirements. The Cen­ ter provides guidance, training, and assistance to end users in the use of appropriate products to improve the effectiveness and productivity of managers and staff profes:sionals, THE PROBLEM-A DEMAND SIDE VIEW INTRODUCTION The delivery of computer power to the non-data processing end user who can benefit from it has been a problem for most organizations. It has only been in Lhe la::;t few years that there has been significant activity to effectively address the problem with an in-house solution which is under the control of the data processing organ­ ization. By giving end users a udo-it-yourself l1 capability, considerable benefits can be realized in the areas of productivity, decision support, traditional application development, and in ap­ plication maintenance. The organizational aspect of the solution is called the Information Center. Why this particular solution at this particular time? The answer lies in the nature of the prob­ lems faced by business and government which have forced a major addition to the traditional ser­ vice strategy of most data processing groups. It is well to begin with a discussion of the prob­ lems and their impact in order that the ap­ proaches to the solutions be better understood. THE ORGANIZATION UNDER PRESSURE The relatlonshlp among operational, fUll(;.tional, and executive management levels is a hierarchica",Sugi-83-81 Torgler.pdf
"an information center oriented MIS that produces numerous user­ initiated ad-hoc and standard reports can quickly outstrip the price of initial development. Maintenance of a continuously expanding and changing database compounds the88 problems. These costs can be substantially reduced over the life-cycle of a system by giving the responsibility for maintenance of a substantive nature -- including variable definitions, input data source formats, and output report .formats -- to the users. A MIS that does this must be designed to allow users with no expertise in system development to generate fundamental changes to the system through a simple, easy-to­ learn procedure. T,his procedure must be built in a way that expands user confidence, knowledge, and power over system capabilities with continued use. SAS provides some of the critical tools necessary to implement such a system w1thi3 reasonable time and budget constraints. The purpose of an information center is to allow an information seeker to directly extract and summarize data from a ~eterogeneous information pool. The information seeker, or end user, is already familiar with t~e often complex set of requirements for data manipulation. Therefore, a method of direct access to the infornation will allow him to extract data himself much more quickly than his requests could be fulfilled indirectly through a programmer. In designing a Management Information System (MIS) or DeciSion Support System (DSS) to facilitate direct inqui",Sugi-83-82 Toor Beekman.pdf
"TRANSFERRING AND PROCESSING A ""VERY LARGE"" DATASET FROM A PDP 11/34 TO AN iBM 360/370 K. J. Seiple and K. E. Muller, University of North Carolina, Chapel Hill INTRODUCTION As research laboratories acquire faster and larger minicomputers. the amount of data that can be collected from the research subject and stored directly on a magnetic medium increases at an increasing rate. Inexpensive and readily available minicomputer technology allows a megabyte database to be collected and stored, yet does not have the memory, speed, nor the software to conveniently analyze the data. Therefore, the data must be transferred to a ~ainframe.computer. We had a megabyte database stored on a PDP 11/34 minicomputer that contained EEG data. The EEG data are amplified, digitized voltages measuring human brain activity. We needed to do Fourier analyses (via PROC SPECTRA) on this EEG data and then do multivariate linear models testing. We expect to create one to three such databases ~very year. We estimated that the final SAS analysis dataset would be ""not small il to livery large"" depending on how we structured it. Muller, Smith and Bass (1982) defined a Iinot small il dataset as one that includes from 10,000 to 100,000 observati-~ns and a livery large"" dataset as one that lncludes more than one million observations. They are also highly recommended top down structured planning and a test run through the transformation process from raw data files to final SAS analysis dataset before transfer of all the data is started. Top down structured planning resulted in a livery large"" ideal final analysis dataset that was flat, very long, and sk~nny (few variables). After we ran three test subJects through the whole transformation process, we decided this ideal final analysis dataset was too expensive to create within our budget 1imitations. We iterated the top down structured planning and developed a ""not small II flat, shorter, and ""ider affordable final analysis database that contained ""many d",Sugi-83-83 Seiple Muller.pdf
"bstract This paper describes a system developed at Lilly Research Laboratories which provides utilities for producing all image of an IBM Syst_emj3& (S/38) data base in SAS. Image is defined as the data and its underlying definition within the S(38 environment as well as references to associated dictionaries_ The system includes methods for reading 5/38 file descriptions and automatically generating SAS code La build SAS datasets and format libraries. Introduction The IBM 5/38 is a relational data base machine which supports both batch and interactive processing with the emphasis on the latter. The S/38 provides a high-level machine interface in that many typical operations are performed by hardware instead of software. Also, it supports both COBOL and RPG. The 5/38 is used by Lilly Research Laboratories to manage the data obtained in clinical trials. The data flow [rom the moment that a case report form (CRF) is mailed from the investigator's office to its final residence in a SAS dataset is obviously a multistep process. Below is a list of the six ways in which the S/38 conlribules to this process. l. 2. 3. 4. 5. 6. CRF logging allli tracking Kpy pntry/verification of the data Interactive query and update of medical dictionaries Monitoring safety data via interactive inquiry and summary reports Editing the data Profiling the data, i.e., reporting the data with all dictionary corlp-to-tprm translations Note that there is one CRF per patient enrolled in a study; the CRF, howe",Sugi-83-84 Hardison Burge Hizer Halloran.pdf
"LDMS: A Set of SAS PROCS for Longitudinal Data Management Philip Dow, Westat Inc. The Longitudinal Data Management System (LOMS) was designed to manage and analyze the data from the Continuous Longitudinal Manpower Survey. This survey collected data on the participants in the several CETA programs in order to evaluate the effectiveness of these programs. The design of the survey was somewhat unique in that new cohorts were constantly entering the survey while at the same time old cohorts were still being followed up. Cohorts are identified by the calendar quarter in which they entered the CETA program. Each cohort was sampled at rate of from 3000 to 6000 subjects. Each respondent received an intital interview and up to 3 followup interviews spread out over the succeeding three years. Several instruments were used in each interview. The original system gathered the interview data into one mammoth flat as file using an edit/update program written in Cobol. The primary design goal of this system was simply to agglomerate the various waves of data for each cohort so that longitudinal analyses could be done. No serious data validation was done at this point as another contractor (the Bureau of the Census) was responsible for the actual collection and initial data preparation. A second program created various derived analytic variables and output them to an analysis file, again in os format. Various analytical packages (notably SAS, SPSS, and TPL) then operated on this. Data collection began in the middle of 1975. By 1978 several serious problem areas began to be manifest. The amount of data either collected or in the pipeline was approaching one gigabyte. This in itself was causing management problems -- keeping track of all the tapes that contained the various waves of cohort data. A major reason for the growth of the data was the duplication of variables: once in the original file, once in the analytic extract, and once in the system file of each statistical package. N",Sugi-83-85 Dow.pdf
"i l: , LIVING WITH THE AHA: THE CONSTRUCTION OF A MULTI-YEAR HOSPITAL INFORMATION DATA BASE USING THE AHA ANNUAL SURVEY AND SAS Frederick Pratter and Mireille Leger, Abt Associates Inc. Introduction The annual survey of its members by the American Hospital Association represents one of the largest and most widely used sources of data on U.S. hospitals. Indeed, for many items included 1n the survey it 1s the only readily available source of that particular information for all hospitals. Making full and effective use of this data set, however, requires an appreciation of the datals limita­ tions and an understanding of the possible alternatives for dealing with them. This paper describes the experience of one major research project working with the AHA data in the hope that such a description will con­ tribute to a better general understanding of this important data set. Spel"":ifically, the paper describes the activities which were required to incorporate twelve years of AHA data into the data base of the National Hospital Rate-Setting Study (NHRSL a four year study being conducted by Abt Associates for the Health Care Financing Administration on the impact of prospel"":tive reimbursement legislation on hospitals. In general, the difficulties encountered in using the AHA data tapes fall into two distinct categories: • problems related to the management and comparability of the annual surveys-­ i.e. activities necessary to put the data in a format which is useful for a particular analysis; and • problems associated with the validity of specific values reported by the AHA--specifically with identifying and correcting inaccurate or missing values for data elements. This paper discusses these two types of problems and suggests some implications for future uses of these AHA data. The first major problem in the construction of a longitudinal file from AHA survey data was that over the period of interest (1969-1980), the questionnaire formats and data tape layouts changed ann",Sugi-83-86 Pratter Leger.pdf
"z, Understanding the Methodology of the ConstruGtion of the Americ:an Hospital Association (AHA) Annual Survey of Hospitals; a Response to 'Living with the AHA: The Construction of a Multi-Year Hospital Information Data Base Using the AHA Annual Survey and SAS' Roy A. Clark-American Hospital Association Introduction Frederick Pratter et. aI., in a paper titled 'Living with the AHA: The Construction of a Multi-Year Hospital Infonnation Data Base Using the AHA Annual Survey and SAS; presents a methodology for editing and improving the infonnation collected by the AHA's Annual Survey from the years 1969-1979. This improve­ ment methodology was developed without a full under­ standing of the processes used to collect and edit the origiual 1969·1979 AHA Annual Survey data base. Pratter et. als.' efforts to improve the quality and accuracy of the AHA data by eliminatiug values that fail their editiug techniques actually diminish the reliability and validity of the data. AHA edited the 1969-1979 data using the same methodology duplicated by Pratter et. al. When a value failed the AHA edits, the reporting hospital was contacted directly by an AHA staff person and the questionable value was validated. When Pratter et. aI. eliminate a value that fails their edits, it is very likely that they are removing an accurate validated data item, therefore distorting rather than improving the accuracy of the data base. A brief look at the AHA Annual Survey processing methodology illustrates the duplication relationship of Pratteret. als.' and AHA's editiug techniques. The AHA's Annual Survey Data Base ConstruGtion MethOdOlogy Pratter et. aI. identify 'temporal edits' (comparing a given year's variable values with those reported for other years) and 'contrast edits' (comparmg a variable's value with associated variable values presenting the same record) as the most effective methodology for identifying erroneous data and ensuring that correctly reputed data are not flagged as errors. Th",Sugi-83-87 Clark.pdf
"SAS on 32-Bit Mini-Computers Richard A. Usanis, SAS Institute Inc. Introduction Good morning and welcome to this session on the SAS system on 32-bit mini-computers. There is a handout containing major differences between the Portable SAS system and the 1982 version of the SAS system. The differences are changes to the SAS language, most of which will be implemented in the IBM version in 1984. I am speaking to you today as Director of the Portable Systems Division at SAS Institute. In order to understand my role in the development of the Portable SAS system, I'll mention my background. Prior to coming to the Institute in September 1982, I was the Director of the Computing Center at North Carolina State University involved in software, hardware, and user interface. Prior to 1974, I was a private consultant in statistics and computing with research companies in the Research Triangle Park. I received my Ph.D.in quantitative genetics and forestry from N. C. State University in 1972 where I was working as the Computing Center's statistical consultant using what was then known as the Statistical Analysis System. My first introduction to the SAS system was discussions with its founders as far back as 1968 when I was a programmer with the Genetics Department. I have been closely tied with SAS software and SAS users for for many years and hope to use this experience to provide you with another good SAS product. Also here from the Portable Systems Division of SAS to answer any technical questions during the demonstrations are: Carl Thorne, Manager of the Digital Equipment Corporation VAX Systems; Jeff Polzin, Manager of the Data General MV Systems; and Mark Watson, Systems Programmer in the Compiler Writing Group. The Portable Systems Division includes eight other staff members in Cary. People here in New Orleans have asked me three questions almost constantly: 1. When is SAS going to be available on mini- computers? Followed up by: 2. What will it look like and how will it pe",Sugi-83-88 Usanis.pdf
"SAS AND THE MICRO IN THE SPORTS. ENERGY AND FINANCIAL ARENAS Cec i I R. Gary E. Graybeal. PetrochecK Hallum. University of Houston-Clear R. Bryan Erb. Erb 50ftware LaKe busine55 itppl ic:at.ion5 of c:omput~r-aid~d func~ion. ~rl! rapidly moving forward Hit.h t.hliil rapid IiiIxp~5ion of the .mall business and home computer indust.riliil. it. i5 ent.irely faa.ibis for mo.t smell bU5inliil551!5 t.o b&ilgin to utilizil thi5 capability. In meny c:e._ the ownar of a Bmell busine55 or pilrsonal microcomputer realiziI& that it would greatly enn.ncil thliir c:apebilitill& if they could bring Borne of the mora powilrful analytical techniques to bear on the data they h.viI on their mic:roc:omputilT' data bases. They al5C find that as their data base grows, the micro provides anSWI!!r5 more slowly_At this point the Question is how to inc:rliitSii computational effic:ili,nc:y in a c:05t-l!ffec:tiva mannl!r? Thi5 i5 whl!rl! c:ommarc:ially ~vaileble &oftwarl! sys tam. 5uc:h as SAS c:an bl! ut 111 zad to fulfill 'the !Smell busine5s manager's dl!5iree and nl!l!ds 8E~EFITS OF THIS COH8I~ATIO~ TMl!re ara sl!vl!ral banafit.5 t.o bl! gainad by utilizing a c:ombin~t.ion of high t.ec:hnology 50ft.ware pac:kagl!5 suc:h as BAB and a mi~roc:omput.er. rir5t onl! can eas11y gain a morli cost effective use of your resourC:l!s. This is brought about t.hrough a signific:antly lowar requirl!ml!nt. for c:apit.al equipml!nt. invl!stment., lower operating c:osts by better utilization of availabll! r.sourc:es [bo'th dollar. and menpower), and thli oVilrall system is mere rl!edily upgradliiliib II!. you c:an i nc:raase ac:c:essi b iIi ty to both the online data basl!s on 'th. mic:ro -and intlirec:tivl!! use of thl! high t.ec:hnology pac:kagas on a main-frame c:omputar. Storing your input run5treiims and the resul t5 of the SAS runs on floppy disket.tas on t.hl! mic:ro providliil& more raady and timely ac:c:eS5 470 to c:hanges you may deem either nliclissary or desir.bl. Through use of a state-of- thl!",Sugi-83-89 Graybeal Hallum Erb.pdf
"SAS AND APL: THE SIMULTANEOUS USE DF BOTH IN DATA ANALYSIS Richard LaValley and Eugene Mertz. Satellite Business Systems I. Introduction With the modernization of data collection and processing hardware, most businesses are facing an enormous quantity of useful data. Analysts have the challenging task of reducing this data into useful and concise information which can be used by management to make well informed and timely decisions. Many software tools have been developed to assist analysts in their efforts. Two of the more powerful tools are SAS and APL. SAS offers business analysts standard sta­ tistical and graphical techniques which can be easily used in a relatively user-friendly envi­ ronment. Simple data manipulation can be easily coded within SAS. Complex data manipulation, however, is not as easily accomplished and the code is complex. APL is an analytically structured program­ ming language which provides the analyst with the capability to do complex data manipulations easily. Additionally, a vast number of statis­ tical procedures are available for an insta11a­ tion1s public libraries. Data selection and data manipulation are extremely easy with the use of APLDI, one of the standard software packages, which can be obtained from IBM. This package is extremely useful in processing large data sets because it is easy to request complex multiple criteria selections from the data. In addition, this package has a series of standard data ma­ nipulation programs which can be used on the selected data (programs such as sums, averages, crosstabs, etc.) as well as anY program that the analyst can develop. This paper attempts to show examples of the use of both APL and SAS in data analysis and data modeling. It attempts to show both Iltools"" being used to perform the necessary job in a quick and easy way. Satellite Business Systems (SBS), is a telecommunications firm which provides voice, data and image communication service to commer­ cial and residential users. SBS",Sugi-83-90 LaValley Mertz.pdf
"TASK ITEM TRACKING AND NAGGING (TITAN) SYSTEM Paul C. Willman, Virginia Electric and Power Company Introduction The Task Item Tracking and Nagging System is a work assignment tracking tool. It can also be used for Project and Time Management purposes. TITAN consists of several data storage and organization programs which assist in categorizing tasks. identifying re­ sponsibilities, allocating time. establishing priorities, and documenting request references and response files. It is designed to be run using SPF Dialog Manager and SAS. Project Management TITAN requires the user organization to define a common file of specific ""project"" and associated sub-project or ""tasktl titles. A ""proj ect"" is simply defined as any area of responsibility which constitutes a significant portion of the organizations role. Subdividing ""projeets"" are ""tasks,"" where R. ""task"" is characterized as either a logical step within a project or a specific ~~spons~bility function •. Work assignments or 1tems, are used to 1dentify a specific action or set of actions. The three subordinated levels (projects, tasks, and items) provide a hierarchy that sufficiently defines and categorizes the work assignment. An example of TITAN project/task/item classification is shown below. Project #30 - Nuclear Fuel Budget System Task 4f10 - Program Maintenance Item #YY.N - Burnam Pgm. Revision The ""projects"" and ""tasks"" are predefined by the user group. and stored by TITAN in a table from which they can be retrieved by project and task number. This eliminates the need to specify project and task titles when ~ntering a new item. TITAN assigns a unique 1tem number to each item USing the format YY.N where YY is the current year and N is a sequential number between 1 and 9999 beginning with 1 each year. Time Management TITAN requires information needed for time management such as assignment date, due date, priority. and estimated vs. actual hours for each assigned person. Historic Record In addition to the project",Sugi-83-91 Willman.pdf
"enting relational data bases in a TSO (Time-Sharing Option) environment on IBM/Amdahl computers. SAS has proven to be a flexible, easy-to-use and low-cost implementation with extremely broad data manipulation and analysis capabil ity. The data bases support selective inquiry using standard- or specially- fonnatted reports. Any desired subset of information can be produced in any required order by making minor run-time modifications of existing programs. For example, given two files, one containing coded Attributes of fiel d fail ures (e.g., ·location, date. type~ cause) and the other containing narrative information associated with each individual failure, a report can be produced containing all records satisfying a given selection criterion and sorted in a specified order, with the narrative infonnation properly attached to each failure record. SAS also provides nice facilities for summarizing and charting information. For example, one program produces histograms of the failure histories over the last thirteen weeks of the ""top ten"" failing items. Pie charts portray the relative frequencies of faflure causes~ and scatter plots show the relationships between variables. APPLICATIONS We currently have _four different data bases containing facto~ test and field failure information on various types of equipment. Two of the data bases contain information derived by computer extraction from other files, and two are supported by manual input and edit. All the data bases contain mult",Sugi-83-92 Waina.pdf
"etenmlned a need for a Marketing Information System.that would allow for real-time access to vanous types of marketing data such as compet~tor cap~city information. competitor product lnfonmatlon, customer needs/directions/new programs. and government publication information (import/ export details). A small-scale system was created that allowed for inquiries to be made on a CRT using selection panels created with SPF's dialog manager. The SPF panels transfer nece~sary parameters to a elist which in turn wrltes a SAS program, using SAS features such as % include, the index function, SAS/Graph, and Proc TPRINT and then executes the SAS program once writte~. The small-scale system (involving data-entry of literally thousands and thousands of observations using SAS-FSP) took only four months to create, test and put into use with only a team of two handling the project--this was possible largely because of the ease-of-use and flexibility of SAS. Future plans are for the small-scale system to become a large company­ wide system. INTRODUCTION In April of 1982, top management of Milliken & Co. decided there eXlsted a wealth of market infonmation in the hands of its marketing management and marketing research personnel but that the data was too fragmented, too unstructured or too massive to benefit the company. It was decided to create a small­ scale prototype computer system to access and manipulate this data into a useable form. The computer system was to have ""real-time ll inquiry",Sugi-83-93 Frye.pdf
"Strategic planning, whether at a corporate or de­ partment level, requires a reliable control system to insure the accuracy. efficiency. and quality of its operations. At Texas Instruments, this need saw the deve 1 opment of an interact i ve. user-friendly Strategic Planning Control System (SpeS) to aid management in evaluating future fundable projects throughout the annual operations review cycle. The fol1owing paper describes the development and structure of the system, its use during the review cycle, and the advantages of its operations.",Sugi-83-94 Vendeland.pdf
"rd, Connecticut With the release of data from the 1980 Census the demand for timely application of this information for management deci­ sion systems has rapidly increased. The work that we report on here involves the integration of virtually millions of in­ dividual statistics from both the 1970 and 1980 Census into a system which allows retrieval of informa tion for user­ d~fined areas of interest. These areas are constructed through a user-friendly interface which allows either existing geo-political areas to be selected and combined or geometric shapes defined (for example, a circle describes all the area within a fixed distance from a specified point). There are a wide range of applications both public and private sector, for such information. This paper will focus, however, on the utilization of this system for multi­ site consumer outlets where the areas defined approximate market areas. SAS programs and IBM TSO procedures are '1.escribed which allow the demogralJhic and economic characteristics of a user's series of current facilities to be merged with actual client data. Types of statistical analysis and modeling that follow from this capability are then discussed. BACKGROUND Business decision making has changed radically over the past several decades with the rate of change increasinq to unprecedented highs. Two keys have been responsible for unlocking the door to advanced scientific business decision making, the development of high speed computers with their associ",Sugi-83-95 Meyer.pdf
"AS macros designed to permit storage, retrieval, and man­ agement of bibliographic citation.:;, The macros are intended for relatively unsophisticated users of CMS/SAS. It is assumed that such users have access to an editor (e.g., XED!T) and a format­ ter (e.g., SCRIPT), but have relatively little working knowledge of SAS data library operations. One set of macros performs input of new citations fram rather free-form sequential files, with important features (e.g., date, author) of citations demarcated by user-modifiable signals. Citations to be input may (optionally) include keywords, and notes or connnentary of arbitrary length. Macros are available which allow the user to search through stored entries by date, author, keyword(s), words contained within the citation itself, and by portions or combinations of these elements. Items retrieved through such searches may be output as SAS data sets, to be processed later by PROC'~ such as PRINT, or as external sequential files to he processed by CP/CMS commands. The user may request that such external output files include markup commands, so that they may be input directly to a formatter like SCRIPT. The system can also produce direct­ ories of authors, titles, and keywords currently in the user's citation data library. Desiderata The time-honored system of using 3xS file cards to maintain information about bibliographic citations does have the advantages of being inex­ pensive and rather flexible. Rut it can also be tedious to us",Sugi-83-96 Gleason.pdf
"EASYTAST: A Complete Data Management System Using SAS and TSO/SPF for Target Animal Safety and Toxicity Studies Dr. F. E. Livesay and Mr. R. l. Van Duyn Lilly Research Laboratories Background Lilly Research Laboratories conducts Target Animal Safety and Toxicity (TAST) studies to obtain regulatory approval for animal nutrition and health products. TAST studies are required by the Food and Drug Administration to show that the proposed animal products are safe. Studies are conducted in broiler chicks, pigs, sheep, calves and large cattle. A typical study requires that twenty animals of each sex be randomly assigned to four treatment groups; control, lx, 3x, and 5x treatment levels. The treatment levels and treatment time are based upon optimum values as determined in other efficacy studies. The data collected varies widely from study to study, but usually body weight, feed consumption, several blood parameters and urinalysis values are collected. Following the unsuccessful use of previous systems, a small SAS-based system was completed in the early fall, 1979, in time to meet the analysis needs of a TAST study. Indiv,idlJalized training on SAS was provided the scientist who soon proudly announced, ""For the first time in 13 years, I have control over my own data. II This small SAS-based system has functioned quite well for 3 years. Because the system has been successful, other enhancements have been planned. In particular, it was desired to implement a system based upon the following set of philosophies: Design Philosophies 1. A research data processing system is a powerful tool to extend the personal memory and calculating abil.ities of an indivirlual scientist and research team to help them to be as efficient and effective as possible in turning research data into research information. 2. The data system should provide a researcher (and his consulting statistician) easy assess to his data and to provide results from which inferences can be drawn and decisions made. 3",Sugi-83-97 Livesay VanDuyn.pdf
"~,: INCREASING PRODUCTIVITY: BATCH AND ON-LINE-INTERFACES TO SAS USING SPF DIALOG MANAGER CARY N. PRAGUE. Inc .... easi ng p .... oducti vi ty is of key impo .... tance in today's economy. UsinQ SAS as a computer language 15 a way to inc .... ease p .... oductivity both in use .... s and p .... ogramme .... s. One p .... ablem we have found in helping people use SAS is that u<sers mu~t be taught dataset concepts and even Job Control Language to run their iobs. p .... og .... amme .... s campI ai ned ther-e were too many que<stion<s to an<swer in standa .... d SAS CLISTS 0.... alot of files to change in batch JCL. To solve these problems I have written a series of SPF panels. Some allow a SAS user- to USe SAS in the batch mode while othe .... s allow a use .... to use SAS in the on-line 0 .... interactive made. Usi nq these panel s has i nc .... eased producti vi ty fau .... to six hund .... ed percent in my benchmark studies, especially in the debuggi nCi phase of a p .... og .... am. These panels have eliminated the need fo .... a user- to Llnde .... stand dataset concepts or JCL. Topics that wi 11 be cove .... ed are: The on-l i ne port i on uses the 1 atest versi on of SPF to create a power-ful front-end and back-end to SAS. Included a .... e menu fields to retrieve the SAS program in any format including a pa .... ti ti oned dataset, sequenti al dataset"" and even interactive SAS. All in-fi lesfoutfi les can be entered wi th the dispositio~ specification. An interface to the peri pheral s of SAS/GRAPH is included. The ability to specify the log file to the terminal or a tempo .... ary dataset that can be browsed or printed also is possible. There is a place to specify SAS options as well as an optional interface to PANVALET • • A very powerful back-end cont .... ol saIl b .... owsing and p .... inting of the infilesfoutfiles~ log file, program, and output repo .... t. The p .... oq .... am may be reedited and .... erun withoLlt leaving the system or reallocating",Sugi-83-99 Prague.pdf
"~ most common techniques used in computer performance e'/aluation. This paper discusses how the FASTCLUS procedure can be used to analyze workloads. In particular, it discusses scaling and the treatment of outliers, how to effectively use the objective radius parameter, and the idiosyncrasies of the FROC FASTCLUS algorithm. U:lfortunaLely, the use of clustering techni',!ues 1.0 Introduction i:ltroduces a number of other statistlcal issues. Among them are scaling and the treatment of During the early 19705, Domenico Ferrari outliers. Improper scaling and failure to account introduced the concept of workload for the influence of abnormally large observations characterization (FER72). The basic premise of (i.e., outliers) are the most common reasons for the concept was that studies of compu~er systems investigators obtaining ilIValid results workload could be facilitated by the identification of a characterization studies. number of ""resource patterns"" lhat could be used to statistically represent a systemls workload. Since the introduction of SAS FROe FASTCLUS, a Since capacity planning and performance management number of instal~ations have attempted to apply studies often encompass tens of thousands of jobs the methodologies that have been introduced by the or hundreds of thousands of transactions, the prior investigators. Unfortunately, some of lhese ability to represent the workload by a limited users have obtained results that can at best be number (typical studies result",Sugi-84-02 Artis.txt
"OCIETY ABSTRACT Analyzer II, RMF, SMF. We needed a means of culling only the data of interest to us, This paper will describe the development summarizing it and saving it for later of a system to track problems related to analysis. This analysis would be used to spot various hardware components in a nationwide trends, predict future hardware needs and on-line health claims payment system. guide us in fine tuning the system for better The Net~ork Availability Logging and response time. To this end, we designed a system u~iQg SAS(R). Reporting System (NALARS) was developed to fulfill a need for accurate, complete SAStR) was chosen because it was easy information on vendor hardware problems. It to expand as new needs became evident and it was done in two stages. We will discuss the would be easy to develop ad hoc reports reasons for the two-part development method, without a lonq lead time. We establised the extensive error-checking, a high deqree of separate SAS(R) databases for each CIes user-friendliness and the use or SAS(R)I in system. In addition, we createD program, accomplishing these goals. macro and format libraries to support the NALARS is used by two distinct groups of system. people--network control operations staff and network management personnel. The needs of DESCRIPTlCN OF SYSTEM both groups and the solutions to their respective problems will be explained. Problem Definition To accomplish our goals of ease of use Network management was having a difficult and ass",Sugi-84-03 Blitz Levine.txt
"Douglas Automation Company Calculate the rclative variablcs of these ABSTRACT different measurements. A method of allocating scarce computer resources is of prime concern to data processing PURPOSE s~stem managers attempting to control the and distribute the cost of these resources back to the user. Therefore a computer cost distrib- The purpose of this study is to determine and ution algorithm was developed using the system analyze the signi:icant factors involved in resource measurements available in the HIeS data charging for computer resources. An attempt shall be made to discover a valid relationship base. This algorithm was designed to discretely account for batch and time sharing resource among these factors which could be developed utilization in an IBM 370/30XX environment. into a desirable cost algorithm. A valuable pricing scheme requires several critical charac- teristics. It must be equitable, understand- A background of why this is necessary and abl/';!, controllable, reproducible and stable, the restrictions that are_ placed on this type of algorithm are provided. It is demonstrated how thereby making i t marketable (Bernard, 1978). SAS can determine the critical variables in an Therefore, it must not only recover costs but algorithm and how the corresponding coefficients also allocate the scarce computer resources are determined. Statistical methods such as the appropriately. Norman R. Nielsen(1968) states multiple stepwise regression analysis and the in his a",Sugi-84-04 Bluth Waits.txt
"DASD MANAGEMENT. An overview of the Haws and Whys Stanley E. Rubinson Miami-Dade Community College The single most critical resourc! other programs in the system must wait affecting the p~rfoTmance behavior of a their turn. computer system is PERIPHERAL activity, In a typical data processing center the bulk of the peripheral activity centers Now let's discuss the DASD peripheral around the disk - DASO units. Thererore, activity. management of the DASD system effectively equates to the management of Each time that a progr~m requires a the data processing system. transfel' of data. it must switch to the operating system to invoke the actual read 01' write function. Since these To fully understand haw DASD imparts commands al'e cDn5ider~d ""pTivileged."" this critical impact. i t becomes only the operating system can execute necessary to briefly discuss the them. One othel' item to remembel'. although the 110 path can progress elements of a computer system's performance behavior attributes. For the thl'ough a peripheral activity purpose of simplicity. this discussion independent of the computer. it will is limited to a single CPU computer impact the computer system in two ways. First. during the actual transfer of system. data between the peripheral device and the memory within the computer. the CUrrent technology is sometimes instructional capability of the computer described as the capability to must wait for the memory (which is a accomplis~ multiple functions (or Jobs) serial resource) if the input-output running in t~e system. If we were to requires that resOUrce. Second. lIIhen the interrogate the status of a machine at a peripheral transfer is completed, the computer is instructional Tlow is halted given moment in time. we would certainly find a number of batch Jobs running again to service the ""interrupt"" command concurrent with a teleprocessing (TP) issued by the 110 path. s~stem. T~pically the TP network includes a group of local as well as remote terminals.",Sugi-84-05 Rubinson.txt
"decision maker can order the objectives, based on their relative importance to define a preemptive priuriLi;t;dLioll of lhl:> objec::..ives. The ubje<..Lives Many problems that arise in the practice of are then optimized sequentially according to the management science require decision making in the priority scheme. This approach has an advantage feee of multiple objective::;. Usually these over the aggregation sehe_me in thflt_ it eliminates objectives rep:cesent conflicting goals so that the need to evaluate all objectives in one given the achievement of one over another results in measu:::-e. Furthermore, i: is often a more accurate tradeoffs in the ""overall good"". In t:-'is paper we model of the decis~on makers desires than that of consider the problem of decision maki:Jg when the aggregation scheme. The decision model that there are multiple objectives in the restricted results from this approach is called a goal setting of linear deterministic models, We program. When the objectives are linear the model discuss the formulation of these models, &.nown as is called a linear goal program. linear goal programs, and present 'a macro in ~he SASi& language that uses the LP procedure in SAS/ORfM to solve them. A Network Example",Sugi-84-06 Cohen.txt
"APPLYING PATTERN RECOGNITION TO VALIDATING TIME SERIES DATA FOR ELECTRIC UTILITY LOAD RESEARCH Andrew E. Allen. Hinimax Research Corporation Tom L. Juhnston. Minimax Research Corporation Ed""""ard L. Tabakin. NinimA.X Rt>.search Corporation INTRODUCTIOt: 1. The switch ~ay fail to open, either inter- o mittently or consistently, upon receipt of In 1981. PGandE's Residential Peak Load Reduc- the correct signal. LiLln (RPLR) Program iLlcluded the direct control The air conditioner may continue to func- o by PGanciE of over 38,000 central air conditioners tion after the switch opens, if the switch and 600 electric water heaters. distributed over is mis-installed. eleven test site areas. Since then, the program has grown to include over 68,000 air conditioners o The meter may produce an incorrect number and 2,000 water heaters. Participants are given of pulses. an incentive in the form of a monthly discount on a The recorder may either add spurious pulses their bills. or drop valid pulses, on either the data tracks or the timing track. To provide load data for analysis of the pro- gram, PGandE installed pulse-initiating watthour The cartridge may be incorrectly removed or o re80rding equipment, including both maGnetic tape inserted. and solid-state load profile recorders, at 500 o The meter reader may write down the ,,'rang participants' houses distributed over seven test cartridge removal or insertion time. Si::2S. Figure 1 shows the configuration of the cycling and metering equipment. The receiver is The data may be miRtranRlated on the micro- D coded to respond to signals for a certain ""ad- computer~ for example, by using an incor- dress"" (radio or tone frequency). When an appro- rect scale factor. priate signal is received. the switch opens, lurn- ing off the air conditioner(s). The meter mea- In addition, mis-installation may prevent any sures both energy usage of the air conditioners usage from being recorded on one or more channels. and of the total household, and",Sugi-84-07 Allen Johnston Tabakin.txt
"ather conditions as well as This paper applies Box-Jenkins time series analysis analyze previous forecast errors in terms of to the problem of modeling and forecasting inherent model error, and errors due to the monthly residential sales of electricity. Using the forecast of the input variables. SAS/ETS ARIMA procedure, the identification, estimation and diagnostic checking stages are out- DATA DEVELOPMENT lined and forecasts presented for an ARIMA Short-term (one-month to eighteen months) sales transfer fUnction model. models and forecasts are an important input to company planning processes in the area of Due to the strong dependence of residential budgets, fuel planning, rate setting and weather electricity usage on weather conditions, transfer normalization of sales. Like all companies, the functions are specified for the two input variables, electric utility needs a forecast of revenues for heating degree days and cooling degree days. In the coming year in order to establish the order to account for the time varying nature of the budgeting and schedule its manufacturing process, weather parameters, the input series are precon- and since kilowatt-hour sales is the primary ditioned by the saturation of weather sensitive variable affecting revenues, the sales forecast appliances. A further input, the number oj resi- becomes the basis for revenue forecast. For fuel planning and adjustment purposes, a six-month dential customers, is incorporated through a use- per-customer sp",Sugi-84-08 Jacob.txt
"FORECASTING INDUSTRIAL PRODUCTION - 1981-1984 Carlos T. Bailey, Huntington Alloys, Inc. 3. A 1.0 reference line (i.e., same value as First, some background about Inco and its a year ago) provides a convenient visual refer- business. ence of the status of the business cycle. possesses a number of interesting ~ickel properties which cause it to be used i:1. vary- 4. A timely indicator of the ""momentum"" of a ing proportions. from 1% to 99.9%, as a primary series is obtained. alloying ingredient in a variety of ferrous and non-ferrous alloys. ~~erever t~e service con- Until recently, we have depended upon the ditions are demanding, one can expect to find macro-economic forecasts published by firms a nickel-containing material, ranging over a such as DRI, Chase, Wharton. etc., for our IPI 0= forecasts. One problem with all of these ser- tremendous number applications as diverse as the lead frame for a semiconductor mi crochip 'J'ices is that the sheer volume of variables to the coinage in your pocket to the aircraft being forecast prevents publication of any er- jet engine you last depended upon. ror band around the ""point"" estimates. However, in 1982, the lack of a confidence interval was Because of this "",ride variety of a?plica- overshadowed by the fact that for at least nine tions, the broad measure of induotrial produc~ months of 1982 all the macro-forecasts of which tion has proven to be an excellent measure of I am aware were simply wrong, 8S we shall see. physical demand, whetr.er for forecasting pur- That is, industrial production was forecast (by poses or for price analysis. Hence, we have the macro services) to begin climbing each month from March, 1982 onward, when in fact the actual nad a long-time interest in good forecasts of bottom did not occur until December, 1982. the Federal Reserve Board's Index of Industrial Production (IP!). (Figure 1) To think of paying (handsomely) for that As producers of these alloys, we are ex- kind of forecasting prowness i",Sugi-84-09 Bailey.txt
"Prelimil'lary Trandormation. in Time Seriet Modoling David A. Dickey John C. Brocklebank Associate Professor of Statistics SAS Institute Inc. North Carolina State UnlVl!!rsity Cary. N.C. Raleigh, N.C. 1. INTRODUCTION This Implies that the sen .. s mean is 100 and it's variance IS 400. If the last two observations are 128 and 135, then our forecasts The theory of estimation and forecasting of stationary time wilt be 140.32. 144.23. 146.95. 148.68. 149.60. 149.85. 149.55, series IS fairly well developed at this time. The sAs/ESTr. 148.88, 147.73, 146.37, Tile forecast standard error will procedures such as ARIMA and STATES PACE allow you to approach 20 ~nd the foreca~t will approach 100. easily fit models to stationary data anc forecast from these models. Procedur-es such dS FORECAST a""d AUTOREG alluw for specific types of nonstationarlty, but you must specify them 11'1 Stationarity and Differl!!l'Icing advance. Thus. you must either assumE! a spE!ciflc type of nonstationarity (for example a trend) or reduce the data to Contrast this with the model stationarity through some type of preliminary transformation. Two cOnl;ideratlons are of interest in thiS regard. First, 100me kind of contemporaneous transformation of the data such as Again let the last two observations b .. 128 and 135. We now get Xt=log{Y ). may be more amenable to modeling than the original forecasts 140.6C, 145.08, 148.66, 151.53, 153.83, 155.66, t 15l.B, 158 . .10. 1~.914, 15999, data Second, some kind of transformation involVing I.. g differences, such as X ""Yt- Yt_1' may reduce the series to t stationarity In this case, which occurs often in practice, the We seE! here two very similar models ori9illal dala Y t iliO said to have a unit root type of nonstationa rity. This paper re\liews the Box -Cox transformation as introduced BOI( and COl( {1964) and used 11'1 the well-known book by BOI( 11'1 and Jenkins (1976). Examples using the 5AS® System demonstrate methods that indicate when contemporaneous",Sugi-84-10 Dickey Brocklebank.txt
"Wayne W. Crutcher and David P.Menapace Loyola University of Chicago Medical Center ABSTRACT of mp.dic.inp., R SIS-hed teaching hospital, the school of dentistry, the school of graduate Computerized nutrient data base systems are studies in the allied health basic sciences. available and can be utilized as instructional tools by dental. medical and other students in Since opening in 1969, this center, which the allied health sciences in the study of adjoins a large VA hospital and a state mental nutritional science. health center, has become one of the more comprp.hensivp. hp.a]th care complexes in the \Hth these data banks, students can develop Chicago metropolitan area, and the only major skills in the compilation and the analysis of heal th center serving the weste'rn suburbs. patient food consumption histories, in the ACADEMIC COMPUTING SERVICES calculation of nutrient composition of foods. in the design and evaluation of individualized nutrient standards menllS for meeting specific The medical, dental and nursing staffs are and objectives in preventive health care, and in supported by a wide range of technical skil h the utilization of nutritional assessments for provided by ancillary support personnel. the development of clinical treatment Facilitating access to computing resources for strategies. supporting education and research at the medical center is provided by the ACS department. In the summer of 1982, such a. data base system was designed and implemented by the",Sugi-84-100 Corliss Simmons Crutcher Menapace.txt
"TECHNICAL EXPOSITION OF GRAPHICAL TOOLS IN SURVIVAL ANALYSIS G. G. Enas, C. D. Hardison 7 and F. W. Rockhold Eli Lilly and Company SECTION 1 - INTRODUCTION i.~ f Tt,e produ(t-l nit <'!""timator 0' then G>:aphical technique"" are useful tools in 6 veil by lIIany arc.:ts of sta~i""tical evaluation and this is especially true in th"", analysis of d ""J time to failur"", data from eontmlled J FpL (t) "" clinical trials. Hypothesis testing Y' (j) "" l procedures are bec,~ming increasingly mor"", available in the form of compLter softW'are, .A.-sume th..~t a~y tied, kJ.·,'.m "";illlres fir"" They are also becOIDing more sophis~icated, .:f '.it «p"",rt 111 infi.nitessimal U·_l. ""len~S a,\( but there ilre few descriptive statistic~ UnCensored obserVations occur just prio: to useful in summarizing the data. All of this censored observations when ccnsore"" and increases the ImpOr:ance of the role uncensored observations are tied. graphics has to play in the statistical ~nalysis of these data Confi.dence intervals may be computed by ""irtll.;o of the asymptoti~ cnnvergence o£ In this paper \<""e present the outline of a F (t) :0 a :;aussian process whose variance menu-driven system writlen in SAS which may approximated using Greenwo-)d's :orrnu.la prrwides the rl~t<l <loalyst with tools to !:~i::~o;.dtfince of til"" ~l,;,,,iL""'~ <lLLu<l""ial characterize a set of failure time data, eXalline the validity of statistical assumptions, and test hypotheses. 7he need 0-0')""% con£idence interva~ is then given An for this system grew out -)f a real application "" in the analysis of a clinical trial. The desire was to provlde the statistielan with traphics In aid 1.n ma::ing inferen.'es lnd as a 'Ilechud of presenLng results tu ilo',)""tatistica 1 audien(~s. Thus presented is ,"" d. ~ [':h~ V~l.i.O""s olltiolls aVdi.;. ,lJl~ ('U!'."">'Y J = FpL Cll 6,'· (21 ~n fh .. s:is~em r1ngug ~rom b.1~ic descriptive l -c!. ) ("" Yell "" ~rclphi(,' t-l' re:a,iv""ly co'''plex d:'ag:lOstlCs J J J We begin by presenting in S",Sugi-84-101 Enas Hardison Rockhold.txt
"The relational nature of a SAS database This is why in this application there was a often puts it at an advantage over a hierarchi- need to first transfer information from a SAS cal database for ease of access and maintenance. dataset to an SPF table, update it, and transfer it back again to a SAS dataset. Altnough we However, continually updating a SAS database can could achieve this by copying data into a tem- slow turnarounrl, particularly as the size of the porary sequential file as an intermediate step, database increases. To reduce access time we this would again result in an unacceptable turn- developed a procedure which transfers data around time when frequent updates are necessary, directly from a SAS database to an ISPF table. and would not be efficient. To eliminate t~is This paper assumes the availability of ISPF step. a program invoked through SAS~ Proc (Interactive System Productivity Facility) and SPFLINK, was created to enable a direct link the 'Dialog Management Services' required to develop an interactive application under ISPF. between SAS and SPF. De sc ri pt i on",Sugi-84-102 Muro Shetzer.txt
"Although methods for exact power calcula- B (X'Xp'Y tions for tests of the multivariate general linear hypothesis do not exist~ convenient E Y'[I - X(X'X)-X']Y/[N - rk(X)]. accurate approximations are available for three commonly used multivariate test statis- In turn, testing the GLH requires estimating tics: Wilks' Lambda, Hotelling-Lawley Trace, and Pillai's Trace (Muller and Peterson, 0: . .. 1983). In thi s paper two computer programs = sC 8 U - 0. are presented which calculate these approxi- .0 ~ and V must be such that G is estimable mate powers. One program performs ""prospec- (identically equal to some-linear function of tive"" power analyses in which powers are the expected value of V), which guarantees calculated for tests on hypothesized models. invariance with respect to a particular B. The other program performs ""retrospective ll The three multivariate test statistics for power calculations on observed test statistics. which power is calculated in these t~~ programs",Sugi-84-103 Peterson Muller.txt
"ANALYSIS OF A LATIN SQUARE DESIGN USING THE SAS SYSTEM BAL~CED M. Lorie Skalland. Marion Laboratories. Inc. Kent R. Skalland. Farmland Industries, Inc. One of the most common uses of latin square DATA ON£;SE'r LATIN; designs is in experiments in which the different treaODents are applied in sequence to the same IF PEF(IOD=1 THfN DO,Yi=Y TRT1=IH:nt:TPUT ONf;fND; IF F""ERIOD-2 THEN DO; Y:?;Y TRT2=NT i OUTPUT ONE;END; patient. plot. animal or machine. Whenever IF PFRTnn"",::> THfN nn;Y3=Y TRT::>=NT Ol!TPUT ONE;f?ND; there is some reason to believe that residual effects may emerge, a common solution is to FROG SORTT DATA=ONE;BY COW; separate any two periods of treatment by an FROG I1EANS NOPRIIH SUM NdlY COW, interval of time sufficient for the residual \JAR Y1 '12 '13 TRT1 TRT2 TRT3; effects to die out. Often it is nol feasible OUTPUT OUT=NEW SI1M""'(1 Y2 Y3 TflTt TRT? TRT3; or desirable lo allow this inlerval of time. A solution is Lo change the method of ani:l.ly~l~ DATA TWO; SET NEW; of the resulls so that the lreatmenl means NT=TRT I ; R=Y?; OUTPUT; can be adjusted for any residual effects. NT=TRT2;R=Y3iOUTPUT; Cochran and Cox in their Experimental Designs FROC SORTT; DI' NT; book describe such a method for the balanced latin square design. The following SAS code FRoe MEANS NOPRINT SUM N;VAR R;BY NT; produces the analysis of variance table and OUTPUT OUT=R SUM=R; 1ft TOTAL OF THE YIflDS IN PERIODS 1I1M£DIATELI' descriptive statistics for such a design. FOI.LOWING THE APPLICATION OF THIS TREATME-NT ttl NfW; DATA THREEiSET OPTIONS NODATE lS=76i F=SUM(Of Y1 '(2 Y3), 1* ******************************-11-*******-11*** NT=TRT3; · · · · ANALYSIS 0' A BAL.ANCED LATIN SQUARE PROC SORTT; DY NT; · · DESIGN ,,, · · PROG MEANS NDf""RINT SUH Ni'llAR F,BY NT,OUTPUT OUT=F SUM=F; · · LATIN SQUARE 1* T01Al Of THE SHWr:I'I(;F.S E)(flMPlE IS A · · USING TWO SQUARES IN WHICH THIS' TREf'lTMENT · IS HiE FINAL ONE *1 · · EXPERIMENTAL DESIGNS, REfERENCE: CnCHFl'Af.! wr.. CO)( OM, · · · SONS,",Sugi-84-104 Skalland.txt
"PROC ARKMAP: A Low Cost Method of Presenting Geographical Data in an Educational Environment Dennis w. King, University of Arkansas Richard M. Smith, University of Arkansas be produced using limited equipment-CRT INTRODUCTION and line printer; (2) It is easy to use The ARKMAP procedure is a means of because of its limited command set and parallels to standard SAS procedure creating county-level choropleth maps of coding 1 (3) Few map design decisions are the State of Arkansas (Figure 1). It is required on the part of the user. The in current use primarily by researchers, selection of class intervals (levels) graduate students and classroom students and print symbols is built in and is in the College of Agriculture for consistent with the most current presenting geographical data. There are cartographic research. several reasons why ARKMAP is an attractive procedure: (I)"" The maps can ............ ............ : : : : : : : : ~"""""""" .. ,, . . . . . H ~""."" < ........ "" .................... "" .. """" ........ ,,"""""" ....... ,,"" ........ "" ........... ,............. "" ........... "" ............... "" ....... "" ........................ : ... ... "" . . . . . : .. "".... "".... ""· .. ""··<>"" ...... ~ .... "".. "".... ·........ "".. ·...................... "".. ~f~[~O; .. :E~i~~"" .... ·.......................... ·.... ""...... "".. ·...... ""........ ·.......... ·.......................... .. LP""ns PATTEIIN CLIISS LIMITe; PAHEIIN (LA""S CLAS~ L P""!tS ..... '"" ., ... )I<;T · ~r. I l l l I '"" toE DI SE nIST. iiHi '"" 1111111111 · s ... 0 I<;r · ~""'"" ""~"""".'"" ................. "" .. <> .. ......... "" ................................................................ "" ....................................................................................... : 566  of the mean. ARKMAF is written in PL/I and runs Current cartographic research in a 1 MB virtual machine under VM/CMS indicates that the average map reader is SAS 82.3. ARRMAF will process both unable to reliably differentiate more numeri",Sugi-84-105 King Smith.txt
"L061STIC RESRESSION AND ASSOCIATED DIAGNOSTICS USIN6 PROt HATRIX Thl chi-.quarld goodnl'l-of-fit .tati.tic, ABSTR.ACT 2 X (ylog(y/np) + ,'V-l., thl d.vilncl, Logistic r,or ·· ,1an lodtll .,. ulld in .tny (n-y)log[(n-YI/(n-np)J), Ind th. ""Ulated covari.nc. latrix of b, U'YX}-l, .pplications. 80"" .... pIn includ. don- providl, rllplctivlly, .0.1 11.lurl of the r'.pons, IMp.ri.tnt., pro.plctive Ind retro- .pproprilten ·· , 04 thl fitt.d .0d.1 Ind thl spectivi studt'l of di..... ineidlnce, Ind the analysi, of Ilrklt ,b., I. Thl ulull ·· thad of u·· 4ulnl"" of thl Ixplanltory vlrilbll"" fitting logistic lad,l., IIXilU' likllihood, hll REGRESSION DIAGNOSTICS 2. good opthllity properties in idlll IIttin;' but il Ixtr.l.ly I'nlitty, to outlying '.Ipon, ·· ty) Di.gno.tic tichniqui' havi b.ln .v.ilabl. Ind IIItr ... p01ntl in the lod,. 'p'CI U). to idlntify .ub ·· t. of thl dltl that appl.r to D110nolt1c I ·· ,.r.. to lid the analYlt in hlVI a dilproportionlte influinci on the detlcting such ob ··rvations Ind in quantifying their .ffl,t on vlrioUI .lpI't, of the .~xi.u. I.ti.ltld norlal th.or~ r.or.,.ion .odel Ind to a.c.rtain Nhich plrt. 04 th. I.ttlat.d IOdil likelihood fit h,VI bl,n rl'lntly dlvelopld ar. 10.t ,f4lctld by th ·· 1 .ub ·· t. (BKN, 1980 10It natably by Pr.oibon (1979, 1981), hllhy, and Cook Ind ~.i.blrgt 1962), TNO ba.ic Kuh, Ind WIIICh (1980), Ind Landwlhr, Prlgibon, qUlntitt.. tblt Irl u·· ful for dltlcting Ind BhDllaklr (1983'. influlnti.l obl.rvation. are the r ·· idu.l ·· nd Thl purpo'l of this plplr i . to dllon.trltl thl proJlction I.trix into the Irror 'paCI. To thl 11.1 with .hic~ I laxi.u. likllihood ftt of ······ the i,plct of influ.ntill ob ·· rvation. I loOi,tic rlgrlnion IOdil Ind thl "",ochttd on thl I.tilatld co.4fici.nt"" thl ,tlndlrdiZld diagno.tic. prapa""d by Prlgibon (1981) cln bl c:hlnq' in thl cOlffict,nt. du. to dlletint I ilpllllnhd u.ino Proc ""Itrix. A. 100i.tic: 'inol' ob ·· rvltion, 'D'lti... d.notld by rlqrl,.ion i, I .""blr of thl c:",Sugi-84-106 Devlin.txt
"A PROCEDURE FOR SELECTING MULTIPLE-ITEM CU1DFF SAMPLES Ener9~ Eugene 11. Burns, Information Administration INTRODUCTION example, Cochran selection p~ocedure. For 1. pp. 113-123) presents severa! methods of (lS77, sample alloc:.tion for multiple-item probabi It~ samples, none of which are as strongl~ supported In sample surve~s the need often arises to b~ theory as the single-item methods. select al I or part of the sample b~ the cutoff method. A sample (or portion of a sample) Hultiple-item cutoff samples could be chosen b~ selected by the cutoff method consists of 01 I sampl ing each variable separate I y, and then sampling units with values above 0 given level merging the resulting samples into one. on some avai lable measure of size (MOS). Units Ho~ever, ~uch a procedure Iolovld ignore the rela- I~ing belo~ the cutoff a~e either subjected to tionships omOn~ the HOS. When adding a unit to fUrther sampl ing or omitted altogether. the sample based on its NOS for one item, the unit's other MOS also contribute 10 the sample Pure cutoff samples are nonprobabi lity somples coverage, regardless of whether the unit would because, given the MOS information, all units qualify for the sample based on these other MOS. are ~elected with certaint~. As nonprobabi It~ In extreme cases (see Table 1 for a simple exam- samples, cutoff samples have been criticized b~ ple) a procedure merging single-item 50 percent probability sampling theorists as lacking a samples could lead to 0 census of the pop- of precision and as relying on an un- ulation, ~ith 100 percent coverage on 01 I HOS meas~re verifiable assumption that the relationship variables. between large and smal I units is relatively constant (Raj 1972; Hansen et 01. 1953). However, cutoff samp I es have been tal erated in Table 1. Seleetion of a Merged Singl-e-Item 50 establ ishment surveys for two main reasons: Percent Cutoff Sample from a Population ~ith 4 Sampl ing Units and 1. Many variables of interest in establ ishment",Sugi-84-107 Burns.txt
"SCULLY, L.L. MICKLEBOROUGH, R.J. BAIRD Division of Cardiovascular Surgery. Toronto General Hospital and the University of Toronto, Toronto. Ontario, Canada Abstract SAS system was chosen as the software pack- SAS system. Our discussion will focus in the age for implementing data bases at the Division following areas: of Cardiovascular Surgery at Toronto General brief description of each of the data bases Hospital. Among the many retrospective and pro- file management aspects of the SAS system analyses of the data spective studies done by the Division, four on- going data bases were established between the period of 1980 to 1983: Data Bases Description Metro Toronto Open Heart Data Base To collect clinical, operative and post- Metro Toronto Adult Open Heart Data Base operative data on each patient in order to The city of Toronto is one of the major document indications and results in the city- open heart centers in Canada. In 1981, the wide practice of Cardiovascular sur~ery. three hospitals that perform open heart surgery Physiological Data Base agreed to participate in the data collection To examine ~ocardia1 performance as a result project. The purpose of setting up this data of various techniques used on patients during base are: and after cardiopulmonary bypass. to collect patient clinical information Intra-Aortic Balloon Pump Data Base on a cfty-wide basis To document each patient that requires bal- to document indications for surgery, loon counterpulsation. providing in",Sugi-84-108 Tong Kuzin Weisel Goldman Scully Mickleborough Baird.txt
"A SAS MACRO FOR DETERMINING THE CAUSES OF INTERACTION IN A TWO WAY MOOEL Edward P. Barry, Schering- Plough Dar-Shang Hwang, Sandoz, Inc. IT EW. 1. Introduction = J In the analysis of clinical trials examlnlng Cj Wj 0 treatment by investigator interaction is a step before pooling the results across desir~ble investigators. When the interaction is statis- tically significant, the statistician would like the term PC j is the percent contribution of the to know which investigators are responsible for the interaction and how much can be attributed investigator j to the interaction sums of to them. This macro presents two methods for squares. answering these questions. Similar calculations can be made for the case of more than two treatments, but the value 2. Contrast Approach can be easily found by squaring the difference One method of determining which investiga- between the predicted values from the model tors are different from the others ;s to form without interaction and the model with inter- pairwise contrasts comparing each investigator action and summing over the investigator. to all others. We refer to this as pairwise These values are easily computed using OUTPUT interaction. With two treatments. the pairwise and PREDICTED features of GLM and calculating interaction contrast between investigators i and the differences and sums in a data step. j is made oy calculating 4. The Macro The following steps are taken by the macro: ~ delete the blocks with empty or small cell s - write the pairwise interaction contrasts a t-statistic with the error variance and degrees of freedom from a two way ANOVA model. to a temporary data set One can then find how many times an investigator - perform a GLM for a two way model with significantly interacts with the other investi- interaction on the raw data, and use the gators. Those who interact most frequently with above contrasts the others are presumably the chief contributors - read the output from GLM and save the to the over",Sugi-84-109 Barry Hwang.txt
"TN PkEDICTING PRISON POPULATION USING THE SAS/ETS PRODUCT* Davis~ Steven Oklahoma Department of Corrections Intrcduction. Some of the earliest applica- the analysis. All data were aggregated by tion!'; of Box-.Tenkim; time seTies analyses in month. the social sciences were concerned with law enEo~cement or criminal justice data. for Identification of Time Series Models. The example, analysis of data on the Connecticut input and outpufMvariables were first plotted crackdown on speeding (Glass, 1968). Since using SAS/GRAPH PROC GPLOT (see Figure 3). that time. many of the reported time series Next a univariate model was identified for analyses of criminal justice data have con- the output series prison population. After tinued t.o center on evaluation of the impact examining the plots of the raw data (Figure 3) of innovations such as speed limit. laws and sample autocorrelation function (Figure (Johnson~ Klein and Levy. 1976) or gun control 4). it was clear that there was a trend in the laws (Deutsch and Alt~ 1977). However. events data and a first difference was required. of recent years have increased awareness and Parameters for several possible models were application at the torecasting capabilities then estimated for the differenced series and of the time series analysis. In particular. the residual autocorrelations examined. An increaSing prison populations. court decisions autoregressive model was found to be the most regarding prisoner housing. and decreased parsimonious representation of the data: appropriations have increased corrections .3IUUj~*B4 - .3I38S1~B8) (1 - B)*PRl~POP= planners 1 need for projections of prison (1 - population. In Figure 1. the sharp increase + 45.9945 at' since 1979 demonstrates that Oklahoma1s prison Univariate models were then identified for populat.ion has followed the national patter¥~ A project that was started to use SAS/GRAPH each of the input variables to be used in the programs* to plot this rapid population change pre-w",Sugi-84-11 Davis.txt
"beginning of the second period, each subject receives the drug formulation that was not ad- Federal regulations require that pharma~eutical ministered during the first period. An equal companies demonstrate the bioavailability and number of subjects are randomly assigned to bioequivalence of new products and of new form- each of the 2 sequences of drug administration. ulations of existing products. Bioavailability and bioequivalence are established by clinical During the 24 to 48 hours after each adminis- trials in which concentrations of drug in tration of drug, several blood samples are plasma, urine, or both measured after adminis- drawn from each subject to be assayed later for tration of the compound. The consistency of drug concentration. The sampling intervals are the type of data and the experimental designs chosen to characterize the absorption and makes it possible to develop a system of SAS elimination of the particular compound being programs to analyze and report the data. The studied. The parameters of greatest interest modularity of these programs makes adaptation for establishing equivalence of the 2 formula- from one trial to the next a simple procedure. tions are tbe largest observed concentcatiori (Cmax). the time interval between drug adndn- I.",Sugi-84-110 Crowe Malicz.txt
": Manually keyed data may need to be Some studies necessitate the quick visually checked to achieve a high level of processing of voluminous amounts of data precision. The visual checking process so that data errors can be located~ files involves comparison of the original document fixed and master files updated. Such against a listing of the data file. Various studies use a team of data checkers who problems are encountered in monitoring the identify errors and indicate correct visual checking process to ensure adherence values. Special coding and overall forms to quality standards. One approach utilizes examination is also done at this time. the injection of ""errors"" in listings to be Such a task is tedious and prone to checked. Errors can be randomly assigned to various kinds of errors. There is the variables and observations. Error frequency potential for overlooking values~ forms, can be modified. A sample program with aad even batches of forms. supervisor key to error location shoW's Supervisors have problems monitoring utilization of this technique. Unbiased the accuracy and consistency of data measures of data checking procedures can be checkers. Supervisors lack an objective obtained as well as measures of data measuring device to eliminate bias in accuracy. their supervisor duties. Without solutions to these problems the visual Introduction: checking procedure will not result in the quality of data needed by the project. Data in medical and clinical trial drug studi",Sugi-84-111 Taylor.txt
"TRANSFERRING DATA BETWgEN THE SAS SYSTEM AND FOCUS Edward P. Spotni tz, Signetics Corp. III. Examples I. Introduction In industry SAS is used extensively for data Figure 2a displays a cOL8ole session in analysis, statistical and mathematical which the CMS SAS environment is entered, a modelling, manipulation of flat data files, plot cf the actual and prOjected federal and graFhics. ':'he FOeU::: database management governmcnt deficit for the years 1970 to system is frequently used for maintaining 1982 is produced. and then FROe OUTSAS is large quantities of data and report invoked _to produce a descriptor file called writing. To meet the demand for quick SASFOCUS MASTER A and a binary data file transfer of data between the two systems :wo called SASFOCUS FOCTFMP Figure 2b A. simple eMS SAS PHaCs have been developed. displays a FOCUS session in which a report Thin paper discusses the concepts 'behind of actual and projected federal government these two FROCs, provides examples of using deficit is prepared using "",;he files created the PROCs, documents the langu~ge the PROC~ by PROe OU'I'SAS. are written in, and summarizes with the advantages of the data transfer concepts presented and tow they can be applied to transfer data between any software systems and/or stand alone programs. CO~POIUTIO~ NOTE: CMSSAS RELEASE 82.3 AT SIGNETICS (--------). II. PROCs OUTSAS and INSASY - the Mechanics "" option"" 1~·G8, "" fO~US; title E><a""""le of Transferring Data froll SAS to PRoe OUTSAS is used to tran3fer data from "" SAS to FOCUS. PROC CU~SAS creates 8 hnary proc plot data-deflcit.Oata; "" actua1 'year_' proJect-yaar' data file and a descriptor file. The plot 'P' 10llerlay; A' "" descriptor file contains the variable name, run, an alternative variable name, a print format for the veriable to be used when data is PLOT Of ACTUAL'VEU SYMBOL USED IS A prbted, and the actual format the data is PLOT Of PRO,JECY-YUR SYMBOL USED IS P stored in ( alptanumeric or double precision The descri",Sugi-84-112 Spotnitz.txt
"cted organ system listed first, Gary D. Rovack, Allergan Pharmaceuticals followed by the date of occurrence (in DATE7. Jeffrey S. Kouba, Allergan Pharmaceuticals format. with 31DEC99 for unknown dates) followed by a brief description of the adverse SIlMIIAAY experience. Other key words which may be entered anywhere in the comment field are: We have designed and used a system to manage clinical trials of investigational drugs using 1) names of the second drug (DRUG2A or a CMS data base, an INQUIRE data base. and a DRUG 2B) added to the regimen of series of SAS programs. 1 This system will terminated subjects described above. generate listings of subject status and nuaber; side effects sorted by organ system, a notation regarding any notification 2) date, or study: the number of subjects in each that may have been ,made to the human study for various time periods; and projected subjects Institutional Review Board visit dates. (IRB) or the FD1\ (Form 1639) of any serious adverse experiences. INTRODUCTION The second data base is an INQUIRE system Management of clinical trials of investiga- (INQUIRE DATA). Information regarding each tional drugs is often problematical. subject-visit is entered into this system by Typically, such clinical trials involve field personnel. hundreds of subjects who have been entered into the trial in a staggered sequence. Thus, PROGRAMS while some subjects are approaching the end of their participation in the trial, some are Eight SAS programs are avai",Sugi-84-113 Novack Kouba.txt
"A SAS Testscoring and Item Analysis Program which Utilizes the SAS Hacro }"" aci~i t y Charles E. Rich, Ohio University Backqround name and appropriat disk file data set name. The last line of each data file contains the parameters indicated on the The author (Rich, has 1983) previously described SCOR, a S~S program ~equest form. CALL SY~FUT statements in seo II to used by the Testsccring office at Ohio arE used crea te macro University to score multiple choice variables which will direct SAS macros tests, perform item analYEis, and create in qer:era-ting lines of SAS code. A raw data for USErs. full fi~es parameter summary sheet is output A descript.ion of the features provided by reflecting user- selected features. that program is availatle in the cited Also, if a job fails due to user error article. SCOR was tailered using eMS on the request form, parameter the execs according to user output requests, sumaary sheet output by that job will and a mUlti-step job was created to indicate the errors and the necessary process the tests. The ;01; was t her. run corrections. in batch on an IBM 370-158 against a Bulti-file data tape produced by an NCS fILF PUNCH is used to create 3. 7003 optical scanner. The present raw data files. Because of the article describes revisioDS designed to predominant demand for virtual data increase efficiency throuqh (a) havinq files, only card-image files are users specify features and suhtests on a produced by default. The operator customized NCS form called the Scan queries the system punch after the SCOR Request Porm, to I:e scanned with the iobs have run, transfers the SCOR punch standard NCS forms, (b) larqely files to the operator's reader and replacing eMS execs with S~S macros thence to the users' virtual machines. which generate SAS statEments in SCOR Backup copies of th e raw data fils sent accor::ding tc informaticn frOID the to users are kept in the operator's request form, and (c) runninq user jobs reader for a week. ap~ropria",Sugi-84-114 Rich.txt
"AEPG - AUTOMATED EDIT PROGRAM GENERATOR Lynn T. Julian. The Upjohn Company IntrodUction bee~ We have usi ng an automated approach to Many other applications would be able to create SAS® databases for clinical drug si mp 1 ify the inputs by i gnari ng ti me peri ods stud; es for a couple of years (refer to and creating a Study Description file con- Reference 1). I t has great 1y reduced the ti me taining only the names of the files describing required to analyze the data. Once the SAS® the records. Refer to Figure 3 for a sample database is built, both the programmer and the Study Description. The first column has the bi ostati stician can work with the data. Thi s names of the files containing the record de- approach requires a data dictionary to be scriptions, the second column has version built from files which contain record (or number, which will be explained later. the form) descriptions. In order to find thi rd cO'l umn has the record number I and the remaining columns ~ave sequence numbers repre- erroneous data, PROC FREQ has been used on discrete variables and PROC UNIVARIATE on senting time periods. continuous variables. However, often there is a need to edit the data specifically and ~. A program reads the study descrip- individually. rather than in groups and by ti on and is referred to each of the record classes of variables suc~ as discrete and description files. It creates a SAse dataset continuous. For example, PROC FREQ displays w~i ch wi 11 be referred to as the SAse edi t all the values of a variable. and dataset. It contains the variables from all inappropriate values are easily detected, but the records in the system. The time periods it cannot be determined from this output which are ignored in this step. observations have the erroneous values. The PROC UNIVARIATE output lists the five lowest Step 2. The user enters interactively and five highest values, but other values through PROC FSEDIT the type of editing de- which may also be outliers ar",Sugi-84-115 Julian.txt
"7.MACRO UPONE FOR CAPITALIZING THE FIRST LETTER OF EACH WORD by Lawrence H. Muhlbaier~ Duke University Medical Center Judith A. Stafford, Duke University Medical Center This I.MACRO will only operate in We have recent 1 y found the need tq the envi ronment of a DATA program. The convert various files from the normal execution of the 7.MACRO is in two data processing format qf all capital steps. In the first, a '!.MACRO UPLOWSET 1 etters to a mi xture of upper and lower is called without arguments to define case. UPONE is specifically oriented to working variables and arrays, UPLOWSET converting nam~s and addresses from all is specified just once in the DATA uppercase to uppercase for the first program. The second 7.MACRU, UPONE, has letter in each word. The 'l.MACRO has one argument, the string to be converted provision for special cases (Mc, III, into upper and lower case. The argument etc) and is designed to be easily string va.riable is modified by the extended to provide for other special %MACRO. cases particular to an application. UPONE can handle a number of UPONE is written in function format and special cases in names and addresses. directly modifies the string variable The prefix ""Mc"" is followed by a that is its argument. The suffi>:es ""II~"" capitalized letter. ""III,"" and ""IV"" are all handled As more and more word proceSSOrS properly. The letter following the and micro-computers are being connected prefi;·: ""Mac"" or ""Van"" is not converted to mainframe computers, there is more becaLIse we found as many names whose and more interest in converting the text ne:·:t letter was not capitalized (e,g. data t VPi call y found on 1 arge mai nframe We ""Mack"") as was !e.g. ""MacDonald""}. data bases into a more ""socially .:'11 so judged that errors 1 i ke ""Macdonal d"" acceptable"" form, e.g. with upper and looked better than ""Macl<"" and ""Vandyke"" lower case in the form that we 1 i ke to I ooked better than ""VanCe."" see it on a typed page. Most of the mainframe databases",Sugi-84-116 Muhlbaier Stafford.txt
"and Freda Truman, Toxicolo8Y and Microbiology Division, He~lth Effects Research Laboratory U.S. Environmental Frotection Agency Cincinnati, Ohio 45268 and size, location and type of each observed ABSTRACT skin tumor. A typical study would contain 600 mice in 15 to 20 gToUpS. SAS software is being used to check and summarize vast quantities of data. The data In addition to 9825s, we also had a hard- comes from computerized collection of data in wire line from an HP 9825 to a PDP H/70 main- an animal housing facility by a Hewlett Packard frame located in our CincinnaU facility. In 9825 ""Calculator"". The data is collected weekly turn, the PDP 11/70 had communication capabil- for a peTiod of one year and consists of loca- ity with the Agency IBM 370 located in North tion, size and type of each skin tumor observ- Carolina. The point is that with available ed. In addition, study number, treatment number equipment and a fair amount of effort, a system cage number, animal number, week of the study, was designed in a rather simple manner that is operator ID, weight of the animal, and date of currently handling 8000 mice and producing over the current observation are obtained for each 4 million pieces of information per year. SAS weekly data set. A typical study will contain software he came an integral part of the system 600 animals in 15 to 20 treatment groups. In because it could process the data in a manner order to monitor each study, two SAS software that was acceptable to both i",Sugi-84-117 Laurie Stober Wessendarp Truman.txt
"MODELING CONGENITAL CARDIAC SURGICAL CASELOAD USING THE SAS/ETS PRODUCT Mary M. Lane. Veterans Administration Medical Center Cynthia K. Murray, University of Oklahoma Steven P. Davis, Oklahoma State Bureau of Investigation Ronald C. Elkins. University of Oklahoma Introduction data. Three observed values lie outside the 95% confidence limits established for forecast As the number of cardiac surgical procedures values. perforned on children at Oklahoma Children's ~1emorial Hospital has increased, i t has become Discussion of Investigation to the Point important for planning and evaluation purposes to learn more of the nature and causes of that Models which meet the adequacy criterion of increase. The three-stage Box-Jenkins process eliminating autocorrelations among residuals of identification. parameter estimation, and have been derived :or monthly and quarterly model adequacy evaluation was chosen as the data, but forecast values vary from observed values unsatisfactorily. Residual outliers means for modeling the behavior of the data. (see Figs. 9 and 10) nay occur at times when Analyses of the monthly and quarterly case changes in personnel. procedures, or other frequency time series were performed using the SAS/ErS ARIHA procedure. explanatory factors may have occurred. These will be studied as interventions (step, impulse. Procedures ramp functions) in the next phase of the inves- tigation along with birth rate series as input to the case frequency output series in a trans- The monthly frequency of cases was first fer function analysis. plotted using SAS/GRAPH GPLOT (see Fig. 1). The variance of the data appeared to increase with time and, therefore. a range-mean plot was made as suggested by Box and Jenkins (1976). This plot (Fig. 2) illustrated an increasing linear trend from which it waG inferred that a log transformation of the data was required. rhe log transformed series is shown in Fig. 3 and it can be seen. in comparison to Fig. 1. that the variance non",Sugi-84-118 Lane Murray Davis Elkins.txt
"AN EVAIl.IATIOlif OF 'IRE PCMIER OF THE K-SAMPLE BElL OOKStM STATISTIC krry Ko, Merck, Sharp, & D:Jhrre Research laboratories Edward P. Barry, Schering Plough Corporation 1. IhtroductLon denotes the carmon JX>pulation standard devid- tiona COhen referred to the measure, f, as the In the mid 1%0'6, Bell and D:lk6um (1) intro- stan:iard devLation of the standardized means. duced a series of stdtist.ics msed on randan f assures the value zero when fb is true and a large value whm the differences anong the :< normal scores. For the k-samplc problem, it involves replacing the original samples with means are largfd. the corresponding normctl order statistics. 'Ihis statistic has g<Xld asymptotic relative The alternative hypothesis can take on many pat- efficiency (A.R.E.); equal to' 1 as crnpared terns. In this p3.per, only the ::::ase where the with the F-test When the F-test is appropriate, k means are equally spaced OVer a maximum dis- and greater than I When the oorma.lity assump- tance of d is considere:1. AB described by Ccx::>k tion is rot satisfied. Howevl;!c, the Bell- and Larntz (5), the pa.ver for t.he other pdt- r:ok.suu test has a problodU of being dependt!nt on terns (given equal sdlllple sizes CiHong Lhe k the randan sample chosen from the standard groups) can be eusily derived fDDm this pattern. noDTldl clistribu't_ion. The objectives of this p:3.per are: 1) to examine the pc:1Ner of the Bell- of the Bell-Diksurn Statist~s...._~ 3. Power DJksum statistic and its canpdrison with t\\O _~ Sanple SiZes and Variances classical k-sarrple tests, the F and Kruskal- W:tllis statistics, under equal sample sizes and Simulation st.udies were done for k=2 and k=3 variances with an underlying distribu:.ion of with equal sample SIzes and variances under normal, uniform or exponent.ial; 2) to exarru...ne rnrmal, uniform and exponent.ial distributions. the influence of unequal sample sizes or vari- The canparative power of the Bell-I:bksum, F and anc~s on the power of th",Sugi-84-119 Ko Barry.txt
"e SCALINK procedure provides a link whereby SAS jobS can uti lize the extens'lve time ser'les capability of the SCA statistical system. 1. 'NTRODUCTI ON (5) Comprehens i ve methods for i dent i f i cat i on of multiple-input transfer function models, The SeA Statistical System. developed by Liu. Hudak. Box. MUlier. and Tiao (1983) implements (6) Conditional least squares and maximum like- the time series methods proposed by Box and Jen- I ihood estimation algorithms, kins 1:1976) and Tiao and Box (1981). The abil- ity to access the se~ system from SAS enhances Ability to retain mUltiple model informa- (7) the time ser i es capab iii ties of $AS present 1yin tion. the ETS 1 ibrary. The SCA system allows the user to :entatively identify, estimate, diagnostic check ~nd forecast using ARIMA, tr~nsfer func- 2. SPECIFICATIONS tion and vector ARMh models. The system pro- vides an easy to use control language and is a The statements used with PROe seAL INK are: powerful research tool for time series analysis. PROC SCALINK options; PROC SeALINK has been designed to faci I itate VAR variables; PARMCARDS; the use of the SCA system bot1 ina batch mode and interactively. 11 the first method of oper- seA statements ation, the user would uti }ize PROC SeAL!NK to bu i 1d ar SCA input procedure f i 1e and execute any SCA statements found after the SAS PARMCARDS PROC SCAllNK Statement command. Such a setup is illustrated in Figure I below where the SAS variables GASRATE and C02 PROC SCALINK op",Sugi-84-12 Stokes Liu.txt
"SAS MACROS FOR SAMPLE SIZE AND POWER CALCULATIONS Erik J. Bergstralh, Mayo Clinic a, prObability of Type I error ~ Lntroduction I a prtreject HolHo is true) The importance of sample size and power e. Prohability of Type II error considerations in planning and evaluatiflg l'r(reject HAIHA is true) research studies should not be undtorestimated. , z (zIPr(Z)z(1)=a) where Z is a normally If the samole size is inadequate, one can be faced 1oI1th- tll ... prohlem of large (and distributed random variable with mean substantively important) sample differences not zero and variance one, i.e. Z-N(O,I) being statistically significant. Similarly, 1 ZB' (z Pr(Z>zB )'B ) failing to reject the null hypothesis in studies [N], integer part at N. based on small samples, showing only trivial differences in sample estimates, can be very risky without some estimate of the probability All formulas are presented for one-sided Qf netccting a relevant difference (i.e. the If a two-tailed test is alternative hypotheses. power). In view of this, Lachin states three desired, one should replace za with za/2' All questions one must consider in planning and sample size values are rounded up to the next evaluating research studies l : largest integer before being printed. The Zs Ql. equation for is presented rather than the What sample size is required to ensure power directly. The macro output prints the adequate power in detecting a relevant power directly where the power ~ (I-Fr(Z)ze)' difference'? Q2. What is the power for detecting a A. Suppose we wish One-sample test for mean: relevant difference when the sample to study the random variable X in a sizes are fixed? popUlation where X~N(~ ,0 2 ). The aim of the Q3. What is the minimum relative study is to choose between Ho! ~=~l and HA! difference detectable with fixed ~9.I2 (j..L 2>~ 1) on the basis of a sample of sample size and specified power? size N · Note that if X represents the l differ~l1ce in measurements of paired data To answer",Sugi-84-120 Bergstralh.txt
"@1 R *1 The compustat data base distributed by DNUM RB4. I'INDUSTRY NUMBER /*CUSIP COMPANY NUMBER Standard and Poor's Compustat Services, Inc., was 'I CNUM $B /*CUSIP ISSUE NUMBER AND CHECK *1 input into a SAS data set with an updated version (eIC /*PILE IDENTIfICATION CODE FILE of macro SPYR (SAS/ETS). Appropl'iate inuustrial */ annual data items were selected to produce the ZLIST) (RB4.) /*EXCHANGE LISTING AND S&P INDEX*/ *1 financial statements as indicated by Compustat. /*INDUSTRY NAME INAME $28 Financial ratios were also calculated for the 'I CONAME $28 I'COMPANY NAME *1 I'STOCK TICKER SYMBOL selected company, and industry means of these 5MBL $B. *1 /*S&P INDUSTRY RtLATlVb cum: ratios were determined. The data were transposed, @249 (XREL *1 /*STOCK OWNERSHIP CODE all data items were labeled and footnotes were STK included so that pertinent information was dis- DUP (RB4.) '; /*DUPLICATE COMPANY CODE 'I closed in a meaningful format. Seven lines later the statement COL~85+4* (YR-i); shOUld read COL~89+4*(YR-IJ; these changes This is a practical method for businesses will allow for the correct input of the Compustat and classrooms since the user supplies only the data after August, 1983. The footnotes are company number-or ticker symbol to obtain the stored in a more useable form by changing the financial statements and ratius. The::;e SAS pru- SPYR statement FOOTNOTES $70 to {AFTNTI~AFTNT35) grams thus allow straightforward access to and conventional display of compustat annual data. ($2.) · The Compustat manual indicates the appro- priate data items for each entry of the financial",Sugi-84-121 Hirsch Byington Dodd.txt
"A SAS PROGRAM FOR CORRESPONDENCE ANALYSIS USING PROC MATRIX Bernard Clement, Ecole Poly technique de Montreal Daniel Levesque, Ecole Poly technique de Montreal Let ~ n1) Ll.: n .. Correspondence analysis is primarily a tech- 2: n .. .. n n. n .j 1) j 1. ') 1 nique for the simultaneous display of the rows and columns of a two-way contingency table in a n. n n .. ~ L -""l. low-dimensional vector space. Apart from contin- f f. f .. n .j n n 1) 1. gency tables, the analysis can be applied to table of positive numbers or to a suitably pre- f .. f .. I fi 1) 1) pare table derived from one. As such, it is a fi F N r .) r 1. n 1 J alternative well worth considering. to the more conventional methods of principal components and factor analysis. Noteworthy features of corres- N or F js represented by its row- Each row of C pondence analysis are the well-developed aids fOI (conditional frequencies) in R --- profile fl .c interpretation. space: i i "", (ri ·...· f )' i = l, ...· r f Since no correspondence analysis procedure c ~c I existed in SAS. we undertook to write a corres- with ~ £i. Similarly each c01~ of pondence analysis program for SAS users. The represented by its column-profile ~i in program is run under PROC MATRIX. It is easy to space: use and has a wide choice of uption~ available. especially for the graphical output. 1, .... c In this paper. an overview of correspondence with mass f .. .) analysis is presented and the general features of our program are given fOllowed by an example. The sqvared distance between two row- fi l f1 and is defined as profiles -c ~c CORRESPONDENCE ANALYSIS: AN OVERVIEN I The French statisticians have stressed the £:"" .) ,importance of a geometric approach to exploratory multidimensional analysls over the more classical ;approach of inferential statistics by hypothesis tes~ing. One of the most popular methods they use is correspondence analysis and its strongest advocate is J.P. Bcnzecri (1969, 1979, 1980). The \I'here technique is theo",Sugi-84-122 Clement Levesque.txt
"GENISYS was developed to run in batch mode on an IBM 3083 MVS system. An average STATUS Patlent accountability is of prime importance in the analysis of clinical trial data for a New Drug job for three record types with a total of 20 varlables takes under 30 seconds CPU in our Applica tion (NDA). The Generalized Inventory System (GENISYS), in use at Hoochst-Roussel, is a environment, and a CALENDAR job for 60 method of verifying patient counts for all time subjects' data with 20 record types takes under 50 points used in the statistical analyses. seconds CPU. The program is usually set up iind run by a programmer or a programmer trainee. The GENISYS System consists of two programs: Program Structure: 1. The Calendar Inventory Program (CALENDAR) produces a complete summary of a subject's da ta Tbe GENISYS programs run as one-step batcb jobs, and both 8T ATUS and CALENDAR are divided by record type. The presence of a record is indicated by its study day. Missing records are into four sections: easily spotted, making this report a valuable diagnostic tool. 1. A program narrative, optionally viewed by the user on a CRT, contains general instructions fOJ running tbe program. 2, The Subject Status Inventol)' Progmm (STATUS) shows the presence or absence of 2. A preprocessor, set up by the user, contains selected data for each subject for time periods the necessary Job Control Language (JCLl and defined by the study, and categorizes ·missing and excluded data. STATUS also produces",Sugi-84-123 Frueh.txt
"further confounded by having Abstract several variables which are subj ected to the statistical analysis. rather than only one. Experimental designs are often similar or Also, if errors in the data are discovered identical to designs of studies previously after the tables have been typed and checked. analyzed. Fnr example, in large-scale clinical one may need to go through step 4 more than trials. analyses of individual centers or other once. subgroups of patients are often required. For this reason, SAS macros have been written to Many of these steps can be averted in future analyze data. These are general in the sense studies with designs similar to the present that they can be readily re-applied to a later experimental design by initially writing study with the same basic design. general SAS macros. It greatly simplifies the process of analysis in the long-term. The macros require only that the SAS dataset be Subjecting numerous variables to analysis takes in a specified conventional form, and that no more effort than a single variable. as will several parameters be defined prior to invoking become evident in subsequent sections. And, if them. Hence, they are quite simple to use. error!'! in thf'. data are found after generating The output is a statistical table. complete the statistical tables. all that is required is with summary statistics, tests of hypotheses. to rerun the program. and confidence intervals. These tables are suitable for direct insertion into statistic",Sugi-84-124 Offen.txt
"PROC GLM - REARRANGEMENT OF OUTPUT Karen L. Bourn, The Upjohn Company c1arHy the type of output the macro wi 11 not INTRODUCTION work on. Analysis of continuous data from clinical An examp 1e of the ca 11 to REARANGE is found trials frequently involves the PROC GLM (Gen- eral Linear Models procedure). This proce- If the default values of the in figure 2. dure is often run wi til more than one depen- parameters are to be used, the parameters do dent var1able at several time points. The not need to be 1; sted. However, if the call to the macro is the last statement in the output from the PROC GLM procedure contains an ANOVA table and Least Squares means or SAse program, then the parameters should be means for each dependent variable at each included or a RUN; statement should appear time point. Depending on the model and the after the call statement. Failure to do number of time points the output from this either of these could produce an END OF FILE procedure can become voluminous. This some- error and cause the program to abend. This times large volume of data has produced the figure also contains an example of a multiple need to have a means by which it may be con- call to the procedure. If multiple calls are densed so that the desired information is in to oe made the files must be cleared first. a more useful and understandable form for Figure 3 contains output from REARANGE. The reports. To meet this need, a set of three data is from an actual clinical triaL but for reasons of conti dent;' lly all i denti fyi ng macros has been developed. The first rear- ranges the output from the General Linear information has been changed. The code for Mode 1s procedure by p1ad ng the Leas t Square REARANGE is found in figure 4. (LS) means under the ANOVA for each dependent STATISTICS FROfi ANALYSIS OF VARIANCE vari ab 1e a teach ti me poi n t. The second macro pulls the p-value and the F value along Often p-value surrmary tables, in which p- wi th va 1ues of the effect and t",Sugi-84-125 Bourn.txt
"USING SASe ISOFTWARE TO PRODUCE SUMMARY TABLES OF GLr1-CALCULATED STATISTICS Margaret A. Grady Northrop Services s Inc. Least squares means are calculated for all Although some of the results (predicted analyses of covariance. A sample of this values·, residuals) from the GLM procedure are output appears in Figure 2. available for furt2er analysis. other statistics such as the MSE, R , and least squares means Creating the Formatted Tables Input 2. cannot be accessed directly. In the preparation File from the Analyzed Data of reports of statistical analyses of datasets, The analysis jobs are run batch under tables summarizing the analysis of variance WVLBUR and fetched upon completion. Once it results, means, and least squares means can be is determined that the run was successful. the cumbersome to transcribe. Copying errors can JCL and SAS code are deleted, the remaining be introduced, particularly if the tables must input is stored in a dataset with DCB character- be retyped for inclusion in a published report. istics lRECL=133 and RECFM=FM which allows for retention of carriage control characters, and Using the programming capabilities of the SAS software. the desired statistics are read the job is printed. Several lines from the file from the output of an analys~s run and printed created using the second analysis run are listed in Figure 3. If a facility for fetching out in formatted tables. These data can also jobs is not available, the analysis jobs can be written into a permanent file for further be run using the SAS procedure PRINTTO. The analysis. The analysis program is run on an fi 1e created wi th thi s procedure wi 11 have the IBM 370 and the job routed to the OBS WYLBUR attribute RECFM=VBA. Using PRINTTO increases fetch queue. It is then saved as a sequential the CPU time required by the job. Additionally, dataset. If desired, the job itself can also because PRINTTO routes the job output to a be printed. permanent file rather than the print file, a s",Sugi-84-126 Grady.txt
"'-MACRO KAPLAN FOR KAPLAN-MEIER SURVIVAL CURVE ESTIMATION Lawrence H. Muhlbaier, Duke Unlversity Medical Center Michael J. Helms, Duke University Medical Center Frank Harrell, Duke University Medical Center This 'l.MACRO provides Kaplan-Meier output dataset cont.ains one observation Survival Estimates [1] and their for each unique uncensored TIME point standard errors from individual survlval plus one observation for TIME 0 and one time observations. The input file must observation for the ma>:imum TIME have variables for time to failure or observed, for each block (level of the ~nd censoring an indicator of whether CLASS variables) processed. the observation failed Dr was censored. In addition the file may have class or grouping variable(s). The 'l.MACRO provides one observation for each time The CLASS variables include MISSING as paint at which an event (a failure) valid level for generating curves. This occurred, plus one observation for time is needed sometimes bLlt not others. For o and one for the largest time observed now either delete them before calling in each group. The data set contains I<APLAN or whenever they are not wanted the optional grouping variable<s), a for a plot. time variable, the survival estimate! its standard error"", the nLtmber at risk, and the number of events. The data for this e;.:ample are from The %MACRO I{APLAN is wri tten in E.T. Lee (2] in which rats in three statement form and provides defaults for diets are measured for days to tumor. all of the parameters except for time Lee shows both the data a.nd a survi val and event_ curves for comp.arison wi th these. The '/.MACRO I<APLAN is a rewri te of and an extension to the (old form) MACRO 1. Kaplan EL and Meier P (1958). KMPL wri tten by Frank Harrell. .<Mf'L was Nonparametric estimation from rewritten to allow easy use of SAS J. Am · incomplete observations. · tatement form invocation of ths macro, Stat. Assoc_ 63, 4~7-481. and to allow the use of class variables. E.T. Lee Sta.t",Sugi-84-127 Muhlbaier Helms Harrell.txt
"USING SAsGP SOFTWARE FOR GENERALIZED SYSTEM TESTING AND VERIFICATION Claude Briggs, ORr, Inc. Katie Hubbell, ORI, Inc. I~TRODUCTlON In the development of large-scale systems The life cycle of a set of software can be divided into three phases as shown in such as a set of programs which interpret a survey, programmers and analysts ne~d ,to syst~m Figure T: the design and development phase, which incorporates the writing and deve I op ways of test i ng code and venfy, ng output. This becomes important when a large preliminary testing of code; the system system is being developed by several people. execution testing phase. which involves using SAS provides features which can be used to the source code with test data to check test code and verify output, for example, the syntax; and the system results verification FREQUENCY PDS and SOURCE procedures. These phase, during which the ""live"" data is used SAS proc'edures can be incorporated into with the source code and actual results are packages called subsystems which oper~te checked for accuracy. Four subsystems have independently of the main system and prov,de been deve loped by OR I, Inc. for the purpose information about the system to the of testing code and verifying output in the programmer, analyst, and management. The three phases of the softWare life cycle subsystems are written in SAS i however, the (Figure 2). The first subsystem maintains large system can be written in SAS , Pl/I, source code in partitioned data sets through FORTRAN, or COBOL. the use of PROe SOURCE and PRoe PDS. The FIGURE 1. The Three Phases of the Software life Cycle DESIGN IMPLEMENTATION DESIGN VERIFICATION PHASE 1. SYSTEM DESIGN AND DEVELOPMENT PHASE 2. PROmAHMEp. -~41 SYSTEM EXECUTION TESTING SUCCESS 678 second subsystem verifies successful PROGRANHER execution of the system and de letes unused OS ANALYST flIes allocated by the system. The third MANAGEMENT subsystem presents resu Tts to be hand checked by the programmer or analyst afte",Sugi-84-128 Briggs Hubbell.txt
"IMPROVING PROGRAMMER PRODUCTIVITY THROUGH CODING CONVENTIONS Anne M. Asher, ORI, Inc. Migdalen C. E1ey, ORI, Inc. The coding conventions described here were B. If a DATA step, uses the same constant adopted by the authors and their colleagues at frequently. substitute a variable ORI, Inc. for pragmatic rather than esthetic initial ized in a RETAIN statement. reasons. Though not always necessary or Then the constant value can be changed desirable, the use of these conventions with only one modification· instead of genera TTy saved more time and effort than was many. Efficiency will also be enhanced. needed to imp lernent therll. Not Recommended: Each convention helped in at least one of DATA OKAY; the following areas: other SAS statements Maintenance Made it easier to I. modify code after the initial testing and debugging. IF ( A LT 1 ) THEN A-= 1; II. Documentation - Clarified the purpose IF ( 1 LE B LE 10 ) THEN of the program, and of its component parts. Explained less obvious coding DO; algorithms and made code more B 1; readab 1e. C = 1; END; Efficiency Helped m1nlmlZe the III. computer resourceS needed to execute the program. RecotJJnended: IV. Error Prevention and Debugging DATA BETTER; Helped the programmer avoid logical and syntactical errors. or made it RETAIN ONE 1 TEN 10; simpler to trace the causes of such errors. other SAS statements The coding conventions are grouped by the major IF ( A LT ONE) THEN reason for adoption~ A = ONE; I. Ma intenance IF ( ONE LE B LE TEN ) THEN DO; A. When using a conditional DO loop B = ONE; (indexed DO, DO WHILE, or DO UNTIL) C = TEN; after a THEN or ELSE statement, nest it END; within an unconditional DO loop. Not Recommended: c. When multiple data sets are created in a IF X = 4 THEN single d.ta step, use Pl/I-sty1e DO I = 1 TO 5; /* INDEXED LOOP */ conrnents to describe each data set. This convention is also helpful for other SAS statements documentation. Remember that in the IBM-OS environment, Pl/I-sty1e COlll1lents",Sugi-84-129 Asher Eley.txt
"TM CHANGES AND ENHANCEMENTS TO SAS/ETS PROCEDURES by David DeLong, Leigh Ihnen and Mark Little ARIMA and AUTO REG changes: by David DeLong ARIMA PROCEDURE CHANGES AUTO REG PROCEDURE CHANGES The ARlMA procedure may now be executed interactively at the The AUTOnEG procedure has had two new estimation method~ statement level. Additionally, ~ome minor changes hal'e been made added, unconditional least squares and maximum likelihood. PROC to the estimation methods. AUTOREG will now generate confidence limits for the predicted values and can also handle missing ~alues in the input time series. The option CONVERSE may be specified on the PROC ARIMA statement to reque:;t that each IDENTIFY, ESTIMATE or FORECAST The Model statement be executed immediately. In this case the execution or the procedure is terminated by any ,'alid PROC or DATA state- The mudel u1>ed ill AUTO REG i~ ment or by the end of the job. If this option is used with the BY statement then the BY statement must immediately follow the PROe statement. When the termination or the procedure is = XB + v y signaled, all by groups remaining in the data set will be run through the same sequence of statements as the first by group. where y is an T X 1 vector ot observations of a dependent ';ariable, The o.lgorithm for computing the estimates has been modified in X i5 an T X k matrix of independent variables, B is a k X 1 vector of unknown constants and v is an T X 1 vector of unobservable some cases. A Kalman filter algorithm (Pearlman 1980, Morf, Sidhu and Kailath 1974) has been added to compute the so-called nncon- disturbances, usually referred to as the errors or noise. The noise ditio~al ~um of 5quarc,'j or exact sum of squares (S) for high order i1> a:s:sumed to follow an autoregressive process moving average models. PROC ARIMA now cbooses between a Kalman filter algorithm and a band Cholesky algorithm (Ansley 1979) to minimize the cost of calculation with the Kalman filter being cheaper for ARMA models with",Sugi-84-13 DeLong Ihnen Little.txt
"PROC UTM: Construction of a Procedure to Convert Nap Coordinates Between Geodetic and Universal Transverse Mercator Systems J~ff Yaplee, Boeing Computer Services ,!ona-id W. ~:parling, Statistician. U.S. Fish anJ Wildlife Service HHRODUCT IOi~ ~ ~ .x:-47·00' rT~,,,,~,""---'=""+l----C=------::~D 98·45' 54\'< '20""'""""""[ The SAS language has the capability of incorp?- -~ rating user-created FOKTRAN or PL/1 programs 111- LAT-LONB to SAS procedures. To interface these pr~grams with SAS routines. however. users must \','rlte o custom parsing and procedure modules to accomn0- date SAS supervisury system requirelolent::;. i\l- though the rules for writing these lilodules are specified in SAS progralTUller's guides, there are few examples which delineate step-by-step pro- cesses in their creation. Tl1is paper demon- strates a custom FORTRA.r~ procedure \'I'hich con- verts map coordinates between geodetic and Universal Transverse ,i':,'r.ator (UTI'l) systems and explains the steps iriv'j',v'C.1 in adapting a FOR- TRAN program to a SAS prol..>:2dure. The custom procedure we des iyned dddpts d program (J380) written by the U.S. Geological Survey (USGS). The geodetic system. which uses tne familiar no- tations of latitude and longitude, is universal- ly acknowledged as a means for measuring distances and angular directions over large U.S. Geological Survey maps use botn Fig. 1. aredS suctl dS conLinenLs or tle!;lispheres. At- 'deodetic and unl coordinates. tpmrts to locnte specific points with this sy- stem, however. are often cumbersome and require FEATURES OF PROC UTM a capabil ity in spheroid geometry. Several rectangular systems have been developed to Our procedure retains many features of tiie ori- facilitate making locations through the u~e of ginal USGS FORTRAN program. Input consists of a Cartesian coordinates. One of tIle ITKlre wldely SAS dataset which may contain obs~ervations accepted of these methods is the UTM system used either in geodetic form. expressea as de~ree",Sugi-84-130 Yaplee Sparling.txt
"rt J. Jannarone, Psychology Department University of South Carolina positively. Given the content of the two Abstract items, this result could be due to the situation in which H~hizophrenics might find This paper first reviews the concept of themselves when they go out in the evening. ""item interactiveuess"" and then shows how If a schizophrenic makes overt, highly mal- information from item interactions on a adaptive responses in public, then the people binary test can provide significant, around him/her would probably emit some type additional information to the researcher. A of negative judgements or behavioral SAS macro that performs all the necessary sanctions. Thus, in this example items #1 tests to assess aud capture this new and #2 would be considered interactive items. information is then described. It is possible thal lht! lwo items might also exhibit main effects due to their positive relationship with schizophrenia. Yet, the Intr-oduction fact remains that the items interact to influence test scores in a nonadditive What are item interactions? This manner. It is this interactiveness of test question would be most suitably answered with items that a simple additive model fails to an example. Suppose a clinical psychologist explain. was attempting to develop a paper and pellcil test to aid in distinguishing between Are Item Interactions Useful? schizophrenic and schizotypal clients. (Both of these conditions may involve oddities of The answer to this question depends",Sugi-84-131 Roberts Jannarone.txt
"A common practice in lengthy clinical II. Repeated Significance Testing Using Tsiatis Class of Statistics trials with serial patient entry is the performance of repeated significance testing to determine if significant In his papers, Tsiatis provides a deri- ,vation of the asymptotic joint distribu- results exist so the trial can be ter- tion of a class of statistics that are minated early. A repeated significance testing framework can he implemented special cases of a general class of non- using the asymptotic joint distribution parametric statistics characterized by of a class of sequentially computed log- Tarone and Ware (1977). These sequen- tially computed statistics include the rank statistics derived by Tsiatis logrank, Gehan's modified Wilcoxon, (1982). A documented SAS MACRO for per- forming these calculations is provided Prentices's generalization of the Wil- coxon, and the tests based on score with an example analysis. statistics proposed by Harrington and Fleming. This class of statistics is 1.",Sugi-84-132 Davis Ward.txt
"Making Systems Portable Richard A. Usanis, Ph D. SAS Institute Inc. Good morning and welcome to the sessions on The system is large and complex. About 450,000 Port.able SAS. lines or 15 mb of source code in approximately 2000 modules. The Dal.a Sl.ep WaS redesigned and implemented based on the 1982 User's Guide. The I. INTRODUCTION procedures were mostly converted from the IBM although some have been completely rewritten. th~ system, For developing we are now implementing both a filter, to insure that the My plan in this session is to give you a little code coming from the developers is portable insight into the porting process too'e have gone (something not easily assured) and a source through at the Institute. Ours is a unique manager to ensure that all changes are made experience in many ways: the size, complexity and everywhere they are needed. The system is being manag!>.ment style are not out of a textbook. Our developed on the Digital VAX and then 'ported' to goal was simple: to implement Institute program the D.G. and Prime systems. products on the Digital VAX, DG MV and Prime 50 series computers, Over the next several months, DEVELOPMENTAL PHASES ]~ we ~ill refine the process and begin porting the [SLIDE: product to other machines yet unspecified. We will now move into the porting process and see [ SLIDE: TOPICS OF DISCUSSION ]1 hoW"" we developed it at the Institute. As you probably are aware, the classical definition of the porting process involves moving software from To give insight, I will review classical one environment to another with significantly portability concepts and present two 'new to me' less cost than developing it completely from management concepts that I call 'Parallelism' and concepts on the second and succeeding systems. 'Developmental Flexibility' . This process involves reducing the cost of the four phases of any software system: Definition, Let me note first however, that immediately Development, Testing and Maintenance. following",Sugi-84-133 Usanis.txt
"Progress and Prospects of the Portable SAS System Portable Systems Staff, SAS Institute Inc. The format used for this morning's panel the demonstration area. We have and will discussion is to discuss the progress we have continue to implement all of the SAS products on the portable system during the coming made in developing the SAS System for year, but our major emphasis this year and Minicomputers over the last few months because we realize that most of you who are using the during the immediate short term is to improve the general performance of the system by portable SAS Systcm are using Rclease 4.03 or making changes to the system itself and by 4.04, and we have just recently shipped 4.06. putting more of the code into machine There have been significant changes made language. That is where our emphasis is, between these two releases, and we feel that in and we feel that is where you want it to be. order to ensure that everyone understands what we are talking about versus what you are On the subject of debu99ing, we know of probably familiar with, we will describe the about 80 bugs that are in the system right difference, or at least some aspects of it. Then, now. We think that is rather amazing, we are going to talk a little about what we have spectacular, and a salute to the efforl that planned to develop over the rest of this year; we have gone through to bring you a system essentially in a very general for'mat, but we will that is solid. With each release, we hope to at least try to answer a lot of your questions keep the number of bugs within the system before they come up. That is basically the under 100. If you want to make any presentation. We are going to have two of the comments on this, please let me know. Also, developers talk about the progrp.ss, and eac:h onp. if you think that we should give something will talk about the prospects in his particular higher priority than performance and bug area. fixing in the system, please let me know, and we c",Sugi-84-134 Portable Systems Staff.txt
"collaborate in the pro':ess of dru,; design, chemical synthesis, biological This paper describes the experiences and clinical testing, scale-up and with the SAS System on a DEC VAX-Il/7eO manufacturing. This resea~ch process at Lilly Research Laboratories. Same produces huge amounts of data which differences between the SAS System under currently are being managed primarily by several Digital Equipment Corporatior, VAX/VMS and the SAS System under VM/CMS VlLX 11-780 mini-computers, with some or MVS are described, and examples are additional processir,g being supplied by given which illustrate the use of the is a IBM mainframes. Figure 3 SAS System: simplified diagram of the current LRL 1. to analyze VAX system performance computing network. data, Before 1980 [ie, before LRL acquired the to analyze and generate reports from most of the large-scale scientific 2. V1L~s) data collected on remote DECnet data analysis was performed using the SAS System on the IBM mainframes, with nodes, real-time data collection being performed by DEC ·PDP-ll and Hewlette to move SAS applications between the 3. Packard HP-1080 mini-computers. Most environment and the IBM VAX/VMS VM/CMS environment with PRoe XCOPY. scientists were uncomfortable with the batch computing environment supplied by the IBM systems, and so either developed their own data analysis programs on the DEC and HP minicomputers (or had someone do it for them) or the THE SAS SYSTEM FOR pe~formed MINICOMPt~S FACY~GE analyses by hand. The",Sugi-84-135 Suckstorff Hardison.txt
"PANEL DISCUSSION OF SAS USERS UNDER AOS/VS OPERATING SYSTEM I'm going to give an overview of the processors compatibility as a first consideration regarding on which the SAS System runs and an overview any of our future products. of our AOS/VS operating system. I will discuss the role that PUI plays in Data General I would now like to talk about the MV processors. Corporation. I'll give an overview of Data I would like to put the MV/4000, Mv/BOOO, and General's communication products, as well as the MV/10000 into a global perspective I'll some of our commitments to communications. regaarding performance as compared to del lars . I attempt to cover all of this information in a would also like to do this in two categories; manner that reflects the relationship with SAS MIPS and whetstones, software and our commitments to SAS Institute. The MV/4000 has an entry price of about $35,000 and the 32-bit normalize MI PS for this processor are .6. The MV/BOOO has an entry price of One of the things I want to review with you before I get into some of the items I am going to around $100,000. The 32-bit normalize MIPS for discuss is the relevance that we at Data General this processor are 1.2. Our MY/10000 is place on our relationship with SAS Insitute. From approximately $150,000 to $175,000 for an initial entry system. It has 32-bit normalize MIPS of the time Data General started business until the 2.5. late 70s we were primarily a hot box manufacturer. We were very well received in the The MV/4000 has whetstone single precision of scientific and industrial communities. Most of our 600, and it has whetstone double preCISIon of marketing of systems was through OEMs, and 400. The MY/BODO has whetstone single precision from the beginning until the late 70s, we enjoyed of 1,260 and whetstone double precision of 995. an increased place in the commercial market. But The MY/10000 has whetstone single precision of even that was primarily through commercial 2,500, and the whetstone d",Sugi-84-136 Harber Fleig Sashihara.txt
"VAX FAMILY _ THE COMPUTING STRATEGY WITH A FUTURE Theresa Stokes NOW. Where there are several different family members that need to communicate. we can link I am here today to talk about the VAX Family these all together with a single network of computers manufactured by Digital based on DECNET. And since each member has Equipment Corporation. In particular I want the same hardware architecture, the same to address four points. The position of VAX operating system. and runs identical versions within Digital's world. the success that VAX of the layered products. we can indeed has had in meeting the needs of many guarantee compatibility from the bottom to environments. the importance that software the top end of the VAX system family. plays in the VAX family. and. most importantly, probably, the future directions To the user tnis means tnat applications of VAX. developed on one member of the VAX family can be transferred to another member and/or Digital uses several product families to communicate across multiple family members support its many markets and businesses. We wi thout change. This preserves data, offer board level CPU products for inclusion programming and training investments. It also in our OEM's products; devices and components allows for a wide range of systems to meet such as terminals and disks as add-ons to any price and computing style. Key to the current installed systems; as well as the success of Digital'S VAX Family and the total systems arena, where we offer products reason why users choose VAX for developing ranging from desk top personal computers applications packages has been and continues through the PDP-ll Family to the large to be Architecture. mainframe family of DECsystem la's and 20's. I f one looks at 1977 to the first VAX in the At the heart of our familY offerings, of family that was shipped, we see a 730 wi th course, is VAX. Indeed, VAX is a very VMS. DECNET and FORTRAN. indeed a success in significant family within Digital. T",Sugi-84-137 Stokes.txt
"PANEL DISCUSSION OF SAS USERS UNDER VMS OPERATING SYSTEM a DD stGtement you have to tell the SAS System Louise Horny - Program Resources, Inc. - where to find the data Soet. You can do this in will be speaking, from a user's point of view, several ways. The LIBNAME statement tells the on the transitioning process from IBM to VAX SAS System where your directory is, or you can use a VMS command ($ specifies the VMS Brad Reese - Loyola College-graph ies command), which tells VMS to set your default · directory or work In the directory Gerald Perry Celilnese Corporation- [USERID.SUBDIR]. With the IBM there was a statistics right way and a wrong way, and that's it. With the VAX you can do the same thing several Kevin Mallory Texas Instruments different ways. I did not realize that, and I performance used to do all of them. I think there are some things that I could leave out now, but what the SAS System lool<s for is a data set in your Louise Horny subdirectory called, whatever the name is.SSD. That means it is a SAS data set. The as data I am going to talk about a system at the National set, which can have several SAS data sets within Institute of Environmental Health Sciences at the it, really doesn't exist. You have a separate file Research Triangle Park. This is a pretty large for every SAS data set. and impressive place now, but a few years ago we were in temporary buildings and trailers. Our There are some other bugs that I like to think of own computing facilities have grown from a as ladybugs. We are glad to see them. For PDP1170 to a couple of VAXs. We are a branch of instance, now we get subscripted arrays, and we NIH, located in Bethesda, Maryland. Most of our have been promised n-dimensional array handling computing was done through the Division of in the future. Computer Re:;earch and Technology at NIH. We use the IBM 370 in Bethesda, and our turnaround time is very fast. We have have lots of memory, A lot of the SAS code looks the same. I learned and if s",Sugi-84-138 Horny Reese Mallory Perry.txt
"Repeated Measures Analysis in PROC GLM Phil SAS Institute, NC Spector~ Cary~ and regular MANOVA is that in the usual 1. INTROOUCTION MANOVA setting, the dependent variables represent qualitatively different things, such as length and weight, while in the repeated Experiments in a wide variety of disciplines measures situation, the dependent variables result in situations where the same experimental represent responses to levels of a factor of unit (subject~ animal, mCichine~ etc.) is observed interest. For this reason, repeated measures at a number of times or under a number of analysis can be thought of as an analysis of treatments. Such experiments are necessary transformed dependent variables, where the when the number of experimental units is small~ transformation is chosen so that the usual or when an attempt is being made to control MANOVA tests are tests of the hypothesis that subject to subject variability by having each the independent variables had no effect on the subject serve as its own control. Analysis of underlying factor which defines the repeated variance (ANOYA) is often the statistical method measure effact. Several SUG I papers in recent of choice in these designs. These experiments, years (for example, Patel and Bonus, 1980) have however, present some difficulties in the usual used the DATA step to implement this approach analysis of variance setting. First, since for analysis of repeated measures designs. In measurements taken on the same subject tend to addition. the ordinary univar'iate analyses of be less variable than those taken on different these transformed variables are very useful in subjects~ error terms other than the usual understanding the effect of a repeated measures residual error need to be used to test hypotheses factor. The transformations available with the of interest. A second and more subtle problem is REPEATED statement include orthogonal that observations taken on the same subject tend polynomials. differences betwee",Sugi-84-139 Spector.txt
"A CUellf'l-i ng Theory Model For Optimization Using SAS software Chitra B. Prabhakar American Natural Resources(ANR Pipe Line) When a programmer arrives for service and INTROCUCTION finds that all terminals are busy, then he/she does other work until the tenminal This paper describes a study undertaken to becomes free. This interim period is determine the optimum number of MVS referred to as waiting time and is computer terminals required in a computer considered to represent a loss of center to achieve the greatest productivity productivity, measurable in dollars. we for the lowest cost. A queuing theory make the simplifying assumption that the roodel was used, where the prCXjrammers are total loss of productivity for all considered as customers and the terminals programmers is proportional to the total as servers. Distributions of inter-arrival waiting time, thereby ignoring qualitative times and service times were estimated and pay differences among programmers. using sample data. A large number of If C denotes the cost per unit waiting time arrivals and services were simulated using due to loss of productivily and W the total the estimated service time and inter- waiting time in the system during the arrival time distributions. Under suitable month then the total waiting cost per assumptions, estimates of the waiting cost month'is P = C * W. The total cost is were obtained from these simulations, for taken to be the sum of the waiting tine different number of terminals in the cost and terminal cost, i.e. P + T. The system. From these measures, the optimum objective is to find N, which will minimize number of terminals and various parameters the expected total cost. Note that, for a of interest for the corresponding queue fixed number M of programmers the expected were obtained. waiting time will decrease as N increases becoming zero when N )= M. SAS was used for analyzing sample data, for performing simulations of the queueing (2) Estimating distributions: sys",Sugi-84-14 Prabhakar.txt
"This paper deals wit_h the analysis of C'LIZC :::: variance or covariance in a repeated measures e'L e;;;: (3) design with at most two grouping factors and rc one repeated measures factor. Using the where C is a p x (p-I) matrix of (p-l) normal- MATRIX procedure, a macro is written to test ized orthogonal column contrasts, ~ > 0 and the hypothesis of equal cell VC (variance- covariance) matrices and the hypothesis of I _ ) is the (p-l) x (p-l) identity matrix. ep l equal cell VC matrices with a common matrix This is equivalent to saying that all L .. having Type-H structure. The macro also 1J computes e, the multiplicative adjustment have a type-H structure and they are all equal (Huynh and Feldt, 1970). factor for the degrees of freedom for the F-tests in the analysis of a mixed model_ When HOb does not hold, but HOa holds, one can perform the approximate univariate 1.",Sugi-84-140 Patel Roy Huque.txt
"subject groups, We would do a multivariate analy- sis of variance of ~he linear and quadratic coef- Repeated measures experiments involve two or ficients between groups. more intended measurements per subject. If the This method has been advocated by Sanders within-subjects design is the same for each sub- (1978) and others. ject, and if no data are missing, then the analy- sis is not very hard and there are readily avail- UNBALANCED LEAST SQUARES able programs that do the analysis automatically. Huwever, if the data are not balanced, with the There are three equivalent methods for test- same arrangement for eaeh subject, then the ing the interaction between time and groups of analysis becomes much more difficult. subjects. The basic idea is to fit the linear Beginning with procedures which are not opti- model (in SAS GLM notation) mal but are fairly simple, we move on to Yw A+ T SeA) A * T, + + unbalanced linear model analysis, and then normal maximum likelihood procedures, We discuss ML and where A is the between-subjects effect, T is the time effect, A * T is their interaction, SeA) is REML estimators for the mixed mouel and also max- imum likelihood estimators for a model which the effect of subjects nested within A, and the allows arbitrary within-subjects covariances. We error terms are normal with zero mean. are inde- give a program which uses SAS MATRIX to do gener- pendent between subjects, and have the same dis- alized least squares based on the output of tribution for each subject. Schwertman (1978) BMDPAN, which gives a maximum likelihood estimate has shown that the GLM analysis is legitimate if for the covariance matrix. it is valid when the data are complete; that is, it is legitimate if the symmetry conditions hold:",Sugi-84-141 Berk.txt
"THE USE OF CA TMOD FOR REPEATED MEASUREMENT ANALYSIS OF CATEGORICAL DATA William M. Stanish, SAS Institute Inc. Gary G. Koch, University of North Carolina at Chapel Hill A third method of repeated measurement analysis 1. INTRODUCTION is to use maximum likelihood estimation to fit log- linear models to the joint probabilities of the Many studies use data collection designs in which contingency table (Bishop, Feinberg, and each subject has a response measured under more Holland, 1975, Chapter 8). With this method, than one condition. A major advantage of using hypotheses of marginal homogeneity must be such a design is that comparisons among the expressed in terms of models corresponding to conditions are not obscured by subject-te-subject symmetry and quasi symmetry. For such variability. The price that one pays for this analyses, one disadvantage of this method is that advantage is that the responses within a subject it may require larger sample sizes than those are correlated, and those correlations must be required by WLS analysis, since the asymptotic taken into account in the data analysis. For continuous data, this may add a dimension of theory must apply to the individual cells of the contingency table, rather than to the marginal complexity to the analysis since, for example, it probabi IHies. has the potential for changing a univariate analysis to a multivariate one. For categorical data, on the other hand, repeated measures change only the complexion of the analysis since the methods were specifically designed to deal 2. METHODOLOGY with I;orrelated functions: namely, the response The WLS analysis of categorical data from probabilities. repeated measures experiments involves three components: (1) computation of appropriate One difficulty posed by repeated measures functions of the data, (2) fitting asymptotic analysis of categorical data is that repeated r'egression models to the functions through WLS measurement designs can result in a great estimation,",Sugi-84-142 Stanish Koch.txt
"really determined the minimum When questions are received from the FDA about a pending New Drug effective dose? Application, they must be answered as Usually we would have covered quickly and efficiently as possible. these questions thoroughly in the NDA This task is made easier with the use wi th a dose-response study. However, of SAS. This paper deser ibes the use oral Drug A Tablets have been on the of PROe GLM and PROC TABULATE to market for sorne time and so, for this answer two questions recently raised new delivery system, we were filing an by the FDA about a pending Ne\l Drug Appl ieatian. abbreviated NDA relying on the or igi- nal documentation for Drug A Tablets. Since the FDA had agreed to t~is abbreviated NDA prior to submission,",Sugi-84-143 OConnor.txt
"Co., PRDD ABSTRACT TreatmEnt groups with similar prognoses This paper describes an on-line sequen- arE! essential in obtaining valid results in a tial randomization system (SEQ RAN) for assign- clinical trial. Sequential treatment assign- ing treatments in a controlled clinical trial. ment methods which consider known prognostic This system is easy to use and runs quickly. factors have been developed to assure balanc- It currently is being used in a multicenter ed treatment groups. These methods are adap- cancer clinical trial. Examples from this tive in that the treatment assignment for the application will be used in this report to nth patient depends on the treatment assign- demonstrate SEQRA~. ments and prognostic characteristics of the This paper describes the sequential n-l patients already enrolled ill the study. treatment assignment technique; presents the However, treatment assignments cannot be made SAS program, which is the core of SEQRANj and in advance. This provides a unique oppor- demonstrates the interaction between the user tunity for utilizing the interactive capabil- and the system. iti~s In this paper ~ W~ of the eomputer. present SEQRAN. an interactive system for SEQUENTIAL TREATMENT ASSIGNMENT METHOD assigning treatments in a clinical trial using a sequential randomization approach. Pocock and Simon's (1) sequential random- SEQRAN performs two vital functions: ization procedure produces simultaneous screening patients for eligibility and marginal balance",Sugi-84-144 Fondy Lee.txt
"USING SAS SOFTWARE FOR FATIGUE LIFE PREDICTION OF MECHANICAL SPRINGS Robert L. Woe1l. International Harvester Company The life of a metal component is primarily a INTRODUCTION function of the stress levels the component is The last few years have seen SAS® subjected to and the number of times it is software become an important tool du~ing the cycled between one stress level and another. As research and development phases of new products shown in the progr8l\ listings. STlUUN is depend- at International Harvester Company. SAS ent upon whether the spt'ing has deflected software has become important to us because it thl.'ough flat. Stress values were computed for offers a wide range of analysis procedures and a each of the samples using this model. The model It is used very powerful programming languaS8. also takes into account the material thickness primarily interactively via TSO. This gives us (KATTHICK), the at rast height (FREEHT), and the ability to quickly and thoroughly analyze the lack of syml'letry (MAXWARP) of the spring. data upon which important and sometimes costly These parameters were all related to stress as engineering decisions depend. The use; of SAS the equations show. software range from complex performancE studies of agricultural equipment operating in the field The equation relating stress and life is: to simple quality studies of individual parts. AMP = (K-MEAN) *CYCLES**B The following is an example of how we have used SAS softWare to reduce laboratory and field testing time and provide the design engineers where: with important guideline information. AHP=stress amplitude (stress range/2) TRB PROBLEK HEAN~mean stress CYCLES=cycles to failure The part under evaluation was a disk spring K=fatiSue strength coefficient being tested for fatigue life under a then set B=fatisue strength exponent of operating conditions. A number of sample K and B=parameters to be estimated springs had been tested under various deflection regimes. The deflection reg",Sugi-84-145 Woell.txt
"USIN"" SAS PROCEDURES TO EXAMINE 110NTHLY LEVELS OF INDUSTRIAL I~ATURAL GAS SALES John H. Herbert. Energy Information Administration Introduction requirements of the industrial sector are less than the residential and commercial sectors, the The principal objective of this paper is to manufacturing sector sill has significant space demonstrate how specific SAS procedures were used heating requirements as suggested by the seasonal to examine the degree to which recent monthly pattern of natural gas sales. changes in aggregate natural gas sales to the The specific equation to be estimated is: industrial sector appear to be related to such factors as the price of natural gas and indus- St = a+ ""ibiOi. t+cPGt+d(PG/PO)t+gHDDt+et (2) trial activity. Emphasis is placed on a careful examination of estimated results. Regression monthly sales of natural gas to the diagnostic techniques, especially col1i~ea~;ty industrial sector in billion cubic feet diagnostics. are employed. This emphasls 15 mo- [1] tivated by a lack of well defined relationships at an appropriate level of detail and by the = monthly 0i t indices of industrial activity in paucity of the data given the large number of i manufacturing industries [2] , parameters to be estimated. The time period examined extends from January of 1980 to March PGt = estimated monthly average price of natural of 1982. It is a short, but interesting time gas per million Btu's [3] period, during which the industrial sector wft: nessed dramatic monthly and quarterly changes ln = estimated POt monthly average price of residual activity and during which the industrial price of fuel oil per million Btu's [4] natural gas increased by 52 percent. = monthly HDDt population weighted index of Model heating degree days [5] The general relationship examined is: =a e randomly distributed residual S flO, PG, PR, HOD) (l) t January, 1980 through March 1982 = S aggregate level of industrial natural = coefficients a.b.c,d.g to be estimated gas sal",Sugi-84-146 Herbert.txt
"y ABSTRACl' SAS was applied to a yield modeling project rainfall values had the greatest effect on by soil scientists at North Dakota State Univer- yields of spring wheat and sunflower. sity. Soil, climatic, and management variables were used to develop yield prediction models for Variable Recombination by Computer spring wheat and sunflower. The large number of climatic variable combinations warranted the use SAS arrays were used to recombine the bi- of SAS arrays. SAS proved to be an effective weekly values into new variable groups. A tem- language for variable recombination and statis- porary array was used to store the 12 original tical analysis. values. Each array consisted of elements Ql through Ql2 with each element representing a Additional Index Words: Array elements, biweekly value. An example of the array is IBM-VSPC, PROC REG, DO OVER. shown in Table 1. The biweekly rainfall values are illustrated by the variables R4_16_30, Introduction R5 1 15, etc. These variables represent calen- dar periods April 16 through 30 and May 1 The manipulation of over 480 variables is a through 15, respectively. difficult manual task. but it represents an ef- fective computer application. In this project, Table 1. Temporary array used for storing bi- models were developed for predicting spring weekly rainfall values wheat and sunflower yields using soil, climatic, and management data from agricultural experiment 10 ARRAY Q (M) Q1 Q12; station research sites. The data base consisted Q",Sugi-84-147 Held Ulmer Knuteson Patterson.txt
"Merck & Co., Inc. ABSTRACT est observable concentration at which there are no detectable effects. In section 4 we discuss Experiments using a series of increasing the computational aspects of trend/sequential doses of a compound, including the zero dose trend test analysis. SAS programs TRENDP1.DATA, control are often used to study the effect of TRENDP2.DATA and STREND2.DATA using the ESTI- a test agent on the response of interest. The MATE statements in PROC GLM and PROC MATRIX are purpose of such experiments ;s either to estab- presented for analysis of uncensored continous lish that the test agent has no effect on the data. Finally. the methodology is illustrated response of interest or to find the concentra- using data from an oral toxicity study in rats. tion of a comnound at which there ;s no detec- tab 1e effect (n acceotab 1e concen tra ti on"" ) . TREND TEST, DEFINED: ~ In this paper we discuss the implementa- Suppose we are given mean responses tion of a sequential trend test suggested by ~O' Yl···~k to an increasing sequence of doses Tukey et. al. (6) for Lhe analysis of such exp- dO (dO=O), dl , d2···d k of a compound. We want ~uestion eriments. The trend test addresses the of orogressiveness of response with increasing to test the null hypothesis that the test agent dose, and thus is more selective and sensitive has no effect on the response of interest ver- than alternative procedures. A SAS macro using sus the alternative that there is a progres- PROC GLM and P",Sugi-84-148 Mehta Capizzi Oppenheimer.txt
"oration Sue Huang and Nguyen V. Dat Ortho Phanmaceutical Corporation 1. The frequency counts must be sorted by ABSTRACT preparation and dose (BY VARIABLES also require sorting. if they are being used). PROC QRPT procedure is a SAS procedure which provides estimations for ED50 and Relative PROC SORT; BY PREP DOSE; Potency and their fiducial limits in a Quantal Response Assay_ This SAS procedure PROC QRPT; CLASS PREP DOSE; is written in FORTRAN and is geared to the VAR RESP; TOTAL TOT; convenience of the user in the SAS enviroment. Exampl e I: This program estimates a 50~ effective dose Responded Total Animal s (ED50) and relative potency with their 95% Drug Dose RESP TOT fi duci aI lim; ts wi thi n the framework qf (DOSE) (Freg count) (Freq count) JfBm Fieller's Theorem from a joint probit X2 statistics for testing the similarity of the I A 50 44 probit regression lines required for 24 46 A 2 attaining parallelism. 50 6 3 A I B 47 50 PROC QRPT is very user-oriented and can be B 2 34 48 tun easily by usi ng SAS data sets. B 50 3 6 INTR DOUeT! ON where the overa 11 sampl e si ze is 294 We would like to thank Dr. Richard Lam for 2. The preparation values must contributing the original FORTRAN program in be eight characters or less. Which this PROC is founded. Dose values ~ be numeric. If you would like a copy of thi s PROC, please 3. Each VAR variable must have a Ronald Fleming at Squibb Corporation. ~ontact corresponding TOTALYariable. 'Princeton. NJ. 4. Class statement must con",Sugi-84-149 Fleming Huang Dat.txt
"FORECASTING CUSTOMER AIR CONDITIONER LOADS AND LOAD DROPS FOR ELECTIUC UTILITY LOAD MANAGEMENT PROGRAM PLANNING Bruce A. Smith. Minimax kesearch Corporation Marjorie R. McRae, Minimax Research Corporation Louise Weiler. Minimax Research Corporation Richard M. Scheer, Pacific Gas and Electric Co. Introduction load analysis, Minimax used these LMG partici- pants to estimate the program's realized load Thl~ :,Japt:'l"" rt:'purLs on aIL ilLuuvative dpplica- reductions. tion of SAS performed by Minimax Rl?search I.orpo- ration and Pacific Gas and Electric Company TABLE 1 (PGandE) to develop a method of forecasting 1981 Air Conditioner Cycling Strategies ~PLRP electric utility customers' daily air condition- er loads (measured in kW) and load reductions produced by PCandE' s Residential Peak Load Re- OF~ TUG ~OF""'I CyCLI .... ,............_ CVC""I"""" !'Otlo!) """"R IlALF HOUR CIF'ERIO.TION DAYS duction (~PlR) air conditioner cycling program. These forecasts can serve to improve the pro- IZ· .. IN.JT"" 12:0'·18:00 "" .. ,N.J'IT,. gramls operation and planning. The RPLRP is one 1.· .. IN.1I'E 12:0~· 18:00 I. :00· '.:30 of the nation's largest. having approximately VAR'tS: . . ""IN.lTES . 68,000 participants in 1983. In 1981, 27.9 MW . . MIN.J'TI:S. of potential load reduction accrued to the lPlRP OR , .. ' ......... 5 1.,0'·20;30 VARIES: for an average cycling (operations) day across I. MIN.JT .. S. all participants and cycling strategies. 15 MIN.lTES. OR · "",rf.JTE:5 Minimax Research Corporation and PGandE have developed a viable method to predict RPLRP load reductions. This paper presents results of our Analysis Approach initial development of the program's Load Reduc- tion Forecasting System (LRFS). The LRFS can The analysis approach that we used was based improve the RPLRpls operations and planning by on a multiple-step process, beginning with a providing accurate forecasts for the ef:ects on comprehensive editing and cleaning of the load air conditioner (A.C.) load of differ",Sugi-84-15 Smith McRae Weiler Scheer.txt
"Jarres T. Love, Bcehringer Engclheim Randy L. carter, University of Florida tor, def ined by 1he REPREG prClg'ram is written in the 82.3 -1 n A release of the Statistical Analysis System (SAS) EW.b.), Q (n prC9rarrming language. REPREG utilizes the :rm.cro ...n i=l-l.-1. processing facility (SAS 1982A) and the rratrix proce:iure (SAS 19828) to I;:erform estimated is asymptotically equivalent best the be generalized least squares estimation of linear estirrator (i .e., the generalized least squares Ccefficient Regression (RCR) m:rlels. Randan is useful for estinating an overall REPR.EX; estirrator) \Itlere as or regression equation fram repeated measures data. n , -1 A (n- l , w. , E + {tss ~) i=1 '2 is the pooled o MSE In rrany regression problems with repeated measures on each of several indi vid.ta.ls the fram individual regression fits, is ~i usual assumption of independent deviations about an Q\ierall regression curve is violated. 'Ihus, the vector of ordinary least squares estirna- ordinary least squa.res (QLS) estimators are inefficient, even in large samples. The REPREb th for tors individual, i the program t:erfonns asymptotically efficient esti- n ~2 ma.tion in such cases by a:mputing estimated generalized least square estinates. '!he vector i=1 n i=1 -1 of generali2ed least squares (GLS) estirrates is (b.-b)(b.-b) , E b .. and n ihe a weighted average of cx:.s estimate vectors fran -1. - 1. i=1 _1. individual regressions. Estimated ge~cralized user is referred to SWan!Y (1970, 1971) and Car- least squares is the weighted average with esti- ter and Yang (1982) for !TOre detailed discus- e. nated. weights. '!he RElPREl3 program canputes CLS sions of RCR UKXlels and the properties of i .. '!he REPREx:; prClg'ram COO1pUtes ~ with estirrates for each individual, estimates the modi- fied slightly to guarantee fXlSitive defi~heness weighting matrices and computes the weighted average using these estnnated weights. (See carter and Yang, 1982). Several tests of I",Sugi-84-150 Love Carter.txt
"c. National Center for Toxicological Research Jefferson, Arkansas 72079 ABSTRACT FORMULATION OF THE GROWTH CURVE PROBLEM A class of nonparametric rank order Let there be k experimental groups and assume that initially there are N. experimental statistics for testing the homogeneity of dose units in group i. i=l, .··· k. response growth curves has been proposed and Fu:Fther. suppose discussed by Koziol et a1. (1981, Biometrics that we administer k doses or treatments to 37, 383-390). These nonparametric tests allow these k groups and that in the combined incomplete andlor missing observations on population of k expericental groups, we response variable in one or more treatment observed individual growth response of each groups over a period of experimentation. These experimental unit at n distinct time points or procedures are applicable when the sta~dard (1) parametric procedures are not appropriate due time intervals TI .·· Tn' Let W · t=l."" ·· n. tj to missing observations, for example, animal j=l, ··· ,N weights in prechronic and chronic bioassays. , denote the growth observation of it th A general SAS program in PROe MATRIX is the j experimental unit in group i at time developed to compute the Koziol generalized Note that not all the Wei) may be linear rank statistics for testing the point T · t tj homogeneity of dose response growth curves. The program computes the test statistic and the observed. In general only Nit of Ni corresponding P-value using i) Wilcoxon rank sco",Sugi-84-151 Amini Patel.txt
"SAS Functions Useful For Probability Computations N. D. Prabhakar General Motors Corporation The first argument for each of these INTRODUCTION: functions is a numeric code which specifies the particular of probability ~ distributions. For example, a code of 1 This paper describes a group of eight SAS means a binomial distribution, a code of 50 functions that are being developed, which means a normal distribution and a code of can evaluate, the following eignt functions 102 means a Poisson sum of binomial or qUBntities associated with a univariate distributions. A partial list of codes and types is shown in table 1 probability distribution : CDF the oumulative distribution The next group of arguments for these function, functions specif.y the parameters of the PDF particular type of distribution and thereey the probability densit,y function, a unique probability distribution on the the characteristic function, real line. The actual number of parameters CHF and their meaning depend on the type MGF the moment ~nerating function, CDFINV the inverse of the cumulative specified by the first ar~ment of the distribution function functions. For instance, the parameters for (percentage points). the binomial distribution are the number of RAWMMT the raw moments, trials (n) and the chance for success in a CNTIJIIMT the central moments, trial (p), whereas the parameters for the a random observation from the normal distribution are the mean and RNll>1 distribution. variance. The parameters are seperated by commas and must appear in their correct The probability distributions for which the order. Table 1 shows the parameters for the above functions can be evaluated will different ~pes and their meaning. include a wide class of distributions such as (1) basic discrete and continuous The last.argwrnent for each function is a distributions - e.g. binomial, poisson, number a. Given the ~pe and parameters, hypergeometric, negative binomial, one has a specific probabili~ distribution",Sugi-84-152 Prabhakar.txt
"i f Ak = 0 In Yijk Building on the notion of data based powe~ transformations, commonly referred to as for i::::: l, ... ,mj j::::: 1 .... , n.; and k::::: I, ... p. Note that both covarIance matrix Box-Cox transformations, a SAS procedure has = ... = I =I stabilization, i.e., II been written for simulla-neous normalization (I unspecified). and normalizatioW are and covariance matrix stablization in the m-sample, multi-variate case. Test runs on implicit in the likelihood function cor- two quite diverse operating systems for responding to equation (2). Details of the Fisher's iris data and for a more elaborate iteration leading to maximum likelihood example indicate that the iterative procedure estimates of h1,"""" h are summarized from Dunn and Tubh::; (1980) ~n the following is economically feasible in terms of CPU time to convergence as well as being relatively section. The purpose of this report is to insensitive to starting values. describe and illllstratf' a f1f'W HAS procedure which is an implementation of this approach. I.",Sugi-84-153 Dunn Zodrow.txt
"GENERATING BIVARIATE EXPONENTIAL DISTRIBUTIONS VIA SAS MACROS WITH APPLICATION TO REPEATED MEASURES DESIGNS M.L. Moeschberger. The Ohio State University P .K. Tandon. Sterling-lfinthrop Research Institute terval. Thus we can set u =(1+4p-8pu ) INTRODUCTION 1 2 Quite often researchers in the medical, bio- (3) exp (-A x )+4p(2u -l) exp (-2A X ) 2Z 1 Z2 logical, or social sciences are confronted with since u = exp (-A x ) from (2). 11 data which calls for a repeated measures analysis. 1 If these data satisfy the assumptions of normal- Solving equation (3) for X yields z ity, homogeneity of variance-covariance matrix, 0'+4n-BnUl) and compound symmetry, then the usual ~arametric x2~- -i; 1:::::~:::0 analyses will bl?_ Hsed ((,_f. Winer, 1971; l.eisser and Greenhouse, 1958; Huynh and Feldt, 1970). ln - Sometimes the previously mentioned assump- tions are not satisfied. In ~uch insLaru;t:'s, nun- (4) parametric methods introduced by Koch and Sen 64p 2 (2u -1) 2 (1968), Koch (1969), and Koch (1970) and written 1 as SAS macros by Tandon and Moeschberger (1983) where the appropriate sign on the last term is may be more appropriate. taken to make x2~O. In attempting to compare the parametric and This same concept and procedure, as described nonparametric models a large simulation study of above, can be used for generating X3 (third samples randomly selected [rum many dif[t:'rt:'uL level of repeat factor) conditional on X2 . types of mu1tiv:ni R.te oi stributions is necessary A SAS macro for generating such multivari- to perform. The purpose of this paper is to ate exponentials is prOVided in the Appendix. present a SAS macro for generating multivariate distributions with exponential marginals and to COMPARISON OF PARAMETRIC AND NONPARAMETRIC investigate the probabilities of Type I errors ANALYSES and power analyses for various parameter values, Situations which had two levels of the various amounts of correlation, and for some group factor and three levels of the repeated se",Sugi-84-154 Moeschberger Tandon.txt
"RANKPLOT: A SAS MACRO FOR GENERATING LINE PRINTER SC1TTERPLOTS OF POINTS r,ND POINT HBELS WITHOUT OVEllPBINTING THE POINTS ~ND LABELS ioIarren F. Kuhfeld, The University of North Carolina lBSU1CT I!E IABK 1!21 ~2g~~ --- sc~tterflots arp typically produced Cne of the simplest a~thods of after a multidimensional scalin~, dimensicn interpretation 1s to sort the oth~r princif:al components, or points en each of the r dimensions, and exploratc:r multivariate data analysls print r lists of point descriptions and for use as an aid to configuration th~ir corres~onding coordinate values. int~q:retation.. Standard lin~ printer InspEction of the order of points on a plots yenerally Jo not co?tain, enough dim~nsicn, particularly if the data were information to cl'iarly 1dent1fy all analyzed with the INDSCAL model, could peints. somq points may bA Mor~over, lead to hypotheses concerning possible A SAS macr') that generates hidden.. interpretatiens of the dim~nsions. This scattertlcts wher~ points are plot~ed by approach can b~ thought of as generating cooIdinat~ inst~ad of value ranks r unidimensicnal vertical plots where original co~rdinat~ be values will the location of a point on a plot is the discus.sed. This method has the rank of the coordinate of the point on advantage that long point descriptions The rank plot model is tbp. dim~nsioD.. can be prin~ed with no oVArprinting or an ~xtellsian of this basic idea to two f.oint~ d~scriptions. hiding af and dimensions. The Y coordinate of a point There is a trade ~ff; accurate d1stanc~ in a rank pl,=t is (an integoer multiple infQrmaticn is sacrificed for complet~ the rank of the coord inate of the of) pOint descriFtions. F'1int on dimension i (i=1, ..... ,.r) and the I c')ordinate is (an int9ger multiple of) i l l RO.Q!!f11.Q!! the rank cf the coordinate of the point Gen~ratiny scattprplots of derived on dimoeDsion j O=l, ··· ,r and i HI j). FoiDt configurations to aid th~ proc~ss The actual coordinate values of th~ of c~nfigu",Sugi-84-155 Kuhfeld.txt
"On the Study of Clusters with Factor Analysis Eric Deaton, The Coca-Cola Company Richard Israel, The Coca-Cola Company Spearman reallzed that these positive corre- In the early years of this century, much of lations indiCated that the tests did not measure social scientists' time was spent on the measu~e statistically independent skills. He believed ment of hunan attributes and characteristics. that either of two theories might account for Many of the general statistical techniques that this observation. According to the first of researchers now rely on most heavily were devel- t~ese these theories, positive correlations op;;""d all': of necessity by researchers of this era. expressed the relationships among a large number Correla~ion analysis was one SUCh technique. of abilities, each of which consisted of a slightly different combination of a small number The notion or statistical correlation among vari- of independ~mt ""f.3cultie.<;"" of the mind. Spearman ables, was first described by Francis Galton in referred to this theory as the ""oligarchic"" theo- 1888. Like other anthropologists cf the time, ry of the nature of intelilgence. According to Galton was interested in the relat~onShips among the second theory, t~ese positive correlat~ons certain characteristics of the human body. He expressed the relationships among a large number was especially interested in causal relationsr.ips of abilities, each of which consisted of some between people's physical and psychological ct,ar- proportion of a slngle general fa=tor and some acteristics. This was the heyday of craniometry proportion of an ability-specific factor. Spear- and phrenology. The mathematics of the bivariate man referred to this theory as the ""monarchic"" normal correlation surface had been worked out theory of the nature of intelligence. Spearman much earlier by LaPlace, Gauss, Adrain, and then began to study matrices of correlatlons others concerned with error in astconomical among psychometric measures fo",Sugi-84-156 Deaton Israel.txt
"POWER FOR LINEAR MODELS: THE TIME HAS COME ANALY~IR Ralph G. O'Brien,i The University of Tennessee Virginia 1. Lohr, Washington State University sample means, ignoring the direction of that dif- The purpose of this session is to show you ference. Similarly, the statistical difference how to use the SA~ System 3 to methodically ex- between the population means 1s measured by amine the statistical power of your linear-mod- els analysis. The purpose of this particular 2 - ""2) paper is to set the stage for the other papers, which contain the core of the technica~ materi- al. The next paper, Lohr and O'Brien (1984), SSH(populat.1on) handles univariate linear models. Fol~owing (Z) .. (;Z that, Muller and Peterson (1984) extend matters to the multivariate case. We are pleased and A is called the noncentrality parameter. For grateful that Rudolf Freund has agreed to discUSR this two-group test, A is the population analog our works. Of related intfl:rest is a poster pa- of F. The random variable F haa a nOllceRtral F per, Peterson and Huller (1984), which presents distribution with one degree of f'[eedom in the specific SAS code for the multivariate computa- numerator, denoted F[l, DFE, A]' If the popula- tions. To set the stage for ""Practical Methods tion means are equal (the null hypothesis is for Power in Linear Models,"" we will now address true), F follows the (""regular"") central F dis- these areas: tribution. which we can denote F[l, DFE, A = 0]. An increase in A reflects a larger underlying Noncentrality parameters, noncentral dis- violation of the null hypothesiS, and produces an tributions, and power. increase in the expect&i value of F. Thus larger values of h yield greater power, the probability An example of a power analysis. that F will eKceed its critical value, F* ~ F[l, DFE, A = D, cd. ). is increased by 1) in- Power analysis in consulting: a task for Z c.reasing the population effect size, (fll - J-l2) ; ~arly researcher-statistician communica- tion. 2) inc",Sugi-84-157 OBrien Lohr.txt
"THE SAiJ SYSTm MAKES IT EASY POWER ANALYS IS FOR UNIVAR[A. TE LINEAR MODELS: 1 Virginia I. Lohr , Washington State University 2 Ralph G. O'3rien · The University of Tennessee Introduction A-toxin: 0 PPM, 2 10 PPM, (1 3 - 100 PPH) Power is the probability that a hypothesis test will be statistically significant. In this B-toxin: (l '"" 0 PPM, 2 10 PPM, article we use a hypothetical example to show 3 100 PPM, 4 = 1000 PPrI). how easy it is to use PROC GUi and the S.'S 3 Sup- plemental Library functions FPROB and TPROB The treatment will last one year, at which time (HardisOD. Quade. and Langston, 1983) to compute al~ animals will be sacrificed to obtain the de- power for any hypothesis testable by FROC GUM. pendent measurement, WEIGHT. (Any other linear models routine, such as PROG REG. can also be used.) Chen and Klub have sufficient money in their research budget to study as many as 240 To illustrate this methodology, we will foc- rats. They would like to use fewer so that they us upon linear models applied to factorial de- can have funds fat"" a follnw-up study. Chen and signs. Associated with factorial designs are Klub therefore have chosen to compare the powers many types of hypotheses. including main effects. of experiments using N = 120 rats and N = 240 interactions, Bubeffects. and simple effects. rats (n = 10 and 20 rats per treatment). Each hypothesis leads to a different F-test. The power of a particular F-test (the probabil- Step lh: Making Educated Guesses About the ity that a particular F-statistic will exceed its Population Means and Variances. In order to com- critical value) is determined by the spe:ific pute power, Chen and Klub must supply conjectured values for the groups' population means. their means for each of their twelve treatments. TIley common within-group variance, and their sample must also supply a conjee.tured error variance. sizes. Of course. we never know the values for They know from other rcsearch that the dependent the true means a",Sugi-84-158 Lohr OBrien.txt
"a, Chapel Hill For testing purposes, rk(C) = a<r and rk(~) = ABSTRACT bsp will De required. The matrix of secondary General approximatlons have been known for a parameters. ~, contains linear combinations of decade for computing power in multivariate the matrix of primary parameters,~. The linear models tests with Wilks' lambda~ matrix ~, the usual contrast matrix in uni- Hotelling-lawley Trace and the Pillai-Bartlett variate linear models, computes linear com- Trace (Lee. 1971. Sugiura and Fujikoshi. 1969). binations of rows of §, which correspond to All use complicated mixtures of noncentral chi- different predictors in the design matrix. square variates. Recent results (Muller and The matri~ U computes linear combinations of Peterson. 1983) based on single noncentral F columns of B. which correspond to different variates provide far more convenient approxi- dependent variables. It is useful and accu- mations. The basic ideas needed to implement rate to think of U as transforming the depend- the new approximations are reviewed. A direct ~ ent variables. appro~ch, using matrix manipulations, and an The model contains two parameter matrices indirect approach, using linear models programs, to be estimated: Band Y:. Under the assump- are sketched. tions stated. estimates are I NTRODUCTl ON B (X'X)-X'Y (3) Moti vat; on Power calculations in testing the mUlti- , = Y'[I - X(X'X)-X']Y/[N - rk(X)] (4) variate general linear hypothesis have pre- sented difficult problems. Although no",Sugi-84-159 Muller Peterson.txt
"PROPOSED U. S. PASSENGER CAR AND LIGHT TRUCK SALES FORECAST MODEL S. J. Olson, Allied Corporation Dr. John Janakiraman, Miles Laboratories INTRODUCTION MODEL My job responsibility within a large automotive supplier To reflect the events stated above within a model and de- company includes forecasting U. S. automotive vehicle sales velop conclusions which have relevance todDY, I chose to use monthly data to the extent possible for the period 1971 (specifically passenger car and light truck). It is necessary to prepare an annual and five-year forecast for recommendation through 1982. The dependent variable, Total U. S. Passenger to top management tor concurrence and approval. This fore- Car and Light Truck Sales including imported product, was selected to r(linimiLe market complications caused by th~ cast then provides the basis for corporation automotive shifting consumer preference to light trucks and imports. financial and strategic planning. Approximately 60 researched and derived variables of 144 Recently, the accuracy of automotive forecasting has been observations each were chosen for their potential impact on less than desired. Methods used are often highly subjective- the autolliotive consumer from an economic, psychological based only upon economic service bureau and/or O. E. and technical perspective. The following five independent manufacturer assumptions. Although our forecasts have been variables were used in the model and are ranked in order of conservative by design to others within the industry, they contribution to R2 : too have been far from reality. X3 - Consumer Confidence - Conference Board Stimulated by exposure to computer regression analysis Survey and SAS as a student in the Graduate Business Program at Xs - Vehicle Seasonality - U. S. Dept. of Commerce Indiana University in South Bend and Dr. Janakiraman's X 4 - Vehicle Scrappage - R. L. Polk & Co. systems analysis courses, I have spent considerable time de- X 1 - Average Retail Price of R",Sugi-84-16 Olson Janakiraman.txt
"METHOD Recent trends in regression analysis have led to a variety of robust estimation procedures. No Missing Values Case The topics of influential observations. residual diagnostics and outlier detection have received a Let Yi denote the i th observation on the great deal of attention in both the theoretical dependent variable and let Xli' X2 i' ... , Xki and applied literature. Selected diagnostic denote respectively the ith observation of k techniques have appeared in the statistical independent variables where i = 1, 2, .,., N. software; however, most robust regression methods Let R(Yi) dp.notp. thE>. rank of Yi among the are not readily available to the general user. {Y l , ... , Yn }, and let R(Xji) be the rank of Xji The rank regression Illodel provides a robust among (Xjl, ... , Xjn}' alternative to its parametric counterpart and is The regression model associated with the rank easily implemented within SAS. This paper regression model is illustrates the general properties of the rank regression model and the potential problems + ... + R(Yi) =~. +~, R(Xl1) ~ R(Xkj) aS50ciatp.d with its use in the presence of missing values. Under these conditions, the different ways in which the model estimates can = 1, be derived using PROC RANK, GLM, REG, CORR, and 2, ... , N i ~~TRIX are discussed and compared. Least squares estimation gives "" A A 6. = N+l (1 - 6, - 6, - ... 6k) -2- where 1 rzs",Sugi-84-160 Rubison Thran.txt
"y Hobos, West Virginia University the sample size. The Jackknife estUastes are ABSTRACT the average of the pseudo-values. PROC JACKREG allows the user to calculate robust estimates of regression coefficients in SPECIFICATIONS simple or multiple regression problems by use of the Jackknife method. See Mosteller & Tukey The following statements are used with the for a good description of the Jackknife. JACKREG procedure: +---------------------------------------------+ PROC JACKREG may also be used as a I validation tool. The Least Squares Regression I PROC JACKREG options; equation is validated by comparing each I MODEL dependent = regressors / options; observation to the equation generated when that I OUTPUT OUT: SASdataset keyword~name ·· ; observation is left out. I BY variables; +---------------------------------------------+ Output includes the individual regression coefficients at each step of the leave-one-out The procedure must always be accompanied process with their corresponding R-square by a MODEL statement to specify the values. A further table of the final Jackknife regression model. An OUTPUT statement may coefficients and the ordinary least squares be specified anywhere after the PROC coefficients. with their estimated standard statement to request an output data set. The deviations, t-stati8tic8 and P-values are a180 purpose of each statement is: displayed. The MODEL statement specifies the dependent Output data sets may be created optionally and independent var",Sugi-84-161 Hambi Chilko Hobbs.txt
"l~ODELS GRAPHIC REPRESENTATION OF LOGISTIC REGRESSION Edward L. Spitznagel, John K. Gahagan, and Donald G. Sessions Washington University THE nRAPHICS ABS'PRM'r In all, we present six figures, three Logistic regression and discriminant related to density functions and three having analysis are valuable tools in medical diagno- to do with sensitivity versus specificity, sis and other disciplines involving prediction :iane in ~he traditional ROC format. of a binary variable. Once the model or rr.oct- els have been fit, there remains the important The uata '-'ndl:lrlying all tlix it; th~ same, task ~f conveying their meaning to the clignt. consi3ting of 615 head and neck cancer cases, This paper demonstrates several alternatives of which 316 had recurrence, For the 316 cas- in grap~ical presentation of these res"".ll ts. co of recurrence, the mean logit was 0.39, with a standard deviation of 1.36. For the ,~99 cases of ~on-recurrence, the mean logit IN1'RODUCTIO::i was -1.22, with a standard deviation of 1.15. In ana~yzing data from a ""umor registry Figure 1 shows normal density functions of head and neck cancer patients, one of our to these means and standard devi- ~atched goals has been to predict recurrence of can- ations. The amount of overlap between these cer. A?plication of logistic regression has density curves shows clearly that LO cutpoint been fairly ~mcce8sf1l1: F:1r Flxlimple,:in stu- will achieve perfect discrimination between dying tumors from three primary sites (supra- the two groups. In the ~ase of our data, the glottiC, glottic, and inferior hypop~arynx). logit values were approximately normal within the logistic regression model incorporating each group. It is a good idea to check for si te, Tlm classification, and age had the fol- approximate normality before using this kind lowing measures of association: of portrayal, but with m'.lltiple predictors contribu~ing to the logit, normality is likely LR chi-square = 269.0 (with 14 df and n=815) to be",Sugi-84-162 Spitznagel Gohagan Sessions.txt
"STAGEWISE EXPERIMENTAL DESIGN TECHNIQUES FOR NONLINEAR MODELS T. J. Bzik nonlinear models. The end result of applying this criterion in a WHY STAGEWISE EXPERIMENTAL DESIGN IS IMPORTANT stagewise manner wltl be to obtain an acceptable model quality A stagewise or sequential approach 10 designing experi- in a minimal number of experiments. mental programs has several advantages over experimental de- A major implicit assumption in USing this deSign criterion is sign techniques which collect all experiments prior 10 statistical that the true model form (ex: W = Xbl Y 2 Zbs)is known. A model analysis. The most obvious of these is the real-time nature of form which can reasonably approximate the true unknown a stagewise approach. Information acquired from the previously model form over the design space will suffice, however. If there run experiments can be used in determining the next best ex- is any uncertainty about meeting at least the latter of these two periment(s) to run in the program or whether additional ex- statements about the model form, then this design criterion perimentation is even necessary. A stagewise approach can al- should not be used to the essential exclusion of other experi- low problems with the model form or the control variable ranges mental design criteria. to be identified and corrected before all allotted resources (time, Table 2 contains a simplified flowchart for the application of money, raw materials, ... ) are consumed. Such an approach this design criterion to a linear or nonlinear model of known is especially useful when working with nonlinear models. form. Some steps illustrated in Table 2 require additional substeps. For example, an examination of whether satisfactory model BACKGROUND: DIFFERENCES BETWEEN LINEAR quality has been achieved calls for the model to be evaluated AND NONLINEAR MODELS in several ways, Both statistical tests and prior process knowl- When performing regression analysis, some presumed math- edge need to be em",Sugi-84-163 Bzik.txt
"A MACRO FOR FITTING NONLINEAR MODELS TO POISSON DISTRIBUTED DATA Edward L. Frome, Oak Ridge National Laboratory Richard MeLein, Oak Ridge Associated Universities SUMMARY sufficiently greater than p to ensure estim- ability of the parameters. The regression Models are considered in which the depen- function will in general be nonlinear in the dent variable y 1s a count that follows the parameters, and in all but the simplest cases Poisson distribution. The expected value of y an iterative procedure is required to obtain Is represented with a regression function that estimates of the parameters. describes the relation between the expeeted count, the predictor variables, and the In the next section we will describe how parameters. Estimates of the parameters can be iterative weighted least squares (IWLS) can be obtained using iteratively weighted least used to obtain the maximum likelihood estimates squares (IWLS). The IWLS procedure is equiva- of B, the estimated parameter covariance lent to using the method of scoring to obtain a mat;ix, the ""deviance,"" and various regression root of the likelihood equations. Poisson re- diagnostics. Frome, Kutner, and Beauchamp gression models include linear, log-linear, (1973) have shown that this IWLS procedure is quasi-linear, and intrinsically nonlinear re- equivalent to Nt estimation and gives a de- gression functions. This approach allows the tailed discussion of POisson regression. In analyst to concentrate on determining the most Section 4 we discuss the SAS procedure NLIN and appropriate form of the regression function a more flexible approach that we have developed without regard for computational complexity. using PROC MATRIX to implement the IWLS proce- The SAS procedures NLIN and MATRIX can be used dure. A numerical example is presented in to obtain ML estimates, their estimated Section 3 using an intrinsically nonlinear re- asymptotic covariance matrix, and diagnostic gression function to illustrate the analysis. mea",Sugi-84-164 Frome McLain.txt
"omputers, com- ABSTRACT puting all possible regressions becomes a prohib- Stepwi~e methods are well known to be suboptimal itive task for moderate to large studies. at determining ""best"" subset regressions. Com- puting all possible regressions to identify Over the years a number of computational algo- ""best"" subsets becomes a formidable task for more rithms have been developed for large regression than fifteen variables. However, recent advances studies which attempt to find the ""best"" regres- in subset selection methods now make their appli- sion subset(s) [3]. Although theSe provide good cation for isolating ""best"" regressions feasible results, in many cases they do not provide iden- for studies containing as many as 50 or more tical results and they can not guarantee obtain- variables. This paper describes a new SAS proce- ing the ""best"" regression subset(s). Of these dure, named BESTREG, which implements the most methods the most notable are a) forward-selec- recent version of the Furnival-Wilson ""leaps and tion, b) backward-elimination, and c) stepwise bounds"" algorithm for ""best"" subset selection in regression. regression analysis. This procedure, intended primarily as an exploratory tool for mathematical Forward-selection evolves the model by succes- model development, provides summary statistics sively adding the most ""significant"" variables, a for the ""best"" and alternative ""next best"" step at a time. Backward-elimination first regressions of all sizes. In'addition,",Sugi-84-165 Gugel.txt
"GENERAL WOOLF-HALDANE/HANTEL-HAENSZEL PROCEDURE FOR DICHOTOMOUS OR POLYCHOTOMOUS EXPOSURE VARIABLES AND FOR ANY NUMBER OF STRATIFICATION/CONTROL VARIABLES Philip N. Gallagher Jr., Pan American Health Organization William M. Haenszel, Illinois Cancer Council Introduction Nonetheless, the patterns that empty cells reveal can be vital to the intelligent interpretation of the statistics - for example, When we and our colleagues began the when for some combination of levels of the hypothesis-generation analysis of a moderately stat1fication variables there are neither cases complicated case-control study (several kinds of cancer, several interesting exposure nor controls at the reference level of exposure. This kind of pattern is concealed variables with multiple exposure levels, and many presumably cogent contra] variables). we when one examines only the overall M-H realized immediately that the Mantel-Haenszel statistic or the logistic regression (M-H) analyses that we preferred would be coefficients.) extremely tedious, time-consuming, and unlikely Therefore we wrote a general SAS program to to be correct if we attempted to manually produce M-H and Woolf-Haldane (W-H) analyses of calculate the M-H statistics for all of the data with exposure variables with two or more permutations about which we were curious. Many levels and any number of discrete statisticians prefer Rome form of logistic stratification variables, including regression for problems of this kind, and intermediate analyses of the constituent tables and their contributions to the overall suitable computer programs are readily available; had we been satisfied with logistic statistics. The output is intended to be regreSSion, the technical difficulties in useful to critical scientists who are producing the desired analyses would ha've been determined to guard against unusual distributions within the sample data that lead minimal. However, we feel that contingency table data ought not to be analyzed witho",Sugi-84-166 Gallagher Haenszel.txt
"CiI New SAS Survival Procedures David DeLong, SAS Institute, Inc. INTRODUCTION The analysis of data from failure time experiments has at least two and Xi a vector of covariates. We assume for the moment tha.t the distinguishing characteristics. First, the failure times are inherently covariates have no effect on the distribution of the ti and that the t; represent a censored sample from a distribution with SDF, 5(1). positive and the normal or log normal distribution is generally not appropriate as a basis (or analysis. Second, there ne often One of the fundamental quantities of interest is an estimate or the SDF. Probably the most widely used such estimate is the product right censored obsen'ations present in the data. Because of these limit or Kapl:\n-Mf'if'r Pl'ltimate givpn hy and oth"""" differeol""f's modf'l~ and methods specifically designed for survival data have been developed. Several textbooks devoted to the analysis of such data have recently appeared and some of them are listed in the references. Olle of the first steps in ana1ysing a set of sunivaJ data is to where S; is the number surviving at t{,n, is the number at risk jUst generate descriptive plots and statistics which indicate the distribu- tional properties of the data and the association of the response prior to I; and the product is over unique noncensored failure times. time with I'Ovariables. Plots of the empirical cumulative distribu- The variance of this estimator may be estimated using Greenwood's tion (unction (CDF) or the empirical survival function (SOF) and formula as transformations of these functions can be useful in suggesting what distribution types might be appropriate. Estimates of the probability density function (PDF) and the hazard function can also be helpful. Additionally generating estimates within strata defined by values where d j = nl- Sf. of covariables can suggest what eHect these covariates may have Altl'rnativt'ly actuarial or liretable- ml'thods may be used to es- o",Sugi-84-167 DeLong.txt
"ON GENERATING STATISTICS, FORMATTING RESULTS AND EFFICIENCY Ingrid A. Amara and Gary G. Koch University of North Carolina at Chapel Hill Introduction A convenient format for a randomization The choice among methods for generating schedule involves replicated paired columns on equivalent statistics often is based on the form each page. Here, the paired columns list patient of the printed results. Steps in transforming number with treatment assignment. The computer output to informative displays can be researcher would sequentially read down the minimized by the careful selection and combina- paired columns as aSSignments were made and tion of SAS PROCedures and programming state- then start at the top of the next paired ments. columns on the same page. For clarity the SAS code, printed results and time estimates replicated paired columns should have the same relative to alternatives are presented for two headings, e.g., 'PATIENT' 'DRUG' and should examples. The first example shows an automation have additional spacing between listings. of transforming PROC PLAN random numbers to a SAS code in Figure 1 for a schedule in tear sheet schedule for assigning patients to Figure 2 shows the use of PROC MATRIX program- treauments in a clinical trial. Here with a ming statements to construct the formatting modicum of SAS statements, PROC PRINTTO is used requirements of a single page schedule. Here to make the results of PROC PLAN accessible to PROC MATRIX is used as an alternative to detailed DATA programming statements in the same job. pointer instructions. PROC MATRIX prepares the PROC MATRIX programming statements are used to page layout as a table which is readily printed consolidate the long two-column list output of by PROC PRINT. Additional spacing between the the DATA step and provide corresponding column paired columns is obtained by an imbedded blank spacing and replicate variable names. PRDC PRINT column with a null variable name. More specifi- prints the results.",Sugi-84-168 Amara Koch.txt
"New Features of the SAS® System for Minicomputers Stepherl M. Beatrous, SAS Institute Inc. Bruce M. Tindall, SAS Institute Inc. m'inicomputer operating system use the COpy procedure or use the TRANSPORT= data set option. I. INTRODUCTION THE XCOPY PROCEDURE -- The SAS® system on minicomputers uses Transport Data Sets on IBM essentially the same SAS® language as the SAS® system on I BM mainframes. You can move whole applications from one type of computer to another PROC XCQPY is used under I BM OS or VM/CMS and run them with only minor changes. operating systems to read and write transport data librades, PROC XCOPY can read transport But there are differences between the two data libraries created under any of the versions of the SAS® system. minicomputer operating systems and can reformat SAS data sets created under IBM OS or VM/cMS Several differences are due to changes that the so that you can use them under a minicomputer users asked for on the SASware Ballot. Others operating system. are due to new features that let you take advantage of facilities unique to minicomputer operating systems. Moving Data Sets with PROC XCOPY All these differences and new features for VMS SAS are covered in detail in Technical Report SAS data sets may be transported to a P-128, which is available from SAS Institute's minicomputer on tape or disk, The tape Publications Department. (A similar report for transport requires that the minicomputer have a AOS/VS SAS will be available soon.) tape drive and that the tape created by PROC XCOPY be of a density compatable with the The topics we are going to cover briefly today minicomputer's tape drive. The disk format are: requires that a netwot'k exist between the IBM and the minicomputer. How to transport SAS data sets between computers, Restrictions on XCOPY How to use permanent SAS data sets and formats on minicomputers, using the lIBNAME and lIBSEARCH statements. XCOPY is capable of moving only one SAS data library per tape or disk file.",Sugi-84-169 Beatrous Tindall.txt
"A PHOSPHATE PROOUCT MIX MODEL USING THE LP PROCEDURE Agnes Eggleston Texasgulf Inc. I ntraduction code 142 (93% Sulphuric) is shown for cost area 416. The Phosphate Production Model was originally conceived as an optimization model to determine Beginning Inventory- tons of material on the most profitable product mix in a multi- hand at the beginning of the time product environment. However, recent market period. conditions have necessitated operating below capacity and the emphasis of the model has Transfer In tons material coming in shifted. At this time, the main purpose of the from purchases or from another cost area. There can be as many as 5 areas model is to assist the company accountants in from which the mz.terial is transferred. projecting costs based on anticipated production scenarios. This is achieved by generating material balance tonnage information within the · Production tons- quantity of production model and interfacing those tonnages with in that cost a rea. projected costing data. This paper will not address the costing aspects but will concentrate · Transfer out tons - quantity transferred on generating the material balance data. to another cost area. There can be as many as eight areas to which the product can be transferred. Design of Equations · Losses tonnage lost due to normal 1. Design Considerations processing, such as evaporation, etc. The Phosphate Production Model was Waste - tonnage lost due to production fluctuation, but for which an average designed to reflect the existing accounting system with which it was to interface. In percentage can be anticipated. the past, production tonnage information was calculated manually and entered into Consumed- material consumed in the manufacture of another product. the system in card image format. The data was then processed by an existing Cobol program and a material balance report was Ending Inventory -tonnage of product on produced. Because of the complexity of the hand at the end of the time",Sugi-84-17 Eggleston.txt
"A REVIEW OF SAS INTERFACES WITH VARIOUS SOFTWARE SYSTEMS Richard laValley, Satellite Business Systems APlDI Introduction LaValley and Mertz described an application Organizations in the past have selected using the indirect app~oach linking APl/APlDI and software systems to meet specific data storage SAS at SUGI 83. APlDI is a relational database and management needs. The rapid evolution of management system that selects data using an data usage has made it necessary for software inverted access technique with indexing. APL is systems to adapt to more sophisticated require- a high level programming language which can be ments in analysis and graphic representation. A used in conjunction with APlDI for spec1f1c SAS solution to this problem has been the linkage of analysis. The technique used by laVal ley and SAS to existing software systems. Mertz used APlOI to create a summary file of com- plicated relational type queries and then pass Most software systems allow the user to pass the data via an OS file to SAS. data to a IIflat file n which can then be read into SAS. This method can be defined as the lIindirect approach"". Other software systems have developed FOCUS IIdirectll interfaces which el iminate the need for FOCUS 3 is a comprehensive information con- a flat file and creates the SAS DATASET directly. trol system which allows access and updating of This paper is a review of known interfaces single and comp1ex files. and is also a report using either a direct or indirect approach to generator. In the Summer 83 FOCUS NEWS, an link SAS with various software systems. As each interface was announced which--dllrectly linked software system is described in this paper, the FOCUS to SAS in the TSO and CMS environments. appropriate SAS interface(s) will be introduced With this interface. FOCUS extracts two files: highlighted. A summary table of known SAS inter- a data file of selected fields and a data faces with current contact information can be description file in",Sugi-84-170 LaValley.txt
"r, but what is a data base? This term is much abused. 'Data This tutorial provides the SAS® user who needs base' is sometimes used to refer to any file or to access data stored in DL/I data bases with the set of files in order to project a state-of-the-art fundamental concepts and techniques necessary image. We can, however, define the term more to write a SAS/IMS-DL/I® DATA step. The precisely. DLil session includes an introduction to A data base is a collection of interrelated data programming concepts and an examination of statement extensions. SAS/IMS-DL/I Sample stored in one place for access by multiple users. DL/I data bases and SAS/IMS-DL/I programs The data are collected together and are in one illustrate these concepts and programming place to provide control and eliminate techniques. The material focuses on retrieving duplication. In addition, the physical structure data from DL/I data bases. Due to time of a data base is transparent to the users. Only restrictions, data base update considerations the data base system must know the physical remain outside the scope of this presentation. organization of the data, since users and applications access the data through the data base manager. Then, if the data base changes Since the tutorial is geared to experienced SAS users who know little or nothing about DL/I, physically, the applications are not necessarily much of the discussion deals with basic data base affected. Often just the definition of the data concepts and",Sugi-84-171 Turney.txt
"MANAGING A DATA BASE OF PERMANENT SAS DATA SETS Joshua SharT;n, ORr, Inc, 1.0 INTRODUCTION used as keys to match/merge the data sets. There are nO simp 1e formu I ae for determin i ng This tutorial for beginning SAS users will the number of data sets and the variables to be review and explain the logic and SAS code for used within each SAS data set. In any case, as the creation and management of a SAS data use of the data base evolves. the initial base. A Project Management data base which structure, no matter how carefully planned wi 11 tracks project schedules and the hours and usually be modified. The data management dollars spent on each project's activities will capabilities of SAS make this modification of be used as an examp 1e. The des i gn of the data the data base structure quite simple. space~ base allocation of disk. updating, and maintenance of an audit trail will be Designing the data base requires a balance discussed. Although the allocation of disk between a few data sets containing many space wilT be specific to the as operat 1 ng variables and many data sets containing only a ~f d~ta system, the principles SAS base few variables. Small SAS data sets are easy management described in th,s paper Wlll ,apply and inexpensive to maintain (using the UPDATE d~ta'l to all operating systems. For more on statement), but usually must be combined to data base editing, see the paper 1n these generate a report, requiring a SORT and MERGE. In~eractive Proceedings titled, itA General fzed SAS data sets with many variables can be Full-Screen Edit-Update System USlng SAS expensive to process and can use excessive Software"". An understanding of the mechanics amounts of disk space~ especially if there are of permanent SAS data sets is essential to many missing values. But, having many building a successful data base. variables stored in the same data set makes reports easier to generate since extra Data 2.0 PERMANENT SAS DATA SETS Steps are not needed to combine varf",Sugi-84-172 Sharlin.txt
"PROC CPM Radhika V. Kulkarni SAS Institute Inc Table II shows a network containing nine tasks in AOE (orm. The CPM protedure is used to schedule activities suhjed to prece_ dence constraints. In order to determine the schedule one needs Note that in order to capture the precedence relationships between activities usin~ AOE notation, it is sometimes necessary to use to speciry the duration or each activity and the precedence lela- ti005 in the Corm of a network using either activity-on-edge (AOE} dUlllmy arcs of zero duration. or acth·jty-on-vertex (AOV) rormats. To illustrate by means or a simple example, suppose a project has three activities, A, B, and C of duratiom 3, 4, and 2 days, re~pectivt'ly. Suppose rurther that· activity A is followed by activities Band C. Table I shows the two representations of this simple network. In this tutorial we shall illustr:'l.t,e f;omp nf thf' options and r""'aturf>s Example AOE form III or the CPM procedure using some examples. Table I also shows the main statements needed in PROC CPM for both AOE and AOV format:;. Table I AOE Af'pt),·n~ opna.hrr AOV A DATA CRANEl ,Em mm mlS ACTTVTTY TATL , , , , , , AOE OBTAIN QUOTATIONS , PLACE ORDER 3 3 PROC CPM options; · , , 3 3 DELIVER CRANE , TAILNDDE variable; 4 3 NOTIFY AUTHORITIES , · APPOINT OPERATOR 3 8 HEADNODE variable; , , , , 6 4 INSTALL CRANE 3 , DURATION variable; INSPECT CI\ANE DUMMY 1 0 B B , · , · variables; (optional) ID DOMMY , 8 0 TEST THE CRANE U 3 AOV Table II PRDC CPM options; variable; ACTIVITY SUCCESSOR variables; DURATION variable; variables; (optional) ID Table I The stat.ements required to obtain a schl'cinlf' and the resulting output data set are shown in Table III. 938  Suppose now, that a particular activity, say 'Appoint operator', is required to start on March 26, 1984. A schedule satisfying this Undated Solution requirement can be obtained by spedfying 26 March 1084 in the DATE= option on the PROC CPM statement and specifying the ALIGN, NTAILNODE, and NHE",Sugi-84-173 Kulkarni.txt
"Tutorial U~in9 the SAS Systam to Perform Univariate and Cross-Spectral Analysis John C. Brocklebank David A. Dickey SAS Institute Inc, Associate Professor of Statistics Cary, N,C, North Carolina State University Raleigh N.C. E)(ample- A!lST::lACT G>ven witte,' usage dilt .. 'n a hou~ehuld rrr .. ~su!'ed Ol/el' an Time serles analysis is widely cI~ed in engineering, the physical elght'week period, SCiences, economics, and statistics. Spectral analysis, or the ""frequency domain"" JPproach to time series analys,s, is po<>ular to dete'--l1""'"" whelhe, or 1I0t there I, a weeldy cycle G(MI "" in engineering a;:>pllcations. Firmly intertwined with the n, '.... ""ter u""'''(jr· spectral approach is the ""correlations"" or ""time domain"" approach, often used for shtistical mod .. ling, i'kU; Gl'l.lrr; Many find the concepts of power. fr""qupncies, and periodicities l'IUI' ~':-T; in spectral analysis difficult to grasp. Yet with applications covering many fields and a wide range of problems. spectral ousehold Water Usage analysis proves to OF!"" f""scin""ting f, .. ld of study. 'l.tl!~!lj .. jlllto OVERVIEW This lutonal focuses on the ""spectral"" approach to t,me series analys,s uSing the SAS'"" System The many relat.onshlps between the spectral app'""oach d'''.1 the ""t'me"" uorrrd'"" dpp'O<lo..l, al'e discussed, The tutol'lal eOl/ers the follOWing topics' D ..f,n,t,on of ,ppr_I'""LJm of ARMA pl'OeeSS.,s, 'ncludlng white nOIS., ~pect,-a Def,n,t,on of pef""lodog,-;un and clst'-Ibutlon of per,odogr'am O""dlnates Obt~""""""9 plots 0 1 the p~I'lodogram and smoothed per'lodo9,-am fr-om the ~f'tC !'KA proceeu,""e Cons,deratlons for cllOo""ng appr'o!""riate we'ghts fo"" smoothing Testing for h,dden penodlc,\,es """"I""""'''''T'''''~''T'""'""'''''T''~''I'~''n''T'''''''''rnnn''1'""''''''''l''~'''I'~'''''T'''' ser,es :and guantit>es_ Multlpl~ cro>~,>pectr~1 I, PERIODIC DATA Example continued ~pect .. al dnalysls was uocvloped to deteLt ,1I1uso,dal components "", t"""""" ,e, ""'~ ,,""uuels Use the GLM I-Hl.ll.eUU,e to deter",Sugi-84-174 Brocklebank Dickey.txt
"INTERFACING SAS/GRAPH SOFTWARE WITH GRAPHICS HARDWARE Mike Killt, SAS Institute Inc. r-----------------------~ WE WILL COVER: QUESTION OF THE DAY: 1) WHAT IS A GRAPHICS DEVICE? WHAT DEVICES CAN I USE 2) HOW SAS/GRAPH WORKS WITH SAS/GRAPH SOFTWARE 3) CLASSIFYING DEVICES AND HOW DO I USE THEM'! 4) USING SAS/GRAPH WITH DIFFERENT TYPES OF DEVICES CD CD 5) PORTABLE CONSIDERATIONS TYPES OF DEVICES WHAT IS A GRAPHICS DEVICE? · VIDEO DISPLAY TERMINALS -- FOR OUR PURPOSES-- · PEN PLOTTERS ""ANY PIECE OF HARDWARE CAPABLE OF DISPLAYING A PICTURE GENERATED · ELECTROSTATIC OR LASER PRINTERS BY COMMANDS SENT FROM A HOST · DOT-MATRIX PRI:-.JTERS COMPUTER"" · CAMERAS <D HOW DOES SAS/GRAPH WORK? HOW THEY WORK EXAMPLE -- YOU CODIi' · HO~r COMMAND SEQUENCE SENT FROM TO DEVlr::F. · GOPTIONS DEVICE=TEK4105; USUALLY MOVE. DRAW. TEXT FILL COMMANDS & PROC GPLOT; PLOT X*Y; · RUl\; COMMANDS VARY FROM DEVICE TO DEVICE · EXAMPLE--DRAW FROM (0,0) TO (1000,1000) AND SAS/GRAPH SENDS THE CORRECT HP722D JNSTRUCTION -- PAO,O;PD;PAlOOO,lOOU CODE TO THE TEKTRONIX 4105 TERMINAL HP722I INSTRUCTION -- p""@O( TO DISPLAY THE PLOT. CD HOW? HOW DOES SAS/GRAPH WORK? HO W GilAPHICS OUTPUT lS GENERATED (CONrINUED) A TWO-STEP PROCESS STEP 1: INTERNALLY YOUR REQUEST IS ~ I CONVERTED INTO A SERIES OF GPLOT l=rDEVICE § MOVES, DRAWS. ETC. ON AN USER ----""I PL.O'l'I""J -- IftICI I =~I ~ DEVICE INDEPENDENT GRID SYSTEM PGM STEP 2: THESE MOVES AND DRAWS ARE rODULEI~1 DRIVER CONVERTED TO THE SPFCWIC COMMANDS LSED TO PRODUCE THE PICTURE ON THE DEVICE YOU ARE USING. THIS IS (j) DONE BY A DEVICE DRIVER 955  CLASSIFYING DEVICES --3 MAJOR CRITERIA-- DISPLAY TERMINAL VS. IIARDCOPY CLASSIFYING GRAPHICS DEVICES INTERACTIVE VS. NON-INTERACTIVE CODE AND COMMUNICATIONS PROTOCOL -- CLASSIFYING DEVICES I CLASSIFYING DEVICES CODE & ,COMMUNICATIONS PROTOCOL INTERACTIVE VS. NONINTERACTIVE · · WITH SAS SOFTWARE INIS HOST WHILE GRAPH CODE INTERACTIVE--USER COMMUNICATIKG ASCII BEING PRODUCED. DEVICE CANNOT BE EBCDIC . SHARED. COMMU'IICATION",Sugi-84-175 Kalt.txt
"USER-WRITTEN DEVICE DRIVERS Howard Houston, SAS Institute Inc. LEVELS OF INTERACTION INTRODUCTION The degree of interaction between the internal User-written device drivers have the advantage of allowing users to tailor device support to their and the external drivers is controlled by the specific needs. This can take the form of an developer of the external driver. There are three levels of interaction possible between the environment that does not allow the standard internal driver and the external driver. At all Institute support, or a graphics device which is levels of interaction the external driver can not supported by the Institute. Presently, the only way the users can provide their own handle the communications with the graphics device, but at certain levels the internal driver support is with the linkable device driver. This can be used to communicate with the graphics serves many users needs quite well, but it is not device intelligent and is designed more for use device. This frees the developer of the external driver from supporting communications with the with a plotter than with a CRT. graphics device. In the next release of the SAS/GRAPH® product, The lowest level of interaction is when the there will be a new method for user support of a external driver is a post-processor. The graphics device. This method will allow users to internal driver only produces the metafile. After develop device-intelligent drivers. These device the SAS/GRAPH® program is finished, the user drivers are not linked into the SAS® System. must execute the external driver to produce the This removes the need to link your device driver graphic output. The external driver must with each new system release, and allows this support all communications with the graphics type of device driver to be used with systems device. that do not allow the linking of external routines with the SAS® System, as is the case with The next level of interaction allows use of the minicomputers. inter",Sugi-84-176 Houston.txt
"USING THE SAS/GRAPH DEVICE DRIVER FOR THE IBM PERSONAL COMPUTER Mike Kalt, SAS Institute Inc. How It Works Ilegir.ning with the 82.2 release, the SAS/GRAPlI® product contains drivers which permit the IBM Personal Computer (PC) to be used as a graphics The TERM5l50 program operates in a loop between a ""sending"" mode, in "",'hieh characters keyed in by outpt:t device. When using this driver, the PC functions as an asynchronous (ASCII) terminal the user are transmitted to the host via routines in the Asynchronous Support Package, and a COIlIlec..Led Lo a uminfrBrne where the SAS Syslem i::; I1recieving"" mode, in which data are received from running. the host. If the data received from the host are in the forD of text, the text is displayed on the What You Need PC monitor. However, i f input from the host consisLs of commands from lhe 1BI15150 device To use the driver, you need the following driver, TERM5150 branches to code which generates ~IBM hardware and software for your IBM PC Item a picture (based an the commands from the host) numbers in parenthesis): on the screen. This process is depicted in Figure 1. 1) 64K Memory Expansion Option (1501012) 2) PC Computer Diskette Software (DOS IB~ How to Use the Driver diskette) (602~OOl) Before you begin, you must download the TERM5150 3) Color Graphics Monitor Adapter (1504910) and REPL5150 programs to a diskette on your PC. On the as SAS installation tape, there is a iile 4) Asynchronous Communications Adapter. This called SAS.GSDURCE, which should be loaded into a is a bClllrri that 1 P.ts yon connp£.t the PC; with a parti-:ioned data set on your host computer. On ~ainframe. (1502074) the CMS tape theye is a GSDURCE MACLIB, which should be loaded into a MACLIB on a CMS minidisk. 5~ Asynchronous Communications Support. These programs may downloaded from the be (6024032) This is software for the PC that mainframe to the PC, using the either the flllnw~ it to function as an ASCII te_rminaL dmmload or ""filewrite"" functions",Sugi-84-177 Kalt.txt
"epts I I I I- Sample Presentation. I I I I- Audience Questions/Feedback. , I , I I I Good afternoon ladies aud gentlemen, my name is Roger Williams. The agenda we will follow \.I'i~l begin with an overview, just giving some objectives, etc. Then a concepts section, that will not be too~detailed, followed by a sample presentation. This will be concluded with audience questions. 971 I I Objectives I I I I I I- To familiarize the audience with the broad capabilities of I the product. I I I I· To do a limited demonstration. I I I I· To provide an opportunity to explore user applications and I requirements. I I I I The objectives that we would like to accomplish by giving this with the broad presentation are first. to gain a familiarity capabilities of the product. The important word here is broad; this is a management summary type of presentation. We will do a limited demonstration. There is a more complete demonstration in the demo rooms upstairs. Finally this will provide an opportunity to explore user applications and requirements or what are typical uses for the product. I format I I I I I I- Introduction with questionjansto.'er. I I I I- Walk-thru with a real life example. I I I I- Review and audience questions/feedback. I I I I The format that we will follow in order to cover this material is the concepts will be presented as an introduction in question answer format. This means We will ask a question and pose several possible answers. The demonstration portions will use a",Sugi-84-178 Williams.txt
"STATEMENT STYLE MACROS Donald J. Henderson, ORr, Inc. David L. Kuhn, SAS Institute than in a permanent format library in order to 1. INTRODUCTION facilitate updating them as needed. The MAKEFMT MACRO will be developed to convert the The SAS 82 MACRO facility can be used to information stored in this data set into a define and add new statements to the SAS format module. language. This tutorial will illustrate, by example, techniques for designing, testing and implementing statement style macros. A statement style macro is a macro whose call ACLID ACLTITL looks like a SAS statement. The call begins with a keyword, which is the macro name, and FINALIZE REQUIREMENTS 10 ends with a semicolon. The parameters follow PREPARE FUNCTIONAL SPECS 20 the keyword and are separated by blanks. REVIEW AND ACCEPT SPECS 30 Particular emphasis will be given to techniques DESIGN SYSTEM which allow the macro program to verify syntax 40 before passing control to the SAS compiler. CODE AND UNIT TEST 50 SYSTEM TEST 60 This tutorial is for the advanced user who ACCEPTANCE TESTING 70 is thoroughly familiar with the SAS system a~d MOVE INTO PRODUCTION 80 has experience with SAS 82 MACROs or TSO CLISTs or CMS EXEC s. FIGURE 1. Sample Data for MAKEFMT MACRO The primary reason for using the STMT option is to tailor a SAS environment so that users and programmers can perform functions common to their environment using a syntax The MAKEFt4T MACRO has four parameters: the which they are familiar with. Thus, the STMT name of the data set containing the desired option can be used to define or build user information (FROMDATA); the name of the languages. Given this use of the STMT option, variable with the code values (KEY); the name it is crucial that meaningful error messages be of the variable with the corresponding labels issued if a mistake is made~ just as the SAS (RESULT); and the name of the format module to system issues a meaningful message when a be created (NAME). As presently defined (se",Sugi-84-179 Henderson Kuhn.txt
"I~ARKET A HIERARCHICAL APPROACH TO DAILY STOCK FORECASTING ~eydar Pourian, University of Missouri at Saint Louis SAS is the best software currently available aggregation. Based on a ""memory"" of six to in offering a ""complete"" package of stock market seven manU s. da i 1 y fo rec as ts a re generated by forecasting on a day-to-day basis. Due to the use of the latest available information. The measure chosen is the most-watched Dow Jones richness of its DATA. OUTPUT and a variety of PROCEDUREs, SAS is capable of providing a Average of 30 Industrial stock prices (DJI). workable forecasting tool both for the The ""estimation"" period is the six-month individual inlJestor and the brokerage firm. period from Monday. August 16. 1982 to Friday. February II. 1983. Each model, therefore. has a Such a complete package of stock market forecasting can be secured with a simple SAS memory of at least six months (initially, N=1271. application of the ""Analytical Hierarchy Process"" and pairwise comparison (see Saaty. 1980). The hierarchical approach to forecasting The ""forecast"" period is the one-month the daily path of stock pri ces can be generally period from Monday, February 14, 1983 to Monday, decampl ; shed by a11 or some of the follow; n9 March 14, 1983. It should be noted, however, steps. that each day data were updated and ~ estimates were obtained, upon which the Variable Identification forecasts are based. Thus. £Iach daily forecast I. is based on a memory from August 16. 1982 to 1. OATA Step, including PROC CITIBASE/ ""yesterday."" It can be seen that the estimation Xll, a priori Transformations, and and forecast processes themselves followed an ARRAYS ""iterati veil process: Preliminary PROC PLOT/TIMEPLOT estimation, forecast, ... , update, 2. reestimation, forecast, ··. PROC CORR/RSQAURE/RSREG/TTEST 3. This process continued throughout the ""forecast"" II. Estimation and Forecast period, utilizing the latest information available up to yesterday inclusive (N=146 for 1. Adju",Sugi-84-18 Pourian.txt
"SAS TUTORIAL - INTERACTION PLOTS Rudolf J. Freund, Texas A&M University Interaction in a multifactor experiment reflects inconsistent responses of one factor across levels of other factors. The existence of significant interaction hinders the interpretation of main effects for the individual factors. Graphical representation of interactions can be used to determine what. if anything, can be said about the main effects. This presentation consists of a set of transparencies that show several methods for making graphical representa- tions of interactions with SAS. Copies of the handout (also available from the author) can be used to make the set of trans- parencies. 989",Sugi-84-180 Freund.txt
"e model for a ABSTBACf one-way treatment structure with one Tbe analysis of covariance is described covariate in a completely randomized design in tbe framework of comparing several structure is regression surfaces. one surface for each population or treatment combination observed. Methods for using PROC GLM to carry ont the (1) i=l ····· t. j-l ····· n analysis of. covariance for both equal and ~Y.lx = tti+~iX and we will assume that where unequal slope models are presented. Three 1 examples are used to demonstrate tbe Bij - iid N(O.a 3 ). computations and resulting inference Model [1] has Zt+l parameters as it has t strategies. intercepts. al ····· u · t slopes P1""-'''P t t 1. Introduction and a 3 · the variance of each experimental The technique of analysis of covariance unit. is used to compare regression surfaces when a The analysis of covariance allows the different surface is possibly needed to experimenter to make various comparisons adequately describe the relationship which between the t treatments or t regression exists between the dependent and one or more lines (surfaces). The analysis involves independent variables for each of several comparing the t slopes and comparing the populations. There are several different distances between the regression lines applications of analysis of covariance with (surfaces) at preseleoted values of X. The many of those requiring special techniques to estimates of the mean of y for a selected specify the appropriate model needed",Sugi-84-181 Milliken.txt
"tric procedure are violated. Additionally, the introduction of the In this article the use of SASe soft- to do nonparametric statistical idea of the rank transform has produced ~are analyses is explored. It is assumed some procedures which are~ in some ways, better than the previous nonpara- that the reader is familiar with the software package and has some fami- metric method. Since the rank transform liarity parametric statistical approach essentially suggests replacing ~ith It is not assumed tb&t a know- methods. the data by ranks (the ranks may be ledge of nonparametric methods exists. assigned in various ways) and then Some of the material covered involves carrying out the usual parametriC procedure on the ranks instead of on the documented in [lJ existin~ procedures~ data themselves it is usually a simple or in other places. Some of the mate- procedure to find the software rial involves the use of parametric procedures an ranks in order to produce neccessary to carry out the analyses. the desired test statistics in an indi- The SAS Institute and most othe~ rect way. Occassionally ~ the last step statistically o~iented program develop- needs to be done with pencil and paper ers have spent most of their effort develping routines to perform the or hand held calculator. traditional parametric analyses as well as those techniques ~hich are commonly I. INTRODUCTION claimed by both the parametriC and In this article we assume that the nonparametric camps. In the later category",Sugi-84-182 Hobbs.txt
"T fey) = F'(y) This paper is aboo t FROC STATESPACE and how this program uses Akaike's Information (assuming F(Y) has a derivative). Criterion. Suppose further that f(y) is a p.d.f. of a PROC Basic criticisms of STATESPACE parametric distribution. i.e ·· fey) ill indexed are: by a vector of parameters, say, 9 · 9 could be estimated by finding what values of 9 maximize If the user doesn-t pick the form 1) a likelihood function L(9). L(9) is defined FRoe STA1ESPACE picks the himself, to be model form of a time series using n L(8) (Y , ·· ,Y ) IT (Y ) Akaike's Information Criterion. =f f o 1 i""'l 0 n n 2) Akaike's Criterion often doesn't Since the Y values are independent observa- I t tends to overes t ima t e work well. tions, L (9f is the joint p.d.f. of the data the number of parBmeters in a time assuming that each Y has a p.d.f. of fe(y). n series model. An equivalent Bnd usually easier problem to solve is finding which values of 9 maximize 3) The penalty for overestimating the the logarithm of 1.(9). The methods of finding number of parameters in a time series the values of 9 that maximize L(9) will not be equation can be Ilubstantial, in terms discussed here. of the mean square error of prediction. However, in addition to estimating the par- There is no such thing as an ""auto- 4) ameters of fe(y), the likelihood function caD matic statistical method"" any more than also be thought of as a measure of the data's there is an automatic method of think- distance to the data's mo",Sugi-84-19 Chavern.txt
"Response to 'On the Limitations of Akaike's Information Criterion and Its Use in PROC STATESPACE' by Jim Chavern By David DeLong The author has made some interesting observations, some of which indicate a ba8ic misunderstanding of the pur- poses and the use of the ST.41ESPACE procedure. The fad t'!; that the same AR(l) model 'Wa"" dlOfien both by the author and the STATESPACE procedure. First and most importantly no statistical program is meant to be applied blindly. The role 0/ the"" automatic"" sela- lion in PROG STATESPAGE is 10 provide a slarling model which must then be checked for overfitting or lack of fit. There is alu:ays the need to plot raw data and residuala to examine distributional assumptions. Secondly when run on this dala PROC STATESPACE issues two distinct warning messages that there are not enough data to support a value of ARk/AX"" equal to the default of 10. The value of ARMAX is ""dured 10 8 but with only 41 observations on five series, an AR(8) model effectively leaves onl1/ 1 degree of freedom for the residuar variance matrix, Stnce it is the loy of the deter- mt'nant of the residual variance matrix whIch determines the AIC and also the stepwise chi-square test, either test applied blindly will pick an AR(8) model. Thirdly, although for the aboue reasons the preliminary model t'S an AR(8), this model is only used as an in- termediate step in the complete model selection process, The adual final model selected ""automatically by the STATE:SPACE proadure is an AR(l) whi~h is exactly the same model hand fit by the author! The difference in forecasts is due to different estimation techniques and not to a differente in tfie chosen model, The author used the default estimation method which is appropriate for large amounts of data, HOH/ever 41 observations (205 values) is not a large amount 0/ data for fitting 30 parameters, PROG STATESPAGE has an alternalive rondilionalleast squares' estimation technique which is more appf'Opriate for small sanple sizes",Sugi-84-20 DeLong.txt
"handling all initial contacts with users, answering the general type of A new system has been implemented at SAS more"" specialize~ questions, and referring Institute to track user-reported problems. This questions to the appropriate second-level paper will discuss the new procedures and representative. The associates completed an requirements that are necessary when contacting intensive four-month training program and began with SAS· the Institute regarding a problem answering the telepcones last fall. software. Automated Tracking System Introduction If the reorganization of the Technical Support Last summer, it became obvious that the methods Department was to be successful, an efficient previously used by SAS Institute's Technical method of probh~1I1 luggiug wa::; :-equired. An Support Department were insufficient to meet the 8lltomated t_racking system has been designed and needs of a growing user community. As the number implemented to log all calls coming into the of user inquiries increased to 300 per day, the department. It serves as an electronic ""note- system was beginning to break down. Users were pad"" for recording detalls about problems, and having to wait too long before a consultant provides data that permits the Institute to became available; consultants were having to gather statistics on the types of problems spend increasing amounts of time dealing with the encountered by users. Sucr. a system requires a problems of the grov;ing number of new users; and torm",Sugi-84-21 Adair.txt
"STARTING A LOCAL SAS USERS GROUP: SOHE ISSUES AND GUIDELINES Jim C. Knoop, Aetna r.ifp. Clnrl Casucclty Co, TAKING THE FIRST STEPS ABSTHACT Your first step should be to verify there is not Drawing upon the experiences of two New England already a users group either in. existence or in SAS users groups (Hartford and Boston), this the planning stages in your area. To this end, paper identifies major issues involved in start- you might want to contact the SAS Institute ing a local SAS users group, and suggests sever- directly. Assuming that the field is clea[', al options and practical guidelines for address- your initial efforts should then be focused upon ing these issues. two major obje~tiv@:R: to id@:ntify Hnd estHblisb contact with your group's potential members; and Initially, the discussion is dire.:.ted to any to make preparations for your first meeting. potential organizer(s) of a local users group. in terms of the time and resources required on Reaching Potential Members their part, specific ways of reaching potential members, and the necessary preparations for--as The simplest way of reaching potential members well as the actual conducting of--the first meet- is to announce the formation of your group in ing. Attention is then shifted to the decisions SAS Communications. Your request should be for- facing the group as a whole. These include: warded to: the group's objectives, structure and leader- ship; the frequency and format of meetings; vari- Edi tor om; Rdmini~trative concerns and the question of SAS Communications operating expenses, Finally, several options Box 8000 for subsequent meetings are presented I such as Cary, NC 27511 varying presentation formats, forming special- (919) 407-8000 topic subgroups, organi2ing workshops and host- ing social events. Be sure to include your name, address, telephone number, geographic area covered (Boston, San Given the diverse nature of members' needs and Diego/Los Angeles. etc.) and special interest backgrounds",Sugi-84-22 Knoop.txt
"Happenfl When, pgs. 16-17), a brief summary will be presented. The SAS A systematic approach to understanding supervisor checks each incoming the new macro facili ty is presented. statement one at a time for syntax Included in this discussion ~ill be errors using a wordscanner. prope~ definition and calling of a Statements are collected in this macro, iORntifyine e!=lch of thRflR fashion until the current parser tasks, examining the context in which (being the DA~A step compiler cr a macro is called, proper use and p.<lr""H:~~) Rno procet1urf'! e""lCClunteT'fl ttA passing of macro variables, and a of the present step. Once an entire general overview of using macr~ step is compi:ed, it is then executed programming statements, Several (barring any syntax errors, of comEon errors regarding ~acro lnnguagc course). No more SAS statements are usage accompanied by a brief read until th~s process is completed, discussion of macro options and how they may be used fer debugging The macro language processor is found purposes will complete the between the words canner and the nA~A Exa~ples :llustrating presentation. step compiler or ?ROC parser, (See varlOUS pOints will appear t~roughout Figure 1, adapted from SAS the discussion. Communications, Fall 1983, Pg. 16), The macro processor is triggered by Th@ 82.0 release of SAS included the ""%"" and ,,&n encountej""ed by the",Sugi-84-23 Siryk.txt
"State University Karen Griffin - Smith College ABSTRACT intere5t to undergraduates, and power that had attracteQ us to SAS An introduction to SAS is taught as in the first place. part of the sophomore level Information Processing course. In 3 - SASB2 APPLICATIONS the Spring term of 1983 SASaZ was Procedure Tabulate (3) creates made available to us. The new SAS hierarchial tables that can contain Procedures Tabulate, and Calendar descriptive statistics such as mean, made excellent additions to the SAS standard deviation, and range. Procedures taught in the course. Tabulate is a very flexible procedure but is nob ~oo hard to get 1 - BACKGROUND started with. To illustrate its application two examples cr@at@d by The Information Proc@ssing cours@ students will b@ presented. One was first offered at SC8U in 1972. example shows how Tabulate could be It has introductory programming as a used to present data collected on a prerequisite. The coursels objective geological field trip and the other is to provide students with a is from the area of production practical __ well .s intellectual control. survey of the field of information processing. The students study a Geological Example t@xb with sections on comput@r In January 1954, the Geology technology, programming, systems, departmen~ of a nearby college and computers in society. It was sponsored a field trip ~o San always felt that students should use Salvador, Bahamas to collect as well as read about computers and different algae t",Sugi-84-24 Workman Carr Griffin.txt
"rnisch, University of Illinois at. Urhil.na-Chamnaiqn Carolyn J. Palmer, University of Illino;s at Urhana-ChampaiQn ABSTRACT proficient in their fields.~ (p. 131) and This paper describes a project conducted that they are seeking computer skills and SAS at the University of Illino;s at Urba~a applications which will help them in their Champaign, wherein the SAS system under current work. In many cases. SAS instructors VM/CMS is used to complement and supplement and materials have safely assumed that such ""students"" already have a fundamental working mater; a 1 presented in an i nt roductory statistics course, Undergraduate and knowledge of statistics. graduate students from a variety of academic departments are required to participate in Our course differs from some of those weekly computer laboratory sessions and to formerly described in that we introduce SAS complete homework assignments and a course to students who are not only fi rst-t ime SAS project which require the understanding of users and first-time computer users, but also use of statistical concepts and the first-time statistics students. In fact, SAS appropriate SAS statements and procedures. is used not only to supplement. but also complement other material presented in this This presentation will emphasize the introductory statistics course. offered by importance of designing appropriate the Department of Educational Psychology. instructional materials, developing effective teaching practices. and providing an",Sugi-84-25 Harnisch Palmer.txt
"EXPERT BASED TRAINING OF SAS USERS: GETTING PRODUCTIVITY FAST Nelson R. Pardee, Syracuse University simple: the director of the program wanted ,. Abstrc.C+ things done right, done quickly and efficiently. training methods for teaching languages M~ny Also, he didn't want tasks left undone because the person doing it didn't know how, It became in general (computer languages and SAS in particular) have been tried with varying degrees clear, however, that we hed too much work for of succesS. Because it Is desirable that SAS one, and latsr two. sxperts. We needed a way to users be productive as soon as possible, choosing multiply the knowledge thoss experts had. the right training method is very important. We accomplish this at the Health Studies Program by Early, datQ cleaning and complex file giving new users (generally graduate manipulation was done In PL/I, and dato analysis SAS students) a minimal amount of SAS training In was done In SPSS. We began spreading the load by giving the SPSS portions to graduate students. classroom. textbook. or CAl fashion. cnd then giving them a ""real"" task to do. An expert then Then SAS became 6vallable Qbout three years ago works closely with the trainee, providing help and we found we could do just about anything we needed in SAS. To our surprise, we found that In whIch initially may include \IiIriting most of the their tenure, graduate program. SAS Over SAS the graduate students could do most of the students continue to rely on the expert for nelp programming formerly done In PL/I. So we 16t with and approacnes to new projects, althougn In thsmt The only question now was the best way to lesser degrees. This method attempts to multiply train them. the expert's ski lis, and to foster immediate productivity and rapid training for new users. IV. Characteristics of the Training Method 11. Background In retrospsct. our training method nBedsd to~ The Health Studies Program does funded resEarch involving analysis of ""not small"" 1. Work w",Sugi-84-26 Pardee.txt
"t achieve the train- If you are assigned the task of developing a ing results you want. SAS& training course, where do you begin? How can you decide what topics to cover and how to organize them into a logical sequence? This The Course Development Plan paper discusses a structured .technique used at SAS Institute to analyze the skills students The plan consists of five phases. need to learn and the development of a course based on that analysis. Materials developed 1. Investigating needs and av""ilable re- may be in a variety of forms - overhead trans- sou rces parencies, 35mm slides, videotapes, or text for a workbook or computer-based instruction. 2. Designing course content and flow Since many people are concerned with develop- ing an introductory SAS course, this paper 3. Writing the course outline and materials uses topics in such a course as examples. The techniques, however, can be applied to the de- 4. Testing and revising presentation and velopment of any course, at any level of expe- materials rience. 5. Finalizing course materials and content. ~ Why Have Method? Investigation Why is a method needed for course develop- ment? Designing a course is like writing a com- The investigation phase of course development puter program. Programmers that follow struc- includes two stages: needs assessment and re- tured design techniques usually complete search. In your needs assessment, you define assignments faster, since repetitive components what needs the course is expected",Sugi-84-27 Ussery.txt
"NODIS PROCEDURES FOR DEMOGRAPHIC ANALYSIS Janice S. Tobin. Cleyeland State University (NODIS) Mark J. Salling, Cleveland State University (NODIS) UNMET NEEDS INTRODUCTION: SAS NODIS & Al though SAS is a very powerful Sta t i stical Analysi s System (SAS) so::tware is used at many research soft'v,'are system we have found there are inst.itutions. Its ease and flexibility several programming needs at NODIS in file maintenance and processing, its which are not easily satisfied by strong features as a high level existing SAS procedures. programming language, and its extensive statistical analysis Agaregation capabilities, make it probably the Roftware best package ~ingle available for research organizations using large IBM, and now One til' the unmet needs is the several other large computer systems. aggregation of data. The aggregation of data among ob::;ervalions using FROC SAS is used extensively at the Northern SUMMARY is somewhat combersome and does Ohio Data & Information Service (NODIS) not permit retention of unaggregated at Cleveland State University, for example, in processing data from the data fields in the output data set. For example, in aggregations of geographic U.S. Bureau of Census I Bureau of Labor I parcel based county auditol"" s files, census data it is usually necessary to and a variety of other large data files. retain an alphanumeric area name as well as other da.ta with the oummed N:)DIS is a data service both for variable( s). PRoe SUMMARY does not research wi thin The Urban Center in the permi t carrying unaggregated fields to College of Urban Affairs and for data the output file. Furthermore, an users in northern Ohio. NODIS has been addi tional DATA step is requi red in designated by the State of Ohio and the order to subset only aggregated Bureau of the Census as the regional records. Use of the created data center for northern ohfo. Among variable named TYPE, which defines its functions, therefore, NODIS has the the levels of- aggregatio",Sugi-84-28 Tobin Salling.txt
"THF SAS SYSTEM AS AN INFORMATION CENTER TOOL Patrick Timmins, Washington Data Procesing Service Center Three Products to Facilitate the use will solution; concentrate on one of SAS creating aids that eliminate as many of the computer system complexities as The purpose of this paper is to give possible without limiting the function examples of data processing tools or of the SAS user. Because users have aids that facilitate the use of SAS by different needs one aid could not eliminating some of the complexities fulfill everyone's requirements. of the computer system that SAS runs Listed in the appendix are three aids on. The paper will also define three or tools for the SAS user. Each aid types of SAS users and show how these is a full-screen menu that prompts the tools or aids make their use of SAS user for the information he or she easier and in turn reduce the support needs to run a SAS program. Below is a discussion of the different types of these users require from the information center consultant. SAS users, their requirements and which aids would be useful to them. WHAT IS AN INFORMATION CENT~ Three Categories of SAS Users The Information Center is a (Ie) section of an organization designed to I have classified SAS users into three give non-data processing professionals categories: Those who use SAS as a access to data processing products. statistical package, those who use SAS The IC provides training and as an applications language and those consulting services to these non-data who use pre-written applications that processing professionals on selected are written in SAS. In this section I data processing products, such as SAS. describe the SAS tool or tools each To be effective the Ie must save more catagory of SAS user would find organization resources through useful. The three tools, SASPANEL, increased productivity than it spends SUPERSAS and SASBENCH are described in in helping users learn IC products. the appendix The tools or aids mentioned in this",Sugi-84-29 Timmins.txt
"PANEL DISCUSSION - SUGI '84 John Boling, Education Division, SAS Institute I am pleased to announce at this conference a Inc. new course: the SAS Report Writing course. This two-day course explores the power of the base This past year has been an exciting one in the SAS product to generate tables, graphs, Education Division. More than ten thousand spreadsheets, calendars, repetitive forms, and products have been installed in the United listings of the data using the full range of SAS States, and over thirteen thousand products formatting capabilities. This course was designed have been installed worldwide. This equates to for those of you who have completed the SAS countless SAS users like yourself expecting to Basics course or have used SAS software receive quality instruction from the Institute. extensively for si x months. The fi rst public course offering is scheduled for August. Course We continue to receive requests to provide descriptions are available in the Education booth. instruction for new software products, such as SAS/FSP and SAS/OR; for new minicomputers we Creating Maps with SAS/GRAPH Procedures is a new support such as the Digital Equipment, Data video training course. This course discusses how General, and Prime computer machines; for to create and control the appearance of different audiences, such as the experienced SAS SAS/GRAPH maps to better illustrate your user or the user in the information center. We reports and analyses. The video also discusses also get requests to provide this instruction in how to digitize you r own map and how to use the different media forms, such as video, computer- SAS/GRAPH product to display it. Excerpts from based training, and lecture with and without this course can be reviewed in the Education workshops. booth. This past year we taught approximately 30 We are also extremely excited about the SAS courses per month at the Institute, and an Statistical Lecture Series, a series of seminars additional 250 course",Sugi-84-29a Boling Council Nichols.txt
"fying costs associated with training. In a fast -paced tecilIlulogica.l indus try, managers are constantly forced to seek compllter training In addition to educating the training coor- courses for employees and end-users. dinator in cost justification techniques, a Traditionally, employers wonder what training critical element must exist for SAS training, or But with courses their employees should attend. for that matter, any training to be successful. more training mediums emerging, managers are This element is the education of management. faced with a new question, which training mediums Some investment in tTIne should be made in this will best serve the general needs of the company. necessary area. Management needs to under- stand \>.hy one or more SAS training mediums are A true measurement scale for determining the SAS training medium(s) best suited for your needs being acquired. This is mandatory to the ultimate success of the training endeavor, since currently is not available. This paper dis- several misconceptions exist about training in cusses the importance of evaluating and weighing general. Prevalent among many managers is the the alternatives and offers helpful suggestions belief that training that costs the least offers for selecting appropriate training mediums. the most in effectiveness. This could not be farther from the truth, especially since many variables interplay with the objective of eff- INTROruCTIDN There are several ~portant ective training. variab",Sugi-84-30 Lafler Triff.txt
"THE INFORMATION CENTER AT BBl MICROBIOLOGY SYSTEMS Patricia W. Botelle, BBL Microbiology Systems Introduction Why an Information Center? The Information Center (Ie) concept has become One of the universal problems of data pro- the most written about concept of data pro- cessing departments is the programming backlog. Although there is no real way to estimate the cessing in recent years. However, there is programming backlog, al' data processing mana- insufficient data available to address the experiences of an on-going Information Center. gers admit there is one. By allowing users to Although the structure of an Information Center access copies of system data bases, reports are may vary from one installation to another, the generated to meet specific needs quickly with minimal MIS involvement. When the MIS staff basic concepts and procedures are the same. This paper will discuss the Information Center uses the Information Center facilities to help evolution at BBl Microbiology Systems and some design systems, the number of changes during reasons why SAS and its family of products were the implementation phase are minimized. The Ie chosen as the foundation for the Information facilities are used to prototype new on-line Center. applications and the report-generation part of a system is written and maintained by the user. Background The Information Center has reduced the known systems and programming department's backlog BBL Microbiology Systems, a division of Becton from 3.4 years down to 2.0 years and the in- visible backlog from 5.6 years down to 1.0 year Dickinson and Company, has been manufacturing products for the microbiology laboratory for during its two year life. over 45 years. The division consists of three strategic business units (SBUs), each manu- A universal complaint of data processing facturing and marketing its own product lines. departments is the time required to change an These units are located either in the Baltimore application. Since the use",Sugi-84-31 Botelle.txt
"ritten to the INFONET is to aid non-data processing occurs~ menu. An on-line tutorial is available personnel in producing their own ad-hoc to show the user how to fill in the menu stand alon~ systems. The r~ports and properly. To receive the tutorial, the SAS menu allows users to execute SAS user just presses the PF HELP KEY. interactively or submit d batch job without needing to kno~ how to write SAS SELECTION MENU SELECT OPTION ===) ENTER S ON THE SELECT OPTION LINE. 2. PRESS THE ENTER KEY. 1. SWC2WR6 ---------INFORMATION NETWORK --------- TIME - 11:10 SPF PRIMARY OPTION PANEL DATE - 83/07/19 JDATE- 83 .. 200 SELECT OPTION ===> SPF PMMS - SPECIFY TERMINAL AND SPF PARAMETERS 0 BROWSE - DISPLAY SOURCE DATA OR OUTPUT LISTINGS 1 EDIT - CREATE OR CHANGE SOURCE DATA 2 UTILITY - PERFORM SPF UTILITY FUNCTIONS 3 TSD - YOUR OWN MOST OFTEN USED TSO COMMANDS 4 TUTORIAL - DISPLAY INFORMATION ON USING SPF 5 TSO - ENTER TSo COMMAND DR CLIST 6 A ACF CHANGE YOUR PASSWORD OR PROTECT A DATASET R RAMIS/II - RAMIS REPORTING/RECORDS MAINTENANCE SAS BATCH AND INTERACTIVE SAS EXECUTION 5 T TELLAGRAF PLOTTING WITH TELLAGRAF EXIT TERMINATE SPF USING LIST/LOG DEFAULTS X FOR QUESTIONS CALL X 6-5200 PRESS PF3 <END KEY> TO TERMINATE SPFINFO TERMINAL TYPE - 3278 NUMBER OF PF KEYS 24 SAS SELECTION MENU SELECT OPTION ===> OPTION 1 WILL PUT YOU IN THE SAS MENU OPTION 2 WILL PUT YOU IN THE SAS MENU WHICH WILL EXECUTE YOUR SAS PROGRAM~ WHICH WILL ALLOW YOU TO ALLOCATE SAS DATABASES AND FORMAT LIBRARIES. -----",Sugi-84-32 Greenwood.txt
"been developed to generate SAS code 2. To achieve widespread acceptance, the system must oper- ate in an interactive environment. for all procedures in the SASjGRAPII product from data entered in SAS data sets on screens in PROC FSEDIT of the SAS/FSP package. Data entered on screens includes such items 3. SAS is an integrated software system (data base manage- as data set names, variable names, axis colors, labels, etc. The ment, report writing, graphics, etc.). The graphics system system permits for rapid creation of graphics during interactive should take advantage of all integration that is centered SAS sessions, with provisions made for editing and storing around the concept of the SAS data set. both the input SAS data sets and the resultant generated SAS code. Provisions are also made for storing and replaying the 4. SAS operates on an I:ver im;reasing number of operating systcms-TSO, eMS, etc. The system should be transport- graphic images using GOUT data sets and PROC GREPLAY. able from one environment to another with minimal con- The system is particularly useful for decision support applica· version requirements upon arrival in a new environment. tions where users with minimal programming knowledge desire This requirement meant that the system make minimal to use SAS/GRAPH as an exploratory data analysis tool on use of command level languages such as TSO CLIST and previously created SAS data sets. the VMCMS EXEC2 languages. This also excludes the use of ISPF Dialogu",Sugi-84-33 Muller.txt
"New SAS/GRAPH Features Jack Bulkley, SAS Institute Inc. GPLOT INTRODUCTION Three new options are available in the The SAS/GRAPH® product is an evolving GPLOT procedure, The SKIPMISS option causes a product. New features, as suggested by users or plot to be discontinuous when a missing value is developed in-house, are constantly considered found in the data. Refer to the tangent curve and added. This paper describes the new (figure 3) wher'e the undefined values of the SAS/GRAPH features added in the past year. function at 90 and 270 degrees are missing The paper also provides examples showing the values. Many types of data have inherent missing use or effect of most of the new SAS/GRAPH features. All of these new features are available values, such as data from stores or other businesses that have no sales data from Sundays in release 4.06 of the SAS/GRAPH product for Equipment Corporation VAXTM 11/7xx the Digital and holidays. The time axis for such data may include all days to emphasize the difference Series of minicomputers. They will also be between sales (or other variables) on the days available in the next major release of the preceding and following the day with the missing SAS/GRAPH product for all supported machines. value. The other two features, FRAME and There have been changes in most of the CFRAME=, are related to each other, The FRAME option causes the area defined by the axis to be SAS/GRAPH procedures. The changes in GCHART, GPLOT, GMAP, G3GRID, GPROJECT, closed on all four sides (figure 3). The CFRAME= option causes the background of the GSLlDE, GCONTOUR, and G3D will be presented as well as a list of new device drivers. The axis area to be filled with the color specified. changes are grouped by procedure except for The FRAME option can be used to divide a plot the ANNOTATE facility, which is introduced from titles and labels and give a graph a more separately. professional look. The CFRAME= option can introduce more color to a graph and emphasi",Sugi-84-34 Bulkley.txt
"IHA~[S='OlD::C82'D 'OlJAN83'O 'OlFEB83'O 'OlMAR83'J 'OlAPR83'O VIIMIS= -6 TO 6 BY 1 VREF=-2 0 2% Graphs for some technical publications are DATA PeOT; required to be in a certain format. In cases INPUT NSD DAE DATE7.; FORMAT DATE OA1£].; where HAXIS and VAXIS options are specified, IAB""L Nsn='FF'X' CARDS;- , complete control of ticks, axes, and labels for o OlFEB83 graphs can be achieved by using the NOAXES option 1. 3 OSDEC82 -Z.507JAN83 of the PLOT statement, and MOVE and DRAW options 4 20~AR83 of one or more NOTE statements. The SAS-code GOPTIONS OEVI:E=TEK4662 HSIZE=9 VSIZE=6. ~ NOCHARACTERS PROC GPlOT; used to create 1eft and ri ght vert; ca 1 axes, top PLOT NSD~OATE GPLTOPTS; and bottom horizontal axes, ticks inside the TITL: .H~l .A~90 .r~5IMPL[X ' NUMIl[R or STANDARD DEVIATION,' TllL;:2 .H.=1 .f=SIMPLEX .A=90 ' FROM THEORETICAL VALLE'; axes, and custom tick labels is explained. With NOIr .H=.<J .~'=lIMnrX .J=R 'ulH:'ION=I';I.t.; this information, the user then can select from NOTE H=.9 .F=SIMPLEX .J=R H~OS=OEHULT, NOH .H=.9 F'=SIMPLEX .J=R HSPACE=D,FAlILl; all available TITLE and FOOTNOTE options to customize the axes on SAS/GRAPH! plots. $R""'O""~7<I~ HPOSwDEFAULT rrsPACf:~DEFAULT Occasionally. after specifying 'HAXIS='. SAS/GRAPH will displace the r'ightmost tick label to the 1eft as if there was not enough room to center it below the tick. The HPOS option of the GDPTIONS statement and the HSPACE option of the .-:---- - - - - PLOT statement can be used to solve this problem.",Sugi-84-35 Peart.txt
"isticians, Inc. Terri S. Ackerman, Consulting Statisticians. Inc. Abstract using objects whose visual dimensions (i.e., position, length, etc.) correspond to the Oesigning an effective graph involves mathematical scale, and whose levels on each more than just writing clever and sophisti- dimension (i.e ·· the particular position. cated code. Which type of graph is easiest length, etc.) correspond to the values on to read? And which is most accurately per- each scale. For example, the graph shown in ceived? The study of human information pro- Figure 1 represents a pairing of values on a cessing reveals two important limitations - time scale with values on a pressure scale. sensitivity constraints and linearity con- It uses objects (bars) whose horizontal straints. These constraints are not con- pOSitions (a visual dimension) correspond to stant but, instead, vary with the visual values on the time scale and whose heights dimensions used to represent the information (another visual dimension) correspond to in graphs. This fact can be u~ed to con- values on the pressure scale. struct alternative graphics WhlCh employ the most accurately perceived visual dimension~. The key to this graph's effectiveness We will present two such graphs that have is the abiity of the reader to mentally rep- begun to surface in the literature--~l resent objects along a number of visual dim- charts and dot charts with grouping--and ensions simultaneously. As Bertin (1981) show how they can be constru",Sugi-84-36 Simcox Ackerman.txt
"The PLCJf statement in the GPLOT procedure is: PLOT AMOUNT·';DEPTH=ION, where AMOUNT=the ion concentration in Meq/L; DEPTH, in inchesj and A clear appreciation of saline soil profiles ION, a classification variable. Since GPLOT may be made by graphically viewing the anions fills iIi the lines alphabetically from the bot- and cations plotted with depth. Using the PROG tom up, care must be taken in the variable la- GPLOT procedure, with the fill option, a beling. For this reason, the character variable cross-sectional view of the quantity and depth 'ION' was used as the classification variable, distribution of every anion and cation is ob- to describe which anion/cation was being plot- tained. Through viewing the proportion of every ted. The values of ION were assigned prefixes anion and cation wiLh Lhe 50il depth more def- I in alphabetiC order to control the order of inite conclusions can be made on the genesis and filling beneath the curves. For example, cal- properties of salt-affected soils. cium is the first variable to have the area filled beneath its curve. Therefore, the clas-",Sugi-84-37 Held Maianu.txt
"SOLVING THE IBM GRAPHICS PROBLEM BILL MANOS NICOLET COMPUTER GRAPHICS PREPARED FOR SUGI 1984 HOLLYWOOD PARK, FLORIDA I. INTRODUCTION 3. INSTALLATION 4. PRICE A. BIOGRAPHICAL C. NUMBER OF USERS 1. COMPANY 2. PERSONAL D. LOCAL OR REMOTE CONNECTION B. PROBLEM DEFINITION E. QUANTITY OF OUTPUT 1. SYSTEM RESOURCES F. QUALI TV OF OUTP UT 2. HARDWARE INTERFACING 3. FOCUS ON PEN PLOTTERS G. USER FRIENDLINESS H. ANALYST FRIENDLINESS II. REVIEW OF GRAPHIC DEVICES A. FILM V. IBM GRAPHIC SOLUTIONS B. WCRKSTATIONS A. CAOAM C. COLOR TERMINALS B. GRAPHIC DATA DISPLAY MANAGER O. HIGH RESOLUTION HARD COPY C. 3277 GRAPHICS ATTACHMENT E. RASTER OUTPUT D. 3279 COLOR TERMINAL F. BUSINESS GRAPHICS E. HARD COPY G. PEN PLOTTERS 1. 3287 PRINTER 2. XY 750 PLOTTER III. GRAPHICS INTERFACING CONSIDERATIONS F. 32)0 INFORMATION DISPLAY SYSTEM STANDARD A. SOFTWARE 1. CAPABILITIES VI. PEN PLOTTER CONNECTION TO IBM MAINFRAMES 2. DEVICE DRIVERS A. OVERVIEW B. HARDWARE B. ASYNCHRONOUS RS232C 1. NON-IBM COMPUTERS 2. IBM MAINFRAMES C. REMOTE JOB ENTRY 3. IBM PC D. CONTROLLER PROTOCOL CONVERTERS IBM INTERFACING CONSIDERATIONS IV. E. 3277 GRAPHICS ATTACHMENT A. APPLICATION F. 3270 JOSS CONVERTERS B. SYSTEM RESOURCES G. DIRECT CLUSTER CONTROLLER CONNECTION 1. COMMUNICATION H. SUMMARY 2. HARDWARE 214  XI. SUMMARY VII. NICOLET ZETA 887 PLOTTER A. HARDWARE SOLUTIONS A. HISTORY B. SOFTWARE SOLUTIONS B. SYSTEM INTERFACING COAXIAL 1. XII. QUESTIONS AND ANSWERS 2. RS232C c. INSTALLATION VIII. PEN PLOTTER COMMAND FLOW A. GENERAL 1. HIGH LEVEL SOFTWARE PRODUCTS 2. GRAPHICS DEVICE DRIVERS 3. PLOTTING LANGUAGES 4. INTELLIGENT CONTROLLERS B. NICOLET ZETA 887 1. 3270 INTERFACE BOARD 2. CONTROLLER PROCESSOR 3. PLOTTER PROCESSOR IX. GRAPHIC DATA DISPLAY MANAGER A. OVERVIEW 1. INTERACTIVE CHART UTILITY 2. PRESENTATION GRAPHICS FEATURE 3. GRAPHICS DATA FILES B. GRAPHICS CAPABILITIES 1. TERMINALS 2. HARD COPY X. NICOLET ZETA ZOOM A. OVERVIEW 1. GDDM TO ZElA GRAPH IC MACHINE LANGUAGE Z. OPERATING SYSTEMS B. GODM INTERFACIN",Sugi-84-38 Manos.txt
"ath to the graphics subroutine library. It permits you to Since its introduction in 1980, users have sought specify commands to the graphics procedure for ways to create specialized graphic output with interpretation, execution, and eventual display the SAS/GRAPH product. Some have been more successful than others. While creative on the generated plot. manipulation of data can often produce the The commands are contained in a SAS data set. desired picture, a major criticism of the Special variables in the data set pass SAS/GRAPH product has been its inflexibility in information to ANNOTATE for interpretation and dealing with descriptive annotation. This paper execution. A generalized flow of control could will explore new options for customizing standard be visualized as below: SAS/GRAPH output, as well as new SAS/GRAPH applications. INTRODUCTION The ANNOTATE facility permits you to customize SAS/GRAPH procedure output from variables and values contained in non-graphic SAS® data sets. SUBROUTINE The facility is capable of defining polygons, LIBRARY controlling pen movement, placing text on the GRAPHICS PROCEDURE page, and so on. It adds to existing procedures the capability of producing custom graphic output from a DATA step. This paper is intended only as an overview of the facility, some of its capabilities and its limitations. Complete documentation is contained in Technical Report P-12B; Changes and Enhancements in the Base SAS and SAS/GRAPH Products under VMS, Version 4.",Sugi-84-39 Friebel.txt
"y of South Carolina David J'. Cowen. University of South Carolina Pete H. Oppenheimer, University of South Carolina W. Lynn Shirley, University of South Carolina ABSTRACT complex polygon and grid cell data structures (Mitchell et. al. 1977). Since 1973 tbe United States Geologic Survey has been act! ve ly invol ved in mapping and inven- Each of the digital land use files consists torying the land use and land cover of the of a series of coordinate points defining the United States at a scale of 1:250,000. An boundaries of polygons and an internal node for important component of this program has been the each polygon and its land use code. Unlike creation of a digital representation of land political units these naturally occurring areas use/land cover, hydrologic units, census county often result in several layers of embedded poly- divisions and Federal land ownership maps. gons. For example, a farm that is surrounded by a forest would be considered an island within The USGS also developed a series of special- another polygon. The complexity of any of the ized computer programs, known collectively as resultant files varies with the diversity of GIRAS (Geographic Information Retreival and land use in an area, however, most of the files Analysis System), that performs all facets of are extremely large, averaging 3000 polygons and digitizing, editing, inventorying and displaying 165,000 coordinate pairs. the various datasets. Al though GIRAS is a powerful program set, it lacks i",Sugi-84-40 Bullard Cowen Oppenheimer Shirley.txt
"ing the furmat for the data A package, cal1ed LINEGPAF, was written to to be plotted is c~tionally printed. He is all 01>.' the casual SAS user to generate line then put in the system edHor sc data can be graphs using the capabil Hips cf GPLOT from a placed in a file. If he is recalling an old menu-driven interface. Primary options include plot, he is asked for the name of the plot and hard copy of the plot, viveG plot, editing the it is restor~d. data, changing plot parameters using full screen capability, and saving or retrievillg a Next, the primary options menu comes ur. This graph. Up to 8 1ires can be generated per is shown belcw. Default parameters are 5upp-lied so goed grap~. looking plots can be generated inlr1lediately upon entering the package. LINEGRAF actually writes CHOOSE AN OPTION a SAS program to generate the plots and the user has access to this program if desired. VIDEO PLOT OF CUF:RENT GRAPH (i) LI~EGRAF Thus, also can be used to help train (2) PRINTER PLOT OF CURRENT GRAPH users. Copies of the program are available (3) SAVE CUf<nCNT Gr.:APH upon request. (4) CHANGE: CURRENT GRAPH (5) EDIT DATf\ FILE Introduction (6) RECALL A STORED GRAPH (7) SAME ~nAPH FORMAT, DIFFERfNT DATA A menu-drive system to draw line graphs using (8) STOP SAS/GRAFH and SAS/FSP was developed. It is em called LlNEGRAF. The purpose is to: ANSWER (i, '2,3,4,5,6,7 8) :::::::} {I} Allow the occasional computer user to generate high level lille graphs. Options 1 or 2 will immediately gere",Sugi-84-41 Lauer.txt
"ABSTRACT you might be paying for excess lines. Since modifications to the network are based on the GOS information provided by these records, they This paper describes the COMSYM software system must be processed both rapidly and reliably. designed for IBM's Internal Voice Network by the Network Management Systems Development depart- ment. This system is used by telecommunications engineers to design and analyze IBM's internal THE SYSTEM voice network. The system incorporates different languages to The COMSYM software allows Ilsers to gFmerate provide a comprehensive reporting tool for tele- different types of reports such as IMS queries. communication engineers. Thl'! paper will focus traffic summaries. call analyses. exception on the graphics subsystem which is written using reports. and graphic analyses. The graphics SAS and SAS/GRAPH. This system is designed to subsystem permits the user to select fields from be used by non-technical people. Front end pan- the input records for graphics displays. TSO els (screens) were designed to prompt the user CLISTS and the SPF Dialog Manager are used to for parameters which determine the input records display panels. verify input (allowing easy cor- used as well as the plot produced. The large rection of errors). and submit a batch job to amounts of data associated with call detail provide only the reports desired by the user. A records, performance records, and utility data flow diagram of the system is provided in records are easil",Sugi-84-42 Sherman.txt
"An Interactive Graphics Procedure for SAS Software with Application in Computer Performance Evaluation. H.M.Van IBM Woerkom. INTRODUCTION. The presentation of data under control of SASe!) PGF's Interactive Chart Utility is invoked by the software will vary, depending on the purpose of user from Lhe selection menu. In Lhis way a spe- this presentation and the nature of the data cial format can be created for the chart and the shown. If the presentation method chosen is com- chart data can also be edited. The format of a puter generated graphics, then there are 2 capa- chart is referred to as the ADMCFORM file and the bilities that will enhance it. In t\e first data portion as the ADMCDATA [ile. AHer all the place, interactive modification of the graphic charts have been properly formatted, as the user format ensures that the best composition is wishes them to appear, they may be displayed as a arrived at in an efficient manner. One selects composite from the initial menu. I f the format format options with menus, without having to proves unsatisfactory, individual charts can be change the program that controls the graphic changed again, to improve the appearance of the presentation. The final format should be able to composite graph. After the charts are changed be :,;dved :,;u Lhat iL can be used repeatedly with they must be sto::-ed in their respective format different data variables. Secondly, compositE'. and data libraries. It is also possible to save graphics also enhances presentation. This means the composite, for later redisplay. It can be that several charts are able to be shown on one printed or a file can be created for possible use page, either separately from one another, or by a plotter. Individual charts can be printed by superimposed. the functions av:tilable with PGF's In-:eractive chart utility. PROG ICU provides both of these capabilities. Individual charts can be created from SAS vari- By using the options of PRDC IGU, a composite ables through",Sugi-84-43 VanWoerkom.txt
"and encourages their involvement in the This paper describes a SAS-based system for in- analysis. tegrating information about an insuran~e compa- ny's underwriting activities, market demogra- 2. The ability of analysts to shift flexibly phics, agency force. pricing decisions, promo- dlllUflg Vdliuus levels o[ aggregation of tional expenditures and concentration of compe- infurmation, alternalively reviewing the tition. SASGRAPH is used in conjunction with broad scope and ""zooming in"" on details to statistical models and procedures to present answer specific questions. information on computer-generated maps. SAS 3. An evolutionary design in which the system macros allow users to generate labels that iden- can be changed readily as information is tify the locations of facilities and places. processed and managers' curiosity is aroused.",Sugi-84-44 Smith Blodgett Bartic Janson.txt
"ESTIMATING A TRANSFORMATION BETWEEN PROJECTIONS USING LEAST-SQUARES Co~puter Paul W. Fingerman, Boeing Services Co. Marcia A. Tolbert, Boeing Computer Services Co. One of the characteristics that has made SAS such projections maintain areas of polygons or angles at the corners of polygons equal between the a valuable tool in many data processing original representation and the Cartes ian environments is its versatil ity. The breadth of projection, and produce maps of the sort we are coverage of statistical/mathmatical/graphical used to seeing. techniques allows the analyst to solve a wide variety of problems using a single product. Alternatively, a single problem using teChniques Thus, we cou 1d trans 1ate the COE phone 1ocat ions from several areas may be solved entirely within into one Cartesi1ln coordinate system, while SAS SAS. The present paper illustrates a case where PRDC GPROJECT would permit us to project the U.S. a moderately complex problem in mathematics! state boundaries using a different projection statistics had to be solved in order to produce a into a different Cartesian coordinate system. If the projections were not too different from one map which was the original goal of the project. another, it seemed that it might be possible to Recently the U. S. Army Corps of Engineers (COE) find an algorithm to transform coordinates from one Cartesian system to another, i. approached us with the following requirement: e., to They wanted to produce a set of maps showing all compute X and Y coordinates from V and H of the 535 CDE communication node locations. The coordi nates. location of each node was, known only in terms of the telephone number and name of the'site. Could Since the two projection algorithms are not we find a way to translate telephone numbers into alike, the two Cartesian systems wouldn't some form that woul d all ow computer-mappfng necessarily fit together nicely. Thus, an techniques to be employed? approximate transformation would have",Sugi-84-45 Fingerman Tolbert.txt
"Company 1. Abstract 3. Annotating a Hap The U. S. and world mapping capabilities of Figure 3.1 shows a map generated with AUTOMAP SAS/GRAPHTM are used by analysts at Eastman default annotations. The SAS code used to Kodak CDmpany to display sales territory data generate this map is shown in Figu~e 3.1a. and the results of consumer surveys. Howev- As you can see, there is no title, the vari- er, these users of teL do not have sufficien~ able name appears in the legend and each val- ue in the data set has an entry in the SAS background to write the SAS code required to produce these maps. legend. Figure 3.2 has a title. This is added to the map through the use of the SAS TITLE :,;tat.ement.. (See Figure 3.2a.) Figure Thi:,; paper discusses our approaches to enable novice SAS usc~s to: 3.3 has a footnote below the map. Notice that the size of ~he map has been adjusted to accommodate the title and footnote. The Create a response data set, if necessary footnote was added through the use of a FOOT- · using SAS/FSP® NOTE statement. (See Figure 3.3a.) No addi- Subset a response data set Generate maps tional annotation is added in Figure 3.4 but the legend title has been changed from ""POP"" Outpnt thp. maps on a shared IBM3287 to ""Population."" This is caused by the addi- printer in a VMjCMS environment. tion of the LABEL statement. (See Figure 3.4a.) To set up ranges for the legend 2. Irctroduction instead of the default single data values (Figure>. 3.5), the FORMAT procedl1re was used",Sugi-84-46 Baran Peng.txt
"USING 'flit; SAS/GRAPH PRODUCT FOR THE DISPLAY OF ENVIRONMENTAL MATRICES James R. Carter. Geography Department Robert A. Muenchen, Computing Center, University of Tennessee, Knoxville talk about how he graphically portrayed his Today there are 8 great number of matrices using three dimensional surface environmental or geographical data sets that processing programs such as SYMVU. While we consist of matrices of numerical values. Some agree with Eyton that there are advantages in of these are matrices based on values using SAS procedures for statistical analyses aggre 5ated into cells while others are regular and file manipulation, we argue further that arrays :Jf sample points of continuous surfaces. SAS/GRAPH procedures provide alternative The U.S, Geological Survey has produced a methods o~ display of these data matrices, number of matrices of elevations for the U,S. whether they bc in raw form or ~fter and has a program to produce more oyer t:1e classification and manipulation. The three years. The Digital Terrain Models or TOPOCON SAS/GRAPH procedures that we have used to Tapes as they are called are one-degree display such matrices are G3D, GCONTOUR. and matrices of elevation covering the complete u.s. The elevatioIlt; are spaced abuut 200 feet GPLOT. apart giving about 2 million values per ~atrix. Some Problems with GCONTDUR and G3D There are now about 9,000 Digital Elevation Models based on 1: 24,000 topographic quadrangle maps. In these models the ele'lations are The procedures GCONTOUR and G3D are spaced 30 meters apart, which results in about designed to display numeric data such as these 200,000 elevation values per quadrangle map. environmental matrices. But there are some Our Landsat satellites pass over everywhere limits to the direct use of these procedUres. in the world on an 1M day cycle, collecting PROC GCONTOUR can be used to generate a numeric values in a grid of about 80 meter contour plot with lines giving form to the spacing. Great numbers o",Sugi-84-47 Carter Muenchen.txt
"USING THE SAS AND SAS/GRAPH PRODUCTS FOR TRANSPORTATION ANALYSIS Gary F. Plazyk, A. T. Kearney, Inc. the overview these maps provide. The Overview detail reports are usually generated by A. T. Kearney is an international a combination of PROes SUMMARY and PRINT. management consulting firm. Kearney's Logistics Group specializes in transportation and distribution consulting. At Kearney, we frequently pevelopment of Symbols and Arrows deal with client data in a wide variety of forms. We analyze this data to help The symbols and arrows we use are a our clients understand their operations, direct extension of an article in SAS and then improve their effectiveness in Communications: nDrawing Lines and managing them. SAS has proven to be an Symbols on SAS/GRAPH Mapsn, Reference 1. invaluable tool, it allows us to read What we have done differently is: and manipulate data, and perform our analyses quickly. (1) Tailor the symbols we use to our needs, providing meaningful Since much of our work is transportation demographic information to our viewers. oriented, we use SAS/GRAPH to display truck, rail, and air movement data in Have the routine draw (2) map form. The basic data for these arrowheads on the destination end of the analyses comes from files of invoices or lines, and little boxes on the origin bills of lading. Each observation ends of the lines. This allows us to represents a shipment or transportation display ~, not merely connections. move. We use SAS to summarize the movements in a variety of ways, and to Combine the graphic routines (3) present the results geographically. We with data processed by a subsetting IF. have developed routines that allow us to This allows us to select prime areas of draw arrows indicating flows, and interest, such as high-volume flows, and symbols indicating key network elements, ignore smaller, less important flows. such as factories and warehouses, on our maps. Examples of Maps Discussion A ma~ with symbols is shown in Figure 1. I",Sugi-84-48 Plazyk.txt
"THE CONSTRUCTION OF A STANDARDIZED ANALYSIS FILE FROM MULTIPLE INPUTS Zelda B. Cohen, Research Triangle Institute Introduction standardizing data across cities and files. A sample of properties was drawn and a The Research Triangle Institute conducted Property Survey Questionnaire (PSQ) was sent to a two-phase NSF-sponsored study. ""Evaluating the each owner. The information gathered from this Organization of Service Delivery: FIRE"". In survey served as the foundation upon which the Phase I, data were collected from over 1.400 analysis file was built. The PSQ provided data fire service delivery jurisdictions in fifty about each sampled property: characteristics of Slanuard Melrupolitan Statistical Areas (SMSAs) the property, its buildings, fires, fire-related in the United States. In Phase II, five of the casualties, and inspection history (Figure 1). Phase I cities were selected for in-depn case The fire files were identified by calendar studies of fire experience in different types of date and time of incident, Julian date or buildings as well as in different neighbcrhood~l) sequence number. Property files contained Two types of analysis files were created, parcel numbers as IDs. Socioeconomic and the first consisting of a sample of burned and census data were identified by census tract. unburned buildings from approximately 3.000 Links from one file to another were developed to properties in the five cities and the second be able to match and merge data from all of consisting of summary data aggregated by census these files. The existence or absence of a tract in each of three cities. common link betv,'een any two files determined the One analysis considered the effect cf sequence in which the files could be merged differences in building type, business district (Figure 2). VS. residential areas and type of service delivery on the likelihood of fire and on loss File Design estimates. This paper concerns the creation of the file for this analysis. Each record on",Sugi-84-49 Cohen.txt
"Design Concepts for SAS Applications Ross Z. Merlin, Pinkerton Computer Consultants, lnc. smaller databases, each unique by, for Introduction example, YEAR or STATE or PRODUCT. In This paper 1S for SAS programmers some situations a more efficient at all experience levels novice. approach waul d be to use the di reet intermediate and expert. Five general access technique with the POINT= subjects will be discussed: Database option of the SET statement. This Design. Programming Techniques, SAS technique, which is not at all Features, Utility Programs. and difficult to use, is discussed in the Resources for Programmers. Each paper l'Efficient Data Retrieval section includes a discussion of the Dfrect Access Using the Point Option"" concept as well as the relevant by Neil Howard of ORI Inc. and Linda features within the SAS language, Williams Pickle of the National Cancer references to papers by other authors, Institute. This paper appears and references to the SAS User1s elsewhere in these Proceedings. Guide: Basics. When designing a new database or a Database Design new applications system, don't use the A common problem encountered when old methodology of input - processing deSigning a database for historical output; instead, the order of data (i.e. time series) is the choice consideration should be output - input between horizontal and vertical why, processing. To understand orientation. There are two choices: consider the sequence of steps used to choose one orientation. forcing some plan a trip: users to use PROC TRANSPOSE every time 1) Decide where to go -- (output) they access the database; or keep two 2) List the resources available versions of the data, one in each (money. access to airport, railroad, orientation -- this may double storage or car) and any other constraints costs and require twice as much (fear of flying, departure times) processing to update. (input) (verti cal) POP 3) Select the mode of COUNTRY YEAR --.rlJo- ""21J5"" T9mr transportation that be",Sugi-84-50 Merlin.txt
"the Desert Botanical Garden. This paper describes a data base devel- oped for the Phoenix Desert Botanical The academic research computer at Garden's Living Plant Collection usin~ Arizona State University is currently an (SAS R) Statistical Analysis System IUM 3081 Group K running MVS!SP under software. The hierarchical data struc- VM/SP. Access to the system is ture is implemented as a relational data primarily via OBS WYLBUR, using ASCII base. A batch SAS program is used to terminals connected to the mainframe via apply updates to the data base and pro- a TRAN communication network. Most duce rollback and backup copies on tape. terminals are ""hard wired"" into TRAN. To facilitate data entry fnd changes to There are also several dial- in lines the data base, a WYLBUR exec is em- for off-campus access. SAS software is ployed as a front-end to SAS. A data available on the academic IBM in batch dictionary is used to produce data mode. Tnteractive access to SAS via eMS collection forms, drive the WYLBUR data or TSO is not presently available. entry program, and produce SAS state- ments that are used in the SAS update program. The data dictionary provides a convenient means of achieving consis- IMPLEMENTATION tency between the contents of the data base and the programs used in its The accession holdings constitute a maintenance. hierarchical data structure. Data on the entire accession is the first (top) level of the hierarchy. Data on the",Sugi-84-51 Greenberg Lewis.txt
"EFFICIENT DATA RETRIEVAL: DIRECT ACCESS USING THE POINT OPTION NEIL HOWARD. ORI. INC. LINDA WILLIAMS PICKLE, NATIONAL CANCER INSTITUTE INTRODUCTION Diract access has been suggested as the most *** DIRECT ACCESS; afficieni: method of data retrieval when less than *** READ SOME -- WRITE SAME; 10 percent of a SAS data set is to be accessed (Reference 2). Several methods of direct access DATA NEW; DO I = 1. 5 1 D; will be discussed. with particular emphasis on ill structured technique using the option on POIHT~ SET OLD POINT = I; the SET statement to simulate an inverted file OUTPUT; structure, where a data 5et of pointers is END; created at the same time as the primary data STOP; base. V:.riables in the pointer d:l'i;;a sc:d;, identifying the first and last observation numbers for the occurrences of single or multiple Using direct access, the POINT= variable. I. keys, are used to index the pri~ary data base. specifies that the first. fifth. and tenth observations will be read from data set OLD; data Techniques for creat.1ng the pointer data set set HEW will have three observations. Maximum and the SAS code for implementing this system efficiency is achieved in this example because: wi 11 wi 11 b& presented. The method be 1) the D~TA step is executed only once. and 2) illustrated by a user-oriented system designed to only three obser~ations are read from data set extract subsets of extensive SAS data bases of Notice t~at a STOP statement is required OLD. cancer mortality and census information. because use of the POINT option on the SET statement di5~bles the end-of-file indicator for DIRECT ACCESS USING SAS data set OLD. Consequently, some other means of controlling end-of-processing must be used. Within a DATA step. the input data are processed sQquentially by default. Each input There are three ways of assigning values to record or obse~vation is rQad using the INPUT o~ the POINT= v~riable: 1) directly. 2) randomly. SET statement. regardless of the number of or 3)",Sugi-84-52 Howard Pickle.txt
"each of the program supervisors, to provide them with a comprehensive data base management system. A da ta base management system has been developed The use of in-house data processing hardware has to manage analyze and report the environmental al so provided considerable cost savings for each data cOll'ected as' part of the Rio Blanco Oil of these programs. Shale Company (RBOSC) operations on Federal Prototype 011 Shale Lease Tract C-a. Multiple EAOOMS is used as a quality control manager master SAS data sets, comprised of data within each of the program segments to; collected in five major environmental programs, are updated, edited, analyzed,. and reported Prov1de a consistent data structure 1. using the Statistical Analysls System (SAS) for each program segment progranming language. SAS is utilized because 2. Reduce data errors of the flexibility needed to manage large 3. Improve review and response time vol urnes of data and the unique graphics and 4. Provide documented quality control analysis procedures, along with the ability to 5. Provide ""user friendly"" file main- generate customized data summaries and reports. tenance and update procedures",Sugi-84-53 Johnson Randall.txt
"1. Seeing and Pointing Versus Remembering and Typing The primary focus of human factors engineer- -Visibility ing is to design for human use, that is, to be A well designed system displays every- functionally effective. With a greater number thing relevant to a task on the scree.n. of SAS full-screen applications being developed, It does not hide things under ""lock and many designers have neglected to incorporate key"" combinations or force a user to human factors engineering into their designs. remember difficult conventions. This One reaRon for thiR neglect could be that be- would not only burden a user's memory, cause human factors engineering is e_ highly in- but could hinder productivity. An ex- terdisciplinary field, the relevant literature ampl~ illustrating the visibility aspect is scattered. Or there may be a deeper reason, of seeing and pointing would be to dis- typically, a lack of understanding exists in the play the commonly used Programmable design of man-made tools for human use. These Function (PF) keys in a visible area on and numerous other suggestion~ are contributed the screen. This would assist the user to assist in the design of human factors engin~ in understanding which PF keys to press eering in SAS/FSP applications. to perform specific actions, e.g., exit- ing system and scrolling backward/for- ward.",Sugi-84-54 Lafler.txt
"USING A SAS DATABASE Carol Lambros, Warner-Lambert!Parke-Davis Pharmaceutical Research to cut down on the default storage The most compelling ~easun fu~ using a length of eight bytes per variable. permanently-stored SAS database is the relative ease with which one can be The actual loading of raw data into the cceated, lIIaintained, and used by SAS database consisted of reading the programming and nonprogramming data from tape in one step, thus, personnel alike. Using SAS with its immediately converting it- all to SAS data-handling~ statistical, and datasets. Next, a series of merges report-generation features means using brought related types of data together. only one major software package for Special calculations were done during many users, an advantage that is hard this series of merges to provide to surpass in the data-processing additional variables for use during environment. With the addition of data retr ieval. Most notable of these procedures defining the steps from was the calculation of a study day (day data-entry to data retrieval, the from start of study) for every date upplication of fairly straightforward, recorded. This field was then stored user-designated CLISTS, and the along with the other variables in the addition of permanently stored SAS dataset. Some additional editing was format libraries, a nearly total SAS also done during these merges using II system"" can be devised which suits the SAS's ability to track from which needs of multiple, diverse users. dataset an observation comes. This helped to find nonmatches in the To give some historical perspective, rnerg ing prucess. three years ago we created our first SAS ud.tabC:ltie for use in f:Jha.t""lUd.<.:eutical, Responsible documentation is key to clinical research. This initial good system development, and ways were database was built for a relatively sought to let s~s do as much as small study of short duration. Raw possible in this area. Documentation data were keyed from case report f",Sugi-84-55 Lambros.txt
"PROC SUMMARY as the Basis for Efficient Analyses of Large Files Juliana M. Ma, UNC Highway Safety Research Center Carol Leininger, Research Triangle Institute fires can be studied for different types Introduction of cars as defined by Manufacturer, Car Type and Model Year. A strategy for efficient analyses of large files can be based on data The final analysis products are generated by PRoe SUMMARY. When a study tables of counts and appropriate per- involves only a few categorical var- centages. Results can be obtained from iables, then several analyses can be PROC FREQ or PROC TABULATE for standard based on one set of stored summary cross-tabulations. Customized SAS@ counts. The strategy description programs may be required to generate includes planning recommendations to special tables when indicator variables increase the potential usefulness of are used. summary data. Strategy An outline of the strategy its I advantages and disadvantages, follows a Advance planning is the key to brief description of the data files optimum use of summary counts. The used. Some familiarity with PRQC actual process of using PRoe SUMMARY to SUMMARY is assumed. Examples of actual generate counts for later analyses is applications are provided. straightforward. The most important decisions involve the choice of var- Background: File Description iables and the number of categories to The files used to develop the allow for each variable. strategy are the North Carolina Accident As a first step, study the analysis files from 1973 to the present, the major database at the ONe Highway Safety request. Make a list of all the var- Research Center. Each accident year has iables required for tabulations. These about 300,000 r~cords. will be included in the CLASS statement. Since 1973 there have been two different data formats. The list should not include variables The format from 1973 to 1978 includes only used for record selection. For 110 variables; beginning in 1979 there example, Vehicle",Sugi-84-56 Ma Leininger.txt
"to the State Abstract: A system for producing statistical Department's world wide network of WANG tables, designed for use and maintenance by computers at embassies abroad. This would non-programmers, is presented. The system was pennit rapid telecommunications with programmed and i~ple~ented by agricultural agricultural attaches in foreign posts. Data economists to replace parts of a subsystem Systems Division thus focussed its efforts on written in COBOL and an accounting package. It software development for the WANG, including a is currently used to create statistical tables new PS&D subsystem. used in publication of a monthly circular in the Grain and Feed D'ivision of the Foreig"" Another cons1derat1on was the absence of Agricultural Service, USDA, and si~ilar systems documentation on the COBOL report writers, so based on it are used in other divisions as that modification of programs constituted a well. The system makes use both of TSO command major headache. In one example, the Grain and language procedures and of interactive SAS Feed -Division requested that Macau be added to programs to create, modify and submit batch SAS the rice report. The change took two months, programs. Output is routed variously to paper, and resulted in the report being disabled the to disk, and to remote output queue for transfer entire time--it either printed only Macau and no to another computer. The SAS-based system is other countries. or for some reason printed only cheaper, more flexible",Sugi-84-57 Mustard.txt
"STRATIF: A PROCEDURE FOR PRODUCING STRATIFIED VARIABLES M.G. Sri Ram, Div. of Computing Services, The Uhio State University College of Medicine Introduction The stratification is accom~ VAR variables. Consider the common situation where a data plished by creating a new variable for each VAR set contains both continuous numeric variables variable and each level of each CLASS variable. and alphanumeric classification variables. It This new variable is set equal to its VAR is desired to study the former within the 'ancestor' in observations containing that separate levels of each of the latter, in other particular level of the CLASS ancestor. In all words. to stratify the former in terms of the other observations it is assigned the special latter. The usual method of accomplishing this missing value '.A', Clearly, there are v*(ll + 12 + is to sort the data set, call the desired + In) stratified variables, where: procedure with the same BY variable, and repeat this for 'each of the classification variables. v = number of VAR variables. This can be a tedious affair if there are more n number of CLASS variables, than a few classification variables, involving li number of levels of the ith CLASS multiple calls to SORT and the expenditure of variable, 1 = i = n, much programming overhead such as disk input/ output as well as program coding. Names and labels of these variables are PROC STRATIF represents an alternative created by the procedure itself since users approach to the stratification problem. With a should not have to know class level information few lines of code the SAS programmer can before using STRATIF. The label contains the produce d data set in which specified numeric ancestry of the stratified variable, describing variables are stratified according to the from which VAR variable and which level of levels of specified classification variables. which CLASS variable it was created. When Appropriate SAS procedures can then be applied assigning names the proce",Sugi-84-58 Ram.txt
"e size of a SAS data library is, in general, a monotonically increasing func- This paper discusses the storage space - comput- tion of the number and size of the date sets ing time tradeoff inherent in many SAS data sys- that comprise it. tems and presents a method for achieving keyed This means that it takes - - - - as - - at least - much access to dllta sets that eliminates the SAS space to store data in a data library as it does tradeoff . the same data in a single data set. Usually it takes more for tll'O reasons. First, the data management overhend is incurred for each data 1. set in a data library. Second, SAS data sets INTRODUCTIO~ use integral numbers of tracks: if you have only one-half a track of data, i t takes one whole A significant storage space - computing time track to store it. tradeoff is generally accepted when considering alternative designs for many large SAS data sys- Tl:is is what I call ""segmentation."" To sum- terns. In a design, you can minimize the s?ace marize, the most space efficient way to store required to store data by increasing the CPU- data is in a single SAS data set. If you seg- time used to retrieve it; or you can minimize ment the data into a data library, you waste th~ CPU-time to retrieve data by increasing the space. space used to store it. This paper outlines a simple data system ar- chitecture and an associate_d BCCA!"":!,; methorl thRt 2.2 CONSOLIDATION can, for many applications, combine most of the advantages of the storage space",Sugi-84-59 Ramsay.txt
"Once our users have become familiar wi th ROSCOE. they are then introduced While there has been much discussion to SAS. In our SAS training we emphasize about the use of SAS in an interactive a modular concept of SAS program design: environment such as TSO. users of SAS in that is. while all SAS programs consist batch mode have a variety of problems of JeL, data definition. data. data that need to be addressed. At E-Systems analysis. and report writers. we stress we have developed several methods that that these elements be developed and have proven effective in minimizing maintained as separate modules to be these limitations. This paper will re- chained together only when a particular view our experiences with modular pro- job is ready for SUbmission. gram design. ROSCOE RPF. and in-house SAS support. Jce",Sugi-84-60 Riba.txt
"USE OF SfJS AND SfJS/FSP PRODUCTS TO MAKE MSA/QPAC'S SALARY PACKAGE ""ONLINE"" H.D. de RODS. Human Sciences Research Council data ina SAS file underCMS via FSEDIT (SfJS/FSP) The talk will primari ly address the ways in which This includes allowances like basic salary, de- the Human Sciences Research Council (HSRC) used ductions like insurances and statistical data SAS to enhance the MSA's Payroll System. Manage- like name, IO-number, address, number of depend- ment Sciences America (MSA) payroll system is a ants. etc. The data is divided into logical South African developed system and ;s marketed groups of variables on 11 separate screens. there under the name QPAC. From this point on- Coupled to every group of data items is a speci- wards the system will be referred to as the QPAC fic date variable also appearing on the screen. payroll system. This SAS dataset is accessed with PROC FSEDIT of The following aspects will be discussed: the SfJS1FSP program package. With SAS/FSP, physical screens are easily defined and addition- 1. Requirements from our Admin department. al variables can easily be added when necessary. 2. QPAC batch under OSVSI. To trigger the creation of QPAC input cards a 3. Computer env; ronment at the HSRC. change is effected to the relevant data and its 4. The creation of a1 online environment for cpAC. corresponding date variable. If this is not done 5. Communications between VM/CMS and OSVSI. in unison,creation of the card is rejected. The creation of cards is effected by comparing this 1. Requirements from our Admin departmerit month1s dataset with last month's dataset and ex- a. An Online input and data retrieval salary tracting all differences. This is done by ~ SAS package. procedure ca 11 ed EXTRACT. Thi s procedure was b. Ease of use for the end user (non-DP). specifically written by the HSRC for this purpose c, Minimum operation involvement from OP-depart- and can be viewed as the inverse of the SAS up- ment. date statement. d. No involvem",Sugi-84-61 DeRoos.txt
"erat~ng Once each month, accountants in public can be secured. The number of accounts utilities across the nation put pencil to paper required to do this is generally a function of and attempt to prepare workpapers to support the number of utility departments you have to the monthly income tax accrual. This task can track. At SDG&E, for each of four departments, become quite frustrating as earnings estimates, we have the following expense accounts: schedule ""M"" projections, ITC forecasts and numerous other variables change constantly Current tax expense throughout the year. Accountants have tradi- Deferred tax expense balancing tionally tried to solve the problem of docu- accounts menting a complex series of tax calculations by Deferred tax expense - other (current finding the best workpaper format. Certainly a portion) well-organized, logical approach to the problem Deferred tax expense other (non- will do much to make the job easier. Even the current portion) best workpaper format, however, will do little Current year normal i7...ed ITC to recompute the calculations wheo an assump- Amortization of normalized IIC (one tion is modified or review the workpapers for account per year) for previous years math errors. Amortization of various other deferred lax chargel::i and cred~ts At San Diego Gas & Electric (SDG&E), the tax accrual was becoming more and more com- In all, we had over 40 income tax expl':nse plex. Additional regulatory requirements and and balance sheet accounts",Sugi-84-62 Sorenson.txt
"such as a VAR statement. The PLOT state- ment of PROC PLOT is an example of a non- list statement; its syntax allows for This paper presents a technique for im- more than just a list of items.) plementing custom procedure statements in user-written SAS procedures. The steps required to implement a custom procedure Procedure Writing Overview ~ statement are presented with sufficient detail such that potential procedure writers will be able to design and imple- A user-written SAS procedure consists of ment user-friendly procedures with non- two components: the parser module and the trivial supplementary procedure state- procedure module. The parser module js ments. The design and implementation of responsible for parsing the control a custom procedure statement for PROe statements supplied by the user in his M204 is used as an example of the tech- SAS program. The procedure module is the nique presented. workhorse of the PROC. It uses the in- formation gathered by the parser to read the necessary input, perform the re- 1.",Sugi-84-63 Gimarc.txt
"Our first a""t:tempt to interface SAS with AN INTERFACE BETWEEN THE INQUIP~ D~T~ Inquire was to use PROC INQSAS, a SAS BASE AND THE SAS SYSTEM VIA supplemental procedure. The users view APPLICATION GENERATOR of Inqsas is illustrated (Fig. 1). Proc Inqsas is flexible; it offers the user Harry M. Lewin, Citicorp Credit the option of creating multiple obser- Services * vations or multiple variables from Inquire repeating fields. However it Introduction: is unable to determine the nunber of '. repetitions in the Inquire data base, Ti~ly data processing to support New To assure that all repetitions are Drug Applications is of vital concern processec_, we specified to Inc;sas the to american pharmaceutical manufact- same repetition limit specified to urers. Because the federal regulatory Inquire. Unfortunately, the re'.)etitiuu approval process occurs during the life limit on some of the fields had-been ~f the drug's patent, delays in bring- set at 700. 'i1!hen this was specified lng new drugs to market represent sales to Proc Ingsas the CPU time of the run revenue which is irretrievably lost. dramatically increased. A run to con- Pharmaceutical manufacturers often vert a single parent field timed out attempt to meet their clinical data after 30 CPU minutes on an Im~ 3033. processing needs using the SAS**System This performance was felt to be in- and/or lhe Inquire Data Base, but even adequate even for <=l one-time conversion today there is no good interface be- effort. tween these two products. Manual conversion (Fig. 2, bottom) pro- Task Definition and Methods: vides a flexibl~ approach to the inter- face problem. Inquire code creates a '.:.'he classic problem in language trans- raw data file subsequently read by SAS lation (natural or computer) is that code to produce the SAS system files. the langlla~-e e""i emenLs are only approx- imately equivalent (':,_'able 1.). For Thir_: paper describes a SAS program, which example Inquire has a Fields Definition greatly simplif",Sugi-84-64 Lewin.txt
"New SAS Tools For DataBase Management N. D. Prabhekar General Motors Corporation INl'RODUCTION (3) ~ACRO NODUPS is a macro which creates The power and versatili~ of SAS has made a subset of an input BAS data set by taking it an attractive package not onlY for only those observations in which a ~ven purposes of statistical analysis but also set of variables do not have duplicate for various data ma~ment and report values in the input data set. The macro has @8neration functions. In fact we suspect the same keyword parameters as %MACRO DUPS that there is a sizeable community of SAS wi th same meaning and default values. users whose statistical needs do not extend beyond the procedures discussed in SAS (4) PROC PRODUCT is a procedure which User's Guide: BaBies (1982). While SAS creates an output SAS data set by combining offers several general tools for routine eAch observ~tion of one input data set with manipulations with data sets, it would be each observation of a second input data set. convenient to have a set of prc-pack8Gd macros and procedures to carry out various qy The procedure is called statements of database management tasks with fewer and the form: easilY understandable instructions. :n this paper, we describe a few such FROG lRODUCT options; procedures and macros. BY variables; MACROO & PROCEDURJ<l3 The follOWing options may be included in the FROG PRODUCT statement. (1) %MACRO CRDUNQ is a macro which creates an output SAS data set by taking unique The options DATA 1 = SAS data set and combinations of values of specified DATA_2 = SAS dAta set specify the names variables frOiD. an input data set. of the input data sets used by the procedure. If either of these options is The macro uses the follOWing four keyword omitted, PRODUCT uses the last data set parameters: DATA, OUT, BYSP:EX::, SCRTED. created as the corresponding input data set. The value of the DATA should be the name of The option OUT =SAS data set specifies the the input data set. Its default",Sugi-84-65 Prabhakar.txt
"- Database systems~tilizing mini or personal computers as SAS1U program generators are powerful and cost-effectIve data collection and analysis tools. These database systeas aeet the bl Reporting needs of a Researcn and Development environaent. The capabilities of the database systems include Reporting. usually in tabular fora. is needed to data collection. maintenance. analysis. and prInt input data and reproduce existing data. reporting. All systsas can be supported by a nany ti88s a varietY,of reports is produced to general analysis package ghich features subsetting satIsfy the various Inforaational needs of and the coaaon SAS PAOCs. Database operation ditferent pereonnel. eliainates the need for users to knog the SAS language and editing techniques. cJ Analysis TABLE Of CONTENTS Even though reporting displays the inforaation ~ol~ecte~. aany tiae8 the ~eport does not give InSIght Into the system being studied. 1.",Sugi-84-66 Schwartz.txt
"THE SAS SYSTEM AND THE MICROCOMPUTER P. L. Olympia, Ph.D. Darwin Systems, Inc. and Roy F. Weston, Inc. INTRODUCTION described the SAS (--> Micro- At SUGr '83 I communications port. The micro at this point is conn~ctlon, running a communicatiorrs program, e.g., MODEM7, cnmputer a system that bdngs the wit.h it!'; ASc.n capt.ure bllffer open (via the CTRL- power of mainframe computers available to micro users. Essentially, the system allows a user who Y command); all data read by the DEST are simply is not necessarily computer-literate to drive SAS passed to the micro and eventually stored on and SAS/GRAPH on a mainframe as a slave of the disk. The disk data can be edited with a text micro. editor, e.g., WordStar, or passed to, and later edited ...·ith. dBASE II. From there, communicating This paper discusses some of the things that the data to SAS and other mainframe software is we have done during the past year that may be of relatively straightforward. interest to SAS users who also are microcomputer enthusiasts. Among the topics covered are: This approach offers many advantages: o Loading SAS and other mainframe data from Paper is a universal and inexpensive o hardcopy input medium; computer wags have always said that silicon is expensive and iron (hardware) is o Converting a System 2000 data base to dBASE cheap, but nothing beats paper in terms of via SAS cost. It is also the only way to go if one has a collection of word-processors and a Displaying graphs on a variety of devices mlcros with incompatible disk formats or a from a single SAS/GRAPH output variety of software that store data in non- standard ways A brief survey of microcomputer statistical o software o The DEST optical reader breaks new ground in terms of cost/benefit ratio; it is rea- Anllouncement of a remote bulletin bOard o sonably fast. supports up to 8 resident system to encourage the free exchdnge uf type fonts, has a low error rate, and can information among SAS-Micro users. read, unattende",Sugi-84-67 Olympia.txt
"ISPF INTERPLAY WITH THE SAS 1 SYSTEM Vladimir Sviraky, International Business Machines Corporation, PoughkeepRie. New York 12602 After selecting Option 8, the INFORMATION I. INTRODUCTION MENU is displayed, as shown in Figure 3. The Interplay is an extension of ISPF which com- Selection of Option 6 on the INTERPLAY INFOR- municates between SAS and the MVS operating sys- NATION MI!:ND, displays the panel where the user tem. It automatically generates JCL and CLIST can change his personal information at any time. procedures and runs any SAS program in foreground or background by gathering information from the user about T/O files which hiR program needs and Selection of Option 5 displays the directory of all Interplay users. It also provides MVS supplies. It retains and redisplays file statistics detailing the use of the Interplay information from the most recent run of every SAS program. Concurrently, it creates a Master In- by every user. See .figure 4. dex, a list of all permanent SAS Data Libraries and other files created by every SAS program run .----------·· ----.- INTERPLAY PERSONAL INFORMATION PANtL .. .. :::) _ under the Interplay. A SUbR~t of the Master In- COMM~ND .. n ·· *·· ... ~ ·· ~.w ·· w~~* M.~~""~~~._._<._""~.~ ~ ,~*~~ ~~*.~~*.~n**'~ dex, the User Index, which is a list of files * WElCOME t"" tho Tn.~""""hv with th"" SAS Svsh.. ! M ~ This ir,for~ation will~ .. ~ used to build the proper JOB card, created by a particular user, is owned by each M It a1~o is adoed to the d;r .. ~toty of all u.ers of the Interplay. - ·· ········ ···· n ·· ··· ·········· 'wou ~~u ~ ~ ~ ~.u ""~,~.n.o .w.~~"".""~""~. user and can be updated only by him. The dele- EMT~R FOLlOWJ~G INFO~M~nON for your USERIO tion of any file from the User Index simulta- neously removes that file from the Master Index ACCT NMBR ACCT7n BUILDING :::) 707 and System Catalog. The interplay maintains a :::) 2C01 CUBICLE directory containing utilization statistics of all users. F:RST NAME HAD LAST NAME P\lO\l",Sugi-84-68 Svirsky.txt
"S AND IBM MAINFRAMES? couple The dF?r""I)alld the t{"".) c1 e~r.l y Mi t:r-ocomputHr' s C'""!t'""e the pewit;""r cind to easy use intel'""'iH:t:ivH 1980'5. ttli? computeI'""' success st.ot'""y of microcampu""l:er-s appi ication ptl.c:kage':> (.)f r.H.'~n:~ona.l IBM' 5 wi 11 be cumputet"" wi t.h Lhe 1 aTqe data nases and pLwc:has(,2-d by 55(); 000 customer's til i s year f)(ll""ler~ of IB!'l mainframes cnmplxt<..'ltional amJ this is ju!:;t i t s second ye<'H' alone! has qiven t'""ise to thp annollnc:ement of of E'?xistance, Mict'""oc:omputer""s now several pr'oducts which claim to link ttlE? c:.Q/IlbiT1E~ i::\pplic~t.ion very sophlsti.cc.itO'i'ci tt.oJo comput.p.I'""'s. These rH""oduct!;:; pl'""ovide pac:kd.qes, subs·tant.i.al disk storclqe l and kirHis of corulF-.>ctions which in vat""ioLls jJt U~t=,~SDr together pLJwer fL!l d Wh.i.LII t:a~>e tr'cHlsfer' of some unJ.)' suppor-ts yield d tlighly illterdLtiv~ ~rotfu~l. IBt1 mainframes inTIJF'mation from t(:J fili(.:rocompt.ltt'~r-s but not back to t.he But. t.he meljor at'lr act i un Llf maillft-amr=-. mi c,.-ocomput.l:!I""·S 1 i eo'S in the sl..lbstanti a1 hiqh quality application number of A ,,,,It..et'""native, one more f.le->:ibl!:? systems whi('""~h i:\r-e available -- ""lith mot""e which is 1'10-:. to any tied specific dai 1 y. appl i cati ons bei nq announ(:ed i:\pplil.:ation packaqe micr'ocIJlJlputer Ll""-:;es CQmp 1 c.·tr~l y l~Qnf i gUf""""Gd wi t.h hat'""dwarf,! and between SAS as Ule qCl:i:eway tiif'? <OJ t,'picc\l costs sDflv,'<.ly'e micl'""""",Sugi-84-69 Trimble.txt
"FORMAT-1-2-3, A SAS Software to Lotus 1-2-3 Interface Valerie Van Langen, Asilomar Conference Center Dennis Van Langen, Defense Manpower Data Center observation. There is clearly a strong I. Introduction. move towards decentralization and The advent of large capacity distribution of processing onto microcomputer systems. microcomputer systems has brought the long awaited nautomated office n into There are several reasons why a researcher would choose to conduct his reality. The plethora of word-processing systems is now being analysis on a microcomputer rather than on the mainframe. Most organizations matched by an equal surfeit of and individuals on a mainframe aIe statistical and analytical routines. budgeted a certain portion of the Fortunately, from this plenitude of software, only a few programs can be computing resource, and are charged for all activities performed on the truly called state-of-the-art. The multi-function spreadsheet program, computer. In many instances this constrains the amount of ftwhat if"" named simply 1-2-3, from Lotus analysis a researcher will perform. Development Corporation is just such a Computer analysis on a microcomputer system. It provides extensive cannot be as wide ranging as on a large analytical, graphical, and even word mainframe, but at least it is not as processing features. Unfortunately, subject to fiduciary restrictions. 1-2-3 does not interface with Typically, the avenues of research on a mainframes, so that large scale processing and software packages are microcomputer are simply constrained by the imagination and initiative of the not directly useable from within analyst. 1-2-3. The use of SAS software on a Data processing independent of the mainframe can provide the researcher mainframe to perform the myriad of ·number crunching n activities inherent with faster computer response time. Typically, the response time on a in a statistical analysis producing microcomputer is virtually ""refined data"" for later review an",Sugi-84-70 VanLangen.txt
"Microcomputers and SAS Software in a Distributed Human Resource Information System Ervin H. Youn9, Hoffmann Research Associates Introduction same data at two places at the same time. I will go on to delineate those circumstances more Personnel data processing in d common type of precisely. Following that, I will point out industrial organization is typical of the kind that those circumstances, though restricted in of application for which the SAS microcomputer concept, are widespread in practice, throughout connection is ideally suited. This paper ident- the business world. Then I will point out the ifies the type of organization in question, features of the SAS system that makes it feas- ible for a BASfile to be one of the two places notes the features of the SAS data step that facilitate its solution. and describes the prop- where the same data exist simultaneously. erties that the microcomputer software must Finally. I will describe the properties that microcomputer software must have so that a possess to complete the connection. microcomputer may be the other location for the data, and so that the micro can drive the updat- ing of the SASfile without human intervention. The Organizational Model The model of organizational structure that underlies this discussion is the wagon~wheel ~ Applicability of the Wagon-Wheel model, with operating units at the ends of the spokes. and a central office at the hub. For personnel data, the wagon-wheel model is as complex as is likely ever to be required. It Personnel data are generated at the operating is diff~cult to imagine an organization where unit level. The only personnel data that are the interchange of personnel information among generated at headquarters are data on the mem- the operating units is required at such a vol- bers of the headquarters staff. ume, and with such speed, as to justify communi- cation of personnel data directly among them. At the operating units, the data-handler's (This is not necessarily the",Sugi-84-71 Young.txt
"RACT analyses of hospital financial The Group for Revenue Analysis and performance is difficult to obtain Special Projects in the New York City through standard vendor provided Health and Hospitals Corporation has reports. SAS was installed at HHC to used SAS extensively in developing provide analysts the capability to applications for monitoring the Billing generate corporate reports and analyses and Accounts Receivable activity of its using vendor provided transaction data. 16 hospitals and health care institutions. The data for these In the course of developing SAS analyses and reports are taken from applications to meet our reporting transaction tapes generated by a major needs, we encountered many obstacles in data processing service bureau which reading the data. These include multiple serves hospitals throughout the country. record types, variable length and quasi-variable length records, unusual Reading this data was complicated by multiple record types within a file, data storage formats, and print image variable length records, a variety of file formats. Each of these hurdles were different storage formats and reading overcome using powerful data processing data from print image files. features provided by the SAS. The ease of invoking these SAS capabilities was partiqularly appreciated by us since our In the course of this paper we will discuss techniques that were employed to backgrounds are in financial analysis, ove-rcome these obstacles in the hope not programm",Sugi-84-72 Kryzak Riave.txt
"AURORA - AUTOMATED ROSTERING APPLICATION Dick te Winkel, KLM Royal Dutch Airlines Erik Tilanus, KLM Royal Dutch Airlines roster. moving down one line every week. 1. Introduct ion The third phase, covered by the PRONTO system, is to assign the names to this During SUGI 1981 KLM presented the PRONTO roster and to maintain it, Le. to record system: Duty-roster maintenance. It and control all requests for changes, covered the last segment of the complete such as leave requests, holidays, rostering process for shift sickpess, staff changes etc. AURORA fil15 personnel.Much of an airline's staff, the gap between the manpower planning such as overhaul technicians and airport models and PRONTO. It depends largely on ground personnel, work in shifts. An the new SAS/OR facil ities. The creation extra campl ication in creating rosters of the duty rosters is done in three for them is that there is a varying steps: workload during the day, related to the airl ;ne schedule, resulting in a varying Initialization 1. number of people per shift. The first II. Creation of a Days-Off pattern step in the duty roster process ;s therefore to determine the staffing of III. Allocation of shifts. each shift on each day of the week. This is done in Qmanpower planning models"". Input to these models is: W E MT WT F S S (i) the airlines' schedule. E 0 U E H R A U (ii) working standards like: K NEOUITN ""arrival of a DCI0 requires X baggage loaders from Y minutes 1 M2 M1 M1 M1 M1 M2 after arrival until Z minutes E2 FI MI M1 D1 ? after arrivaP and 3 D1 E1 03 03 (iii) the possible shift start and 4 01 D1 01 M1 M1 M2 end times. 5 E1 E1 D1 M2 M2 The output of these models is a staffing 6 D1 DI 01 M2 figure for each shift for every day of M1 Ml M1~~--------- 7 the week (fig.l), the ""covertable"". The set of figures from the covert able covers <£1 as comprehensive as possible the manpower- 117 D1 M2 M1 E3 E2 E1 needs (""profiles"") over the week. 118 D3 E3 E2 E1 D3 119 E1 E1 03 D3 NET NUMBERS OF EMPLOYEES",Sugi-84-73 Winkel Tilanus.txt
"THECIS The Clinical Information System Thomas R. Hoffman. Judith A. Burns, Leon T. Hairie Lederle Labora tori es THECIS minimizes the setup time required for a INTRODUCTION new study in several ways. Variable descrip- tions are automatically provided for variables Traditional information systems have difficulty in the THECIS dictionary. This feature not handling the information associated with new only eliminates entry of information but also drug research and development. The data that are lets the user know that a variable name entered collected in clinical studies vary with drug type, has not been used previously. THECIS also takes study design. and the current regulatory guide- into consideration the row and column structure lines. Statistical analyses and reports are not common to most forms. For example. a case re- standardized but change as methodology ;s imr port form designed to collect 15 rows of labora- proved. Database queries often require a sub- tory test results would require entering only stantial programming effort. the information contained in the first row. The remaining 14 rows of information are auto- Because of these difficulties. most institutions matically added by THECIS. Finally, the SAS use the SAS® software package to supplement other code that is required to set up the database systems. SAS is a powerful tool not only for used for data entry and editing is genrated statistical analyses, but also for data manage- by THECIS. ment, data entry and editing, data storage. report generation. and graphical displays. How- ever, although SAS provides a method for dealing DATA ENTRY with the complex and changing problems associated with clinical studies. it does not provide a Data can be entered either off-line into a card system for processing clinical data. As a resul~ image file or on-line directly into a SAS data- too much time is spent developing programs to base. For data thdt are entered off-line, the handle special problems at the expense",Sugi-84-74 Hoffman Burns Hairie.txt
"spent fuel (PWR, BWR, other power reactors, The Integrated Data Base (IDB) Program prO- special fuels); vides official U.S. Department of Energy (DOE) data on spent fuel and radioactive waste inven- tories, projections, and characteristics. This high-level waste (liquid, sludge, salt information is provided through the cooperative cake, slurry, calcine, capsules, glass); efforts of the IDB Program and DOE lead offices, tranauranic waste (buried, contact-handled, lead sites, major programs, ,and glmerator sites. The program is entering its fifth year, and remotely handled); major accomplishments are summarized in three broad areas: (1) the annual inventory report. low-level waste (buried, other disposal including ORIGEN2 applications and a Quality methods); Assurance (QA) plan; (2) the summary data file and direct user access; and (3) data processing uranium mill tailings. methodology and support to other programs. Plans for future work in these areas are out- For all waste forms, inventories and pro- lined briefly, including increased utilization jections are given in terms of waste volume, of personal computers. Some examples of spent curies, and watts. Where appropriate, other units of measurement are shown such as mass fuel data are given in terms of projected quan- tities for two growth scenarios, burnup and age transuranic (TRU) elements (in TRU waste) and profile of the existing inventory. and the metric tons of uranium (in spent fuel). Radionuclide compositions are given. and approximate specific thermal power relative to high-level waste (HLW) from various sources. radioactive decay accounted for. The locations of storage or disposal sites are shown. Projec- tions of both spent fuel and radioactive waste",Sugi-84-75 Morrison Notz Mastal Trice.txt
"the collection of this vast amount of CpI)MS, an interactive, menu driven computer laboratory data. Until recently, system, was developed to eliminate the clinicians at the CCP only had viewing manual transcriptior of laboratory test access to this data on an IBM terminal resull!> Clnd facilitate the management of connected via modem to NHL's Series I this data. Tools provided by National computer, which accesses the corporate IBM Health Laboratories (a Revlon, Incorporated 3042 data base. Hard copy of the and ~AS have. been sub s id iary) , Cl is t s, laboratory test results was limited to the integrated to create this system. USl.ng a form that the laboratory sends to the sequential file stored on the corporate IBM physician, and this was not received until 3042, a SAS dataset is created and used to the following day. (See Figure 1.) The update the master SAS database. This next steps were to manually transcribe this master database provides up to the minute data onto case report forms and keyboard ~nt~r test results needed to prepare final case the data into RHCG's computerized report form documents. Clinical Data Management System. The data was then telecomunicated to the IBM 3042 and a progranuner would put the data ioto",Sugi-84-76 Preis Lyall Brilla.txt
"itative research frequently generates to know all references to the interviewee's more data than can be ~sed readily. Researchers (subject's) family. Those could occur in using 12,000 pages of text transcribed from ,lOa response to questions about the family, and just interviews cannot humanly master the dota In a about anywhere else. It wou Id therefore be necessary to read every transcript page to find short period of time. A system of numerically encoding key ideas In the text provides a al I of the occurrences, a clearly Impossible task on a regular besis. computer readable; Index for rapid access to areas of Interest in the text. The chall enge, therefore, is to use the computer to help us find particular pieces of Background information in a WEalth of data; The SyrQcuse University Health Studies Program, an interdisciplinary research group in Possible Solutions the Maxwel I School at Syracuse University, has been involved for the past 2 years in a study of One way into the data might be to construct drug use and criminal activity. more detai led questionnair~ than the original, 6 cnd 1hen go through each tronscript ~nswerlng The data in this project is drawn from the qU6stions. This almost imm6di~t6ly 6pp6~rs Yule City study, one of a set of interconnected useless. The resulting data could be anBlyzed research projects on drug use and criminal using trcditional computer st~tistic61 analysis activity funded by the National Institute of packages such as SAS, but it has L",Sugi-84-77 Pardee.txt
"THE SAS SYSTEM CAN REPLACE TRADITIONAL PROGRAMMING LANGUAGES Judith H. Mopsik, ORI, Inc. Output process ing and report i ng 1. INTRODUCTION requirements were common to all of the 40 expenditure sections. Error reports were A 50,000 line production system, developed required whenever conditions fell outside of by ORI, Inc. for the Bureau of Labor Statistics the prescribed rules for data adjustment. (SLS) was entireTy programmed using SAS Intermediate results were reported for all software. The system is modular in concept. methods. This included weighted means and easy to modify and maintain, and most of the weighted counts prior to and after data programs were coded, tested, integrated and put adjustment. Expenditures that could not be into production in less than twelve months. automatica lly imputed/a llocated due to Generalized production-level testing and insufficient valid source data were identified verification programs were also written using for manual adjustment. The manual adjustment SAS software. This system is an important reports had to contain sufficient detail on the component used in the construction of the household's other expenses so that a value Consumer Price Index. This paper will could be hand-calculated. All successfully summarize the requirements of this application adjusted attributes and expenditures were and then demonstrate how the SAS programming written in the format required to update the language can be used to implement production database. systems. The above requirements were given to ORI in ORI deve loped a Data Adjustment System for September, 1981. A sma 11 staff of ana lysts, the Consum@r Exp@nditur@ Int@rvi@w Survey. working part time, embarked on the project. This survey collects data concerning a huge Analysis techniques defined by Tom DeMarcol]) variety of expenditures on a continuing basis were used during the first phase of the and is used to update th@ ""Cost Weights"" project. A SAS-based MACRO driven Data required for",Sugi-84-78 Mopsik.txt
"y of the following interfaces between SAS and the end-user: The Statistical Analysis System (SAS ~) Modules consisting of a sequence of has powerful capabilities fo~ allowing SAS statements designed to perform users to interact with and manipulate widely used information processing data to support decision ma~:ing functions. These modules can be acti vi ties. Such interactions depend selectively combined by users to upon the existence of a set of data create which produce prog~ams files (a database) from which data can relevant information. be selected, combir.ed and proces5ed to produce information (data useful in a A II front-end II processor which speci::ic conte~:t) .'1'l:e structure of that specifies :'r..::C"":""matic;1 pl-ocessing database limits its utility for options for the user's selection and manipulating data and presenting then generat(2;:"" dPpr~lJl.-iaLe SAS cude Such limitations can informa~ion. and executes it increase programming requirementsand restrict a decision makers understanding A facility for transferring of the data. This limits the quality of information generated by SAS to a decisions lildLle. soft....·are package which the user views as less complex or more This paper describes the functions, familiar, design goals and structure of a Decision System (DSS) database. Then, Suppo~t Pre-defined reports which users may wi th this foundatiun laid, specific subset or re-order on-line descriptions and cx~mples are given for use of SAS to create a database",Sugi-84-79 Smith.txt
"TENNESSEE'S FEDERAL/STATE TAX COMPARISON virginia N. Adams, Tennessee Department of Revenue Background, jectcd to yield Lh.r:ee million <.lullo.J:~ a.t o.n t:!~ timated cost of $150,000. This charge includes The Federal/State tax information exchange the in-house costs of CPU time, a SAS program- agreement has existed for many years with most mer's time, an analyst's time, auditors' time states making relatively little use of the data spent handling taxpayer's appointments and ques- until recently. Widespread revenue shortfalls, tions, printing and postage cost. This lea'/es budget cuts, and Federal aid reduction coupled the only out-of-house cost being the purchase of with the unpopularity uf el telX inr.;.L-ed.se helve in- data from the IRS. spired and popularized many tax saving programs. This paper describes or.e of Tennessee's tax re- In ad<.liLion Lu LhE: <.lollelL n:~Lu.rll, eluuiL. porting comparison programs. It is a low-cost, coverage has increased. rhc audit budsct allows high-yield program designed to quickly and effi- a 13% audit coverage dLring each three-year ciently locate misplaced tax dollars. audit cycle, whereas ur.der the comparison pro- gram, taxpayers who would not ordinarily be con- All processing (except reading the 1MS da- tacted by sales tax field auditors will receive tabase since SAS/IMS was not available at my ""audit"" attention. This should improve volun- site) wa::; accomplisht;!u will.!. SAS. SAS was r.;hosen ta~y compliance in the long run. because it was the fastcot and moot economical method available for project workers. The pro- When possible auditor ~rainees were assign- grammer pool was not utilized because their time ed to answer taxpayers' inquiries on the let- had already been allocated to other projects. te~s . This proved to he an exce 1 lent. tra i ning tool since new personnel we~e exposed to simple A state and Federal gross sales comparison audit situations, one-an-one taxpayer contact, was initially developec in Tenn",Sugi-84-80 Adams.txt
"pproach, up:3.ating SAS dum The data will then be entereu ana a corrp.1ter data files has always been a tedious process. It is base created.. Based. on the corrputerized data not uncommon for the updating procedure to becone base, a computerized data listing will be gene- a source of erDOr. In developing a system for rated for review by the medical staff comparing updatiIlg SAS udta files, we have set the follow- to the rnFs _ This computer generated listing ing criteria: (I) the task can be accorrplishcd often identifies inconsistencies, outliers, etc. by data entry clerks with efficiency and accuracy, A fomal updating 'tJill he performed on the com- (2) the files to be upjated can be reviewed and puterized data base after this review. At this ve1:'ified before they are actually rrodified; (3) point, the data is turned over to the biostatis- the rrodifications to the data flIes are cOllpletely ticians for review and analysis. and concisely documented. Schematically: Introduction 1. Harvesting of CRF from the Investigational A crucial step in the precessing of clinical data Site is updating (which includes making corrections to 2. Editing, Coding isolated items in data). This process can often 3. Entry Into comp.1ter (incl'.1ding verification) prove to be tedious and a possible source of error. 4. Review of the Computerized Data bctDe by One of the ccrnnnn fpahlrp:s in the updating pro- ~edical Staff cess is that once a piece of datum is replaced by 5. Update the corrected va",Sugi-84-81 Mailloux Yu.txt
"The Role of the SAS' System In the Information Age David R. Dolkart, American Hospital Assoc""ation SAS is a ccmputer software system for dota analysis. Since its Introduction beginnings in 1966, the goal of SAS has been ·0 provide data The ""nformotion age offers more tkm ""productivity gains"" from analysts one system to meet all their· computing needs. VI/hen advances in computer technology. The information age is the your compLting needs are met, you are Tree to concentrate on exploitation of hardware and software technology in e way hat results rether than on the mechanics of getting them. 6 challenges one to expane his or her analytic capabilities. The pace that one expands trese analytic capabilities accelerates Microcomputers are vital components in the balanced automation tirrie-coll~urninSJ tusb. Wilh easy-Io·learn and of rt'fJtJlilive unJ wilh euch uU'Iur·ce in hurdwme ulld sofiwme. Another· muior advance occurred witr the October 1983 announcement of the easy to use softv.tare, microcompubrs also help a growing IRM P8rsonnl C:nmputpr XT/:;70 2 With thR RxrRrtion nf perfor- nlJmber. of people meet expanding information needs. Without rricroccmputers, some people would still be locked out of the mance ""Tlodifications, the SAS svstem should run on this XTi370 work station in a stane-alone fashion. By exploiting he techno- informa:ior age. Some people would have little C1ance of even Icgical revolution of the IBM Personal Computer XT/378, the SAS e1tering the information age. system will continue to playa maior role in the information age. Where does the SAS system fit in the race toward smaller, more powertul, and cheaper microcomputers? Will SAS Institute Inc. IBM's October Revolution slrecmline its prcducts for the IBM PC XT/370? Will :hey develop A revolution occurred in October 19133. mM announced the links between its products ard microcomputer spreadsheet packages and data base management systems (DBMSsf? One Persoral Computer XTJ370: a desktop work sta",Sugi-84-82 Dolkart.txt
"APPLYING A MARKOV PROCESS TO ORGANIZATIONAL DYNAMICS Mark Edmondson, International Business Machines Corporation INTRODUCTION 5. Balancing forecast skills with respect. to planned work.-load demand by developing A Markoy process model has been applied to retraining and recruiting strategies. forecast the distribution of skills for an The theory that forms the basis for these employee population. Its objective is to forecast skill imbalances to help managemen: tec,niques is well established ane documented in t1e literature of human resource planning (see formulate retraining and recruiting strategies. Bibliography, in particular, Price, Martel, and Lewis for an overview of previous work). This The model accesses an organizationls employee discussion emphasizes the comprehensive use of data files that contain current d1d historical these techniques to develop a human resource information concerning employee position and planning process for a dynamic, full-employment skill. From this data, IItransition matrices"" are envir:lnme'lt. constructed that contain the following information: METHODOLOGY Conditional transition probabilities The techniqJe used :0 forecast skill representing flows between skills d:.Jring one distributio'lS is to model organization dynamics time period as a Mark~v process. As Figure 1 ill~strates, three factors influence the current skill The skill distribution of the p~pulation distribution over time: The attrition rate for each skill. which reduces the number of Attr;ti~n, observations fo~ each skill ln a dynamic organization, future transition rates can be expected to differ from historical lnternal skill transitions, which represent rates. Therefore, in order to anticipate changes employees w~ose primary skill has changed in trarsition rates, the theory of the internal labor market is used to modify the historical Recruitllent, which is large~y controlled by transition rates. By using these modified management to alter the sk.i-,l distributio",Sugi-84-83 Edmondson.txt
"THE USE OF SAS SOFTWARE IN NEW PRODUCT INTRODUCTIONS Joyce D. Geier, Corning Glass Works NEW PRODUCT INTRODUCTION: SOME from limited experimental data. Predictive PROBLEMS relationships (or, hypotheses concerning the effect of product characteristics on product Several conflicting goals arise when a new performance) can be efficiently developed. product is moving into a highly competitive Attention can be focused on only the key and rapidly evolving marketplace. The product characteristics. Limited additional product must be introduced quickly, but it testing can then prove or disprove these must work and the testing r'equired to relationships, and verify the criticality of ensure functionality is often time consuming. the key characteristics. Total introduction Manufacturing throughput must be at the lime is substantially reduced since large highest level possible to supply the market, amounts of initial testing may be delayed or and yet the risk to the customer must be eliminated. Product knowledge and function- minimized. Lack of product knowledge often ality are not sacrificed. Additionally I this results in non-optimal I1trade offll decisions method enables the assurance of not easily- in these areas. These conflicts are further measured, but spedffed, parameters by aggravated if it is necessary to specify relating them to other easily measured charac- functional parameters that cannot be measured teristics. directly in production. The flexibility allows the relationships devel- It is generally accepted that computer based oped and verified above to be fully utilized simulation work or engineering imagination via simulations. By varying product charac- can alleviate these conflicts. When combining teristics and then predicting the resulting them (the best of both worlds), another functionality in such a simulation, field problem arises: the required programming in performance can be quantified. By relating the traditional languages is complex, technical the c",Sugi-84-84 Geier.txt
"A General Approach to Decision Support Systems Utilizing the SAS@ System William Ingram, III and Thomas Rothrock. Info Tech 1.0 DECISION SUPPORT SYSTEMS--AN Shn't Tez'/ri Success OVERVIEW In an effort to place more computing power directly in the user's hands, many organizations Traditionally. business organizations have employed their computers in the area of opera- have implemented Information Centers and Decision Support Groups that are separate from tions support--for recordkeeping, transaction their application development center~. These processing. and generating periodic routine re- groups work directly with users and aid the user ports. Today's managers and professional!:;, however. are demanding hands-on ac:::ess to data in developing their own computer applications. The use of microcomputers for end-user computing and computerized systems that provide solutions is another alternative. This strategy is often to a variety of ""ad hoc"" problems, many of which implemented in conjunction with an Information have never before been a part of the data pro- cessing (DP) mainstream. Center or Decision Support Group. Initially. these approaches often meet with The Problems a high level of success. The keys to this success lie in their use of: As a result of these heavy demands, several well-known problems have surfaced: Nonprocedural application languages Computer languages that require the user Application Backlog DP departments to tell what is to be done but not how have become severely backlogged with re- to do i t . - - quests for information and application development. This includes the Interactive computing - When analyzing invisible backlog of requests that and interacting with the data in an decision-makers do nut even consider information analysiS mode, the user making due to the growing documented needs quick response from the computer backlog. to maximize the creation effort. Complexity - Ad hoc requests often call GraphiC presentation - The presentation",Sugi-84-85 Ingram Rothrock.txt
"ACBPS: A Budget Planning & Reporting System Usmg SAS/FSP Jesse Gary, ORI, Inc. Donald P. Gleason, American Cyanamid Company o Handle complexity of Cyanamid Inter- The Cyanamid International Group of Ameri- can Cyanamid Company in collaboration with ORI, national currencies and detailed input data Inc. designed, developed and implemented an interactive, generalizable, and menu-driven software system for the maintenance of finan- o Interface with other Cyanamid systems, cial data and the generation of profit & loss both input and output reports. This system is called the Budget/ Planning System (BPS). o Conform to Cyanamid accounting code structure and also provide degree of BPS replaces an ad hoc system of IBM PCs, security and integrity ca 1cu 1ators and 13-co 1urnn account i ng pads with a common system for collecting and analyzing o Flexibility - can be modified to reflect financial data for each of the various organiza- changing management patterns and future tional groups within Cyanamid International. enhancements or organizational changes BPS Currently captures financial data from approximately 50 foreign subsidiaries (in their o Maintainability - must be maintained and local currencies) plus numerous home office serviced by small staff, most without adjustments and additions. After consolidating training in traditional DP languages the financial data, the system outputs reports ~Iust in both loea 1 and U.S. currencies at various o be operational in six months at a development moderate cost levels of detail, e.g. product groups, subsidi- aries, selling markets (referred to as ""profit centers""), and division or department summaries. In the remainder of this paper, the design and implementation of BPS is described. Special Most frequently, the above type of applica- attention will be given to how the three basic tion has typically been a candidate for a Data system components - SAS, CLISTS, and SPF, were Base Management System (DBMS). BPS, as illus- blended in",Sugi-84-86 Gary Gleason.txt
"Methods SAS code, in general, has many structured SAS code is fairly structured with a specific features. This is f'specially true of SAS number of options and alternatives being procedures which have a known number of needed for various operations. This is options, procedural information statements, particularly true for the procedure steps etc. Likewise, certain operations in the 'iI'hich require a certain amount of information data step such as data set definitions and have a limited number ot options. Many and queries can also be structured. These operations in the data sLep can al::;u be structures lend themselves to reduced to several common denominators. fill-in-the-blank menus foe the naive user Historically, menus and SAS applications which, when peocessed, pass the user's input to E SAS code generatoe. were married via SPF panels, see Prague (SUGI, 1982, 1983) or Hardison et a1 (SUGI, Heretofore, these menus were developed using 1983) for examples. Construction of menus the SPF Dialog Manager and CLIST::; (or in this manner required a knowledge of EXECs) with the eode being generated o~tside Dialog Manager and CLISTs in addition to SAS. We have found that the SAS full scree~ SAS. Thus. the typical SAS user was unable editor available via PROe FSEDIT in SAS/FSP to readily build a menu-driven system. With provides the same functionality as the the",Sugi-84-87 Hardison Muller.txt
"A GENERALIZED INTERACTIVE FULL SCREEN EDIT UPDATE SYSTEM USING SAS SOFTWARE Donald J. Henderson, ORI, Inc., Connie G. Welch, ORI, Inc., Jesse Gary, ORI, Inc. 1. INTRODUCTION For purpose of illustration, we assume that we are editing a permanent SAS data set The editing and updating of data is a very SAMPLE. BUDGET. This data set contains three common application. SAS has a variety of tools variables: DEPT, REVENUE and EXPENSES. Our that facilitate this function. These tools core program is: include: PROC FSEDIT DATA·SAMPLE.BUDGET; the UPDATE statement the MERGE statement 2.1 Selected Updates and Transaction Types PROC EDITOR PROC FSEDIT When updating is done on a master data set, it is generally in the form of the replacement Edit/Update applications run the range from of field values. PROC FSEDIT accommodates this manual correction of card-image data followed by type of update, but other types may be desired the creation (or recreation) of SAS data sets by the user. For example, the user may want to through sophisticated full screen applications multiply the existing value by some factor or which update an existing SAS data set. increment it by a specific amount. In addition, if PROC FSEDIT is used in isolation for The use of the above mentioned tooTs in updating, all fields in the permanent data set isolation does not satisfy what we will present will be rewritten; it is preferable to update as a set of minimum requirements for an update only the fields to be changed. Therefore, there system. In particular, the UPDATE statement and is a need for the means to create a traditional the MERGE statement require user coding of the transaction data set in the interactive appropriate data steps to perform the update. application. Furthermore, the data base is not protected from unauthorized access or even destruction if the In the example that follows, a pre-FSEDIT user must code or even just run his/her own DATA step is used to create a local copy of the update program",Sugi-84-88 Henderson Welch Gary.txt
"SAVING TIME WITH THE SAS DISPLAY MANAGER Phil Busby, SAS Institute Inc. Here is the initial screen you see when the The SAS® display manager is a full-screen control program that greatly enhances the display manager takes control. It is really two productivity of the SAS programmer. It is now logically distinct displays: the program editor window, below, is where SAS source statements part of the SAS System for minicomputers, are entered, and the log window, above, is ,'unning in full-screen mode. This paper where the SAS log lines are displayed, showing describes the display manager and shows how the results of your executed SAS source you can use it to create and run SAS programs statements. quickly and effectively. To see exactly how each window works, enter a First, ~ discussion of the basic functions of the trivial example. Key in the following: display manager and ""instructions for controlling the program, log, output, and help windows DATA A; when running a simple SAS program are presented. Then the powerful editing commands X=l; are described, followed by a description of each RU~; screen command that you can enter on the command line. The final part of this paper and enter' the SUBMIT command. The source illustrates how the program function keys can be statements appear on the log window, followed by used for the fast entry of commands. the note, which tells vou that your data set was created successfully. Begin the SAS session by entering the following command: Notice that the program editor lines are blank, ready for new source input. SAS/FSD=TEK410S Here, separate the command keyword SAS from the options you want set at initialization time with a slash, and in this case, the only option needed is the full-screen device option. This specification says two things to the SAS System: first, you want full-screen mode, and second, your full-screen device is a Tektronix 4105 terminal. By specifying what kind of terminal you are using, the SAS System can choos",Sugi-84-89 Busby.txt
"set construction or report The focus of this paper is interactive SAS writing only has to be written once by an Specifically, a technique is experienced programmer. Others can use the programming. presented for developing programs which enables same code through the interactive program. users, unfamiliar with SAS syntax, to create and There no need for individuals to ~s duplicate efforts. execute SAS programs. The steps involved in (3) DASD SPACE CONSERVATION interactive SAS programming are summarized, and Both data and l:XamplAs arA presented which employ an IBM source code reside on one disk which can be software product, EXEC2, as the pre-processor. accessed in read mode by all users. There is no need to redundantly store data and This presentation should provide a useful code on individual A-disks. comparison for SAS program generator programs (discussed in Chapter 12 of the SAS Applications The concept of interactive SAS program building Guide), and an alternative strategy in some is rather Simplistic and straight forward. F.ssentially, interactive progranuning may be cases. viewed as an extension of SAS. Just as SAS has provided the code for numerous procedures to save Background programming time and ensure accuracy, interactive Deregulation has had a profound effect on the SAS programs provide additional code to read data and banking industry. New challenges into SAS data sets and/or invoke SAS procedures. unprecedented opportuni ties have emerged as In other words, f",Sugi-84-90 Brichta.txt
"PROC FSCALC IN THE ESTIMATING ENVIRONMENT R. T. Grant. General Dynamics Fort Worth Division B. J. Collins. General Dynamics Fort Worth Division lZlng in a specific area of business (F-16, Introduction Electronic Programs, New Business, etc.) My group. Computer Support. specializes in the The Estimating Department exists to perform the function of integrating large amounts of sophisticated pricing routines used for large proposals and provides consultation for the rest diverse information into a coherent product, the of the department in the use of the computer. proposal. Due to customer desires and the amount of the data involved, estimators have One aspect of our work involves the inte- become increasingly tied to the use of computer- gration of new technology into the department. priced proposals and the structure they impose SASe has been used for a few years and. until on a task that used to allow some creativity. recently. was seen only as a successful number We are now experiencing a change in the crunching report writer. Over the past few months. however, we have begun to build a total amount of dependency estimators have on compu- reporting and analysis system around SAS~ . ter support personnel. Increased computer literacy, encouraged by the computer support More on this development later. section, is creating a new class of estimators who realize that the computpr is here to stay Early Uses of SAS® and, with languages like SAS®~ it is not that hard to use. A new dimension of creativity has Early in the pricing process. we receive returned to their jobs and with it a new enthu- input from various functional groups. SAS® siasm to take charge of the basic analysis need- certification of input streams helps flag ed for executive review and negotiation backup. erroneous data for correction before submittal into the costly pricing routines. To a large degree, the success of SAS$ and SAS/FSPTr'has made this possible. The pricing routines we use have a limited r",Sugi-84-91 Grant Collins.txt
"ABSTRACT If the print output has been directed to an ex- ternal file, then the FSLIST procedure can be Currently the SASjFSP FSEDIT procedure allows used to browse the dataset. In fact, in this the user to edit only one observation per screen. example, FSLIST has two advantages Dver FSBROWSE: For some applications it is more convenient to 1) all data for one patient appear together edit and/or browse a data set when all observa- 2) the FIND command can be used to locate tions in a BY group appear together on one character data in the RX and RXIND fields. screen. This can be accomplished by first writing code to create a horizontal data set However, to edit the dataset requires the that contains one observation for each BY group FSEDIT procedure. In this case the default and next rebuilding the FSEDIT screen data set. edit screen appears as follows: This latter step requires the user to format the screen and inform FSEDIT of the location of each PT· 3001 variable on the screen by moving the cursor to DAY: 168 the proper location and pressing the 'ENTER' key. For data sets with a large number of variables. RX PREDNISONE this procedure can be quite time consuming. OUR: 4 RXIND: ARTHRITIS This paper describes an alternative procedure. A program has been written that 1) builds the code to horizontalize the data set. 2) creates Only one observation is shown per screen. the new screen dataset, and 3) builds the code This structure is acceptable for locating and to restore the datase",Sugi-84-92 Burns Hoffman Hairie.txt
"Interactive Psychological Testing Using the SAS System: A SAS Program to Administer and Score the MMPI Robert M. Hamer and Joseph M. Antonello~ Virqinia Commonwealth Universitv <.X:lI!'uter-scored for years. 'IW rorporations, The HISIDRY Psychological Corporation, and Roche MMPI compu- terized reporting service ~rfonn IIDst of this The MMPI was first p.!blished in 1943 am is remote computerized sooring, although a numter of today the nest widely usoo. objectiVe personality smaller services cperate as ~ll. Once the MMPI inventory. When pecple think of a l'psychological has been computer-scored it still requires a test,"" the MMPI aoo perhC\=>s the ""Ink Blot"" test trained and experienced p6¥chologist to interpret HOSt often corre to mirrl (Hathaway and McKinley, the results of a patient's entire profile as the 1967; Dahlstrom, Welsh, and Dahlstrom, 1972; relationships arrong the scales is at least as Dahlstrcm and Dahlstrom, 1980; Green, 1972; Hathaway am Meehl, 1951). 'llle MMPI consists of inp::>rtant as the scores on arr:f particular scale. These services cost noney, arrl it takes time for 566 statements to which a patient is to respond the MMPI answer sheet to travel through the mail with a ""true"" or ""false"" with respect to Yklether am for the results b::> return. the particular statement applies bO him or her. I t is possible to score the MMPI t¥ hard, The statements caver a range fram physical using terrplates v.hich can I:::e purdtased from the symptoms to psychiatric and psychological publisher, or using information available in syrrptoms, as well as a ronsiderable rurrber of published books (Dahlstrom and Dahlstrom, 1980; questions with no obvious connection to either Green, 1980). pQysical or mental problems. Wi th the oovent of mi croromputers, many The construction of the MMPI was completely psychological tests are now being administered am empirical. Hathaway Md<innley collected, am scored 1:>; computer. sane psychologists am selected, inspected, am wrot",Sugi-84-93 Hamer Antonello.txt
"l PRECHECKING SAS SYNTAX WITH A MICROCOMPUTER Jeff Bass 2 BASS Institute. Inc. INTRODUCTION. VARIABLE NAMES. Microcomputers are increasingly being used as Variable names must be checked for correct terminals and workstations connected to large spelling and length. This is especially diffi- mainframt! computerc. Tht! microcomputer, running cult in SAS programs because variables can be an appropriate program, can act as a full screen referred to in some statements by the minimum editor or a very smart terminal with local number of letters necessary to make the reference storage. Mainframe computers can prepare and unique. For example. AGE can refer to AGEYRS edit programs offline, saving connect charges after AGEYRS has been defined. Also, variables and moving their mainframe usage to off peak can he referred to indirectly in lists of vari- times. After uploaded programs are run, the ables (e.g., ABel-ABC3 also refers to variable printouts can be downloaded and incorporated ABC2). Both of these cases make syntax checking into reports using the microcomputer's word- more difficult than in a more typical language. processing abilities. We discourage the use of variable abbreviations, Thc usefulness of microcomputers could be so we dealt with the variabl~ name abbreviation further enhanced if the programs to be uploaded icsu~ by flagging such uses as initialization to the mainframe could be checked for syntax errors. For the second case, the syntax checker errors on the microcomputer. This could reduce internally expands the variable lists and checks or eliminate the syntax checking runs made on the the spelling and initialization of each list mainframe and increase programmer productivity. member. We have implemented a SAS syntax ~rechecker that runs on an 1BM3 Personal Computer using Pascal. PROC SYNTAX. This paper discusses the issues involved in Each SAS Proc has its own rules for what key- developing such a program as well as some of the words may be used in the p",Sugi-84-94 Bass.txt
"A HUMAN RESOURCE INFORMATION SYSTEM USING SAS·l SOFTWARE Alan A. Parrow, Ph.D. Introduction report generation. Each subsystem is capable of stand-alone operation or alternatively of being Computerization of the personnel function in tied into a single menu-driven system which does all interfacing in ""'- manner transparent to the medium to large sized corporations has lagsed user. behind the computerization of other management functions. To a great extent, this can be at- APS supports three different levels of users: coders (data entry or clerical staff); operators tributed to two major characteristics of most (personnel representatives and human resource human resource information systems (HRIS-e) on managers); and the system master (human resource the market today. These existing systems tend data systems administrator). Each type of user to be extremely expensive Rnd very rigid. That has a different level of system access and hence is, they allow little room for customization to different capabilities. The APS front-end pro- current needs and even less room for adaptation cessor restricts the menu options available to to future changes associated with fluctuations coders and operators. though the system manager in busirress climate. has complete access. These menu options control Because .. the personnel function requires that user capabilities including proviSion of read a variegated set of tasks he performed on a only ss opposed to write access. and what types large and heterogeneous collection of data ele- of information can be displayed at the virtual ments, costs for in-house development often are console. An example primary option menu for a as prohibitive as the costs of existing commer- master level user is shown in Figure 2. cially developed systems. Furthermore, even if Security is a prominent feature of APS. To the initial cost of a human resource information invoke APS, the user must supply a password, system can be justified, questions of flexibili-",Sugi-84-95 Parrow.txt
"enter, The University of North Carolina at Chapel Hill Abstract The system stores citation files as SAS data See Chhinnan and Moon, 1981; Gleason, 1983; sets which researchers can access through a Graham and Doubek, 1982. While in some ways menu-driven, interactive system under MVS TSO. these systems are all similar~ the system Citations can be retrieved by searching on described in this paper has certain unique features, both in design and in capabilities, authors, titles, subject key words, journal which are noted below. names, or ID numbers. Citations retrieved for bibliographies are written to disk as SCRIPT source files and can be downloaded from the The user can access his or her citation file through an easy-to-use, menu-driven, interactive mainframe to a word processor in a form ready to submit to a publisher. system. Optional help is provided at various points. There are no spectal commands to learn to do searches on the file or to generate bibliographies for papers. Background The system was designed for use by the The search capability is achieved by an researchers at the Carolina Population Center of algorithm which uses the concept of ""refining a The University of North Carolina at Chapel Hill. search."" To refine a search means to do the next Many papers and proposals, often including long search on the records retrieved in the last bibliographies, are written at the Center each search. This algorithm is implemented with the year. The requirements for the system",Sugi-84-96 Stone.txt
"PUI!PCSR , AN INTERACTIVE IlATA MAIIAGEMENT SYSTEM F(Jl CUSTDIER SERVICE R1!lIUESTS OF INruSICli PUMPS Peter Chen, Cutter Labozatories * The system must be designed. in such a INTRCDUCTI (]I , way that the l::asic structure can be used for PUMPCSR is an on-line, menu-driven. data other systems. management system monitoring and reporting ~or of Customer Service Requests and Repair Records IMPLEMENTING PUMPCSR It is customer-designed to for infusion pumps. I take advantage of the full screen facilities FILES , Two SAS data files are maintained on provided by SAS/FSP and IBM's IFPS/m.&.log Mana- the system; gement Services. 1. CSR FILE - Customer Service Requests, which includes date, serial number, customer, service center, kinds of RACKGRCUND , complaint, etc. All customer service requests and repair 2. ERSS FILE-.Equipment Repair/Service Summary which includes date of retair. records of infusion :pumps at Cutter were handled manually. With more than 200 requests per month complaInt code, finding code, action it 1s very difficult to have meaningful statis- code. part numbers and quantity. tical summaries and timely reports to manage- ment. The manager of Product Customer Services ISPF/DIALCG MANAGEMENT SERVICES : Panel service is used to generate the was often asked the following questions t main and other auxil1ary menus. 1. For certain serial number, how many User failures had occured ? can select options. starting and ending dates on the main menu and their input is 2. What Is the trend for a specific com- checked for errors. After an option is plaint code '? Obviously, a computer system is needed to selected, the system invokes dtalog fun- ctions coded. in TSO Command l.a.nguage( answer such questions. CLIST). The system always return to the main menu when an option is f1nished. DESIGN OBJECTIVES , CLIST TSQ I The main purpose of this system is to ob- 1. Each report progxam is actually a tain useful statistics and reports in a timely CLIST program. fashion and",Sugi-84-97 Chen.txt
"few user-supplied directives as possible. The user should not be expected to memor- ize a long series of commands o~ to have The business programmer/analyst possesses a very powerful tool when the flexibility and wide appli- a thorough understar,ding of the resident computer system. cability of SAS software is combined with the quick, interactive mechanism of the VM/CMS operat- 3. The system should be easy to use with plenty of help inCormation. ing system. By weaving eMS EXECS, panels, and macros around SAS programs and utilities, easy-ta-use business systems can be built to opti- This paper, therefore, proposes four techniques to the programme>""'/analyst for designing a business mize the capabilities of both tools for the programmer and the end-user. This paper disu5ses system. techniques for implementing SAS utilities under VM!CMS to build araphics and reporting systems, to These techniques a.re: use SAS programs as both a pre- and post-processor 1. to a batch job, and to write a complete trans- Using SAS programs as pre- and post- processors to a batch job. actions file from a SAS/FSP (TM) update session. 2. Creating a complete transactions file from a SAS/FSP update seSSlon. Using CMS panels to construct a si~ple 3.",Sugi-84-98 Vendeland.txt
"n St. Louis Abstract Some of the most important data obtained are applicants' self-rated levels of skill for 211 skills. For each skill, applicants indicate one of the following: 1) I consider myself proficient A Human Resources Management System (HRHS), under with this, 2) I have done this occasionally, 3) I have never done this, but I have some knowledge development for the Personnel Department at the or understanding of the principles involved, 4) I Washington University School of Medicine in St. am not at all familiar with this, or 5) r do not Louis is described. The primary function of the want to be considered for a position which would system is to match applicants with employer reqUire me to do this. The skill-level data and requirements. other information from the application process is A pool of applicants is created, composed of then entered into the HRMS. potential employees. The pool contains applicants' skill levels for 211 skills, in Departments ask the Personnel Department for assistance in locating qualified applicant8 to addition to standard application data. Employers fill their needs by submitting a job requisition specify minimum levels acceptable for these same skills on job requisitions. fonn. Two different forms are used, a Technical and a General Requisition. Together, these two The applicant pool is searched using a forms contain the same 211 skills listed on the candidates with skills applicants' Skills Data Sheet. requisition to identify meeting or",Sugi-84-99 Roesti Achtenberg Fishel.txt
"Performance Tracking In A Complex Environment Gordon R. Stauffer Morino Associates Vienna, VA 22180 Abstract: Performance tracking techniques have evolved considerably over the past several years with the introduction of new technologies and methodologies. Improvements in data acquisition, integrated data base systems. powerful reporting procedures, and color graphics have provided significant advances in the productivity of performance analysis. The evolution of these tools has allowed analysts to redirect their focus from data collection/reduction to interpretation. New methods continue to be developed which further enhance analysis of performance variables and improve the surveillance of workload and service levels. An overview of the evolution of tracking methods, a current, successful approach (which was developed at a data center where the author managed performance services), and ideas for future consideration will be discussed. This paper presents techniques used and plans envisioned by the author while employed at a large data center, It should not be implied that the techniques or plans are those of Morino Associates, where the author is presently employed. 1.0 Introduction · Hardware monitors - early 70's through 80's, e,g., DYNAPROBE, XRAY [3J Over the past several years many data centers have grown from a single processor with primarily batch workloads to large · Accounting systems - late 60's through early 70's, e.g"" complexes. Today the majority of organizations have two or more KOMAND, JARS [4J processors with many having four or more [1]. These processors support multiple system control programs, large and multiple · DASD management systems - mid-70's, e.g., ALERT, subsystems, complex networks, distributed processors, office ASMI2, PACIMASTER [5J systems, personal computers, and a multitude of applications programs both homegrown and commercially developed · Subsystem monitors - mid-to-Iate 70's, e.g., TSO/MON, CONTROL/IMS [6J Forthe performance tr",Sugi-10-02 Stauffer.txt
"Run Time Component Analysis Using SAS Software H. Pat Artis Morino Associates Vienna, VA 22180 Abstract: One of the most fundamental techniques employed in computer performance evaluation (CPE) studies is the decomposition of process execution times into their component parts. In this paper, we will examine how MVS/XA SMF and RMF data can be used to decompose the execution time of batch jobs. page ins 1.0 Introduction PGMPGIN VIO page ins PGMVPGIN One of the most common problems presented to the performance analyst is a process execution time that does not meet the Using the average page service time from the MICS SCPPSO file (note: the page/swap dataset activity file contains information expectation (i.e., service objective) of some user. When presented extracted from the RMFtype 71 record), these values can be used with such a problem, the most logical first step is to decompose the execution time into its component parts. Once this process has to calculate paging delays to further reduce the unaccounted been completed, the analyst can identify specific service times or component of execution time. In a SAS implementation, the server delays that can be improved to achieve the desired service simplest method for incorporating these page delay times is the level. Prior to MVS/XA, SMF and RMF data did not provide use of SAS formats. These formats will be discussed in the sufficient information to effectively decompose the execution time following section, of batch programs. As a result, analysts typically used real time monitors (like the Ca[ldle Corporation's OEXAN degredation The final measurable components of program execution time are analysis product) to examine their characteristics. contributed by device delays. In MICS, the BATWOA file provides EXCP data by device address. To support this study, the summary Using the new measurement variables provided by MVSIXA in the sequence of the BATWDA file was modified to include JOB and SMF type 30 records, execution",Sugi-10-03 Artis.txt
"At the Automobile Club of Southern California, a Current workload analysis (Where fonnal Data Processing Planning Department was are we now?) - The resource con- established in March, 1982 to address areas such sumption by each application, ser- as Capacity Planning and Performance Management. vice levels and system component This paper discusses the approach, tools and utilizations. (1) techniques used to set up the CPE function at the Club. Emphasis is placed on a practical Workload forecasts (Where are we approach and establishing credibility wIth-~ana: going?) - The prediction of growth gement. 1n existing applications and the estimation of the resource require-",Sugi-10-04 Shane.txt
"ASSESSING THE IMPACT OF VM SYSTEM MODIFICATIONS USING VMAP AND THE SAS SYSTEM HOl""'riet Bl""'ichta, Electronic Dota Systems rangement of minidisks. Prior to the Abstp""oct change, the temporary disk, the operating the paging fi les, s!:jsteltl, and the spool fj les all I""esided on the same 3330 disk Vat""'ious modifications wet""' made to a VM/CMS pack, whi Ie timesharing customer minidisks site. Secut""'it!:j and maintenance software were kept on 3350 disk packs. This was were put into production, and minidisks done because the 3330 disk pack is port- were reart""'anged on disk packs. The s!:jstems able, and could be ph!:lsically transferred fi les which pt""'eviousl!:j t""'esided on the-same to another site if Q l1lojor system fa i I ul""e 3330 disk pock wet""'e repositioned as head of occurred. Having the system disks together stt""'ings on separate 3350 disk drives. on the slower, but portable disk pack may Customet'"" minidisks were also redistributed hove provided a mechanism for emergency to achieve a bettet'"" balance. The primat""'!:j it also bockup. but resulted in high purpose of this stud!:j was to examine the contention between critical system effects of these modifications on s!:jstem resources. Even more illlportantly, the 3330 perfot""'mance. disk drives were being phased out in the altet""'nate site, t""'endering tt""'anspot""'tabi I it!:j There were a few pt""'oblems involved in the infeasible. ona l!:js is. . First, the CP MONITOR command was modified twice during the data Pat""'t of the planned s!:jstem modification collection period changing the time pet""'iods involved t""'epositioning the fout'"" s!:jstem dut""'ing which data was coptut""'ed, and rendet""'- disks on separate 3350 disk drives and ing the SAS MONT REND fi les useless. placing them head of stt""'ings on diffet""'ent Secor>d, two new accounts with unusual I !:j channels. The t""'ationale for the change was heav~ workloads were odded to the timeshar- a~ong tha7 reduced contention critical ing s!:jstem short!!:",Sugi-10-05 Brichta.txt
"any virtual machine loads the saved system, it shares the same set of pages in real storage as other virtual machines using the system. This The YM/CMS SAS system can be installed as results in savings of both real and external modules or as saved segments. Use of segments storage. Discontiguous saved segments have an results in better system performance. This paper added advantage because the segments can be deals with the advantages and disadvantages of attached to, and detached from, a virtual ma- the segment- and module-orientated versions. chine. Programs which are not continuously re- An analysis of four SAS test programs running quired can be shared and loaded when needed. with modules and segments is made using (1) The stipulations for discontiguous saved seg- CPU time, (2) virtual storage utilisation and (3) ments is that the code must be re-entrant and the number of start I10s, as measures of system the segments must be loaded and saved at an performance. All three measures indicate that the address beyond the normal end of a virtual ma- use of segments is more efficient than modules. chine. System programs and user programs that Some disadvantages of using SAS software from are not shared may be termed modules. segments are also discussed. THE SAS SYSTEM IN MODULES AND SEGMENTS",Sugi-10-06 Griffiths.txt
"of Capacity Management and Capacity Planning have recently emerged, providing the data center In this paper the authors present a SAS procedure manager with a large arsenal or measurement and for evaluating and predicting the performance of predictive tools that can help him make important token ring-baeed local area networks. The decisions such as acquiring new equipment, altering description and parameters of the network are all sYstem parameters (sYstem tuning), and shuftling input through the procedure control carda, then an workloads among the machines for which he is analytic model of the ring is constructed and responsible. executed. A SAS data set is created which contains the important performance metrics of the network, In the near future, it is likely that much data notably predicted queueing times for each station processing wiD be handled not by one or two huge and overall utilization of the network. Examples computers in a central location, but rather it will are provided to show how this procedure can be be distributed among many smaller machines, each used to predict the behavior of a token ring in performing a specialized function. While the scenarios or projected increases in message traffic. management and planning of the capacity of these Use of the procedure to perform sensitivity analyses processors themselves is an important issue in itself, on the network is also illustrated. the management of the network that ties these machines together is of even greater concern. In 3.",Sugi-10-07 Gimarc Smith.txt
"A ROTATION SCHEDULING MODEL USING PROC LP Duane R. Walker, AT&T Technologies, Inc. The required packs for each cycle will be This paper will explain a scheduling model input values for the model. It is recommended that applies to the Circuit Pack rotation update processes. The model will give a that the cycles with the smallest requirements complete demand schedule for seed stock be ranked highest, and cycles with largest circuit packs by cycle to the manufacturing requirements be ranked lowest. This will reduce the amount of packs not being utilized division, minimizing the total cost of investment while meeting the projected in each rotation cycle, in addition to schedule required. The results will show reducing investment cost and allowing for rotation to begin earlier. that a smaller number of seed stock circuit packs will be required. II. DETAILS OF THE MODEL I. OVERVIEW The objective of the model is to maximize customer satisfaction, minimize the total A model to determine the number of seed stock investment carrying cost in the firmware packs needed to accomplish a firmware change has been formulated. The approach is process, meet rotation time schedules, and give manufacturing a projected schedule to be different from previous work done by members met. It is imperative that manufacturing not of this particular Division. The model is allow the production of packs to be stored in based in principal on Linear Programming investment to reach an excessive level before Formulation and uses SAS/or software package. introducing them into rotation. The model's The model formulated can be extended to ability to provide manufacturing a projected include mUltiple changes and firmware/hardware time schedule of the needed packs will change processes. expedite the process. The model is also designed to give a schedule of the return to The current rotation time for implementing a manufacturing for repair of defective packs firmware change is specified to be 15 cycles, and",Sugi-10-08 Walker.txt
"PROVAL AN AUTOMATED METHOD FOR EVALUATING TRADE AND CONSUMER PROMOTION FOR PACKAGE GOODS INDUSTRIES AMBAR G. RAo ROSS DENNIS DOUGLAS GRADY RAO ASSOCIATES. INC. :9 RECTOR STREET SUITE 2604 NEW YORK, NY 10006 Promotions are a widely used The impact of a promotion on marketing tool in packaged goods sales to the trade or to consumers industries. They usually provide is usually clear and unambiguous. a short term incentive to the Figure shows a typical plot of trade (supermarket chains) or to sales over time. Periods 4 and 5 consumers to purchase more of a and 11 and 12 are the promotion particular package size of a periods; the sales these .:n brand. A typical trade promotion periods exceed the average of nonpromoted periods by a factor 0: might offer a discount on cases of the 12 oz size of a particular 5 to 8. Us~ally, the sales in the brand that are purchased over a 4 periods immediately preceding anc. week period. Other types of trade following promotions are promotions might combine a depressed, the firs t beca-:..tse the discount with an advertising trade ant.icipates promotions and allowance. The trade is supposed delays purchases, and the second to use this allowance to purchase because inventorj.es Qui2 t up newspaper advertising to publicise during promotion are being drawn the promotion to consumers. In down. The phenomenon of the post both cases, is expected that dip is also evident i~ it promo~io~ the trade will pass through some consumer sales, as home of its savings to the consumer, inventories built up duri~g the although this is a requirement promotion are depleted and that is hard to enforce. purchases are delayed. In orde~ to compute the i~cremental effect Typical consumer promotions of a promotio:;. these dips need to be considered i~ addition :0 the include on-pack and in-pack coupons, as well as coupons sales during the p~omotion itse:f. distributed via direct mail or newspaper supplements. Figure 1 Usually, trade promotions are (ooos) BRAND A SA",Sugi-10-09 Rao Dennis Grady.txt
"ed on ABSTRACT goodness of fit criteria and tests of white noise on Statistical models of peak electricity demand provide the residual series using PROC SPECTRA. the basis for short-term load forecasting and weather normalization applications. Due to the weather sensitive nature of peak demand, a modeling DATA methodology is developed that explicitly accounts for Models of peak demand are especially useful for the relationship between peak demand and weather normalization and forecasting purposes. temperature. By focusing on daily data, this Since changing weather conditions represent the relationship can be identified on a seasonal basis for any given year. primary source of variation in peak demand, the question is often asked, ""what would have been the A multi-regression framework is initiaHy formulated peak demand had normal weather prevailed?"" In that provides the basic structur~ for a time series order to answer this question, statistical models that modeling approach. The SAS/ETS ARIMA procedure relate peak demand to one or more weather variables is used to identify and estimate a Box-Jenkins model can be developed and used for estimating historical that accounts for the non-linear relationship between peak demands under a set of alternative weather daily peak demand and temperature through a conditions, rather than those which had actually specification of piecewise-linear transfer functions. occurred. By focusing on daily peaks, the models can Also, since electricity",Sugi-10-10 Jacob.txt
"BUILD YOUR OWN QUERY LANGUAGE David Burrage Department of Math and Computer Science University of Quebec at Montreal %MACRO PROJECrCDSIN,DUMl,VARLIST,DUM2, Introduc t ion DSOUT,UNIQUE=O)/STMT; %*----------------------------------------------*j MACRO statements with statement style %* A macro to generate code to project out invocations provide an elegant means of *j *; %* constructing query language commands. If you do columns of a SAS data set with the option *; %* of eliminating duplicates. not possess a data base query language for SAS %* (two query languages are currently available, *j *; %* COMMABL is a macro which replaces commas DS/QL [1J and RAQL C2J) , perhaps you should %* with blanks in a character string to consider building your own with the SAS82 macro *j %* generate a new string NEWTEXT. language. *j %* *j *; %* SORTDS( is a name-style invocation ~ language programming %*----------------------------------------------*; %IF &UNIQUE %THEN The aim of a query language is to provide an %SORTDS(&DSIN,ONKEYS,&VARLIST,GIVING,DSDUT) easy-to-use high level interface between the COMMABL &VARLISTj casual user or programmer and SAS. Commands may %LET VARLIST=&NEWTEXTj be designed to have English-like syntax. DATA &DSOUTj SET %IF &UNIQUE %THEN &DSOUT ; The program which follows is a sample query language program which uses macros CREATE, %ELSE &DSIN ; %STR(;) ; SELECT, PROJECT and PRINTDS to create a temporary KEEP &VARLISTj data set and finally to print, with title, two %IF &UNIQUE %THEN %DQ j columns of selected observations with duplicates BY &VARLISTj eliminated. CREATE is a command which requires %LET N=lj %LET VARA=%SCAN(&VARLIST,&N,, '); the user to specify his input data file. IF %00 %UNTIL (&VARA=) ; e.g. CMS FILEDEF etc. %IF &N>l %THEN OR ; CREATE TEMPDS US ING flVARl $ VAR2 VAR3 VAR4 $"" FIRST.&VARAj %LET N=%EVAL(%N+l); ""'> %LET VARA=%SCAN(&VARLIST,&N,' ') SELECT TEMPDS WHERE ltVAR2 TEMPDSI VALUE"" %END; %STR(j); %END; PROJECT TEMPDSl OVER VARl,VAR3 =) TEM",Sugi-10-100 Burrage.txt
"FSCONTENTS--Full Screen Editing far PROC CONTENTS Gary G. Vair. IBM Corporation ABSTRACT. SAS DATA SET The need for a user tool to create and maintain SAS 1 data sets has led to the development of FSCONTENTS a full screen editor for PROC CON- DATA ATTRIBUTES Th';s tool has been implemented on VM a~d TENTS. TSO using PROC FSEDIT and SAS macros. FSEDIT,s the SAS Full Screen Product to edit the contents of a SAS data set. However FSEDIT cannot change PROC CONTENTS PROC PRINT Hard copy the variable attributes associated with the data set or create a new SAS data set. FSCONTENTS allows all SAS data set at tri bute s Full Screen PROC FSEDIT FSCONTENTS listed by PROC CONTENTS to be edited in full screen Edit mode. New SAS data sets may be defined. Data set changes allowed include: Create a new SAS data set Delete an existing variable FSCONTENTS COMPARISON Add a new variable Rename a variable Convert a character variable to numeric and PROC CONTENTS prints the SAS data set attributes vice versa and PROC PRINT prints the data set observations. Change the length of a variable In the same manner, FSCONTENTS allows full scr-een Change, add or delete formats, informats, and editing of SAS data set attributes just as FSEDIT 1abe 1s allows full screen editing of the data set obser- vations. FSCONTENTS has been designed for those who may not be familiar with the techniques necessary to cre- The SAS data step tool s necessary to change the ate or change SAS data sets. Maintaining SAS data following data set attributes are not always un- sets becomes an easy task for the experi~nced SAS derstood by the beginning SAS programmer. programmer and the beginning SAS user al1ke. Create a new SAS data set The fo 11 owi ng sequence of screens ill ustrates the use of FSCONTENTS. Delete existing variables Add new variables CREATING AND MAINTAINING SAS DATA SETS Rename variables USING FSEDIT AND MACROS. Convert character variables to numeric vari- ables and vice versa FSCONTENTS described in th",Sugi-10-101 Vair.txt
"EXECUTING SAS UTILITIES FROM A MENU-DRIVEN SYSTEM Janet C. Lind, San Diego Data Processing corporation INTRODUCTION: SASDATA These panels provides for D SAS data definition (DATA step) How many times has the Information and/or SAS data entry (PROC FSEDIT) Center User or the casual SAS user wanted to perform a simple utility SASEXEC This panel allows the E function but can not remember the PROC user to SPF Edit the SAS code and or the syntax required by the PROC? The execute in foreground or batch. user either asks his co-worker if they This option is for the SAS program have done the function or goes to the coder to repetitively edit, execute SAS BASICS manual and tries to find the and browse output. correct section and then reads through all the parameters. San Diego Data SASGRAPH This is a series of panels G processing corporation found that there to generate xy plots, bar charts, were several utility functions for which pies, slides, and to replay saved all SAS Users had a need and that graphs. much time and many key strokes could be saved by designing some general purpose This is a series of SASREPT R menus and panels. The original menus panels for generating reports using and panels were designed for SAS/GRAPH. PROC PRINT. SAS coding, sorting, However those users also required TITLES, BY variables, and SUMs are non-graphic utility functions such as available. The report output is PROC SORT, DATASETS, PRINT and DATA SPF browsed and can be optionally steps. Many of these users did not have sent to a printer. the knowledge or desire to learn SAS coding. The SAS support personnel did u SASUTIL This option invokes a not have the time to sit down with every UTILITY Menu which is the subject user and write the SAS code and TSO of this paper. commands necessary to perform these functions. Therefore the utility menus Z SASZCOPY This provides for saving and the panels evolved from a need to the SAS code generated by the support SAS/GRAPH and Data Entry with panels so th",Sugi-10-102 Lind.txt
"the flexibility to adequate- In-House Provided System ly manage the human resource from a data stand- Most large companies have a human resource in- point. However, SAS, with its report, statis- formation system provided by the data processing tical, and database capabilities can aid the department. These systems in themselves range human resource professional in managing the from payroll system to a flexible database system resource with ease, flexibtlity and security. covering the many needs of the human resource This paper demonstrates ways that SAS can tx! professional. These systems have documented used to develop a user friendly database procedures for data input, maintenance and system structured for the human resource function. upgrades. Several standard reports are produced In the field of human resources, personnel with varying regularity as the needs are estab- lished. These systems are carefully designed information is normally obtained from one of three systems: a software package from a human and generally effective but large systems carry a lot of inertia and are difficult to move when resource information system vendor, a personnel special applications or reports are needed in a system designed by the company data-processing hurry. department, or from a large bank of file cabinets in the personnel clerk's office. Personnel data systems are the lifeblood of the human resource Examr,es of Needs environment. They tell who is on the payroll, To 1 lustrate these t",Sugi-10-103 Scott.txt
"R Commonwealth Edison SAS Data Set Facility John Fitterer, Commonwealth Edison INTRODUCTION USING THE FACILITY The SAS Data Set Facility was created to aid both our TSO users who are proficient in SAS programming, as well as those-users with TSO users wishing to take advantage of the little or no SAS programming skills, in bene- SAS Data Set Facility select option 4.3 on the fitting from the features which are available SPF primary menu. This displays the primary through SAS. The facility simplifies the process selection menu of the facility which is shown below. The options give users the ability to of working with SAS data sets, invoking SAS create, delete, modify, edit, and browse SAS functions, and executing SAS programs in the data sets; run SAS programs and interactive foreground. It accomplishes this through the SAS statements in the foreground; and invoke the use of SPF panels, skeletons, and clists. The SAS Data Set Facility has been incorpor- FSCALC spreadsheet procedure. ated into the TSO system's SPF at Commonwealth Edison and is intended for use in an MVS TSO - - - - - - - - - - - - - - SAS DATA SEr F1IC!L!TY - SELEX:l' OPTICN => environment. AI= CREATE A NEW SAS LIBRARY OR DATA 5El' USING FSEDIT 1 09:24 BACKGROUND EXIST!NG SJlS DATA SEI' DELETE AN M:OIFY AN E:lCISTING Si'\S DATA SET Commonwealth Edison is a large electric utility serving Northern Illinois. There IDIT lIN EXIS'l'ING Sl\S DATA SET 1:lSING FSEDIT are about 2000 active users of Edison's computer DISPLAY INroIMM'ION 1\BClJT AN EXISTING SAS LIBRIIRY OR S1\S DATA SE'I' system, more than half of which have little CREl'ITE A REPORr FaN lIN EXISTING SAS DATA SEl' or no programming skills. The programs they IN\iUKE FORBJKXJND S1\S 7 run and reports they produce are created for them by the Computer System's staff as they EXISTING SAS DATA SET USING FSffiOISE BRCWSE }IN are required. The Computer Resource Information Center was ro ro PRESS ENI'ER PRCCE:SS OR PRF-SS EXIT EXIT THIS PANEL created at",Sugi-10-104 Fitterer.txt
"ew macro variables at the begin- ABSTRACT ning of the program. The solution was exten- Presented here is a technique for creating ded even further to allow the values of the generalized report writing software which uses necessary macro variables to be input from a SAS dataset which could be edited by SAS/FSP. SAS/FSP as a user interface. The user, with It was hoped that by using SAS/FSP to edit the 1 ittl e or no know1 edge of SAS, can create a report quality listing or table from a SAS dataset that sufficient information caul d be contained on the edit screen to allow non-pro- dataset by following the instructions provided by a SAS/FSP screen dataset. grammers as well as experienced SAS users to run the program. This would permit the devel- SAS/FSP is used to create a ""controll! dataset opment of software which the clinicians could (or datasets). The information from this use to monitor ongoing stUdies. dataset can be passed to macro variables with the CALL SYMPUT function. Additional control The program would begin by using proc FSEOIT information can be obtained from the input to edit a control dataset which would control dataset which is to be processed and passed to the program processing. The screen{s) for FSEDIT could be designed in advance to provide macro variables as well. SAS code can then utilize these macro variables to adapt to var- the necessary instructions to edit the data iations in the input dataset and/or final re- and checks on the val ues entered. The v",Sugi-10-105 Holdrook.txt
"anged. Within each catalog you have the capability of This paper discusses the changes and deleting, editing, copying, or renaming entries enhancements to the SAS/FSP software. Some within the catalog. To delete an entry, enter the changes are common to all SAS/FSP procedures, command while others affect only a single procedure or a particular screen within a procedure. DEL name. type All the screens you create with the FSCALC and on the command line and press the ENTER key. FSEDIT procedures, letters and forms created The entry is then removed from the catalog. To with PROC FSLETTER, and function key edit an entry, you can enter the command definition screens are stored in catalogs. Catalogs are not SAS data sets, which can be EDIT entry. type accessed in the same manner as data sets are cu rrently accessed. Catalog management involves understanding how the catalogs are set or you can put an S in the selection field for that up and manipulated. entry. The EDIT command only works on entries that are acceptable to the procedure you are using at the time. For example, if you are A common text editor is now available for accessing PROC FSLETTER and try to use an FSCALC program screens, PROC FSEDIT screen FSCALC report screen, you will be told that it is modification, and FSLETTER forms and letters. an invalid type field for this procedure. If you In addition, PROC FSEDIT has changed try to edit a letter, however, you can gain significantly in order to protect screens and to acce",Sugi-10-106 McAlister.txt
"run the program When writing a SAS* program to be f'- is very simple. If the user specifies the executed by an individual with little or no SAS debug option in the CLlST, several of the macro experience, the interface should be as debugging tools were included in the options transparent as possible. SAS is an ideal language to use in the creation of many statement passed to SAS. If the user accepted the default, the options statement was set to different kinds of ""production"" programs. The nosource~ and the userls entry to SAS was difficulty with using SAS is that in order for completely transparent. someone to take advantage of all of the interactive capabilities of SAS, the user needs Upon termination of the SAS program, to have a working knowledge of the language. the CLIST offers the user options for ·the This sometimes limits the usefulness of an otherwise very desirable program. output. If the user chooses to view the output, the output is sent to the screen. If A more desirable situation is one in the user wishes a print of the output, they are whi ch the user of the program has the ,.bil i ty to given the option of which printer they wish the enter SAS interactively via a TSO CLIST, output routed to and prompted for the number of copies requested. Please refer to FIGURE 1. selectively process a wide variety of data, view the interim output, choose to print or delete the output upon termination of the program and have the entire process be transparent to the PROGRAM us",Sugi-10-107 Gutting.txt
"SAS® Menu-driven System using SAS 82.4 Macros under IBM MVS/TSO Gustave F. Jonas, Indiana National Bank Mark T. Duffin, Indiana National Bank This system of macros uti I izes SAS/FSp® and SAS® base PR I-MARY MACRO SELECT I ON SCREENS: 'MEMNAME1' -' MEMNAME3' soft....are products. The follo .... ing is a discussion of an onl ine interactive system of macro modules ....hich This code wil I display the option menu for the first .... i II assist a user in performing tasks relating to SAS 26 user options and the common macros. This member is fi les and programs. This system is primari Iy menu cal led from macro 'EXDATA'. driven and as such requires SAS/FSP availability to format the screen menus. Due to the length of the PUT' LISTED BELOW ARE THE SAS FU/fCTlOHs THAT YOU CAN PERFORM'· ~~~: ENHR TIlE ~~~~ ~~E~~E T~~H~~ I~=T~U K~eN~<T~l PERFORM' 1 ' macro source code, it is not possible to include the code for the macros mentioned. Contact the authors PUT' PUT'COOE fUNCTION CODE fU/!CTIOH CODE fUNCTION'; for more information. PUT' 101 1 I<LABELOI '1021 I<UBEL02 'lOll &LABELOll PUT' JO'rl HABElO., '1051 &LABEL05 '1061 &L.ABEL06; To start up this system the following cl ist must be ~LAllEl01 pur'lo11 'IOBII<LABELOB '1091 &LABEl.09l I'UT""1101 &LABELIO '1111 &LABELll '1121 &LABEL12; included in the SYSPROC PDS of your institution in a ;~~:J,~~J, ,.&~~B""',~',,3 &LABELl~ :'1111 '1151 &LA8ELl5. member named' ICC' or as a user executable cl 1st. To 1171 I:lABELl7 '1181 &LABELl8. L"" L ;~:;I~~I : :t::n~~ :I~gl :t::~t~g :I~~I ' :::::~g~: execute the macro menu system the user should enter 'ICC' on the tso command panel. Note that this cl ist ;~~:!;~!.:.~:.!~~~;~n. '1261 ' HABEL26 'IP21 PACE 12 TITLES'· calls another cl ist 'SAS' .... hich is intended to be the PUT INfOCENTER SUPPLI_EO ROUTI NES ..................... ,; SAS command procedure of your installation. 'IMI SAS UTILITIES IBBI BATCH JOB STATUS ICCI SUBMIT BATCH Joe' 1'1001 SET TO SET COPY IEEI CREATE A. SAS FILE IFFI INTERAC",Sugi-10-108 Jonas Duffin.txt
"SASe Dataset containing SAS file directory· via user written Procedure Mark 1. Duffin, INDIANA NATIONAL BANK FIXED BIN(15) INIT(94), 2 lRECl In an effort to create menu driven SAS macros we real- FIXED BIN(31) IN1T(O); 2 PROTECT ized a neccessity to obtain a I ist of SAS data sets FIXED BIN(31) BASED(DPTR); DCL DSNAME residing in a SAS fi Ie. The two approachs avai lable PTR; DCl DPTR did not satisfy our need. The first of the twO methods PTR; DCl DIRPTR to read the directory of a SAS file is to perform a PTR; Del STRUCTPTR Proc Oatasets With the outpUt going to a sequential PTR; DCL ARRYPTR fi Ie and then reading that fi Ie into a SAS dataset. PTR; Del PTRPTR This method is cumbersome and time consuming. The FLOAT DEC(6) BASED(PTRPTR); DCl TSTPTR second method was to read the directory of the SAS file FLOAT BIN(53), DCl DDTST as i f the SAS file was a variable block sequential CHAR(8) BASED(DDPTR), DDCHAR dataset. This method, although faster than the first PTR; DDPTR method, creates other problems. Should the SAS fi Ie DCL , HOlDARRY, not contain a directory (new SAS file) the routine CHAR( 8), 2 HNAME would abend. In addition, certain other circumstances FIXED BIN(31) UNALIGNED, 2 HNOBS can exist in SAS fi les which cause this method to CHAR(8); 2 HRLSE abend. In order to provide a directory I ist of a SAS BASED( ARRYPTR), DCll NAMEARRY(l) fi \e without these problems we have developed user CHAR( 8), 2 ANAME written procedure. This procedure, I isted herein, is FIXED BIN(31) UNALIGNED, 2 ANOBS written in PL/I Optimizing language. The objective of CHAR( 8); 2 ARlSE the procedure is to read the SAS file directory, sort BASED(STRUCTPTR), DCl 1 DIRSTRCTR the entries into alphabetic sequence and then create a FIXED BIN(31) UNALIGNED, 2 REClEN SAS dataset wit~l each directory entry as an FIXED BIN(15) UNALIGNED, 2 RECTYPE observation. The format of the procedure call is as CHAR( 8), 2 DIRNAME follows: CHAR( 20), 2 NOT USEl FIXED BIN(31) UNALIGNED, 2 NOBS PROC D I REeT",Sugi-10-109 Duffin.txt
"ESTIMATING AUTO CORRELATIONS AND CROSS-CORRELATIONS WHERE MISSING VALUES ARE PRESENT: A SAS MACRO Kenneth M. Portier, University of Florida Pan-Yu Lai, University of Florida indicator series and the amplitude modulated se- INTRODUCTION. quence as follows. not In most statistical data analysis methods, miss- ing values are either thrown away or replaced by n-1 L AtAt+.R. 0 < .R. < n estimated values. Both of these methods are not t=1 adequate in dealing with time series data since the latter may influence the estimation of pa- rameters and the former may affect the station- arity of the series. Then, the sample autocovariances are estimated All SAS R software related to time series data by such as the ARH1A, AUTOGEG, SPECTRA and STATE- SPACE procedures in the SAS/ETS HI system at the CU(t)/Ca(t), when Ca(t) f 0 and EX Cx(t) = 0, n beginning of each series until a nonmissing val- ue ;s encountered, then use only data from this and the sample autocorrelations are estimated by point until the next missing data occurs. In this way, only part of nonmissing data can be PX(t) = Cx(t)/Cx(O). utilized when missing values are embedded in the Ox When EX n F O. then EX ;s estimated by series. A program which allows estimation of n some basic parameters of time series analysis~ n n such as autocorrelations and cross-correlations, EUtl LAt' In this case the original X is re- utilizing all nonmissing values in the series is t presented here. t=1 t=1 P placed by X~ = X - x and U = AtX in the t t t Estimation of autocorrelations of a discrete equations for CX(t) and PX(t). Let the serial stationary stochastic process having missing values and the properties of these estimators autocovariances EXnXn+t be denoted by YX(t) and have been discussed in Dunsmuir and Robinson PX(t) = YX(t)/yX(O). Dunsmuir and Robinson (1981a, 1981b) and Marshall (1980). Similarly, properties of spectral density estimation can be 1. n (198Ia) prove that if ~ = 1m n-1EA(t) a.s. and found in 8100mfied (1970),",Sugi-10-11 Portier Lai.txt
"S * and the SPF Dialog Manager Facility to else logic, sorting formatting reports, make SAS more user friendly. It will include titles, subtotals, and totals. an interactive test, and batch runs. the following areas: Data Dictionary 1. Why you should build such a system. The data dictionary used in this system is a 2. \-fuat you need to create the system. simplistic version of a true dictionary. It This includes the files. partitioned contains 8 file description records and up to data sets, clists. and other necessary 999 field description records. (see Exhibit tools. 1) · 3. A detailed explanation of what the Record 1 contains the number of fields in system is and is not. This will the record and the OS data set name. include such items as an introduction to panels and clists, the use of an Record 2 contains the OS data set name of index file and a JCL Generator for SAS. your key file (inde~:) i f applicable. 4. How you create a system. This will Record 3 contains the number of subsets include Job Flow, setting up Panels, within your SAS Database. using Clists, generating SAS code, building a data dictionary, creating Records 4 & 5 contains the Internal SAS index files and executing the system. subset names within your Database. 5. A demonstration of the system and its Record 6 contains the number of key index ease of use. There is no need to know files. SAS to use this system. 1 key file for every Internal SAS subset 6. Features to be added to the System. if using indexed S",Sugi-10-110 Hackett.txt
"l-tichael Cuslnnan, Board of Governors of the Federal Reserve System Phillip Brennan, Board of Governors of the Federal Reserve System more panels. If a SAS screen dataset is not Definitions: specified by the user, SAS provides a default Screen dataset - A SAS dataset whiCh formats display format. In many applications, however, the display of SAS observations ynder the the user finds it desirable to create a SAS Full Screen Products (SAS/FSP) FSElJIT and FSBP~SE. The observations in a screen customized display format and save it in a screen dataset. Text may be added to the panels, dataset are ordered in a special sequence variables may be grouped in logically related and each observation contains only two panels, and urmecessary variables may be dropped variables, TYPE# and 'rEh.""T#. A screen from the display. In IIDst cases the SAS screen dataset is also referred to as a screen definition process is simple and straightforward; definition in this paper. the user need only type in narrative text, if the desired, and identify the locations of Panel - The screen icage produced by SAS/FSP. variables to be displayed. This process 'WOrks A SAS screen dataset is composed of one or best for datasets containing few enough variables more panels, in a defined sequence, which to be displayed on one or two panels. As the are displayed one at a tine. A screen nurmer of variables (and hence panels) increases, dataset which contains two or mre panels the process of screen definition becomes IIDre is referred to as a multi-panel screen involved. dataset. A major problem with multi-panel screen This paper describes two macros which design is that the structure of the screen facilitate multi-panel screen design and dataset can be only minimally altered once it has mdification. They allow the user to copy screen been created. Even though individual panels may definitions, insert or delete panels from a be rrodified with little effort, new panels carmot screen dataset, and rearrange t",Sugi-10-111 Cushman Brennan.txt
"~1enu-driven Reporting James M. Watts, CIBA-GEIGY Corporation I. INTRODUCTION variable and the convention used to name SAS datasets. The major benefit of MDR is that a ~Ienu-driven Reporting (MDR) is an on-line user can select a subset of the observations in ad-hoc report generator provided to the users a given SAS dataset that are of interest to of the Dyestuffs and Chemicals Division of him. In addition, the user may easily retrieve CIBA-GEIGY located in Greensboro North only that subset of variables he wants to see Carolina. MDR is designed to access any SAS® on a report. dataset in the computer. MDR employs a simple operating philosophy. To get a report, the user fi 11 sin one screen pushes a button and III. Flow of an MDR Session back to the screen comes a report. If the A D&C user types II INFOCNTR Ii in the TSO command report is not acceptable, the user may easily return to that screen, change it and generate a 1 ist panel to access the IC. This action new report for viewing. brings to the screen the menu shown in Figure 2. As mentioned earlier, MDR is one of several The purpose of thi s paper is to di scuss the methods users can use to obtain information components of MDR and their use. Section II from the IC. In this section, we will follow explains a bit of the background of MDR and its the steps of an MDR session (select option A). value to an organization. Section III illustrates how a user chooses MDR during an ---------------- .· -------- TSO COMMAND PROCESSOR ------ interactive session at the terminal, leading ENTER TSO COMMAND OR eLIST BELOW, the user to the standard report selection screen. Sect i on I V exp 1a i ns the heart of the ::'"" > INFaCNTR system, the standard report selection screen and its use. Section V describes the actual generation of an MDR report. Section VI Figure 1. INFOCNTR Command List Execution discusses some of the internal processing of MDR. Section VI concludes by summarizing DI~lSION INFO~lIltnON CENTE~ TltE OYESTU,fS AND",Sugi-10-112 Watts.txt
"the Federal Reserve System Abstract The IIEthodology has always given sane trouble to the SAS developer who uses This is a ftmction which generates screens only occasionally. It usually was a SAS* data entry screens autanatical1y. 'These IJatter of going back to the manual and screens may be used singly or in Dll~tiples to re-discovering the rrethod. Experienced users establish screen based data processIng had no trouble but were forced to think applications. through the sarre steps over and over again. After answering questions from the fanner '!he only requirerrent for its use is many times, it was decided to write a routine knowledge of the attributes of the data to create screens automatically. fields on each observation. It does not require prior existence of a data dataset or TI1.e automatic creation of screens screen dataset to generate a completely new would cut down on the rnmber of questions and screen. Input to this function is at the same titre reduce the am:runt of effort facilitated through a series of screens. and time required to generate the screens. The function generates the SAS code A minimum of knowledge about this required. 'Ihis code is executed in on-line function is required in order to use it. IIDde. The output is a SAS screen dataset, ~t is required is a clear· idea of the which will be saved by SAS if this has been screen which is to be created. Should it be specified in tile function. permanent or temporary (i.e. for test only)? If pennanent, wher",Sugi-10-113 Shankman.txt
"s all of the tools of This paper describes a unique implementation of the office automation. Apart from the usual Federal Government's Small Business Innovation proposal/project tracking. scoring and reporting Research (SBIR) Program that takes advantage of system required. the SBIR administrator has to the best that micros and mainframes have to offer. contend with such things as matching a group The SBIR system. developed around dBASE III. freely (usually 3 5) of expert reviewers for each exchanges data with other microcomputer software as proposal. communicating with those reviewers and well as with SAS and SAS/GRAPH on the mainframe. their technical topic managers frequently. and The system's initial data load is carried out from preparing summary reports and statistics for proposers' hardcopy submissions with the aid of an Congress. The program requires quite a bit of optical character reader. SBIR summary -statistics form letter and mail label generation and and graphs are routinely produced by SAS under communications by voice or electronic mail. control of the micro which can emulate a TEK4010 device to receive SAS/GRAPH output. The procedure has many advantages including OVERVIEW OF THE SBIR REVIEW PROCESS o eQ..6e 0' U06e - a. U6eJL need not be ,am..Le..iQJt w.ith The process begins with the receipt of Phase ~theJL dBASE III o~ proposals which are assigned unique ID numbers in SAS the mail room. The submissions are entered into the computerized tracking system, and",Sugi-10-114 Olympia.txt
system that I operated for several years primarily as Faced with an ever Increasing number of SAS system a living laboratory for testing some of our users who have discovered the power of communication and file transfer programs. I microcomputing. a few organizations have started considered starting a national RBBS when in-house Remote Bulletin Board Systems (RBBS). multitasking. multiuser software became available for An RBBS gives organizations the facility for delivering the IBM PC. Since I am as fond of SAS as I am of timely information and assistance to users via the micros it made sense to focus on the interests of the electronic messaging subsystem and the files SUGI Special Interest Group/Microcomputers subsystem. The RBBS Doors feature allows an <SIG/M) . authorized user to run a program remotely and is an excellent vehicle for diagnosing user problems with software. This paper describes our experiences in The RBBS runs as a background task on an IBM XT operating the national SUGI SIG/M RBBS and tips on clone. The foreground task is whatever we happen to be dOing at the console - data base management. starting and implementing your own RBBS. spreadsheet. word-processing. program compilation or pure number crunching. Thus. the standalone micro that hosts the RBBS is a multitasking. WHAT IS AN RBBS? multiuser one courtesy of the MultiUnk software. An RBBS is an unattended. microcomputer-based Most RBBS users never know that someone else is using the machine while they,Sugi-10-115 Olympia.txt
"® A SAS SOFTWARE TO LOTUS 1-2-3 MACRO Thomas Miron, Wisconsin Dept. of Transportation SAS and Lotus Development's 1-2-3 a Worksheet the value of each integrated spreadsheet program are character-type variable must be popular, user oriented, data processing enclosed in quotation marks. A user products for mainframe and micro familiar with SAS Data Step programming computers respectively. Organizations could write a program to do this. But that support both mainframes and it could be a discouraging problem for micro-computers, often through an the causal or infrequent user of SAS. Information Center, may support both Further, each Data Step written to products. SAS and 1-2-3 are very output an IMPORTable file would be different . as to user interface, specific to one SAS Dataset with it's available data storage and output unique Variable names and types. The devices, and overall sophistication and alternative approach is to build a power; yet both have their place~ and generalized procedure that will convert both lise the same ""flat filen concept any SAS dataset to a 1-2-3 format file of data organization. Users familiar with little user intervention. This with 1-2-3 and SAS often recognize can be done via the SAS Macro facility. situations where data being stored for use with one product CQuid be more appropriately handled with the other. THE ""SAS123"" MACRO Since data organization is similar, A SAS Macro has been developed that SAS's Observations and Variables will read in any SAS dataset and write a host system file in 1-2-3 Import corresponding to 1-2-3's Rows and Columns, transferring data from 1-2-3 format. (see listing) The names of the SAS Variables, wrapped in quotes, are to SAS or vice versa requires no data organization restructuring. The written as the first record in this physical movement of data from a SAS output file and appear as column storage medium (typically a host system headings in the 1-2-3 worksheet. The disk) to a micro-computer (hereafter fi",Sugi-10-116 Miron.txt
"ICROCOMPUTER COMMUNICATIONS ABSTRACT With the IBM 30B1K mainframe acting as What happens when you mix 10% IBM PC, the central processor, AVCO LYCOMING PCjXT, 10% IBM PC AT, 40% IBM 30% IBM runs an intensive and powerful computer 3270 PC and 10% COMPAQ PLUS portable environment (Figure 1). Employees of computers with SAS Software? If done AVCO LYCOMING have a wide selection to properly, you will obtain the most pick from when accessing the mainframe powerful brew currently available. via microcomputers (Figure 2). Access methods include coaxial communications As study this paper will cover a case via IBM 3270PC, IRMA or FORTE emUlation the installation of over 100 IBM or boards; dial-up asynchronous microcomputers in a corporate compatible communications via SMARTCOM, CROSSTALK, to environment. Topics be covered OR SYMPHONY; dial-up bisynchronous include: communications using IBM's SNA/SDLC package, and electronic mail 1). Hardware and software capabilities via ONTIME and EASYLINK. configurations Also, reviews of dial-up asynchronous 2). Communications between the 327x emUlation using packages such as mainframe and the microcomputers CXI's emUlation is taking place. 3). Problem areas to watch out for 4). A review of a successful SAS COAXIAL COMMUNICATIONS Software application. In the coaxial environment (Figure 3) The microcomputer hardware that will be users may select either IBM 3270 PC's or covered includes the IBM PC/XT, IBM PC other microcomputers equipped with FORTE AT,",Sugi-10-117 Hutchinson Hutchinson.txt
"The PC Version Of the SAS® System John Sall, Claire Cates, and Jeff Polzin SAS Institute Inc. The PC version of the SAS System is both an implemen- tation compatible with the mainframe version, and a product """" reborn with significant advances in usability. rr~cy iF :11 1 TOtAL -------+ The PC version of the SAS system runs on the IBM PC --------+ -------+ a 11: 1: 1: XT and PC AT and compatibles running PC DOS 2.0 or : 5,ali: 5.26: 19.53 --------t -------+ -------+ higher, and having 512K memory and a hard disk. a: 12: 3: 5 : 19.53: 15.12: 26.32 -------+ -------+ --------t This new system is' best described by showing the screens 11 3 1312: : 19.53 1 5,a6: 15.19 as they appear in a real session. --------+ -------+ ------+ 14: 2: 2: 4 : 111.53: 111,53 I 21.115 When you entcr the command SAS, you are greeted by --------+ -------+ -------+ 15: 21 2: 4 our display manager with its three windows. : 18.53: 19.53: 21.115 --------+ -------+ -------t II : 1: 16 : The most powerful tabulation procedure is TABULATE. Here we ask for a table with the rows formed by the AGE classification and ALL, and the columns formed by the mean HEIGHT and WEIGHT classified by SEX. ~'''''' '''''~~~~~~~~~ Ic{;~~;~d ~:) .,0 Release 6.· at SAS Institute Inc. !~~ Pl'OC tahuh.tf! aata=save.cl~sl· cl~ss age se)(, Val' height weight; * * iOO@~ tlh!t ag~ all, ~an (heigh weight) !ex; ,9!W""<ll~ I'UII, "" : IIFStN : :l i---------iiiiGlT----------i---------WEIGlY----------! The PROGRAM ED/TOR window is a full-screen editor that ~: :-------------------------+-------------------------: you use to enter and edit SAS statements. In this exampll', ~1 t-----------~~-----------!-----------~~-----------! we call the FREQ procedure to obtain a crosstabulation of !-----------------!_----!------l-----~------!_----!------l-----~------ i frequency counts of AGE by SEX. After you submit these i: I [ l ! : !lACE commands, they appear on the LOG window, togethl'r ilii---------------[ 51.3&1 5'l.59: 59.591 IS.IIt: with a",Sugi-10-118 Sall Cates Polzin.txt
"Bringing Microconputers into a Small SAS! Software-oriented Computer Laboratory Gerald V. Tangren, Tree Fruit Research Center Washington State University easier to use Pascal to prograa the level INTRODUCTION: of work we require. SAS software has become the focus for the CONSIDERATIONS: data analysis systems for many facilities both because moat statistical procedures can be obtained through the system and Necessary considerations at our facility borrow from the inforMation center con- because the SAS systeM as a programming language is both easy to learn and power- cept, which has been widely discussed at ful to use. Therefore with the advent of this and earlier SUGI con£erencea. nicrocomputers with their own attributes the challenge becomes how beat to The advantages and disadvantages of SAS interface and complement the two. I compared to microcomputers are obvious. The SAS system provides an excellent aet would like to share our experiences with o£ statistical procedures, is a powerful such a challenge at a small research facility. but easy to learn applications language, and has the advantges of ita aainfraae ENVIRONMENT: location ,such aa larger a.aory and DASD space and faster execution tia.. The Our facility is an agricultural research disadvatanges are that accessibility can station devoted to the multi-disciplinary be limited whether from poor turn-around study of tree fruits. We are located in tiae in batch Mode, frOM the coat of its the center of the state about 150 miles mainframe location with CPU and other from both the population areas of Seattle mainfraae charges, or froa a restriction to the west and the main caMpus of Wash- on line availabilty into the aain£raae. ington State University at Pullman to the In addition its Ms1n£rsae location ~.Y east. A total of 9 university faculty actually overwhelm some potential users. aembers are present along with a staff of sbout 30 including 2 to 3 graduate stu- In comparison, the advantages of aicro- dents.",Sugi-10-119 Tangren.txt
"A QUADRATIC ProGRAM FOR DEl'ERMINING EFFICIENT FRJNTIER PORTFOLIO <X'MPOSITIQNS US= THE SAS LANGUAGE ALEX ANCKONIE III, THE GEXlRGE WASH=TON UNIVERSITY The second SAS facility of importance to this PURPOSE pa.per is a macro facility \\hich allCMS repetitive canputation of a series of SAS data Since the appearance of the saninal \\Urks of and TObint rnethcrls for cartp.lting the and/or carp.ltational steps. This macro facility MarkCMitz carq;x:>sition of efficient frontier p::>rtfolios will be discussed further in the section of this raper dealing with extended application of these have been describe:i by a mmber of authors including Martin3 and Francis and Archer~ The programs. p.l:q:ose of this paper is to present ~ versions of a quadratic program for detennining the For p1.ll1X)Ses of this paper, program one will be use:i to indicate the unconstrained program C<ll'I±X'sitions of efficient frontier p::>rtfolios and program two will be used to indicate the written in the SASS language which is widely available at corrplting facilities in the UnitOO. program for which only p:>Sitive asset weights are allCMed (constrained to lang pcsitians states. '!'he b«> versions of the program which only). Both of these programs have three major are presented cover the case where assets can be sections, an input section, a canputation held in lang and short ];X)Sitians without There are two constraint and the case where assets can on1y be section and an output section. held in long fX)Sitions (only y;:x:Jsitive asset inpct sections which may be used interchangeably weights) ~ Either program can be operated using with either of the two canputation sections historic price/dividend data, using historic depending upcn the nature of the inpct data as total yield data or using a variance-covariance will be discussed below. The two crnputation matrix and a yield vector (where these are sections are unique due to the rrore ccmplex detennin.ed fran either ex-p::>st or ex-ante ccmputations",Sugi-10-12 Anckonie.txt
"The following organizations participated in the survey: Coupling the low cost interactive power of microcomputers and the data Air Products and Chemicals Company analysis, and display Cornell UniverSity management~ capabilities of the SAS System is a Dean Witter Reynolds tantalizing possibility many SAS users Federal Reserve Bank of Chicago have long contemplated. Several GTE Laboratories organizations have been able to combine General Dynamics Corporation these capabilities and have built such Health Care Financing Administration systems. the interchange of However~ Hercules Chemicals information about alternatives and Intel International successful appt-oaches between users in Miami University this dynamic area has been quite Morino Associates limited. National Center for Health Statistics Portland General Electric Company In order to measure the effectiveness, Saga Corporation applicability, and operational Southland Corporation requirements of building Hybrid Systems U.S. Department of Justice which use the mainframe computational United Bank Services Company pOwer of the SAS System and the University of Rhode Island interactive power of microcomputers, Upjohn Corporation over fifty organizations who have shown \,>'eterans Administration an interest is such developments were Weyerhaeuser Company surveyed. The results of that survey and an analysis of its implications show what QUESTIONS hardware, software, and operational considerations are needed to best build Hybrid systems. This paper describes THIS OF PRIMARY PRODUCT OR SERVICE 1. the SUrvey questionnaire and presents an ORGANIZATION. analysis of the t-esults. <check only one) ._~ Banki ng, Fi nance, Credi t Manufacturing 4",Sugi-10-120 Trimble.txt
"II. The Tnrtnise and the Hare -- SAS Versl1s BMDP The intf"".rest and onstions that emerged in Onc!"" noon .<I. time a !!rnllp of f'lk.eptical 84 re~ardin~ nsa~e of SAS on Vax 11/700 SUGr stRtisticians decided to hRve a computer race. I the followin\! The ever slnw Rnd Bteady SAS f;tatistical nackage series machines oromoted investi\!ation. Three areaf; of concern are W'tS nit t ed Rg.<l.i nst the quick flnd conf ident BMDP examined: hmo7 does SAS comnare to BMDP in r/o Rnd stAtisticfll packRge. Since the SAS/VMS version CPU time, what condit inns canse machine 4.07 does not have PROC BMDP flvail.qble. this degradRtion when multinle users run SAS jobs, Rnd C0111PRrison was of interest to the Vax nsers. The how eff icient is the l1se of SAS data sets. Since December 1982 Vax version of BMDP was nsed. the Vax is very slow in r/o comnared to IBM machinef; and SAS is very he.qvilY based in r/o The following Btfltistical technioues were oner.qtions, we Rnticinated th.::tt SAS wOllld be the stndied nn both nRckRP';es: lineRr regressinn. tortnise and BMDP the hare in both real time and nonline.qr regress inn, balRnced flnd nnbalRnced CPU nerfnrmance. However. we Rll know how that RORI ysis of variance. clnster anal YBis, and fable ended. The stndies were comnarisons of discri111inant analysis. The consulting problems statistical nrocednres nsin\! SAS ven;inn 4.07 on 11sed to test the above procednres cover a variety a Vax 11/700 series with VMS. The viewuoint is of sample And v.qriRte sizes flnd come from real that nf a statistician and not 3 cOMpnter (or experiments. even a SAS) expert. problem has 33 regre~sion The linear observations ,qnd 4 v,qriables. Four different I.",Sugi-10-121 Booker Johnson.txt
"USER-WRITTEN 1/0 DRIVERS AND THE SAS SYSTEM FOR MINICOMPUTERS UNDER VAXNMS Thomas 8. Cole, SAS Institute Inc. INTRODUCTION THE VAX IMPLEMENTATION This presentation describes a new user-written feature of SAS software under VMS. This new As previously stated, the driver is accessed via feature allows the user to write 1/0 drivers for the external 1/0 facilities of SAS. This means use by the FILE and INFILE mechanisms of the files that are opened using the SAS FILE and DA TA step. With this featu re comes the INFILE statements and that are read and written capability of writing interfaces to external data using INPUT and PUT statements. The d,""iver base systems and other complex or unique file facility does not interface directly with SAS data systems that the DATA step is not designed to sets. access directly. The new FILENAME statement is the ""point of It should be noted that this user-written feature entry"" for the driver. In the FILENAME string, is NOT SUPPORTED by SAS Institute. It is instead of a file name you can reference a device provided as a convenience to sophisticated users driver by name and pass it parameters to be with the need to specialized data accesS used in accessing external data. structures or environments directly from SAS. The syntax for this is to specify a FILENAME Also note that this user-written feature is string that starts with the ""at"" sign, @, cu rrently on Iy available on the VAX version of character. This identifies the string as a driver the SAS system. The specifications of this des,ignation instead of a filename designation, feature may change with Version 5 of SAS and The ""at"" sign is immediately followed by a driver may function differently on other minicomputer file name and then any optional at'guments to be systems. used by the driver. WHY A USER-WRITTEN DRIVER? The driver is dyndmically loaded into memory in a fashion similar to the PROC dynamic loader. If already resident from a previous invocation, it is The idea of a use",Sugi-10-122 Cole.txt
"A QUALITY ASSURANCE SYSTEM FOR MANUFACTURING USING BASE SAS SOFTWARE ON A MINI-COMPUTER Sandra Heard, M/ A-COM Telecorrnn..mications Judith Mopsik, ORI, Inc. ll significantly less than a IIcanned pack- Quality Assurance - making sure that age, which the in-house MI~ staff h~d a product meets a certain standard of been unable to implement dur1ng the SlX reliability - is of great importance to previous months. As more procedures on everyone. From the dependability of the the plant f""loor are automated (e.g. data office products we buy to the safety of entry using bar code readers) at MIA-COM, the cars we drive, we depend on the the original system is being expande? integrity of the quality controls that The following topiCS will be covered 1n are built into the manufacturing pro- the sections that follow: cess. Traditionally, the measurements of reliability and quality have been o A manual system for Quality Assurance performed manually, and a lot of paper o Goals of an automated system (i.e. forms) was generated to keep track o The SAS system on a mini-computer of the assembly line production or the o using the SAS system in manufacturing manufacturing process. The integration applications of microprocessors and minicomputers on o Expansion of the system beyond its the Manufacturing floor is making it initial implementation possible for paper forms to be eliminat- o Future plans for automation ed. Putting production status on an on-line data base is making it possible for Management to determine more quickly where production problems occur and what corrective actions need to be taken. The result of this is realized as cost savings. The conversion from manual procedures to automated processing involves data A MANUAL SYSTEM FOR QUALITY ASSURANCE entry using a computer terminal or key- punch machine, data base management, In the Summer of 1983, the manager of computerized data editing, statistical Quality Engineering at MIA-COM Telecom- analysis and report generation.",Sugi-10-123 Heard Mopsik.txt
"An Environmental Data System using SAS Software on the VAX 11/780 Dewey A. Blaylock and E. Larry Salvo, Computer Sciences Corporation INTRODUCTION 2. Data supplied in a variety of different formats including raw and I work for the Computer Sciences processed data files from tapes, commu- Corporation under contract to the Envi- nication networks and interactive ses- ronmental Protection Agency to provide sions. computer support services to the Chesa- peake Bay Program. The Chesapeake Bay 3. Data which covers a large geograph- Program is dedicated to the restoration ic area. The Chesapeake Bay drainage of water quality and living resources in basin drains portions of six stateS and the Chesapeake Bay. The Program is coor- the District of Columbia. The Bay it- by the Environmental Protection Agency self is over 200 miles long, 30 miles and operates under cooperative agreements at its widest point and 4 miles at its with other Federal Agencies and contracts narrowest point. with many State Agencies which partici- pate in research on, and management of Other features that had to be considered the Chesapeake Bay. in the development of the system included a wide variety of data types including One of the principal goals of the biological data, flow data, metals data, Program is the establishment of a compu- physical data, 'sediment data and water ter center dedicated as a repository for quality data; several data management data concerning the Bay and to make this concerns including documentation, file data available to research and management organization, data formatting, data veri- studies of the Bay. In late 1983, the fication and data storage and retrieval; Program acquired a DIGIAL VAX 11/780 and and last of all a number of different the SAS Institute Inc.'s base SAS and uses for data including mapping, graph- SAS/GRAPH software products. With these ics, modeling, resource planning, data two tools the Computer Sciences Corpora- reporting, and statistical analysis. t",Sugi-10-124 Blaylock Salvo.txt
"ati College of Medicine A comfile can be created either directly from the ABSTRACT SDF, or from worksheets, which are two dimen- sional arrays of data items. We use a worksheet, The General Clinical Research Center (GCRC) a file which, for our purpose, contains a dif- at University Hospital in Cincinnati, Ohio, is ferent data item in each column; and each row one of 7S GCRCs in the country, 28 of which have access to the CLINFO Data Management and Analysis contains all data items for a given subject at a specific time or visit number. At the top of System. In addition, there are another 10 CLINFO each column is a label which identifies the data sites worldwide. CLINFO was developed specifi- items, and at the beginning of each column is a cally to aid clinical investigators in a research label which is the patient identifier. The environment and provides for data entry, manipu- worksheet is converted into a comflle (comfile.9) lation, and simple analyses. Since CLINFO was using the CLINFO retrieve activity. The form of being run on a VAX-11/7S0, we decided to augment comfile.9 is displayed in Figure 1. The response CLINFO with the base SAS® product to aid sta- file (SASRF) which creates the comfile is pre- tisticians who undertook more sophisticated ana- sented in the Appendix. lyses of existing data bases. We received the test version of the base SAS product under VMS in FIGURE late 1983 and developed a simple procedure to convert CLINFO files into a form which could FORM OF",Sugi-10-125 Khoury Laskarzewski.txt
"pedol""ms ABSTRACT calculations and writes many observations to a SAS data set. Often a user has a choice of two or more STATE is a progt""am that pet'forms SAS programming styles that will accomplish a task I/O, character manipulation, and equally well. Normally, the style chosen so rts. depends on the user-'s previous exper'jence with some other programming language. However, the is a DATA step that reads input IF chosen style may not necessarily be the one that from a file using pointer movement pI""oduces the most efficient SAS code internally. and does a complex 1F/THEN. This paper"" presents an overview of how a user's RECODE is a DATA step that sets a lat'ge SAS progt'am is optimized in the DATA step. data set (1828 observations) and Examples of vat-jous SAS programming techniques does a recode of 50 variables are presented, along with the style that gives within each obset·vation. the user the optimal SAS code. POINT is a DATA step that does 5000 random access reads of an input THE OPTIMIZER SAS data set which contains 2000 observations and 51 variables. SAS source code is input to the compiler, which emits intermediate code that is executed IMPROVING YOUR DATA STEP interpretively. The code emitted is targeted for a stack-oriented machine. I n this section we present six categories of Given the SAS source statement: statements used in the DATA step that take X A·B advantage of the work done by the peephole optimizer. For each category, we present two example DATA steps t",Sugi-10-126 Dineley Beatrous Colbert Tindall.txt
"functions of a SAS procedure are reading SAS data sets, performing data analysis, printing results, and creating other SAS data sets. The Writing a SAS procedure requires a certain level infot'mation and pt'ocess contt'ol required for' of programming skill. The procedure writer these basic functions is available within the SAS needs to have a clear' understanding of data Supervisor. structures, pointer manipulation, and dynamic storage allocation, as well as a waf-king The Supervisor is the part of the SAS System knowledge of the SAS System. Although which maintains over'all control of system oriented toward SAS users in the minicomputer processing. Therefore, your procedure will need environment, most of the ideas presented here to interact with the SAS System Supervisor. For will apply to other users as well. The intent of that purpose, there is a set of routines, called this paper is not to explain the technical X-routines, which act as an interface into the information and detail requi red to write a SAS Supervisor. For example, to read a SAS data procedure -- that information is available in the set your procedure might call XOOPEN. To SAS Programmer's Guide. Instead, the attempt print a page of output you might call XPAGE. is to construct a conceptual framework upon The knowledge of where and when to call a which the programmer can build. particular X-routine will become more clear as you begin to understand the internal design of SAS procedures.",Sugi-10-127 Betancourt.txt
"el Hill bhoth the previously existing methods and with ABSTRACT t e methoas suggested here. Inherently nonlinearizable models arise nat- REVIEW OF EXISTING METHODS urally in phamacokinetics. econometrics and many Multivariate Nonlinear Re ression other applications. If more than one measure- Allen (1967, unpublished dissertation for- ment of a variable is made on each subject. then mulated a general model for dealing with multi- some account must be taken of correlation be- variate nonlinear models. His interest and tween the repeated measures. Possible methods emphasis was for the analysiS of growth curves can be characterized by their assumption about with nonlinear expected values. He described the error covariance structure. Estimation two methods for such estimation. One method presents few problems for any existing method. essentially minimizes the determinant (gener- However, hypothesis testing. particularly in alized variance) of the residual covariance small to moderate sample sizes, is problematic matrix. and the other essentially minimizes the for most methods. Suggestions are made to help trace of the residual covariance matrix. Under the analyst select a method appropriate for the a normality assumption the first method provides particular nature of the model and the covari- maximum likelihood estimates. In general the ance structure. two methods yield distinct answers and are not MOTIVATION equivalent. Both methods give estimates shown Inherently nonl inear mode",Sugi-10-129 Muller Helms.txt
"USING PROC LP TO OPTIMIZE A COt~MON STOCK PORTFOLIO Raymond A. Gibley Southeast Denver Investment Club For the new investor, it is often difficult to necessary to generate an optimal portfolio can be found in SAS (6) or in Poole (7) for micro- make prudent choices about the composition of a common stock portfolio. This;s particularly computer applications. These results will true of those investors who brave it on their present us with approximate solutions whereby own without the research advice of a commercial senSitivity analysis can be performed to assess stock broker. What issues should one consider, the impact of portfol io beta on expected profit how much risk is involved, and how many shares levels. Perhaps a simple example at this point of each stock should be purchased? These are will help clarify the present discussion. only a few of the many questions that could be raised by the individual investor or practicing Suppose for the sake of argument you have investment c1 ub for that matter. $15,000 in cash that you are considering in- vesting in the market for a five year time Fortunately, one""can find some immediate rel ief period. Being of a conservative nature, you on the subject by consulting The National Assoc- decide to limit your search to stocks rated 2 ia.tion of Investment Clubs (NAIC), Value Line, in terms of safety in the Value Line invest~ent The American Association of Individual Investors survey. Furthermore, you elect to scan the (AAII), or one of the other investment services list entitled ""High 3- to 5-year Appreciation that exist, (1-3). NAIC, for example, offers P!,Jtential ll for !,)ossible candidates. These some excellent criteria for buying and selling stocks typically include Value Line narrative a stock based upon: similar to ""These shares are a solid three to five year vehicle for total returns."" To keep o sales growth rate the example simple, assume that your preliminary o earnings growth rate search turns up a list of seven stock",Sugi-10-13 Gibley.txt
"SAS %MACROs. This paper describes SAS® %MACROs which In Section 2 we discuss the various techniques create design matrices for nominal, ordinal, or mixed currently available in SAS for categorical data nominal-ordinal log-linear models, and fit the resulting analysis and compare them with the typ~ of ~odels design matrices using the Newton-Raphson algorithm. which can be fit with our macros. SectIOn 3 mtro- We compare these macros with facilities currently duces ordinal models and their basic characteristics, available in SAS, and discuss the ba.o;ic characteristics while section 4 gives the syntax, options, and restric- of ordinal models. An example is given using admis- tions of our macros. In section 5 we use these macros sions data for a large research university. to fit an ordinal model to the admissions data intro- duced above. To provide SAS users with greater flexi- bility in analyzing ordinal categorical data, we briefly 1.",Sugi-10-130 Smith Caldwell.txt
"page, with the pages sequenced from most to SAS code is presented which provides an least explained variance. On each page the alternate reporting scheme for factor analysis total explained variance and the variance output. This alternate format is intended to be explained by the factor is reported. Variables more ""user friendly""; that is, directly inter- which load on that factor are listed, with An pretable by the non-technical analyst. labels and factor loadings, in descending order example is included for review. of the factor loadings. The analyst can choose the loading level to be utilized. Any other",Sugi-10-131 Bonner Hancock.txt
"rn COI'I'IIlKJJS SCAlE mm l\NALYSIS III\CRCS R:R PAIRED CATI'lnUCAL 'Ihanas E. Bradstreet Merck Sharp and Dohme Research Laboratories west Point, PA 19486 ABSTRl\Cr of the two test statistics, hON the data SAS' Three /Beros (M:NMRl, M:NMR2, w(SRK) is input into the corresponding SAS Macros are presented for computing M:Kemar's and ~ction 4 il- and the resulting output. Wilcoxon's Signed Rank test statistics for lustrates these methodologies with four paired data analysis. 9':me cannone uses example clinical trials. Statistical of these test statistics are in comparing references and the SAS code are attached. within-group change fran baseline and be- 2. WJ:I,C(J{CN SICNID RANK ""lEST STI\TISTIC: tween-group crnparisons of paired data. MIlCRO WCSRK Each macro accarrnodates missing values, This SAS macro calculates the ~lcoxon zero differences, and small sample sizes, Signed Rank test statistic for comparing and references each test statistic to the the diffeences (Dj) canputed fran matched appropriate reference distribution. pairs data. MiSS1ng and zero differences Counts of data are displayed. Illus- are removed prior to ranking. lIDy tied trative examples are provided. observations are first assigned the lowest, then the mean and subsequently, 1. :nmu:ucTICN the highest of the corresponding ranks In the conduct of clinical trials, (Ri) · often times the efficacy of only two ~ treatments is carpared. Q1e of the major '!he input data shoold contain a variable objectives of the trials is to demonstrate representing the differences between the that (i) an active therapy is ""better"" matched pairs named ""0"" as part of an in- than a matching placebo as judged by sane put data set called ""01"". accepted criteria or (ii) to show that one ~ active therapy is superior to another '!he frequencies and corresp::mding percent- therapy or in sane cases, is ""as gcod as"" ages of ,missing, zero, negative and posi- the other. tive differences are displayed followed by TWo major compari",Sugi-10-132 Bradstreet.txt
"OPTIMAL ALLOCATION FOR THE (OMPARI.SON OF TWO PROPORTIONS David C. Huang, The Upjohn Company I. INTRODUCTION VW)=p\Q\in\+pZQ 2 1 n 2 The determination of sample size needed in a is minimized when study for testing the difference between two pro- portions requires the following three quantities. a. the chance of concluding that the two proportions differ when they are In fact the same (a, Type I error). the variance of R II. VIR)= IPll p,)'{q/ (nlpl)+q2!(n:f~} b. the chance of declaring that no differ- ence exists when the true difference is non-zero (S, Type II error). is minimized when the smallest difference which the experi- c. menter would like to declare significant. Two meaningful comparisons of the two proportions in the study are (i). D = P,- P , and (ii). Tables 1 and 2 present the percent- H = p,!p;. For example, the comparison D can be age increase over minimum in the stan- viewed as the difference between two success rates dard deviations of D and R, as a function and the companson R has an intuitive appeal since of F. For specified values of P, and p, (I.e., it seems reasonable to say ""the success rate is the proportions of individuals wh~o re- doubled"" or ""the rISk of side effect is halved"". spond in Group 1 or 2), there exist many Optimal allocation strategies for sample size based sampling schemes which are far from the on different criteria can result in different recom- designated optimal value of F but yield mendations. Armitage (1971) proposed a study nearly optimal precision of D and/or R. design based on a criterion that the estimate of D or R has a small standard error. Brittain and Optimal Precision for Rd 2. Schlesselman (1982) Introduced a study design criterion--mlnlmlze the variance of D or R with The relative difference, Rd, denotes respect to F, the fraction of individuals who are the proportion of individuals among sampled from Group 1. those failing to respond to the first treatment (i.e., Group 1), who would be In this paper, a stud",Sugi-10-133 Huang.txt
"pIer to use because of such features as: the built-in SAS functions (POISSON and PROBBNML) This SASe routine computes the minimum sample used to compute the probabilities of acceptance, size and acceptance numbers required for single and PROC's (PRINT and PLOT) used for printing attribute plans which are based on the binomial, and plotting the output. or Poisson distributions. Using a modified search procedure, the program also determines Briefly stated, the search procedure is as the operating characteristics and average outgo- follows: ing quality curves designed to meet the desired 1. The user provides the probability distribu- protection levels for both producer and con- tion type (Poisson or binomial); acceptable sumer. Receiving inspectors who must inspect quality level (AQL); probability of accep- shipped lots of goods may utilize this routine tance given the AQL (1- IX. ); rejectable interactively without having to resort to pub- quality level (RQL); and the probability lished tables, graphs or formulas found in most of acceptance given the RQL (.6 ). acceptance sampling plans. Program description, 2. The sample she (n) and acceptance number listing, and examples are provided. (c) are initialized to 1 and 0, respectively.",Sugi-10-134 Alexander.txt
"An Enhanced SAS Macro for Testing Homogeneity of Variance Dennis W. King, University of Arkansas John H. King, University of Arkansas Kevin C. Thompson, University of Arkansas INTRODUCTION 2 n2- 1 2 nI-l GMSE"" [ (sl) In Analysis of Variance, model (s2) error terms are assumed to be distribu- ted normally with a mean of 0 and variance 02. 2 lJ 1/ ( N-r We then assume that the estimate nr - ) for this error variance also estimates ( s r) the variance within each factor level to be tested using an F ratio. which is The validity of this F ratio is then and has indicated that upon division dependent on the fact that of T by each factor level error variance, and thus each factor level variance,;s in --~--JI·. : fact equal. The applied statistician is faced with verifying this equality -: -l with some sort of statistical test C and then, if equality is rejected. N-r, nj-l 3(r-l) J suggesting some transformation of the 1 1 '"" data to stabilize these variances. In more complicated designs and mixed The distribution of the statistic TIC models this may become quite a tedious task. A split plot design will produce is well represented by that of a Chi Square distribution with r-l degrees 8 sets of factor levels, many of whose sums of squares may be used as the of freedom. However, Box (1949) has shown that the distribution of the denominator in an F ratio. Hence, the validity of the variance equality statistic may be of interest in some or all of the sets. A SAS Macro, VAREQ, has been developed for use by the stati- f 2T F stician to test the equal ity of va- riances in each of these sets and sug- gest appropriate transforms to correct variance inequal ity. The Macro is designed to run in CMS SAS82 and OS may be approximated by an F statistic SAS82. with f1 and f2 degrees of freedom where (r "" ( r + 1)/C2, fl 1), f2 TEST STATISTICS In fact, this b ""f2/(1 C + 21f2). approximation is shown to be closer VAREQ performs three statistical to the exact distribution calculated tests f",Sugi-10-135 King King Thompson.txt
"FITTING LOGLINEAR MODELS USING SAS SOFTWARE Weichung J. shih and Amy Ko Merck Sharp & Dohme Research Laboratories (1 2); 1. INTRODUCTION LISTRI (1 3); LISTR2 The SAS program LOGCAT fits hierarchical (2 3); LISTR3 log linear models to complete multidimensional The number of brackets (NBKS =: 3 in the contingency tables as discussed in Bishop, Fienberg & Holland (1975) and Fienberg (1977). above example) used to specify the model as The iterative proportional fitting (IP1o') well as the number of categories (Cl C2··.Cd) algorithm is used in the program to obtain for all the variables in the data set are the maximum likelihood estimates (MLEs) of the only two additional inputs required from the expected cell frequencies. The IPF algorithm user. is described in the above references and also For ANOVA-like model interpretations (see in Haberman (1972). The program writing is an li'ienberg, p. 39), LOGCAT is restricted to fit application of the new SAS macro language (SAS hierarchical loglinear models for which Institute, 1984). higher-·order u-terms may be included only i f After obtaining the estimated expected the related lower-order terms are included. cell frequencies, LOGCAT computes the likeli- This restriction to hierarchical models allows hood ratio, Pearson, and the Freeman--Tukey the use of an iterat.ive proportional fitting chi--square statistics for testing the procedure, due originally to Deming and Stephan goodness-of-fit of a specified loglinear (1940), for calculating the maximum likelihood model. The corresponding degrees of freedom estimates of the expected cell frequencies when and the central chi-square probabilities of the the observed counts have been generated by one goodness-of-fit statistics are also given. of the following sampling schemes: Poisson, LOGCAT also provides a table with observed Multinomial, or Product-multinomial. Interpre- counts, estimated expected frequencies, and the tation of a model depends very much, among simple, standardi",Sugi-10-136 Shih Ko.txt
"user will generated using a SAS program, including SAS make use of whatever tools are available, and macro code. (They were then pri nted on a likely will not make much effort to use tools Xerox 9700 printer.) A commented listing of whose existence or location of documentation the program follows the main portion of the is unknown. There are a number of routines paper. A number of interesting techniques are illustrated: (l) Dealing with the enclosing (functions and subroutines) available in the SASR System that are not documented in the quotes of parameter values when using implicit SAS User's Guide and whose documentation is (statement-styl e) macro i nvocati on. (2) scattered- elsewhere. This paper gives the General techniques for using SAS for text programmer or user a concise list of these generation including dynamic centering, routines, thus making their use much more special character generation and conditional likely. under1 ining. SAS and SAS Communications are registered Most of the functions and subroutines trademarks, and SAS/ETS and SAS/OR trademarks available to writers of DATA and PROC MATRIX of the SAS Institute, Inc., Cary, NC. steps are documented in the two volumes of the SAS User's Guide, 1982 edition. However, a *The author is an independent consultant variety of other functions and subroutines are currently subcontracting through Analysts documented only in other user's guides (e.g., Int'l Corp. The work on this paper was done SAS/ETSTM), techni~al repo",Sugi-10-137 Frank.txt
"PROC accesses micro a SAS dataset. Prior to approval of a benchmark survey Archival format and creates for Federal Reserve System consumer credit The user enters: components, questions arise as to how much = SASNAMEj error can be expected in the estimates. The PROC ARCHIVE IN file OUT amount of error depends on the sample size, stratification, and method of estimation. ITEMS list of names. SAS Macros were written to use Neyman alloca- tion over a number of possible sample sizes One observation is produced by each bank from and produce standard errors using ratio esti- the quarterly Report of Condition file. For our application, the list of names contains mation. financial items: automobile, revolving, Background mobile homes, other and total consumer credit as well as total assets. Also we select The Federal Reserve System collects con- structure items: numeric bank identifica- sumer credit data from a monthly sample of tioo, bank name, city, state, district number This gives the data about 300 insured commercial banks. and membership status. Reporting detail includes 'auto', 'revolv- needed for: ing', 'mobile homes' and 'other' credit a) stratifying the universe categories. Estimates of the corresponding aggregates for the 14,500 bank universe have b) computing standard errors been produced by separate ratio estimators, c) identifying information for an even- using Report of Condition benchmark data tual sample. which is collected quarterly from the uni- verse. However, cha",Sugi-10-138 Slowinski Grunwald.txt
"Enhancing Printout of SAS Data Sets Using Macros Gary G. Vair, IBM Corporation PROC PRINT ABSTRACT. Using PROC PRINT to display this data set is a Techniques for improving printouts of SAS 1 data natural first choice. As can be seen, this output sets using macros are discussed in this report. is for all practical purposes, unreadable. Even though this printout has been limited to 48 char- Data sets with large fields such as a 200 character field or an array of 200 character fields, II wrap acters in width for this report, a 132 width printout ;s really no better. The 200 character around ll when using PROC PRINT, making reading of the data very difficult. This paper presents a variables have been truncated and the variables are grouped on the page in such a manner that macro which greatly simplifies the printing of reading of a single observation ;s very difficult. data in column format when used with PUT state- ments in a DATA step. DEPT DATE OBS NAME 884 1 VAIR 06123/84 DATA SET EXAMPLE 844 VM USERS 2 07/11/84 844 GENERAL USERS 3 07/11/84 543 USER X The macro presented in this paper can create from 4 11116183 1 to 9 columns, each containing 1 to 999 variables. BUILDING FLOOR 08S NAME The examples included in this report are based on a SAS data set that contains 10 variables. 2 of 001 3 1 VAIR which are character variables of length 200 de- 001 3 2 VM USERS fining a problem for a problem report, and 3 of GENERAL USERS 001 3 3 which are character variables of length 200 docu- 299 1 menting the solution to the problem. The follow- 4 USER X ing is the PROC CONTENTS of this data set. PROBLEM OBS CONTENTS OF SAS DATA SET DATA.SASPRINT The audience is falling asleep!!!!! 1 OBSERVATIONS=4 CREATED BY CMS USERID VAIR Teach a new user how to do their work us 2 How do I as a user control my data, proc 3 AT FRIDAY, JULY 13, 1984 BY SAS RELEASE 82.3 4 How do I create letters and documents? SASPRINT GENERATED BY DATA PROBLEM1 FILE=DATA OBS ALPHABETIC LIST OF VARIABLES 1 user, e",Sugi-10-139 Vair.txt
"ENHANCEMENTS TO SAS/OR'"" SOFTWARE Marc-david Cohen SAS Institute Inc. Cary, North Carolina 1. Introduction In conjunction with the flexibility gained by maintaining dual feasibility, the procedure gives the user considerable control over rules for selecting the branching variable and the next This paper presents an overview of the node to explore in the branch and bound tree. enhancements to the SAS/OR software. We Moreover, the interactive capabilities allow the user the option of modifying the node and assume the reader is familiar with the 82.4 variable branch selection rules during the course release of the SAS/OR product. In the beginning sections, we discuss the changes to the of the solution process. mathematical programming capabilities of the product. This includes enhancements to PROC Finally, PROC LP provides the user with a LP. We continue the discussion of mathematical mechanism for stopping the iterative process programming by introducing PROC TNETFLOW, a midstream, saving the current best integer new procedure for solving network flow problems solution (if any), and saving a copy of the with side constraints. In the final sections we current tree of active problems. Then, the user present the new capabilites in the area of project can restart the process continuing iterations with management a discussion of the where they were left off. As a result, not only enhancements to PRQC CPM. We also introduce PROC GANTT, a new procedure for producing can the heuristics used for searching the tree be modified mid-solution, but the tree can be hand Gantt charts on printers and high resolution pruned. graphic devices. 2. PROC LP Enhancements An example illustrates the use of the integer programming capabilities. I nteger variables are identified in the SAS data set that contains the model. The type variable should contain the PROC LP has been improved in several ways. keyword INTEGER in an observation. Those variables that have non-zero and non-missing The most",Sugi-10-14 Cohen.txt
"aracter of a particular font is called a character It is widely known t~at laser cell. Each cell is graphically printers produce high quality displayed on the terminal as a string printouts. However, they can also be of black dots on a white background. used to print special characters which The cell is then changed by rearranging are self-designed. Therefore, with the dots. For instance, the letter ""A"" this capability one can produce more is shown below. professional looking tables by highlighting specific words in TITLES, LABELS and individual data points. In addition, one can alter SYMBOL, FORMCHAR and LABEL options to greatly enhance the appearance of PRoe TABULATE, PROC FREQ, PROC PRINT, PROC CHART and PROC CALENDAR. BACKGROUND Sterling-Winthrop Research Institute recently bought and installed a Hewlett-Packard (HP2680A) laser printer. This laser printer is currently used as the primary output device for the HP3000 and the IBM3033. Two additional pieces of software were also purchased. These were Interactive Design System's Character Font and Logo Design (IDS/CHAR) and Interactive Formatting System (IFS/3000). IDS/CHAR allows for the simple self-design of character fonts, logos and other graphics. with IFS/3000, one can specify which character fonts are to be used to print information, associated with a IFS/3000 environment file, on the laser printer. In regard to my own personal experience, I have never liked the appearance of tables produced by certain SAS * Procedures",Sugi-10-140 OSullivan.txt
"0000; ""oPUT ERROR: PARAM MUST BE A NAME. Programming in the SAS® macro language, ""oPUT VALUE SPECI FlED: ""PARAM; like other computer languages, is more efficient °oLET ERROR::: 1; after' a library of utilities that per'for'm commonly (~ENo; done tasks is compiled. The macro language does not explicitly give the user the ability to write library subroutines or functions, however it is possible to wr'ite macl'Os that can subsequently be The macI'o facility does not provide such used in other macros as if they wer'e functions or functions, but it is fait'ly easy to write macros subroutines. Such macros should contain no that will check par'ameters. This poster will generic SAS code so that they may be ""called"" present macros that look like macro functions from anywhere. This poster will illustt'ate this that can be used to check for all of the common capability with six macros that can be for'ms mentioned above, and can be used like the °oINCLUDE'ed and then used as if they were example above. These ""functions"" resolve to a 1 macro functions. These ""functions"" check their (TRUE) if the argument is valid and 0 (FALSE) arguments, which will typically be the parameters otherwise. In addition a macro called °oREPLACE of the calling macro, to see if their value is a that looks like a macro function, and gives the valid SAS name, SAS variable list, dataset name, macro language a convenient way to change only integer, signed integer, or floating point part of the value of a symbolic va",Sugi-10-141 Kuhfeld.txt
"yees. Designed for a corporate Data to be processed comes from environment to determine health trends and potential health many geographical Sites, tagged by problems among workers. and to location and date. Data is processed in one of the following provide employees with specific methods: personal guidelines to improve their health. over 300 parameters · Questionnaire data is of health are analyzed. Health keypunched and provided on profile data, including personal information, medical history, tape; no laboratory data current symptoms, medications. use required; of alcohol and tobacco, diet and exercise and many other items are completed by the employee on an · Questionnaire data is annual basis. This data is keypunched and provided on combined with a physician's tape; laboratory data is provided e~amlnation. blood laboratory work- on second tape by up. electrocardiogram. x-ray. vision and audiometric tests plus laboratory contractor. occupationally-related tests to Once both tapes are received and establish a comprehensive databank logged, a Merge/Edit program is for each person. run. The merge phase sorts the file into Social Security Number The software, dependent upon order. and merges the lab data tables and computation formulas, with the questionnaire data; the relies extensively on the use of edit phase prints out records for macros. It is well structured to allow for easy update and which no match was found. Corrections are entered into a Fix revision. Computations",Sugi-10-142 Taylor.txt
"MORE EFFICIENT nATA STORAGE WHEN PROC TRANSPOSE IS liSEn FOR OISPLAYING THE OUTPIlT Lynn T. Julian, The Upjohn Company Donald n. M. Tong, The Upjohn Canpany a variable for weight at each time point ;s INTROnUCTIO~ needed. This method greatly rerluces the for number of variables needed and eliminates the Several different approaches are used problem of storage being wasted. A vertical storing clinical drug trial data in SAS® data set will have more observations, but no data sets. One approach called the IIhorizon- extra variables and no additional storage tal method stores all of a patient's data in U space are required to handle unscheduled one observation and di stinguishes between visits. Refer to Figure 2 for an measurements taken at different times by illustration of data stored using this attaching a sequence number at the end of the t;me~ For example~ WGTO~ WGT7, and method. The variable ETIME (elapsed variable name. WGTl4 are variables representing weight at represents the time in the study. day n, day 7~ and day 14. However~ in One objection raised against vertical data studies where the patients are seen almost sets is that listings of them are not in an randomly rather than adheri ng to a prearranged schedule of vi sits, it becomes acceptable format for reporting purposes. A necessary to add more and more sequence patient's data is printed on several lines numbers to represent the length of time the instead of one. It is more desirable to have patient has been in the study. This approach a patient's data displayed on a single line soon becomes very cumbersome and tedi ous, as of a report in chronological order. Then, well as wasteful of storage space due to data can be monitored to find errors and variables which have missing values for most trends in the data. This reporting format patients but have data for a few. For can be easily created by using PROC TRANSPOSE on the vertical data set~ letting the time example, 100 patients are enrolled in a study an",Sugi-10-143 Julian Tong.txt
"SAS ® MATRIX ALGORITHMS FOR THE RECOVERY OF INTERBLOCK INFORMATION IN LATTICE AND INCOMPLETE BLOCK DESIGNS Paul L. Cornelius, University of Kentucky **1, DRIVER PROGRAM MUST SET UP DATA SET DS 1 The algorithms -are identified as follows: CONTAINING IDENTIFICATION VARIABLES GROUP, BLOCK AND TRT AND THE RESPONSE VARIABLE Y. 1. Algorithm SASICBR - Analysis of incomplete TRT MUST BE A CHARACTER VARIABLE. IF TRTS block designs with blocks arranged into ARE DESIGNATED AS INTEGERS AND THERE ARE replicates or groups of replicates (i.e. MORE THAN 9. THE FIRST 9 SHOULD BE STORED resolvable or a-resolvable designs as AS CHARACTERS 01. 02 ETC., IN ORDER TO MAKE defined by Clatworthy, 1973). 2. Algorithm SASICBN - Analysis of incomplete THEM SORT PROPERLY. DRIVER PROGRAM NEEDS TO SPECIFY NUMBER OF REPLICATION GROUPS block designs with blocks not arranged into (NGROUP) (=NO. OF REPLICATIONS, NREP, FOR replicates or groups of replicates RESOLVABLE DESIGNS. NGROUP = NREP/ALPHA (nonresolvable designs). FOR ALPHA-RESOLVABLE DESIGNS.). NUMBER OF 3. Algorithm SASICBL - Analysis of ""Latinized"" REPLICATIONS (NREP), NUMBER OF TRTS (NTRT), designs, i.e .· incomplete blocks with com- plete replicates or groups of replicates NUMBER OF INCOMPLETE BLOCKS (BLKNO), AND orthogonal to blocks. THE BLOCK SIZE (BLKSIZ) IN MACROS. ALSO A MACRO SPECIFYING THE VALUE OF PRTVAR MUST BE 4. Algorithm SASLAT2W - Analysis of tt-Jo- INCLUDED. SPECIFYING A NONZERO VALUE IF THE restrictional lattices (lattice squares and VARIANCE-COVARIANCE MATRIX OF ADJUSTED lattice rectangles). MEANS SHOULD BE COMPUTED AND PRINTED, ZERO SASICBR is the method of analysis (with a OTHERWISE; The algorithm checks whether NREP*NTRT = few feasible shortcuts) described by Cornelius BLKNO* BLKSIZ but does not check whether (1983) for one-restrictional lattices with these constants agree with the data input. slight modification needed to make it handle any nor does it make any other checks on whether resolvable or a-resolvable design.",Sugi-10-144 Cornelius.txt
"PRoe ELPRINT is similar to PROC PRINT. Individual values can be footnoted with user defined footnotes. Two data sets are read - a print data set and a footnote dictionary. The symbol of a marked variable value is matched with its definition and the footnote is printed on the bottom of the print page. If requested, the procedure will mark statistical outliers - row or column outliers or interaction outliers (Bradu-Hawkins, 1982). The outlier detection methods are robust to presence of multiple outliers. 0.0",Sugi-10-145 Young Fraction Skrzynecki Shotts.txt
"The University of North Carolina at Chapel Hill when they are displayed by a call to macro Abstract PRINTHEM, the independent variables are in alphabetical order as in Figure 3, which shows The program presented here was written in the SAS data set created corresponding to the response to the request from researchers to input lines shown in Figure 1. A call to macro manipulate the output from PROe LOGIST in SAVETHEM could optionally be used to save the various ways. Many features of the SAS macro collection of data sets in a SAS data base for language were implemented to make this possible later manipulation. and to make the program flexible and easy to use. The user first directs the output from his PROC LOGIST run to an OS data set with PROC How the Program Can Be Used PRINTTO. The post-processor program extracts, from the saved output for each MODEL statement, The post-processor program can be used not the names of the independent variables, the beta only for summarizing the output from PROC LOGIST values, p values, means, standard errors, and in a rearranged form, but, more importantly, for other data and prints them in a rearranged saving the means, standard errors, beta values, summary format. The statistics extracted by the or p values from PROC LOG 1ST if they are needed program can be saved in a SAS data base for for later manipulation or as input to another later manipulation, or they can be passed to a program. Figures 4 and 5 show examples of its subsequent progr",Sugi-10-146 Stone.txt
"SAS® GRAPHIC MACROS FOR PRODUCING 2-DIMENSIONAL AND 3-DIMENSIONAL STEP-GRAPHS Akos Felsovalyi, J.e. Penney Company, Inc. INTRODUCTION x -x Let data set A have variables X and YI--YN 2 1 (N);I). We can request a line graph (Figure 1) Method 2: x .. ------- with the following commands: Xl= o1 2 PROC GPLOT DATA;A; x -x PLOT (YI--YN) * X / OVERLAY; i ; .. 1 SYMBOL I;JOIN; x' 2 SAS graphic The HIST2D. HIST3D and HIST3DM macros presented here transform data set A such x -x 2-dimensional that the new data sets yield k k-l (Figure 3 and 4) (Figure 2) and 3-dimensional + _ _ _ __ =X Xl step-graphs. k k k 2 The number of observations in data set A is and the number of Y variables is n (n=N). (Xl is the midpoint of x and x where i ; i-I %MACRO HIST2D i;I .... k-l) X and Data set A contains n functions between Parameters of HIST2D: YI--YN. The functions are: YN; F (X) Yl ; F (X) ..... DATA ; SASdataset specifies the input data 1 n set. Default is _LAST_. into OUT SASdataset specifies the output data Macro HIST2D transforms those functions set. Default is OUT. step functions: ... YN ; S (X) ST ; n Yl ; S (X) n is 0 if data are sorted ~ ~ n with no ties, otherwise n 1 is 1. Default is 1. ZRO ; n n ;s 0 if no border is The domains of functions Fare desired, otherwise n is 1. Default is 1. X,X~ ··· ,X METHOD ; n 12k specifies the method to The domains of functions S are define the domains of the step functions. See above. Default is 1. Xl , Xl , Xl, ··· , Xl x= 012 variable specifies the x variable. k HIST2D has two methods to define Default is X. Y1 variable specifies the first y x' · variable. Default is Y. YN variable specifies the last y variable. Default is Y. Method 1: m X =X - In order to obtain the step-graph (histogram), o 1 the user needs to run procedure GPLOT using SYMBOL statement with I;JOIN. The number of observations in the output data (where set is 2*k if the IIno border ll opt i on iss pe- -x cified (ZRO;O) and 3*k+l if the ""border"" i-I m;------ option is specifi",Sugi-10-147 Felsovalyi.txt
"xt' When the apriori researeh interest is be ob.servations Let ~ ~e the overall mean testing for trend in a completely randomized Tj be the treatment effec.t of_ j th design, the Jonchkheere-Terpstra non- parametric test is usefuL It is used -to population test the hypothesis that three or more Eij be the error term treatments are in a definite order, e.g., the second is better than the first, the third The assumption is that the observations better then the sec:ond. are independently sampled from the same continuous distribution. A SAS MACRO has been written to Xcj = "" + Tj + Eij with nl + n2 + ··· produce Model: + nj ::: n Treatment effec.ts are equal: 1. Hypothesis tests for small or large RO: sample sizes =Tk T, = T2 0"" Treatment effec.ts are ordered, 2. F.s timates of treatment differenc.es Ha: .s. T2 .s. TK 3. Confidence lntervals of estimates T, 000 Where at least one of the < is really < of treatment differenc.es The test applies, as well, to Hi of 4. Estimates of treament differences L L L weighted by sample size T, T2 Tko 000 5. A graph of the medians for the THE CALUCATION treatment groups 1. Arrange sample data by treatment",Sugi-10-148 Hoop Mohebalian.txt
"linear regression model, using least squares estimates, is equivalent to testing the Experiments using a series of doses of a significance of an appropriate single degree compound, including a zero dose control, are of freedom contrast. The least squares often used to assess the effect of a test estimate b of the slope of the regression compound. line on the ranks can be described as follows: A nonparametric sequential regression analysis, which is an extension of the k NOSTASOT procedure (Tukey, et al 1983, 1985), "" is proposed to assess trends in the response i= [ variable. The proposed trend test handles b k progressiveness of response with increasing "" Ni [R(Xi) - R(X)]2 doses, providing more selectivity and i=1 sensitivity than some alternative procedures, with proper a error and distribution free characteristics. k "" Ni [R(Xi) - R(X) ]R(Yi) A program of SAS PROC GLM and BMDPIV is i-I presented using a numerical example. k "" Ni [R(Xi) - R(X)]2",Sugi-10-149 Park.txt
"SELECTION OF VARIABLES FOR IDENTIFICATION OF TRANSFER FUNCTION MODELS ON SAS SOFTWARE James A. Deddens~ University of Cincinnati Wang Ping, Northern Jioatonq University a = ~(B)-1x. The resulting INTRODUCTION. The purpose of this report ciosscovaria~ce function then equals is to discuss some of the complexities involved when modeling transfer function Vk~. Hence the crosscorrelation function relationships between non-stationary time series using the SAS-ETS software. We will P B(k) = V "" I""B. Thus after prewhi- restrict our discussion to the case of only k t~ning, the grosscorrelation function is one input, and we will be particularly proportional to the impulse response interested in the case where the i ""put and function (see section 11.2.1 in [2]). If output time series require different orders the sample crosscorrelation function is of differencing in order to achieve sta- not significantly different from 0 for tionarity. Such relationships occur often negative k. then transfer function rela- with engineering control or economic data. The selection of the series of interest is tionship exists and b. WeB), and S(B) can be identified and estimated using the somewhat arbitrary. For example. if one was sample crosscorrelation. interested in rice production, then one might select the monthly increase in production, 3) A univariate analysis of the resi- the monthly production. or the cumulative duals Yt - V(B) x to determine the form production as the input or output series. t PROC ARIMA provides great flexibility in of .(B). (See Section 11.2.3 in [2]). modeling both the input and output variables. In case both time series are nonstationary The input variable is called the Crosscorrelation variable (Ce), and the out- but with the same order of differencing necessary to achieve stationarity, then one put variable is called the Identification Variable (ID). It is important to correctly simply applies the above rules to the dif- specify these two variables, since incor",Sugi-10-15 Deddens Ping.txt
"tonio Abstract Program 1 shows the first program needed to A set of procedures have been written which create a metropolitan area map. We kept the create a IlBp of the United States showing all area mapped at the smallest geographic division, the metropolitan ststistical areas (MSA) as since MSA I S can always be recoded to reflect a defined by the U.S. Census Bureau. This is done CMSA division. There had to be only one using a Zip Code to County Conversion Data base. CountylMSA Code comblnstion. By sorting the zip In addition each county is assigned to the code conversion file by MSA code, state code and appropriate MSA, if it belongs in one. The same zip code data base was then used to take our county code and using the LAG FUnction, we are able to get rid of the multiple county code internal data files which only had zip code records. geographic infonmation and create files with county and MSA information on them. These Program 2 shows PROC GPROJECT, which takes the converted data files were then used to map inverted county code SAS map and creates a map customer demographics and company positioning by where east is east and west is west. metropolitan areas. Examples of this use show market penetration, membership concentration, Finally Program 3 uses PROG GREMOVE to create a and cities which are gOing to be brought on line in different phases of a program. map data set which only contains coordinates for MSA's based on the original SAS county data set. All counties in the",Sugi-10-150 Ohm.txt
"ct This algorithm uses the DATA step's ImrAIN When testing the goodness-of-fit of actual and OUTPUT statements to collapse the cells. data against a hypothesized distribution To be consistent with BAS notation, ""cell"" will fWlction, the chi-square test statistic requires be referred to as an observation and the ""five each expected cell frequency to be greater expected observations"" will be referred to as than or equal to five observations (2). Often the expected counts of the observation (or this requirement creates a problem when there frequency). Table 1 is a flow diagram of the are few observations and/or nany values of the algorithm. Table 2 illustrates the algorithm BY variables. This paper illustrates a SI\S with an exarrple. An abbreviated description of algorithm designed to satisfy this requirement. the algorithm follows: First, the algorithm checks an observation to Intrrxlngtion determine if the expected frequency for the Often in industry, a need ar ises for testing observation is greater than or equal to five. actual data against a hypothetical distribution If it is, then first the expected frequency is function. The exanples of the paper are added to any previous observations not yet output to the new data set and the sum is related to queueing models which assume the arrival rate follows a POisson distribution and outputed to the new data set. the service time follows an exponential distribution. In order to test these underlying If the observation is not great",Sugi-10-151 Zobre.txt
"data values in the image. Each data value in the original image is classified into one of a prespecified number of groups from which a This paper briefly describes a series of new image, called a classified image, is Statistical Analysis System (SAS) procedures displayed. The classification scheme used to and a single FORTRAN program which may be produce the maps may utilize external inputs used in the analysis of digital image data from from the analyst or it may be completely the LANDSAT series of satellites. These automatic, relying on statistical concepts to procedures permit the user to complete a digital provide the rules for carrying out the image classification without the need for the classification procedure. highly specialized image processing systems generally used for this type of analysis. Image enhancement differs from image classification in that enhancement refers only to",Sugi-10-152 Hetrick Portier.txt
"A DYNAMIC WORK STATION LOADING PROGRAM Paul H. Grant, Jr. General Dynamics Corporation, Quincy Shipbuilding Division THE STATIC STATION LOADING PROGRAMS INTRODUCTION A new element was added to the QSD schedul- General Dynamics Corporation/Quincy Ship- ing system in the early stages of its current five building Division (QSD) has developed a ship Maritime Prepositioning Ship (MPS) con- scheduling system, programed in base SAS· struction program. A series of SAS programs software which generates start and completion was written to assign a specific work station dates for each of the successive construction for each structural construction activity for activities that must be completed before the each unit on each of the five MPS ships. One several building blocks of a ship, called' 'hull of these programs assigns work stations against erection units"" or ""units"", can be joined the schedule window dates for each activity together at the launch site to form the ship. and displays the total work station loading re- quirement for the entire multi-year construc- A building location, or ""work station"" , is re- tion period on a weekly basis. quired for each of these construction ac- tivities. The work stations at QSD are grouped The page format for the output of this program together in ""platens"" of seven to eighteen was chosen for its visual impact and clarity. work stations. Some of the platens are inside The output is printed on 500 line pages. On buildings; others are outside, exposed to the each page, the station loading for 30 stations weather. Each platen has its particular was printed in columns with the weeks as characteristics: door size (for inside platens), rows. Sixty dummy stations were added to the number of service cranes, crane lifting capaci- 150 shipyard work stations to handle an- ty, etc. Most the platen work stations are flat, ticipated overflow. Examples of the this out- put format are provided in Figures A and B. fixed steel cradles, suitable for unit",Sugi-10-153 Grant.txt
". Robins Company lation. The experimental design is a 2-treat- Research programs in the pharmaceutical indus- ment, 2-period crossover (Cochran and Cox, try require that very similar studies be per- formed on many different compounds. If the 1957). During the first treatment period, each SUbject receives 1 of the 2 formulations experimental designs and the variables measur- (e.g., a single oral dose of drug). After a ed and compared are sufficiently similar, it ""wash-out 11 interval long enough to ensure is possible to use a set of standard programs complete elimination of the drug from the that differ only in the names of the data body, the second treatment period begins. At files and in the variables to be reported. the beginning of the second period, each sub- This paper is a description of a set of inter- ject receives the drug formulation that was active program generators that use PROC FSEDIT not administered during the first period. An to specify the information that varies from one study to another. The program generators equal number of subjects are randomly aSSigned to each of the 2 sequences of drug administra- use a common data set to store the values of this variable information. The common data tion. set also automatically includes audit trail During the 2~ to ~8 hours after each admini- information, such as, the date and program- stration of drug, several blood samples are mer's name each time a program generator is executed. The design and use of the program d",Sugi-10-155 Crowe Brizendine.txt
"To estimate the power function, Lehmann (1975) describes a normal approximation of the %MACRO POWER generates power curves for the Mann-Whitney form of the Wilcoxon test based on Wilcoxon Rank Sum test using a method described the fact that the distribution by Lehmann (1975). %POWER performs both a priori and post-hoc power calculations. The user may HXY - E(W xy ) define a range of deltas and the alpha level or use the defaults provided by %PQHER. An output j data set of the results and formatted output are Var (W xy ) also aVailable.",Sugi-10-156 Todd.txt
"ro b a b i 1 i tie s a-s a bas i s for dis c rim i (j a t ion between two populations. The extension ABSTRACT of this to more than two populations Logistic discrimination can be is given by Anderson (1972): used to classify an observation into one of several populations. The observation Psx - exp((I,.x.')'Os)pr(Hk/!), can be qualitative or quantitative. The estimate of the probabil ity of population k=l membership as a function of the independent pr(Hk/.x.) - Pkx -11[1 +shexP{(I,.x.')""s)]. variables is represented by the posterior probabilities. The SAS procedure LOGIST where ~~=(ClsO,(lsl.'"" ,asp) (5=1 ·... ,k-l). will give the logistic discrimination function and posterior probabilities Let nsx denote the number of sample when the number of populations is two points which are observed from Hs at or the model is ordinal. J. A. Ander- Then nso;:;rnsx the point..: (s=I .... ,k). son (1972) extended the logistic regression denotes the total sample from Hs and ns is a random variable. approach to discrimination to the case The function to be maximized is where the number of populations is more than two. ,, k The purpose of this paper is to log L J'-l icE j use the results developed by Anderson and present a SAS macro which will produce the maximum likelihood estimates for where Es is the set of rol'/ identifiers the regression parameters and the variance- of x for observations from Hs. The res ul tin 9 ma x i mum 1; k eli h 0 0 d e qua t ; 0 n s covariance matrix for the paramet",Sugi-10-157 King Dunn.txt
"In section II, the steps leading to the Control charts are an important tool in applied development of the control chart limits are statistics, especially in qualjty control. detailed. Sections III and IV contain an This report describes the generation of control example as well as an annotated listing of the chart limits for process data in which the SAS Macros, which make up the program. limits are developed by first grouping the raw process readings into many relatively small The statistical theory underlYing the groups and then, from this grouped data, generation of control chart limits both for obtaining subsets, which are stable with the process mean and for the process variation respect to the standard deviation and the mean. is presented in Ref 2, Chapters 3 and 4. See also Ref 3, Chapters 5, 6, and 7, for an even An important feature of this report is the ~ demonstration of the effective use of the SA~ more detailed presentation of control chart theory. Macro Language in facilitating the calculations required to develop the stable subsets and the The calculations presented in the next section censor limits. Without the macro language and the example in the last section make use capabilities, the computations would be long, of a sample of size 9. As will be seen, the tedious, and error-prone. use of a specific sample size makes it possible to identify exactly the scaling An example is given, and the SAS Macros, which factors, which are required for generating the make up the program, are listed. stable sets of data and the control chart limits. It is hoped that the use of such",Sugi-10-158 Walker.txt
"CT files and SAS* files. The SAS file includes the same level of detail SAS* has the capability of efficiently handling appeari ng in the COBOL fil e. I n some a wide variety of complex system data files. cases, the programmer would otherwise miss When creating files for input or output in SAS, an important data element and have to the programmer can employ macro coding remount the tape to retrieve the data, but techniques to design hierarchical file this procedure allows the entire block to structures. These are especially useful when be easily input into the SAS 1 ibrary. data is to be stored for subsequent use in a SAS library. When this method is used to input 3. Data appearing in tables, such as the data data from tape files stored in COBOL 1 ibrary group identified by the macro LlMTR_HIST"", formats (e.g., COBOL copylibs), it greatly may be entered in blocks. Since there are enhances the ease of determining data times the programmer doE's not know in positions, counting table occurrences, handling advance how many times data values are related data in macro ublocks"", and preserving data integrity between files. repeated in a table. the macro also uses control variables, such as the variable SCI M H, to determine table data content. To effectively create SAS* macros for data In 1hls case, the file record format is operations, the programmer groups lower level data for input, selects a meaningful macro name fixed block and SCI M H controls the number of times a non=-zero t",Sugi-10-159 Landon.txt
"STATE SPACE MODELING John C. Brocklebank David A. Dickey SAS Institute Inc. Associate Professor of Statistics North Carolina State University Cary, N.C. Raleigh, N.C. INTRODUCTION The input series X can depend on lagged t values of Yt; that is, we allow arbitrary forms of feedback. The SAS® procedure STATES PACE provides a powerful tool for forecasting multiple time series. Procedure is automatic. An alternative methodology is the usual identification and estimation using vector ARMA models. The vector ARMA approach is not used * Also in SAS/ETSTM software because the models are true for ARIMA but may require more user theoretically equivalent. This equivalence is intervention. exhibited in the first part of this paper. 2 DISADVANTAGES Although the STATESPACE procedure can be run almost automatically in its default mode, some User must decide order of differencing for all * examples are shown that illustrate benefits that variables. are obtained by exercising some of the available control options. The importance of preliminary Default version can have trouble picking up tran""sformations is also emphasized to render the seasonal factors in monthly data. input series stationary. Theory behind procedu re is rather * complicated. STATE SPACE MODELING Model resulting from procedure is hard to explain. 1 ADVANTAGES The theory requires nondeterministic inputs. Currently, will not handle missing values. 2 DISADVANTAGES * In default mode, likely to overparameterize 3 DESCRIPTION OF METHOD simple ARIMA models. Procedure is automatic. 4 FORECASTS AND STATE VECTORS 5 DOES IT WORK? * Also a disadvantage in ARIMA. 1 ADVANTAGES 3 DESCR I PTION OF METHOD Allows lagged values of Xs, Ys, and es to 1. Input the variables in your system, possibly help explain Y differenced Xe Yt' Zt' 2. Regress X t , Y t , Zt on X t _ 1 , Y t - 1 , Zt_l' Y t =8 0 +S,X, ,t +8 2X 1 , t-l +S3 X 2, t +pY t-l +e t * +8e _ X t _2 , Y t-2' Zt-2' ... , X t _h , Y t-h' X t _h t1 where h is chosen to optimize a",Sugi-10-16 Brocklebank Dickey.txt
"uSING EPIC AS A DEVICE DRIVER ,'OR SAS/GllAPH SOFTWARE PRINTEH GRAPHICS ON THE XEROX 9700 PRINTING SYSTENI Robert B. Holland, Boeing Computer Services Thomas G. Steger, Boeing Computer Services G. Louis Roberts, Boeing Computer Services tho! \i(i:'Ct.OI~S (h.w:l ng Pj""liOlS('? I I · 3y~:;;tem"" L are first sorted int.o the left-to-riqht Thi 5 papE~lr' nepor-t.s on t.hl~ of t:he sLanninq sequence In whi(.h t.hey will Ll'58 ThE""~;E') ~501~tC'?Ci apP"""",M' lmaqf.? Canst.n.\et.ion whE?n Imaged. E.lectr'oni.c Pd,nter"" (EPIC) !:iClfb\l.:;w'(i:i 2I!5 a SAb®deviC:E~ drivE~r' Vf2c:t:.OI~S (::onvETtE'cl ""l nt.o '""H"" (,':: t.!""'H.,""'n a for printer graphics on the Xerox 9700 t'-a';c,tl;?r lin(;?~:; and -::.ncodeci to ~3E'I""J.i;?~~ D·t Printing System. Image construction 1S Fina] disposition of printable f""lles. accomplished by EPIC In two phases: t.h f2 C uns tr""'uc:tEi:'cj i. maqE;)::, i ':~ C:Orl,::,;!:?r: ut :i, VE' i. Y ~:h~~;(:. ~ ~ _,c~a~::: v~ct~~r: i n+ ::!r-ma::, i (~~~ .~+ l,..t?f1l orqanized into a SYSOUl file on a spool .r J pi ucecur LS~ !-hd,~f., ;::.{-kJ!r:.:!F<f!..'lFH 3..1d devil:e which 15 electronically attached to th& Xero¥ 9700 Printing System. rhe tl""'~:HF.;fc)l'""·msvector 'lnfo!""'mation .into SVSOU1 pl.ottablf.~ fil:::· capablE? o·f bE-:~:inq pr--intec:! file contajns optional print directives used by EPIC for X~~:I~CJ;{ r;;'r-int.i.ng processing by the '""}700 BYSt.f21n. P~inter on the Xero~ 9700 printer. the images output can be in portrait E1y~;;tf::in~, 9700 TI'') (2 Xelr-D;< Pr-intinq (vl?rtici:il} lant:!scape (horizDntal) 01""- M'-J~3 ,o<_n 8 TElI""'1 i.ntE'I'""'·Facinq with the hDs;t orif;)nt,',\t:ion on l/2 }; ll'--inch (width by length) page with of sy~""'tEHn~, CDiIlUl rH""'~:> :1 a~:;Pi'~"" comput.E'\'- option si.mple;.; or- duple;.; pl""intinq"" communi. c"",_t i_ Dn~:; and technologies to print the formed imaqes on one or both sides of 8 1/~ :: lL-inch II. c:ut p,3r.l(:"":~I'-. ar-e EPIC qr-'aphi C~5 usi nq S;A~3 ~:;ystem 9700 wi.th E-~>(:;.cut.i nr;) b",Sugi-10-160 Holland Steger Roberts.txt
"was needed which produced report-quality tables A library of standardized SAS* programs was and data listings in a consistent format developed to perform the statistical analysis requiring minimal text editing. and data reporting for a large project of clinical trials. Numerous studies with varying III. METHODS/SOLUTIONS designs and large amounts of data needed to be analyzed. Due to regulatory requirements and a strict time schedule, the analyses needed to be We realized early on that the only way we could performed and reported consistently and quickly. meet the established goals for this project was Since several programmers from different to automate the collection, analysis, and projects would be doing the analyses, the reporting of all data that would be handled software needed to be easily understood and similarly for each study. This led to the idea of developing a library of standardized soft~are modified to accommodate different study designs. This paper describes the methods and SAS that could be used for all studies, with enough features used in completing this project, flexibility built in to be able to handle the emphasizing those that allow for rapid analyses variations among studies. and consistent output. These include the macro language for conditional execution of code and for variable substitution, format libraries, and STANDARDIZING THE DATA COLLECTION Full Screen Product*. A composite program illustrating several techniques is included. Part of the solution was to standardize the input data. By doing so, we could minimize the number of changes each bioanalyst would have to II.",Sugi-10-161 Bingham-Barnes Nelson Tappe.txt
"COMPUTERIZED MATERIAL LOADING SCHEDULES: AN AID IN IMPLEMENTING HIGH DENSITY STORAGE SYSTEMS Darryl W. kolojacD! Houston Lighting & Power Co. (]BSTRHCT The research conducted during the feasibility This oaper reports the develooment and use of study provideS the decision of ~hat type of system software to provide a schedule for implementing IS required. However, the planning activities new storage equipment at Houston Lighting. Power that occur during procurement can be the deciding Co.·s service center warehouses. The output from factor of whether or not a high density storage this development has been used by warehouse system succeeds. The software package presented personnel to determine where specific material is designed fer a specific storage system type w~s scheduled to be stored In modular drawer (modular drawers), but the programmIng technique addItions. Each page of the output report provides is adaptable to other types of equipment. a lIst of material representing a sub-set of the full list of items being moved. These items are cross-re4erenced to their proposed 'warehouse grld DATA REQUIREMENTS location. The output page also provIdes th~ us~r with a profile view of the drawer unit in which loading schedule software is depend- the material IS to be stored, identifying the The dent upon collection of data from three sources: cabinet identification number in the installaionn. 1) the ldentification of candidate material, This profile includes a set of arrows pointing to the cabinet drawer In which the material is to be 2) the engineering feasibility studv l and 3) thE' vendor sl1r-.-e~s. stored. Finally! a layout of the dra~er IS provided indicating the exact compartment In which In the scheduling system te!t case, warehouse each part number is to be stored. personnel at th~ prOjEct Slt2 were responslble for identifying the materIal to be included in the system. Decisions ~ere based on item size, fre- INTRODUCTIO~J quency of issue, and security needs. A pre",Sugi-10-162 Kolojaco.txt
"FAST REPORTER Mark Freeman, BENDATA Management Systems. Inc. Print Variables INTRODUCTION Up to twelve variables (data fields) may Fast Reporter 1s an on-line report be printed on the report. Also, special wri ter for use with SAS data sets. variable designators allow the user to Written in SAS and utilizing SAS/FSP the specify IIprint ali ll variables, print all system allows non-SAS-trained personnel nUmeric variables, or print all charac- to design and create custom reports from ter variables. data residing on SAS data sets. Report SequenCing The system utilizes the descriptive in- formation maintained on SAS data sets in The report sequence is specified via the evaluation and generation of a sort variables. Up to three sort vari- report request. In add! tion to the ables per report may be deSignated. One descriptive information, FAST REPORTER will be the primary sort variable (i.e. utilizes such SAS features as: major controlling sort variable), then %INCLUDE, PROC PRINT, PROC CONTENTS, the secondary and third sequencing PROC SORT, PROC FSEDIT and PROC FSLIST. var iables. For example, the user may want a report sorted by name within city wi thin Zip Code. In this case the Zip Code Is the primary sort, city the FUNCTIONS AND CAPABILITIES secondary sort, and name the third sort variable. Easy to use on-line screens allow Fast Reporter users to specify: Summary totaling may be specified with *Record Selection the sort variables and also for numeric *Varlables to Print *Report Sequence variables that will appear on the *Summary Totals report. Then when the value of the sort variable changes, all numeric variables *Crosstooting Totals *Number of Records deSignated for totaling will show a sum- mary total. *Report Title *Page Length Cross footing Totals *Page Width *Report Spacing Up to three crossfooting totals may be *Page Breaks specified. Each crossfooting total may *Number of Copies be a combination of two or more of the *Print SAS Data Set Record Number numeric",Sugi-10-163 Freeman.txt
"Box Plots using SAS/GRAPH Software Ann Olmsted, Syntex Research What are box plots? Why box plots? ANNOTATE facility to draw the boxes. If Box plots I TUKey, 1977) display 5-number boxes with width proportional to some summaries of batches of data. The function of the sample size, boxes standard box IF i g. 1) has top and bot tom notched to indicate some sort of edges at the 75th and 25th percentiles, a confidence interval for the median, or line across the box at the median, and almost any other variation is desired, solid vertical lines ('whiskers') PROC GPLOT alone is flexible enough to extending to the extremes. The FIGURE produce them. For a detailed description plots are a useful exploratory of some of these variants and their tool, providing as they do a advantages, see 'Variations of Box graphic summary of sample Plots,' by R. McGill, J. W. TUKey, and W. distributions which lets the L. Larsen, in the February 1978 issue of data analyst simultaneously The American Statistician. This article assess location, spread, shape, was the inspiration for the GPLOT SAS and extreme values. They are macro BOXPLOT described below and listed also a compact and informative in the appendix. way to present resu lts. As a way to present results, they How to draw a box1lot lor anything else) are probably most valuable using SAS GRAPH* software when: + - sample sizes are large The PLOT y*x=z / options; version of the enough to maKe the PLOT statement, used with appropriate plotting of individual SYMBOL statements, maKes PROC GPLOT an data values impracticable, extremely versatile graphics tool, not and limited to simple y vs. x plots. To distributions are skewed and/or long-tailed, ruling produce arbitrary connected figures, one has simply to create a SAS dataset out the usual mean ± Istandard deviation) or containing the (x,y) pairs outlining each figure, with observations in the order mean (standard error of ± the mean) summary plot. that the points are to be connected, and a",Sugi-10-164 Olmsted.txt
"using PRoe eOPYLIB to Create a SAS-based Data Dictionary wayne Beekman, Information concepts, Inc. PROC COPYLIB was developed to · Technical Documentation - The overcome the major difficulties as- standard reports generated from sociated with quick access to data PROC COPYLIB are very helpful that are maintained by COBOL pro- in the first phase of technical grams. COBOL maintained data are documentation. The Data Dict- described using COBOL File Descrip- ionary adds file level informa- tion which will enhance the tions usually located in COPYLIBs. documentation effort, Because these record layouts are not easily converted into SAS input · Information Center Reference statements by a programmer, prepara- Users requesting information tion to use SAS to access these center assistance can reference files can be a time consuming process. the SAS-based Data Dictionary PROC COPYLIB quickly converts any through standard reports or COBOL File Layout into a SAS input PROC FSBROWSE. This will allow statement with little programmer users to research their data effort. requirements completely before submitting Information Center After using PROC COPYLIB to con- Requests; and vert File Layouts into SAS INPUT Statements, another use of the pack- · Cross Reference listing - Data age became evident. It is possible Administration can use the SAS- to use PROe COPYLIB to create a SAS based Data Dictionary as a dataset of the information that cross reference list of data describes the COBOL file. This SAS items. This list aids in il- dataset can be merged with file lustrating the impact of changes dependent information to create a on production systems by point- Dictionary of all information in the ing to dependent variables on computing environment. separately maintained COBOL files. A SAS-based Data Dictionary can be used for the following purposes: To use PROC COPYLIB to create a following Data Dictionary, the · Generate Source Code - The steps, as illustrated in Figure 1, dictionar",Sugi-10-165 Beekman.txt
"Junction, Vermont 05452 The third option, SURFACE, is simply a contour map Abstract of the wafer surface with the parameter value for It is possible with each device site connected. The art of semiconductor device and process char- this option to alter a constant that acts as a de- acterization has become an increasingly difficult that i t determines the rate of cay function in task for many reasons. One of the most pervasive fall-off from one device to the next. This can be of these is the manipulation and interpretation of useful in either smoothing the entire surface to the massive quantity of data that can be generated with today t s highly automated and sophisticated testing equipment. Until now, the summarization of this data into logical subgroups (i.e., device In· Process Electrical Test Data sites or wafers) and subsequent statistical analy- sis has been both difficult to do, and even more Choropleth Map - Continuous Array difficult, if not impossible, to portray to oth- ers. This poster presentation is intended to il- lustrate the use of the SAS/GRAPH GHAP procedure in the context of data analysis and portrayal. As such, it will include both SAS code listings for the various graphic outputs and analyses as well as examples of possible graphic outputs. Overview The programs and techniques presented here allow a person with a moderate computer background to per- form very complex data reduction, analysis and graphical depiction. They are suitable for use in either VH/",Sugi-10-166 Maslack Hendrix.txt
"matrices of the estimates; * goodness of fit statistics, the scaled devi- Logistic regression is :'l statistical tool for describing, controlling or predicting pro- ance and Pearson's chi-squared; and portions or rates. It has found application in *. a sUltunary table of deviances, chi-squares and such diverse fields as medicine, marketing, degrees of freedom across models. * toxicology and industrial processes. Devlin Should the IRLS algorithm fail to converge, (1984) demonstrated the use of the MATRIX interim estimates are printed. procedure for obtaining maximum likelihood fits An output SAS data set containing the fitted and the associated diagnostics proposed by binomial probabilities and means can be option- Pregibon (1981) for logistic regression models. ally requested for later usage. This paper describes the SAS statement macro LGTREG which provides a more convenient, user- DIAGNOSTICS oriented implementation of those techniques. As maximum likelihood estimates are sensitive to outlying responses and extreme points in the 1.",Sugi-10-167 Devlin Weeks.txt
"METHODOLOGY Program Planning Charts are easily A methodology that produces Program Planning Charts using SAS/GRAPH software has produced by using Logic Flow Diagrams. The been developed as an aid to program management template for the planning chart is created by in the CO Research Program of the U. S. placing an appropriately dimensioned transparent Department 2of Energy. The methodology uses grid over a copy of the Logic Flow Diagram. MAPPER, a front-end program programs from MAPPER is then used to replicate the Logic Flow (written by D. A. Dahl) for DISSPLA to produce diagram. An inexperienced user can quickly Logic Flow diagrams. Each research question, or learn the MAPPER language to produce exact set of questions, which comprise one phase of a replicas of any simple chart or diagram. research program, is represented by a boxed area containing the title of the particular research In the next step, a coordinate file is question(s). The GMAP procedure of SAS/GRAPH constructed by defining each of the bounded software reads user-supplied information areas, that are to be color-coded, in the manner regarding a variable aspect of each research prescribed by the GMAP procedure in the question and shades the boxes accordingly. The SAS/GRAPH basics manual. Each area is assigned result is a color-coded planning chart depicting an identification code by the user and the x-y the user supplied information for the individual coordinates of each corner are identified. research questions and, consequently, the status of the overall program. The boxed areas are formed by a pair of triangles so that the user has the option of",Sugi-10-168 Nelson Farrell Gross White.txt
"oduct. ABSTRACT Because CUSUM procedures give an early indication of process changes, they are con- Cumulative Sum (CUSUM) quality control sistent a management philosophy that with schemes are becoming widely used in industry encourages doing it right the first time. The because they are powerful, versatile, and easy use of CUSUM procedures ;s also consistent to use. They cumul ate recent process data to quickly detect out-of-control situations. with a management by exception philosophy as the CUSUM will point out areas needing They also serve as a powerful diagnostic attention. tool. There are now more than 10,000 CUSUM control schemes in use daily ;n Du Pont. This talk describes design and implementation Cumulative sum control schemes are cur- rent ly used more for the control of vari ab 1es procedures for CUSUM control schemes with than for the control of counts (attributes). emphasis on properties that are recorded as counts. The talk will describe recent de- To help remedy this, we will give counts more emphasis here. We will show that the design velopments which make CUSUM procedures more useful and more powerful. and implementation procedure for Counted Data CUSUMs (Lucas 1985) is very similar to the The recent developments described are: procedure for CUSUMs for variables (Lucas 1976). We will use a Poisson distribution in o Fast Initial Response (FIR) CUSUM which our examples. A Poisson CUSUM is used when it gives extra sensitivity to out-of- is administratively conv",Sugi-10-169 Lucas.txt
"* Project This paper shows how the Wisconsin Gas Company over a ten year time horizon, * used SAS@. SAS/ETSU. SAS/GRAPH@. and SAS/FSP@ Forecast by Residential, Commercial, to develop a gas sales forecasting system. It and Industrial Rate Class, and * emphasizes which SAS Institute Inc. software Produce forecasts at monthly time PROC's were used to complete each model intervals development stage. In particular, the Insti- tute's PROC's that were used to build and This paper will describe the steps in which evaluate the forecasting system are outlined. the WGC applied SAS Institute software pro- Although this paper addresses the process for ducts to develop its gas sales forecasting building and evaluating an econometric model, system. The scope of the paper is to show the the process can be adapted to most forecasting process the WGC used for building the gas demand models, and for evaluating the gas techniques. demand model's forecasting capabilities.",Sugi-10-17 Brand Funk.txt
", Los Alamos National Laboratory ABSTRACT How does one obtain and quantify expert opinions? How uncertain are expert opinions? How can one pool expert opinions? To explore these and related questions, an experiment was conducted by using four types of stimuli to com- pare six direct numerical methods for eliciting subjective probabilities over continuous variables. The four stimuli were questions in- volving percentages, magnitudes, rates, and probabilities (chances). The direct numerical methods varied as to the type of point and inter- vals elicited, the order of elicitation, symmetry versus nonsymmetry in the interval estimates, and feedback versus no feedback. Noninteractive group feedback of the judgments of other subjects reduced the median absolute error in the point judgments and decreased the number of surprises in the interval assessments. Six mathematical aggregation rules for producing consensus point judgments and six rules for producing consensus confidence intervals were also compared. The median was found to perform well in producing consensus point judgments, while an empirically developed interval estima- tion rule was found to yield an average relative containment frequency of approximately 92%. Finally, the subjective judgments of norma- tive experts (professional statisticans) were not found to be statistica11y significantly better as a group than those of non-normative experts. No formal paper is included because the fol- lowing two closely related paper",Sugi-10-170 Martz Bryson Waller.txt
"APPLICATIONS IN BAYESIAN ANALYSIS Arnold Zellner university of Chicago Introduction 1. The rapid growth of Bayesian econometrics ment and consumption data. Production function and statistics since the 1950s has involved many models have been analyzed from the Bayesian applications of Bayesian inference and decision point of view by Sankar (1969), Sankar and techniques to a wide range of problems and the Chetty (1969), Zellner and Richard (1973), and development of Bayesian computer programs--see, Rossi (1980, 1984). Tsurumi (1976) and Tsurumi e.g., Press (1980). This experience in applying and Tsurumi (1981) used Bayesian techniques to Bayesian techniques has indicated that Bayesian analyze structural change problems. Reynolds solutions to applied problems are as good or bet- (1980) developed and applied Bayesian estimation ter than non-Bayesian solutions. Indeed, it has and testing procedures in an analysis of survey been shown that many non-Bayesian results can be data relating to health status, income and other obtained by Bayesian methods under special as- variables. Harrison and Stevens (1976), Harri- son, West and Migon (1984), Litterman (1980), sumptions. However, these special assumptions are often unsatisfactory and thus full Bayesian Doan, Litterman and Sims (1984), and Highfield solutions, which relax them, are preferable. (1984) have developed and applied Bayesian fore- casting models. Merton (1980), used Bayesian Further, as is well known, the Bayesian approach permits the flexible and formal use of prior in- estimation procedures in a study of stock market data. Akaike and Ishiguro (1983) have developed formation in obtaining solutions to applied in- ference and decision problems, a feature of the a Bayesian approach and a computer program, BAYSEA, Bayesian approach which is particularly valuable for seasonal analysis and adjustment. Morris when sample information is limited. These and (1983) has discussed and referenced many appli- other features of",Sugi-10-171 Zellner.txt
"AN INTERACTIVE, MENU-DRIVEN SAS® SYSTEM FOR SAMPLE SIZE AND POWER COMPUTATIONS IN CLINICAL TRIAL DESIGN Gregory G. Enas, Lilly Research Laboratories Walter W. Offen, Lilly Research Laboratories John D. Taulbee, Procter and Gamble Question 3: Introduction ""What information do I have concerning the treatment effect?"" Any investigation of treatment for human illness or disease has ethical and logistical constraints placed upon it. These constraints This question may be answered in the form of an reflect the nature of the questions asked. The interval estimate for the plausible treatment objective of a clinical trial is ""to ensure a effects (e.g. 95% confidence intervals). This high probability that the better treatment is system is designed with Question 1 in mind. identified"". A clinical trial seeks to maximize This requires that both sample size and power possible benefits and minimize harms. The issues be dealt with, for ""adequate chance!! (power) and Itrequired sample size"" must be primary purpose of a good research design is to uphold this norm. As Levine and Holder (1984) considered. state Clinical Design ""If the research is not well designed, there will be no benefits; investigators The randomized clinical trial (RCT) utilizes who conduct badly designed research are either parallel or crossover experimental not responsive to the obligation to do designs. The two-group parallel design is good or to develop knowledge which is utilized most often due to its simplicity and sufficiently important to justify the its obvious advantage over k>2 group designs in expenditure of public funds, to impose its ability to accrue patients. Thus, methods upon human subjects risks of physical or are given here which allow sample size and power computations for two-group parallel psychological harm, and so on."" designs l.,rhere the response of interest has either a binomial or Student's t-distribution. The design of the trial is thus of primary importance. No posterior sophisticati",Sugi-10-172 Enas Offen Taulbee.txt
"Mult!dlmmsional ScalIng Models and Metbods for Two-Way aad Tlree-Way Proximity aad Prefermce Data J. Douglas Carroll AT&T Bell Laboratories another """"y, the two subscripts j and k range over the In its braidest delinitim, multidimensiooaJ scaling same mcxIe, cr set c1 entities. ''Two-way'' means that, (MDS) includes a wide variety eX gecmetric models fir since & bas two subscripts, a two-way table is implied.) representatim eX psychological Ir other behavilral science data. Such models can include discrete The model assumed for these proximities can be geometric models such as tree structures (typically expressed as follows: associated with hierarchical clustering) overlapping Ir F(&j') '"" dj · II!JIlOYerlapping cluster structures, Ir other netw<rk models. Mire typically, however, MDS is associated where F is some functim (e.g., linear, sane specified with cmtinuoos spatial models fir representation eX nmlinear functim, or in the case eX nmmetric MDS, a data. In the braid delinitim eX MDS, such spatial merely monotonic functim), ""="" can be interpreted as models can include such general geometric structures meaning ""approximately <quals"" (or, <quais, except f<r as what are called the vectlr model Ir the unfolding err<r terms which will not be further specified in this model for representatim eX individual differences article) while d j' is the distance between pants preference (Ir other dominance) data Ir even the representing j and k in an R dimensional factor analysis model. Fir discussim eX sane eX the models and associated methals included in this braid multidimensional space. The distance, d j' , is usually, delinitim eX MDS, see Carroll (1980), Carroll and but not necessarily, assumed to be Euclidean distance, Arabie (1980), Carroll and Pruzansky (1980), and defined as follows: Shepard (1980). Vf For now, however, we shall focus m the IIlQIt -Je.,)2 (1) d J1 = (Jefr ammm meaning eX MOS, and, indeed, focus even ,~1 mire narrowly m what wruld now be called, in t",Sugi-10-173 Carroll.txt
"Taking MDS Beyond Similarity Data J.O. Ramsay. McGill University 1. for example, is a cognition about the relation Dual Nature of Attitudes ~ of the SAS system to the attribute of syntactic compleXity. Salience, on the other hand, is a Attitudes are the basic stuff from which statement about the relation of the individual decisions are made. Sometimes ephemeral, to this attribute. I may say that my relation sometimes unshakable, they are our response to a to the attribute of syntactic complexity is one transitory, unpredictable and complex of comparative indifference when I am environment. A fascination with attitude and functioning in a programming mode, but that the its formation characterized the best of Greek more complex the syntax, the mOre negative my philosophy, animated the great debates of reaction when I am contemplating a system for medieval world, spawned the liberal philosophies of the seventeenth century, pervades modern instructional purposes. Thus, we may say that psychology, and is the basis of marketing, one both cognitions and saliences are statements of of the largest industries in developed relationship to an attribute, involving the economies. The social implications of even our stimulus in the former case and the perceiver or present dim understanding of and control over judge in the latter. Of course, it must be attitude formation are everywhere to be seen, understood that both cognitions and saliences and deeper understanding would surely rank with will depend on the context of judgment (whether I am programming or teaching, for example). our discoveries in nuclear physics and genetics as an intellectual adventure with the An entity such as the SAS system is related profoundest consequences for good and evil. to many different attributes, and one's final What does statistical technology have to evaluation of or utility for it will be somehow contribute to the study of attitudes? Let me compounded from the cognitions' and saliences try in t",Sugi-10-174 Ramsay.txt
"nvolve nonlinear ABSTRACT transformations of variables, three are strictly linear, and one is a plotting procedur'e. A software development project is currently in progress at the Univer""sity of Nor'th Car""olina at Chapel Hill (UNC). This project has two major The four nonlinear procedures (CONJOINT, pur'poses: The development of SAS® 1) PRINQUAL, TRANSREG, and PROXSCAL) are procedures to perform a var'iety of popular based on the work of Young (1981) and Gifi descriptive multivariate data analyses. 2) The (1981). These procedures nonlinearly transform development of a ""flight-simulator""-like SAS variables so that they are optimally described by procedur'e to enable visual exploration of a specified data analysis model. The four multivariate data. This paper' describes the procedures are briefly described in the design of sever'al of the pr'ocedur""es being remainder of this section, and then are discussed developed. extensively in section 2.0. The plotting procedure (IDPLOT) is briefly described in this Disclaimers section, and is described at length in section 4.0. These procedures are being developed at UNC, not by SAS Institute. There is no commitment by the Institute or UNC to support nor to distribute The thr'ee linear procedures (MeORESP, these procedures. PRI N3WAY, and PATHANAL) introduce new ways of analyzing multivariate data that are currently This paper repor'ts on the potential design of unavailable in the SAS system. We briefly several procedures. Some of these",Sugi-10-175 Young.txt
"Institute Inc. Forrest W. Young, The University of North Carolina at Chapel Hill discussed in many other multivariate statistics Abstract The PRINQUAL (PRINcipal components of texts, also. QUAlitative data) algorithm implemented in the 1.1 The Principal Components Model PRINQUAL SAS® macro generates model estimates Principal components (or simply components) for rescaling variables in one of two ways. The maximum total variance method maximizes the are new variables that are linear combinations (weighted sums) of the original variabl~s. The variance accounted for by a stated number of components. The minimum generalized variance weights, which are functions of the covariance structure of the variables, are constrained to method minimizes the determinant of the variance-covariance matrix (the product of the have finite variance. Specifically, each set of eigenvalues) subject to the constraint that the weights is typically constrained such that the sum of the squared weights is one. The first variance of each variable (and hence the sum of the eigenvalues) remains fixed. The former principal component is the weighted sum of the method results in a different scaling for solutions original variables that has the most variance. The second principal component is a weighted calling for differing numbers of components while sum of the original variables that is uncorrelated the scaling in the latter method is invariant to changes in the number of components extracted. with the first",Sugi-10-176 Kuhfeld Sarle Young.txt
"is a graph where each cluster corresponds to a line (its profile). The variables of the cluster analysis A Cluster Profile form the x-axis, the cluster means form the y- axis and the means of a cluster are joined by a straight line (Figure 6). The presentation is optimal if the order of the variables is so chosen that the number of intersections of the , _ _- - ' . . . - _ CLUSTER 2 cluster profiles is minimized. The optimal presentation yields better inter- pretation of the clusters I interrelationships. This paper presents the CLPF SAS procedure (CLuster ProFile) that produces the optimal presentation of the cluster profiles. 1. I NTRODUCTI ON In this paper the expressions IIpresentation Figure of cluster profil es II , ""cluster profiles"" and IIprofile ll have the same meaning. About the optimal presentation of the cluster profiles in general see (6). 1.1 Problem The Optimal Profile is the matrix of cluster means, where (A ij i=l, ·.· ,n and n is the number of variables, j=I ····· k and k is the number of clusters. CLUSTER 2 is the intersection matrix, where an (D element d is the number of i nter- ij ij sections in the profile between variable i and j when they are adj acent · The matrix is n x nand symmetrical. p , ··· ,p is a permutation of the cl uster Figure 2 1 n variables. S(p ····· p) d +d +d is the 1 n pp pp pP 12 23 n-l n The problem of finding the optimal profile can total number of intersections in the be translated into a slightly modified profil e, if the vari",Sugi-10-177 Felsovalyi.txt
"Suitability of Microcomputers for Statistical Analysis Phil Spector, SAS Institute, Cary, NC demands special attention to insure that the ,. INTRODUCTION strong points of the microcomputer are emphasized, and the weak points dealt with in While microcomputers have provided an efficient manner. tremendous computing power to a large number of users, there are still many problems inherent in bringing existing 4. THE INPUT INTERFACE programs into the microcomputer environment. This paper will examine some of the features of microcomputers which make them an Since the microcomputer user often doesn't appealing tool for statistical analysis, as well have available support personnel to aid in as some of the problems which may be coping with a program, it is essential that the experienced when trying to develop programs input interface be as friendly and flexible as for use on the microcomputer. Illustrations of possible. Error checking and correction these concepts will be provided by examining should allow the user to continue after some features of PROC GLM in the SAS® correcting errors, preferably with some System under PC-DOS. assistance from the program itself. Although beginning users appreciate menus, a line input mode should be available. In the SAS System for Microcomputers, all these options 2. THE MICROCOMPUTER ENVIRONMENT are available, and compatible with each other and earlier versions of the SAS system. The display manager offers an easy to use editor Even though microcomputers can not match coupled with a program submission system to larger systems in the areas of speed and simplify the writing and running of programs, storage, they present many appealing features while the SAS Applications Facility allows which can not be found on their larger custom written menus to serve as the source counterparts. Chief among these is the of input. Enhancements to the data step dedication of the processor to the single allowing controlled windowing for input and microc",Sugi-10-178 Spector.txt
"THE SAS SYSTEM AS A STATISTICAL SIMULATION LANGUAGE Robert M. Hamer and Timothy J. Breen Virginia Commonwealth University, Medical College of Virginia cell and save the results. Some of these This paper discusses use of the SAS oonditions might include no violations, System as a tool for simulation: as a and Same of these conditions might simulation language. First, we will include many violations of various types. define some terms and lay groundwork. We might even arrange the various Second, we discuss characteristics of the violations in a factorial design, and type of simulation about which we will analyze the results of our simulation restrict ourselves, the statistical using ANOVA or some similar technique. simulation or monte carlo study. Third, we will enumerate characteristics of a This is the type of simulation in good simulation language, and fourth, we which we are interested, not simulations will examine the SAS System in light of of supermarket checkout lines, gas these characteristics. Finally, we stations, war games, subatomic particles, include a brief discussion of methods for eto. performing simulations quickly and efficiently using the SAS System. Simulation has both advantages and disadvantages. The advantages include Rubinstein (1981) cites Naylor et al oontrolled experimentation, time (1966), who define simulation as "" ... a compression (we can do on the computer in numerical technique for conducting seconds what might take days outside of experiments on a digital computer, which the computer), sensitivity analysis (the involves certain types of mathematical ability to manipulate various aspects of and logical models that describe the the system), its effectiveness as a behavior of a business of economic system training tool. the fact that the model (or Some component thereof) over extended may not need to be expressed in any periods of time."" More simply, Graybeal particular format, and the faot that and Pooch (1980) defines simulation as th",Sugi-10-179 Hamer Breen.txt
"Forecasting and Simulation Using SAS/ETSTM Software Mark Little SAS Institute Inc. Good morning. My name is Mark Little, and I am A RANGE statement has been added to control the period-of-fit for parameter estimation or the with the Applications Division of SAS Institute. The title of my talk is ""Forecasting and range of the forecast or simulation. The RANGE statement also specifies a variable to use in Simulation using SAS/ETSIM Software"". I'm going to discuss some topics on forecasting with PROC identifying observations and automatically handles the initialization of lags. SIMNLIN. All of the programming statements of the SAS The topics I hope to discuss this morning are: DA TA step can now be used in writing models. the use of Monte Carlo simulation for forecasting; The new programming statements added include the use of the PROC SIMNLIN FORECAST option; PUT, STOP, DELETE, ABORT, LINK, RETURN, extrapolating exogenous series for forecasting; GOTO, and CALL. combining sectorial models for forecasting; and calling user written subroutines from models. Missing values are fully supported in the new version. The way that lags are processed has The SAS/ETS Nonlinear Modeling System been improved, and several problems with lags in the old system have been fixed. Also, error But first I should give a little background on the conditions are dealt with much better. The SAS/ETS modeling system, and summarize the documentation of the system has been expanded changes to the system from the 1982 version. The modeling procedures have been completely several fold in the new SAS/ETS User's Guide) Version 5 Edition. rewritten and many new features have been added. Monte Carlo Forecasting The modeling system consists of the three procedures PROC MODEL, PROC SYSNLlN, and The list of changes and enhancements goes on, PROC S IMN LI N. These procedu res estimate but my subject this morning is forecasting with parameters of and simulate or forecast discrete PROC SIMNLIN, and I think tha",Sugi-10-18 Little.txt
"THE ROLE OF INVERTIBILITY AND SYMMETRY OF POLYCHOTDMOUS METAMETERS FOR GSK AND OTHER RELATED ANALYSES James E. Dunn Department of Mathematical Sciences University of Arkansas Fayetteville, AR 72701 1. INTRODUCTION Grizzle, Starmer, and Koch (1969). In the alternative setting of continuous This paper is about data transformations of proportions, e.g., the percentage composition of composition vectors. For notational purposes, household budget items, Aitchison (1982) pro- let any lower case letter underscored denote a posed a variety of tests of independence, again column vector. Then Qd = (PI' ... ,Pd)' is a d- using principally the additive logistic meta- dimensional composition vector if Pi represents meter. Implicit to both situations is the result either a continuous or counted fraction attribut- that all analyses are accomplished in Rd rather ed to an ;Ith category of response. Geometrical- than in Sd. Clearly then with the assumed lin- ly, Qd is an element of the positive unit simplex d d d d ear model providing a mapping from X, the space S = {Q : p. 0, T(Q ) = 1: p. < I}, > of the concomitant variables into Rd~ it becomes ;=1 1 1 important for interpretation and forecasting of where the existence of a fill-up value Pd+l * 1 - T(Qd) is impl icit. Several statistical pro- composition to be able to refer ~ s uniquely back to Sd through Rd. This invokes the addition- cedures of varying familiarity are based on post- ulating a set of transformations f:S d + Rd such al requirement of invertibility: that if Y = f(Qd) , then Y ~ N(B'~~l:), either Definition. y = f(Qd) is an invertible, d-chotomous ~eta;eter if f:S d ++ Rd. asymptotically as for counted fractions or exact- Section 2 extends work already reported by ly for continuous fractions. Here~ B represents Dunn and Cappy (1979) in the pursuit and charac- a matrix of parameters and ~ a vector of concom- terization of general classes of invertible meta- itant variables for an intrinsically linear model meters. Th",Sugi-10-180 Dunn.txt
"A SAS PROCElXJRE FUR SMXmIIlC GENERALIZED LINEAR t-Il!lELS William J. Rayrx>r, Jr. Kimber1 y-Clark Corporation 2. A REVIEW OF SMOOTHING SPLINES I. INTRODUCTION AND GENERALIZED CROSS VALIDATION A number of techniques are used Smoothing splines and their to perform smoothed nonparmetric application to data. have been regression when the response variable extensively studied during recent exhibits normal or, more generally years. References include Craven symmetric errors. Such techniques and Wahba (1979), Wegman and include spline smoothing, running Wright (1983), and sources cited means or medians, kernal estimates, therein. The basic model of and nearest neighbor estimates. these papers is the one dimensional These techniques are often used regression to produce a plot which summarizes the relationship between a pair y(t i ) = f(t i ) + ei' ti I': [O,lJ, of variables in a way which is smoother than a scatter plot and where the ei are assumed to yet does not require the assumption be independent zero mean random of a specific model form as, say, variables with a common unknown linear regression does. An investigator variance. The data y. = y(t i ) using these techniques is thus are observed at 0'"" t l ;; t2 "" able to take a relatively ""model-free"" · . · ~ tn -=- 1. In a typical look at the relationships between regression, f is assumed to variables, and can be guided (or have a known form with a small warned) in choosing a parametric number of unknown parameters form in which to model the data. (e.g. a polynominal of degree m), and the parameters may be There are, however, many cases estimated using standard regression in which the data do not meet the techniques. However, if we assumption of zero mean errors assume only that f is a function with a constant variance. An example, with (m-l) absolutely ro?tinuous common in biological or medical d rivatives and that f m £ 2 applications, is a binomial response L [0,1], then f becomes a function variable. This type of r",Sugi-10-181 Raynor.txt
"SAS SOFTWARE FOR LOG-LINEAR MOOELS Peter B. University of Illinois Imrey~ response, on which sampled units are jointly 1. Introduction observed. These response variables may be This paper will review the capabilities of nominal, ordinal, or scaled, or the set of current SAS*software for log-linear model variables may contain some of each type. When analyses of counted data and extensively dis- multiple dimensions of the variables defining cuss, using a variety of examples, the enhance- the r response categories correspond to ments to these capabilities incorporated in the observation of the same response under several SAS Version 5.0 procedure CATMOD, which replaces conditions or at different times, then the FUNCAT from Version 4 releases. The relation- term ""repeated measurement"" is used to describe ships of various procedures available from the array of responses. When a repeated SAS Institute and, to some extent, those from measurement response array exists in each of other vendors, will be remarked upon. Cap- several populations differentiated by l~vels abil ities of PROC CATMOD and aspects of its of one Or more experimental or observatlonal syntax that seem important, but are not factors, the s*r table is called a ""split- highlighted in the forthcoming documentation, plot"" categorical data s~t. These ~erms a~e will receive attention here as will limita- entirely consistent statlstically wlth thelr tions of the new software. Although the counterparts in the terminology of classical collection of software mentioned here provides analysis-of-variance of continuous measurement capabilities far more general than log-linear data. Categorical data analysis software . model analysis, no attempt will be made to varies in the degree of flexibility in handllng comment upon such capabilities more than the various types of structure that may exist peripherally or for contextual purposes. in the s populations and/or the r responses No attempt is made to provide a comprehens",Sugi-10-182 Imrey.txt
"s, the estimation procedure depends on which variable, if either, was fixed by the This paper illustrates the usage of the FREQ study design. The FREQ procedure therefore procedure for stratified categorical data analysis. gives different estimates for different study The procedure gives one the capability of designs. exploring the relationship between two variables after controlling for any number of stratification 1. For case-control studies (0 fixed, E variables. Statistics are printed for each random), the estimator of the common stratum, as well as for the overall summary. For relative risk is the common odds ratio. general r by c contingency tables, three types of Cochran-Mantel-Haenszel statistics are computed 2. For cohort studies (E fixed, 0 random) and to, test for partial association. Also computed for for cross-sectional studies (0 and E both 2 by 2 tables are Woolf-Haldane and Mantel- random), there is a direct estimator of the Haenszel estimates of the common odds ratio and common relative risk. risk ratio, together with 95% confidence limits and the Breslow-Day test for homogeneity of the For each type of study design, the FREQ odds ratio. Examples are given. procedure gives two methods of estimation. 1. Mantel-Haenszel estimate and test-based INTRODUCTION confidence interval The FREQ procedure provides an analysis of the precision-based 2. Logit estimator with relationship between two variables, after confidence interval adjusting for the effect of potential c",Sugi-10-183 Stanish.txt
"Descriptive Statistics: Using Indicator Variables Juliana M. Ma"" UNC Highway Safety Research Center Tamara R. Fischell, UNC Highway Safety Research Center These properties hold whether the Introduction statistics are calculated for an entire file, or for subgroups. Subgroups may Indicator variables have proved be specified using BY variables (PROe useful in certain categorical studies of MEANS), eLASS variables (PROe SUMMARY), highway safety data when counts and or GROUP variables (PROe CHART). percentages are computed and displayed. Alternative methods of producing these Applications statistics can be based on the special properties of indicator variables. We use indicator variables for Examples presented in this paper categorical studies that focus on one demonstrate the variety of ways characteristic while controlling for indicator variables can be used. other variables. One standard analysis compares different types of cars with We will present a brief description regard to rare events, such as over- of highway safety studies where these turning or post-crash fires. Another techniques are effective, and use example is the consideration of changes several examples to illustrate common in seat belt usage over time controlling applications. An intermediate-level for variables like sex and race. knowledge of SAS@ basics (DATA step, SUMHARY, FREQ, CHART, MEANS, WEIGHT Our vehicle studies of rare events statement) is assumed. involve large files, where four or five variables are sufficient to define the Definition subgroups of interest. The analysis may An indicator variable is a very be based on 100,000 to 1,000,000 simple variable with special properties. observations. We use indicator variables to count the rare events so It has two specific non-missing values: that more classification variables can one and zero. The value is defined as one for an observation that satisfies be used to define subgroups. The statistics are computed by PROC SUMMARY some criterion of",Sugi-10-184 Ma Fischell.txt
"abi 1ity"" and Abstract denotes ""given"" or ""conditioned on"", and ~~~ for the , predictors are X. , ... , X. 1 observation. Here ~ is the irifercept and the Ss Logistic multiple regression using the method of maximum likelihood is now the method of are the regression coefficients. choice for many regression-type problems involv- ing binary, ordinal. or nominal dependent vari- The nominal or polychotomous logistic model ables. Logistic regression does not require is a generalization of (1). The polychotomous grouping of observations to obtain valid esti- model has the disadvantage of requiring a large mates of effects and of outcome probabilities, number of parameters to be estimated (specifical- and it has been shown in the binary case to ly (p+1) x (c-1) where c is the number of catego- provide more accurate probability estimates than ries of y), resulting in efficiency problems. linear discriminant analysis when the assumptions of the latter (i.e., multivariate normality of The ordinal logistic or proportional odds predictor variables with common covariance mode 1 [1, sect i on 6), for an ord i na 1 dependent matrix) are violated. Even when multivariate variable having values O,l, ... ,K assumes that for normality holds, logistic regression has been 1 .~j ~ K, shown to yield probability estimates virtually as accurate as those obtained using discriminant analysis. The assumptions of the logistic regression (2) 1+e-(aj+S1Xi1+···+SpXip) model are for the most part straightforwa",Sugi-10-185 Harrell Lee.txt
"subjectJand ~ is a vector of parame:ers. Now i~ Logistic regression models are a commonly i indexes the ith matched set (of Slze N.) and J used form of analysis for categorical data. For indexes the jth individual within the ith set, matched designs, however, the usual logistic then a model that includes a separate parameter model becomes quite unwieldy. The conditional for each matched set would be logistic model is a computationally more effi- cient way of handling such matched designs. Three SAS MACROs are presented that perform conditional logistic regression in a step-up (2) scheme. An epidemiologic case-control study example will be discussed.",Sugi-10-186 Kraemer VanLier Drube.txt
"rces, Inc. ABSTRACT FORMULATION OF THE REGRESSION ANALYSIS OF TUMOR PREVALENCE DATA Trend tests play an important role in the Consider the problem of comparing K analysis of tumorigenicity experiments. experimental groups with respect to the Recently, a logistic regression model for development of a tumor that neither causes death comparing treatment groups with respect to tumor nor is 'detectable before death. Suppose that prevalence has been proposed and discussed by initially there are N i experimental units in dose Dinse, G.E. & Lagakos, S.W. (1983, JRSS, series C, volume 32, No.3, pp 236-248). Unlike the group i, i=I, ··· ,K, and by the end of the study, other available methods used to compare the information [ T , Y J X t Z ] is coUec ted treatments in animal carcinogenicity experiments for each study subject, where, (e.g. Hoel & Walburg, 1972; Peto et (11.,1980; and Gaylor & Kodell, 1983), this method provides = survival T time (time from weaning until death) direct incorporation and analysis of covariables. if subject is free of' the tumor of A general SAS program is developed to interest at death estimate the parameters from a regression y analysis of the tumor prevalence model and to compute the overall dose related trend tests if tumor of interest is detected at using the likelihood ratio, Wald, adjusted and death, unadjusted score test statistics. If the pairwise comparison of control versus treatments x """" dose level (or indicator) is desired, then the program al",Sugi-10-187 Amini Palka.txt
"ABSTRACT the presence of censored observations and is resistant to outliers. Information on the The goal of many clinical trials is to dispersion of the survival times can be evaluate the effectiveness of treatments in obtained by estimating the confidence limits prolonging patient survival. In these of the median. studies, interest is not only on what Estimation of the cumulative proportion proportion of patients died but on how long surviving and median surival in SAS is often after treatment the deaths occurred. accomplished by accessing the BMDPlL program Typically, survival data are illustrated by a through the SAS/BMDP interface. This program plot of the cumulative proportion surviving has several drawbacks. As the output from against time, and summarized by the median BMDPlL cannot be saved as a SAS dataset, plots of the cumulative proportion surviving against survival time. A commonly used approach to estimating time cannot be generated using PROe GPLOT. the cumulative proportion surviving and median The median survival time estimated by BMDPlL survival time in SAS is to access the program is the lowest, uncensored survival time where BMDPlL through the SAS/BMDP interface. As the the cumulative proportion surviving is below output of BMD1'1L cannot be saved in a SAS .5, and is an overestimate of the true median dataset, plots of the cumulative proportion survival time. In addition, BMDPlL does not survlvlng cannot be generated using PROe provide estimated confidence",Sugi-10-188 Lee White.txt
"each Xi lDay ' ·· We di.cu.. the problem of be a single number or a vector) and we boot.t rapp i n9 in SAS®. A boot 5t rap have a statistic T(X 1 ... Xn). This stat ist ic may be simple I ike the mean, macro for bootstrapping any sequence of or compl icated I ike a regression SAS statement, is prov i ded. We a Iso coefficient. We are interested in the d i .cu.a the poss i b iii t Y 0 f more apecialized (and efficient) statist ieal accuracy of T(XI"" .X n ). Spec i fica I Iy, we might .ant to est i mat e implementations the standard error of T(XI'"" X ), then bias or some other aspect of its distribution. 1. Introduction The boot.t rap met hod works as The bootstrap (Efron 1979) is a follow.. A bootstrap 5O""ple i. created power fu I too I for a .. e.s i ng the by samp ling n tI me. wit h rep Iacement accuracy of a statistical proced~re, fro. XI X2,"" ,Xn' Call these values * X2' . . X *· The st ali st icia '* It is non-parametr i c in nature and can Xl, n then evaluated for this bootstrap be appl ied to compl icated procedures. O Good references for the bootstrap are sample. Denote this by T = T( XI""' Xn * ) . Efron (1982) and Efron and Ti bsh iran i X/. . . Th i s process is repeated a large number of times, .ay In this paper we give a short (1965). description of the bootstrap and 200 time., produc i ng 200 boot.t rap o 0 0 discuss how it might be implemented in values TI ' T2 , ... T200' Unless our SAS. First, we provide a simple (but statist ic i. very simple and we only fair",Sugi-10-189 Tibshirani.txt
"CHANGES AND ENHANCEMENTS TO SAS/ETS"" SOFTWARE David Delong, SAS Institute Inc. Leigh Ihnen, SAS Institute Inc. Mark Little, SAS Institute Inc. MODEL-SYSNLI N-SIMNLIN INTRODUCTION PROC MODEL is no longer necessary. A RANGE statement has been added and missi'ng values are fully supported. All This paper contains a description of some of the data step programming changes and enhancements to the SAS/ETS statements are supported. product under the Version 5 Release of the SAS Models can be specified and System. Because a similar discussion of changes developed in sections which can and enhancements was given last year at the 1984 later be merged into larger SUGI conference (Delong, Ihnen and Little, models. Model files are now 1984), this paper will concentrate on illustrating special SAS data sets which can the additions with examples. be manipulated with standard SAS utilities. Lag logic and moving average models are now Briefly the enhancements to the procedures simplified. All SAS library covered are: functions can be used in models as well as external user-written COMPUTAB An output dataset is now subroutines. A FIT statement available. You can access table has been added to SYSNLlN cells by using the special name which controls estimation of row and column TABLE with subsets of parameters, initial indexes. Several depreciation grid searches and equations functions are now available. included in the estimation. Several options have been added FORECAST A seasonal forecasting method, to SIMNLIN to support simulation the Holt-Winters method, has of models. been added. Also, you can now specify ALPHA values for the prediction confidence intervals. In addition three new macros are included: PDLREG This is a new procedure to fit Polynomial Distributed Lag %READDRI This is a macro for reading data REGression models. A correction tapes containing data extracted can also be made for from Data Resources Inc. data autocorrelation in the residuals. banks. AUTOREG The observati",Sugi-10-19 Delong Ihnen Little.txt
"SAS' HACROS FOR BOOTSTRAPPING AND CROSS-VALIDATING REGRESSION EQUATIONS Richard T. Carson University of California, Berkeley z.Bootstrapping A.bstract The bootstrap can best be thought of as drawing samples from an initial distribution Mea9ure~ of predictive success from regres""- with replacement. This initial distribution can sion equatlon~ sucn as R2 and measures of param- either be the original obserVations or more fre- eter precision such as standard errors for coef- quently the residuals from an initial regression ficients tend to be overly optimistic, particu- equation. Just as the original observations larly, when the ratio of estimated parameters to (frequently referred to as the empirical distri- observations is not large. Statisticians bave bution) are the result of a random sample from recently proposed two non_parametric techniques, the parent population, the bootstrap observa- bootstrapping a~d cross-validation, which are tions represent a sample from the empirical dis- resampl1ng plans useful for Obtaining more pre- tribution. Under fairly general conditions, it cise eatt.ates of these statistics. The two can be shown that the bootstrap samples from the techniques are applicable in a wide range of empirical distribution approximate random sam- situations. ples from the unobserved parent population. Bootstrapping is based on creating new data As an illustration, let {X1, ··· ,xj, ··· ,X n } sets by drawing random sa.ples (with replace- be a random sample of observations. The mean ment) from the original data set (or function of value of these observations is simply the original data set), while cross-validation X= ~ n 2 Xi n To calculate the bootstrap vari- 1s based on dividing the original data set into ances !f~at X as the population mean and draw subsets and creating cross-validation data sets by leaving out one of the subsets for each pair with replacement from the original sample m of learntes and test sets. Thus both bootstrap- bootstrap samples",Sugi-10-190 Carson.txt
"data of identifying information such as names ---- and addresses does not provide sufficient Randomized response is a technique for protection to respondents, since if some of collecting survey research data of a sensitive the other variables were known from public or nature. The transformations used in other external sources, these variables could randomized response may also be used to be used to perform matches and hence identify individual respondents. Warner (1971) noted contaminate pre-existing data sets so as to allow their release to external investigators, that randomized response transformations could while protecting the confidentiality of the be used to contaminate the pre-existing data respondents. A major drawback to randomized sets in such a way that individual responses response has been the inability to perform and respondents could not be recognized but multivariable analyses that examine the that the data set could still be used to relationships among two or more variables. produce statistical estimates and inferences. This paper presents the necessary methodology Rosenberg (1979) describes one such for performing multivariable analyses of transformation. categorical randomized response data utilizing THE TRANSITION MATRIX the SAS· procedure FUNCAT.",Sugi-10-191 Rosenberg.txt
"SAS Methoclsfor Obtaining the Exact Hypotheses from Type I, n, m, and IV Estimable Functions in Terms of Cell Means Model P.K. Tandon and Richard R. Lustiek Sterling-Winthrop Research Institute Rensselaer, New York: Miller (1981) refers this over-parameterized model as ""Beta"" model. The GLM procedure produces four types of sums of squares, namely Types I, II, III and IV. To The least squares normal equations can be de term ine the hypotheses being tested by each type given by: of sums of squares, GLM prints the estimable functions associated with the effects in the model. (X'X)b = X'y These estimable functions are difficult to interpret especially in the presence of empty cells, The cell To solve these equations SAS uses g2 means model (i.e., ~ .. ) is sometimes used as a generalized inverse matrix. This solution gives only alternative procedurelJ of hypothesis testing in certain linear combinations of the solution vector General Linear Models aod these hypotheses are elements to be estimated. Searle (1971) defines easy to interpret. estimatability as II a linear combination of the This paper presents SAS Macros which can be solution vector, q'b, is estimable iff a linear used to ob~ain the exact hypotheses being tested by combination of the expected value of the the four different types of sums of squares in terms observation vector, t'E(y) is equal to q'b II. The GLM of the cell means model. An example is presented produces the set of such linear combinations in the to illustrate the output from the macros. terms of general form of the estimable functions as determined by METHODS mo~el: Let us consider a two-way fixed effect (X'X)- (X'X) Therefore, q'b is estimable if a generating set of Y··k = P + A. + B· + (AB) + ij~jk IJ IJ linear combinations (L's) from (X'Xf(X'x) are estimable. The general form of the estimable where, functions and different types (Type III or Type IV) of estimable functions may be obtained by specifying Yijk :; observed value of kth Observa",Sugi-10-192 Tandon Lustick.txt
"BOUNDED INFLUENCE REGRESSION USING SAS SOFTWARE David Giltinan, Merck Co., Inc. & ABSTRACr influence regression estimate described below has -two main advantages: (i) it provides an estimate In the usual linear rrodel, under standard of .a. which is representative of the bulk of the assumptions, the least squares estimator of the data and which is insensitive to changes in any regression coefficients enjoys a variety of opti- small subset of the data (ii) t--he met_han TTIF.Iy al!=:O rna.li ty properties. However, if the standard be used as a diagnostic tool. As will be seen be- assumptions are not met, use of ordinary least low, the estirna.tor works by dO\'mWeighting poten- squares techniques can be disastrous. In parti- tially influential points. A data point which is cular, the existence of one, or rrore, erroneous severely downweighted is thus tagged as being data points can have a considerable effect on the highly influential. In such a case the data ana- least squares estimate. l yst may wish to examine the point rrore closely. A point can have a large influence on the In the next section we give same general least squares estimate for two main reasons: (i) background on rounded influence regression esti- it may have a large residual or (ii) it may have mates and define the particular estimator which high leverage. In the recent literature, nl.llIer- we shall consider. Section 3 illustrates the OUS proposals have been made to overcOlTE this rrethcxi using data involving rreasurerrents on ""'later lack of robustness of the least squares estimato~ salinity and river discharge in Pamlico Sound. Mallows (1975) proposes a class of 'bollllded in- The analysis is discussed in Section 4, while the fluence' estimators, which automatically lirrUt final section gives details on how to use the the influence of any small fraction of the data. program. This paper presents a SAS macro for computing such a rounded influence estimator and illustra- 2. BOUNDED INFLUENCE REGRES",Sugi-10-194 Giltinan.txt
"ied and r(X;B) is relative risk regression model to l-R matched the hazard relative to a nonexposed subject X = case-control data using an exact conditional O. The quantity r(XjB) is called the relative likehood, where R is the number of controls and hazard. hazards ratio or incidence density may vary for each matched set of individuals. ratio. Strata are incorporated into the The procedure outputs maximum likelihood proportional hazards model by defining stratum parameter estimates, their standardized values specific hazards. p-values. the asymptotic covariance matrix and the maximized log-likelihood. Up to six different models can be s_pecified involving sets of covariates. The procedure also outputs a chi-square based on a score statistic to test Applying this model to casewcontrol data, one the contribution of additional covariates in matches on time (usually age) and, perhaps, nested models. To test the influence of each other stratifying variables (Prentice and set on the overall estimation, an option has Breslow, 1978; Greenland and Thomas, 1982; been included in the procedure that estimates Lubin, 1985). the parameters when each set is singly excluded from the data. The parameter estimates are If time to disease event is not available obtained using an iterative NewtonwRaphson or ignored, then one may apply a logistic method. The procedure supports BY group regression model for disease incidence defined processing and also outputs the parameter as estimates to a SAS d",Sugi-10-195 Kalyandrug Lubin.txt
"Division, elBA-GEIGY Corporation Abstract An associated 95% confidence band for the mean of y given x can be expressed as: In an experiment where samples from various ,(~ t treatments are drawn and observed over some 2 x. prespecified length of time, regression meth- J Yj ± t. 975 ,df + ods are often used to fit a line and confidence n nO -2 band representing treatment behavior over the L (x - x) j time frame. The best fitting regression line is one that takes into account treatment effect and the results of tests of homogeneity of where Yj is the fitted value from (1), t. ,df treatment slopes. Unfortunately, a line created 975 th by the SASjGRAPH R-series interpolation command is the 97.S percentile of the t-distribution RLCLH would be from a model where these condi- with n-2 degrees of freedom, S2 is the error tions have been ignored. Therefore, a macro is written which uses the output from PROC GlM mean square, and nO is the number of observa- to construct a line and confidence band that tions at Time O. best represent the data after evaluating these conditions. Now suppose we have several batches. Then a model including a batch effect with corre- sponding equation is: Background + (2) £ .. Consider a set of drug stability data where 'J batches of tablets of some product are assayed i 1, . , , , I batches . th over some pre-specified time frame beginning at 1, ... ,n observations in the ~ batch j Time 0 (initiation of stability testing), with i the objective being to esti",Sugi-10-196 Hait.txt
"COMPARISON OF MULTIVARIATE REGRESSICN ANALYSIS BEIWEEN IIJGISTIC M:JDEL AND THE LEAST SQUARE M:JDEL USING Sl\S SOF'IWARE Joyre S. Kim, Pennsylvania State Depart:rrent of Health George K. 'Ibkuhata, Pennsylvania State Depart.nent of Health Jane R. Bratz, Pennsylvania State Departrrent of Health Researcher wishes to investigate a set of ABSTRACr the most contributing variables for prediction equation which will explain structural rela- From our past experience with multiple re- tionships. In the rrean tine, independent gression analysis of discriminate functian with variables should l::e carefully selected, with dichotcm:ms dependent variable, encxruntered 'We or without sorce pre-established statistical the predicted value of the dependent variable criteria are available. fell outside of the interval 0 and I, which is The STEf'IiilISE regression prcx:edure (7) is inconsistent with the definition of probability. most helpful for exploratory analysis when we The multiple logistic regression rrethod is gain- have a collection of independent variables and ing wide acceptance in data analysis where si- want to find which of the predictor variables multaneous adjustrrent for a number of confound- should be included in a regression rro::lel. The ing covariates is desired. STEPWISE regression procedure is a useful tool This paper presents the implementation of because it provides us insight into the rela- the IIJGIST procedure (1) and GIM (General tionships between the predictor or independent Linear Model) of least square prooedure (7) of variables and dependent response variable. The the SAS software for the multivariate regres- result of the STEIWISE procedure yields an sion analysis. Several investigations took optional prediction equation with rranageable place for selection of regression analysis parar number of predictor variables. rreter and experinented those two rrodels CUX;rST There are several selection strategies and GIM) for various population sizes with avail",Sugi-10-197 Kim Tokuhata Bratz.txt
"is in the interval (xk - do/n 1/ 2 , xk). The When the object of an experiment ;s to select constant d is the solution of the integral the best of a number of treatments, then the use equation of multiple comparison procedures is ineffi- _£OO(.(X + d))k-l ~(x)dx = p* cient. A subset selection procedure which ~(x) .(X) where and are the cumulative and selects the smallest subset which contains the frequency distributions for the normal distribu- best treatment with pre-specified confidence ;s tion. preferable. Examples are the procedure of Gupta Somerville (1984) proposed the following (1956, 1965) and the recently proposed multiple multiple range subset selection procedure: range subset selection of Somerville (1984). choose the smallest value of j such that This paper includes preliminary tables and (xk - Xj) < d k_j 0/n1/ 2 and include in the algorithms for the case where the underlying subset populations j, j + 1, ... , k. The common variance is unknown, but for which an constants di are functions of p* and k and are estimate with v degrees of freedom is available. tabulated. It has been shown by duPreez, An example is included. Swanepoel, Venter and Somerville (1985) that in terms of the expected size of the subset, for Introduction k = 3 the procedure is uniformly better than Gupta's procedure for p* ~ .98. Extensive Monte In the analysis of data involving several Carlo sampling indicates that the procedure treatments, the usual first step is to conduct compares very wel",Sugi-10-198 Somerville.txt
"Data from the behavioral sciences are often analyzed by normalizing the scores Population: Z = (Xi for individuals in experimental subgroups to a reference population. Normalized X) = I s ref Sample: Z (Xi - scores, called Z-scores, may then be used ref to compare performance relative to the reference group either across the Where: experimental subgroups or among different Z Normalized Score variables. Individualized Raw Score al~ow Summary procedures group statistics to be output to SAS data sets. These data sets may be reshaped using the Reference Mean Scores MATRIX and TRANSPOSE procedures before being brought together via SET and MERGE Reference Standard Deviation statements. The result is a compact table of normalized scores with SAS variable labels identifying the tests presented. Addition of the reference values to the table allows the reader to extrapolate information about the experimental subgroup means and to compare the reference group to The resultant Z values are unitless other popUlations reported in the scores indicating the number of standard literature. Further, the percentage of each subgroup having absolute Z-scores deviations by which the corresponding raw score lies above or below the mean of the greater than an arbitrary cutoff could be added yielding an even better definition of reference distribution. The reference group is characterized by a Z-score mean of the experimental subgroups. For example, absolute scores greater than 1.64 indicate zero and standard deviation of one. If an individual has an absolute Z-score of 1.64 that an individual is performing at a level different from 90% of a normally or greater, he is performing at a level different from 90% of a normally distributed reference group. distributed reference population.",Sugi-10-199 Owen.txt
"rsity of Illinois at Chicago ABSTRACT link to the SeA Statistical System. PROC SCALINK provides SAS users a SeA formatted SeA PROC LINKSCA will read an file into SAS. An formatted file can be creatad by the SeA System or by SAS (via a new opt i on in 1 i nkage between The advantage of two way PROt SeAL INK) · SAS/ETS software and the SeA statistical system is illustrated. An SAS dataset is created and passed to SeA which in turn is used to estimate a vector autoregressive (VAR) model. The VAR coefficients are saved by SeA ina f i 1e wh i eh is then read back into SAS for processing by the SAS/ETS PROt MATRIX procedure MRATIO which is used to transform the estimated VAR model to vector moving-average (VMA) form. Documentation for the PROC LINK5CA is provided. Options I NTRODUCT I ON 1. BROWSE specifies tt.at the SeA file on UNIT In a recent paper, Stokes and Liu (1984) wi II be ::>""'Clllned and comments and illustrated how PROC SCALINK could be used to control statements printed. augment the time series capabilities of SAS/ETS (1982) with the extensive additional time series NOPRINT specifies that PROC LINKSCA will capabilities of the SeA Statistical System which not display data loading was developed by Liu. Hudak. Box. M.uller and information. liao (1983). PROC SCALINK allowed for one way communication from a SAS job to SCA. A PRINT specifies that PROC llNKSCA will disadvantage was that the extensive time series display data loading information. manipulation capabil ity of t",Sugi-10-20 Stokes Liu.txt
"******* trhe SAS Macro Facility ® An Introduction · Macros to · Macro variables Macro Processing · Macro progra7n state7nents ******* · Macro functions Lynn Ha,nnah SAS Institute Inc. ? ***** eTo produce strings of text which are What is cits rnost often used to construct S AS prirnary function ? statements or parts *** of SAS statements ** /, _To per form conditional ***** execution of S AS code oTo generate repetitive What are its code oTo provide users with . appU~cations ? a building tool oTo allow the design of ***** complex, user-friendly ~; menus and systems 5 6 The SAS System *** * before Macro * * The I MaC1""O SAS Compiler [--------1 Source ------1 Supervisor Processor ar Code I Procedure Parser ****** 7 8 1121  The S AS Syst.-rn after AI aero ***** The Role oj the YES W ordscanner I ***** Icompiler .. ~~m tm~~r:r ~~ ~M""W:;~;,~"" :~~,: fil::;~~perv~:. 9 -~ Major Corn.,ponents of .Checks for &'s and %'s followed by non-blank the Macro Processor tokens and passes the1n · SY1nbolic Substitution to the 1nacro processor · Open Code Handler .Passes the first word of each sta tenten t to · Macro Compiler the 1nacro processor if · Macro E xecu tor the IMP LM AC option icn -f -forof 12 11 0'0 0 Handlring oj &'s Handling oj %'s I&-Variable I -1 Reserved Act Local I.... r"" on it Word? L-T_a,bl_e-t I en S¥;::'?~l ...J c:to Compiled Macro Symbolic --+--- ode __, Exeoutor Macro? Handler ubstitution Manager I Lm1 JfA.RN1NC Neither f.. - 1353 13 14 his dia ram not leet the autocall acilit dOQS 1'8 .The SAS supervisor * * * * * per forms sequential Processing execution .The SAS compiler oj accepts tokens until SAS Code it encounters a step boundary * ** * * 15 16 1122 These staternents force ***** step boundaries Processing · a DATA statenwnt of · a P ROC sta temen t Mac1~o Code · a RUN statement · a PARMCARDS or ***** CARDS statement 17 18 ~hat Happens When? ***** Macro Macro ComFils ! Compile SAS Macro --------- <---. Execution Compi/e Time J SAS ***** Execution 20 19 .",Sugi-10-200 Hannah.txt
"is compiled and executed separately and in sequence. Figure 2 shows the This tutorial is a discussion of the structure of a traditional modular SAS~ Macro Facility as a tool to enhance system, in which a main routine controls system execution and calls subroutines SAS' performance as a programming language. The focus is on using Macro as needed. Figure 3 lists four major to construct modular SAS-based software requirements of software systems, and allows one to compare SAS without Macro systems. Modular structure, conditional execution of SAS code, and the use of to traditional programming languages as Macro variables as software system to the ability each has to satisfy the parameters are the key elements of the four requirements. tutorial. The first feature or requirement is modular structure itself. This",Sugi-10-201 Phillips.txt
"DEVELOPING AND USING MACRO UTILITY LIBRARIES DAVID S. SEPTOFF, ORI INC. KATIE A. HUBBEL, ORI INC. Z. Building the Utility Library 1. INTRODUCTION What should be included in a Nacro Utility Library depends on the needs of de~cribes This tutorial the those who would use the library. A advantages of using a SAs-Macro utility general nlle is that any Macro which A Macro Utility Library is a Library. a perfOl""mS commonly needed function collection of macros which perform E~ould be included. There is virtually functions common to many applications. on this type of Macro. Some JiPljt no These macros can easil¥ be used within examples would be~ any program by using the %INCLUDE statement. Given the c~pabilities of the FORMATS o crest ion of SAS from %INCLUDE statement, one- may ask ""why in SAS information stored data Macros?II, why not just %INCLUDE code to sets(see Figure 1) * perform the needed task? The answer is simple. The Macro Facility has o creating a Macro variable whose increase~ our ability to use SAS as a value is the number of observations languag-e. The prograrnmlng I""lacro in a data set Facility contains features that basic SAS does not. Specifically,. Macros can e~ecutlng o conditionally (if there be used to: are t.ransactions) an UPDATE step. o replace repetitive code; o conditionally execute code; Per hops the most useful types of Macro Utilities are those that o execute parameter driven code facilitate the program development (this beconles increasingly These are M.acros that. a~si.st. process. important when in a syster[l the programmer jn debugging and testing envj fonment) ; of code. exaropJE'f prints on data For the sets are needed to test whetl)pf o retain variables across SAS logic is flowing properly. Frequencjes steps; as a debugging tool. are also useful Both of these debugging tools can be put o package long, detailed programo together as Macros with parameters that making them available wi tb one will allow the user to suppress the simple comm",Sugi-10-202 Septoff Hubbel.txt
"Macro Quoting Functions Jerry Mock SAS Institute Inc. Quoting Functions Available in the SAS Macro There are three components of the SAS macro Language language that use the above characters to di rect thei r action. The components are the Compile time functions macro compiler, the macro executor, and the string evaluator (%EVAL). %STR(argument) °6NRSTR (argument) Compile time functions Execution time functions %STR(argument) %QUOTE (argument) %NRSTR(argument) %BQUOTE (a rgument) * %N RQUOTE(a rgument)* The macro language is a text string processor. %N RBQUOTE (argument)* Some characters that may appear in a text string have meaning to the macro compiler. %UNQUOTE (argument) The following example illustrates a conflict of meaning: %MACRO FREQ(T); *new with Version 5 of the SAS System %IF &T,= %THEN PROC FREQ; TABLE &T;; %ELSE %PUT FREQ MACRO REQUIRES A VARIABLE; %MEND FREQ; Why do we need Quoting Functions? %FREQ(AGE) Definition: Token In the above example we wish to emit ""PROC FREQ; TABLE AGE; Ii A token is a sequence of characters to the SAS System. However, the macro is that is treated as a single data item. compiled and stored as: %IF &T,= %THEN PROC FREQ; There is a class of characters that are tokens and that the SAS macro language uses these TABLE &T;; %ELSE %PUT FREQ MACRO REQUIRES A VARIABLE; characters for its lexical scan. These characters are typically called the When invoked, the SAS System will see ""special cha racters. "" A partial list follows: PROC FREQ TABLE AGE;; semicolon delimits SAS statements comma separates parameters The semicolon is missing from the PROC FREQ arthimetic perform calculations +- statement. When coding the macro FREQ we need operators /* a way of masking the meaning of the semicolon comparison perform boolean < from the macro compiler so it can be passed to ,> operators arithmetic the SAS System. logical combine boolean & operators left collects parameter Masking the meaning of characters parenthesis list right ends parameter",Sugi-10-203 Mock.txt
"USER-WRITTEN DEVICE DRIVERS Howard Houston, SAS Institute Inc. INTRODUCTION LEVELS OF INTERACTION User-written device drivers have the advantage The degree of intet'action between the intemal of allowing users to tailor device support to their and the extet""nal drivers is controlled by the specific needs. This can take the form of an developer of the external driver. There are two environment that does not allow the standard main levels of interaction possible between the Institute support or a graphics device that is not internal driver and the external driver. At both supported by the Institute. Pr'eviously, the only levels of interaction the external dt""iver can way the users can provide their own support is handle the communications with the graphics with the linkable device dr'iver. This set'yes device, but at the more interactive level the many users needs' quite well, but it is not internal driver can be used to communicate with device intelligent and is designed more for use the graphics device. This frees the developer of with a plotter than with a CRT. the external driver from supporting communications with the graphics device. In Version 5 of the SAS/GRAPH product, there is a new method for user support of a graphics The lower level of interaction is when the device. This method will allow users to develop external driver is a post-processor. The device-intelligent drivers. These device drivers internal driver only produces the metafile. Aftet' are not linked into the SAS System. This the SAS/GRAPH program is finished the user removes the need to link your device driver with must execute the external driver to produce the each new system release and allows this type of graphic output. The external drivet' must device driver to be used with systems that do support all communications with the graphics not allow the linking of external routines with device. the SAS System, as is the case with minicomputers. In addition, this method of The higher level of in",Sugi-10-204 Houston.txt
"UNDERSTANDING THE ANNOTATE FACILITY REFERENCE SYSTEMS Anthony L. Friebel SAS Institute Inc. The reference systems form a unique framework Example 1. The NOTE statement shown produces a box on for data handling within the ANNOTATE Facility. This framework permits a wider degree of the screen. The data set CELLS performs the identical function and illustrates the conversion flexibility when communicating graphic requests of the NOTE statement format into the equivalent of the system. No longer are you forced to ANNOTATE data step code. convey your message only in grid cell measures. Percentage measu rements, relative measurements, Old NOTE format : and, for the first time, actual data values can be used in referencing coordinates on a graph. These unit specifications may be intermixed in PROC GSLIDE; any of the ANNOTATE Facility functions. NOTE .C=GREEN .D=( 30, 10, 50, 10, RUN; 50, 20, 30,20,30, 10); I. ABSOLUTE SYSTEMS ANNOTATE format DATA CELLS; A. SCREEN VALUE / SCREEN PERCENTAGE LENGTH FUNCTION COLOR $ 8; XSYS = '4'; YSYS = '4'; COLOR=' GREEN' ; Users of the NOTE statement are already familiar FUNCTION='MOVE' ; X=30; Y=10; OUTPUT; with the SCREEN VALUE ('4') system. The FUNCTION=' DRAW' ; X=50; Y=lO; OUTPUT; display area is divided into grid cells as FUNCTION= , DRAW , ; X=50; Y=20; OUTPUT; measured by the GOPTIONS HPOS= and VPOS= FUNCTION=' DRAW' ; X=30; Y=20; OUTPUT; parameters. SCREEN PERCENTAGE ('5') defines FUNCTION='DRAW' ; X=30j Y=10; OUTPUT; this area in a more constant 0 to 100 field. RUN; Because the SCREEN VALUE system depends PROC GSLIDE ANNOTATE=CELLS; entirely on the HPOS= and VPOS= values to RUN; determine screen size, it is a more volatile coordinate system as parameters change from ° device to device. By always specifying the range The code below converts the above value as to 100, the SCREEN PERCENT system helps to guarantee device independence of ANNOTATE specifications to the equivalent percentage generated graphics. values. DATA GELL2PCT; Fo",Sugi-10-205 Friebel.txt
"A NEW TOOL FOR THE INFORMATION CENTER: SAS/AF SOFTWARE Phil Busby SAS Institute Inc. SAS/ AF software is a new to01 that allows SAS DISPLAY have a required parameter, the catalog programmers to create full screen menu specification, of the form application systems for non-technical end users. CATALOG=libref . member .object. type. PROC This tutorial covers the preparat~on of Help, BUILD needs only libref .member. The libref is Menu, CST, and Program screens using PROC. the external data set reference that most IBM BUILD. The SAS programmer can easily tie users call the DO. You must assign this logical these screens together into a complete name to the physical data set where you want your screens to be stored prior to executing a information center tool that end users may access through PROC DISPLAY. SASI AF procedure. The libref you specify may also contain regular SAS data sets. They are kept separate by the system through the second part of the catalog specification, the memname, PROC BUILD, which gives you the powerful which is any unique identifier up to six Display Products Editor to facilitate screen characters long that you may choose. The creation, will be demonstrated, and many useful editing commands will be illustrated. You will memname specifies a group of screens within the libref. see how to set up branching to other screens in response to the user's menu selection. At the heart of SAS/ AF software are program screens, The thi rd part of the catalog specification is the consisting of (optional) displayed text that the screen name, also called the object name. Let me user sees and SAS statements that are submitted point out here that ""screen"" and ""object"" are the to the SAS System. The technique of substituting user-keyed values into the SAS same thing in SASI AF software; the terms refer to a collection of lines that are displayed together source statements will be discussed. The use of in a full-screen environment. An object may SAS macro variables",Sugi-10-206 Busby.txt
"TECHNIQUES FOR USING THE SAS® SYSTEM IN AN ON-LINE PRODUCTION ENVIRONMENT Barbara Kennedy, SAS Institute Inc. Yes, you can operate a company using the available through one command that brings in SASe System. their screen. Then at the touch of a key, or entry of a macro name, they are able to perform The Management Information Systems Department at a specific function. SAS Institute provides a variety of programming services to every department and person at the CONTRACT MAINTENANCE MENU SCREEN Institute. There are over 22 departments who regularly use applications developed by MIS. All of these systems were written using SAS software. Included among these departments are Administration, Finance, Education, Sales, Legal, Marketing, and Operations. There are approximately 150 employees out of 500 actually logged on and executing these SAS programs on a daily basis. These systems include book orders, inventories, work CONTRI\.CT MAINTENIUICE INeORAATlON schedules, documentation libraries, software SYSTEM sales, payroll, fixed asset accounting, personnel applicants, and everything else a CONM company needs to operate on a day-to-day basi~. I The MIS Department has established guidelines or I I INSTALL I LAST SASCOM I I MAIL LIST I DATA !>ASE I CO/olMND goals for system design to include: I I I I · consistency of design · using a modular approach to programming (which provides for) · ease of maintenance Behind the user1s screen is modularized code in · flexibility (and) the form of macros, each one invoking code · user control. necessary to provide the user the ability to perform their desired task. These macros may This is accomplished by using menu-driven contain code that submits a job for later systems written with base SAS software, making execution, brings in SAS code that runs use of its macro facility. We have successfully interactively, or executes one of the many SAS used this design under both TSO and CMS. System products. These systems can be as simple as a",Sugi-10-207 Kennedy.txt
"REPORT WRITING: A CASE STUDY Ann Lehman, SAS Institute Inc. Tim Lehman, SAS Institute Inc. How is The Tape Constructed? The following paper is a modified version of the case study presented in the SAS® Processing The data tape contains twenty files named course. This study was designed to illustrate to US1960, US1961, """" US1979. Each file contains intermediate level students the wide range of SAS daily weather data for the United States for one capabilities that may be needed in a report year. One record contains the data for all writing assignment. A complex INPUT program reporting stations for one day. The number of is used to read mUltiple raw files; SAS reporting stations each day varies and is not procedures are used to verify and summarize the known but ranges from 225 to 245. Each station data; SAS data management techniques shape a reports 21 numeric variables and, if a reporting data set to fit a report design; a tailored report station has missing values for any variable, the is written. variable is given a missing value code. Each file contains a record for each day of the year beginning with January 1, but the date is on the What I s The Task? records. Examination of the documentation reveals that the station code numbers 24281, You have obtained a tape of twenty raw data 24233, 24157, and 94240 identify the stations files. The files are composed of records of daily Seattle, Takoma, Spokane, and Quillayute, weather data from all reporting weather stations respectively. You need to read the weather in the United States for years 1960 to 1979. You information for these four stations from three raw have been asked to design a report that presents files named US1977, US1978, and US1979. The a concise summary of weather for the state of variables to be read are station number, maximum Washington during the years 1977 to 1979. and minimum temperature, rainfall, and snowfall. The files were written using unformatted Example of Output Report. FORTRAN write stat",Sugi-10-208 Lehman Lehman.txt
"the top of the table. Sub-totals appear for each department. Table cells are formatted using DOLLAR and COMMA formats. There are several enhancements to PROC TABULATE available in the next major release of The principal SAS statements used with PROC the SAS System. This tutorial begins with a TABULATE are review of the fundamental language features of TABULATE. The rest of the tutorial describes supplies classification levels. CLASS enhancements including supplies numeric values on which VAR correct interleaving of crossed subgroups to compute statistics. application of user-defined formats in table describes how to classify the TABLE cells data, what values to compute, and how to arrange the values in a CONDENSE option to put mUltiple logical the table. pages on a single physical page a BOX option to put page dimension text, a Other important statements include KEY LABEL, variable label, or a character string in the LABEL, FORMAT, TITLE, FREQ, WEIGHT, and empty box over the row titles BY. using analysis variables in denominator defi n ltion s. Contents of a table cell Four things define a table cell: The new algorithm for interleaving crossed classification levels: DEPT ACCT subgroups is most useful for locating subtotals of classification groups immediately following the levels of each group. Using analysis variables in a single analysis variable: AMOUNT denominator definitions allows better handling of multiple response variables. Improved algorithms a single statistic: SU",Sugi-10-209 Eaton.txt
"AN INTERACTIVE IN'l'ERFACE FOR SCHEDULING YOUR WORK FORCE Michael J. Cybrynski SAS Institute Inc. I f this program is to be beneficial and INTRODUCTION practical, it should also have the capability of: The technical support department at SAS Institute Inc. faces the problem of scheduling preparing a schedule in advance, its consultants (currently 29!), every week. differentiating between personnel, The department has outlined very specific cri- assigning consultants randomly and uni- teria for staffing the phones: criteria dic- formly, tated by the needs of our users and the needs accounting for weekly variations in: of, and the considerations given to, our o responsibilities, employees. These requirements must be fulfilled preferences, weekly. conflicts, o holidays, and Whenever you manage people, however, you vacations, must account for any holidays, vacations, meet- being understandable and useable by ings, appointments, and other conflicts that may those unfamiliar with the SAS System or may not be anticipated. Rather than leaving and/or linear programming, and the conflicts to be resolved by those involved, we have always tried to account for these being easily adaptable to changes in: o personnel, ""exceptions."" Less ""switching"" tends to mini- mize confusion and the number of ""missed"" hours. the length of a work day, However, this can lead to a very large combina- the number of days in a work torial problem. week, and the number of consultants needed Until recently, this problem was always during any particular hour. begrudgingly solved by hand, requiring two peo- ple for almost an entire day. Since the intro- THE INTERACTIVE INTERFACE duction of SAS/OR'"" software, this problem is solved using the SASe System. The SAS System The interactive session is used to enter is ""black boxed"" as an interactive tool that can information that is variant from week to week be used by almost anyone. only a minimal amount (meetings, appointments, vacations, conflicts, of data",Sugi-10-21 Cybrynski.txt
"PROC TABULATE Applications Andrew A. Norton, OR! Inc. would be more expensive. Suppose a PRoe TABULATE is exceptionally large dataset is to be summarjzed, and flexible and powerful. Its syntax allows the specification of an endless both a SAS dataset and PROC TABULATE variety of tables. The structure of the table are desired as end products. PROC table is further specified by the input SUMMARY and PROC TABULATE could both be data itself -- the table becomes larger run independently, but this would entail or smaller as needed, automatically two passes of the large dataset. A much more economical solution would be to use splitting into multiple pages. The result is nicely formatted and a variety PROC TABULATE to format and print the of labeling options is provided. dataset created by PROC SUMMARY. The second procedure would only need to In addition to the formatting of process the small summarized dataset. tables, PROe TABULATE also computes the In fact, PROC SUMMARY is more efficient statistical results reported in the than PROC TABULATE at reducing large tables. The statistics supported are amounts of data to summary statistics, the same as those supported by FROe so this method can be more efficient SUMMARY. even when the PROC SUMMARY dataset is not of interest in itself. In some applications, however, PROe TABULATE cannot compute all of the Basic Method statistics that we would like to present in a PROC TABULATE table. This paper All variables used in the TABLE will describe techniques for using PROC statement defining a PROC TABULATE table TABULATE to format and report must be declared in either the CLASS or statistical results obtained from other VAR statements. Variables declared in sources: other procedures, DATA steps, the VAR statement are called analysiS other statistical packages and programs, variables; variables declared in the published data, and so on. In effect, CLASS statement are called class or the statistical computation phase of classification v",Sugi-10-210 Norton.txt
"tract This paper describes a technique that uses the SALES DATA SET SAS DATA step to produce customized tables. The table can have any form either rectangular TOTALRET NUMBER REPNAME l or otherwise, and the data displayed within the table can be of any desired type. The program FOSTER 119.9 6 used to generate the table is simple in concept. FOSTER 400.0 2 FOSTER 400.0 2 Introduction FOSTER 297.0 3 FOSTER 6200.0 2 The SAS System is capable of producing any type FOSTER 3100.0 1 of report that a line printer can print. Many GRANT 40.0 2 procedures exist for generating reports. These GRANT 20.0 1 work very well when the format of the report GRANT 20.0 1 does not have to be too specific; however, if the GRANT 1749.9 5 format of the report must be very exact, the GRANT 700.0 2 DATA step is an easy and powerful way to GRA.NT 124.7 25 produce the report. For instance, a table that GRANT 24.9 5 summarizes sales activities such as the following GRANT 200.0 1 can be easily produced with the DATA step: GRANT 12400.0 4 GRANT 2189.0 11 GRANT 199.0 1 Sales Rep: The total 1 1 1 Overall 1 dollar GRANT 52.0 2 FOSTER GRANT amount 1 GRANT 52.0 2 1-----------------------+-------------1 sold is: 1 1 Units 1 1 1 1 1 1 Sold, 1 16 1 62 1 78 1 1 1-------+-------+-------+-------------1==> $28,288 1 IRetail 1 1 1 1 1 2. Summarize the data set using the SUMMARY IMean 'I $1,7531 $1,3671 $1,489 1 1 procedure: PRoe SUMMARY DATA=SALESj This table is impossible to generate using any CLASS REPNAME; current SAS",Sugi-10-211 Roach Kelly.txt
"OF THE SAS* LOG ENHANCING SAS* SOPlWARE SKILLS THOOUGH A BEITER UNDERSTANDING Judith MopsiJ~, ORI Inc. Arme Asher I ORI Inc. will enable SAS NOTEs ERRORs and Testin g a compu ter progra m is a to debug their code more progra mmers task that someti mes takes as long as and to develo p effici ent exped iently design ing the progra m and writin g the for testin g their progra ms. strategie~ code; someti mes it takes twice as longi tOP1CS to be addres sed in the The and someti mes it comes back to haunt us sectio ns that follow are: has been progra m the after long In the past releas ed for produ ction. A system atic approa ch to o the testin g of compu ter years ten readin g the SAS LOG. progra ms has been sir[lpl ified. First, compu ters have become so fast, that Messag es associ ated with o of luxury the have progra mmers readin g and writin g data. debugg ing their work almost immed iately In a few hours, after it has execu ted. which proble ms Data o numero us combi nation s of data values genera te NOTES or ERRORS. progra mming Second I can be tested . langua ge syntax has evolve d into an Detec ting logica l errors o senten ce struct ure, making ~ngli5h-l~ke for strate gies and code, write to eaSler l.t succes sful testin g. theore tically to debug it. Yet, with both of these drama tic improv ements in the compu ter progra mmer' s enviro nment , or method s for thorou gh style the A SYSTEMATIC APPROACH TO READING testin g of progra ms has not change d. THE SAS LOG When a progra mmers is faced with a perple xing error, he may still try a number of futile approa ches to resolv e The LOG is the key to how well the the proble m with no true unders tandin g what the perfor med Superv isor SAS While we have come a of its cause. The simple m told it to do! progra way in the last 25 years from lon~ inform ative messag es at the beginn ing it's ready"" , we ""it compi led, sa-¥lng , of the SAS LOG and the NOTEs after each have not develo ped metho dical stlll or proced ure",Sugi-10-212 Mopsik Asher.txt
"SAS® TUTORIAL: MULTICOLLINEARITY AND VARIABLE SELECTION R. J. Freund, Texas A&M University Multicollinearity. the existence of strong correlation among independent variables in a regression, hinders estimation and interpretation of the partial regression coefficients of the model. Methods have been developed to assist in the detection of multicollinearity. Methods to alleviate the effects of multicollinearity are also available. This tutorial uses an example to illustrate the multicollinearity detection options in PROC REG. This is followed by illustrating the most popular remedial tool : variable selection using PROC STEPWISE and PROC RSQUARE. Finally a different alternative. principal component regression is illustrated using PROC PRINCOMP. The tutorial is in the form of a set of transparencies which are not reproduced here. Full size copies which can be used to create the transparencies are available from the author . . · 1215",Sugi-10-213 Freund.txt
"er multivariate SAS S Procedures are illustrared using a bird Developing a model is an iterative process involving interactlve habitat data set. The objective of the ana!ysis is to assessments of the model form, distributional assumptions, discriminate among four sparrow species basl2d on l2ight habitat outlil2rs, and col linearity. Thl2 interrelationships of these variables. Emphasis is given to assessing the assumptions of concepts are what makes modeling a creativl2, but difficult, the discriminant model. DISCR1M and PRINCOMP are used to task. A starting place is to examine the univariate graphical Bl!amine the assumption of equality of covariance matrices. presentations (stem-and-Ieaf, box, and probability plots) and Collinearity is evaluated by PR1NCOMP and STEPDISC. Outliers nurr.erical summaries (e.g., means, medians, standard are determined from the Mahalanobis distances, which are deviations, and pseudo-standard deviations). Since species Normal ity is thl2n computed from the output of D!5CRIM. differences would distort the distribution of values for any assessed by constructing gamma prObability plots from these variable, the analysis should be done within each species. The Mahalanobis distances. Both weighted (based on Mahalanobis SAS statements are: distances) and unweighted canonical discriminant analyses are PRoe UNIVARIATE OA T A~IN.5PARROW PLOT NORMAL; performed using CANDISC. The important variables are ""selected by invoking STEPD/SC. H BY SP; VAR BAC LC FC 5",Sugi-10-214 Harner.txt
"where ei is a random variable about which certain assumptions are made. The In this article we assume a b's are fixed parameters called familiarity with the SAS ® software regression constants. It is convenient package and with the rudiments of least to represent the n equations above using squares linear regression analysis. In matrix notation Section I we review some of the relevant literature. The default output from PROC Xb y= +e REG is explained briefly in Section II ,' ) and newly developed techniques of model ... , en where b=(bl, .·. ,bp)', e=(e1, criticism and case analysis are and discussed in the context of options to =[~ ~11 the proceedure PROC REG in the following ··· :X1 P] x tt1ree sections. Both real and fabricated data are used in examples to illustrate the behavior of certain statistics and 1 xnl xnp diagnostics in various circumstances. The focus) then) is on explaining the is called the design matrix. The least regression di8gnostics which are squares solution to the matrix equation produced as options under PROC REG. above is -I I.",Sugi-10-215 Hobbs.txt
"bstract they are usually driven by the problem they are trying to solve. For instance, an end user No longer the private domain of data processing may say, ""I know that the SAS System can professionals, the computer is being used with produce a plot for me, but how do I request increasing frequency by other professionals in it?"" The end users want training that is very their day-to-day jobs. These end users require specific to their applications. They generally training that is targeted toward their special do not want to wade through a lot of details to needs and applications. Too often, the end user learn to invoke the PLOT procedure and receives training designed for the DP request a plot of sales by month. professional. After all, if the course effectively trained our programmers, it should train the Training designed for end users should present users, right? information in a problem-oriented format. The learners should quickly understand, based on Rising demand for computer services and a their own experiences, what the problem is, steady increase in the creation of information and why and how it should be solved. They centers encourages end users to do more of should be able to concentrate their learning their own data processing work. These changes efforts on the solution and the process of within organizations have made end-user treating it. In that way, end users can see training an area of concern for many training the structures of the solutions and begin to coord",Sugi-10-22 Ussery Marriott.txt
"The SAS* Biostatistical Workbook: Bridging the Gaps Between Statistical Methods, Statistical Applications, and Statistical Computing David A. Ludwig University of North Carolina at Greensboro Statistical methods and statistical Introduction computing must be tied together in a meaningful experiential way if students are to understand the ideas and concepts Hardly a day goes by at the taught in graduate level statistics Statistical Consulting Center at UNC-G courses. Fictitious data sets found at that a student armed with computer the end of textbook chapters are a poor output from one of the statistical substitute for what the student is packages doesn't wander by uttering the likely to encounter in the future. A familiar phrase, ""I have this computer much more meaningful and thought printout but I don't know what it provoking approach involves the analysis means."" This admission of ignorance of data obtained from published concerning whatever they have in hand research. Published research not only also implies that the selection of the provides data to analyze but provides statistical treatment was in error and information on how the experiment or probably chosen in a questionable observational study was conducted. The manner. After a few minutes with a student is able to evaluate design consultant, the student soon realizes considerations, methods and materials, that the data warrants a different approach to the statistical analysis. and a variety of other factors that But what about the student who never determine the validity of the statistics seeks advice on interpreting the output? and the experiment in general. This is After all, he or she was able to select not possible. with a collection of meaningless numbers found at the end of and obtain complex statistics without a textbook chapter. much effort. Why not make an attempt at interpretation? It's all so easy. Ask Workbook Development and Content your thesis chairman what statistics are most impressive, sel",Sugi-10-23 Ludwig.txt
"THE DEVELOPMENT OF USER SUPPORT MANUALS FOR SAS*SOFTWARE: SOME GUIDELINES David L. Masamitsu, Independent Computer Systems Consultant gaps in its documentation and user support often Introduction: canbine to make it difficult to use. The -pJint that I am making is a simple one: SAS is one of the best documente::l. ~""1nd best sup- ported systems of it s kind on the market toclay. 'When software is made easier to use, odds Despite this fact, gaps still exist in its doc- are that it will be used. umentation -- gaps which the SAS Institute would probably find uneconomical, ~practical, This paper draws upon my recent experiences in or quite impossible to fill. developing a user support manual for a state agency, and offers what I consider to be some Examples of such gaps are: important guidelines to consider for anyone else who may attempt to develop user sUPIDrt manuals Job Control Language for SAS software. Overviews of the physical comp1ter Basic data management teclmiques Overview of the Problem: Basic data processing principles Magnetic tape usage For 13 months during 1983 and 1984, I was on Corrmonly made errors in using SAS contract to the Arkansas State Department of Error detection and diagnosis techniques Health. Logon pr'ocedures Site-specific differences Computer system & equipment peculiarities In my opinion, many of the problems that I have mentioned were present at that time in the Arkansas Department of Health. As a consultant, I have often found that most of the user problems I encounter, have come from a Additionally, there was another problem: A lack of training and user support in these areas physical lack of hardware. At that time, the -- pr'oblems and frustrations that cOlld probably Arkansas Department of Health was in the process be avoided with a proper system of user support. I have also found that even experience::1 SAS of replacing its hardware. users, who may know quite a lot about SAS, but Since user needs were at least temporarily not litt",Sugi-10-24 Masamitsu.txt
"SAS SOFTWARE INTRODUCTION FROM A MENU-DRIVEN SYSTEM Thomas F. Harwood San Diego Data Processing Corporation Users often had little time in which to The latest statistics show that over 65% learn to use the data processing tools of all major corporations have needed (SAS) to solve their problems, implemented Information Centers in one and they only wanted to learn enough to By the end of 1984, it form or another. solve their particular problem. is estimated that this figure will rise to over 85%. With this in mind, it is In order to solve these problems, the becoming increasingly important to IRC staff, working with the system staff recognize the many uses of SAS and how made use of dialog manager, TSO/SPF SAS they relate to the Information Resource Interface to produce menus (a Center. check-a-box system). Using these panels, the IRC staff teaches a half day Traditional methods of teaching and SAS Introduction Course, covering the using SAS must be modified when in the minimum a user has to learn to be IRe environment. When using SAS the non-data processing user does not want productive. to be bothered with JeL, TSO CLIST's or IMS EXEC's. After taking the SAS Introduction Because of its versatility and 'user Course, users are encouraged to contact friendliness', SAS has become a widely the IRC staff on a one-on-one basis to used reporting language at SDDPC. Also, r¢ceive additional help starting their because of SAS/FScalc and SAS/Graph, projects in the form of follow-up many users have learned SAS so they can training. Once a user has taken the SAS use the graphics and spreadsheet Introduction Course, the follow-up features. training and user projects become easy. The IRC staff recognized early that the The purpose of this paper is to show way SAS had been taught and used would that users do not have to be not work. The user who came to the IRC ""progranuners"" to define a dataset, usually came with a pressing problem. create reports, produce graphics, and They want",Sugi-10-25 Harwood.txt
"Individualized Reporting OSing PROe CHART Alissa Bernholc, UMDNJ, Rutgers Medical School After discussion, a oompranise in the pre- lin appl ication of FROC CHART has heen de- sentation of these reports was satisfactorily veloped which is useful in reporting individual The new report would oonsist of two scores on different tests in comparison to a achieved. given ""normal a range. AI though this technique !;ages: one the graphical presentation of the descri~ion. has heen developed for. the reporting of various scales, the other the verbal roT statements were used for the verbal descri~ psychological tests adninistered to employees of a department in the New Jersey State GwerIlTlent, tions, and PROC CHART was used to create the it can be applied in many- areas where canpari- graphical report. One of the tests adninis- tered, the Jenkins Activity Scales (JAB), will sons to preset levels are to he made. I:::e llsed as an example. '!he JAB test oonsists of four scales: per- sonality tY};ei s[:eed; job involvenent; and hard- A series of four psychological tests were driving. Therefore we wished the output to adninistered to employees of a de!;artment in the oonsist of four horizontal charts; one for each New Jersey state GoverrJllE!nt. Each of these scale. Each chart should have two bars: the tests oonsisted of different scales. The re- upper har representing the standard cutoff searcher wished to present each partici!;ant with points, and the lcwer bar representing the indi- individual reports consisting of a verbal and vidual's actual soore. graphical description of where they fell on the various measured scales of each test. 'Ihus, for the r:ersonality tyt:e scale, we would like the output to look something like Figure 2a, whereas the other scales only had a '!he researcher's prop:lsed format for the high cutoff point and should look like Figure 2h. output is shwn in Figure 1. TEST 1 ................. In TEST I, you fall within You are here ... the normal range. TEST",Sugi-10-26 Bernholc.txt
"been prepared, PROC T-TEST will be performed, and the results will be written to disk. e.g.: SAS procedures can produce copi ous amounts of data. A problem of too much data can develop when information from these data are extracted PROC PRINTTO UNIT=20 by hand for a report. Obtaining p-va1ues PROC T-TEST DATA= ALLPAIRS; produced by PROC T-TEST on many treatments and BY GROUP; variables is an example of this problem Thus, CLASS TREATMNT; it is necessary to find programming techniques VAR VAR1-VAR9; that will extract this information. By PROC PRINTTO; combining PROC PRINTTO with SAS data step The first PROC PRINTTO initializes the programming and PROC TABULATE, obtaining information such as p-va1ues will require less procedure to output the data to di sk. The UNIT option references the data set contained effort. in the JCL that will be named and created by By fi rst sendi ng the resu1 ts of T- Test to a this procedure. The JCL statement containing dataset on di sk and then by readi ng in the //FT20F001 will thus be matched by the UNIT=20 data, using an INFILE statement, the option. The program will then perform the programmer can search the data using various T-TEST procedure on each pair and subsequently programming statements in order to find the send the results to the di sk fil e. The di sk desired values. Once these values have been file should look something like figure 1. The found, output to the current dataset, and second PROC PRINTTO is used to stop the output printed for verification, PROC TABULATE can procedure. then be used to create a tab1 e of p-va1 ues, thus saving hours of tedious hand work. USING SAS PROGRAMMING TO EXTRACT P-VALUES",Sugi-10-27 Brown Konnerth.txt
"Check for out-of-range arguments from SAS. 3. This paper describes the JCL and FORTRAN program- Call the IMSL routine. 4. ming necessary to create an interface routine Check IER for a bad value. 5. which can be called from SAS as a SAS function, Assign the value of the function to the in- 6. which, in turn, calls an IMSL routine to perform terface function names. an operation. The interface routine then returns 7. Return. the value calculated by the IMSL routine to the As an example, the interface routine for MDCHN SAS user. is given. This is the routine for the non-cen-",Sugi-10-28 Conlon.txt
"USING THE SAS MACRO FACILITY TO TABULATE COUNTS AND PERCENTS FOR INDIVIDUAL VARIABLE VALUES Thomas J. Higgins, Blue Cross/Blue.Shield of Mass. Richard H. Potter, Mass Ratesettlng Commlsslon The following is an example of this process. lfuen dealing with a file of records it ~8 often useful to know the values that certain fields may take on. It may be that only PROC SORT DATA=SASIN ·__ ; certain values are permissible, or that we BY CERT_NO; msy.want to use PROe FORMAT to define value labeling formats for all possible variable PROC FRfi; values. It may be useful to know the fre- BY CERT_NO; quency for each variable value. TABLES CERT NO'SEX / OUT'FOSEX; TABLES CERT=NO'lOC / OUT·FOlOC; For example, suppose we have a file of records which consists of a certificate DATA FTSEX; number, sex code, and location code for each SET FOSEX record. The certificate number will be BY CERT_NO; unique for each family. the sex code should IF FIRST.CERT_NO THE/j DO; have been entered a 'F', 'M', or 'UI. The 8S SEXJl1=O; SEUF'O; SEX_CIFO; location code will consist if a single SEX}I1=O; SEX}F'O; SEX}IFO; character: a digit 0-9. We would like to END; know what the frequency of variable values IF SEX .'N' THEN SEXJl1=COlM; are for each certificate number. IF SEX ·'F' THEN SfX Cf'COlM; IF SEX ·'U' THEN SEX-CIFCOlM; If the following file is the input. IF SEX .'M' THEN SEX-I'I1=PERCENT; , LOC~TI QI...: CODE SEY. CODE CE~.':-IF::;f'o\TE !~!.IM6Ef"" , IF SEX .'F' THEN SEX-PF'PERCENT; M 123 , ,'u' THEN SEX-PIFPERCENT; IF SEX U 123 M RETAIN SEX_C11 SEX3(SfX_CU 12' , 3 F 123 SEX}H SEX}F SEX_PU; , U 125 DROP COlM PERCENT SEX; F 125 , "". 2 F IF IAST.CERT_NO THEN OUTPUT; U 125 3 M '25 DATA FTlOC; SET FQlOC BY CERT_NO; We would like the output to be: IF FIRST .CERT NO THEN DO; - LOC_Cl:01 LOC_C2=Oj lOC_C3=O; lOUI'O; lOC}2=OI lOU)oO; , -:;E'<_PU SEX_CF SEX_CU SEX PM SEX]F - CERT NO SEX eM ENOl , 33 3,3 33 1 123 , , IF lOC .'1' THEN lOC CI'COlM; 0 50 SO C 124 25 ""' IF lOC .'2' THEN l£C2=COlM; 25 125 IF",Sugi-10-29 Higgins Potter.txt
"- A method of entering and read- The simplest, most straightforward ing data is proposed that is easier and method to read these data is shown below: less prone to error than traditional methods for certain classes of problems such as unbalanced designs. Program tech- niques are developed to process these data as stream input with imbedded *DATA SET EX1A ON ACCOUNT LA00004 ""tags."" Examples of SAS programs using SAS EXAMPLES FOR T-TEST traditional techniques and the proposed EXAMPLE WITH UNBALANCED GROUPS 1'stream"" technique are developed. RON CODY - AUGUST 1984 , DATA EX1A; INPUT GROUP $ X @@;",Sugi-10-30 Cody.txt
"THE INTRODUCTION OF SAS SOFTWARE AND THE STRATEGY USED TO SPREAD ITS USE Akira Yagi, Takenaka Komuten Co., Ltd. of the new system, we checked the items We are dealing with a variety of computer-based business using an ON-line system that connects that may cause hindrance to the use of conventional systems. (Table 1). The the main or branch offices. Throughout this analysis of the extracted causes by the country, installing a control computer in Osaka relative projection and DEMATEL (Decision (where the head office is located). Since the Making Trial and Evaluation Laboratory) introduction of CWQC (Company Wide Quality con- method brings about the following. trol) in 1976, the importance of data analysis have been more and more recognized, and com- (Figure 2, 3) puters are now increasingly employed in this 1 The influences with respect to systems are field. The statistical package, purchased as most important factors. That is, there software for the above-mentioned business, on are too many systems used and each system the programs developed by us are not able to can cover only a limited range. cope with the diversified needs at present. 2 The education, PR in assisting system can Taking those situations into account, we have be mentioned next. made the investigation and studying of new sta- tistical analysis and business graphic systems since 1981. In this connection, we introduced the SAS software as a new system next year, and endeavored to increase its prevalence throughout our company. In this report we refer to the results we have obtained. 1. Utilization rate of statistical analysis systems Fig. 1 shows the chances in use of statistical analysis programs as of 1981 when the survey was started. The use of computers for statistical analysis rapidly increased since 1979. The num- Figure 2 Relative projection for effective use ber of jobs in 1981 is nearly 17 times more than (D-RJ O······Syste. in 1977. The fields of utilization are various ~~ x······EduC3,tion.",Sugi-10-31 Yagi.txt
"~ Enter Instruction You have been asked to develop a computer- Initial Write Instructional on Computer Re,ea""h - Goal, and Obiect,v\ / based training course (CBT) for your organization. Where do you start? What design principles do you apply to make your CBT course both effective and motivating? Or maybe you are Structured responsible for acquiring computer-based Design training courses for your company. How do you recognize a CBT course that is welt designed? High quality CBT courses are developed through Figure 1. The Course Development Process with careful planning and structured design. Structu red Design Structured design promotes CST that is interactive and tailored to an individual's needs. Structured design also helps prevent the production of computerized ""page-turners"" where A structured design approach to CBT pressing the ENTER key is the only required development has several advantages. Fi rst, the interaction built into a course. This paper entire course is planned before any keying of provides you with the specific steps to follow in a material is done on the computer. This affords structured design approach to computer-based you the opportunity to look at your course as an training. If you use authoring systems. to develop integrated unit, one that accomplishes the CBT courses, you will find that the structured training goals you have established. With this design approach works particularly well. If you type of preplanning, you develop an efficient and coordinate or select CBT courses for your organized flow of instruction so material is not company, you will find this information useful for repeated or overlapped unnecessarily. evaluating the potential effectiveness of a CBT course. Second, your course is written and tested in levels. You create these levels by breaking down",Sugi-10-32 Sibley.txt
"A SUCCESSFUL FORMULA FOR SAS EDUCATION ON A ROCK BOTTOM BUDGET Roger A. Chapin, Kais.er Permanente Medical Care Program If your company is anything like ours, you've The experience levels of the members with SAS probably experienced a surge in the number of are as follows: people using SAS during the past year or two. With this surge, of course, comes a demand for Number Percent Level education and training which we were neither staffed nor budgeted to handle. What worked for 66 novice 55' us was to form our own in-house, grass roots 36 30% intermediate SAS Users Group. advanced 18 15' 120 100% The results were striking. Our computer systems consultant used to spend half his time with With these different experience levels in mind, his nose in a SAS manual trying to answer all the presentations have been rotated to provide the questions he was getting on the phone. something for each level. For example, ""Report Since the Users Group started, he reports that Writing"" for the novice was followed by ""SAS the number of SAS calls has dropped to a trickle. Graphics"" for the intermediate user, and this was followed by ""My Favorite SAS Tricks"" for the Our effort began with an organizational meeting advanced user. Each meeting notice contains a in June, 1983. We used a TSO news bulletin to brief description of the topic to be presented invite interested persons to attend. Thirty and the level of the talk, novice, intermediate people showed up from all corners of our organi- or advanced. zation. This initial group indicated that as SAS users they would like: Periodically we distribute an updated roster of all members which lists their departments, phone 1) an opportunity for interaction on tech- numbers and current uses of SAS. This facili- niques, problems and solutions, tates contact with other SAS users to encourage 2) contact with other SAS users, self-help. 3) to be kept informed of new capabilities, and, What has been the cost for all of this? Nothing 4) training sessi",Sugi-10-33 Chapin.txt
"A second and related area of interest to researchers is whether or not the attributes of a medium enhance its potential for learning. The attributes of media such as zooming, animation, When selecting courseware for self-paced or symbols (like arrows to draw attention to instruction it is essential for the reviewer to details) have been examined for their effect on have a standard for evaluation. This paper learning. It has been found that it is not so presents a criteria for evaluating courseware important what attributes are used. It is more which is derived from the principles of important how attributes are used to help instruction used for development. These learners process information and develop mental principles are based on the critical conditions strategies relevant to the learning task. This is and events that influence learning. The but one aspect of the research which supports principles include prerequisities for learning, the premise that learning is influenced by the modes of presentation, and feedback and instructional design of materials. reinforcement. Examples from both video and computer-based training will be used to illustrate the concepts discussed. I nvalid assumptions Media can be used for instructional purposes if a regarding learning will be identified and ""put to number of events and specifiC conditions for rest."" This presentation will better equip those learning are met. The purpose of this paper is to persons who make the decisions about end-user identify the critical conditions or events which training by providing them with the developer's influence learning and describe how these are viewpoint. manifested in the courseware you are evaluating. These conditions and events are defined as the evaluation criteria are addressed.",Sugi-10-34 Bruce Brown.txt
"USING THE SAS® SYSTEM FOR COURSE AUTHORING John C. Boling SAS Institute Inc. The SAS/ AF software product is an interactive Primary fv1enu facility for application development using As screens are created and placed in a catalog, a screens. SAS/ AF provides the necessary tools directory for that catalog monitors the name of using a full-screen terminal for screen design each screen, the type of screen, a description and for configuring those screens in a system or for the screen, and the date the screen was last application. One application of SAS/ AF, among edited. others, is authoring and presenting computer- based training. This paper discusses the technical features of SAS/ AF that support the instructional designer when authoring and presenting computer-based training. Oirectory for Catalog' IIEUU,MENU · Comma,,"" Overview of SAS/AFTM Desniptlon N.me 1ype :Jpclatecl L.sson 1 LeSSONl CBl 120C1'S4 The SAS/AF software product consists of four Lesson ~ LESSON2 CBl 120CT8 ~ Kurtosis Oefi"",t,on HELP 12SEP84 KURTOSIS procedure steps - BUILD, DISPLAY, CPORT and Stati.tic Chuted 14SEPa~ STAT HeLP CharlO Varuble VARNAME 1~5EPe ~ HELP CIMPORT. The BUILD procedure provides the MENU CBT Selection Mana CBT 17SEP8~ tools for creating, editing and configuring MENU Modify, Examine S""'S Data Sets Cre~te, _ UAT\SET 14SEP8 ~ u.'coptiva statistics IIanu MENU m:SLSTA1' 14SEPS4 screens, in other words ""authoring"" the Color CllaTt Selecbon Menu GCHART MENU 03JAN85 PlHKARY MENU S ... S Sy.telll Primary Option Menu 20SEPa4 computer-based training course. The DISPLAY S... SGR ... PII 1'IENU Color Grapb Selection Menu 1~sep9~ S ... S SoHware System SCREEN1 IIENU procedure is the ""presentation"" system. PROC 120C1'a4 _ SCRUN2 MENU S""'S Sy""tem Primary Qption Menu 120C1'a~ DISPLAY presents or displays the information _ STA'r Statistics Kenu I~SEP94 KENU PROGR ... M Eut Program 12sep~~ authored by PROC BUILO. PROGR ... H Raw doh location _ n""'1'A lijSEPB~ _ FR~Q PROGRAII FREQ PIlOGRAK 2SAUG8~",Sugi-10-35 Boling.txt
"TEST DATA Most SAS/GRAPH@mapping is done at the state and county levels of geography using cartographic data bases (boundary coordinates) supplied by the SAS Institute. However, SAS/GRAPH has a comp- letely general mapping capability limited only by the kind of data and cartographic databases supplied to it. This paper briefly outlines the history of cartographic database development as the basis for thematic mapping and describes options for SAS users desiring to map data at various levels of geography.",Sugi-10-36 Cooke Farrington.txt
"Predicting Arkansas Tornadoes with SAS/GRAPH Software Ken Schriner. Craig Brown, Dan Puckett, Richard Smith - University of Arkansas Introduction with SAS code. This paper describes an effort to adapt and use The project was broken into essentially two dis- SAS/GRAPH for analyzing the occurrences of tor- tinct portions. The first part dealt with ma- nipulating the data into SAS datasets so that a nadoes within the state of Arkansas. This re- search project was funded by Arkansas Power and set of small SAS programs could easily access Light Company. The information produced may the data for analysis. These small SAS programs well result in financial savings for the utility were the second portion of the project. These company. They will use the maps and other data programs dealt with both the statistical analy- produced to determine where to place heavy duty, sis and graphical presentation of the manipu- reinforced utility poles as opposed to lighter lated data. duty less costly structures. 1. Data manipulation The state of Arkansas is located in the south- Arkansas Power and Light requested that all the central region of the United States. This is very close to the region of maximum tornado oc- available data on tornadoes be translated ·from currence in Oklahoma. The core of 'tornado al- latitude/longitude coordinates into a discrete ley', averages approximately 55 tornadoes per state plane coordinates grid cell network. year. Arkansas averages approximately 21 torna- These state plane coordinates grid cells are does per year. used by their offices for problem reporting and maintenance reports. The state of Arkansas uses The unique topography of Arkansas influences the a state plane coordinates grid network based on distribution of these tornado occurrences. Are- grid cell squares with sides of 25,000 feet. as of tornado concentration include: the This means each grid cell is approximately 22.4 Springfield Plateau in the northwest section of square miles. the state",Sugi-10-37 Schriner Brown Puckett Smith.txt
"TRACT graphics can be employed to relate How people use energy is a major empirical results to other personnel research issue throughout the world. not familiar with analytic details of San Diego Gas & Electric embarked on an energy research analysis. By using ambitious program to study energy various graphic options, more infor- demand and how it could be reduced in mation can be conveyed to a wider homes with central air conditioners and audience. Graphics can also present electric water heaters. An experiment information at several levels of was performed using radio controlled detail. This is important since broad devices designed to turn off air condi- overviews must be available as well as tioners and electric water heaters fine structure to complete the during the utility's peak period of operation. analysis picture. The strongest argument for the use of this approach is that graphics can offer more com- A variety of very large data bases munication and are often more re- in this study. The data in- were used vealing to general audiences than cluded information about the struc- statistical tables and algorithms. tural characteristics of houses family demographic data, outdoor temperature ANALYSIS recorded every fifteen minutes and energy information recorded every five Gas & since 1980, San Diego minutes in the home. The energy re- Electric has been measuring and corder information alone required monitoring the effects of direct 400,000,000 bytes of storage space on ra",Sugi-10-38 Simmons.txt
"Corporation system. The purpose of this file is to generate lists Due to a growing reliance industrial by of potential customers by market segment for manufacturers on distributors, it has become Parker distributors. Numerous secondary sources of extremely essential that both parties work closely information are used to compile the master together to identify growing markets and target company file such as: Dun & Bradstreet, State their efforts for joint rewards. This paper describes Manufacturer's directories, Thomas Register, and the usage of a SAS-based system for analyzing sales on-line data bases. The master company file data, company lists, and government statistics, and contains these following fields of information. applying this information for developIng a target market plan. SAS/GRAPH is used to further a) Name enhance the data by graphically displaying the b) Address statistical information. Number of Employees c) d) Telephone Number e) Sales Territory Code INTRODUCTION f) SIC Code The Parker Hanni!in Corporation manufacturers an It is the merging of the customer and the company extensive line of fluid power components and files and the usage of Base SAS which generates systems for Industrial, Automotive, Aviation, Space product/market reports. These reports provide the and Marine applications. Through a partnership major source of information for developing target agreement with its distributors, the corporation is market plans for Parker distributors. (Figure I",Sugi-10-39 Hodlik Marvin.txt
"ZOOMMAP AND OTHER SPECIAL TECHNIQUES FOR SAS MAPPING APPLICATIONS Warren Repele Jr., Info Tech Inc. map suffers from an ""island"" effect INTRODUCTION (Figure 1). Even when the areas are contiguous, the map may have an Maps can be invaluable when data of irregular or unrecognizable shape. a geographic nature needs to be displayed and understood. PROe GMAP is Specifying the ALL option on the adequate for the majority of SAS/GRAPH* PROC GMAP statement will retain all mapping applications. However, there intervening and surrounding boundaries, are some types of maps which a user with only a limited knowledge of SAS* but the close-up effect needed to PRoe programming and GMAP is unable to emphasize the area of interest is lost produce because of the complex (Figure 2). programming techniques required. The %ZOOMMAP macro creates a Among the most requested special ""close-up"" map data set in three steps. applications are ""subset"" maps and maps The area interest is of wi th labe Is. Maps wi th labe Is are 1. almost trivial to produce with the determined by enclosing all addition of the ANNOTATE facility to non-missing response areas in a SAS/GRAPH. Subset maps, which can be rectangular ""window"" as shown much more difficult to generate, fall in Figure 2. When the ANNOTATE into two major categories: facility is being used to label points 'on the map, the window Close-up maps in which we ""zoom is defined to enclose all X-Y 1. to show a in "" small area of ANNOTATE coordinates. interest within a larger region. 2. The response window is adjusted to conform with the dimensions 2. Regional maps in which a large of the graphics device chosen. area is ""split up"" into smaller individual maps. 3. After the device-specific window is established, the appropriate subset of the To permit more extensive use of the original map coordinate data mapping capabilities of the SAS System, set is obtained. a set of algorithms has been implemented using the %MACRO language to assist with the creation",Sugi-10-40 Repole.txt
"ENHANCEMENTS TO PROC GREPLAY Morse F. Kalt, SAS Institute Inc. PROC GPLOT GOUT=MYLI B. PLOT1; The GREPLAY procedure has been completely PLOT X*Y; redesigned for Version 5 of the SAS/GRAPH® product. Unlike previous releases of the places a picture in a permanent catalog pointed procedure, which were essentially limited to to by the libref 'JMYLlB"". A major difference redisplaying pictures from GOUT data sets, the between the creation of catalogs and GOUT data new version is a tool for both display and sets is that graphics procedures can now append management of graphics catalogs. With PROC pictures onto the end of existing graphics GREPLAY, you can now: catalogs, whereas previously they replaced the * contents of GOUT data sets. For example, if Display graphs from a graphics catalog on you code different devices without leaving the GREPLAY procedure GOPTIONS GOUTMODE=APPEND; * PROC GPLOT GOUT=G1; Change colors on a graph before displaying it * PROC GSLIDE GOUT=G1; Design templates for combining multiple graphs onto one page screen Or PROC GMAP GOUT=G1; * Rearrange and group graphs within a catalog by default all three of the graphs will be stored * in the graphics catalog named ""Gl"". In previous Modify graph descriptions on menu screens releases, only the last graph would have been * Delete graphs from catalogs placed in the GOUT data set. * Copy graphs between catalogs A TEMPLATE is a set of four-sided polygons into which pictures can be placed when they are * Transmit graphs to VSAM displayed using the template facility of PROC files for GREPLAY. It is through the use of a template subsequent use by SAS/REPLAY-CICS"" that multiple graphs can be displayed on one software page or screen. Like graphics catalogs, * Produce templates are stored in SAS utility data sets. A ""Executive Presentations"" number of pre-defined templates are shipped with the SAS/GRAPH product, but users can PROC GREPLAY can be used either in full- also define their own. See the section below fo",Sugi-10-41 Kalt.txt
"STATISTICAL GRAPHICS MADE POSSIBLE BY THE SAS/GRAPH ANNOTATE FACILITY UNDER VMS Patricia M. D. Benoit, American Cyanamid Company, Chern. Res. Div. programming in a higher level language, Introduction such as FORTRAN, and using callable graphics subroutines gives great Anyone who analyzes data needs flexibility, yet is costly in certain readily available tools for the development, maintenance and task. Statisticians, researchers and modification time and effort. A few managers of today require data analysis software packages might have more tools from calculators to data built-in statistical graphics but might management, statistics and graphics. not be compatible with the existing While good data analysis can involve computer environment. all of these tools, well-done graphics is surely the one which stimulates our SAS/GRAPH® with ANNOTATE has the inquisitive mind the most and advantage from the developers communicates most readily the results viewpOint, that SAS/GRAPH can be,used of that thinking process. statistical as the workhorse for creating the basic graphics embodies the concepts of good graph layout, for example, performing graph design and is extending our axis scaling and titling. Also as a repertoire of graphs from what is direct consequence of SAS/GRAPH, many ordinary today to more powerful data graphics devices are already supported. displays that will become ordinary Thus the development effort can get to tomorrow. The SAS® family of products work immediately on constructing the is well-suited for participating in elements that make up the statistical this evolution. By combining the SAS graph. As for maintainability and tools of calculations, data management, modification effort for graphics statistics, basic graphics, and now programs, my experience says that ANNOTATE, SAS users can develop well-documented SAS code is easier to programs that will add statistical support than its FORTRAN counterpart graphics to their list of data analytic which reli",Sugi-10-42 Benoit.txt
"e text for example, you will drawn on the graph. 'AFTER' the area is be covered up when the Otherwise, the text will ABSTRACT area is filled in. The immediate uses of the annotate facility center The annotate facility permits you to customize around accurate data dependent positioning of SAS/GRAPH procedure output. The facility is text labels, particularly in mapping applications. capable of defining polygons, controlling pen Annotate uses may also include: movement, placing text on the page, and so on. It adds to existing procedures the capability of Placement of city names on maps producing custom graphic output from a DATA Identification of areas step. Highlighting data minimum, maximum, or inflection points Special presentation graphics THE ANNOTATE FACILITY Because annotate commands are specified in a Welcome to. the annotate facility, a command SAS data set, the facility is flexible enough that driven graphics customization tool. The an entire graphics procedure may be simulated commands, or functions, are contained in a SAS with DATA step coding mechanisms. data set. This data set is then specified in the ANNOTATE= option of the graphics procedure. SUPPORTED FUNCTIONS PROC GMAP DATA sample.data MAP sample. map The annotate facility is directed by a series of ANNOTATE company. lego; observations and variables contained in a SAS ID id; data set. Observations are the commands, CHORO id / discrete variables are the qualifiers of information in the nolegend command. The var",Sugi-10-43 Friebel.txt
"A TESTS RESULT TREND ANALYSIS SYSTEM USING SAS/GRAPH' SOFT\lARE Susan S. Duckworth, Mlddle South Services, Inc. Introduction TRDRIVER brings up the main menu shown in Figure 1. The item number, result field name, and start and end date for results are The Middle South Services MIS Power used in the first step. The TRDRIVER eLIST Plants and Materials Section has developed a builds SORT CNTL CARDS based on these inputs Trend Analysis system. The system is used to and the SYNCSORT utility selects result values plot and predict the trend of test results for from the results history file based on the in-service inspections of vital plant safety SORT CNTL CARDS and includes them in an input equipment and systems at Grand Gulf Nuclear Station in Port Gibson, Mississippi. file. The purpose of this paper is to describe Step two is optional. If the user enters the Trend Analysis System and the use of 'y' to exclude results, he gets the menu SAS/GRAPH in the system. Based on user input, shown in Figure 2. He is allowed to exclude the system builds a SAS/GRAPH program to plot up to ten results by entering the dates he the trend of specific test results. A SAS wants to exclude. The GLIST builds SORT CNTL program then creates a listing of the test CARDS based on these entries. SYNC SORT results used in the plot. omits certain results from the input file built in Step one based on these SORT CNTL CARDS. Background The driver CLIST also builds control cards which will be used by the COBOL program Currently, the test results of the to build the SAS/GRAPH program. The item in-service inspections are entered into number~ result field name~ and start and end TANDEM computer databases which are converted date for graph are some of the input fields to IBM VSAM files. These files are input to on the control cards. a Results Analysis system which evaluates the test results using limits and reference values from another database. If evaluated Processing successfully, the result is stored i",Sugi-10-44 Duckworth.txt
"The chartbook developer must work with the end Many end-users, such as executives, do not wish user(s) to determine what charts to put in the to spend the time necessary to learn to produce chartbook. The type of data being represented their own g'raphs. Instead they are only strongly influences these choices. The interested in viewing the selected data in chartbook developer should produce rough copies graphical form. An executive chartbook can of graphs to be reviewed by the end user(s) and provide this capability. An executive chartbook attempt to represent each relationship in the data is a catalog of predefined graphs. Executive in the best form. chartbook users simply find which graph they want to see and enter the catalog name to view the latest data in the chosen form. This paper is a guide of how to develop an executive chartbook CHOOSING THE DEVICES using the SAS® System. This paper assumes that the reader is familiar with the SAS System and SAS/GRAPH® Software. The examples include wanted to be able to display the graphs in enhancements and new features of Version 5 th ree forms. SAS/GRAPH software. 1) Interactively on a color terminal, 2) In batch on a color hardcopy device, 3) I n batch on a black and white hardcopy",Sugi-10-45 Bulkley.txt
"Humans are exceptionally proficient at processing values can be read directly from it, and it is far visual information. With the widespread avail- less likely to introduce bias. ability of computer generated graphics, much interest in recent years has focused on graphical These techniques have been implemented as two new graphical profiles procedures under SAS named methocis to supplement analytical techniques for STARS and FACES. Extensive capabilities are pro- studying complex multivariable data. This paper describes the implementation of several of these vided through enhanced graphics 1 , analytical methocis as two new $AS procedures named STARS and tests, and flexible program controls. Applica- tions, primarily for data exploration, include: FACES. These procedures create graphical profiles of multivariate observations in the form of star- · Data description and summarization like polygons and face-like images to collectively · Outlier detection (univariate & multivariate) picturize the information in the data. Color, · Identification of trends in serial data combined with several analytical techniques, is · Clustering of multi-dimensional data added to current graphical methods to extend their · Comparisons with a standard or control group utility at representing high-dimensional data. · Assessing data compliance with speCifications Ease-of-use in executing the procedures and flexi- · Multivariate paired comparisons bility is stressed to provide comprehensive and · Correlation and variance analysis effective tools for exploring and summarizing mul- 2. Discussion tivariable data. Although both STARS and FACES accept the same n-dimensional data, their graphical representa- 1.",Sugi-10-46 Gugel.txt
"1 shows the anatomy of a boxplot. The 'box' of the boxplot repre- Boxplots are a useful tool for exploratory sents 50~ of the data and is drawn to a Y data analysis. This paper describes a macro scale; that is, the top aligns with the 75th written with the SASR (SAS Institute, Inc., percentile (upper fourth) and the bottom lies 1982) macro language which produces multiple at the 25th percentile (lower fourth) of the pages of boxplots appropriately labeled for distribution of values. Inside the box a line inclusion into reports or memos. The macro has is drawn at the point corresponding to the extended capabilities over the previously median (50th percentile). The distance between documented boxplot procedure PROC SPLOT (Gerig, the upper and lower fourths is called the 1983) such as automatic fence plotting and a fourth spread. When 1.5 times this distance is capacity for 22 boxplots per page. Labels for added to the upper fourth and subtracted from each plotted page as well as for each box may the lower fourth the locations of lhe fences be easily changed to allow for production of have been found. Any points lying beyond these report quality plots, and plots are routed to a fences are, in some sense, outliers and subject user-specified device such as graphics terminal to close scrutiny. The adjacent values are or graphics plotter. defined as the points nearest to and inside of the fences. Lines are drawn from the box to GENERAL OVERVIEW these points and are sometimes termed",Sugi-10-47 Stock.txt
"THE HP 7470 PLOTTER AS AN OFFLINE SAS/GRAPH@OEVICE Thomas Miron, Wisconsin Dept. of Transportation ASCII control characters like carriage The Hewlett-Packard 7470 two pen plotter is an inexpensive color return and line feed are not handled in graphics hardcopy device capable of the same manner by all file transfer producing high quality output on cut facilities. There can also be problems sheets of 8.5 by 11 inch paper or if more than one type of file transfer transparency material. User is used. The concern here is that intervention is required to change different record types can be produced if paper between plots and change pens by different transfer programs. The more than two colors are being used. two possible record types are SAS the HP7470 as an supports sequential and random. In Microsoft ASCII interactive device. User BASIC terminology, a sequential record messages prompting paper and pen is variable length and terminated with changes are produced as part of the a carriage return/line feed sequence; a output data stream and can appear on an random record is fixed length (in this attached display. Unfortunately, this case 80 bytes) and should be terminated system is not workable in an with carriage return/line feed by the environment where interactive ASCII file transfer program. When the connections to the host system are not incoming record type is unknown the available. SAS does provide the basis plotter driver running on the PC must for a solution to this problem with the be able to determine the type and process the file accordingly. GOPTION NOTERMINAL. The NOTERMINAL option allows output Handling user prompts, transferring data streams meant for an interactive control codes and dealing with multiple device to be captured in a file. This transfer methods are the major problems file can then be fed to the graphics facing an HP7470 offline system. A device to produce the intended output. solution to these problems lies with When the SAS/GRAPH output dev",Sugi-10-48 Miron.txt
"since the installation of SAS, and now more than This paper describes techniques to edit pictures one hundred people use SAS about 3,000 times a produced by SAs/GRAPH ® procedures, employing month. the various functions of different graphic devices, At the same time the use of SAs/GRAPH has such as the CAD system, in order to create more been widely expanded. attractive pictures. Under such circumstances, statistical analysis For this purpose an interface system was results need to be expressed more clearly so that developed at the Information Processing Center of ordinary people can understand them not just Kajima Corporation. specialists. This system transfers graphic data from one For instance, land-use analysis charts for the device or the mainframe computer, where SAS ® is area of surrounding a construction site and charts installed, to other devices. illustrating the effect of a building on the As a result, manipulations, such as environment are now very important in promoting magnification and reduction, overlapping, coloring construction work. with as many as 4,913 colors, shading, use of The SAS/GRAPH system is now being used in Japanese characters, and combining pictures . every department to make various graphs for produced by different programs are realized. practical use, but the following needs have been It can be used to produce more intelligible identified and remain to be filled. graphs containing more information. 1. editing graphs (magnification/reduction, overlapping, insertion of comments) 1.",Sugi-10-49 Takaya Tomita Nakasawa Yoshida.txt
"ENHANCEMENTS TO SAS/GRAPH® DEVICE DRIVERS Morse F. Kalt SAS Institute Inc. * Version 5 of SAS/GRAPH software contains a The driver is device intelligent--that is, it number _of changes and enhancements to device can use such features as hardware driver support. These can be grouped into the characters and fills, if they are available on following areas: the device. * 1) New Device Drivers The driver is available on all operating 2) User-written Device Drivers systems. 3) Enhancements to the Linkable Device Driver The user-written device driver has 4 4) User-defined Colors (2) an components: (1) an internal driver, 5) Configuration and System-oriented Options attribute file, (3) a metafile, and (4) an external 6) Enhancements to Existing Options driver. The driver works as follows: 1) The user supplies an attribute file, New Device Drivers containing information about the device, such as available colors, hardware fills, New device drivers for Version 5.0 will include and so on. those for the following devices: 2) Using the data in the attribute file, the * Hewlett-Packard 7550 plotter internal driver (an Institute-supplied * Tektronix 4105, 4106, 4107, 4109 and 4115 module) creates a metafile of graphics terminals commands. * Tektronix CX4106, CX4107 and CX4109 terminals 3) The external driver (written by the user) * Digital VT240 and VT241 terminals takes the metafile written by the internal * Selko O-SCAN 1104 and 2414 terminals driver and generates the code necessary to * Houston Instrument DMP-40 plotter liD drive the device. The actual * CALCOMP 84 plotter operations can be done by the driver, or * IBM Instruments XY749 plotter the external driver can give the commands * Matrix QCR Film Recorder back to SAS 1/0 routines, which will send * ZETA 887 plotter them to the device. * Tektronix 4510 Rasterizer In addition to the above devices, new and Enhancements to the Linkable Device Driver enhanced support will be available for various models of the IBM Personal C",Sugi-10-50 Kalt.txt
"software and suggests incorporating this characteristic throughout the SAS The SAS® System has established itself as one of System should be the primary goal of SAS Institute the standards against which quality software is in the coming years. measured. It is so good that, in the area where it began, statistical analysis, it has virtually no direct The conclusions that I reach are personal views. competition. Yet, the environment for the software But I have a great deal of experience with the SAS that SAS Institute provides is changing. Users are System. I have been a SAS user since 1977 and I becoming more knowledgeable and are demanding continue to use the SAS System, practically on a more sophisticated but easier-to-use information daily basis. Furthermore, as an Independent processing and data analysis capabilities. Consultant, my experiences have been both broad Furthermore, microcomputers provide a much more and deep. I have contact with, and can speak to, user-friendly environment than mainframes and the interests and needs of a wide variety of users. their speed and memory capacity are increasing rapidly while their costs are dropping. The software WHY WAS THE STATISTICAL ANALYSIS appropriate for this environment is different than SYSTEM SUCCESSFUL? that designed for other environments. Its hallmark is a user interface that is highly interactive, easy-to-Iearn and easy-to-use. The SAS System is To understand why the SAS System has been so not well-adapted to this envi",Sugi-10-51 Blank.txt
"USING SAS SOFTWARE AS THE REPORT WRITER IN A DATA BASE PACKAGE Thomas M. Koenig, University of Wisconsin-MADISON Jack Jimieson, University of Wisconsin-MADISON wants changes, the above process is repeated. After user approval. the programmer writes production JCL and INTRODUCTION documents it. All of this takes 2-5 days. The user calls back in two months and wants a report just like the other one but - change this and that. So the programmer This paper presents the use of SAS® software as the report copies the program, changes the code. and then repeats the writer for an inhouse IMS fourth-generation data base package above. This only takes 1-2 days. called QUICK FILE. This package is similar to many data base packages developed for the IBM PC. QUICK FILE is a Two months later the user calls back again and wants one just table-driven data base package which allows a user to bring up like the other one but - change this and that. So the a new on-line file in minutes. In addition, the user can choose programmer again copies the program and changes the code: from a full range of powerful data maintenance functions to But this time, the programmer gets smart, puts parameters 10 add, change, or delete records. Users or programmers the JCL to generalize the code, and sets up a request form for accomplish all of these tasks interactively by selecting options the user. Now the user can specify the parameters and have from a series of menus. an liD tech run the job. This takes five days. QUICK FILE system can also be appJied to a non-IMS The next time the user wants a change, the programmer environment such as CICS with VSAM files. Reports can also doesn't want to change the program because of all the be generated for non-IMS files (e.g., tapes or disk files), simply generalized code, forms, and production JCL. So the by adding the file descriptions to the data base dictionary. programmer complains to the manager about the unreasonable user who can't make up his or her mind",Sugi-10-52 Koenig Jimieson.txt
"facing the organizers of a professional conference is the management of the paper selection and agenda creation processes, Briefly described, the program manager must acknowledge the receipt of abstracts and papers, send various reminder letters, and send letters of acceptance or rejection to each of the contributing authors. In addition, the program chairman must communicate session times, locations, and abstracts to the session chairmen and produce the preliminary and final agendas for the conference. This paper discusses the implementation of a SAS/FSP database application designed to perform these functions. The application maintains file structures for papers, referees/chairmen, and sessions and makes extensive use of FS/LETIER to generate standard letters for all of these individuals. In addition to the standard paper and session tracking reports generated by the system, an interface to a phototypesetting service has been developed to produce the preliminary and final agendas. Operational experience with this application from the CMG XIV and CMG XV conferences will be discussed. design stage of the project during December of 1982, it was 1.0 Introduction envisioned that effective automation could linearize the One of the most significant problems that confronts the organizers administrative burdens associated with program management as of any professional conference is the issue of growth. Growth is a a function of the number of submitted papers. feedback effect that re",Sugi-10-53 Artis.txt
"& Electric John S. Willard, Mascari & Associates Roger B. Glaser, San Diego Gas & Electric flexible, but they require a more extensive ABSTRACT programming background for everyday use. With command driven systems, one needs to remember The ""Information Age"" is placing ever increas- the commands and parameters. Because of this ing demands on information processing profes- they tend to require more training and docu- sionals to produce more and more automated mentation than menu-driven systems. Casc&ding systems. Management not only expects systems through layers of menus can be tedious for to be developed faster, but also requires them someone who is quite familiar with a system, to be easy to use, ,flexible enough to adapt which makes the command driven approach more rapidly to change and to execute efficiently. suitable for systems frequently used by Fortunately, there are more development experienced personnel. alternatives available today to meet these challenges than in the past. Personal compu- In menu driven systems, one merely ""sees and ters and 4th generation mainframe languages points"" (15). Far less information is re- can be used directly by those requesting the quired for the user to remember. Menu driven system when requirements are not complicated. systems are ideal for occasionally used Very large and complex systems, or systems systems or systems used by inexperienced where the volume of transactions is large, personnel (see Martin. 16 and Trimble. 29). still r",Sugi-10-54 Roberts Sorenson Willard Glaser.txt
"Automate production of publication quality tables and graphs. A system (DRAMS), under development by the Issue Analysis and Information SeIVices Branch Is de- Provide SAS users the facility to extract data and scribed. The functions of the system are: data execute SAS procedures interactively. storage and maintenance; provide transportation related data to planners and analysts: produce The computer system most widely available publication quality tables and graphs: and provide to users is the IBM Virtual Machine/System Product SAS users with an easy to use method of extracting Installed at the Steven B. Teale Data Center, a state data for more specialized analyses. owned and operated facility. This menu driven system utilizes panels formatted under Display Management System and controlled The Data Base by EXEC2 programs. Users select data and data A SAS data library is stored on disk. For each type of processing routines by moving the terminal's cur- data, there are two SAS data sets--one contains sor to the option desired and pressing a function data observations, while the second Is a file of edlt/ key. DeciSions made In this way cause EXEC2 to update transactions applied to the first. The menu write CMS GETSAS and SAS macro language for selecting data Is shown in Figure I. The types of statements to a temporary SAS source file. When data currently Included are: the decision process Is complete, EXEC2 initiates · motor vehicle accident data for California execution of the SAS source file. highways: · commercial air passenger enplanements and",Sugi-10-55 Ramsey.txt
"rance Coverage Maintenance Coverage A major concern of large data processing Investment Tax Credit organizations Is the management of com- puter hardware, software and communica- TESS benefits include a reduction In the tion lines. TESS - The Equipment and number of personnel required to manage Software System was developed to assist hardware and software assets, increasing in the management and control of these control over these assets, eliminating items. Functional capabilities include: vendor overpayments, minimizing contract cancellation penalties, and providing Inventory Control aecurate up-to-date information. Vendor Invoice Approval Budget/Expense Forecasting Bill To/Charge Back TESS Functional Capabilities Configuration Management Features Accounting Many users in an organization can benefit from TESS. Development objectives included that the * system be on-line, easy to use and easy Network and Operation Managers can to maintain. These objectives were use TESS to determine physical loca- achieved by using SAS* software. tion and equipment addresses and connectivity data. SAS software was chosen because of the * Financial Services personnel can use various procedures and facilities which are included in the package and because TESS to assist in the vendor invoice of its ease of maintenance. Among the verification and approval process, facilities available which are utilized and also to charge equipment back to in TESS are the macro language, end users. %INCLUDE, stor",Sugi-10-56 Freeman David.txt
"ored SAS macro requi res SASX). The first modification is the addition of a statement to allocate the two operations: the macro must be MACLIB (MACro LIBrary); the second i t must loaded (by %INCLUDE), then be invoked. Once a macro has been loaded, modification is an INITSTMT specifi- cation to include the loader from the it remains available throughout the session and should not be reloaded; MACLIB. For example, if the loader's name is PLEASE: however, if many macros are being used, it is not reasonable to expect the user ALLOC F(MACLIB) DA('XXX.MACLIB') SHR to keep track of which macros have been SASCP TASKLIB(&TASKLIB &LOAD) - loaded .and which have not. Dther OPTIONS('&OPTIONS + programming 1 anguages 1 cad macros only INITSTMT=' '%INC MACLIB(PLEASE);'"" ) ··· when needed -- why not the SAS system? The primary purpose of this macro The second modification precludes the library facility is to let the software manage a collection of macros; i.e. to use of IN ITSTMT by the user J absent load macros only when necessary, to further modifications. make macros readily available through a Positional and keyword parameters lfbrary, and to provide a framework for may be used, although parameters the standardization of parameter names. containing blanks will require special Dne use of this facility is to handling. The trick to parameter maintain a library of ""general-purpose"" handling by the loader is that any or ""utility"" macros -- a ""programmer's parameter list passed to it is rega",Sugi-10-57 Merlin.txt
"DB2 SIMULATION USING SAS/ISPF DOUG KORTIIOF Panel variables and the report name are passed 1.... OVERVIEW. to the CLIST invoked by the panel and then any run-time variables are passed by the eLIST to the Many computer users would like the ability SAS program and then run. to use a Itrelational"" search on a recent snapshot Panel definition. of their database to produce a list of items which fulfill the criteria of the search. Such ""ad hoe n CLIST invoked by ISPF. SAS program and use of SAS macro variables and inquiries can easily be answered either by use of CLIST PUTFILE to insert the panel choices in the a relational database product such as IBM's OS/MVS SAS program. product DB2, or by asking a programmer to write a quick SAS report. 1! OPTION: USERS WRITE TIlEIR OWN REPORTS. III. This paper describes a way of setting up a system with readily available tools (SAS, CLISTs, Diagram: Programmer-user-data and report. ISPF) which allow users to generate their own The programmer sets up a system whereby the user reports, with results similar to DB2's report can go directly to the data and make up a report. writer, QMF (""Query Management Facility""). Deciding on the search variables. Not all Relational search means that anyone of the variables available need be used as search data items in the database (in a table, any variables to cull the database by placing them on column) can be used as a Itkey"" to cull the the panel. Choice of variables is based on data database for database records (a database record structu~es and user request. If, for example, the is any specifiable collection of data items or patient s marital status will never be the basis column names) which meet the search criteria. for an inquiry, there is no need to put it on the An ISPF panel is associated with a particular panel. Also: function. Since (usually) not all data items 1. The most important or often used items should (columns) in the database are required, or be placed at the top of the panel, d",Sugi-10-58 Korthof.txt
"THE SAS DISPLAY MANAGER SYSTEM FOR THE OS/MVS ENVIRONMENT R. Michael Oatsval1 SAS Institute Tne. The SAS Display Nanager System CDNS) is a full-screen interactive facility available as an integral part of the base SAS software product. Comrtlilnd Program Editor ~~.> The display manager allows users to enter and 00001 edit programming statements. submit them to the 00002 00003 SAS System, and to view the program output. DBS 00004 00005 provides the user with quick and easy access to 00006 00007 all parts of a SAS job in a full-screen OODOa 00009 environment. 00010 00011 00012 00013 Visually speaking, the display manager is 00014 00015 composed of two primary screens. The first 00016 00017 screen, displayed after initialization, is a 00018 00019 split screen containing two logical windows. A 00020 00021 horizontal dashed line indicates the division 00022 00023 between the SAS log and the program editor 0002~ 00025 window. For the sake of this discuss ion 00026 ""screen"" is used to refer to the entire terminal 00027 00028 face and ""window"" is considered a logical subset 00029 of a screen. This is the initial screen showing the log and program editor windows. SAS(r) L09 QS:58 SAS(r) L09 08:59 NOTE, COPYRIGHT (C) 19a~ SAS INSTITUTE INC., CARY, N.C. 21511, U.S.A. NOTE: COnPlGlIT (C) 1984 SAS INSTITUTE INC., CARY, N,C. 21511, U.S.A. NOTE: SAS RELEASE 5 06 AT SAS INSTITUTE INC. (SYSTEMS) (00000000). NOTE, SAS PKLEASE S 06 AT SAS INSTITUTE INC. (SYSTEMS) (000000001. Proqram Uttor CO!llllland ~~~> Command ~~~> Proqram Editor 00001 00002 00001 00003 00004 00005 00006 00007 00008 Users can dynamically enlarge or shrink the size The second screen is the procedure output window of the program editor and log screen by using which can be accessed by either pressing the the SPLIT command. To alter the split, position OUTPUT function key or typing OUTPUT on a the cursor on the row where the division is to command-line and pressing enter. occur and press the SPLIT function key. The en",Sugi-10-59 Oatsvall.txt
"By default, the SAS® system stores numeric of -300 is greater than the absolute value of vari ab1es ina SAS data set in 8-byte +100.) Table 1 shOWS the maximum absolute representation. The LENGTH statement can be value of integer data that can be exactly represented in numeric SAS variables from used to override the default and store numeric variables in a smaller space, thereby reducing 2-bytes to 8-bytes in length. storage costs. While this may be safely performed with integer valued variables, For non-integer data (fractions), however, the non-integer val ues wi 11 frequently be task of deciding the smallest numeric variable truncated leading to serious computational or length that will exactly represent the data is logical errors. This paper presents an easy not strai ghtforward. Thi s i s because, in to use MACRO for identifying which variables every number system, there are some fractions in SAS data set are integer valued, allowing which cannot be exactly represented. For safe usage of the LENGTH statement. example, in our usual base 10 system (the decimal system), the number 1/3 cannot be",Sugi-10-60 Rosenberg Bogardus.txt
"y variable names or SUMMSTAT is. 5AS® m....o that enables PROC SUMMARY to be codtng DATA steps. utilized more effectively es a tool for producing summery statlstlcs.SUMMSTAT allows the user to specify a list of variables In many situations, PROC TABULATE can serve es a useful to be """".Iy2Od, · list of the classification variable or variables to alternative to PROC SUMMARY. Although SUMMSTAT Involves be used to divide the date into subgroups, and a list of the output more overhaed than TABULATE, it is more efficient on large data statistics desired. The m....o, aftar generating a PROC SUMMARY sets. In lUIition, it produces """" output data set, which allows the step to parform the ectual date summarization, uses DATA steps product ion of com pletely custom lzed reports. end PROC TRANSPOSE to restructure the output date set from PROC SUMMARY. A PROC PRINT is then generated to print the desired C. CALLING SUMMSTAT statistics. The user may choose one of six possible formats for transposing and printing the summary data. Eleven keyword parameters are available for the invocation of the SUMMSTAT mecro. In most Instences, not all of these parameters This peper describes how to call SUMMSTAT, discusses some of the will need to be supplied, since many of them have defeult values. codtng techniques used within the m....o, and illustrates the output which it produces. Since SUMMSTAT is e generellzed m....o, it DATA= end OUT= Identify the Input and output flies to be used by may be used in",Sugi-10-61 Rhoads.txt
"ver. Readers interested in the logic for MVS system are invited to write to the author for additional information. Interfaces between SAS® and ISPF (IBM's Interactive System Productivity Facility) have been the topic of several papers presented at previous SUGI conferences (e.g., Chen, 1984, While SAS/FSP® offers considerable advan- Svirsky, 19841 Prague, 1983). The topic is tages over other data entry techniq~es when t~e likely to remain lively for some time as in- data are to be subjected to analys1s, certa1n creasing numbers of users come to see the great applications do not lend themselves well to its complementarity achieved through conjunctive use. These applications are those fitting any use of these systems. of the following criteria: Most systems which have interfaced SAS® and The database is unusually large. 1) ISPF do not do so at the level of data storage. The database is subject to update fre- 2) That is, most often I,sPF generated menus pro- quently (here, the problem is in the in- vide front-end or back-end processing to call ability of SAS/FSp@ to accommodate simulta- SAS® routines for data storage, analysis and neous multiple user write capability to the maintenance. More recently, attention has been same data set). given to interfaces between these software The database must be queried often and is 3) prodUcts which capitalize on the different too large to accommodate sequential search data-storage facilities used by the products. as a viable access techniqu",Sugi-10-62 Parrow.txt
"Initial User Training Sharing Application Development Between liS and the SAS · User - Responsible for Retrieval/Report Processing User Create Retrieval/Report Programs, Using ""User Friendly"" Software (SAS®). A method is proposed for sharing Application Develop- ment responsibility between Information Systems personnel This paper will discuss key activities and milestones for and the End User community, via SAS®. this approach to application development. Unique advantages and benefits will be presented. This approach is currently being undertaken in Owego, NY, with development of an Equipment/Property Control System for the IBM Federal Systems Division (FSD). The programming software base is CICSjVS (Customer Informa-",Sugi-10-63 Slater Ketchum Moshier.txt
"MADAM: An Example of BJeruehleal Data Set Maa.gemeDt Richard L. Gimarc, Boole Babbage, Inc. &; consumed by a particular user and is necessary for 1. Ahetnd apportioning the cost involved with running Model 204. The Model 204 Accounting Data Management System (MADAM) is a system designed to extract, a. DesIgn Goslo summarize, manage, and report user-accounting d ..ta produced by the Model 204 database The primary design goal of MADAM was to develop management system. a system to extract and report user activity in Model 204. This d ..ta was necessary for billing &ad What makes MADAM unique from other data collection and management systems built with SAS monitoring Model 204 usage. With this as a b.... the foUowing design goals were est..blished: ' is its novel technique for managing its collection of summary data sets. 1. Develop a system to extract user-accounting data from the Model 204 Journal data set. MADAM maintains a 2-level hiera.rclty of summary data where """"""h level contains data collected at .. different degree of granularity. Intelligence is built 2. Create a database of user-accounting dat .. into the system which enables MADAM to merge suit..ble for billing and monitoring Model 204 usage. data collected ..t level 0, daily d ..ta, to produce level 1 monthly summary d ..ta. The oniy user 3. Minimize user interaction. interaction required is to identify the target month. The system must be as ..utomated as possible. The user does not need to know the names of the daily data sets used in the monthly merge. 4. Provide for recovery when failures occur. The technique presented for managing a two-level hiera.rclty of SAS d ..ta sets can easily be extended The system developed addressed these four goals to manage an n-level hierarchy. Application of and is described in the foUowing sections. this technique wonid prove valuable in the area of 4. MADAM Compoaents capacity planning, for example, where the planning horizon dictates the granularity of data used; wee",Sugi-10-64 Gimarc.txt
"SAS®-Based Data Management System for Clinical Drug Trials Jean Bitney, A. H. Robins Data collected during clinical trials at 4. Preparation of project programs and A. H. Robins Company are entered into a documentation. computer file and maintained in permanent SAS® data sets. A number of different types of The profile definition begins with the assign- profiles are routinely collected. Demograph- ment of variable names to the data items ic, adverse experience, electrocardiogram, collected. Variables are selected singularly physical examination, clinical laboratory, and or from a predefined group of related vari- concomitant medication data profiles are ables. A single profile contains from 1 to 70 similar for most clinical trials. Efficacy, variables. A profile defines one 80-column dosing schedules, and vital signs profiles may input record. A project has from 1 to 20 vary within project, as well as across proj- profiles. A SAS/FSP screen, Figure 1, ;s ects. Our data management system must be displayed for the user to select variable structured in a manner such that standards are names. The record number 'is automatically easily maintained, where applicable, and still defined as are the first 3 variable names, retain flexibility to handle project-specific CARD, STUDY, and PATIENT. Additional variable prof; les. names are added to the list in positions 4-15. Variables in positions 16-70 are added To fulfill these requirements in 1983, a through Screen 2, Figure 2. Help information CMS/SAS data management system was developed pertaining to this task is presented on to define the SAS input record and create a Screen 3, Figure 3. Key variables, those SAS program to rF~ad this record. This system employed to link to other profiles (data consisted of 3 eMS EXECs, 3 SAS skeletons, and sets), are identified and ordered. In 5 SAS program modules. One CMS EXEC module Figure 1 the 3 key variables are STUDY, served as the system driver providing 6 PATIENT, and VISIT, indicat",Sugi-10-65 Bitney Robins.txt
"The format of the SPARM command is: SPARK fn nfn %PARMn · · SPARM, a parameter passing utility, was developed to run standardized SAS where: fn is the SAS program name. programs over different populations of nfn is the filename of the created files (SASLOG, data. This combination of VM/CMS EXEC'S LISTING). and XEDIT MACRO'S works by preprocessing %PARMn represents the para- and then executing a SAS program. Now used as a standard SAS execution meters (text) that are replaced in the SAS utility, SPARM increases programming program. efficiency and programmer organization. OPTIONS",Sugi-10-66 Gilbert Klompas OSullivan.txt
"AN INTERFACE WITH SAS SOFTWARE AND MUMPS Dr. H. William Cooley, Veterans Administration Michelle Gallagher, Veterans Administration BACKGROUND DHCP--THE VA AND COMPUTERS The VA has undergone an historic effort to com- purposes. Although there are pass-through puterize its 172 hospital system from a manual and hold-harmless provisions of this system, system (with a few exceptions in some of the much of the same type of information that major medical centers who are running systems private sector hospitals need is needed by that are ten years or so behind state of the art VAMCs. 2. From a clinical management perspective, DRGs systems). This effort ;s called Decentralized can be seen as an opportunity to gain infor- Hospital Computer Program, or DHCP. It got its mation about physician behavior and pa- name because some computer oriented personnel tients' clinical characteristics. Since began to develop systems on their own in MUMPS. much of the relevant di agnostic and anc; 1- These individuals were able to prevail on a lary information can be automated, the DRG policy level and their beginning programming in a case mix system can provide invaluable efforts were used as the basis for a series of information for both treatment and manage- application packages that were to be implemented sequentially for a total integrated hospital in- ment. In the di fficult area of cost and outcome, physician managers can track a formation system. number of relationships. HARDWARE AND SOFTWARE FOR AN HIS The heart of this system is a data base manage- 3. Statistical analysis can be made a part of ment package written in MUMPS which is called the ongoing production system of a hospital Fi le Manager. The appl ication programs are by providi ng an interface to SAS and SASI written in an ANSI standard version of MUMPS. GRAPH. Frequently for purposes of cl inical Digital Standard Mumps, and designed to run on management, a statistical table, listing or Digital 11/44 processors for four c1",Sugi-10-67 Cooley Gallagher.txt
"A SAS-based LOG System for Keeping Track of Computerized Clinical Trial Data Ruth F. Quah, Stuart Pharmaceuticals. Division of ICI Americas. Inc. Introduction New data for computerization are A computerized LOG system has been devel- accompanied by a transmittal sheet which iden- oped to keep track of patient data accrual in tifies the study number, patient numbers. and clinical trials. This system is SAS-based and forms inclUded. (Figure 2). In this replaces the need for maintenance of manual particular application. there were 16 different files. At present, the system is used for one CRF's. All the patients do not necessarily major drug project, but the concepts can be have all the forms; therefore. a detailed easily applied to any other drug project. description is necessary. This same infor- mation is then entered into a SAS log data set Backgro1.llld using an FSEDIT formatted screen. (Figure 3). Clinical trial patient data are obtained Entry of the patient list is in the format from case report forms (CRF's) which are filled ""a-b,c,d-e"", where a<b<c<d<e. Up to 30 spaces out by the study investigator at specified for patient list are allowed per record, and times according to a written protocol. more records can be used if necessary. For Completed forms are then sent to Stuart Pharma- each patient listing. the appropriate form ceuticals for review and computerization. names are ""X'"" d. In this way. all the Patient data are computerized as soon as they information from the study transmittal sheet are received, even though the data are not yet can be summarized in just a few log entry necessarily complete; i.e .· parts or entire records. forms may be missing. It is desirable to have some type of log system to keep track of what data have been received and what have been Ttl, computerized. A SAS-based log system was DATE: FROM: SUBJECT: TRANSMITIAL OF DATA developed for this purpose. _ _ _ SAS CODING _ _ _ sAS 'CORRECTIONS The System _ _ _ FINAL DATA The SAS log s",Sugi-10-68 Quah.txt
"ACDAS - AN AUTOMATED CLINICAL DATA ANALYSIS SYSTEM Donald D. M. Tong, The Upjohn Company LYnn T. Julian, The Upjohn Company I NTRODUCTI ON To quickly output all analyses specified by 2. A variable infonnation data set. statisticians for any set of clinical data is a challengi n9 and urgent problem; n the phar- 3. A restructuring of data values into maceutical industry. new data sets. In clinical trials, infonnation on numerous 4. A prototype of analysis and output variables for drug safety and efficacy. etc, programs. is gathered repeatedly for each study subject THE FOUR PARTS either at planned time poi nts or over some unpredictable response time intervals (e.g. cancer trial). The variables, the treatment 1. A Questionnaire for I/O Information groups, and the experimental design, etc, are unique to each study and often vary substan_ At this moment, there are only eleven tially among studies. To analyze the infor- questions, and each requires a simple Or mation, statisticians request specific output blank answer. Information is asked that be~t depicts the data of the particular about: study. Unfortunately. each output format may requi re the use of SAS® procedures on some 1) The name(s) of the dataset(s) to be compatible data set structures. These struc_ analyzed. tures may differ considerably frem the struc- 2) Variables to be kept or dropped. ture of the database that has a1 ready been created for the study. For example, in order 3) Variable names for subject identifi_ cation (e.g., COUNTRY INVestigator to do a linear model with a time factor in_ cluded, a horizontal dataset where the time PATIENT) · pOints are part of the variable names has to 4) Medication code, (i.e., treatment be converted into a vertical dataset where group i denti fication). time points become a variable. On the con- 5) BY or class variables. trary, in order to do an analysis of covari- 6) Time pOint variable. ance, a vertical database has to be converted 7) The value(s) which identify the",Sugi-10-69 Tong Julian.txt
"Application (NDA) to the regulatory agency. Figure 1 shows the steps necessary to The problem of having to pool and summarize transform clinical trial data entered into safety data from many clinical trials to our clinical data base into the reports to be satisfy governmental requirements for submitted as part of an NDA. approving an investigational new drug for marketing was simplified using a SAS' data base. Safety data from each trial was III. THE PROBLEM collected on an ongoing basis and saved in a SAS data library of 5 files, each containing related or similarly structured data. In Our department of Biostatistics and Clinical this way, the data were stored in a uniform Information Processing was committed to manner in one identifiable place and analyzing a large number of studies involving ambiguities or inconsistencies in the data Syntex' new cardiovascular drug Nicardipine were identified and resolved at the time the with indications in both angina and study was analyzed, when such resolutions hypertension. An integral part of this could easily be obtained. The system was analysis was to be the overall safety summary facilitated by incorporating the creation of that out of necessity would include safety files of safety information for individual data pooled across all studies, regardless of studies into selected programs in a indication. standardized library of SAS software used in analyzing each study. Pooling across many studies like this I, , presents a number of problems. One is that each study usually is of a different deSign, II.",Sugi-10-70 Tappe.txt
"facility for submitting multiple SAS jobs simultaneously. The Preclinical Biostatistics Department at Ortho Pharmaceutical Corporation provides DMS/CMS Panel-Driven System Used to Create statistical analyses for the Drug Safety Evaluation Division (DSE) for Investigational SAS Source Code New Drug submissions. The statistical Under CMS, the Display Management System analyses include: individual animal (OMS) is used to generate the panel screens. listings, mean value tables and A CMS EXEC 2 is written to work with the parametric/non parametric methods. panel screens so that the information entered This paper discusses a system built to by the user can be transferred into EXEC 2 variables. The EXEC 2 variables are then generate a series of mean value tables for placed in SAS statements, whereby the DSE studies. This system utilizes Base SAS Software, CMS EXEC 2 and the Display information associated with each new study is easily placed in the appropriate position in Management System. The techn; ques used to the SAS program to generate standardized mean build this system can also be used to value tables (see diagram). The OMS also has generate any standardized tables for different fields of application such as editing capabilities to redisplay the information entered by the user. This marketing research and operations research. editing procedure allows the user to check and correct errors before the SAS program is executed. Thus, unnecessary computer",Sugi-10-71 Pan.txt
"AS Institute, Inc. city pairs are produced, in numbers, based system for computing connection according to the following algorithm: cities to be used for Trans World Airlines', Inc. World Wide Availability Number of City Pairs = System. [(Number of Legs) · (Number of Legs + l)J 2 This system utilizes the worlds airline schedules to compute roughly 35,000 In transposing the above schedule data markets that contain direct (no plane into city pairs, the following results: change) flight service. The direct markets are then processed to DIRECT CITY PAIRS find all combinations of connection points, by utilizing spherical BOARD OFF LAX ORO trigonometry (with world latitudes and 1. longitudes), market and trip mileages may ATL 2. LAX 3. LAX be used as a base for elliptical analysis. NYC 4. ORO ATL ORO 5. This program will aid us in identifying NYC the best connect points and routings for ATL 6. NYC our airlines' construction of trips in From the contents of the SSIM file, markets that may have no direct service or due to traffic ""flow"", require connection approximately 35,000 direct city pair records are created. Depending upon trips as well as direct trips. seasonal schedules, this number may vary slightly. DESCRIPTION The foundation for this program is an After all the direct city pair records input file consisting of the worlds have been created, the mileage between the airline schedules. This data is initially board point, and the off point (for each city pair) must be calculate",Sugi-10-72 Baird.txt
"1/84 Source Projected Nuclear energy is considered the most 33% 28% Purchased Power - efficient source for producing electricity. System Once in service, a nuclear power plant can 30% 22% Oil and Gas operate at a much lower cost than other types of 14% 12% Coal power plants because of lower fuel costs. This 8% 9% Renewables (including ""fuel differential"" translates to millions of all Hydro) dollars in savings to consumers. To realize 12% 5% Purchased Power - these savings, however, consumers may have to Renewable wait as long as 10 years from the time develop- 10% 17% Nuclear ment is initiated. Construction. start-up and operation of a nuclear facility are closely Southern California Edison views research monitored by the utility and regulatory agencies as an investment in the future. The nation's to assure that quality is constantly maintained. first nuclear power station to generate and The information requirements generated can distribute electricity on a commercial basis become unmanageable without automation. Due to from a non-military reactor was located at Santa the dynamic nature of this environment, the Susana in the early 1950 IS. This experimental development of maj or information systems with venture was one of many that made possible the traditional data processing methods has been construction of the San Onofre Nuclear Generat- slow. leaving a noticeable gap in fulfilling the ing Station (SONGS), Units 1, 2 and 3. overall requirements. The three unit SONGS stati",Sugi-10-73 Epperson.txt
"The Current and Potential Role of the SAS. System in Industrial Applications James F. Sattler, ORI Inc. Joshua Sharlin, ORI Inc. Moreover, long and expensive A. INTRODUCTION: SAS AND CYBERNETICS manufacturing cycles have traditionally been caused by unnec'essary design More than quarter century has passed variations, inefficient routing, since the publication of Norbert expensive t.ooling, and poor quality Wiener's classic study ""The Human Use of assurance. Many of these problems Human Beings~ Cybernetics and Society"" center on the inability to process (Boston, In that visionary 1950). classic, he predicted that the infor,mation about optimum designs and industrial life cycle would be production methods. Companies need controlled by computers which would manufacturing information systems which monitor machinery and business can increase productivity and cut information. Today in the U.S., costs. In short, the necessity to computers are being widely used in compete effectively has been the mother industrial data processing and for the of technological invention. automation of complex engineering systems. These include industrial This paper attempts to analyze some management information systems, aspects of this new industrial production processes (both batch and revolution and the role which the SAS continuous), aerospace systems, power system can play in it. It provides systems, and many more. Automation illustrations of current examples of SAS makes possible the solution of problems usage in the sphere of industrial which have direct economic productio~, suggests new opportunitites consequences. These include devising for uS1ng SAS, and makes some optimal product mixes, lowering extrapolations fo~ the future. metal-intensity of products,. lowering energy intensity of production, and Basically, SAS can be used either at assuring high quality materials in a discrete level to solve a specific manufacturing. Even 'agriculture is industrial application or at a global b",Sugi-10-74 Sattler Sharlin.txt
"l Laboratory ABSTRACT some 5 x 10 6 data val ues. The object; ves of the A detailed investigation was made of historical investigation were (1) to characterize the data recorded at EBR-II during operation with performance of all the steam tubes in terms of superheater SU-712. The objecti ve of thi 5 study frequency and rel at i ve severity of unbond; n9, was to analyze and characterize the performance and (2) to establ ish a correlation between the of 72 duplex steam tubes that became unbonded observed anomalous beha vi or of the superheater during a long period of operation. The information processing system ANALYZE, using SAS and it~ operating parameters. foundat i on software, was de ve loped to as its perform the required numerical manipulations, The materials examinations and disassembly statistical analyses, and spectral analyses with observations from this project have been documented in separate reports (1, 2). It is an inpdut data set containing some five million data values. The ANALYZE system was successfully the purpose of this report to describe the development and implementation of the SAS employed (1) to characterize the performance of program ANALYZE. all the steam tubes in terms of frequency and relative severity of unbonding~ and (2) to establish a correlation between the observed II. Data Handling and Pretreatment anomalous behavior of the superheater and its operating parameters. Results from this in- During all EBR-II reactor runs, the values of vestigati",Sugi-10-75 Gross Seidel.txt
"SAS TECHNIQUES FOR READING VARIABLE LENGTH RECORD FORMATS Andrew V. Bowden, Jr., South Carolina Electric & Gas Company INTRODUCTION In order to compress as much Using this fixed format, a file information as possible into a containing information on 200,000 small amount of storage space, ,many customers would occupy approximately 660,000 kilobytes of corporate computer departments are now using variable length records space. However, quite often each in their data bases. These files record in such a file has a few are typically built, modified and segments that do not contain any maintained with programs written in data. {Exactly which segments are machine language or COBOL. In blank may vary}. In this case, order to access this data with SAS, computer programmers might decide an analyst or statistician will to use a variable length record find it necessary not only to format to discard any empty understand the basic concept of segments on a record-by-record variable length files, but to write basis. For instance, if a record a program with an enormous amount did not have any data for segments of flexibility. 5, 6, and 7 in the above layout, the variable length format might This paper will first explain compress the information as how variable length records are follows: formatted, and then will offer some suggestions on how to write a SAS program to handle this type of data. The techniques that will be presented were first developed for use by analysts at South Carolina Type of Data Stored positions Electric and Gas Company, a utility Indicator Byte whose customer master file has variable length records up to 5,000 Customer Identification 2- 77 bytes long and provides thirteen Credit History 78 - 353 months of history on over 500,000 Special Information 354 - 404 customers. Electricity Usage History 405 - 1405 Outstanding Transactions 1406 - 1566 CONCEPT: VARIABLE LENGTH Then, this particular record would RECORD FORMATS occupy less than half the space that it woul",Sugi-10-76 Bowden.txt
"MAINTAINING QUALITY CONTROL OVER INPUT DATA WITH SAS SOFTWARE R. A. Whitfield, Quality Control Software and The Insurance Institute for Highway Safety Human errors in machine readable data are women's colleges), is an ancient FORTRAN habit rarely random errors; usually they are very that dies hard. New students of SAS, many of I systematic. Because they are also not whom have never seen a FORTRAN program, pick up independent nor identically distributed from this habit through osmosis. It does not some normal distribution, their effects do not improve communication. There are more papers cancel out. Errors in data tend to follow in the scientific literature than anyone distinctive patterns. but finding these suspects with results that are totally driven by missing data of the form, ""999:: Don't know."" patterns is rarely easy. SAS software provides many good tools to Variable labels are an excellent means to maintain quality control over input data in physically merge database documentation with information processing. Although used more the database itself (4). These labels provide often for error detection than for error for 40 bytes of information that can link an avoidance or correction, SAS is useful for all informative interpretation to any variable three purposes. At the same time. many name. SAS programmers often avoid using features of the SAS system present easy descriptive rnneumonics for variable names to introduce error into a opportunities to have something useable for variable series, database. All SAS programmers should be aware e.g., VARl-VARlO. This practice is only acceptable when labels are also used. Along of these pitfalls. with other valuable documentation for any SAS Error Avoidance database, labels are always available from PROC Moreover~ CONTENTS. they can't be lost like Almost all data processing projects still generational. source code histories are when require, at some stage. the transfer of data GEM :: 5 is the installation default. fro",Sugi-10-77 Whitfield.txt
"tly be corrected. The error rate for ABSTRACT double-entered data can be calculated as follows: COMPARE is an important SAS quality * E2 * P , assurance tool for data base management that is Overall data entry error rate = El especially useful when the SAS Full-Screen where Product (SAS/FSP) is used for data entry. A good way to check input data for typographical E1 = error rate of data entry operator 1, errors is to have the same information entered by two different people and compare the versions E2 = error rate of data entry operator 2, for differences. This has been standard P = probability that the errors made in practice for data entered via keypunch machine the same position are the same (and on cards; however, it has not been as easily therefore undetectable by a accomplished for data entered using SAS/FSP, via comparison program). terminal, directly into SAS data sets. To facilitate this procedure, a SAS macro, COMPARE, El and E2 are each 0.005, assuming the same 1-in-200 keyboard error rate for each data entry has been developed at Oak Ridge National operator. Given that both operators have made a Laboratory. as part of the U.S. Environmental Protection Agency's National Surface Water mistake in the same position, the probability of Survey Data Base Management Project. the errors being the same is conservatively only 1 in 4. Therefore, Oata are directly and independently entered * into two SAS data sets. COMPARE then Overall data entry error rate = 0.005 0.005 * 0.2",Sugi-10-78 Rosen Kanciruk.txt
"EDITING QUESTIONNAIRE-DATA SKIP PATTERNS WITH SAS® MACROS OR HOW SAS MACROS SAVED MY NECK Susan Bolotin, Research Triangle Institute cations that indicated what action the Introduction: Questionnaire Data and skip Patterns edit should take in all possible situa- tions. The example I will be using is a At the Research Triangle Institute fairly complicated one, but the method we frequently deal with questionnaire is appropriate for any edit that applies data. Often, trained interviewers fill the same rules to all skip patterns. out the forms and editors review their contents before they get to data entry. I decided to use SAS macros to do Nevertheless, it is common for incon- my skip-pattern editing because I found sistencies to escape detection and turn myself in the following situation: I up in the data files. They are partic- had a gargantuan editing task before me, ularly well represented in question- consisting of similar sets of compre- naire skip patterns. hensive and tedious edits on data files A skip pattern has two parts: 1) from seven different questionnaires. These edits included data conversions the routing question, whose answer and some logical imputations as well as determines whether a skip should be skip-pattern checks. I had a lot of performed, and 2) the variable or variables to be skipped if the routing editing to do, but I didn't have very much time. question's value indicates a skip. In a questionnaire, the skip instruction typically follows a coded response. SAS and Editing For example, if Question 1 is a ""Yes- No"" question, ""Skip to Question 411 As usual, I planned to use SAS for might be written after the ""No"" re- all the editing. SAS has two particu- sponse (Figure 1). larly convenient editing applications. Skip-pattern Problems One is the creation of permanent· intermediate files at successive stages All sorts of things can go wrong of the editing process. Storing the with a skip pattern. If the routing data in intermediate files allows th",Sugi-10-79 Bolotin.txt
"were written in COBOL ABSTRACT and were approximately ten years old. At times up to six programs were This paper discusses a customer required to create a sample and sampling and reporting system which generate printed output. Other permits greater accessibility to the problems were limitations on the type contents of an electric utility's of selection criteria from which a customer billing file for the purpose sample could be drawn, inability to of data analysis and research. The select samples that approached 50% of system standardizes the process of obtaining customer extracts, random the popUlation, and the excessive amount of time required to get final samples, statistical summary reports, and labels from the customer billing output -- up to a week per sample. In addition, the report formats were file. SAS is used to manipulate files and data, perform statistical analysis, inflexible, as was access to other data and generate reports. The system is from the customer files. interactively driven by TSO CLIST's and The objective for the development of SAS/FSP to provide an easy-to-use fl11-in-the-blank process to select the system was to allow greater criteria for the extraction, sample, or accessibility to the contents of the customer master file for the purpose of report. The SAS Macro facility sampling and analytical studies. The generates SAS code which produces the three goals of the project were: extract of the population, samples r and reports of the customer file. T",Sugi-10-80 Worline Matthews.txt
"alysis. RAGS also enables the user to rapidly ABSTRACT compare the proposed tariff to existing tariffs by overlaying each model on the same graph. This technique provides the Using the best features of many different pieces of software, information necessary for developing counter proposals. RAGS (Regression Analysis and Graphics System) forms a powerful, yet user friendly tool for use in freight tariff negotia- HOW REGRESSION ANALYSIS IS USED tions. In this paper, the motivations for RAGS' development and design will be discussed, along with examples of how RAGS is not a general purpose regression tool. Using only RAGS is used in tariff negotiations with carriers who trans- two types of regression analysis, simple and piecewise linear port Air Products and Chemicals' products. The paper will be regression, RAGS can adequately handle virtually all types of concluded with a discussion of how and why such diverse modelling requirements encountered by Chemicals Distribu- software technologies were integrated, and the savings to tion to date. Simple regression is used primarily to relate the company by using RAGS. cost per unit weight as a function of the distance (usually Highlights: miles) a product is shipped. Piecewise linear regression pro- vides the added flexibility of being able to model tariffs which RAGS provides rapid access to SAST~ regression and graph- contain many line segments with different slopes and inter- ics software, and through the use of ISPF'~ menus, requ",Sugi-10-81 Peterson.txt
"separate The Virginia Department of Planning and Budget 1s leglslatlvely mandated to develop short and projections be developed for seventy-two long-range population projections for use by cohorts per locality. These cohorts include other state agencies and the legislature for two race categories (white and non-white), lB flve-year age categorles (0-4 to B5 and programs that involve or necessitate population over) and two sex categories. That is, one projections. However, other clients include local and regional governments, universities, cohort would be white males 0 to 4 in age and business as well as private citizens. while white males 5 to 9 1n age would be a Prlor to 1983, thls task was done prlmarlly separate cohort. For each year projected, 72 lndlvldual projectlons were to be de- by consultants with our agency providing the current data, making model assumption veloped for 136 localities translating into nearly 20,000 projectlons. Addltlonally, decisions. and adjusting the mechanical projections were required for multiple projections. In 1984. the decision was made years; 1990, 1995, 2000, etc. out of 2020. to develop the model in-house and SAS* soft- ware was chosen as the best computer language to use. Telephone Survey and Literature Search Using SAS software. we developed a model for An lnltlal object1ve was to flnd out what roughly what the consultant was charging for currently exlsted In the fleld and not to one update cycle using his model. The marglnal cost for",Sugi-10-82 Robinson.txt
"While the conversion to SAS data sets would significantly improve ease and efficiency of general access, it would still not solve another The series of Summary Tape Files produced very important problem associated with by the U.S. Census Bureau represent the primary processing these files. The single most common machine readable products of the 1980 decennial use of the files--at least in the early months census. Because of their massive size and com- after the data was first released--would be to plexity these files present a challenge to any produce reports consisting of simple displays of shop that needs to use the information in a the data. ""Simple!! conceptually perhaps, but timely and efficient manner. The staff of the tedious and awkward from a programming point of UMSL Urban Information Center has created a SAS view. What we wanted to do was to make the based software package that we feel can signif- programming task as simple for the programmer as icantly reduce the costs and programmer effort it was for the user. In other words, he should required to use these files effectively and be able to simply request a report consisting of reliably. nicely formatted table displays for any or all geographic areas of any type.",Sugi-10-83 Blodgett.txt
"The University of Toronto Computing UTCS has been a SAS site since the Services has a large collection of tapes early 1970s, and its use has been with data from three Canadian censuses. increasing steadily for the past several A project was recently undertaken t'o years. It is currently the most popular statistical package at the University of make it easier for users to locate the tape with the desired information, and Toronto. Thus SAS was a natural choice for example programs in the 'UTCS Guide to access the data. All necessary to Census Tapes'. Many people like to details about the tapes themselves were use maps to display census information, put in a SAS data set, and documentation written to facilitate its use through and SAS/GRAPH's PROC GMAP easily handles such geographic displays. Report PROC FSBROWSE or PROC PRINT. Several sample SAS pro9rams were written to writing, PROC TABULATE, and PROC FREQ illustrate techniques for are also extremely useful for varIOUS researchers who have to present their reading the census information. Since counts in a variety of forms. It was census data is frequently presented on also felt SAS/FSP could help solve some maps, UTeS is working with the of the problems with keeping track of Department of Geography to expand its collection of SAS map data sets. As a the tapes themselves. result of this work, many different groups within the University are The Tape Inventory and SAS/FSP starting to use SAS and census data together in a wide variety of applications. Before this project was undertaken, only a partial list of 1976 tapes had ever been publis-hed, and all other",Sugi-10-84 Mitchell Fehlner.txt
"DEVELOPMENT OF A DATA MANAGEMENT SYSTEM FOR LONG-TERM ECOLOGICAL RESEARCH William K. Michener, Baruch Institute Robert A. McLaughlin, Baruch Institute Marvin F. Marozas, Coastal Carolina College INTRODUCTION processes. These projects require the talents of many investigators from The Belle W. Baruch Institute for various disciplines (for further Marine Biology and Coastal Research (one discussion see Callahan, 1984). A of eleven Long-Term Ecological Research single database generated at a site sites in the nation funded by the supported by the Long-Term Ecological National Science Foundation) has Research Program (LTER) may exhibit the developed a flexible system for following characteristics: ecological data management and analysis. The Baruch Data Management System (BDMS) 1. Variety. Ecosystem level research contains four years of data collected requires understanding environmental from ecological research on coastal and conditions (water quality, estuarine habitats. The system is meteorological factors, etc.), natural designed to efficiently incorporate data system interrelationships (i. e. how the from short-term to multi-decade studies. marsh and bordering forest interact), Specific design features include population parameters (i. e. species modular data base design for optimal growth, reproduction, and mortality), flexibility in data set addition and and community dynamics (predator-prey modification. Both hierarchical and interactions, etc.). relational data structures are employed. Full screen data entry can be 2. Large size. Open-ended collections accomplished on-line or off-line using can resillt in extremely large databases. microcomputers. Quality assurance Also, many additional data sets may be programs, cataloging and documentation to address specific generated procedures, and extensive analysis and hypotheses. report writing procedures are incorporated in the BDMS. Also, data 3. Scale. Numerous spatial and are routinely protected using both tape tem",Sugi-10-85 Michener McLaughlin Marozas.txt
"INFORMATION CENTER USING SAS SOFTWARE--A SUCCESS STORY Henry B. Edwards, CIBA-GEIGY A main menu is displayed from which the user BACKGROUND then selects the options he needs. The menu Chemicals and subsequent processing were written using The Dyestuffs anc Division of the SAS Macro language. CIBA-GEIGY produces specialty dyes and chemicals for the Textile, Paper, and the The main menu appears in two sections on the Detergent and Cosmetics industries. An annual revenue of over 250 mill ion doll ars results screen. The left hand side of the menu allows for the browsing of five data bases using from the sale of over 2,000 products to over FSBROWSE. The right hand side has tools for 2,000 customers. In 1982 the Division further evaluating the data bases (see Figure reorganized into two strategic business units. The purpose of this reorganization was to give 1). Although the FSBROWSE function is nice, it more accountabil ity and responsibil ity to the does have its 1 imitations. To give the users business units. Since more people were held more flexibility in retrieving and analyzing accountabl e for the; r performance, the demand the data we have a feature called Menu Driven for accurnte and timely information increased Reporting. This tool allows the users to enter rapidly. The Data Systems staff could not keep selection criteria into an FSEDIT screen which up with the demand. is then subsequently processed into SAS code for analysis and inquiry of the data bases. We He had prev"" ous 1y tra i ned some of the also allow the users to analyze/inquire the Divisionis users to utilize SAS to retrieve data base using on-line SAS. There is also a and analyze data. However, the data was stored NEWS option which allows the user to see what efficiently for production systems and was not is new in the Information Center. A new easily available to the users. vie then decided feat.ure is the File Transfer selection which to install the Information Center concept allows the users to",Sugi-10-86 Edwards.txt
"act the appropriate subroutine libraries, a SAS parser and creativity. The with the progression of end-user result is a user-written PROCedure. computing and the availability of The PROCedure can be totally ""simple to use I! languages such as SAS, transparent to the user as another SAS there is a new direction for SAS users PROC. This is what an Information and programmers alike. The 1980's are Center tool should be, transparent and proving to be the era of the easy to use. Information Center, the necessary link between end-user computing and the data processing environment. What are the advantages of the user User-written FRoes CQuld evolve into a written PROCedure? complete Information Center tool. The scenario is typical, an There are many advantages of SAS end-user would like to use data in PROCs written by the user, but the his/her custom system and SASe The most important reason always gets back application programmer does not know to the user. Is it easy? When the how to create a SAS data set from the user is familiar with SAS, switching customized system or read a SAS data to a new PROC is like adding another set by the system. Creating external type of bread to a bread basket. The files would become a nightmare for friendliness of SAS has always been both the end-user and the application one of it's best features, therefore, programmer. adding another FRoe to the library The Information Center links the will keep the user happy by continued user community to the data",Sugi-10-87 Fleming.txt
"A SIMPLE TIME-TRACKI~ SYSTEM USI~ SAS SOFI'WARE Richard A. Henkle, Consolidated Diesel CCrrpany the development staff. The system BACKGROUND had to be usable even by those who were unfamiliar with the SAS Consolidated Diesel Company (CDC), based in Whitakers, North Carolina, is a system. partnership owned in equal shares by 4. the data entry screen calls Cummins Engine Company, a manufacturer As only for a short mnemonic in iden- of diesel engines based in Columbus, tifying a project, the reporting Indiana and J. I. Case Canpany, a sub-system would require a PRQC manufacturer of construction and agricultural equipment based in Racine, FORMAT type of table to expand the identifier into a meaningful Wisconsin. CDC began building diesel pDOject narre and code. With each engines for its partners in the spring of 1983. member of the staff confDOnted by an ever-changing set of projects and activities which to one degree Like the plant it serves, CDC's data or another is different from that processing department was built from the of anyone else in the department, ground up. Not surprisingly for a it was unrealistic to try to main- start-up operation, the development tain a single project table for staff, which eventually rose to 12 everyone's use. Rather, each user people, quickly found itself faced with over 60 open projects at any giv.en needed the ability to maintain his At the same time, there was no own, and this maintenance had to point. be kept as simple as possible, computer-based software available to aid the staff in tracking time spent either particularly given that most of on these development pDOjects or on the these users were not familiar with various administrative activities which the SAS system. also demanded their attention. 5. Different reporting requirements would demand that the user be able to produce data either in discrete ProBLEM time units or summarized for any There were several constraints which had given time span. It would also be to be ove",Sugi-10-88 Henkle.txt
"INFORMAT, and LABEL for each variable in the database. An easy to use project management sys- Observations are added to this tem was written in SAS* software to dataset using PROC FSEDIT. track the analysis of clinical trials in a As described below, five pharmaceutical company environment. generations of the dataset ex- This system uses SAS/FSP* as an inter- ist at any time to allow error active tool to build and review a SAS recovery. database and uses SAS programs to produce monthly activity reports, Gantt The program used to create charts, and calendars indicating start and this dataset is Appendix A. finish dates for ongoing projects. The system was written and is operated in an 2. A TSO CLiST to allow environment without SAS/OR*. managers to browse and edit the the database using FSEDIT 1-",Sugi-10-89 Cary Rosenberg.txt
"a ABSTRACT large community outreach program with several clinics in the Bronx. The hub of MMC's data The paper describes the application of SAS processing capabilities is the IBM 3081 Model D software In an inventory control system at computer. It is a tightly coupled system Montefiore Medical Center. an 1825 acute and containing two integrated central processors, long term care beds institution. both addressing the same central storage. MVS System Control is utilized and operates in In the past, batch segments of an accounting System 370 mode. MMC has a large SAS software program were utilized to control its software users group. Release 82.3 (82.4 is 2500 inventory items and proved inadequate in in testing stages) is applied in areas such as providing the management information necessary statistical analysis in medical research, census to control the inventory operation effectively analysis to support administration of medical and efficiently. SAS software was introduced services, cost analysis in the decision making by the Department of Management Science to process, graphics for presentations, and provide the analysis and control data necessary recently, in material management as a to properly maintain inventory levels, improve the physical layout, and forecast and plan for management tool. the future. Inventory items for the Medical Center are received, processed, stored and distributed INTROOUCTION from a central warehousing facility. Based on requisition from the user",Sugi-10-90 Aslan Matlaw.txt
"practice, the WBS for a major program can extend to Level 6, 7, 8, or even lower. For example, SAS®QUOTE is a set of programs and procedures in Figure 1, Level 3 could be used to divide developed at E-SYSTEMS, Eel Division, -using SAS hardware/software design tasks into major to access the Division costing/pricing database equipment types as to type (prime VB support). and process this data to meet many internal and Then Level 4 could break down into the various customer decision support and analytical equipments to be developed. Level 5 could requirements. It makes extensive use of the SAS provide module breakdown, etc. The production MACRO Language, looping capabilities, PROC tasks could be broken down in a similar fashion. Transpose, and SAS/GRAPH®. The potential for growth and additional applications is Vast. Figure 2 is another example WBS showing production of four space systems. Here, Total Space Flight Systems is Level 0 and each Flight Unit (FU) is at Levell. All succeeding references to the WBS in this paper are to 1.0",Sugi-10-91 Morris.txt
"AN INDEXING APPROACH TO RANKING RISK IN CONSUMER CREDIT PORTFOLIOS Marshall Costantino, Citicorp Retail Services, Inc. Richard D. Heberlee, Citicorp Retail Services, Inc. Collection Staff shortages: and inexperience INTRODUCTION made passing through the queues virtually impossible during the time between billings. This paper reports results using the base SAS software to generate delinquent account queues Inordinately long down-time during regular by expected value (Risk Index). The Risk business hours minimized the potential for Index Decision Support System was built in consistent collection strategy execution. response to adverse financial concI! tions, to work overloads, to operational/system defi- An unorthodox payment application methodo- ciencies, and to unstable data base derivation logy classified accounts in incorrect and retention. delinquency age categories. The Risk Index System consists of several FREQ PROBLEM DEFINITION and MEANS procedures of the standard base SAS* software package. These procedures generate Given the above issues, an interim step to a the expected value (Risk Index) distributions, statistically valid Performance Scoring algo- the Scheduler, periodic Payment Reports, and rithm had to be developed in a short time Payment Rate/ Balance diagnostics. To insure frame to reverse the loss position assumed by the validity of the Risk Index, an experiment- this de novo portfolio. The interim approach al environment was utilized. Ultimately, the was required to address the following Risk Index approach was not- only validated, considerations: but it was also transported to several other portfolios within Citicorp Retail Services and Minimize the effect of downtime during to the Citibank European Division. business hours. Minimize the instability in the loading of THE SITUATION the queues. Rank the Delinquent accounts by high to low The situation which confronted us was that of risk. a de novo Citicorp revolving credit card. The Provide a Deci",Sugi-10-92 Contantino Heberlee.txt
"aboratories, Inc. Performance evaluations are ranked on a fifteen ABSTRACT point scale from -I (unsatisfactory) to +5 (out- standing). Salary grade position refers· to At Berlex Laboratories, an ethical pharma- where an employee's salary falls in relation to ceut i ca 1 company, emp 1oyeel 5 performance eva 1ua- the salary range defined by Human Resources for tions and salary increases are determined on an that job. The five positions are below minimum, individual basis. The amount of a raise and the lower third of the range, second third, upper number of months unti 1 eligible again are deter- third, and above maximum. The number of months mined by performance rating and salary position until eligible and the percent increase are de- within the limits defined for a job grade. fined in matrix tables where the rows represent Manual tabulation of salary transactions for a performance evaluation rankings and the columns workforce of some 700 employees became an over- represent salary grade positions. whelming task for annual budget reports and pro- jections. In response to this burgeoning pro- An Example of a Percent Matrix: blem, a system was developed for calculating, reporting, and summarizing this information more <min 1/3 2/3 3/3 >max efficiently. This system, PEBUDY (Personnel Budget by Year), is a macro-driven program with -I 0 0 0 0 0 an interactive front end menu. The multi-level 0 0 menu interface uses SAS/FSP to first prompt the Unsatisfactory I 0 0 0 +1 users for the",Sugi-10-93 Hines Buonomo.txt
"THE EVOLUTION OF A DECISION SUPPORT SYSTEM IN CONJUNCTION IHTH A CLINICAL/FINANCIAL DATABASE Sara O. Briller New York City Health & Hosptials Corporation These tools ought to be readily The New York City Health and Hospitals accessible and highly adaptable to Corporation (HHC) is a 1.7 billion specific management needs. To this end dollar health carp. orqanization with 11 the DSS must be the outcome of a acute care hospitals, - 4 long term care continuous interaction between decision facilities and 5 primary care centers. makers and the information processing The HHC is in the: process of in-house function. This i terati ve process will development of its clinical/financial ensure t.lle responsiveness of the database. The first stage icludes data product.s to the users I needs, as well as fram the acute: care hospitals only_ SAS the viability of the system. is used for the creation and maintenance of the database, which consists of SAS DATA 'ID THE LEVEL NEEDED AGGREGATION OF data sets. BY USERS The development of a Decision Support The HHC clinical/financial database System (DDS) is an integral part of consists of data stored on a making data available to the decision transactional level that allows maximum rrakers. It is particularly irrportant flexibility in information processing. when accessibility to the database may The data can be processed on the highest be constrained by the potential . aggregation form at the corporate level, users I limited lmowledge of SAS. as well as on the single admission level, each form of presentation The Decsion Support System ought to be satisfying different needs. Corporate desi<;med and implemented within data and interfacility comparison a decision sUPPJrt environment that information may be used for planning and entails transformation of data into budgeting purposes in Central Office. information and information processina. The need for corporate and facilities' Information refers to data which .- operational infonmation ma",Sugi-10-94 Briller.txt
"Services Abstract time of final settlement, which is after the The Hospital Reimbursement Section (HRS) of data have been audited. the California Department of Health Services In 1981 and again in 1982 the state (DRS) has been using SAS to help hold down the high and rising cost of inpatient hospital care implemented additional regulations designed to further reduce Medi-Cal reimbursement to in- in California since 1980. SAS is used to efficient hospitals. These new regulations re calculate reimbursement rates for the 549 hospitals which provide services to Medi-Cal suIted in additional data requirements and calculations. (Medicaid) patients in California. Three regulations, each with its own set of formulas, The first of these new regulations, Section are used by HRS to limit hospital inpatient 51537, reduces reimbursement to hospitals which reimbursement. SAS is used for all of the have an occupancy rate below 55%. The next programming needs of HRS. Many unique and regulation, Section 51539, reduces reimbursement useful tools have been developed over the to any hospital with an average reimbursement years to deal with these regulations. The per discharge above the 60th percentile of its SAS system used by HRS is now a complete pack- peer group. A peer group is a group of hosp- itals with similar characteristics, which theo- age that is used to determine approximately retically would have similar costs if all hosp- $1.5 billion in Medi-Cal reimbursement each itals were run",Sugi-10-95 Bernstein.txt
"Storage Reduction - The versatility of SAS* as a programmer/end-user tool is generally well known and accepted by An application that has been optimized versus those acquainted with its capabilities. An one that has not affects storage requirements important element that is often overlooked or dramatically. especially when little consider- may not even be considered when using SAS ;s the ation is given to proper planning. Often the need of following a set of optimization guide- end-user as well as data processing directly lines. It is often found that the simplest of suffer from the neglect or lack of knowledge of requests can fall prey to violations of available the application developer. Much of this harm resources, much of it due to the fact that little could be avoided with better care and planning, or no planning occurs prior to program execution. thereby greatly reducing excessive resource Examples of typical abuses as well as guidelines utilization, such as in the amount of work space. for their prevention will be presented to assist the programmer/end-user streamline applications. Responsiveness - Performance Improvement - In many instances application response time (wait time between requests), is related to the way in",Sugi-10-96 Lafler Kirchman.txt
"PROTOTYPING LARGE SYSTEMS USING THE SAS SYSTEM Stephen C. Martin, Westinghouse Electric Corporation Robert M. Moreau, Westinghouse Electric Corporation Prototyping of large and complex computer applications may tPU( '.IsrR ( !; tpur '!:SIR ( ) become the most popular and effective technique that will be \CHOIC, '!:PUT '!:51R(SELECr OP1WII R~O PR,SS ,NrER); used while defining and developing new applications. The formal :UNPur OPI~, methods of developing computer applications utilizing bulky or '!:pur '!:SlR( ). lengthy system analysis documents, structure charts, pseudo- flNI~H \(1' WI'JR"" llHHI t{;OIO '!:LENGrH(&O~lR) code, detailed program specifications and repetitive review proc- %If - 1 \HI[N %DO, SLlo-&OP!~; '!:LET esses are becoming outdated very quickly. These techniques of ~lLSc :l.DO, communicating the details of a computer application have '!:L~T ';l r"":tsu~S'1 ~(&OPI R, 1,1) UND, proven to be very lengthy. costly and inefficient. Prototyping ad- vocates development of a quickly modifiable system that is re- 'UF ~""ELcl '!:TII[N :tDO, :UNC S~~IN(WIlICINQ); fined through an interactive process during the definition and :o-.wU1CrN'il, '!:GOTO SIART. development of a production system. UNO; 1faditionally, prototyping was used for system testing and user \Tf &SELc2 %rHlN %I){), CA~E'>CRN Wl lO~""l, RUN, PROC rS[OIT DArA ,WOl ,CAotDMA SCR'-EN,,,Dl acceptance at the end of large projects. Currently, these tech- %GOTO SIARL niques are being used during both the first phase of a develop- ment project and through all subsequent phases. The success of %H &~cL""3 %THEN \00; OP I 1011 -t. RUN. PRQUUM~ :;CR!:~No-WOl PROD~CRII PROC f SEOlT DAfA--'lDl, any system prototype depends on the flexibility of the software. '.IGOTO SlART; The SAS System provides the necessary tools to build and use 'nr &Sfl=4 %TH[N %DO; prototypes that potentially can be expanded into production sys- ""or, I'LE.~oC~1I PROC ,'ilcUn D~fA""WIl! E'LEMDATA ~CR[ION QP r [ON_oj, RL;N, ~GQTO SI~Rl, tems. T",Sugi-10-97 Martin Moreau.txt
"nsaction processing, record keeping, monitoring and What is it about the existing structure of many exception reporting. etc. ) . However, in the large corporate data processing organizations midst of rampant economic uncertainty, wide- that can transform the proficient SAS user, rich spread deregulation. more intense competition, in technical skills but often data-poor. from a technological advances and increasingly favorable vague threat to the status quo into a confirmed cost-performance ratios of computer hardware, nemesis? Why do many frustrated SAS users the demand for flexible and rapid access to perceive established procedures and standards corporate information resources to support enforced by DP areas as obstacles to he sUr- managerial decision making has been growing mounted rather than as necessary safeguards? explosively. Furthermore, given that many SAS users are technically self-sufficient, why are their dealings Another factor which reflects the changing with DP departments so often characterized by nature of user needs is the increasing complexity the same adversary relationship traditionally of their requests, which can require the integra- associated with non-technical end-users? tion of data from several sources, often from different functional or organizational areas. And By focusing on the technically self-sufficient finally. responding to the rapid proliferation of SAS user as a case in point, this paper address- low-cost microcomputers and reasonably e",Sugi-10-98 Knoop.txt
"porate data ABSTRACT base. The size of this database can be appreciated because it would have to A non - EDP unit of the New York City Health and Hospital Corporation include at a minimum 1 demographic record, 20 service records and 10 developed prototype SAS Prcx.::rrams to diagnosis and medical procedure records create a consolidated Clinical/Financial for each of the approximately 250,000 data base for 11 acute care hospitals. A review of external vendors' data base patients \ve serve in a year. Moreover, these records have to be categorized to systems indicated that in-house indicate into which of same 500 types of developrent 'WOuld produce a systEm with greater functionality at less cost. disease or condition the patient has been placed (this categorization is into Diagnosis Related Groups, or DRGs) · It then \vas necessarv to convert the prototype progranh~ into~ a production system to be run on a regular basis by Several private vendors offer systems that accomplish the categorizing and the EDP Department. This paper also create data bases. These systems discusses the characteristics of the data, the reasons for creating a were reviewed and evaluated for use at production system and the considerations HHC. While the review 'itlaS proceeding, a involved in migrating to a full small unit I outside of the EDP depa:rtrrent, but pJssessing SAS production environment: prograrrming skills, began to develop a prototype data base system. The The reasons for creating a producti",Sugi-10-99 Kryzak.txt
"SAS/ AF® Software Tutorial Phil Busby, SAS Institute Inc. This tutorial covers advanced techniques for SAS programmers to create full-screen, menu-driven PROC 0 GO · TRAC! application systems using SAS/AF software. The If iTRACE · iSTR(TRACE, THEli - following topics are included: CONTROL MSG CONLIST PROMPT ;USI!. - CONTROL IfOHSG PROMPT Using SAS AUTOEXEC to go directly to the fRn'l'(CBT.SASUS8R,SAS8X!CI A1.LOC r( SASUS&R) UNIT (VIO I NBW TRACKS SP( 5 1) DELBn first screen of your application. A1.LOC DA( 'SASprB,CBT,OI!I!O'1 UU(CBT) SllR ALLoe r ( SASSKBC) + liB"" TRACKS 5P(5 1) UIHT(VIO) OBl-ITB Writing a ### MACRO to control the display "" of a program screen. 1* SET U'P AUTOIX8C "" OP8NFILB SA!liXEC OUTPU'l Routing program screen output with userfield SET UASEXECB is'I'R(PGM;) PUTfrLl!:: SAllEnc value substitution to an external file using the === FI LEREF option. 'STR! %LB'I' DKSPfK 1S.UTR{SUBMIT 'PlIoe DISPLAY ;RUN;' ; ); I Setting up a CBT automation sequence using (contin"".d n ·· t scre.lI) 011 the AUTO option. Displaying a graph and a CST frame simultaneously with the GRAPH option. Tracking the answers to your CBT multiple- choice questions with the QUIZ option. from iCOllt1111111d pr&V1()lUI screen) PUTnLB SASEXEC SET iSASEXEC_ + Section 1. The SAS AUTOEXEC facility for iSlR{ ~L!'I' DMsorK !8.'STR( SUSPBND; SUII!\:T 'PROC DISPLAY ;aUN: ' : IND; ) ; ) custom initialization. PUTPrLIl SASEXEC + SET UASEl!:IlC~ tSTR(UIT OMSLPK18.UTR!~GIl;SU6M:IT 'PROC ilISPLAY;RUN;';);) PUTPIT.. .!! SAsnEC With the SAS AUTOEXEC facility of the SAS iSTR( SU8MIT 'PROC DISPLAY C=CBT. IIAIIiDEN. TItLE.CST; RUN;';) Display Manager System, you can configure the PUTPILB SAS!!:XEC CLOSPILE SAnXBC SAS session for your user, and put the user onto "" the main menu of your SAS/AF application 1* TAKE USSR DIRECTLY TO C8t TITLI BcatEN. INVOKli: THB SAS SYSUM "" system. The user needs to re-member one SilT OI'TIONB_iSTlI.jIlONOUS IIOSOURCE NONEWS NOIlATE NONUMBBR oj. command to enter on the host",Sugi-11-02 Busby.txt
"lidation Base SAS® software for Personal Computers Now that our point-af-sale data entry can be used as a very efficient and flexible screen has been developed and can be data editor. Within a SAS program, the displayed, practical data entry is only a loop away. The special variable _CMD_ is DATA step is used to create windows used as a controller: through which tasks such as data entry, data validation, and query are performed. DATA SALES; WINDOW SHOW COLOR=GREEN IROW=l ICOLUMN=l ROWS=10 COLUMNS=40 GROUP=ONE I ntraduction #1 'Input Item Here: ~ ITEM $20. #2 'Input Quantity Here: 'QUANTITY 8. There are many ways within the SAS #3 'Description: 'DESeR $20. System to create data entry screens; #4 I Cost: 'SALES DOLLAR10. 2 however, using the WINDOW and DISPLAY #5 'Total Amount: 'TOTAL DOLLAR10.2; statements within base SAS software, data DO UNTIL (UPCASE(_CMD_)='HALT'); validation and cross-checking are also DISPLAY SHOW.ONE; easily accomplished. Some of the TOTAL=QUANTITY * SALES; advantages of this technique include the DISPLAY SHOW. ONE j ability to customize the editor to meet OUTPUTj specific needs, the availability of efficient ENDj table look-up facilities at any time during STOP; an edit session, cross-checking of input values to any desired level of detail, and the ability to perform calculations at any Formats used in conjunction with the PUT time during a SAS session. This technique function provide efficient table look-Up also offers efficient query for large data f",Sugi-11-03 Roach Pendergrass.txt
"Advanc ed Macro Program ming Lynn Hannah , SAS Institut e Inc. Introdu ction This tutorial was presen ted in ord~r to %STR remove s the signific ance of all special addres s the most common problem s encoun tered charac ters, excludi ng % and &, at compile time. by macro program mers. The major concep ts Use this functio n when you can see the special covered were writing efficien t program s and charact ers you wish to quote, but you do not introdu cing Version 5 feature s. This paper will want to remove the signific ance of % and &. cover the key points address ed during the %STR remove s signific ance from the special tutorial . charact ers that are presen t at compile time, (the ones you seeL it does not affect special Writing Efficien t Macro Program s charact ers that occur after a macro variabl e has The key to writing more efficien t program s been resolve d, or a macro has been invoked . comes primari ly from having a thoroug h unders tanding of the program ming techniq ues %Let Checkda t=%Str(P roc Print: Proc Content s;): you are using. Most macro program mers have problem s in the same areas. The problem areas we will cover include quoting functio ns, evaluat ions, and unquot ing. A major emphas is Using %Str on single and double quotes and unmatche d parenthe ses is placed on quoting functio ns because they tend to make up the common problem area. %let Title=% Str(Sally %'s Garden): Macro Quotin g Functio ns Quoting functio ns are an essenti al part of %NRSTR the macro facility . The SAS® languag e uses single and double quotes to literally assign %NRSTR remove s the signific ance of all text. The macro facility , because it constru cts special charac ters, includin g % and &, at compile SAS code, also needs a way of literally assigin g time. Use this functio n when you can see the text and quoting text after resoluti on. special charac ters you wish to quote and you also want to remove the signific ance of % and &. The importa nce of quoting can be se",Sugi-11-04 Hannah.txt
"To begin, you need to develop a design (not writing source code) that will produce your results. When you develop the design, you need A SAS procedure is a program usually written in a high-level language that performs a specific to think about what the user can do with your task. In this paper, we will aid a programmer procedure. Some of the questions you need to in writing a SAS procedure for Version 5 by answer are: examining the parts of a procedure, explaining the steps involved in writing a procedure, and · What options can the user call? Options are discussing areas in writing a procedure that are either on/off tasks or parameters that can likely to give the programmer problems. have values assigned to them (keyword=value).",Sugi-11-05 Parker.txt
"In addition to the required elements, there are a method for writing a custom device driver for use number of optional components to allow the user with the Version 5 SAS/GRAPH software under more control over the input and output of the Version 5. graphics code. Sometime the user may want to generate an External Driver output file. Another reason for this featu re is to allow the user to SAS Institute provides a number of device optimize the driver code for spooling drivers as well as a linkable device driver. The considerations. Another optional feature is the standard drivers provide support for a large Header and Trailer writing facility. If users want number of graphics devices. Since SAS Institute a header or trailer file written to the Metafile, cannot support all graphics devices, the they can invoke the header or trailer writing Metagraphics Driver Facility exists to allow the code. user to write a custom device driver. This facility allows the user to have support for a new graphics device with full SAS/GRAPH capabilities OVERVIEW soon after the release of the device. , FEATURES HEADER? N T Produce The Metagraphics driver facility allows the user E Metacode to write a device- intelligent device driver. R Users can incorporate the available hardware N TRAILER? features of the graphics device that they want to A L support. Some examples of these features are hardware text fonts, polygon fills, circle/arc tITERACTIVE.. 1 D generators, line types, rectanglefills, and so",Sugi-11-06 Middleton.txt
"CAPTURING AND REPORTI-NG PRIMOS SYSTEM USAGE DATA Toby Trott SAS Institute Inc. Cary. NC Introduction The Usage Utility The Prime usage utility provides measures of the Prime® provides the usage utility with every activities of various components of the system Prime 50n~ series computer. The usage utility covering the periods between the user-specified collects data on various system activities and sampling intervals. It also provides measures of peripherals providing measures of the compute""r's some parameters from the last time the system performance. Data are collected at intervals had a cold start. specified by the user at invocation. This facility can provide volu.mes of very useful information, but the practicality of these data i-s compromised The usage utility is invoked by the USAGE by thei r format and sheer quantity. command accompanied by any of several options that control the format and contents of the output and the frequency and duration of The SAS® System can be used to organize these sampling. The SAS program supplied with mounds of information collected by the -usage Version 5 of the SAS System for Primos is utility into tables, charts and graphs that offer designed to read the full format report which is immediate impact and clarity. produced by a USAGE command with the following format: With the release of Version 5.03 of the SAS USAGE -ALL -FREQ n -TIMES m System for Primos comes a sample program called USAGEREAD.SAS which is designed to read the output produced by the usage utility and create where three SAS data sets. These SAS data sets can be -ALL requests that all available statistics be used to produce customized reports of system reported utilization. By providing this SAS program, we have given Prime users the first step in -FREQ n specifies that samples be taken at n analyzing the performance of their system. second intervals and -TIMES m specifies that m samples are to be My hope in providing this program is to begin an ta ken. excha",Sugi-11-07 Trott.txt
"Performance and Capacity Planning Considerations for the SAS® System on Mainframes Daniel J. Squillace SAS I nstitute Inc. Objectives On the other hand, in an environment where there is little or no concurrent use of the SAS The objectives of this tutorial are to acquaint you system, there is little advantage to installing with performance-sensitive SAS system options in SASLPA in the link pack area. Some degradation the MVS and VM/SP environments and with other might even be observed because loading a private external tuning techniques. Your choice of copy of SASLPA ,is more efficient than page- option settings and tuning decisions can faulting through an LPA copy. substantially affect the resource requirements required to run SAS programs. We will also go over a basic methodology for estimating resource LPA storage in most MVS systems is a scarce requirements of SAS applications. Topics we will commodity, and often you must make hard cover include: decisions when deciding which modules to place there. SASLPA has grown from approximately 250K in release 82.4 to 430K in release 5.08 and SASlPA in MVS will be about 580K in the upcoming maintenance Other MVS program loading considerations release. Most of the increase in the maintenance release comes from inclusion of the routines Saved segments in VM/S P through which procedures request supervisor services. However, you can reduce the size of SASLPA by excluding SAS Display Manager, I/O considerations SAS!FSP®, and SAS!GRAPH® modules if appropriate in your environment. I n this case, Macro processing options these routines would be loaded from the SAS Other SAS system options program library if needed. Sort cons'iderations Other MVS program loading considerations PL/I considerations Even if SASLPA is used to maximum advantage, Quick and dirty SAS application sizing you may still find that the SAS program library remains a significant contention point in your system. If this is so, there are several things for you to",Sugi-11-08 Squillace.txt
"s SMF type data is heavily used in making decisions that may involve the spending or saving of thousands or even millions of dollars for a company. SMF data is also cri~i:al to the success of many other functions, such as chargeback systems and security auditing. These facts alone rank SMF type data right along side other types of corporate data in terms of importance of how the data can be used to effect the profitability of a corporation. Yet. in many installations SMF data is lost or duplicated and poorly archived; in short. SMF data is mismanaged. The author endeavors to illustrate why SMF data should be regarded as an important corporate asset and how it should be managed. I NTRODUCTI ON types are written for each subsystem. This member must be carefully controlled to prevent suprise changes in SYSIDS and changes in which The handling of SMF type data has often been SMF record types are to be collected. This is found to be an error-prone and political also true of the PARMLIB members of other process in many installations. The political data collectors. such as the Resource Monitor aspects of access to SMF data are Facility (RMFJ. understandciJle, since functions such as data security. chargeback, capacity planning. MAN FILE DUMPING ERRORS performance management, and many others all depend on this data. Yet, in spite of the dependence of all these critical functions on I t is more common to experience SMF problems afte r the data has been wr i tten to' the SMF man SMF da",Sugi-11-09 Shane.txt
"data to management in an easily understood form has been a persistent problem. This paper examines a graphical technique for-presenting paging data activity as a relative fraction of the system's total I/O activity. This technique will also be used to comment on the benefits of paging into Expanded Storage on the new IBM 3090 series of processors. 1.0 Introduction spaces or to obtain pages to service page faults (i.e., the, program waits on the system to retrieve a page that is not in memory) for Paging is acomplex activity that can consume a significant portion active programs and tasks. Paging consumes two system of a system's overall capacity. As such, paging is a significant resources: CPU and 1/0. Since only a few thousand instructions factor in system performance that must be included in any are required to service a page fault (i.e., schedule an 110 to obtain management reporting scheme. Historically, most analysts have the desired page), the CPU impact of even large paging rates is chosen to report paging rate as an indicator of system paging not overwhelming for large systems [1 ,2). However, the cumulative activity, effect of transferring hundreds of 4096 byte pages per second can easily represent a large percentage of the system's 1/0 The use of paging rate as a management reporting indicator throughput. makes the implicit assumption that the reader of the report is aware of some range of paging values that are ideal for the reported In fact, there are significant",Sugi-11-10 Artis.txt
"us SAS® code (such as format, label, and rename lists) is 1) The SYMPUT subroutine. presented through three examples of inereas ing 2} Construction of macro variable names and complexity. The more experienced macro program- values through concatenation. mer will recognize the wide applicability of the 3} The use of the double ampersand in method to many of his own problems involving macro variable arrays. repetitious lists. The novice macro programner 4) The o/aDO loop. wi 11 increase his understanding through seeing basic macro coding tools (SYMPUT subroutine and EXAMPLE 1 macro variable arrays) applied to a class of related problems. We have two data sets with the s~e variables. One has format information that we want to add to Usually macros should be used to manipulate the other. For example, let JUL85 be a member of the SAS data set output by a statistical pro- the library with libref Q-ILD. cedure because the same processing is done many times with only minor modifications. The tech- OB5 CHILD AGE HEIGHT WEIGHT NUTRIT nique presented in this paper helps the program- mer to formalize the development of this type of LCH 60 6 51 9 macro. Our third example uses PROC OORR to 46 47 4 7 2 MEB illustrate this process. I NTROOUCTI ON Each of the variables has been assigned a for- Suppose a recurring job consists of a series mat. Now let Al.G85 be another member wi th the of steps, say, a OATA step followed by a PROC, same variables, but no formats. The following then another DAT",Sugi-11-100 Whitlock Cumming.txt
"These macros cut the upper or lower tail from the areas of distribution adjust- of a distribution by putting missing ment, data transformation, randomization values in place of the data. Figure 1 and macro writing. shows a distribution with high extreme 1. Macro CUTTAIL and CTWTIE cut the up- values. Using macro CUTTAIL we can elim- per or lower tail of a distribution. inate those values. See Figure 2. Thus the user can automatically ex- 'elude the extreme values of a dis- tribution. 2. Macro LAG is a generalized version of Distribution with sOllie extreme high values the LAG function. It is able to de- ... termine the lags of a range of the F variables, the lags beyond the IOOth lag, the negative lags (leads) and """""""" """""""""" the lags by a BY variable. """""""""""""" 3. Macros HANDSEL, SHUFFLE, RANDGRP exe- """""""""""""""""""" """""""""""""""""""""""" cute certain randomizations of the """""""""""""""""""""""""""""" """"10"""""""""""""""""""""""",, """" observations. """"""""""''''''''''''''''''''''''''''''''''' """""" Macro HANDSEL selects a random subset --+-----+-----+-----+----+-----+-- -2 -1 0 1 2 ::I of the data set so that each observa- tion has the same probability of Figure 1 being chosen. Macro SHUFFLE shuffles the observa- tions. The !Hlme distribution i!lfter Macro RANDGRP randomly groups the ob- cutting its upper tail .. servations into a giyen number of groups of equal size so that each 1 FI observation has 'the same probability c1 '"" · , """""""" of being put into any group. """""""""" 4. Macro writing users sometimes need temporary da",Sugi-11-101 Felsovalyi.txt
"The Use of the SAS Macro Facility in the Development of a Clinical Information System Thomas R. Hoffman, Lederle Laboratories INTRODUCTION This paper discusses the use of the SAS 3. Reduced coding. macro facility in the development of THECIS, a system in use at Lederle The macro facility can be used to Laboratories for processing information build a higher level command lan- from clinical studies. Information on quage specific to the system. Once THECIS was first published in 1984[1]. these commands are in place, they since that time, data form nine drug can be used instead of many lines of projects, including 70 studies and more code. This feature simplifies coding, than 5000 patients, have been processed documentation, and maintenance. in THECIS. 4. Conversational. The original THE CIS code contained no macro lanqtiage. Instead FSEDIT screens The macro facility can be used to send were used to display menus and capture messages to a user, evaluate the user's user requests,. SAS code was first written response, and then conditionaly send to a temporary file, and then executed the user another message. In some using the %INCLUDE statement. situations, this conversational mode of operation is preferred to a menu During the past year, the system has been system. Rather than read an entire completely 'macronized', that is, the SAS menu, the user only sees the necessary macro facility has been used throughout information. the system. CUrrently, THECIS uses over 600 macros. Forty percent of the BAS 5. Menu avoidance. statements that are used to control the system contain some reference to the Many experienced users prefer to avoid macro lanquage (a word beginning with or skip menus. This menu avoidance, either an & or %), and 20% of the THECIS or option stacking, feature is program library contains macro code. relatively easy to implement using the macro facility. WHY MACRO? 6. On-line help files. conver~ion The to a macro system required The SAS HELP command can be use",Sugi-11-102 Hoffman.txt
"for specific data items, a suggestion facility and an online news bulletin to alert users to This paper describes the design and some of new tools as they became available. the coding concepts of a management information retrieval and reporting 'Toolbox,' focusing on In terms of administration of the system, the report generator. The system, which is the goal was to make it as simple and efficient written in the SAS macro language and as pOSSible, so that a new group of users and is an interactive, SAS/FSP®. menu-driven files could be added with a minimum of effort, system designed for the non-technical user. while insuring that security and system Front-end files define valid users, the data efficiency were nat compromised. The SAS macro libraries to which they have access, and the language and SAS/FSP were chosen to implement data sets with; n those 11 brari es. Users choose this system because in combination they permit which file they wish to access; a PROC CONTENTS the flexible interactive menu-driven environment brings the variable descriptions to the screen, essential to the success of such a system. and, in the report generator, the user specifies which variables to include, as wen as 'sorting, Techni'cal goals for the systems included: subsett 109. co 1urnn sequent i n9. tota 1; ng and title specifications. The system can be used on o efficiency any SAS dataset which has variable labels and by o ease of maintenance any number of users. Its chief purpose is to o thorough editing of user input to allow users to access authorized data in ways prevent aCCidentally aborting the system that are useful to them, without programmer o consistency of menus and screens in assistance. terms of layout and colors o keeping the system ""generic,11 i.e. usable by any business unit for any SAS",Sugi-11-103 Miller.txt
"SAS ® DATA SET COMPARISON: OVERCOMING THE LIMITATIONS OF PROC COMPARE Warren Repole, Info Tech, Inc. Jr~, INTRODUCT ION 3. master data set modification with the MERGE or UPDATE Detailed comparisons of SAS data statement. sets can be useful as a method of documenting changes between generations of a data base, such as updates to a A recent litigation support project master production file, or as d tool for at Info Tech involved a large amount of validation of programs which may be data (hundreds of thousands of records) implemented 'as part of a data on which analysis was being continually maintenance production system. performed for several years at different sites. During this period, information For simply comparing variable which was originally unavailable or values in two SAS data sets, FROe unclear was added to the data base, data COMPARE, a recent addition to the SAS entry errors were detected and System, performs adequately. However, corrected, and the structure of the SAS PROe COMPARE does not report fully on data base itself was altered, but certain important differences between or several generations of the data base problems with the data sets of interest. were retained along the way. since the These cases include data base was to be officially entered into the court racocd, a detailed 1. differences in the variables description of all data changes was contained in the data sets, required. At that time we had access only to a test version of PROC COMPARE, 2. differences in variable but the ""audit trail"" that was needed attributes, e.g., length or could not be fully produced with that format, procedure. We found it necessary to put together some general-purpose programs 3. non-matches of ID variables, to be used as tools for the purpose of indicating the addition or documehting the changes made to the deletion of observations, original data base, as well as to the subsequent generations that may have 4. duplication of ID variables, which causes PROC COMPA",Sugi-11-104 Repole.txt
"programmer a new tool to build menu- driven 'expert' systems, one which allows easy interfaces to be constructed by This paper discusses the role of SAS* straight-forward means. A new method was macros in SAS/AP*. It briefly summarizes givto·n to conditionally execute SAS statements and to input data into macro the ways macros can be used and then describes the role they play in SAS/AF. variables. The relative benefits and disadvantages of a menu-driven application developed This paper addres-ses what the role of the using macros alone and developed using SAS macro is in SAS/AF, it will begin Macros with SASjAF are compared in terms with a brief description of the operation of programming effort and real costs. of AF and how it can utilize macros, and continue with an example of t 1-.:, use of Macros in im AF system.",Sugi-11-105 Cary.txt
"rvey. Typically. a survey The use of SAS* in processing surveys has key quest~on(s) of interes~. These <questionnaires) is described. and the key question(s) are normally single limitations of SAS for survey processing response. categorical questions, and be referred to as reference var- w~ll applications are discussed. iables in this paper. The survey is then The first limitation"" applies to numeric analyzed by these reference variables. PROC UNIVARIATE response questions. The ""usual"" analysis per:iormed provides cross tabs for categorical response ques- should be run for th1S type of question. and PROC UNIVARIATE (var~ables) yet the resultant printout can be vol- tions i""or numeric uminous. Potential solutions are discus- response quest~ons sed. and the shortcomings of each (var~ables). solution are explained. The recommended of runn1ng solution consists PROC Note that other SAS procedures are used UNIVARIATE with the NOPRINT option (re- as necessary, accord~ng to the speci£~c ducing printout). saving the target analysis desired. However, PROC FREQ and statistics in a SAS data set. then using PROC UNIVARIATE are the most commonly PROC COMPUTAB to print the statistics in used. When us~ng these procedures. a tabular format. Macros are described, certain 11mitat2ons quickly become which provide a general implementation apparent. of this solution. It is desirable to run PROC (1) The second limit~tion is th~t PROC FREQ UNIVARIATE for each level of the refer- ence variable ('i .·",Sugi-11-106 Billings.txt
"andling date), for currency (or promise) functions of the SAS base product, trading back into dollars by a coupled with the parameter passing specified future date. abilities of the MACRO LANGUAGE, enable a superior profit reporting system for 2. HEDGING refers to guarding transaction-based data in foreign against excessive trading currency trading. The resulting program is significantly more elegant than the losses by protecting LONG positions with SHORT sales pL/I program previously used for this contracts, and protecting SHORT application. sales contracts with LONG positions. Introduction: 3. Selling SHORT refers to trading The Foreign Exchange department in promises to deliver a foreign banking seeks to earn profits on that currency amount on a specified portion of the bank's deposited funds date, in exchange for dollars which it manages by trading on the received now. ever-varying currency exchange rates existing in the world's money market. Several computer programming concepts in the Macro Language can be Skilled traders seek to exchange confusing unless specifically defined, dollars--or promises (in the form of namely: ""forward delivery contracts"") to pay a ""value. I ' dollars--for foreign funds when the 1. PARAMETER Any dollar is strong against another word or number in an equation. currency, in the anticipation of buying 2. MACRO back a greater number of those dollars a subroutine, (or hcovering"" the IOU's) when the here coded in the SAS macro foreign currencies str",Sugi-11-107 Woods.txt
"FINANCIAL FORECASTING THROUGH SAS MACRO PROCESSES Heydar Pourian, Western Carolina University Introduction Normally. forecasting needs can be 1. Forecasting Needs of a' Financial Managf'.r approached by either ""external"" or ""internal"" II. Modeling Cyclical External Factors forecasting methods [see. e.g., Gitman, 1985, p. SAS MACRO Programming III. IV. 158-159]. Each ~eneral approach to forecasting, The Datn V. Application and Error Evaluation in turn, generates errors particular to that Notes technique. But errors in internal forecasts are References not normally as serious as errors associated with external forecasts. This is because many One of the most serious problems faced by factors in the internal operation 0f a business forecasters in the recent analysls of markets firm are endogenous and under the control of the has been the large, unprecedented err0rs enterprise itself. Factors influencing the assoc::f.ated with foreca.""!ting financial variables external forecasts, however, are exogenous and rsee, e.g., Penner, 1984). A possible by definition beyond the control of 8: firm. explanation for unsatisfactory results may be Many external factors in a business environment, due to forecasters' avoiding methods which rely on the other hand. have a, cyclical nature. They on complex computation procedures which. include sales, interest rates, cash receipts, historically speaking. have been costly to use. among others. External forecast errors observed in the recent years suggest the exploration of alternative forecasting schemes. The method This study contains a forecasting method based on a computationally-lengthy, vet proposed herein is an external method of analytically-simple, procedure. By use of SAS forecasting which can 8atisfy the cyclical forecasting needs of a business enterprisf' in Macro processes the difficulty of the computations is greatly reduced. The included regard to financial planning. capital budgeting. and financial hedging. method is referred",Sugi-11-108 Pourian.txt
"SAS* AND TH2: IBM DIALOG MANAGER AT MILES PHARMACEUTICALS Chris ~. Corcoran James River Corporation Miles Pharmaceuticals data Because we want to make th"" entry process as efficient and Miles Pharmaceuticals is a division standardized as patient po~sible, of Mi les Labt:watories which in turn data is stored in arrays. Although (West A.G. is owned by Bayer arrays work well for data entry, Pharmaceutical unfilled fields waste a lot of un- Germany) . The which is located in West division, necessar""y space. As an example, is among many other CT, one patient may take from five to Haven, the center for processing fifteen lab tests. The fields are things, clinical trial data from around the set up in array format allowing for C:OLtntry. fifteen different entries. Normally, only five are made and Com~uter Facilities ten fields are left blank. Our solution is to turn each of these The Biometrics department at Miles databases into a format more Pharmaceuticals performs the bulk economical for storage and of computerized clinical analysiS. processing. This new database will OU,r equipment has allowed us to be ref er""r'ed to as a Leve I 2 remain competitive in the clinical database. Generally, there is one information processing tield. We Level database per clinical 2 are connected to IBM 3083 in an It from this Level 2 stUdy. is TSO. Elkhart, Indiana via Our database that the next step, the department alone has over 40 IBN running of production tables and and 3180 terminals in 3278, 3279, summaries, is performed. a P.C. addition to We also have two Zeta pen plotters, a Xerox 5700 Where Does The IBM Dialog 8700 Xerox laser printer, and a Manager Come In? laser printer. As member of the programming a Processing of Clinical staff, recognized early on that I Data Trial the users in our department needed some sort of interface to the many Case report forms (CRF's) are programs that they would be running developed in house using the Xerox t~ analyze their studies. This laser. The C",Sugi-11-109 Corcoran.txt
"PERFORMANCE EVALUATION OF MICROCOMPUTERS WITH EMPHASIS ON THE IBM PC/AT Mr. Wayne E. Bell and Dr. Thomas E. Bell Rivendel Consultants Inc., Computer Technology Group approach is more appropriate to The growing use of microcomputers has led si tuations in which the application to interest in their relative environment is not specified in detail performance. Many of the tasks now being (e.g., general evaluations to be reported assigned to personal computers have in the professional literature). previously been assigned to minicomputers or mainframes, so performance capabilit- To use the first approach appropriately, ies as well as functional capabilities a comprehensive study must be done to must be considered in selecting both the indicate the important aspects of the computers and the tasks to be assigned to system requiring testing. This study is them. The IBM PC/AT is one of the best needed because selection should be based examples of a new generation of computer on comparative values that predict that offers significantly greater power performance of the system when installed than its predecessors, so interest is [11. this study is not done If particularly acute in determining its carefully, the comparative numbers might, performance characteristics. for example, indicate that System A is superior due to fast disk access even Experience has proven to performance though 99% of the work is CPU-oriented analysts the danger of accepting a Single and System B has a faster CPU. As an test as an indicator of computer perform- output of the study, a series of ance. Al though some comparisons of benchmark programs is drawn up which mainframes and minicomputers still fairly represents the workload of the consist of running a single arbitrary real environment. application program on each candidate, the inappropriateness of this technique The advantage of using jobs representing seems to be understood by the vast the real environment is that, for a majority of performance",Sugi-11-11 Bell.txt
"Microcomputers and SYSTEM 2000. DBMS Paul Kent SAS Institute, Inc. A terminal emulation program provides SUMMARY features of some terminal hardware by emulating the same functions with This paper discusses the integration of PC-based applications with larger data software. (A package of this nature may bases stored on mainframes. It addresses emulate a silent 700 terminal.) features already available in the SAS® Although the PC is capable of doing System and SYSTEM 2000® DBMS, as well as smarter things, this type of link future direction of the interface. software is not. For example,. a program running on a PC can translate ANSI The functional requirements of a screen commands into those suitable for micro-to-host link are discussed, and display on the PC, but cannot provide a scrolling facility since the terminal features of the SAS System that make it being emulated does not have this useful as a link vehicle are placed in context. The benefits of the SAS feature. end-to-end protocol that transfers both output and data are explored and o Smarter dumb terminal compared with other approaches. Here, software provides all the The SAS micro-to-host link supports a functions mentioned above, as well as variety of communication protocols, with take advantage of the nature of the PC. the SAS System, or SYSTEM 2000 DBMS For example, the program may keep a executing on the (IBM, CDC or Sperry) session journal file that can be spooled to the disk. This provides a primitive host. The different methods of file transfer solution, as the file connecting to these host computers are discussed. could be ""listed"" and saved in the session journal on the PC. The program Potential applications of the link can also provide file-to-file transfer. technology are examined, showing how one can integrate the features of the SAS o PC as host terminal clone System on the PC, with traditionally mainframe-based applications. One can Through hardware and software, the PC use the PC as a host wo",Sugi-11-110 Kent.txt
"The SAS System® on the Apple MacintoshTM: What should the Display Manager look like? AIM. Best Biostatistics Department & Clinical Research Center for Periodontal Diseases Virginia Commonwealth University, Richmond, VA 23298 ' likely candidates would be Aztec C and Consulair C. At last year's SUGI it was announced that the SAS So, I know of no technical reasons to reject the System® would be available under IBM PC® DOS. Macintosh Plus as a host for the system. That the SAS System should be available on personal Principals - There are two principals that must be computers is obvious. In addition, the choice of the followed for a successful implementation of the SAS IBM as the first PC for version 6 was also clear. As System on the Mac: I) The Macintosh ""look and anyone who has used the system knows, one of the feel"" should be fully supported through the things that makes this new software so useful is the Macintosh interface. 2) SAS statements should be use of the Display Manager (DM) as an environment identical across systems with few exceptions. for one's session. As such, the DM is presumably The Macin~osh ""look and feel"" - Why not just port designed to be the only thing that might change from the PC versIOn over to the Mac? The experience of system to system. That is, the code for all Apple II and PC programmers is that you cannot just procedures and DATA step code would essentially reco~pll~ a program on the Mac and let it go at that. remain the same whether one was running on a It wIll SImply not sell. Anyone operating any mainframe, mini or micro. What would change software on the Mac expects it to be ""Mac like"" and would be how information was passed down to the reviewers have consistently panned software guts of the SAS system and how the output generated vendors that have tried to take this short-cut. More would be presented to the user. As a result, for any importantly, it is clear that the Display Manager and system to run the SAS System, one important t",Sugi-11-112 Best.txt
"ia, Los Angeles Successes for SAS on the PC The topic of this paper is a set of speculations about how PC SAS will be used in the workplace. We believe that the porting SAS on the PC will achieve its greatest usage of the SAS system to the PC DOS environment as the goal of connectivity between larger systems and intelligent workstations is will be a watershed event for SAS users, and realized. Connectivity will increase the indeed, for business and academic computing productivity of the information worker. organizations in general. It has been Connectivity will allow the information estimated that lout of every 5 Americans uses a computer of some form at work. This consumer to use the computer directly, rather than relying on computer professionals. number ;s expected to climb steadily for the Let us start with the; nformati on worker. As next 15 years. The PC environment is ideally a thought exercise, try to estimate what suited for such institutional change, and in percentage of time information workers spend fact is leading the way towards increased on getting data from one process to computer use bynon-specialists. The another. By this we mean getting data which introduction of PC SAS leaves the SAS are output from one program into another Institute positioned to take advantage of program. Of course, if the two programs are this growing user base. on two different phYSical machines, the In this paper we would like to address required time to do the work increases still se",Sugi-11-113 Hofacker Hoffman.txt
"AN INTEGRATED APPROACH TO CLINICAL DATA ENTRY & MANAGEMENT USING PERSONAL COMPUTERS AND SAS SOFTWARE Robert W. Heinemeyer, FOREGROUND INC. would be less than the telephone charges Introduction for conducting the data entry entirely online and (2) when the data entry As the cost of personal computers environment does not provide easy access (PC's) has fallen and their computing to either power or communications power risen, it has become both connections. So, for example, under practical and economically feasible to the first set of circumstances, if the apply this technology to the traditionally pencil and paper-oriented clinic site were in France and the SAS task of recording clinical research host machine were in New Jersey, it data. Moreover, this application of the would almost certainly be much cheaper technology has become even more viable to set up the French clinic with PC's with the proliferation of very capable rather than to arranga for online FSP and affordable personal computer-based sessions. Similarly, under the second data filing and data base management set of circumstances, the personal programs. computer approach would be attractive The object of the ensuing when the data must be entered at a discussion, then, is to explore the remote location where the phone lines issues involved in constructing a PC- must handle a high volume of voice based data entry application and calls. Also, a battery powered laptop integrating this application into an PC might be an attractive solution when overall data management strategy built collecting data in the field, say, for around SAS software. These issues are public health surveys, where there may addressed in two groups. First, the be no readily accessible electrical relevant decision-making criteria are outlets. The remaining situations, the examined: What determines when a ambiguous ones, are both the most common personal computer-based approach should be used as opposed to SAS/FSP? What and the most diffic",Sugi-11-114 Heinemeyer.txt
"tegrated PC appl ication and provides a simple This presentation describes a corporate model for similar applications. It assumes the user has little or no experience with the file management system which was converted from personal computer, DOS, dBASE III, or SAS. The a manual filing system to a dBASE III menu- application was written to be easily maintained driven record entry system and a SAS PC DOS and to use the power of dBASE III file statistical reporting system. The existing system was projected to grow rapidly and the management combined with the flexibility of SAS requirements were to automate the system PC statistical reporting and formatted printing. Figure 1 shows the system flow diagram for the allowing for rapid searches through more than 10,000 records as well as provide for dBASE III to SAS PC reporting system. statistical reports and graphs for system i nforma ti on. The presenta t i on inc I udes dBASE dBASE III tasks include: III to SAS PC DOS conversion descriptions and add data, examples of SAS analysis and reports. edit data, browse/delete data, Advantages of this system include: and sort/backup data. 1.) Allows a PC standalone system for SAS PC tasks include: having the best of both worlds - converting the dBASE II I file to SAS relational database software and datasets, using SAS DATA steps to select and format data, using SAS statistical reporting software. PROCEDURES to produce reports. 2. ) Menu dr i ven so the user need not be familiar with SAS P",Sugi-11-115 Landon.txt
"A SAS* MACRO WHICH COMPUTES UPPER CONFIDENCE LIMITS OF THE NUMBER OF DEFECTIVE UNITS IN A LOT M. Taylor Alexander - Westinghouse Electric Corporation ABsraACT - Where knowledge (or data) about the variation of the process which produced the lot is unknown or cannot be assumed; TbiB macro eomputes one-sided upper or, confidence limits for the number of defective unit. in a finite population (lot) usin! the - When supplier lot quality history is byper&eometric probability distribution. A suspicious. method is described Which allows the results of tbe macro to be compared with similar If lot quality is imporeant, the results found in published tables. The macro hypergeometric serves as a more appropriate i8 useful to industrial quality control model to use in computing confidence limits personnel in estimating the maximum nu~ber of on the number of defectives in finite-sized defective units in finite-sized' lots from lots, as poor quality lots could sampling inspection results Where prior significantly delay consumer assembly i,nformation about the process producing the operations which use the lot components. lots is unknown. Although tables for binomial confidence IIIITRODUCTIOIi limits are prevalent throughout the literature, tables for hypergeometric Industrial quality control practitioners confidence limits are rare. This lack is often estimate the number of defective items largely due to the effort involved in in a lot from the number of defectives found computing hypergeometric probabilities. in a sample of the lot. Typically, such estimates are assumed to follow the binomial Chung and DeLury (1950) presented charts for distribution provided that: hypergeometric confidence limits for lot sizes of 500i 2,500; and 10,000. Odeh and - the lot size was """"infinitely"" large, or Owen (1983) presented tables for one and two-sided confidence limits on the number of - the product comes from a process in defective units for selected lot sizes of 400 continuous production W",Sugi-11-116 Alexander.txt
"uter program A the means of the groups, the number of executed in SA5 under the PROC MATRIX observations per group, and the procedure was written to handle variance-covariance matrix of the means: univariate between groups analysis o£ 1. For data sets in which there are variance situations in which one might large numbers of observations and want to input group means and their several models one wishes to fit, it variance-covariance matrix rather than could be more computationally efficient input the raw data. Estimates of to input the means of the groups, the primary and secondary parameters and number of observations per group, and tests of hypotheses such as main effects the variance-covariance matrix of the and interactions may be obtained by means, than to input the raw data to an either ordinary least squares or ANOVA program. weighted least squares. 2. In studies which involve national probability sampling, the variance-covariance matrix of means must INTRODUCTION often be estimated by special purpose Analysis of variance (ANaYA) programs because of the complex sampling schemes often employed. The estimate computer programs generally require that of error variance obtained from existing the user input data for each ANOVA programs assumes simple random experimental unit. The general linear sampling and thus is not appropiate for univariate model, represented by the studies which have complex sampling model equation schemes. An ANOVA program which would E<V = Xl>. allow",Sugi-11-117 Bryson.txt
"th Carolina at by Chapel Hill Abstract most powerful tests hypotheses of ilLS Rl't is _a -PEOC MATRIX m.acro that concerning the within-subjects factor performs variol1s types of analyses of while were delineated by G.rizzle and repeated m.easures data that cannot be Allen (1969). 'rhe OLS models are easily done with PRoe GLff, even wit. the preferred when the spericity assumption These methods for REPEATED statement. is met or when p is small or n is very analyzing repeated measures data often (p-l)~th orde~ large so that fitting the will be more powerful than the tests polynomial growth curve {PGC} model does not result in multivariate tests lacking parLormed by PBOC GLK the model ~hen assumptions are met. The four types of in power. If none of these conditions analyses condl1cted by WL5_BM involve is met. then tae iLS or conditional OLS fitting a truncated polynomial growth models generally provide more powerful curve (PGC) model through ordinary leas~ IIllltivariat'e tests while aakd.nq lIore squares (OL5) estilD.ation~ weighted least stringent assumptions of the data than squares and models. Multivariate estimation, do the OL5 (WLst conditional OLS estimation.. The order involving u~weighted analyses least of the PGC fit to the data is either squares estimates can be performed easily in Version 5 using paoc GLM with specified by the user or, ~nder condl tional OL5 estimation, the REPEATED statement if a rank p is determined through series of top-down deSign matrix for th",Sugi-11-118 Burchinal.txt
"is to be related to heat CFigure IJ. Th. Stone's additive spline aodels for wavelike nature of the polynoaials is inconsis- regression functions are described. Me discuss tent with the dati. Coapare these with the fit their iapleaentation within our Itateaent aaero of Stone's Idditive spline with 5 knots which %""ACRO L6TRE6 for logistic regression aodeling requires only the estialtion of is aany and provide an illustrative application of their use. par.aeters as the quartic poJyno.iil. I.",Sugi-11-119 Devlin Weeks.txt
"Managing VM/SP: An Analysis of the CP NUcleus Using SAS Software Stuart D. Guthrie: wesson, Taylor, Wells & Associates ABSTRACT: Although SAS has long been popular with 2. A listing of the above information by end-users and application development version, so that all base modules are staffs, in the past few years more together, all HPO versioned modules are people in the technical support area have together, etc. discovered that its ability to read and 3. A listing of the above information by analyze any type of data make i t date so that all recently assembled particularly useful for many technical modules are together (and all those modules that haven't been reasserob~ed applications. Instead of installing i t and forgetting it, we are using i t for in years are quickly identified). performance analysis and monitoring, for 4. A listing of all APARs, with the APAR accounting, and for data conversion. description, the affected module, the Here is one technical application we the module's assenilily date, and the have found very helpful in managing a VM module's entry location. 5. A listing of all modules which have installation. been reassembled since the last nucleus PURPOSE: build. 6. A listing of modules which have The implementation of High Performance changed version since the last nucleus. Option for VM/SP and the addition of 7. A listing of any APARs which are support for new hardware configurations missing from or added to the new has made the job of managing VM even nucleus. more complicated. In addition to the base version of VM we can now have NOTES ON RUNNING THE PROGRAM: several layers of additional code to keep track of. If a change is sent by This SAS program runs under SAS 82.3 or IBM to a particular module we now need Version 5 with no changes required. to insure that i t is applied to the The program issues a eMS filedef for 'CPNUC MAP *' which is the map of the And the correct version of the module. CP nucleus map provided by IBM's mapping nucle",Sugi-11-12 Guthrie.txt
"SOLUTION Often it is necessary to create tables of a The solution was to combine PROC PRINTTO and the DATA _NULL_ step to first create a SAS more tailored design than can be achieved through conventional SAS report writing proc- dataset containing the GLM output, and then edures such as PROC PRINT and PROC TABULATE. create a tailored report. PROC PRINTTO directs Further, when statistical tables are desired, output to an external file defined in the the problem arises that many statistical proc- program JCL. Data are then read in. and a SAS edures do not output SAS datasets. Combi ni ng dataset is created. Once data are in a SAS PROC PRINTTO and the DATA_NULL_ step allows dataset. a statistical table can be created creation of SAS statistical datasets and sub- using report writing features in the DATA_NULL_ step. sequent production of a tailored statistical report. The example below will show how combining PROC An example is given of the use of PROC PRINTTO PRINTTO and the DATA _NULL_ step automated pro- duction of a statistical table from PROC GLM to obtain pairwise comparisons p-values from PROC GLM output. Once a SAS dataset is output. created, a statistical table is produced using EXAMPLE report writing features in the DATA _NUll_ step. In a clinical trial conducted to test the saf-",Sugi-11-120 Emmrich.txt
"through 1984. The output from the PROC PRINT statement is shown in Figure 2. Further examples The Compustat IIR annual bank data file of the results of the options are presented in distributed by Standard and Poor's Compustat the SAS/ETS manual. Inc. is accessed using SAS software Services~ based on the macro SPYR described in SAS/ErS. MACRO BANKSTAT The user has the option to select the companies, beginning and ending years, and the data .items to BANKSTAT selects the variables that are be included in the SAS data set. needed for the balance sheet-assets statement; these data items are defined in the Compustat manual. PROC TRANSPOSE is used to transpose the A second macro is outlined to serve as a model to transpose and present appropriate data data set, and all data items are labelled so that items in a balance sheet or income statement for- the information is presented in a familiar for- mat. Figure 3-5 outline the controlling state- mat. ments in th'i s macro and the resu 1t i ng balance",Sugi-11-121 Hirsch.txt
"west Missouri State University George D. Williams, Lou18i8>na State University ABSTRACT Figure 1. A Switchback Design for Four Treatments PROCEDURE SWITCH is a user written SAS algorithm which calculates the analysis of variance, Block 2 Block treatment means, standard deviation, R-square, and coefficient of variation for switchback Time Time Individual Individual experimental designs with three or more Period Period 123~ 123~ treatments. The switchback experimental design ABC D ABC D 1 1 is useful for controlling period effects due to BCD A C DAB 2 2 changes in environmental conditions and ABC D ABC D 3 3 variation between subjects' response levels. The switchback design is described by H. L. Lucas (2). PROe SWITCH includes options to Block 3 specify a blocking factor and a data set name. Parameters which must be specified are period, Time Individual treatment, and subject variable names. A Period ~ 123 variable statement must be present which ABC D 1 specifies the response variable. Error DAB C 2 diagnostics include missing value indicators for ABC D 3 subject, period, treatment, response, and block, a comparison of the treatments assigned to periods to insure that the design has been The task of developing generalized switchback correctly specified, a check that at least 3 software is not an easy one. The computational treatments are specified~ and a check that the formulas (see Lucas article) are complex 'due· to number of subjects is a correct multiple of the the fact th",Sugi-11-122 Keith Williams.txt
"Methods Analyzing and manipulating large volumes of A data base which was randomly created by the data can often result in the use of extensive authors analyses consisted of product purchasing programming as well as CPU time. It is information for three types of products made by therefore beneficial to not only be familiar a number of department stores located in the with the various SAS PROCs but the extent to United States. For each store the product which the analyses they execute and the output purchased. its manufacturer, the number of units they generate overlap. Concentrating primarily purchased and the cost of the purchase were collected. The information was retrieved for on summary statistics, an investigation was undertaken to compare the efficiency in terms three' consecutive months from the stores financial of CPU time and the similarities with respect files. Analyses were conducted to investigate to output of using PROe SUMMARY as opposed to marketing trends and purchasing patterns. The multiple other SAS PROes. The results of our variables incorporated into the analyses inch~de: investigation demonstrate that by becoming familiar with the -TYPE- variable and the Variable Name Description values generated by SUMMARY numerous analyses can be completed efficiently with only one pass Store Store identification number. through the data eliminating a number of Prod Product catalog number. intermediate DATA steps and PROCs as well as reducing both programming and CPU time. Mfg Manufacturer of the product Group Product classification group",Sugi-11-123 Konowal Clark.txt
"BSTRACT whioh has four method s of produc ing printe r plots where the empha sis is PROC IDPLOT is a Versio n 5, base placed on adequ ately labeli ng the points . produ ct, line printe r plotti ng proced ure The method s are: RANK, based on the that allows points to be labele d with rank model first implem ented in Kuhze ld's long point labels . PROC IDPLOT has four (1984) RANKPLOT macro, MODRANK, based on plotti ng method s, three of which can the modif ied-ra nk model, GENRANK, based guaran tee that no point labels will be on the gener alized -rank model; and METRIC hidden . This is accom plishe d by using which produc es an ordina ry scatte rplot varyin g amoun ts oX nonme tric rank and (Kuhfe ld, 1986). The modif ied-ra nk and metric distan ce inform ation when gener alized -rank models are extens ions of compu ting rOw and column point locati ons. the origin al rank model that use both The RANK method locate s each point on a nonme tric rank, and metric distan ce separa te line of the plot so long point inform ation to locate points on the plot. labels will not be obscur ed. The MODRANK PROC IDPLOT can use the three rank models method also locate s each point on a to produc e plots where no ID's are hidden . separa te line, but the number of lines All four method s use a simple separa ting points is a functi on of the formu la to map the origin al data values differ ences betwee n adjace nt y to a row or column of a plot. These coord inates . The GENRANK method compu tes",Sugi-11-124 Kuhfeld.txt
"ONE DEGREE OF FREEDOM TEST FOR TRANSFORMABLE NONADDITIVITY - A GENERALIZED SAS MACRO Shiferaw G. Mariam and Daniel W. Griffin Research Laboratories Ortho Pharmaceutical Corporation Raritan , New Jersey 08869-0602 (intera ction) and a remainder sum of INTRODUCTION squares. Tukey proposed the following model for a two-fa ctor ANOVA when n=l.l ,2 The analysi s of two-fac tor studies with (3) Y.. =. . . + a i + Bj + Ra. Bj + ':j n=l depends on the assumption that the two 1 1 ,J factors do not interac t. A plot of'the where R is a regress ion coeffic ient. Note the residua ls versus the predicted values RaiBj is a more restric ted interac tion sometimes reveals a relatio nship suggesting effect when compared to (as)ij in model nonadd itivity between the study factors . A (2) · SAS macro for a general approach to the test devised by Tukey is given. It may be used Using model (3), a test for R=O is with any analysi s of variance from any design equiva lent to a test of the hypothesis that (two-fa ctor ANOVA, randomized block, latin the product term in (3) does not contrib ute to square) or from any regress ion analys is. If the predict ion of Yij' In order to test for the Tukey test indicat es the presence of 3 R~O, least squares procedures are usect. interac tion effects , the macro performs a estimator of R, assuming the The least squares series of simple transformations such as a other parameters are known, turns out to be: square root or logarithmic transformation to see if the interac tions can be removed or made unimportant. When a suitabl e transfo rmation of the response is selecte d R for data covering a wide range of values, a conside rable gain in precisi on is possib le. Y ), (Y i . - The usual estimat or of ni ;s METHODOLOGY Replacing the and that of Bj is (V ij - Y ). When there is one observation in each parameters in R by these cell of a factori al experiment, there can be estimators, we obtain: no within -cell variati on and hence no direct estimate of th",Sugi-11-125 Mariam Griffin.txt
"outcome Yi, X is the user-specified 1 x k vector of explanatory variable values and ~i is the ith The macros presented in this paper use output k x 1 vector of calculated coefficients from the from PROe MLOGITl to generate (currently only MLOGIT output. for the polytomous logit model): 1) all pair- wise combinations of the effects of explanatory variables on the relative probabilities of all Outline of the Macros outcomes, and 2) the predicted probabilities of each of the dependent variable outcomes, evalu- The PERMUTE macro (see Figure 4) reads the ated at the means of the explanatory variables, raw output from PROC MLOGIT line by line as or any user-specified values. character variables of length 133. (See Stone, 1985, for a detailed example of the method.) It scans through these lines, searching for com-",Sugi-11-126 Molyneaux Stone.txt
"PROC ElliPSE Charles E. Shipp and Charles G. Margolin Northrop Corp. (213/970-6300) There are three parts to the paper and the poster has a paragraph and graph for each of the three areas: (I) Theory Description, (2) Graphical Example, and (3) Milestone Chart to consolidate interest. The six pages are pOSitioned on a poster board and shown during the conference. There is also an opportunity to discuss the poster with attendees, give them handouts, and exchange addresses and phone numbers. The layout for the poster is as follows: PROC ELLIPSE . ~ Desoription h~t of the Staod.ard Deviation Ellipse-. ~ Example showing correlation Gnd dispcersion . MILESTONE CHIIRT Explain plans t.o xxxx ~velop.and test 4:.....A xx Proo ELL IPSE. '""--'> xxx .0.....-0 (I) Theory: Proc ELLIPSE Is an Implementation of the Standard Deviation Ellipse described at SUGI - 1982 in San Francisco. Coordinate values are projected onto the Least Squares Fit line and a line perpendicular, as shown. The ellipse Is then drawn through the four pOints on the lines which are two (or some value) standard deviations from the Center of Mass of the pOints. (2) Example: SAS/GRAPH Is used to overlay several ellipses to note their differences in dispersion, correlation, and position. Generally, the graphs are made by selecting one independent variable for the horizontal axis, one dependent variable for the vertical axiS, and using time periods or different : populations as the parameter differentiating the different ellipses: Subject Independent var. Dependent var. Parameter Weel</Config. CADAM response Number of Users Response TIme Pharmaceutical Treatment Strength Degree Reaction Type treatment Human Resource Seniority Salary Skill Types/Co. 011 Exploration Time Drilling Payoff Value Locations (3) Eutuu: The purpose Qf the poster paper is to setmllestone objectives and invite other interested persons to test the current Proc ELLIPSE, and work towards it being made available in the SAS package. If you are int",Sugi-11-127 Shipp Margolin.txt
"Using SAS/lMS-DL/I Software as a Development Tool in a Cobol-Based IMS-DC System Phil Brennan Board of Governors of the Federal Reserve System 1. ABS'llW:T 2.2 Using SAS/1M!-DL/I in Systa:n DeveI.opoent and Iilpl ........tati on The SAS/Il1S-DL/I 1/ product can serve as a valuable inplementation tool in the There are many tasks for .mich SAS/IHS-DL/I development of large Cobol-based Il1S-DC software can be efficientlv used in system systans. Significant tiIlE and cost savings development and iIrplementation. Prototyping, can be realized in lIl'lIly of the usual system program testing, data validation and mapping development tasks such as program testing, (=ving data from the old systems to the data mapping and verification, and report new), and report generation are scm? of which generation, when perfonned with the batch and are ma.de significantly easier and IWre interactive (PROC DLITEST) features of productive when performed with S,\S/IMS-DL/I. SAS/IMS-DL/I. This paper presents exanples This paper will eoncentrate on the latter of bow these products were utilized in the three tasks. The DLITEST procedure and development of the Administrative Info:rnation SAS/IMS-DL/I batch programs were used in Retrieval System (AIRS) at the Board of AIRS developroont to retrieve and verify the Governors of the Federal Reserve System. eontents of specific database segmmts as AIRS, completed in December, 1985, is a large part of the program testing and data mapover IMS DB/DC system, consisting of seven IMS phases. Before giving a detailed account of databases, which bas consolidated the the specific SAS/IMS-DL/I products that were autcrnated processing of the Personnel, used, a brief description of the IMS testing Payroll, and Position Control programs at the envirorments used at· the Boatd of Governors Board of Governors into a centralized system. will be provided. A generalized batch SAS/IMS-DL/I data verification program and a Clist used to invoke PROC DLITEST will be presente",Sugi-11-128 Brennan.txt
"SAS Software utilization by the Oklahoma Foundation for Peer Review Alan Dav is, Oklahoma Foundation for Peer Review Hospital claims contain diagnostic and The largest of these ,files contains ICD9-CM diagnoses, and requires procedure codes, along with patient 1,824,256 bytes of disk storage (1). demographics, identification, dates, and charge/payment information. Dates are These are 5-character codes. The read as SAS dates, for convenient commands for creating these files on calculation of length of stay, age of AOS/VS follow: patient, and analysis of data by month, quarter, or day of the week. Because of LIBNAME H ':UDD:ALAN'; reporting requirements, it is imyortant to produce readable reports for the PROC FORMAT DDNAME = H; VALUE $DIAGS physicians, providers, and others served by the Oklahoma Foundation for Peer '001 '=""CHOLERA "" '0010 '=""CHOLERA D/T VIB CHOLERAE"" Rev iew. '0011 '=""CHOLERA D/T VIB EL TOR "" Counts and percentages for the '0019 '=""CHOLERA NOS "" reports can be produced by TABULATE, '002 '=""TYPHOID/PARATYPHOID FEV "" FREQ, and the MEANS procedure, or by ··· etc ; producing the counts in a DATA step. \\ Nearly 20000 ICD-9 procedure and 1. DHHS Publication No. (PHS) 80-1260 diagnosis codes, 14000 physician names, US Department of Health and HUman and 200 hospital names are formatted in Service-Health Care FinanCing Admin- SAS Format files. These formats aid istration, ""The International Clas- tremendously in producing reports. sification of Diseases, 9th Revision, Clinical Modification"" (ICD-9-CM). 696",Sugi-11-129 Davis.txt
"A MACRO-DRIVEN FORECASTING SYSTEM FOR EVALUATING FORECAST MODEL PERFORMANCE Bryan Sellers, Ross Laboratories INTRODUCTION list for the input-output and time A major problem of forecasting, aside from specifications and the other for the forecast obtaining accurate forecasts, is choosing among equation. This speeds up model development and a wide range of forecasting models. This improves efficiency of computer resource usage problem places a major burden upon the from several standpoints. forecaster in two respects. First, the The user does not have to spend time forecaster spends a substantial amount of time writing and debugging programs. All models developing and maintaining a set of programs start with a common base and framework. The covering the potential forecast models. And user only has to be concerned with the second, the forecaster must somehow aggregate parameter list for each model. Multiple the results of numerous test runs in order to versions of programs with much duplicated confidently evaluate and choose among these source code do not have to be developed and models. maintained for each forecasting model. By I have developed a forecasting system which simply changing a couple parameters, the user aids the forecaster in both of these respects. has an entirely new forecasting model. This system consists of a set of programs which All output results are easily can be grouped into 3 categories: 1) an input standardized. By only changing the forecast module, 2) a processing module, and 3) an model parameters, output from every model will output module. Rather than developing and be in identical format. The user can maintain maintaining a set of programs for each model, separate input-output parameter lists and the user only has to maintain a parameter list combine them with separate forecast model for each one. In the input module these parameter lists to generate the same set of parameters are converted into SAS@ macros, output reports or files for ea",Sugi-11-13 Sellers.txt
"automatically executes the current SAS program. The current SAS program is a SAS program which was last written onto The paper presents the eMS tool of exe- the disk on the current day. ,The name of cuting SAS by pressing only one key. the file is SASEXEC EXEC and it requires the EXEC2 interpreter. The listing of the file is in the Appendix. Before we see the use of SASEXEC EXEC, let us set up three other EXEC files. SASLIST and They are called SASLOG, SASEDIT. The new files are created from",Sugi-11-130 Felsovalyi.txt
"PROGRAM The SAS sys tern has experi enced phenomena 1 growth It Macro CONTROL is invoked by the CLIST. in applica tion since its introdu ction. The power First it executi on of the program. contro ls and versat ility of SAS macro facilit y allows user display s the system entry screen via DISPLAYI, flexibl e as well as ther. calls INPVAL, which in turn display s the to develop and build user main menu and validat es user's input. user-fr iendly softwa res. (Figure 1) Thi s paper descri bes a SAS-based system used at the Revenue Require ments departm ent of Souther n Macro MAINMENU is called by INPVAL. It offers Califor nia Edison Company for rate analys is. The the user a series of options . (Figure 2) menu-driven to allow rate design system is analyst s to perform 'what if' type analyse s due Macro INPVAL validat es a selecte d option to changes in rate components, to perform supplie d by the .user. Once a valid option is customer impact studies in differe nt climati c entered , macro variabl e MCHOICE is created to on recommendations make pass to other data steps via ACTION. Macro to and regions, ACTION is conditi onally execute d based on the implem enting new baselin e rates. user's selecti on. (Figure 3) Further more the system is designe d for use and maintenance by non-programmer. Macro GUIDE invokes PROC FSBROWSE. It provide s user with instruc tions on how to use the system. program Upon termina tion of this procedu re, control will return to the driver macro CONTROL.",Sugi-11-131 Ho.txt
"GETTING MORE FROM PROC PRINT William R. MacHose. Pennsylvania Power & Light Company ABSTRAcr DATA MIXEIUJP; FORMAT D B C A 6.1; /* Order of Vars */ PROC PRINT is a very powerful and convenient LABEL B='B-VAR'; SAS® procedure. There are two features that the D=4; B=2; C=3; A=99; OUTPUT; procedure does not currently have that would 0=5; B=7; C=8; A=50; OUTPUT; often be very helpful. The first is to print the variables in alphabetic order. and the PROC PRINT LABEL; second is to be able to force the variable TIlLE ' VARIABLES MIXED UP' ; column labels to be horizontal. This poster will illustrate how to get both features. VARIABLES MIXED UP VARIABLES IN ALPHABETIC ORDER OBS D B-VAR C A PROC PRINT displays variables in the order 1 4.0 2.0 3.0 99.0 in which they occur in the file. This order is 2 5.0 7.0 8.0 50.0 dependent upon the order in which the variables were originally created. The VAR statement is available to print the variables in a different %APRINT(MIXED UP); order, but when there are a lot of variables TIlLE ·AiPHABETIC VARIABLES'; this is Qot a practical approach. The macro shown in Figure 1 will utilize PROC TRANSPOSE. PROC SORT. a DATA step. and ALPHABETIC VARIABLES PROC PRINT itself to generate an alphabetic list of the variables. The macro shown here is OBS A B-VAR C D named APRINT. 1 99.0 2.0 3.0 4.0 2 50.0 7.0 8.0 5.0 %MACRO APRINT (SASFlLEl ; PROC TRANSPOSE DATA=&SASFlLE<OBS=l l Our=NAMES(KEEP=_NAME_ COLl>; HORIZONTAL LABELS FROM PROC PRINT PROC SORT DATA=NAMES OUT=ORDERED ; PROC PRINT sometimes prints variable labels BY NAME; in a vertical format in order to squeeze more PROC TRANSPOSE DATA=ORDEREo variables onto a page of output. These vertical OUT=ORDERWRQP=_NAME_l ; labels are not only difficult to read. but often take up more report space than if the horizontal SET ORDER <OBS=O) &SASFlLE; format had been used. The trick to force horizontal labels LABEL; PROC PRINT requires that the variables do not already have labels. To force horizontal labels",Sugi-11-132 MacHose.txt
"Sample utility Macros Ross Z. Merlin, Pinkerton Computer Consultants Inc. This presentation is a collection of general-purpose MACROs: ANY,NOTANY -- shorthand for multi-value I'IF"" statements INDEXBLD -- build an index dataset and index functions (FORMATs) to facilitate direct access of a SAS dataset MAKEFHT -- make a SAS FORMAT from data in a SAS dataset OBS -- ascertain the number of observa-tions in a SAS dataset without counting SEARCH -- search a field for user specified values, display all obs that match TYPE -- determine the type (CHARACTER or NUMERIC) of a SAS variable USAGE -- access SAS Usage Notes VARNAHE -- display variable names and labels VALIDATE -- validate a response and generate a label for %GOTO WP -- reformat text for inclusion in SAS listings ANY and NOlANY are macros that allow for a shorter notation in multi-value ""IF I ' statements. In COBOL, one can code: IF (CHANNEL=2 OR 11 OR 13 OR 45) ... but in SAS one must code: IF (CHANNEL=2 OR CHANNEL=ll OR CHANNEL=13 OR CHANNEL=45) .. . Using %ANY, the SAS code would be: IF %ANY(CHANNEL,2 1113 45) ... Similarly, %NOTANY(CHANNEL,2 II 13 45) would expand to: (CHANNEL'=2 AND CHANNEL'=l1 AND CHANNEL""=13 AND CHANNEL'=45) . Two limitations apply: I} character values can not have imbedded blanksi 2) each character value in the VALLIST must be enclosed in quotes. %MACRO ANY(VAR,VALLIST); %MACRO NDTANY(VAR,VALLIST); %*PURPOSE: SHORTHAND TO GENERATE PART %'PURPOSE: SHORTHAND TO GENERATE PART OF SAS ""IF"" STATEMENT; OF SAS ""IF"" STATEMENT; %*USE: %ANY(X,I 2 3 9) GENERATES %'USE: %NOTANY(X,I 2 3 9) GENERATES (X=I OR X=2 OR X=3 OR X=9); (X""=I OR X'=2 OR X'=3 OR X""=9); %*LIMITATIONS: %-LIMITATIONS: VALUES CAN NOT HAVE IMBEDDED BLANKS. VALUES CAN NOT HAVE IMBEDDED BLANKS. CHARACTER VALUES MUST BE IN QUOTES.; CHARACTER VALUES MUST BE IN QUOTES.; %LET POS=I; %LET POS=I; %LET VAL=%SCAN(&VALLIST,I); %LET VAL=%SCAN(&VALLIST ,1); (&VAR=&VAL (&VAR=&VAL %LET POS=2; %LET POS=2; %LET VAL=%SCAN(&VALLIST,&POS); %LET VAL=%SCAN(&",Sugi-11-133 Merlin.txt
"n EXEC driven Background - The use of control charts to monitor text editing language such as INTH RACT or processes dates back before 1940. They are generally called Shewhart Control Charts after W.A. WYLBUR to generate SAS- programs. Shewhart {a statistician who developed methods to improve process control using basic statistical This technique has been used to ""write"" SAS techniques and a colleague of W.E. Deming; one of programs to provide a Statistical Quality Control System for the Quality Engineering Department at the well known names in statistical quality controD. Syntex Laboratories. The system has been in use for two years to provide reports, plots, and statistical The basic purpose of a control chart is to study a analyses of pharmaceutical data and has given us process for potential improvements the capability of the ability to periodically review our products and a process. As put by Grant and Leavenworth in check for trends in the data. their book ""Statis1-ical Quality Control,,;l ""Measured quality of manufactured product is always subject to a certain amount of variation as a The system is called the Quality Engineering Report and Plot Generator and was designed to allow result of chance. Some stable system of cha.nce personnel with no programming experience the causes is inherent in any particular scheme of ability to use SASe to generate summaries, plots, production and inspection. Variation within this and reports using data from our Quality Assurance stabl",Sugi-11-134 Potter.txt
"EFFICIENT USE OF TABLE LOOKUP PROCEDURES Craig Ray, ORI Inc. Howard Levine, ORI, Inc. Because every file is different. this paper shows a simple example of exploiting the composition of your files to achieve maximum Table lookup procedures (i .e.. cross efficiency in table lookup. An evaluation referencing a lookup file based on the value of should be done on a case by case basis. This a variable in the main file) are generally properly f11ustrates general techniques whose rather Simple and easily performed using SAS. efficiency is detennined by the size of the Both the MERGE statement and PROC FORMAT with files more than any other factor. Even without the PUT function are c01ll1lOnly utilized for this optimizing for file composition. our guidelines purpose. However. if the main file is lal""ge. can provide dramatic improvements in efficiency MERGE can be very inefficient since it requires over MERGE and PROC FORMAT when large files are sorting and a data step for each lookup and being used. finally another sort. Likewise. if the lookup file is very lal""ge. using PROC FORMAT becomes Some general guidelines to follow in order prohib1t1vely expensive. Two other table lookup to exploit the composition of files are given. techniques are discussed here. One uses MACRO Strive to IlIimillize the number of conversions. variables and is similar to PROC FORMAT in its string operations. assignment statements, and advantages and di sadvantages. The other is a reading of observations. For example. by not1ng binary search. Other techniques can be found in that a key is numeric and ranges between 100000 Reference 1. and 109990 with the last digit 0 at all times, a new key can be defined based on the third. fourth, and fifth digits of the old key. Sfnce the key is numeric, perhaps the new key can be Dfscussion used to directly access an observation on the lookup table using the POINT option on the SET statement. This gives a basic idea of how file The effects of file size on the va",Sugi-11-135 Ray Levine.txt
"n. Drug screening studies RATS (Rodent Activity and Thermogenesis require three control groups and at least three System) is a completely automated computer- test compound groups per study. The control controlled data collection system for drug groups consist of a vehicle control, a thermo- studies. Oxygen consumption, carbon dioxide production, and motor activity in rodents are genic control, and a motor activity control. recorded. Drug-related changes in motor activ- At the conclusion of each day (block), a ity which affect oxygen consumption are of data stream of approximately 30K unidentified primary importance and present a complex problem in statistical model building. numbers was transmitted by modem to an HP3000 through the HP9836C using HP Series 200 terminal Data from 10- or 20-day experiments were emulator software. When transmission had been transmitted by modem via an HP3QOO to an IBM completed, the data were sent to the IBM 3033 mainframe through Multileaving Remote Job Entry 3033 mainframe. Approximately 30K successive unidentified numbers daily were stored in a (MRJE), a subsystem of the HP3000 which provides fixed-pattern data file; identification of these for the submission of multiple batch job streams numbers required modulo arithmetic. The data to remotely-located host computers. Each set were formatted into observations on a time basis of numbers generated by RATS was stored in a conditioning them for SAS procedures. repetitive pattern, creating a sequen",Sugi-11-136 Singer Bobik.txt
"SPF menu-driven dialog provides the The objectives of the estimation system are: foreground for SAS® programs that generate demand Make the reports easy to generate. Give deposit ownership estimates from survey data~ The input screens are fully documented with tu- the data technician a series of data entry screens torials and easy for the end-user to eXecute. for inputing parameters and include tutorial screens. The programs retrieve micro data, trace an IMS data base for mergers and acquisitions, Put a secondary level of data quality resolve structure changes, produce data analysis checking on the initial editing procedures by diagnostics, generate strata summaries with esti- printing survey data on all respondents, indica- mates and standard errors, and table the results. ting When the survey total is much different from the covariate~ Also, show the percentage of an DDOS Survey item a bank holds to the total of the size stratum to which it belongs. The Demand Deposit Ownership Survey (DDOS) provides estima.tes of the components of demand Print estimation report by deposit item deposits held by individuals, partnerships and and size stratum showing population and sample corporations at commercial banks~ Five de pos- counts, ratio estimation components and standard i tor ccmponents are identified in the Survey: errors ~ financial business, nonfinancial business, con- Data-Flows sumer, foreign, and all other. Based on data reported by a sample of banks, Board staff con- struc",Sugi-11-137 Slowinski Marrie.txt
"h, Marion Laboratories, Inc. Option 3 produces a printed copy of the' ABSTRACT normal range file. Option 4 provides two major functions: Marion Laboratories, Inc. has developed a system to provide consistency and increase efficiency in the reporting of laboratory 1. verification of the data against the data from clinical trials. This system has normal ranges flagging outliers within a the capability of tailoring programs to fit given range different trial data structures and different reporting requirements. The user may select a choice of final reports 2. from five report options with some options producing mUltiple layouts. If the data verification option is chosen data will be compared against the normal ' The programs used by this system make ranges. Any data falling outside of the effective use of the SAS® macro language for error percentage chosen will be reported. both variable name substitution and selection of blocks of code for execution. This The five report options provided are: increases the efficiency of the system and minimizes the number of changes necessary before execution. The system is menu-driven 1. By patient listings: with all macro variab.les and program options assigned from data provided through user a. of all laboratory recordings prompts. b. of all laboratory recordings which were normal at prestudy with subsequent abnormal recordings INPUTS 2. By parameter: A CMS EXEC executes the driver which brings a. listings of all laboratory recordings up the",Sugi-11-138 Baxter Smith Smith.txt
"UPLOADING LARGE DATA FILES FROM MICROS TO MAINFRAMES William M. Taylor DataSoft ABSTRACT: File Definition: The files to be moved conSisted of four large MicrocoMputer technology provides excellent data sets of 30,000 records each, totaling capability for bUilding. Modifying, and approximately 120,000 records. The logical Maintaining large data files; but it is liaited record length was 255 bytes in the longest in Meeting sophisticated statistical analysis files when the record was fully expanded with and reporting requireaente in a responsive and flexible tiaefraae. For this reason, it becaae blanks in the fields. The data stored in the necessary to Move several large aicro-based .icrocomputer was in the dBase II file foraat. data files to a aainfraae environ.ent. Two approaches were used. The first involved transaitting the records via 1200 baud co.munications lines fro. an IBM PC with a Avatlable Hardware/Software Tal1gras6 35 aeg hard disk to an IBM Mainfraae to Support the using PC TALK III or Crosstalk, dBASE II, WYLBUR and SAS the software. This approach 8S The following hardware was available to support had ~any liMitations. A second approach the data move: directly coupled the IBM PC with Tallgrass disk to an HP 3000 through the serial port. Using IBM PC with a Tallgrass hard disk, CROSSTALK. the data was transaitted at 4800 baud to the HP hard disk and then converted to 35 meg disk drive. 45 .eg tape backup; a 9-track 1600 bpi tape for transfer to the IBM IBM 4341 mainframe; This approach resulted in the ~ainfra.e. efficient and accurate transfer of the data. 1200 Baud dial-up coa.unications lines; The transferred coaaa-delimited file was not readable using the SAS SCAN function because if HP 3000 mainframe. two or ~ore delimiters appear together, they are treated as one. Therefore a SAS routine The following software was used to support the was written to expand the comma-delimited tape lRove: data sets into flat files. PC TALK III CROSSTALK Reasons for M",Sugi-11-139 Taylor.txt
"COMPARING PARA1'1ETER ESTI:1ATES BETWEEN LINEAR NODELS John E. Teberg, Washinton State University Introduction y ... Q KQ A hypothesis statisticians want to 1 1 Y QK .' .Q test is whether or not a set of models .. K Y are the 'same.' An example would be where a researcher measures the yield of y ., ,~ QQ plants versus soil moisture. He does m this for two years. Our researcher may MP N1 N x x want to know if the relationship between f!. J:; soil moisture and yield are identical 1 1 for both years. f!. , J:; f!. J:; Let's say that a person ran an experi~ ment with six treatments. The response variable was measured over time, One N1 MP 1 may want to know if the six treatments x x have the same trend over time. Here, Enter: the computer the person wants to test the parameters of the six regressions for the same Before returning to our test of hy~ value. potheses, another order of business needs to be discussed: setting up the There are many different hypotheses problem for theRcomputer. We can use that can be tested. In the simple PROC REG in SAS to do the computational linear case, tests can be made for work, though we still must decide our identical slopes, the same intercept, hypotheses. PROC REG makes specifying intersecting at a given point or identi- the hypotheses clearer than PRoe GLM. cal models. One can test for like hy~ per~subplanes in the multiple regression But first the data must be structured models, like the ~ matrix. I'm assuming the dataset looks like the following: Notation Variables - -> <~~p-l Let's say we have M mUltiple regres- Model VARl VARPMl Y sion models with P parameters including 1 Y X the intercept term. Each model has n 11 11 observations. For the simple linear m 1 Y X case, P=2 which gives the follOWing set "" "" obs n of matrices, 1 Y X 1 1 n n y 1X E ,m ,m 1 ,m .. 2 Y X y 1X E ,m "" "" ,m ,m y X- E '"" '"" m Y X y 1X E ,m ,m nm nm nm m m m Y m X ,m ,m obs n a m m II fl. ~m m Y m X nm nm m m where N = Zn > P for all m n m One needs to crea",Sugi-11-141 Teberg.txt
"CHOOSING DUMMY VARIABLES FOR A GENERAL LINEAR - INTELLIGENTLY ~10DEL Stephan Arndt, University of Notre Dame The purpose of the present paper is to provide 2 then R1 1; Else R1 D; If Race a variety of means to include continuW5, interval, If Race 3 then R2 1; El se R2 0; If Race 4 then R3 1; Else R3 ordinal and categorical information in a general 0; linear model. Typically, zero-one dummy coding has been used for nominal data such as ethnicity, Notice that Whites are never mentioned and wi 11 get zero on all three variables. Then the D but a number of alternatives are available. While all of these will yield the same sum of matrix would look like: squares when the variables are tested collective- RACE R1 R2 R3 ly, sums of squares and -interpretation for indi- viduals will differ from method to method. It White 0 0 0 is important to choose the best set of contrasts a pri-ori in order to make the individual sums of Black D 0 squares meaningful. In addition to dummy vari- Asian D 0 1 ables, it will discuss effects coding, contrast coding, Helmert contrasts, power and orthogonal Other 0 0 1 polynomials. These other types of coding are appropriate for a wide variety of data from I chose this particular pattern since the Type nominal to ordinal to contiruou_sand nonlinear. IV Sums Squares and the B-weights in GLM reflect Proper testing techniques will also be discussed the deviations from the group which was given including a general warning against Type III and all zeros - ;n this case the Whites. The Type IV Sums of Squares. weights for the individual variables represent that races increment or decrement from being General Premises. white. To make this a little more clear, I will give the four different equations for each Consider the simple model: race omitting terms that were zeroed out and simplifing. y BD + intercept = If White; .here D might represent ethnicity. Suppose that intercept (all other terms y there are four catagories of race: 1 = White, are zero) 2 =",Sugi-11-142 Arndt.txt
"It has been recognized that centering + 7 (x-x) + 7 (X_X)2 + ... + ~ y- o reduces the condition number of the in- 1 2 cidence matrix in ordinary linear re- fJ (x-x)p + E P gression models. In polynomial models, centering can occur first (X_X)2 or last The random error, E, is assumed to be (x 2 _X 2 ). This paper determines condi- independent and identically distributed tion numbers using simulated incidence with variance q2. The symbols for the matrices and the COLLIN option in SAS constant terms and the regression coef- PROC REG. The results empirically veri- ficients are chosen to reflect the fact fy that centering first dramatically that ~ is the same for all three reduces the condition number whereas P centering last provides only a small models and that the constant terms are improvement over no centering at all. are not the same for all three models The empirical evidence supports the A - A with a - y but 7 y. The ~ theoretical discussion in Bradley and o Srivastava (1979), Marquardt (1980) and centered-first model has been advocated Snee (1983). by Bradley and Srivastava (1979), as well as Marquardt and Snee (1975).",Sugi-11-143 Bendel.txt
"PROC RSMCB: A PROCEDURE FOR RANKING, SELECTION, AND MULTIPLE COMPARISONS wmI THE BEST James C. Aubuchon, The Ohio State University Shanti S. Gupta, Purdue University Jason C. Hsu, The Ohio State University 2. Choice of Multiple Comparisons Procedure 1. Multiple Comparisons Procedures Historically, Multiple Comparisons (MC) has been There are three major types of multiple comparisons: taken as synonymous with All-Pairwise Multiple Comparisons (MCA). For example, the MEANS option in MCA: All-Pairwise Multiple Comparisons PROC GlM of the SAS® System contains Scheffe, Tukey, GTZ, REGWF, REGWQ, Siddk, Bonferroni, MCB: Multiple Comparisons with the Best Newman-Keuls, Duncan, Protected and Unprotected LSD, all of which are implemented as MCA procedures (SAS MCC: Multiple Comparisons with a Control User's Guide: Statistics, Version 5 edition, pp.169-175). Suppose k treatments are to be compared in terms of Among these MCA procedures, it is well known that their treatment means (long run average treatment effects), Newman-Keuls, Duncan, and LSD are statistically invalid. which are denoted by 8 I' 8 2 , ... , 8 k . In this article, we The true error rate for Newman-Keuls (i.e. its probability confine our discussion to oneway (possibly unbalanced) of making at least one incorrect assertion), can be as high designs only. as 1-(I-cq[k/21. Thus, for 10 treatments say, Newman-Keuls with a nominal error rate of 5% can have a All-Pairwise Multiple Comparisons compares all pairs true error rate as high as 1-(.95)5 ~ 23%. The error rates of treatments. For MCA,the parameters of interest are 8 i - for Duncan and LSD can be even higher. 8 j for all i * j, the k(k-l)/2 pairwise differences of Among the other MCA methods, Tukey's method is treatment means. generally the most efficient. (Dunnett 1980) Until recently, there lacked a proof of the statistical validity of Tukey's Multiple Comparisons with the Best compares each method for unbalanced oneway designs. However, such a treatment w",Sugi-11-144 Aubuchon Gupta Hsu.txt
"In this paper we do not address the issues concerning the appropriateness of the use of Two SAS@ programs are presented for per- multiple comparisons. For this topic the forming the Tukey-Kramer and Dunnett multiple readers are referred to the papers by Chew comparison procedures on the LSMEANS obtained (1983) and O'Brien (1983) among others. from PROC GLM. These programs compute test statistics which can then be compared to tabled TUKEY - KRAMER PROCEDURE values of critical points for hypothesis test- ing. A program for extracting the necessary Let (Pl, ... ,Pr)' a vector of LSMEANS ob- variables from the GLM output and creating a tained from PROC GLM, have a multivariate normal SAS data set as input for these procedures is distribution with mean (~I""""'~r) and variance- also presented. These procedures can be used corvariance matrix a 2v, where V=(v .. ) is a known for multiple comparisons of the levels of a 1J given factor in a mUlti-way (fixed-effects) . matrix of order rXr. The t-statistic for testing model with analysis of variance or covariance. the significance of ~.-~.(i<j) is Examples are given. J 1",Sugi-11-145 Koester Patel Mellars.txt
"ries current, and time. In the analysis phase of the experiment, regression analysis will be used to estimate the effects of varying each variable OVERVIEW from its low to its high level. The -'s and +'s will become -l's and The design and analysis of fractional factorial experiments will +l's for the experimental variable settings, recorded in columns, and be described. Use of SAS software for the design and analysis of these columns will then be used as independent variables for regression fractional factorial experiments will be discussed and illustrated with modeling of the dependent variable yield. examples from the author's experience. A full factorial design for this experiment requires 24 or 16 runs in order to obtain every possible combination. The resulting design INTRODUCTION matrix is given in Table II. Note that the pattern 01 the plus and minu8 JJigns ron be easily generat«l in an orderlll manner. The first Scientific studies often investigate the effect of changing the variable column has alternating plus and minus signs, the second settings of one or more variables on some measured quantity of variable column has alternating pairs of plus and minus signs, and interest. Experimental design deals with the selection of settings of the input variables at which the output or response variable is so on. measured. A class of designs called the 2 k - p fractional factorials is Ta.ble II very cost effective, especially at the initial variable screening process. DESIGN",Sugi-11-146 Wendelberger.txt
"REPEATED APPLICATION OF A GENERALIZED LOGISTIC MODEL TO COUNT DATA USING PROC MATRIX Linda Williams Pickle National Cancer Institute available to convert MATRIX code to the new system (7). When cancer mortality data became available for the 19705, we began Statistical methods planning an update to the Atlq~--2i for _..1LA:.... Counties. ,Q.rul~""_,Mortali ty The logistic form of the binomial 1950~~ (1), first published 10 years distribution is used to model the ago. The new Atlas (2) is a compendium effects of explanatory variables on a of U.S. maps showing the geographic variable Y (8). dichotomous outcome patterns of cancer mortality rates for That is. each of the last three decades since 1950. These additional data also P(Y=liX) = exp(X'B)/(1+exp(X'B)) provided sufficient numbers of deaths to where X is the vector of explanatory analyze and map the geographic patterns of changes in the mortality rates over variables (X"" X"" Xl< ) , and B is time. The sheer volume of data to be the corresponding vector of parameters. processed for these maps, about 2 We will refer generically to the outcome million records representing population of the trial as ""success"" (Y=l) or counts and 9 million cancer deaths, ""failure"" (Y=O). Note that the necessitated careful planning of storage frequencies of successes and failures, and processing methods to minimize cost stratified by the explanatory variables, and CPU time. are sufficient statistics. The entire has been done project For our Atlas example~ the outcome using the SAS* system (1982 version). of interest (Y=l) is death due to a The cancer mortality data base was of a particular primary malignancy stored as a SAS data set along with an anatomic site; explanatory variables are pointer index, or file, to allow age group and time period (5 year cost-efficient direct access of the data intervals) at the time of death. (3)4). SAS macros were written to Although the Poisson model would be more select the population and mortality app",Sugi-11-148 Pickle.txt
"PROC TABULATE as a TOol for Categorical Analysis Tamara R. Fischell, UNC Highway Safety Research 'Center Juliana M. Ha, UNC Highway Safety Research Center Equal Sign: Introduction An equal sign is used to assign either a label or a format. Formats are PROC TABULATE is a very useful tool specified by adding ""F=.ll Thus, the for categorical analysis. This paper presents three examples--beginning with code a simple table and progressively adding TABLES AGE, BELTUSE='RESTRAINT STATUS', subtotals, totals, and finally INJURY * N * F=7.0: percentages--which show how to generate and display statistics typically labels BELTUSE as ""RESTRAINT S'rATUS"" in considered in categorical analysis. The the column dimension, and formats N as a examples are from a highway safety study seven-digit integer using the typical of injuries in car crashes where injury w.d format notation. (Note: It is best outcomes of young children are consi- to enclose any label within single dered. Injury outcomes are analyzed quotes. ) controlling for several other categorical variables (severity of the Pointed Brackets < >: crasil, age of child, restraint usage and Any variable or group of variables seating position). within pointed brackets designates a denominator. A denominator may be Descriptions are presented assuming defined for counts taken from an entire a beginner/intermediate-level knowledge group «INJURY» or from a subgroup Only a limited knowledge of SAS basics. «INJURY * BELTUSE». of PROe TABULATE is assumed. A summary of symbols and keywords essential to N: understanding PROC TABULATE is also N is a special variable. It is a included. count of the number of observations for each combination of the values of the TABLES Statement categorical variables. It is equivalent to _FREQ_ in PROC SUMMARY. The Comma: There are three dimensions a table PCTN: can take on: page, row and column. The PCTN is, as its name implies, a location of commas determines which variables define each dimension. At percen",Sugi-11-149 Fischell Ma.txt
"SIMULATIONS TO COMPARE VOTING RULES: AN APPLICATION OF SAS MACROS AND A FAST NUMERICAL APPROXIMATOR Roger S. Cohen, University of Mississippi 1. INTRODUCTION II. THE PROBLEM In a democracy group, decisions reflect the Political scientists and economists have long wishes of individuals within the group. Citizens debated the relative merits of earmarking and vote their wishes in elections, and the winning general fund financing as fiscal institutions for outcome of the election becomes the community government. Under a system of earmarking, choice. If a simplifying assumption is made about individual items of the public budget are segregated candidates, _namely, that they seek to maximize and funded independently through specific taxes. their chances of being elected, then .. model can be General fund financing is a system of allocation constructed for community choice based upon the whereby items of public expenditure are combined desires of a particular individual, the the median and paid for out of a general fund whooe source is tlDter. Consider the following example: a general tax. One issue in the debate is the question of which system leads to tile largest level Two candid..tes compete for the same of public expsnditure. Techniques which are in an election where the commonly applied to solve related theoretical office candidate receiving the moot votes problems have failed in this case partly as a result of the complexity of the problem and partly wins. There is only one issue which divides the candidates, namely how because of limitations in the approaches themselves. much money is to be spent for police The present work applies simulation as a protection. Voters realize that the methodology for addressing tlke problem, and this larger the poIice foree, the more they approach proves successfol at answering the will have to pay in taxes. Because question of whether earmarking or general fund voterBhave different preferences for financing can be expected to prod",Sugi-11-15 Cohen.txt
"USING SAS SOFTWARE TO GENERATE LEAVE-ONE-OUT HIT RATE ESTIMATES FOR GROUP CLASSIFICATION Joseph M. Wisenbaker, University of Georgia Cathy A. Stawarski, University of Georgia Introduction observation, the vectors of estimated group In conducting statistical analyses it centroids, the estimated population is a rare situation in which a client isn ""t covariance matrix, and the proportions of the population contained in each of the interested in some form of prediction whether it be of tomorrow"" s weather or the groups. Huberty (1975) states that the optimal classification, assuming equal costs effect of some new instructional program in for misclassifications, results from education. Mcst clients are also interested in the confidence they should place ill that assigning an observation to the group for which the following expression is maximized: prediction. What differentiates the applied statistician from the soothsayer under these Lik ~ -1/2 In ISI + circumstances is the statistician""5 formal In Pk' -(l/2) 02ik and replicable approach to incorporating In this expression S is the estimated information in making that prediction and providing assessments of predictive population covariance matrix, Pk is the accuracy. prfPortion of the population in group k, and D is the Mahalanobis squared distance of A wide range of prediction techniques the ith unknown observation from the are available depending upon the nature of estimated centroid of the kth group: the variable whose values are being 0 2 ik ~ [(""i - Kk )' Kk ) ]. predicted and the variables used as S-l (""i - predictors. What seems the most commonly SAS Institute' s PRO C OIS C RIM prov:irles a applied predictive tool, at least in educational research, is multiple regression ready means of obtaining estimates of the necessary components and, through PRO C analysis (Pedhaz ur, 19 8 2). Mul tiple regression allows for the use of a sample SCORE, the transformed posterior probability having known values for multiple pr",Sugi-11-150 Wisenbaker Stawarski.txt
"ANALYZING SURVEY DATA IN THE ELECTRIC UTILITY INDUSTRY USING SEVERAL SAS' PROCEDURES Mary Lynn Spada, Boston Edison Company Several SAS procedures allow the user to member of the permanent SAS dataset, thoroughly analyze survey data. Typically, Ressurv.Sasset. survey information includes interval-scaled data, as well as nominal data. Among the Data Survey; procedures one can use are PROCS FREQ, Set Ressurv.Sasset; UNIVARIATE, REG, FACTOR, GLM, CORR and If Class = 1 then W= 2.2276; STEPWISE. These analyses allow the user to Else if Class 2 then W= 0.1414; obtain descriptive results, perform data Else if Class 3 then W 0.1545; Else if Class = 4 then W= 0.1080; reduction techniques and study the relationships among several survey questions. PROC FREQ SAMPLING Proc Freq was used to iummarize the Boston Edison Company provides frequency of responses (; .e., produce electricity to over 500,000 residential tabulations) for the survey questions which were nominal or categorical in nature. This households in the greater Boston area. The Company surveyed a sample of these customers tabulation simply counts the number of in order to better plan for their responses in data categorles for a electricity needs in the years ahead. particular survey question~ In addition to Almost 2700 residential customers completed the tabulation counts, SAS output also and returned the questionnaire, yielding a reports the percent of observations in that category of the total number of observations 32% response rate. Respondents answered questions about what appliances they own, for each category value. Another name for this tabulation output from Proc Freq is the what actions they have taken to conserve energy, and general household and frequency distribution. The Freq procedure demographic characteristics directly related yielded frequency distributions of to energy use. particular household appliances, energy conservation behavior and demographic The customers sampled were selected from chara",Sugi-11-151 Spada.txt
"ASSESSING RELATIONSHIPS AMONG MULTIVARIATE DATA POINTS BY TRANSFORMING THEM INTO 2-D CURVES Calvin D. Croy, National Demographics & Lifestyles Introduction Many different techniques have been devised of -1T<t<7T. This methodology transforms each to graphically depict relationships among data. multivariate datum into a curve. By using For univariate data, individual points can be Proc Plot or Froc Gplot to to plot the curves, plotted on a unidimensional scale. To compare one can detect either clustering or the entire univariate datasets, boxplots (1,2) may presence of outlJers in the original space. be used. To display bivariate data the standard x-y Cartesian plot still stands the Examples and Discussion perennial favorite. Trivariate data are most frequently plotted using x-y-z coordinates, To illustrate his methodology, Andrews and compu~er-driven graphics packages such as plotted data taken from Ashton et. al, (7). SAS/GRAPH have opened new ways to present such Two of Andrews's plots are reproduced here as coordinates apart from the traditional lollipop Figures i and 2 because of the clarity with (ball and stick) representation. For higher dimensional data the task of which they show the advantages of his tech- nique. Figures 1 and 2 compare the permanent fully showing relationships has been, however, first lower premolar teeth of fossils with more difficult. Analysts have had to resort to those of different ""races"" of men and apes. more complicated solutions. Principal Figure 1 shows the teeth group means with components analysis, factor analysis, 90% confidence regions plotted on the first discriminant analysis, multidimensional two canonical variates. Figure 2 shows the scaling, ordination (8), and other multi- same data represented as curves created from variate statistical procedures have arisen at least in part from a need to condense informa- Andrews's function. One can observe two interesting tion to facilitate understanding and graphical phenomena withi",Sugi-11-152 Croy.txt
"A MACKO LIBIAl.T ma CLASSICAL AND IOBust MUL1IVAIIAYB MODELING E. James Harner and Kathryn S. Fletcher West Vitainia University Abstrael The macroleIt is organized sequentially according to a natural flow; I) macro program statements to check the validity of the parameter This paper describes a macro library Cor modelitl.g multivariate data. Cur- options specified by the user; rently, three statistical macros are available: REG, Cor regression model.i.ni; 2) PROC MATRIX FW-=&FWIDTH FUll; PCA, Cor principal components analysis; DISC, Cor disa""iminant modeling. Bach of these allows a number of options, .including robust analyses and 3) FErCH statementls) to read the input SAS datasets; 4) PROC MATRIX statements to check. (and detete) observations with validation tecbniques. missinR values; The macros are Reared toward interacLive modellDa. The commands Cot in- '5) macro program (contrOl) statements to select the aflpropriate voking the macros are easy to use and are brief. The output displayed at the ""subroutines""; terminal is carefully se.lected. Additional output -- depending on the 6) ""subroutines"". number or observations, e.g., residuals -- is output to a SAS data set which PROC MATRIX is not amenable to structured programmin8. However. the can be printed by the PRINT utility macro. code W1lS modularized wheneVer possible. latroductioa The PRINT macro is a utility Cor lilting long output. The macro contains a DATA step to Cormat the observation numbers and a PROC step (PRINT) Cor The many facets of developing a multivariate model include; determining printin&. The orJ.a.inal variables as well as computed quantities, such as the functional Corm of the model, selecting and transforming relevant weights and squared Mahalanobis distances, are printed. variables, assessing distributional and other (e.g.,fu:l.earltyl assumptions, assessing the efCects of mUlticollinearity and influential observations, and The form of the 'lMACRO statement for PRINT is Riven by; validat",Sugi-11-153 Harner Fletcher.txt
"PROGRAMS FOR THE GMANOVA AND EXTENDED GMANOVA MODELS Ronald K. Elswick, Jr., A. H. Robins Company Vernon M. Chinchilli. Medical College of Virginia, VCU Two assumptions are made on the error matrix. First, each row Introduction of E is assumed to follow a p·variate normal distribution with the mean vector being the null vector and variance:E, where E is a p by p positive definite covariance matrix. Second, the rows of This paper presents two macros written in PROC MATRIX (SAS0 E are assumed to be independent. It is also assumed that n > p System procedure) which allow parameter estimation and + r, so that the estimate of the covariance matrix is nonsingular hypothesis testing for the GMANOVA and extended GMANOVA models. Although the statistical theory is not stressed. the in probability. necessary background material is presented along with references for the interested reader. The GMANOVA model reduces the number of location parameters--from rp to rq over the MANOVA model. Therefore, the advantage to this type of polynomial modeling is that fewer A positive aspect of the macros is that any hypothesis which can take the form of the multivariate general linear hypothesis can parameters are estimated, yielding' more powerful hypothesis be tested. However, the generality requires the user to possess tests. (It will always be assumed that q is less than p, because if q is equal to p the GMANOVA model reduces to the MANOVA a background in linear models. modeL) The paper begins with a review of the two models. Maximum likelihood parameter estimators, likelihood ratio tests of Potthoff and Roy (1964) proposed the GMANOVA model as a method of analyzing data resulting from growth hypotheses and appropriate goodness·of·fit tests are included in the presentation of each model. Next, directions and measurements. Subsequent authors such as Rao (1965, 1966, 1967), Khatri (1966), and Grizzle'and Allen (1969) expanded the suggestions on the use of both macros are presented. Finall",Sugi-11-154 Elswick Chinchilli.txt
"VERIFYING ASSUMPTIONS OF THE COX PROPORTIONAL HAZARDS MODEL Frank E. Harrell, Jr. Kerry L. Lee Duke University Medical Center, Durham, NC Introduction The Cox proportional hazards multiple PH, recently added to SAS procedure PHGLM [3,4] regression model [I] is widely used to analyze will also be discussed. survival time data. The Cox model can be stated in either of the following ways: The COXOBSPR Macro Procedure COXOBSPR is a SAS macro-1 anguage procedure So(t)exP(BIX I + .·· + BpXp) S(t,X) or that, for a single covariate X, estimates surviv- al probabilities as a function of X and t both + ··· + BpXp)' with and without making the assumptions of the h(t,X) hO(t) exp(BIX I Cox model. Cox-Kalbfleisch-Prentice survival where S(t,X) is the survival function or the estimates are obtained by PHGLM [3] by treating X probability of surviving past time t for an as a continuous independent variable in the individual having covariate (predictor variable) model, no matter which grouping is used to obtain empirical survival estimates. ""Observed"" survival values X=[X"" ... , X], So(t) is an unspecified llunderlyingl4- survival P func'tion, B , ... , Bare estimates are also calculated by PHGLM, using the i~ the unknown regression coefficients, lh(t,X) method of Kaplan and Meier [2} after appropriate- hazard function for an individual with covariate ly stratifying by X. COXOBSPR can be used to value X, and hO(t) is an arbitrary underlying easily obtain -log-log plots as described above. hazard function. In many cases, however, (see example later), more This model has two kinds of assumptions that can be learned from examining the effect of need to be verified before its statistical making the PH assumption (i.e. examining differ- inferences and predictions can be relied upon. ences in predicted vs. observed survival proba- Our discussion of these assumptions and of bilities) than by examining -log-log plots to try methods for verifying them will be restricted to to judge if PH is",Sugi-11-155 Harrell Lee.txt
"tions, and the problem of estimation for such a model has been addressed by many authors. An Field ~amples of insect larvae represent a early solution was presented by Karl Pearson mixture of populations, one for each instar in (1894), in the form of moment estimators for a the development of the immature insect. Assuming mixture of two normal distributions. Several normal distributions for measurements on the latter investigators, including Harding (1949) instars, maximum likelihood (ML) estimation and Cass'e (1954), relied on graphical tech- procedures as developed by Hasselblad (1966) can niques in obtaining estimates. More recently, be applied to the problem of*describing larval estimators with better statistical properties population structure. A SAS program to imple- have been presented. In papers by Hasselblad ment the ML approach is described and applied to (1966) and Peters and Walker (1978), the method data for larval moths of the genus Ancylis. of maximum likelihood (Ml) is applied to the mlxture problem. The ML estimators are consis- tent and assymptotically ·:?ffh:ient.",Sugi-11-156 Berg.txt
"THE KODAK QUALITY PACKAGE James L. Bossert, Eastman Kodak Company Julie A. LaBarr, Eastman Kodak Company INTRODUCTION availability, accessibility, and compatibility. We are here today to talk about a statisti- The quality consultant would be responsible for cal quality control package which ye developed on determining what programs were needed, the prior- our IBM mainframe utilizing SAS(R) as our foun- ity of the programs, what hardware was preferred, dation. We are proud of this package because: and user interest. The consultant who developed the strawman was responsible for the format of 1. It shows the adaptability of SAS(R) to the the package: how the package is developed -- needs of its users. modular? integrated? user-friendly? user vicious? 2. It was the first IBM mainframe quality pack- menu-driven? command activated? -- these types of age ever developed at Kodak Park. things. Then he would present what he felt was 3. It met the growing needs of Eastman Kodak the most appropriate based on the fitness-far-use as i t searched for ways for improved quality in criteria. its products. So the team was picked; I was in the role of The development of this package was anything the quality consultant who would determine the but smooth. There were times when KQP (as we fitness-for-use. Julie was the programming and affectionately call our package) seemed like a hardware coordinator. millstone around our necks. This presentation What were the needs of the potential users? is to provide a roadway for others in how to Many people at Eastman Kodak were enhancing their bring a quality computer package into existence. knowledge on statistical process control. What The talk is broken into four segments: Background, were the types of processes which would be attemp- Development, Implementation, and Future Develop- ted to be controlled, and what type of techniques ments. would be utilized? Kodak Park manufactures many products; the processes vary as much as the prod- BACKGROUN",Sugi-11-157 Bossert LaBarr.txt
"VISUAL EXPLORATORY DATA ANALYSIS. PROC VISUALS. A USER-WRITTEN EXPERIMENTAL SAS PROCEDURE Forrest W. Young, Douglas P. Kent Thomas C. Edds, and Warren F. Ku~£eld Psychometric Laboratory University ox North Carolina at Chapel Hill 1. Visual Exploratory Data Analya1. PRoe VISUALS presents you with a high resolu- tion, color picture of a three-dimensional (3D) There have been many new developments in space. Contained in the space is a cloud of exploratory data analysis (EDA) in the past objects which represent the observations in your decade, including ney EDA methods for exploring The dimensions of the' space are three of data. and visualizing multivariate data. During these the variables in your data. To enhance the 3D same years there have also been tremendous effect, the picture is presented in perspective improvements in graphics hardware, accompanied projection. by significant decreases in costs. You are the director of the moving picture of Taken together, these developments permit a new your data. Using the cursor keys, you animate approach to exploratory data analysis, an the picture to move (translate) and spin approach that has been recently discussed by (rotate) the cloud of objects. The movements Friedman (1985), Huber (1985), Donoho, Donoho & take place in real time, giving you an animated Gaska (1986), Tukey & Tukey (1985), Suja & picture of your data structure. The combination Asimov (1985), ourselves (Young, et al., 1985, of perspective projection and interactive 1986) and others. We call this approach Visual animation helps reveal the 3D structure of your Exploratory Data Analysis (VEDA). data. The goal of VEDA is to graphically represent the Simultaneously, you can have a second 3D moving structure of multivariate data so that visual picture that is based on three additional exploration can provide you with fresh insights variables, giving you a different view of your about your data's structure. To do this, the data. Its motion is also under your d",Sugi-11-158 Young Kent Edds Kuhfeld.txt
"University Thomas C. Edds, North at Hill o£ North Carolina Chapel Hill The University at Douglas P. Kent, o£ Forrest W. Young, Caroline Chapel The University North at Hill o£ So far, the project has produced ABSTRACT several programs. One program is a Ver- sion 5 plotting procedure, PROC IDPLOT, A SASI software development project is which is described elsewhere by Kuhfeld currently in progress at the University (1985, 1986a, 198Gb, 1986c). The project of North Carolina at Chapel Hill.8 One has also produced the Version 5 PRINQUAL of the purposes of this project is the macro (Young and Kuhfeld, 1985) which is development of procedures that an enhancement of the 1982 PRINQUAL SAS perform a variety of descriptive multi- macro. Also, VISUALS, an interactive variate analyses. Three of these three-dimensional graphics system for the PROe procedures, PRINQUAL (principal IBM PC AT with the Professional Graphics PROe components of qualitative data), Device, has been developed and is being CORRESP (simple correspondence analysis) enhanced (Young et. al., 1986a, 1986b). and PROe CONJOINT (analysis of variance As of this writing, three Version 6 and regression with a nonlinearly data analysiS procedures have been com- trans£ormed dependent variable) will be pleted, in preliminary £orm. These pro- described. PROC's CONJOINT and PRINQUAL cedures, PROC PRINQUAL (principal com- zit a linear model to nonlinearly ponents o£ qualitative data), PROC trans£ormed variables using an alterna- eORRE",Sugi-11-159 Kuhfeld Edds Kent Young.txt
"may be biased. PROC RSQUARE in SAS will only search among models where the independent vari- The recursive residual technique, developed ables have been built. With th,s procedure a1 i by Brown-Durbin-Evans (1975) has proved to possible lnteractlon terms are not considered. be a powerful tool to test for dynamic As an example of the use of the recursive resi- problems in OLS regression models. Code was dual procedures, consider a cross section OLS initially developed to implement these pro- regression of the form MODEL CON SUMP = INCOME cedures in the B34S system in the late 70s. AGE;. If the dataset were sorted with respect The PROC CB34S allows the B34S system to to INCOME and regressions were calculated, run under the SAS software system. The use adding a higher INCOME observation each time, a significant movement in the INCOME coefficient of the recursive residual procedure is illustrated by means of a sample dataset would suggest that the effect of income on from the SAS/ETS manual. consumption, holding age constant, was not stable. If the coefficient of AGE were to change, it would indicate that there was an",Sugi-11-16 Stokes.txt
"REFINING SCALES: SOl""( CONSIDERATIONS WHEN USING FACTOR ANALYSIS AND GUTTMAN SCALING Matthew Scha II University of California, los Angeles Primary consideration In scale development must Scores on the original negative behavior and be given to the homogeneity of scale Items (lord & coping scales correlate very highly with measures Novick, 1968). A scale containing Items that are of total alcohol use and the average amount of manifestations of more than one underlying trait alcohol used per occaSion, but the underlying or ability will be confusing and difficult to factors that ;lctually covary with the alcohol use Interpret. This paper describes how to use factor measures Is not clear. analysis and Guttman Scaling to produce a unidimensional scale, and applies the method to Factor analysis and Guttman scaling were used to make the negative behavior and coping scales much two scales currently used In alcohol research. more Intelligible by simplifying their factor structure. Neither of the original scales Two scales In a questionnaire administered to 600 displayed a clear factor structure or the university students in the fall of 1983 examined characteristiCS associated with a Guttman Scale. the effects of alcohol on behavior. They were a 16 item negative behavior scale and a 6 item using A single factor develops when there Is a set of alcohol to cope scale. SUbjects' scores on both several Items that are highly correlated with each scales were calculated by summing scores on the other (Comrey, 1973). When there are sets of Individual scale Items. Items that are highly correlated within each set, but the sets are not correlated with each other, The negative behavior scale (Mills, Neal & analysis will produce multiple factors. In this Peed-Neal, 1983) contains questions about social, way, factor analysis can be used to determine If a physical, academic, and cognitive difficulties scale is composed of homogeneous Items. caused by drinking. Subjects' answered the questio",Sugi-11-160 Schall.txt
"r machine) that are The improvement of product quality is a top sporadic and affect the manufacturing system locally priority for industry during the 1980's, and many companies are applying statistical quality control methods on an unprecedented large scale. common causes (such as environmental SASiQC software provides a set of tools for a fluctuations) that are inherent in the process wide variety of statistical quality control and affect the entire manufacturing system. applications. These tools include PROC SHEWHART for producing Shewhart control Shewhart invented what is now known as the Shewhart chart for detecting special causes. A charts, PROC CUSUM for producing cumulative sum control charts, and PROC CAPABILITY for Shewhart chart is constructed by plotting a characteristic of process performance, computed process capability analysis. from sample data, as a function of time. Horizontal control limits are added to indicate the extent of natural variation that can be expected I ntraduction due to common causes. Points outside the control limits or special patterns of points provide SASiQC software, a recent addition to Version evidence that special causes are present. 5 of the SAS® System, provides graphical and statistical tools for improving product quality by In Japan since the 1950's, statistical quality control has been taught to thousands of analyzing data obtained from the production process. Products with which these methods are managers, engineers, and foremen,",Sugi-11-161 Rodriguez.txt
"S~PROCEDURE PERSONYRS: A FOR PERSON YEAR ANALYSES Erik J. Bergstralh, Kenneth P. Offord, Jon L. Kosanke, Glenn A. Augustine Mayo Clinic Introduction PROG PERSONYRS statement In epidemiologic studies, one often wishes PROC PERSONYRS options; to estimate rates of certain events in a cohort The options available are: of individuals observed over a period of time. For example, what is the rate of cancer following DATA=dataset the diagnosis of rheumatoid arthritis and is it names the SAS data set containing the data to higher than expected? A common method of be analyzed. If DATA= is omitted, the most estimating such rates is to divide the total recently created SAS data set is used. number of observed events by the total p~rson supresses all printed output. NOPRlBT years (sum of the individual follow-up t1mes in years) at risk. It is also often useful to look RATEMDL~integer at event rates based on person years classified integer is the constant multiplier for by sex, age, calendar year and follow-up year. calculated rates. Rates will be printed as Table 1 below contains an example of how an events per ""integer"" person years. The individual's follow-up time can be broken down by default value is 100,000. age, calendar year and follo~up year. MALES / FEMALES PROC PERSONYRS is a SAS procedure which can indicates that input data set contains ~nly calculate sex-, age-, calendar year- and follow- MALES or only FEMALES. If omitted, it 1S up year-specific person years, events and rates. assumed that the data set is not restricted to The expected number of events can also be a single sex. calculated by applying user-supplied event rates to sex-, age- and calendar year-specific person RATESDATA=dataset years. In addition, rates adjusted for age or names the SAS data set containing expected age and sex can be calculated. This is accom- event rates. In this data set, there must be plished by having the user supply the number of one observation for every age interval for persons i",Sugi-11-162 Bergstralh Offord Kosanke Augustine.txt
"A SYSTEM FOR THE ANALYSIS OF COHORT MORTALITY DATA Richard McLain, Oak Ridge Associated Universities Edward La Frome, Oak Ridge National Laboratory Methods SUMMARY A system is developed for the analysis of The MAS is generally designed for use with cohort mortality data. This Mortality Analysis occupational cohorts but is not limited to System (MAS) is designed as a research tool in occupational settings. A file with a stan- epidemiologic studies. The system allows a re- dardized format is required as input to the searcher to investigate the effect of one or system. This standard input file (SIF) can be more factors on the mortality of a study created easily from a typical. cohort file con- cohort. Variables can be categorized as fac- taining demographic information, vital status, tors to allow for stratification in the analy- and risk factors (see, e.g., Frome and Hudson, sis. DATA. steps and PROC MATRIX are incor- 1979). The SIF must contain one record for porated in the system to produce the output. each study subject and the risk factors must be Person-years, observed deaths, and expected categorical. Using standard variable names and deaths are calculated and cross-classified by factor level assignments the data set becomes the levels of the factors. The resulting data input for the MAS macro. Options allow the set can be used to compute the standardized researcher to request specific causes of death mortality ratios (SMR) for each stratum level. or a screen selection of all causes. Poisson regression models can then be used for further statistical analysis. PURPOSE AND DESCRIPTION Cohort Data Public concern about the health risks of exposure to occupational and environmental hazards has generated much current research in epidemiology. In the study of a cohort there are often many different factors that can in- fluence the force of mortality. Socioeconomic status, attained-age, birth year, calender period, and exposure level are examples of com- mon risk facto",Sugi-11-163 McLain Frome.txt
"1) rank (Xi) = p <ri; 2) the ~i - IND N(Q. 02Iri); The GGCMAOV (Generalized Growth Curve Multivariate Analysis of Variance) procedure analyzes a class of polynomial growth curve 3) the!:i - IND N(Q. '1'); and models that commonly arise from longitudinal or 4) the ~i and ~i are mutually indepen- repeated measurements studies. The program is written in the MACRO language of the version 5 dent. The between-subject model given by release of SAS® and follows closely the REPREG Stage 2 can be written alternatively as program written by Love and Carter (1984). The Stage2 ,···=(I9Z')'+I; . P -1 - · -""-1 -1 GGCMAOV program performs estimated generalized where _ - ("" ... '-p) and Iii denotes the d i rect "" - _l, least squares (EGLS) estimation of random coef- "" ficient growth curve models (RCGCM's). Option- product. ally. the program can perform tests of hypothe- Our primary goals in this paper are to pro- ses as well as pairwise comparisons for com- vide estimates of A. 02 and 'I' and to test the pari ng mean growth 'curves between two or more groups. A primary feature of the program is general 11near hypothesis that it allows for incomplete and/or unbalanced H' vlxq qxp PXV2 = 0 CAA longitudinal data. O·",Sugi-11-166 Vonesh Story.txt
"* WHAT SAS SOFTWARE DOES AND DOESN'T DO: THINGS YOUH NOTHER NEVER TOLD YOU Calvin D'. Cray I National Demographics & Lifestyles It has been said that people learn more from Example 2. The programmer places a semicolon in the wrong place. Consider a data step opened mistakes and failure than from success, Yet learning by self discovery can cost time, with this accidentally split line of code: composure, and sometimes money. Because of Data First(Keep= X)j Second(Keep= Y)j these costs, most people have probably sometime The resulting error message ""Explicit subscript- in their lives had occasion to reflect ""Gosh, ing of array variables is not supported in this I wish someone had told me. · ."". The purpose release of SAS"" means little. No array has of this paper is to help prevent such after- thoughts concerning SAS code. Listed in this been referenced though SAS software has mistaken paper are a few of the SAS softw!re version 82.3 Second for one. peculiarities I or my colleagues have encoun- tered while submitting batch jobs within a VS1 Surprise #3. The logical comparison SAS soft- operating system. We've all ""discovered"" instances where SAS software handles data in ware makes may not be the one wanted. The unexpected ways, The few here might take more user should take care to understand the than a li tUe digging through the user's manuals Boolean logic behind SAS software logical to unearth. They're listed below according to comparisons. decreasing likelihood of being encountered. Example: The statement ""if X or Y) 5"" will always be true, regardless of the value of X and Y. The Boolean interpretation of this Surprise #1. Little elementary-level documen- tation in Basics ~§~. User statement is ""if X = X or Y) 5"". Since X = X familiarity with SAS software insufficient to is always true, all records will pass this test. Similarly, the test ""if X = 10 or 20"" will select the best Procedure. always be true because 20 is always equal to 20. The correct syntax for these t",Sugi-11-167 Croy.txt
"The Basics of SAS Software The BY Statement When You Need It and When You Don't Peter 1. Rikard 'BY RACE SEX AGE'; This ~:rfesentatiQn was a tutorial and as such note was done as a series of slides with commentary. RACE SEX note AGE ,; Below is the basic text of the slides with a FEMALE note BLUE 12 general description of the remarks where BLUE note FEMALE '; 13 note BLUE MALE '; required. "", BLUE MALE note 5 'Users Guide: Basics'; BLUE MALE note note '; 12 'Users Guide: Statistics'; BLUE note note OTHER 12 ,; 'SAS/AF Users Guide'; note note ORANGE FEMALE 37 'SAS/ETS Users Guide'; note ORANGE note MALE 2 'SAS/GRAPH Users Guide'; '; note ORANGE note MALE 32 , 'SAS/FSP Users Guide'; note ORANGE note MALE 999 '; , o ORANGE NONE note Given the mass of documentation provided by the ORANGE SOME note -4 '; Institute, and the application of the SAS system to smaller and smaller machines, it An example of an ordered dataset. becomes more and more important for users to make the most effective use of SAS possible. note 'Yes' ; "", This generally means thinking through your note Race Sex Age By , use of the programming capabilities BEFORE you '. note' BY Race Sex ,. , write your program. note Race By "", note 'The BY Statement'; note note 'No'; 'Benefits'; note note BY Sex '1. Run ""mul tip Ie"" procedures wi th one '; note note BY Race Age '; extra statement. '; note '2. Provides tools useful in producing '; note By statements that may/may not be USed given the ,; reports and altering data. note order of the data above. "", '3. One of the simplest AND most note powerful facilities in SAS. '; note note 'NOTES:'; 'Costs:' ; note oot. , ,; "", SORTing data takes computer note note Sorting data COSTS. (1) '; time and space. note THINK through the problem, note (2) FIRST, note ,; Making effective use of the BY process requires note (3) If data is already in order. learning HOW to use it as well as WHEN. Simply '-; note Do not resort. , sorting your data to insure correctness leads '. n",Sugi-11-168 Rikard.txt
"IF IT UERE A SNAKE, IT WOULD HAVE BIT YA OR . · . 101 THINGS ON THE SASWARE BALLOT YOU CAN ALREADY DO Neil Howard, ORI, Inc. Merry Rabb, ORI, Inc. INTRODUCTION Recoding can also be accomplished with the PUT The SASware Ballot{R) is the vehicle for function. The PUT function is used to specify SAS(R) users to identify additional features an output format for a value. The trick is to realize that the resul ting format can be stored they would like to see in the SAS system. as a new variable, as well: Response to the Ballot over the past few years indicates that many SAS features are not being PROC FORMAT; used to their full potential. Several recurring requests for new features involve 'problems that VALUE $TYP can already be solved using existing tech- 1 .. 'CHOC CHIP' niques. The priorities for new features seem to 2 = 'CIiOC CHOC CHIP' 3 = 'PECAN' be heavily geared toward the mi crocomputer 4 = 'MACADAMIA' products and full screen facilities. This paper 5 = 'PEANUT BUTTER CHIP'; is designed to deal with some basic base SAS items and to emphasize that there is no DATA NEW; substitute for ""trying"" and experimenting with whatls already around. LENGTH COOKTYP $'8; SET SASDATA.CHIPS; The following discussion will provide available solutions to some of the most frequent COOKTYP = PUT(PROOUCT, $TYP.); requests, focusing on data management. formatting. table look-up and recoding. indexing or direct access by key into SAS data sets, and The reSUlting variable can be saved in the new methods for reading data dictionaries or SAS data set. A LENGTH statement should be codebooks. The exampl es demonstrate the base coded to pre-set the 1ength to accommodate the product's greater capabilities and suggest longest formatted value. ,The formatted value imaginative approaches to programming in SAS need not be stored, however. ,since the format software. library Can be stored more efficiently than the additiona', potentially long, new character variable. The same technique can be use",Sugi-11-169 Howard Rabb.txt
"seasonal period i, and 0 otherwise. The error term et is assumed to be uncorrelated and At present, forecast for four lines of busi- identically distributed with mean 0 and con- ness at Blue Cross/Blue Shield of Rhode Island stant variance. The model currently being are generated using the standard regression used is of the general form: methodology (SASlGLM). The current methodology is evaluated in an attempt to update and/or Zt = 8 0 + EBiti + EAimit + et validate these methods. In addition, Box-Jenkins univariate ARlMA In evaluating the current methods problems models are fitted to the four types of claim that warrant ,investigation include the presence data sets using SAS/ETS software. Comparisons of autocorrelation of the error terms and the are made between the forecasting abilities of siglificance of the cooponents in the models. the regression methods and the ARlMA models. The SASlGLM procedure is used to fit the The results of this study show that ARlMA model and also to generate the forecast values. models did improve the forecasting considerably The procedure provides statistics to test the for some types of data. The SAS software has signi ficance of the components in the model. been a valuable tool in forecasting of the In addition, the Portmanteau test statistic four lines of, business to aid in managerial decision making. 2 Q = n(n+2)r r (k)",Sugi-11-17 Salzillo Hanumara.txt
"USE AND MISUSE OF PROC GLM R. J. Freund, Texas A&M Uni versi ty Specifically it is shown that: According to the SAS User's Guide, PROC GLM can be used for many different analyses, PROC GLM should not be used for regression including: PROC GLM should not be used for balanced data analysis of variance simple linear regression PROC GLM must be used for unbalanced data multiple linear regression analysis of variance (ANOVA) analysis of variance PROC GLM can be used, but carefully, for the analysis of covariance analysis of variance with missing cells response surface models PROC GLM must be used for the analysis of weighted regression partial correlation covariance. multivariate analysis of variance (MANOVA) repeated measures analysis of variance. The presentation is in the form of a set of transparencies, which are not suitable for So. why use anything else? reproduction in the proceedings. Full size copies of the paper are available from the author. Because PROC GLM is so very general, it is, in fact, quite inefficient for many analyses. R. J. Freund Also, because of its broad scope, it is easy to Department of Statistics misuse. Texas A&M University It is the purpose of this tutorial to outline College Station, TX 77843 those analyses for which PROC GLM is and is not (409) 845-3141 suitable and to illustrate some pitfalls in the use of this procedure. 913 - 914",Sugi-11-171 Freund.txt
"approach is that it borrows concepts, power probabilities over several!) reasonable scenarios for tenninology, and software commonly used for data analysis the ""true"" parameter values, which for ANOV A designs are within these systems. The scheme allows one to easily study the cell means and common variance; 2) possible sample sizes; the power of any hypothesis test that can be performed with 3) Type-I error rates; and 4) llnporlant hypotheses. This one's favorite linear models routine, thereby making the method more genentl, fl~xible, and precise than table-based tutorial shows how understanding statistical power and perfornting the computations are greatly sllnplified by taking methods, such as those bf Cohen (1977) and Odeh and Fox advantage of the strong paraJ1els that exist between familiar (1975). The method is illustrated using statistical consulting aspects in data analysis and their not-so-familiar counterparts example, which employs the SAS System, but reference is also made to corresponding SPSSx procednres. in power analysis (e.g. F statistic ~~> noncentrality parameter, p level ~~> power probability). Tools wit1tin the standard SAS® System, including PROC GLM, enable one to This paper represents a substantial maturation of the straightforwardly petfonn all the necessary computations and material presented at the 1984 SUGI Conference (O'Brien & tabulations. This strategy is exemplified in detail by applying Lohr 1984 and Lohr & O'Brien 1984). Another paper in it",Sugi-11-172 OBrien.txt
"atrix language that is SAS/IML software is a new product developed by both powerful and flexible. The fundamental data SAS® Institute. PROC IML offers a working object on which all commands operate is a row by environment that is interactive, dynamic, and column matrix. Therefore, single elementwise flexible. The matrix language is interactive at operators such as + and j can operate on many the statement level. You can see results and diagnostic information immediately. The data values to produce many results. In addition, programming environment is dynamic. Necessary there are commands to reduce many values to a activities such as memory allocation, dimensioning single desired value, for example, SUM and SSQ, results, and monitoring data types are done subscript reduction operators to reduce rows and automatically. columns within a matrix, and special matrix operators such as matrix multiplication, transpose, and inverse. The fundamental data object' of the language is a row by column matrix. A single operation acts on an entire matrix and so can affect many values. You can control the execution of operators and Matrix level operations also avoid the need for commands using SAS/IML programming explicit loop control. Since the native data object statements. SAS/IML subroutines allow you to is a matrix there are many specialized matrix decompose a large application into modules. operators built into SAS/IML software. There is a rich set of data management commands to transfer",Sugi-11-173 Eaton.txt
"Using PROC COMPARE and PROC CONTENTS to Compare SAS Data Set Values and Characteristics Tim Lehman and Ann Lehman SAS Institute 1nc. Why compare SAS data sets? PRoe COMPARE compares the values of variables within a single data set or between two data sets and reports the differences. Verify that two files are identical in order to delete duplicate members. General syntax: Verify names and characteristics of variables prior to using the SET, MERGE, or UPDATE statement. PRoe COMPARE options; VAR variables; Compare data values following an application. WITH variables; ID variables; BY variables; The primary function of PROC COMPARE is to Selected Options compare data values following an application. PROC COMPARE can be used to DATA= names the data set to be used as the base data set for verify data updates by comparing 'before' comparison. and 'after' images of a SAS data set names the data set to be used as COMPARE= perform a budget analysis from financial data the comparison data set. monitor changes in sales, transactions, or requests that differences for OUT= other money figures numeric variables be written to a SAS data set. compare characteristics of variables between two SAS data sets. of requests the printing STATS the summary statistics for that numeric variable pairs compare unequally. Comparing SAS data sets suppresses the printing of the NOSUMMARY summary notes. suppresses all printed output NOPRINT (used with OUT= option). Comparisons of interest specifies the method for METHOD= comparison (RELATIVE, Names of variables in two data sets PERCENT, or ABSOLUTE). Number of observations in two data sets specifies the criterion for CRITERION= judging the equality of numeric Characteristics of variables in two data sets variables. Position of variables in two data sets requests that values and ALLOBS differences for all matching Values of pairs of variables observations be printed. If these five comparisons all prove equal between two data sets then the SAS files",Sugi-11-174 Lehman Lehman.txt
"nd physical design of the production data base. To make the SYSTEM 2000 DBMS user-oriented data base is a best possible business decisions·, end users need management system. It provides data management access to the most current data with minimal data capabilities that serve the entire range of system security and need to be prepared for backup and the end user, the application developer, users: recovery in the event of system failures. and the data base administrator. SYSTEM 2000 DBMS is controlled via an integrated data dictionary; SYSTEM 2000 DBMS represents a solution for reduc- uses multiple-indexed hierarchical data structures ing demands on the Development Center. As a com- for fast retrieval and updates; allows the definition of complex network structures; features prehensive data base management system, SYSTEM 2000 DBMS provides integrated facilities, interac- a programming language extension (PLEX) that tive data base definition, access to data via log- allows data base access from COBOL, PLll, FORTRAN, ical views, high-level programming interfaces, and Assembler programs; provides a powerful, easy- nonprogramming alternatives for both end users and to-use query/update (QUEST) language; and includes data processing, as well as application concur- an interactive report writer to accommodate rency. tabular reports. SYSTEM 2000 DBMS currently runs on IBM 370 and compatible machines under OS, SYSTEM 2000 DBMS includes a basic (single-user) VM/CMS, and VSE; the Sperry 1",Sugi-11-175 Springer.txt
"where the ei are random variables with The b~s are fixed, mean equal to O. if Developments in the area of unknown, constants often called the regression over the last analysis regression parameters. It is convenient fifteen years have been qUite to represent the n equations defined remarkable. In this paper we review some above in matrix notation of those developments as they are +e reflected in PROC REG~ In the first = Xb y section some of the relevent literature is reviewed and notation is fixed. In ,bp)~, where b=(b1, ·.· e=(e1, ·.. ,en)' and Section II some examples are provided to the matrix demonstrate the inadequacy of standard summaries such as R-sqare. In the third x KIP = 1 xl1 and fourth sections certain influence diagnostics are reviewed. In Section V collinearity measures are defined and XnP 1 Xn1 explained. In Section VI partial regression leverage plots are exhibited The least squares solution to the matrix and discussed. In the seventh section equation above is some comments on model building and vari8ble selection are given. I.",Sugi-11-176 Hobbs.txt
"Performing the Xll-ARIMA Seasonal Adjustment john C. Brocklebank, SAS Institute Inc. David A. Dickey, North Carolina State University Most seasonal adjustment methods are based on Realistic confidence limits on the X11 forecast are somewhat di'fficult to produce. the assumption that seasonal fluctuations can be measured and separated from the underlying Xl1 is an inexpensive and powerful tool that trend and irregular components. you can use even if you are a nonstatistician, but you are limited to a ""canned"" model applied to all series. The U.S. Bureau of Census Method II-Xll variant of a seasonal adjustment program The Xll procedure can be combined with developed by Shiskin, Young, and Musgrave PROC ARIMA to perform the Xll-ARIMA (1967) has often been criticized. Critics state method. that the estimates for observations of the most recent years do not have the same degree of reliability as those of the central observations. The Statistics Canada Xl1-ARIMA developed by Dagum (1975) extrapolates the unadjusted data SEASONALITY one year ahead at both ends using ARIMA models of the Box and Jenkins type. The extended Seasonality refers to the regular periodic original series is then seasonally adjusted using fluctuations that recur each year with the same various moving averages of the Method II-X11 timing and intensity. variant. The majority of procedures for seasonal analysis This paper discusses how Xll-ARIMA involve smoothing to eliminate unwanted irregular methodology can be applied using several variation from patterns that are meaningful to the procedures provided in SAS/ETS® software. In analyst. particular, many of the ""advantages"" of the Xll- ARIMA over the Method II-X11 variant are discussed. Seasonal Adjustments Many economic series show seasonal variation. Session Objectives I ncome from an orange grove farm may rise each year from the late fall until early spring and then Understand the principal features of the drop very sharply. SAS® seasonal adjustment",Sugi-11-177 Brocklebank Dickey.txt
"Checking for Autocorrelation in Regression Residuals David A. Dickey, North Carolina State University John C. Brocklebank, SAS Institute Inc. Linear Regression Autocorrelation in regression is a violation of standard regression assumptions. It often occurs in data collected over time. Many SAS® procedures provide methods to check for autocorrelation. This paper illustrates the use of This section reviews the method of linear the Durbin-Watson test statistic and a SAS macro regression, an elementary but common form of that performs a runs test of residuals. SAS/ETS® mathematical modeling. Suppose that at time t you software contains procedures that correct for observe Yt. You also observe explanatory autocorrelation, and these procedures are variables X , X , and so on. For example, Yt mentioned. This paper explains how to recognize 2t H sales in month t f X and deal with autocorrelated residuals. could be could be H advertising expenditure in month t, and X2t could be competitors' sales in month t. A simple plot of monthly sales versus date is given in Autocorrelation Output 1.1. A simple linear regression model relating the variables is Autocorrelation is the phenomenon that distinguishes time series from other branches of statistical analysis. For example, consider a Assume for this model that the errors et manufacturing plant that produces computer parts. Normal production is 100 units per day, have the same variance at all times t while actual production varies around this mean of 100. Variation may be caused by machine are uncorrelated with each other (e t and e s failure, absenteeism, or incentives like bonuses or approaching deadlines. A machine may are uncorrelated for t different from s) malfunction for several days, resulting in a run have normal distribution. of low productivity. Likewise, an approaching deadline may increase production over several days. This is an example of positive These assumptions allow you to use standard autocorrelation, with dat",Sugi-11-178 Dickey Brocklebank.txt
"used to create two output data sets, one containing the schedule and the other containing information regarding resource In this tutorial we discuss various aspects of usage. These data sets can then be used as project management and describe how the SAS® and input to various procedures in SAS to display SAS/OR® software can be used to address some of information regarding the project. You can the problems that arise in this area. The SAS/OR® use PROe PRINT to print the schedule or Software contains two procedures, PRoe ePM and resource usage, PROe CALENDAR to print a PROe GANTT designed specifically for project calendar of the schedule, PROC GANTT to management. We shall present several examples obtain line-printer quality or high illustrating features of the two procedures and resolution graphics quality Gantt charts, or show how some special situations can be handled PROC CHART, PROe GCHART, PROC PLOT and PROe fairly easily with a Jew programming steps in the GPLOT to draw resource usage profiles. The SAS language. DATA step functions, PROC SORT, PROe SUMMARY and other procedures can be used to summarize the information in any number of ways to",Sugi-11-179 Kulkarni.txt
"maximization of this index sUbject to a binary strike vote choice constraint leads directly to The purpose of this paper is both a logistic regression model for the individual substantive and methOlogical. The substantive miner. purpose Is to better understand the 1981 UMWA The problem IS that individual miners are coal strike in terms of the factors that not about to reveal how they voted. The lowest influenced the strike vote. The methological level at which votes are collected and counted purpose is to demonstrate the use of ridge is at the union local level. There are about 800 regression and principal components regreSSion locals in the UMWA Some of these are (PROC RIDGEREG) in evaluating the stability, retirement locals, anthracite locals or other and, therefore, the reliability of ordinary least locals not participating In the contract squares regreSSion estimates. ratification vote and, therefore, not used in this analysIs. Since regression analysis Is used",Sugi-11-18 Marsh Ghilarducci.txt
"dresses each of the techniques will also be presented. A powerful feature of the annotate facility is the capacity of using the system of coordinates Text Applications generated by a graphics procedure to provide custom enhancements to the procedu re output. This paper explores the use of the DATA step and the macro facility to add data-dependent, Text is used in nearly every graphics display to user-defined modifications to graphics output clarify the content and meaning of the picture. Text is also used alone to disseminate information from the GSLlDE, GPLOT, and GMAP or to prepare the viewer for the next picture. p roced u res. TITLE, NOTE and FOOTNOTE statements can be used to position text strings if the text strings General Capabilities of the Annotate Facility have fixed values and occupy fixed positions on the page. To accommodate variable text strings in variable positions with TITLE r NOTE, or SAS/GRAPH® software provides a powerful FOOTNOTE 'statements requires the use of the system of procedures for producing business macro facility. A much easier alternative is graphics in a production environment. The provided by the annotate facility. graphics user can display information stored in a SAS® data set by selecting a SAS/GRAPH procedure and providing appropriate statements A Strategy for Annotating Text Strings and options. A fixed range of modifications are possible for each procedure when selected statements and options are used. Any strategy for using the annotat",Sugi-11-180 Kelly.txt
"utput 1 obtained. This tutorial presents interesting and unusual uses of PROC GREPLAY that go beyond the examples supplied in the SAS/GRAPH- User's Guide, Version 5 Edition. Examples of the following types of applications will be discussed: * Creative template designs * Combining multiple graphs · Effective and unusual presentation of data * Combining text and graphics * zooming and rotating with templates * Adapting color to different media This is not meant to be an exhaustive summary of the capabilities of PROC GREPLAY, but rather an illustration of a few of its nonstandard uses. CREATIVE TEMPLATE DESIGNS In most PROC GREPLAY applications using templates, template panels are rectangular. A second example illustrates the use of non- However, a panel can take any shape using three rectangular panels and clipping to create a or four sides. For example, you can use the templi$te that looks like- an open book. Use the following statements to design a template with following statements to create the template: nonrectangular panels that give the perspective of looking into a box: PROC GREPLAY NOFS: TC TEMPLATE; PROC GREPLAY NOFS; TDEF BOOK MYTEMP~ TC ULY=94 1/LLX=2S LLY=20 ULX=2S TDEF BOX CLIP LRY=Q5 URX=50 URY=80 LRX=SO LLY= o ULX=20 ULY= 40 l/LLX= 0 ULY=88 2/LLX=15 LLY=lS ULX=15 LRY= 0 URY= 40 LRX=lOO URX= BO LRY=05 CLIP LRX=50 URX=50 URY=80 ULY=lOO LLY= 0 ULX= 0 2/LLX= 0 ULX=07 ULY=82 3/LLX=07 LLY=lO URY= 90 LRX=20 LRY= 40 URX= 20 LRY=OS LRX=50 URX=50 URY=BO LLY= 90 ULX= 0 ULY",Sugi-11-181 Kalt.txt
"Selecting Graphics Hardcopy Devices--What is Best for Your Site? Roger Chenoweth SAS Institute Inc. want to present information here to help graphics'"" or does it need to be of managers, project coordinators, and end users ""presentation quality""? Most graphics make informed decisions about graphics hardcopy software on the market is capable of device acquisitions. This information falls into producing ""presentation quality"" graphics. th ree catagories. The real limitation is the hardcopy device used. The quality of the picture itself is a 1. Criteria for judging output devices. All combination of many of the hardware features these factors should be considered before any listed below. purchase is made. Considered here are presentation quality, resolution, number of Resolution - refers to the discernable line colors, speed, cost, preview capabilities, pairs per inch the device can produce. What multiple copy capability, media, plot size, is usually reported in the device specification sheet is addressable dots per inch (dpi). required software, and configuration This resolution specification is misleading. possibilities. With many devices the ""dots"" actually 2. The configuration possibilities of various overlap. Thus the number of discernable line hardcopy devices is a criterion that requires pairs per inch will be less than the dpi. The special attention. Can the device you are smaller the dot overlap the closer dpi will come to des'cribing the actual resolution of considering be used in the configuration you the device. want? 3. The wide array of hardcopy technologies However, if the dots do not overlap, diagonal available is presented with an evaluation of each or curved lines have a pronounced stair-step of these on the criteria presented in the first or jaggy look. The greater the overlap the part. better these lines will look. CRITERIA FOR SELECTION AND COMPARISON The bottom line is that you need to see actual graphs produced by the device when The following c",Sugi-11-182 Chenoweth.txt
"A Decision Support System Prototype for Network Problems Marc-da .... id Cohen SAS I nstitute Inc. Cary. N.C. Once a general problem is stated it must be Introduction narrowed to a manageable size. For example, in The area of operations research has yielded the general framework one may have identified the manufacture of a commodit~ as an inefficiency in numerous p?werful and sophisticated tools for ! a particular industrial setting. On closer aiding management in decision making. examination, identifying the mlnlmum cost Mathematical programming algorithms for network periodic production and inventory needs for the problems (simplex algorithm for linear commodity given forecast demands is of particular programming, the out-of-kilter algorithm, and the primal simplex algorithm for network programming) interest. This reduction from a general question are some of the most frequently used tools in of manufacture to the more specific one of operations research. Unfortunately. because of particular periodic production and inventory needs not only further clarifies the problem, but their sophistication they are often either overlooked or missapplied. also helps identify those variables which control This paper demonstrates how an operations the process. These variables are called the research tool for network analysis can be decision variables. Finding values for them is imbedded in the SAS@ language to form a decision the goal of the analyst. support system that is application specific. This With the problem more clearly defined, the enables the operations research analyst to build process can be studied for those features that generic models, with model structure hidden, in a significantly affect the decision variables. A way that allows management to apply the model can be abstracted from these observations. methodology correctly without detailed knowledge Knowledge and understanding about the process is of the technique or the specifics of the model. paramount at thi",Sugi-11-19 Cohen.txt
"MIRROR MIRROR ON THE WALL: A SAS SOFTWARE METHODOLOGY FOR PLOTTING CORPORATE IMAGE Luanne Conley, Blue Cross Of Northwest Ohio personal interest in my health and well-being. 1I INTRODUCTION One of the most consistent findinas in the research on attitude change is that a ~ 5) ""This company is primarily run by computers source having an ulterior motive for giving a rather than people."" 6) ""I would feel very message causes little attitude change in the secure I;'fith this health care coverage."" 7) ""In target audience. That is, when the source of the the event of serious illness, I would have finan- message stands to profit from it, the audience cial concerns if covered by this insurer. 8) II tends to resist or discredit the message. One of ""This company provides the best possible service the major instances of a source having an ulte- in paying health care claims. 9) liThe people in 1I rior motive for delivering a message is in adver- this company make an effort to show they care."" tising. The source clearly has something to gain 10) ""If I had my choice. I would have this health from convincing the audience of the authenticity insurance coverage. Data entry and analysis were II of its message. That is one of the reasons suc- done thru the Market Research Department, utiliz- cessful attitude change in the target audience ;s ing BCNWO's IBM 3083 mainframe, and the software so difficult to achieve when using an ad. In 1984, package SAS. Six 11undred seventy-five (675) Blue Cross-Blue Shield of America began an adver- responses were included in the analysis. The tising campaign that attempted to induce attitude Blue Cross Image By comparing the ratings-or-the changes toward the Blue Cross-Blue Shield image. 10 statements when the company named is Blue Although awareness, or identification of Blue Cross to ratings of the 10 statements when other Cross-Blue Shield as a major health insurer was insurance companies are named, it is possible to considered a problem, the public",Sugi-11-20 Conley.txt
"1. Each database must contain a SAS file named As SAS databases grow in size and impor- INDEX. Fite INDEX contains an obse:r:vation tance. it is vital to provide some basic data for each file in the SAS database. Each management services. The services examined in observation holds three variables: FILE. this paper include backing up databases. ARCHIVED. and DESCRIP. A PROC PRINT of the archiving database files. and preparing indexes INDEX file provides a short description of of database variables. The backup/archival each file and indicates whether the file is fmlCtions can be performed on any SAS database. on the disk version or archived on tape. The variable index function is designed for Figure 2 shows a sample PROC PRINT of an time-series files. I """"'DEX file.",Sugi-11-21 MacHose.txt
"r The autom ated portio n of the existi ng system did not suppo rt ABSTRACT these change s and theref ore, much This paper review s the develo pment of the system was not being effort s used to create a Track ing, used. Sched uling, and Repor ting System to assist in the manag ement of OVERVIEW OF THE OLD SYSTEM in-hou se traini ng at Virgin ia Power. The old system requir ed that each traini ng reque st be entere d on the autom ated portio n of the VIRGIN IA POWER INFORMATION system and then be posted SYSTEMS TRAINING manua lly on a roll sheet for the class. When a course filled up, Virgin ia Power Inform ation System s a waitin g list was starte d on the Traini ng provid es both mainfr ame, bottom of the sheet contai ning word proce ssing and person al the roll. If someon e cance lled, compu ter traini ng to the corpor a- which happen ed freque ntly, a name tion's 13,000 emplo yees whose job was taken from the waitin g list respo nsibil ities requir e the use and the openin g was filled . If a of compu ter resour ces. A traini ng wai ting 'list was consid ered full, facili ty, equipp ed to suppo rt names were transf erred to the mainfr ame, person al compu ter, and waitin g lists for other classe s. IBM 8100 traini ng activ ities, is Occas ionall y, a name was entere d maint ained near corpo rate on two or more waitin g lists headq uarter s in Richm ond. becau se of prere quisit es. These entrie s usual ly had a variet y of SCHEDULING PROJECT OVERVIEW hand- writte n notes t",Sugi-11-22 Plunkett.txt
"11IE EXPERIEI«:ES A MIlLTI-sTATE AGEI«:Y USERS GRWP IN DEVELOPING A SERIES (F (F WOBKSllOPS ON SAS* SCFlllARE Gail S. Olson, Missouri Department of Conservation INfRaJUCTION SAS softwar e users not on our regular mailing list J and their enrollm ent in a workshop would In 1984, the Inter-A gency SAS Users Group provide the opportu nity to include them in was formed in central MisSOuri. Its membership future mailing s. consis ts of all interes ted SAS users employed by the various state governm ent agencie s based in WORKSHOP PLANNING IEJECTIVES the capital city area. Curren tly, about 10 agencie s are represe nted by approximately 60 Basic objecti ves were set for plannin g the members. workshops. The first was to offer a broad range of topics, that is, ""something for everyon e"". Prior to the formati on of the Users Group, In this way a larger audienc e could be reached agency personn el had little interac tion with SAS and the Users Group would demons trate its intent users in other agencie s, and opport unities for to appeal to all SAS users regardl ess of their learnin g about SAS were limited . To address the interes ts and level of experie nce. lack of learnin g opport unities it was decided to conduc t a series of workshops which would A second objecti ve was to plan a series of educate SAS users of all levels of experie nce in standar dized workshops, that once develop ed areas of SAS with which they were unfami liar. could be offered once or twice a year as needed Although other forms of educati on were with little or no alterat ions. This would conside red (self-t raining , tutorin g, small group require more initial effort but each repetit ion workshops, and SAS Institu te worksh ops), large would simply involve the presen tation of the group workshops were perceiv ed as being the most same subjec t materi al. This would ensure that efficie nt and effecti ve means of teachin g SAS each person taking a workshop could expect to softwar e to agency users. ge",Sugi-11-23 Olson.txt
"Facilities for Supporting the SASe System - Applications to zaps Margaret L. Adair, SAS Institute Inc. Another book that should be indispensable to a SAS software consultant is the SAS Applications The Technical Support, Education, and Full of DATA step examples, the book Guide. Publications departments at SAS Institute Inc. illustrates ways to use the SAS System to read data with unusual file organization, to recode provide many tools to help SAS software values of variables, to reorganize the infor- representatives and SAS software consultants mation in SAS data sets, to write reports, and support the SAS System at their sites. This paper describes some of the support facilities to take random samples of data. It also offers available from the Institute and how they can be hints on the effective management of SAS data used to best advantage. sets, diagnosing SAS error messages, and efficient processing of large data sets. When a SAS user asks for assistance in designing an application, the SAS Applications Guide should ~IOR be One of the first books you reach for. Members of the Institute's Technical Support Department realize that one of the ways we can The Institute also publishes technical reports most effectively serve customers is by helping covering a Variety of subjects. Of primary local SAS Software Representatives and interest to those involved in the support of SAS users are U-I01, ""A Guide to the SAS Usage Consultants to improve the level of support they are able to provide to local users. As the Notes, Sample Library, and DIAL-A-ZAP""; U-I03, number of licensed sites continues to grow, this ""The SAS Consultant's Guide""; and G-I03, ""Master aspect of our support becomes increasingly Index to SAS Documentation."" With each new important. Only when experienced and software release, a technical report is knowledgeable local support exists can published describing major changes and enhance- individual SAS users count on getting the sort ments from the previou",Sugi-11-24 Adair.txt
"HELPING YOU SELECT THE BEST METHOD FOR TRAINING EMPLOYEES IN THE SAS SOFTWARE Keith Hovland and Stephen Harper Minnesota State Government SAS · It is difficult to know whether to 7. The system software has become use computer-based training, video extremely powerful and varied in recent tape training, SAS Institute live years. While these expanded capabili- training courses, self-developed ties have been hailed as improvements, live training courses, consultants, they have resulted in a more complex or some other method for accomplish- language, and consequently a more com- ing the training. plex training challenge. In addition, the diversity of student backgrounds, In order to determine which training the complexity of the IBM TSO/SPF envi- method is the best one for you, a rating ronment, and the cost of training system must be established. Table 1 increase the training challenge. These lists sixteen widely accepted adult factors, combined with the various meth- learning characteristics and reflects ods that are available for training our rating of the five most commonly employees in the SAS software language, used training methods. A rating of ""1"" make it imperative for trainers and would indicate that this method of managers to have some guidelines by training is highly effective in the area which to select the best method for identified by this adult learning char- training their personnel in the use of acteristic. A rating of ""5"" indicates the SAS software. that this training method is least effective in fulfilling this training This paper provides some guidance for characteristic. these decision-makers. It begins by identifying some of the widely accepted characteristics of adult learners. Then, it compares and contrasts various methods used to train students in the SAS software on the basis of their strengths and weaknesses and on the r.J>le 1 basis of cost. It concludes by offering _(II) IU\TDIG 01' 'ftIloIKDIG suggestions for resolving this training lIT A",Sugi-11-25 Hovland Harper.txt
"SUPPORTING SAS® SOFTWARE ON A PC Michael D. Rhoads, Westat we have discouraged this method of operation The arrival of SAS software on the IBM PC was a because of the heavy load on our system. major cause for celebration for those of us who had long used various SAS products on larger Recently, microcomputers have started to playa computers. As Westat 1 s software Consultant for more important role at Westat. We currently the PC SAS system, I have found that supporting have over one hundred personal computers in the this product has been an exciting, educational, company. Most of these are IBM PC/XT models; and at times frustrating experience. I hope we also have a considerable number of AT's, that our experiences may be of some help to along with some COMPAQ models and a few those of you who are in similar situations. Macintoshes. (Those of us who are MacFanatics are hoping that this number will increase.) Since many decisions concerning training and Many of these machines are principally used for support within an organization depend upon such word processing. We also use these micros for factors as its size, structure, and personnel, such purposes as budgeting, staff management this paper begina by describing both Westat and scheduling, and receipt control. itself and our previous experiences with SAS software. It then discusses our first few Because of this increasing use of personal months of using the PC SAS system. Some computers, we eagerly awaited the arrival of possible ideas are suggested for customizing SAS software on the IBM PC. We felt that the the PC SAS software for a particular installation, and the results of a recently- SAS package would provide a good complement to our other microcomputer software, such as Lotus conducted user survey are presented. 1-2-3 and dBASE III. In particular, we Knowing Your Situation expected that the arrival of SAS on the PC would mean that we could move some entire Westat is an employee-owned statistical survey proje",Sugi-11-26 Rhoads.txt
"What's New? SAS I nstitute Training in 1986 Herbert Kirk, SAS Institute Inc. Introduction With the acquisition of SYSTEM 2000 Data Base Management System, SAS I nstitute established a smaller training center in Austin, Texas. During The release of Version 5 of the SAS';~) System with 1985 only SYSTEM 2000 DBMS courses were new software products, the development of the offered at the Austin facility. In November the SAS System under PC DOS, and the acquisition training center !n Austin was expanded to of the SYSTEM 20()0® Data Base Management accommodate more classes. The new facility has System produced a greater demand for training two classrooms, a computer laboratory with to support our software products. The twelve full-screen terminals, and a dining area. Education Division at SAS Institute is strivino to This allows the institute to teach SAS software meet that demand by updating existing cour~es, courses in addition to the SYSTEM 2000 DBMS courses already offered. In 1986 almost all of the expanding our training curriculum and our instructor-based courses in the SAS and SYSTEM training facilities. We have just added a series 2000 DBMS curriculums are being offered at the of computer-based training (CBT) courses to our Institute's training center in Austin. curriculum to supplement the video- and instructor-based courses already offered. These three training methodologies provide a variety of I n addition to the two train-i ng centers, SAS training avenues for SAS software and SYSTEM 2000 DBMS users. Institute has established a new training site in cooperation with ORI, Inc. located at ORI headquarters in Rockville, Maryland. The site offers instructor-based training with computer Currently, we have thirty-one instructor-based workshops for SAS and SYSTEM 2000 users in courses to support our software with several the greater Washington, DC area. There are more courses under development. Three of the more than 500 SAS software and 60 SYSTEM 2000 courses suppor",Sugi-11-27 Kirk.txt
"The Curriculum Approach: Selecting Training Paths for All Users Jean Ussery, SAS Institute Inc. I ntraduction boxes indicate different courses that cover similar topics. Start with one of three 1985 was a banner year for the Education foundation courses. From that beginning, if you Division of SAS I nstitute. Twenty-five new want to learn more details on using the SAS courses were introduced and six others System as a programming language, follow the updated. With these additions to the training branches to' the right. If you have special program, you have over forty courses from applications, such as creating graphical which to choose. These forty courses provide displays, then select from the End User Special a complete training plan for all users--from the Interest Table (table 1). novice end user to the seasoned data analyst. As you grow in your use of the SAS System, But so many choices can be overwhelming--how you may want cou rses with more depth or more do you select the right course or sequence of courses for your training needs? detailed instruction. If so, look at the curriculum paths for programmers and analysts. If you study in one of the other paths, we To help you make a selection, we suggest five curriculum paths. These paths are designed for recommend that you begin with one of the foundation SAS Basics courses. Although you end users, programmers, and analysts who want have ·experience with the SAS System from the SAS® software training and end users and end user courses, the Basics courses introduce programmers who want SYSTEM 2000® Data Base many new concepts fundamental to all other Management System training. You may find one cou rses. path that suits your needs. Or you may find that the best training program for you combines End User Special Interest Table: Once you different paths. The five curriculum paths are shown in detail below. have completed a foundation course, select courses from this table according to your goals with the SAS Syste",Sugi-11-28 Ussery.txt
"A critical part of any instructional development Figure 1 Model of CBT Development Process process is the cou rse review, whether it be called formative evaluation, instructional validation, or content and style review. It is particularly important for computer-based training (CST) in which the final product is I Research topic usually delivered to one user at a time, out of needs assessmen (1) Analysis ~onduct the developer's sight. 1n theory CST reviews I encompass thorough evaluation of the instruction Determine course goals by content experts. as well as extensive testing of the course by potential users, both under ideal conditions. This paper will address the task of -I- instituting a practical, yet beneficial, CST review process within the constraints of an organization--how to organize available time and Perform task analysis personnel such _that your CBT course receives (2) Design the best possible validation. The review process eve lop content outline used by CST developers at SAS I nstitute will be Develop main branches discussed. +",Sugi-11-29 Yordy.txt
"NEW DEVELOPMENTS IN SAS/AF® SOFTWARE FOR COURSE AUTHORING John Boling SAS Institute Inc. INITIAL value means that the INTRODUCTION screen is initially being displayed. PARSE implies some Since the announcement of SAS/AF® software at intermediate screen display. many new features SUGI 10, have been The END or CANCEL value incorporated into its maintenance release. These means that the END command or new features provide additional support for CANCEL command is in designing and presenting menu-driven systems, progress. It makes initialization on-line help and query systems, and computer- and termination routines easy to based training courses. Many of the new code. enhancements specifically support CST or program screen implementation. The purpose of _DERRON Contains a list of associated this paper is to discuss these new features and macro variables whose provide illustrations of their usage. corresponding user entry fields were found in error. The DISPLAY procedure automatically PROGRAM SCREENS adds variables to this list. The macro code in the program New' features have been added to program screen can also add variables to screens to support consistency checks, the this list. The program screen writing of code to an external file, and cannot be submitted for conditional and unconditional transfers from execution . until no macro program screens to other screen types. variables make up this list. Consistency Checks However, the program screen can be canceled. The most powerful screen type in SAS/ AF software is the program screen, where the values _DERROFF Contains a list of associated entered can be substituted into SAS source macro variables whose statements for execution. Using the ATTR panel corresponding user entry fields for the program screen, validity checks could be were not found in error. This defined for a single user entry field. However, macro variable clears the error there was no way to do consistency checks status of a user entry field (validate t",Sugi-11-30 Boling.txt
"The SAS System for Litigat ion Support Bernard Yancey Introdu ction 2) The generat ion of proced ural docume nts and materi als, includi ng Req~ests for Produc tion, Litigat ion poses a series of interes ting Admiss ion and Finding s of Fact; and 3) The problem s whose solutio ns are simplif ied through perform ing of statist ical analyse s and the the use of comput ers and efficie nt, easy-to -use genera tion of exhibit s. data management systems . The opport unities for using comput ers in support of litigat ion has Data Prepara tion been incre·a singly recogni zed by members of the legal profess ion (See Comput er/Law Journa l, Aside for the legal issues of a case, Vol. 1, No.4, 1979, ""Compu ter-Rela ted Evidenc e perhaps the biggest problem faCing an attorne y Law""). With the decreas ing cost of is dealing with the massive amount of microco mputers , the general increas e in informa tion that must be analyze d. This is comput er power for a given dollar, and the particu larly the situati on with employm ent increas ing comple xity of litigat ion, more and litigat ion where a signifi cant proport ion of more attorne ys are looking toward comput ers to the evidenc e to be present ed is statist ically provide suppor t. based. This is not to say howeve r, that the Given the large amount of informa tion need to generat e and present statist ically needed in the prepara tion_of a case, what is based evidenc e is the only factor contrib uting really needed is a means of storing , to the massive amount of data associa ted with organiz ing, rapidly retriev ing, summar izing, complex litigat ion. If data is viewed simply and analyzi ng inform ation. Thus the primary as pertine nt inform ation, then the potent ial need in litigat ion support is for an amount of data associa ted with a case is rather easy-to -use, efficie nt data management system. large indeed. In line with this definit ion of Furthe r, in some forms of litigat ion at least data, the term ""data analysi sl",Sugi-11-31 Yancey.txt
"EVOLUTION OF A MULTI-STATE AGENCY SAS* USERS GROUP IN MISSOURI Pamela Haverland, Missouri Department of Conservation under the new organization. The results IITR(I)UCTIOIf indicated most of the members were at about Missouri, as with most states, has many the same level using the base SAS proce- diverse agencie's providing services to the dures, but some had specialties in SAS/GRAPH·, SAS/ETS·, and the Macro language public and, most of these agencies have sta- tistical and data processing capabilities. and some had used various versions of the The SAS System is the common thread which SAS System from the 1972 edition to the 1982 edition. All the members were not using the brings these users together. Currently, ten of fourteen state agencies participate in same comPuter system and Some did not have the Missouri Inter-Agency SAS Users Group. access to certain SAS facilities like SAS/GRAPH. Although we got valuable infor~ The members meet to share their experiences and knowledge, to seek help in solving their mation on the SAS knowledge of members from problems, and to learn new procedures. the survey, these were few suggestions for Although the group met informally at first, topiCS or presentations. eventually by-laws were written and now the group has a steering committee. Workshops The most difficult task in organizing on different parts'of the SAS System, have meetings was finding topics which'mIght been organized and conducted by members 'of appeal to a broad spectrum of SAS users. the users group. By sharing information, The members were from'different agenCies and some agenCies have added additional SAS used the SAS system iil'~ their own applica- facilities that they otherwise would not tions. The, survey showed that most members have known about or could not have justi- had not used the newer procedures like fied. The users group is also supPorting CALENDAR and TABULATE, but were familiar the SAS System for personal computers with the commonly used SAS proc",Sugi-11-32 Haverland.txt
"PRQC FSLETTER* Dave Chouiniere, Kaiser Permanente If not erased, several pages of DJDE.informa- pROC FSLETTER is a utility that allows you tion will be printed for each letter produced. to easily create customized form letters. These Affer hitting the END key, the catalog screen letters can be produced one at a time or in will reappear with the new form listed. batch. To alter a form, call the form up, make the The basic outline of a typical application changes, and type SAVE on the command line. is as follows: This will 'save the changes for the form. If you are changing a form and decidG not to save 1. Create a form containing: the changes, type ""CAN"" (for cancel) 0n the command line and the original form will not be a) text information altered. If you wish to create a -new form b) printing information which is almost identical to an existin'g for!fl, c) DJDE information type ""COPY formname"" on the command line and the old form will appear on the screen. You 2. Create the letter. may alter the form as desired. To delete a form altogether, type ''DEL FORM formname"" on the 3. Send (print) the letter. command line. The text and forms are stored in a SAS* The next step after creating a form is to catalog. After the catalog is created, letters create a l'etter. To create or edit a letter or forms can b~ created or manipulated through you must be on the catalog screen. Type ""EDlT PROC FSLETTER*. Letters can be sent either lettern-ame"" o~ the command line, and hit the through PROC FSEDIT* or PROC FSLETTER*. An ex- ENTER key. The letter name may be a maximum of ample of the format of the command to create a letter library is: 8 characters long. If the letter exists you can proceed to edit it. If you are creating a = EXAMPLE, NEW; RUN; new letter, you see a blank letter and a mes- PROC FSLETTER LETTER sage asking you to specify a form a description. Enter a description on the command line by tyv'- In the above command, ""EXAMPLE"" is the ing ""DES"" followed by a 40 character",Sugi-11-33 Chouiniere Permanente.txt
"A COMPUTER BASED MULTI-CURRENCY SHORT-TERM FUNDS MANAGEMENT EXERCISE ALEX ANCKONIE III, THE GEORGE WASHINGTON UNIVERSITY INTRODUCTION the need to integrate real-time multi- national financial and economic Efficient management of multi-currency information, actual- exchange rates and short-term assets and/or liabilities is actual 7 day Eurocurrency deposit yields an essential capability of any individual are used in the exercise. The exercise tye or institution operating in normally runs for about 10 class weeks, international economic arena. The allowing tim'e for effective iterative International Business Finance and learning while-allowing some time at the International Banking courses at most beginning of the course for introduction universities cover the problems of material essential to student associated with the management of short- participation in the Short-Term Funds term multi-currency portfolios of assets Exercise. prior to starting, the or liabilities. Whether the assets andl students are formed into ""management or liabilities in question are rnulti- groups"" for exercise purposes. A brief currency accounts receivable, accounts description of the two available payable, trade acceptances, marketable exercises follows. securities, purchased interbank funds or sold interbank funds, a number of The Asset Management Exercise similar fundamental concepts are required to be mastered to achieve In the asset management implementation acceptable levels of managerial of the Short-Term Funds Exercise, student competence. These important common management groups are informed that they ~lements of managerial understanding are responsible for the multi-currency lnclude mastery of the, integrated marketable securities portfoliO of a relationships which link (albeit in a large US dollar numeraire corporation stochastic manner) the set of exchange with the initial value of this portfolio rates and interest rates of concern to set at an arbitrary figure such as the speci~",Sugi-11-34 Anckonie.txt
"Supporting SAS Software on a PC Network Tom Culver, Appalachian State University SAS software that runs under PC DOS has The logistics of distributing this product in a site licence agreement of extreme disk storage and I/O activity 50 copies is mind boggling. To requirements. In order to run the SAS distribute the BASE and STAT product on BASE product with optimum performance, SAS recommends that you install the diskettes to 50 users, requires you to format and copy to 1.050 diskettes. software on a fixed disk that has at least 7M of free space. This keeps the This must be done each time a new version of the software is released and files from becoming fragmented when installed. The PC SAS BASE product since the product is leased yearly this duplication must be done at least once requires around 4 megabytes to store a year. Of course there are different the programs and libraries. ways to distribute the product. One The BASE product is distributed to might go to each user site and install users on 13 diskettes. The STAT product the product from one master set of diskettes. Tkis might be the best is distributed on 7 additional diskettes. The hard disk storage approach but would require a great deal requirement to store both the BASE and of someones time. In the case of widely STAT pToduct is over 5.5M. With other distributed sites this method might be products in the wings to be announced more expensive than duplicating the such as GRAPH, RTERM etc. these hard diskettes. disk storage requirements can only Because of the extreme hard disk grow. storage requirements and potential distribution problems for our projected The developers of PC SAS cannot be blamed for this. We must remember the 50 users s we decided to see what effect SAS product was originally developed to the PC SAS product would have on an be used on mainframes. The PC SAS existing PC, network on campus that utilized a campus wide broadband developers should be commended on the fact they have been abl",Sugi-11-35 Culver.txt
"four different people registered to call for ?C The technical support process provided by support. SAS Institute Inc. uses a wide variety of tools. This paper describes what those tools are and The SAS user is responsible for knowing who how they are used to provide efficient and his site representatives are and how to contact them. On most operating systems, submitting effective technical support. HELP SITEINFOi produces a synopsis of site information, including the names of the site representatives and how to contact them. INTRODUCTION The Institute Technical Support SAS Department defines technical support, in its DOCUMENTATION broadest sense, to be ""the Institute's obligation to ensure that its software products The Institute publishes a number of conform to published standards."" different types of user aids. Foremost among these are the Software Product manuals. The In order to acheive this goal the Institute manuals describe the products and explain how provides its users many tools. These fall into they work. Of course, every user should have immediate access to the manual for any product three main categories: he wants to use. Every major release of a software product will be accompanied by a 1) Documentation manual. Some manuals include sections about 2) Training generalized topics rather than just the 3) The Technical Support Department softw.are. For example i the SAS/ETS® User's Guide includes sections on time series data and modeling. These are general discussion",Sugi-11-36 Brumitt.txt
"Subsystem.s for Production of Version 5 Graphics Eric M. Klusman and Steven ]. Langford Federal Reserve Bank of Chicago GGXA, controlled via the mouse. The enhanced graph would then Abstract. be saved and played out on the department's slide camera device. Using the well·developed structure of ISPF dialogs and the spe- .iali.-.ed SAS interface functions provided by IlF, we have devel- Unfortunately, this subsystem had poor optical resolution; for ex- oped two interactive subsystems for producing SAS Version 5 ample, pie charts were tlot round, letters were jagged and uneven, graphics quickly and efficiently. With these subsystems, novice and so on. We intend to continue testing this method as new ver- sions of the componeI1t.~ hecome available in order to resolve the cumputer users can develop sophisticated graphs, and expert users can synergistically develop graphs per se and generate SAS code for quality problems. However, we have discontinued testing for now. ~ubsequent modification. We conLinue to de\dop new subsystems to incorporate new ideas and new products. Because of the increasing complexity of our graphics and our lim- ited success with GGXA, it became imperative to develop the fast- est, most efficient program development environment that wt' could. Disclaim.er. Tht: opinions and findings discussed below are those of the authors, Curre&t subsystetns. and do not reflect a position of the Federal Reserve Bank of Chicago or the Federal Reserve System. 'Ve use two subsystems of our present programming environment to develop presentation graphics. The need for quick. efficient subsystetns. That environment, called CERES, was written using three compo- nents: the SAS system; ISP:F, IBM's dialog management facility; Tlw authors (hereafter, 'we') are part of the technological support and IIF, an interface between SAS and ISPF, developed by group of the Economic Research department of the Federal Reserve Tangram Systems Corporation. SAS procedures and data steps",Sugi-11-37 Klusman Langford.txt
"MEASURING DATA VARIABILITY Fred Gehm SYNTEX Palo Alto, CA 94303 Much of statistical research consists of mea- has reasonably good default values, the values are virtually never optimal. Worse, itls hardly suring or estimating the properties of a given variable or variables. In many cases~ what we ever obvious what optimal values are. really want to know is not, say. what the mean Edge location is generally not a problem. In and standard deviation of a particular variable are but how that variable is distributed, and most real world situations at least one bin edge is important. For example, it may be im- estimators such as the mean and standard devia- portant to know what proportion of the popula- tion are only of value to the extent they help tion is larger than zero. Once one edge loca- us judge this. In almost all such cases, the best technique is simply to look at the data, tion has been decided the other edge locations that is, to use a histogram. PROC CHART and follow naturally. PROC GCHART provides us with the ability to plot histograms quickly and easily. Unfortu- Neither PROC CHART nor PROC GCHART allow you to nately, neither PRDC CHART's nor PROC GCHART'S specify and present the bin edges. Rather, they demand that the data be analyzed and pre- default values are the best, that is, they do sented by the midpoints of the bins. While in not a110w us to use all of the information in many cases, this is an inconvenience, it rarely our data. Fortunately, by doing some data step presents a serious problem. In my exper1ence, and macro programm1ng we can get all or almost in almost all cases PROC CHART and PROC GCHART all of the information the data possesses. midpoint selection default values are eminently Histograms are extremely powerful techniques reasonable. When they are not reasonable both the bin edges or midpoints and the number of for representing and analyzing distributions. bins must be changed. A histogram is a graph of vertical bars where the areas a",Sugi-11-38 Gehm.txt
"WHO MAPS? SAS has historically offered State and County boundary files for thematic mapping with There is no easy answer; it would be easier to SAS/GRAPH. Many SAS users want to map at finer say ""everybody can and many do"". One of the levels of geography~ and others are not obvious original mappers is the Bureau of the familiar with the benefits of mapping. An Census. Mappers include researchers. econo- extensive set of boundary files are available mists and analysts in government~ nonprofit from commercial sources which cah expand the institutions. academia and industry. More map analysis capabilities of SAS/GRAPH. An specific users are pointed out later. In overview of how a user would choose appropriate general~ anyone who has data containing geogra- boundaries to accomplish specific goals is phic information can benefit from displaying given. This paper presents a variety of that data in map form. examples of how SAS users from numerous public. private and nonprofit sectors have used SAS/GRAPH with commercially available boundary files to solve their problems.",Sugi-11-39 Farrington.txt
"VI SliAL n,FORMATI ON SYSTEMS C. David Hardison OV·JE?n Graduate 8'-'.·'001 of M anagemen t ') anderbilt University ~ J ~ackQr'ound HOl. . ; many times have yoU had to reKey data A good deal of investigation is being or pass it through temporary files with conducted in the areas of pictorial, several data manipulations to make i t spatial, and geographic information accessible to your graphics systeorn? How systems. Pictorial information systems often do you hear about hOl..v badl y data [1] j nvol ve tr,e appl i cat i on of database were graphically displayed in a principles to digitized images such as prEosE>ntao.tion? This paper- 11 rlc<p.;.fully \..'Ji from LANDSTAT satE'l 1 ite photographs and provide users as well as systems computed tomographic imagE'S from developers and information center medicine. Also, these systems typically knov..lledge v,lorkers IAli th .:o.mmuni tio!""! to taKe include tools for image analysis such as back to their workplaces that will assist pattl?r'n reccogni tion. Computer Assisted ,them in arguments for more and better Drafting/Design and Computer 'Aided USE'S r::.f gr·aphi.cs, in Ql?neral, and SAS, in Manufactur i ng (CAD/CAM) .:<.ppl j cat ion-=:. ar'e particul.:..r. Also, the fr'amework exa.mples of. spatial information systems di scussed, denoted visual i nformat i on [2] which are concerned with managing systems (VIS), should prou~de you wi th geometrical enti ties along v..1i th textual sc,me i dea.s about hOIA! to succl?ssful1 y specifications. Geographic information integrate graphics with existing systems [3] focus on the storage and production and decision support ~etrieval of cartogr-aphic data. The appl ications. Finally, the role of SAS thrust of the resl?arch in thesl? areas products in this environment is mentioned appl?.ar·s to be tOl""lards databa.st? relative to thl?ir current offerings along organization and binary representation 'AI! th somE' chall E'nges for· ttl>? futur·e. rather than implementation and contro",Sugi-11-40 Hardison.txt
"CREATIVE USES OF STANDARD GRAPHICS PACKAGES Julie A. LaBarr, Eastman Kodak Company ConveJt...t.tng a manu.a£. opvr..alion -tn:to a c..omputvUze.d INTRODUCTION one. Standard graphics packages provide the building blocks for displaying data. Often the way a TRILINEAR PLOTS: Areas that work with color package would conveniently display your data is films use trilinear plots to look at the balance not exactly the way you want it. With some effort, between the three primary colors red, green, and you can make these packages produce the plot you blue. This is not a new technique to Kodak. It want. There are several considerations that must has simply been performed by hand in the past. be made to determine the feasibility of this Because of the widespread use of this technique effort. This paper discusses these considerations and the considerable amount of labor hours that and gives examples of programs written at Eastman would be saved with a computerized approach, we Kodak Company that make graphics packages do created a SAS(R) (1) procedure using the DISSPLA ""more"", (R) (2) graphics package to generate these plots. Once the plot program is written, it needs to The following is an example of a typical hand- drawn trilinear plot: be accessible by end-users. User interfaces pro- vide this accessibility. This paper also discusses Simulated r.ata several user interfaces written at Kodak. v __ ~.__~~~~__~__~~~ Hmrl""r_ PloC GRAPHICS PACKAGES - Producing the Plots YOU Want Graphics packages vary in sophistication, ease of use, and capabilities. A package that offers ""user-friendliness!! may have a limited selection of plot types (e.g. line graphs, barcharts) or limited enhancement capabilities (e.g. control of colors, line patterns, etc.). More sophisticated packages require more programming expertise. A problem arises when you have an application that does not fit the graphics package. You start with an idea or a need. You inves- tigate what package is appropriate for your a",Sugi-11-41 LaBarr.txt
"Using AXIS and LEGEND Statements Jack Bulkley SAS Institute Inc. INTRODUCTION and in the legend. Notice the H= option that increases the size of the text to help make it The AXIS and LEGEND statements allow users to more readable. control many aspects of their graphs in Version 5 of SASiGRAPH® software. The examples in CONTROLLING COLORS this paper illustrate some of the main features. Users should be able to adapt some of the There are several ways to specify the colors of following examples to meet their own needs. text and other parts of an axis and legend. The general rule of which color takes precedence is DEFINITIONS that a color refering to a more specfic part of the graph overrides a more general color. For In this paper parts of legends and axes are instance, on an AXIS statement the COLOR= described with the following terminology. See option is the most general. The CTEXT= or Figure 1 for some examples. CAXIS= options from the PLOT (etc.) statement are more specific and therefore override COLOR= Value when they are specified. An even more specific The text associated with a value of the color specification is to use the C= option in the variable represented on the axis or VALUE= or LABEL= options of the AXIS legend. statement. So specifying: Label PROC GPLOT; The text associated with the name of AXISl COLOR=BLACK the variable represented on the axis or LABEL=(C=RED) ; legend. Major tick mark PLOT Y*X / CTEXT=BLUE a mark along an axis associated with a HAXIS=AXISl VAXIS=AXIS1; value. would cause all of the axis to be BLACK Minor tick mark (COLOR=BLACK) except for the text which would a mark between major tick marks. be BLUE (CTEXT=BLUE) except for the labels Offset which would be RED (VALUE=(C=RED)). distance between the fi rst or last major tick mark and the end of the axis line. USING QUOTED STRINGS Axis line the line running the length of the axis. Quoted strings can be used in the VALUE= and The tick marks are perpendicular to LABEL= options of the AXI",Sugi-11-44 Bulkley.txt
"Using the DATASYS Option of PROC GANNO Jade Walker SAS I nstitute Inc. The Annotate facility certain area of the graph. The three major frameworks on which to build a graph are the axis area, the page window, and the plot window. The axis area is the area lying within the axes if The options specific to a SAS/GRAPH® procedure the FRAME::: option were used (Fig G). Annotation do not always document the graph as thoroughly performed in this area is usually dependent on as you may want. Annotation is a means of the data used in the graphics procedure. The customizing a graph to meet your needs. For page window refers to the entire graphics area of example, in this gra'phic produced by PROe the device (Fig 7). The BORDER GOPTION or GCHART with the VBAR statement, the data PROC GSLIDE with the BORDER option shows the values are represented only by the vertical bars range of the page window. The plot window (Fig 1). For those in your audience who prefer refers to the entire graphics area of the device except for the space required for TITLEs and to see numeric representation, you can use the FOOTNOTEs (Fig 8). Note that the plot window LABEL annotate function to add the numbers onto is a subset of the page window, and the axis area each bar. (Fig 2). is a subset of the plot window (Fig 9). Annotation can be either simple or complex and In using annotation, the XSYS, YSYS, and HSYS can appear either on its own as with PROe annotate parameters describe the system of GANNO or PROC GSLI DE, or with a graphics annotation. The method of the system can be procedure such as PROe GCHART or PROe GPLOT. It can place text, lines, or shapes at absolute or relative. The viewports which can be used by annotation are the screen (page your discretion through the use of annotate wi ndow), the Window (plot wi ndow), or the data functions. Annotating a graph adds emphasis area (axis area). The window scales which can be where you want it according to your standards of used are in percentage",Sugi-11-45 Walker.txt
The user-friendliness ot SAS FSEDIT and THE eLIST (Figure 2) initially clears the data manipulation features ot the files previously created by the system SAS base product coupled with 082. a and allocates several old and new re lational database product. are tool s datasets. Print tile destinations are utilized to collect and retrieve data. specified and a- message is displayed to Features ot the system provide data the u~er while SAS Is invoked and the consistency and control in conjunction main program executed. with a transparent and powerful data management tool.,Sugi-11-46 Calabro.txt
"DEVELOPMENT OF A MENU-DRIVEN SYSTEM FOR SOFTWARE ACCEPTANCE TESTING Patricia L. Berryman SAS Institute Inc. The Challenge to an existing entry. If not, an entry is added to The challenge was to develop a systematic the data set. Browsing and updating of the approach to software-acceptance testing for problem-tracking data set is accomplished SAS/FSP®, SASI AF®, and SAS/DMP' software. through the SAS/FSP procedures FSEDIT and These full-screen, interactive procedures do not FSBROWSE. An FSEDIT modified screen is used readily conform to standard or conventional to aid in data entry. testing methods; they generate minimal output, and testing needs to be carried out in an interactive environment. A different approach to Report generation from any entry in the tracking software testing from that used for conventional data set is provided by the link between the SAS/FSP procedures FSEDIT and FSLETTER. A software evaluation was needed to accommodate the interactive and highly visual nature of these letter in an FSLETTER catalog was designed to procedures. allow FSEDIT to fill in the fields and produce a report. Once in FSEDIT or FSBROWSE, the observation you want to print a report of is What is Needed in a Testing Facility? located. Now, enter the SEND command followed Software-acceptance testing needs to be by the name of the letter. The values from that systematic in its approach. That is, it needs to observation are substituted within the pre- be orderly and to follow a plan. The testing designed letter. You can now make changes and facility should ensure that all procedures work as print the report. documented and that all screens and panels are displayed and function properly. Documentation and supporting material must be checked for Through the use of a SAS/AF program screen, accuracy and clarity. Full-screen Help files, subsetting of the data set on various criteria was tutorials, and examples must also be examined implemented. Using criteria entered on the user an",Sugi-11-47 Berryman.txt
"ION MENU: ABSTRACT: The SAS Menu is first presented to the One of the goals of the Information SAS/AF was incorporated in the user. Center is to make the' software as existing ISPF menu with all the other user-friendly as possible. with the SAS functions. Please note option IIA"". advent of SAS/AF, a user-friendly menu/screen dialog system is now available for end-users. But, what SDDPC ---------- SAS MENU -- (VERSION 5) ----------------- SELECT OPTION ..... > about the person, many times an end- USERID _ TSOSJCL user also, who is chosen to write the New options with version 5 PREFIX - TSOJCL SAS/AF application. This end-user .. A AF - SAS/AF screen generation' testing facility .. C CONVE!l.T - convert screen/spread/letter to Ver S format writer has to learn the new SAS/AF menu SAS da~a definition and data entry (edit) D DATA - E EXEC - SAS program edit (SPF) and execute and screen language as well as test it. G GRAPH - SAS 'graphs and replay of saved 5AS graphs This paper addresses the streamlining .. L LETTE!I. - SAS letter editing and printing P PLAY - SAS replay of saved SAS graphs of the SAS/AF screen generation and !I. REPO!l.T - SAS report generation S SPREAD - SAS spread sheet It uses a series of testing process. T TSOU'I'J:L - TSO utilities only U UTILI'l'Y - SAS utilities - variables - add/delete/rename/modify SAS/AF menus and screens to drive the Data Sets - copy/display/rename/sort building and displaying of end-user Libraries - copy I create/reorganize Z ZcoPY - C",Sugi-11-48 Lind.txt
"A review was made of the evolu tion A note of intere st is the SAS system of a payro ll accou nting applic ation from as instal led at SDDPC is invoke d via a gener alized menu- driven SAS® system to ISPF dialog ues that enhanc e the SAS PRoe FSCALC to the planne d conve rsion system . This facili ty provid s them with A user writte n Feder al and menus and screen s where fill-i n to SAS/AF ®. State withho lding tax compu tation was param eters gener ate SAS code used to origin ally design ed to use FSEDIT and per.for m such basic tasks as creati ng 1 The applic ation was SAS datas ets, repor ts, and graph s. SAS DATA steps. The major ity of our users are busine ss later migra ted to FSCALC when that profe ssiona ls, and are intere sted in The produ ct became availa ble. instal lation of SAS/AF with Versio n 5 immed iate resul ts, not proce sses; they will allow furthe r upgrad ing of the are not traine d to write ISPF dialog ues applic ation opera ting under that and their poten tial intera ctions with produ ct, with antici pated benef its to SASe We expec t our innov ative and profic ient SAS users to use the SAS/AF the user depart ment. produ ct.",Sugi-11-49 Patterson.txt
"users that benefits are clear, the users become will permit them to create report speci- self-sufficient, which reduces the fications and produce reports using an growing backlog of requests for new approach that is independent from the systems and reporting on existing host languages or data base managers. systems. The number of programmers This approach offers isolation from developing and maintaining systems in fourth generation languages and permits the last decade will be small compared organizations to change their corporate to the number of users that will be data base manager or 4GL with no impact involved with this responsibility in the 80's. This fact, combined with the on the end users ie. program conversion, etc. since the report ~pecifications are proliferation of end user languages in stored in an independent form. Using corporations, may cause serious problems this method users can access corporate in the future. The job of converting data using a common dialogue independent from one data base manager or fourth of the physical data structures ie. generation language to another may prove Tape, Relational Data Bases and Fourth to he a very large or impossihle task. Generation Data Bases all appear the Tbe conversion is sometimes necessitated same. by evolving technology, husiness requirements etc. The second objective of this system was to develop a computer/user interface The ohjective of this paper is to that was completely syntax free thus the propose a method",Sugi-11-50 McSheffrey.txt
"INSURANCE INDUSTRY FINANC IAL DATA - DEVELOPMENT, ANALYSIS AND PRODUCTION Rober t R. Loren tzen, A.M. Best Compan y The Data Servic es group of the A. M. Best to arrive at a rating for the compan y. Compan y has used the SAS* system to de- The rating is presen ted to the compan y velop produ cts, analyz e data and suppo rt to make sure that no inform ation was produ ction of severa l insura nce data or- overlo oked. The rating is then publis h- iented produ cts and servic es. This paper ed. will descri be some of the experi ences in using base SAS softwa re by presen ting When the databa se is compl ete the many severa l examp les of this use. For the data-o riente d produ cts can be produc ed most part, these are not very sophi sti- and releas ed. cated examp les (some excep tions) and this will not be a highly techn ical disse rta- DATA SERVIC ES tion on the use of SASe Still, they are intere sting and repres ent a variet y of The Data Servic es depart ment is respon - applic ations which illust rate how easy i t sible for the compu ter suppo rt for many is to use base SAS softwa re in severa l of these produ cts. Organ izatio nally the real world applic ations . depart ment consi sts of a progra mming group and a group of applic ations ana- BACKGROUND - A. M. BEST CO. lysts. The progra mming group provid es and suppo rts much of the softwa re used The A. M. Best Compan y serves the Insur- by the analy sts. ance indus try and the Insura nce marke t- place. It maint ains the most compr ehen- The progra mming group uses a mix of FOR- sive databa se on approx imatel y 3500 In- TRAN, COBOL, and PL/I. The Data Ser- suranc e compa nies in the U.S. and Canada vices analy sts corne from a variet y of and within the last few years has been educa tional backgr ounds, such as busi- adding Europe an compa nies also. The ness, mathe matics , statis tics, compu ter, compan y began busine ss in 1899 and is philos ophy and teachi ng to name a few. now locate d in Oldwic k, New J",Sugi-11-51 Lorentzen.txt
"THE CREATION OF AN INFORMATION CENTER TO REPLACE A PAPER DISTRIBUTION PROCESS Margaret F. Moschetto~ Satellite Business Systems Introduction at headquarters and the U.S. Post Office was The Service Quality Analysis department used for the deployed field sites. This of Satellite Business Systems has the respon- distribution method meant a site could sibility of measuring the performance of our receive a report one to one and a half weeks satellite communication system. The perform- late. In addition, our reports were not even ance measurement process has evolved from run until all databases were completely simple manual calculations by two people 'and updated and verified - up to ten days after a a calculator into numerous SAS batch reports month was completed. Field sites were and charts. The importance of these reports receiving their weekly reports for data up to was recognized by upper management for twenty days old. When the report is received maintaining and improving the quality of this late it becomes a Ureport card"" rather service provided to our customers. As the than a tool to help solve problems. In order data became more accessible, every Manager for the information in the reports to be used wanted a report to suit his own need re- by the Field Engineers to fix problems before sulting in more and more different sorts of they became customer affecting, a solution to the exis~ing data and the development of new the time for distribution was needed. lnformatlon from the data. This increase ~aused the need to standardize all reporting In addition, many ~lanagers \I/ould con- 1n a way that every user would be satisfied stantly phone Service Quality Analysis for The hierarchical reporting structure that w~s the numbers prior to the receipt of their developed is as follows: reports from the existing distribution system. As Service Qual ity Analysis de- veloped new measurements, Service Quality COMPANY Analysis personnel received calls asking how it computed th",Sugi-11-52 Moschetto.txt
"GENERALIZED INFORMATION REQUIREMENTS OF INTELLIGENT DECISION-MAKING SYSTEMS Paul J. Werbos, Energy Information Administration a Expert systems use domain-dependent rules (often with some limited intelli- Before getting into the substance of gence) to respond to very specialized this talk, I will begin by defining exactly requests. what I mean by an intelligent system. Next, I will talk brief1YRabout the a~p1icati~ns of However, there are also some similari- this concept to SAS , to human lnformatlon ties: needs. and the like. The first major section of this talk will describe a basic 3-compo- o Initial conditions (prior knowledge) nent intelligent system which could be can be inserted into any intelligent implemented in SAS. The final section will system. describe the kinds of information needed in o Intelligent systems can learn to com- more sophisticated systems. like the human brain or human organizations; it will begin municate, and might even be designed with a capability to exchange knowledge with an intuitive overview aimed at a non- technical audience, and conclude with some of directly. the mathematical and physiological concepts which under1y the intuition (with citations). WHAT APPLICATIONS DOES THE IDEA HAVE? WHAT IS AN INTELLIGENT SYSTEM? The theory of intelligent systems can shed light on five important questions: ll I define an lIintelligent system as a generalized system able to maximize some o To the extent that humans are intelli- measure of success over the long-term in an gent systems, what are the basic, un- uncertain, non-linear environment which it varying components of human thought must learn to adapt to in an open-mided way. and brain dynamics? This definition could apply, in principle, to systems made up of equations in a software a How can groups of humans such as package or to networks of microchips, nerve companies or governments become more cells, ectoplasm, or anything else. The key intelligent, more effective in words in this defini",Sugi-11-53 Werbos.txt
"A Consumer Credit Portfolio Trend Analysis System in the Information Center Environment Marshall Costantino, Citicorp Retail Services, Inc. Richard D. Heberlee, Citicorp Retail Services, Inc. INTRODUCTION Citicorp businesses have experienced a need for a Portfolio Monitoring System to assess This paper is the summary of a Cumulative the underlying dynamics of consumer credit portfolios. A mechanism to provide a con- Sums methodology application to Consumer Credit Portfolio management. A complete cise, consistent set of signals was required to control and manage the consumer credit monitoring, control and forecasting system portfolios. In each case, the following has been implemented in the Information Center environment to support credit policy, issues needed to be addressed: treasury, operational, and processing sys- The net revenue growth rate(s). tems capacity planning decisions. The portfolio growth rate(s). The Portfolio Monitoring System consists of The portfolio aging category growth several DATA steps with several PLOT AND rate(s) · MEANS procedures from the standard base SAS* The write-off growth rate(s). software package as well as several ARIMA When the growth rate(s) changed. procedures from the SAS* ETS software pack- The extent to which the growth rate(s) age. The system requires financial and changed. workload input by a user with minimal back- The implications of the timing and extent ground in data processing and in statistics. of growth rate change(s) on funding re- The program is run wi th output in the form quirements. of plots, revised funding and workload equa- The implications of the timing and extent tions and operations control limits for de- of growth rate change(s) on operational cision making and planning efforts. Using workload requirements. the output, interpretation is straightfor- The implications of the timing and extent of growth rate change(s) on processing ward. This sys tem has been in use since 1981 in several Citicorp domestic",Sugi-11-54 Costantino Heberlee.txt
"ly and Company For these reasons the question at Eli Ully has ABSTRACT not been: Do we need to collect detailed process variable information? Rather, it has An OS/MVS interactive system combining SAs/AF~, been: How do we collect and organize this SAS/FSP®, and SAS macros has information? SAS 1982 software proVided a been developed to aid pharmaceutical produc- partial answer to the question. With its use tion data analysis at Eli Lilly and Company. the scientist no longer had to physically Users with no prior SAS experience can easily maintain (collect, analyze, file, and retrieve) enter and/or extract production data and the process log sheets. Instead, process related Information. variable information could be extracted from the production run (a lot) and be easily The core of the system is built around SAsl AF Menu and Program screens. In addi- entered into a SAS library using FSEDIT. tion, many of the data-entering and system SUbsequently, the data could be analyzed using other SAS supplied procedures. functions requiring user input are presented Reaching this analysis phase, however, still using SAs/FSEDIT screens. Each screen, remained difficult. That is, the user was whether AF or FSP based, is designed in a able to find quick and simple answers to similar format to hasten the user's system questions concerning the use of the specific familiarity. Finally, a majority of the back- SAS procedures; however, it was much more ground system work is performed using SAS macros",Sugi-11-55 Sauer Allee.txt
"SELF SERVE SYSTEM Enio Presutto, York University, Canada INTRODUCTION paging and report layout controlled via the BY statement. Once the fourth menu was completed Self Serve is a computer system developed at the SAS program was created using the York University to assist in the production of information provided and prepared for submission reports as required by the university executive for processing in the batch environment. to assist them in the decision making process. Its initial development was in response to the The fifth menu would present the default job need to provide information quickly to the control information. which would be suitable for senior administrators. As its name suggests. most programs. However. as the user grew more Self Serve is intended for use by those who may experienced they could alter the settings to have little to no computer programming suit their requirements. The information expertise. One of the primary benefits of this presented on this screen would consist of job system is that it provides the end user with a control information. routing information. name certain amount of freedom from the traditional of the database to be accessed and most dependency on systems analysts and programmers. importantly the title to be included as part of the report. Once the ENTER key was pressed the SAS program would be submitted for processing. SYSTEI! OVERVIEW Once ready, the output could be viewed at the terminal using the Roscoe output facility or The initial version of Self Serve was simply printed on the line-printer and picked up implemented using the Roscoe RPF language and of later. course SAS. Five menus as described in detail below, were developed to assist the user in building SAS programs which in turn were This version of Self Serve was quite primitive submitted for processing in the MVS batch and limited in its flexibility. However, it did environment. These SAS programs would access permit reports to be produced quickly and SAS",Sugi-11-56 Presutto.txt
"A COMPUTERIZED SYSTEM FOR THE PREPARAT10N OF DATA ENTRY INSTRUCTIONS Ruth F. Quah, Stuart Pharmaceuticals, Division of leI Americas, Inc. 3) SAS/AF menu-driven facility which serves A computerized system for creating and as a link between com~onents (1) and (2) maintaining Data Entry Instructions has been in order to execute the FSCALC program for developed in SAS®, using SAS FSCALC and a specified module name, and then store SI\S/1IF""'. the resulting values in the ""0. MODULES "" data set. 4) Ability to print Data Entry Instructions Background from the ""D.MODULES"" data set. At Stuart Pharmaceuticals data from 5) Ability to create SAS INPUT statements clinical trial Case Report Forms are from the nD,MODULES"" data set. computerized into SAS data sets from aD-column TSO records. These TSO records are punched by Corporate Data Entry according to a set of Details of the System l~structions provided by the Clinical Systems 1) FSCALC Screen and Program Analyst. Manual techniques available for the Figure 2 illustrates the FSCALC screen creation of data entry instructions include: used for entry of data entry instruction 1) Writing directly onto a Data Entry information. The user fills in entries in the Instruction form coltunns titled ""NAME"", ""DESCRIBE"", ""TYPE"", and 2) Typing directly onto a Data Entry ""COLSH. When ready to calculate the coltunn Instruction form allocations, the last row name is changed to 3) Storing in and printing out from a Word ""LAST"", and ""RUN TEST.PGM II is typed into the Processing document command line. At this point, the user can 4) Storing in and printing out from a TSO continue to modify coltunn allocations as file. needed. Once satisfied, the user can return to DEFINE mode to change the row named ""LAST"" This paper describes a new computerized to the appropriate ITEM number name, and can system for creating and maintaining data entry then save the data entry information with an instructions. Included in the discussion are output statement: ""OUTPU",Sugi-11-57 Quah.txt
"tch? This paper covers using the FSCALC procedure, a feature of SAS/FSP® software, in batch mode. There are many macro variables available that are I neluded is a guideline of when and how to set up extremely handy for batch processing. Pages a batch FSCALC job. Also covered is a 164-166 of the SASjFSP® User's Guide Version 5 description of how to set up a spreadsheet to be Edition documents the macro variables for use used for calculations and sending reports. Using with the new spreadsheet specification screen, the special macro variables associated with some the old spreadsheet specification screen, the of the screens, such as the FETCH screen, to FETCH, CLEAR, INSERT, CONSOLIDATE, and facilitate working in a batch environment is also REPEAT command screens. These macro discussed. variables allow you to define values for the screens before the commands to execute the screens are pushed to the command line. When When should you use FSCALC in batch? you issue a command in batch FSCALC, keep in mind that you are actually going to the screen that the command calls up. For instance, You should consider using FSCALC .in batch suppose you want issue the REPEAT command when you have a job that must be done from the program. You are placed in the repetitively over small periods of time. For REPEAT command screen and must push an END instance, you would probably want to set up command. to leave it. While you are creating the batch execution of FSCALC because you need to consolidate",Sugi-11-58 McAlister.txt
"formation as a corporate asset and a competitive tool. A Integrating the diversity of great strategic potential is software and databases located available for those able to on mainframe and personal com- plan and schedule events. For puters is a major problem con- the others ~ the outcome is fronting many companies as they Ie often not as bright. The attempt to implement a success- that fails to look beyond today ful Information Center (IC). The Ie concept consists of a is wounded from the start. Lana hours plagued with count- department which provides less user problems stagnate any techn i ca 1 support."" educa t i on. signs of progress to a stand- consistent and transparent still. A question often asked access to data~ micro to main- by non-Ie people is whether the frame and mainframe to micro Ie concept will exist tomorrow. links? user computing tools and One can only speculate on what accessibility to computer tomorrow will bring. But one systems. The single greatest thing seems certain~ that the challenge facing the Ie depends Ie failing to look at the needs on its ability to provide of tomorrow will experience a responsive user support while significant loss of momentum integrating the diversity of software and databases. This and possibly failure in meeting paper ill ustrates a strategy the needs of the organization (2) for integrat inq SYSTEM 2000 (R) DBMS and SAS {R) software to assist in the task of managing the company resource, informa- CONTROL OF DATA tion. An area dear to the hearts of every IC and user is the issue",Sugi-11-59 Lafler Kirchman.txt
"size and error rate estimate and the other fields sam- An interactive SAS® based system was developed by the ple size and error rate estimate. No useful information data compliance group in the Biostatistics and Clinical about the kinds of errors found was derived, nor was the Information Processing (BIOCLIP) department to cal- information stored in a way that allowed summarization culate and track data processing error rates for clinical across studies or by other variables of interest. trial data. This system permits tracking and reporting of error rate information across project, study, or form type. In addition to saving time and improving accuracy The system as compared to previous hand-calculation methods, the The system consists of an online component in system provides detailed feedback on pre- and post-QA SAS/FSP® run via CLISTs (execute files of TSO com- error rates to data processing management. mands) , an archive SAS file of error counts and de- rived error rate estimates, a partitioned data set of SAS Background code, a format library, automatic report generation, and report-generating capability in batch mode. The BIOCLIP department is responsible for the data processing and statistical analysis of clinical trial data Input error counts at Synrex Research. The department consists of a data processing group that is responsible for data entry, a A transaction file is created and edited via SAS/FSP small data compliance group that reviews the data for using two sc",Sugi-11-60 Ozer Gilkerson.txt
"~' SPARES - An Interactive Estimating System Using SAS Software, CLISTs, ISPF, and COBOL Pamela Suchoski, General Dynamics - OSO Western Center Dan,Magnuson, General Dynamics - DSD Western Center The first step in the SPARES Clist is to allocate the CLIST libraries needed for INTRODUCTION the different options. SPARES is an interactive system using PROC a SAS Software, ISPF, CLIST; a.nd COBOL. In designing the SPARES System we had a list of SET RELEASE = &STR(SAS508) /*----------------------------------------*/ customer requirements. These requirements /* ALLOCATE CLIST LIBRARIES */ were: The system had to be interactive, /*----------------------------------------*/ reports were needed, both online and FREE F(SYSPROC) hardcopy, the system had to automatically ALLOC F(SYSPROC) OA(' SPARES.CLIST' generate letters, and the system had to be + 'SYSl.CLIST' completed in a six month timeframe. For + '&SYSUIO .. CLIST') SHR these reasons SAS Software was chosen as the primary software tool, but due to some of the shortcomings of SAS Software: No more A condition code is checked. The condition code serves two purposes: first, it checks than one observation per screen and multiple users cannot update the SAS data library at to see if the allocation took place, and one time, ISPF panels and tables were chosen second. 'it checks to see if the user is and CLIST was chosen as the driver of ISPF. valid. If the condition code is greater COBOL programs are used to unload the than zero, the allocation did not take place information from the ISPF table to a flat and the user is not authorized to use the system. Each of our libraries is ACF(Access file so that SAS can read the file for Control Facility) protected. If the user updates to the SAS data library. COBOL is also used to load SAS generated files to needs access to the system then we change the ACF rules to. include that user. update ISPF tables. IF &LASTCC GT 0 THEN + 00 SYSTEM OVERVIEW WRITE ******************************* *",Sugi-11-61 Suchoski Magnuson.txt
"A Simple Documentation Indexing System James M. DeYoung, Jr., Duke Power Company Gwendolyn 8. Crawford, Duke Power Company Reina 8. Cobb, Duke Power Company BACKGROUND After some preliminary design and testing a ""document block"" layout was Duke Power Company is an investor developed. This is simply a structured owned public utility with headquarters in group of comment lines that either begins Charlotte, North Carolina. The Real each program or follows the job card in Estate Division of the Transmission our JCL statements. (see Figure 1.) An Department acquires rights of way and excellent source for information on using land for company operations and manages comments for documentation is ""SOME corporate real estate that is not GUIDELINES FOR DOCUMENTING SAS SOURCE allocated to specific utility operations CODE"" by Scott L. McGregor and Mary such as generating stations, line rights Nelson in the 1983 SUGI Proceedings of way, substations, etc. Although supported by a large information center, One of the features of our system is some applications unique to division that the format of the document block is operations are programmed and maintained easily read by an individual as well as within the division. It by the documentation program. the displays most important and PROBLEM identifying elements of the program which are: The need for a more efficient method of documenting division computer 1. The Program Name (PDS member name) applications became apparent when additional personnel were introduced to 2. A brief description of the program the area. Previously, the system was utilized by only one programmer. With a 3. Identification of related JCl, small number of applications, this Clists, prograrn$, SAS library programmer relied in large part on memory members and stored formats to find the documentation of applications when needed. The increase in personnel 4. Identification of the application combined with the increasing number of and physical location of written",Sugi-11-62 DeYoung Crawford Cobb.txt
"A SAS PROCEDURE USED AS A DBMS UPDATE MACHINE Linda A. Smith, ORI, Inc. Another interface used by this procedure is This paper describes a SAS procedure. written in to the data dictionary maintained by CPCS. This PL/I. that was developed as an update machine dictionary defines the RAPID data base. At for the Consumer Price and Consumption Studies compil e time the procedure inc1 udes Pl/I code (CPCS) Branch of the Bureau of Labor from the data dictionary system. This code Stat; sti cs. Thi s procedure updates a fi 1e enables retrieval of dictionary information by stored as a relation in the RAPID Data Base means of a hashing function. This interface Management System. The input transaction verifies that the RELN (relation) specified by records are stored in a SAS data set. The the user is in the data base. It also obtains procedure is executed in one of three mutually- the variables in the RAPID relation and the exclusive update modes: ADD. for adding rows attributes of each variable includiM its null (records) to a RAPID relation; DELETE. for deleting rows; and CHANGE for modifying the or default value, editing criteria, alias values of variables on existing rows. The variable name, and the value to use if it is to procedure is also executed in one of four be recoded. incremental levels of processing: SCAN, for The interface to this dictionary is also scanning the userls PROC UPDATE statement; EDIT~ used to obtain user-defined hierarchical for scanning and then editing the user's SAS relationships among relations in a RAPID data variables; TEST, for scanning~ editing~ and base. A relation can be defined to be ""parent"" accessing RAPID rows; and UPDATE, for scanning~ to another. or a relation can have Ilchild"" editing, testing and actually updating the RAPID relations. To maintain the integrity of these relation. The user specifies the name of the RAPID relation (RELN=), the update mode and the relationships, th~ procedure performs additions level of processing as t",Sugi-11-63 Smith.txt
"BUD..DING EFFICIENT AND EASY-TO-USE INFORMATION SYSTEMS OR WHAT SYSTEM SHOULD AN INFORMATION CENTER HAVE? Jim DeFoor Fort Worth Division General Dynamics Introduction B. They don't fulfill the user's purpose. I. This paper attempts to prescribe the best system C. They're too difficult to learn or else quickly (method) for generating information systems. Since become restrictive and time-consuming in the function of an information center is to encourage, their operation. train, and outfit users for their information tasks, the center and its users form a process for generating information systems. Implicitly, at least, therefore, IV. Why Do Those Problems Exist? this paper defines the best system for the information center. That system will be ""Intelligent"", as Dr. Paul A. Because the process used to create the J. Werbos describes in his paper, ""G~neralized Infor- system is inappropriate. It's meant for mation Requirements of Intelligent Decision-Making systems for which the user's requirements Systems'"" found elsewhere in the 1986 proceedings. It can be specified in fine detail before design wi1l be a generalized system able to maximize some and coding begins [4, PP. 45-541. Such measure of success over the long-term in an uncertain systems are very structured. They usually environment to which it must learn to adapt in an open-minded way. In this paper that is interpreted to 1. Involve a single subject, such as inven- mean the system of the information center must be tory, which provides a clear though, capable of generating widely diverse information sys- often, narrow focus and a common tems while maximizing the user's computer skills and terminology. task knowledge, minimizing formal training, and 2. Use very specific types and forms of adapting easily to changes in requirements. data. 3. Have developed explicit and widely-ac- The paper's approach is conceptual and deduc- cepted guidelines for the selection and It examines the intrinsic method by which tive. ap",Sugi-11-64 DeFoor.txt
"ow, or within the normal range for that laboratory test), units, or range respec- When summarizing human safety data for new drug tively. For example. red blood count labora- applications in the U.S. and foreign countries tory test values and corresponding status flag, it is necessary to pool laboratory dat~ across units, and range would be named RBC, RBCQ, all studies conducted with the new drug. Data RBCU, and RBCR respectively. management in clinical trials ;s complicated by the fact that multiple service laboratories are The input program that creates the SAS labora- tory data file reads these laboratory data re- used, even with1n each study. In addition. these laboratories often do not have the same cords. A separate SAS file consisting of demo- normal ranges and may even report the same lab- graphic data is accessed to retrieve service oratory test results in terms of different laboratory, age. sex and the date when a pa- units. Manipulation of safety data can be sim- tient began participation in the study (base- plified by the organization of SAS laboratory line). Percentage change from baseline for data files into individual records identified each laboratory test value is calculated and by study. service laboratory, patient 10 and output to the SAS laboratory data file as well, visit date. Summarization or tabulation of the following the previously discussed laboratory data may be performed by concatenating the ap- data valUe naming convention (i.e., <testname> propr",Sugi-11-65 Bogardus Pennelly.txt
"COMPUTERIZED CLINICAL DATA BANK NETWORKS Christine l. Wolf~ National Institutes of Health Bruce Guthrie? U.S. Department of Commerce Each data bank network involves four Introduction: A fair number of computerized clinical data university-based hospitals operating under NIH bases use two or more computer languages; the contract. which are geographically dispersed first language accesses the raw data and throughout the United States. These networks generates _subsets of it, whi Ie the second are implemented by multidisciplinary teams of language is necessary to present sometimes physicians (neurologists and neurosurgeons), complex statistical analyses of that data nurses, behavioral scientists. neuropsychologists, computer experts, subset. ""User friendly"" data base management statisticians. and epidemiologists. All languages will often write out some of the code collaborat~d on all aspects of the study, from necessary to run the other language for you. But more frequently the user is faced with research design through data analysis. Research learning both the retrieval and statistical issues, clinical and laboratory data to be languages before seeing any results. collected, uniform data collection forms that In the base network created to study stroke incorporate operational definitions. and common and traumatic coma patients, this norm was data collection protocol were developed.and are broken. Users are asked to learn the basics of in use at each collaborating hospital. just one language: the SAS® language. The Data entry: Micro Computers: data bases are both stored in SAS System files and accessed through the SAS language, allowing The data bank networks' computer system users relatively efficient processing charges includes a Datapoint 1800 microcomputer at each (as compared to rereading the subsets in the SAS hospital, the NIH NINCDS Datapoint Polling language each time) and an easier system to Center, and the mainframe host system at NIH learn. (see Figure 1).",Sugi-11-66 Wolf Guthrie.txt
"A SAS/AF SOFTWARE BASED CLINICAL DATA REVIEW SYSTEM Richard E. Raftery, Syntex Research Martin J. Rosenberg, Syntex Research James F. Sattler, Syntex Research Prior to the SAS/AF based Clinical Introduction Data Review System, there was no efficient way .for many monitors to This paper is a progress report access the clinical data base. Providing which describes how a clinical such access would have involved a information system was developed and prohibitive amount of programming approved at SYNTEX Corporation. The resources. A new approach to data system is inten'ded to ma'ke medical processing was required. research data available to monitors of The Bioanalysis Department. the clinical studt'es. The theme presented major SAS user at SYNTEX, had an idea. here is how this was accomplished at By using SAS/AF to develop a prototype. SYNTEK using not only SAS/AF, but also the feasibility of such a system could the sample menu system software be demonstrated to upper management. provided with SAS/AF. By modifying the This would be done with a minimum o.f sample menu system software, i t was strain on the department's programming possible to develop a Clinical Data resources. such a demonstration If Review System prototype, and to gain succeeded, the department would probably approval for further development. This get the go ahead for development o£ a was accomplished with a minimum of £u11-sca1e Clinical Data Review System. programming time and effort. The The SAS/AF sample menu system would rationale for using SAS/AF software at be an essential component of the SYNTEX is that it provides the prototype Clinical' Data Review System. programming leverage to serve numerous By modifying and adding to the SAS/AF end users of cli-nical data. During the sample menu system it would be possible coming year, the system will evolve into to develop a prototype Clinical Data 'a full-scale production version. Review System with a mi'nimum of programming time and effort. Background H",Sugi-11-67 Raftery Rosenberg Sattler.txt
"ems have been The EMIS data base is a SAS data set developed at the U.S. Department of Agri- on disk. It is a flat file structure with culture. Soil~nservation Service (SCS) 149 variables and about 12,000 observa- using base SA~software. The two systems tions. The updating of 1.t is complicated are the Equipment Management Information by the maintenance of quantitative data. System (EMIS) and the Real Property The end uspr, for example, enters monthly Manage- miles driven, quarts of oil used in a ment Information System (RMIS). The EMIS month, and gallons of fuel for a month. system stores information about vehicles The update program computes and stores owned and leased by SCS. This information quarterly, yearly, and cumulative totals includes vehicle utilization data, operation from the monthly amounts. The key in the data. and maintenance data. The RMIS system data base is comprised of two variables - contains information about real property owned state and equipment number. and leased by SCS. It is a centralized source The RMIS data base uses a hierarchical of the real property holdings of the agency. model. The major property component is an The information stored in it affords the installation. The installation has associ- ability to.track space utilization; identify ated with it a variable number of build- under-util~zed property; and provide a refer- ings, land, and other structures and ence for answering inquiries from Congress facilities. The data base is implemente",Sugi-11-68 Smith.txt
"conrnodftfes, used modified weights to describe the relative importance of connnodities in Bureau of Labor Statistics produces the aggregating information to a single index, and Consumer Price Index (Cpr), a major economic adopted the use of imputation, that is, the indicator, on a monthly basis. The systems and estimation of values for uncollected items. associated subsystems that support its During World War II. temporary adjustments in calculation are being revised, with major weights were made to estimate the impact of components written using SAS{R) software. rationing and war-time shortages. The 1953 Experiences in using SAS software on a large revision, begun in 1949, was disrupted by the system that processes high volume data are unexpected Korean conflict and the sharp price discussed. The paper addresses the problems increases on a number of diverse items. Changes encountered, along with a discussion of how th~ reVl510n included modifications in in this were addressed usinj the SAS System. weights to reflect new consumer expenditure patterns, and the addition of restaurant meals",Sugi-11-69 Johnstone Rabb Sharlin.txt
"A SAS/FSP SOFTWARE AND CLIST SYSTEM FOR EASY MANAGEMENT OF A MACROINVERTEBRATE REFERENCE COLLECTION Todd C. Folsom, Duke Power Company Introduction Reference Collection (Fig. 1), taking The base SA~ software, SAS/Full advantage of some of the self- Screen Product, and IBM's CLIST command documenting features of SAS (Merlin language can be linked to form a 1984). The data are write-protected with the PROTECT=XXXX option, where XXXX is a menu-driven system that allows non-programmers to handle all tasks for password. management of SAS datasets. These tasks PROC CONTENTS displays the directory information for the dataset REFCOLL include data entry, data checking, appending of new data and report (Fig. 1). This shows the variables and generation. This paper shows how such a their formats, when the dataset was system was designed to manage data from created, its descriptive label, and the source SAS statements. Note that the a collection of macroinvertebrates. Biologists doing environmental password is not listed. The password, as well as other attributes of the dataset, moni tor iog work are often required by can be altered by PROC DATASETS. regulatory agencies to support the taxonomic identifications the biologists The variables STAGE, PREP, and VERIF I refer to the life history stage of the make. When such identifidations have , been verified by taxonomic authorities, specimen, the kind of specimen preparation used and whether the the specimens ar,e very useful for compar i50n with new, unknown specimens. identification has been verified by an A comprehensive, up-to-date list of expert. These character variables were specimens is essential for biologists to given'a length of one on the dataset. I t have if they are to l11ake effective use would enhance the clari ty of data of such a collection. Therefore we reports to have these variables computerized the specimen iriformation formatted. PROC FORMAT was used to turn nAn in Adult, nL n into Larva and so on. for a coll",Sugi-11-70 Folsom.txt
"that were submitted to the The Northrop Corporation, ventura Computer Operations Group for overnight batch processing each time a spares rep- Division Logistics Group provides an organization for maintaining domestic and ort was required. The Logistics Group was primarily responsible for maintain- international provisioning parts list ing these punch cards. In order to databases. The Mechanized Spare/Repair update the spares database, batch Parts System is designed to produce a transmittal sheets with the required tailored list of spare/repair parts to information were submitted to Key meet specific international program Processing for input, In addition, the requirements. CUrrent applications Logistics Group was required to generate for this system are jet-powered and an BO-column punch card for each spare propeller-driven target drones. The part item. If the Logistics Group wished Mechanized Spare/Repair Parts System to query the database, a hard-copy out- incorporates coded data elements in put of the entire file was required. MIL-STD 1552/1561 format in order to util ize a system of SAS® programs to Reports were issued in response to cus- tomer requests for parts lists based on manipulate the data. Discrete coding of specific reflight profiles. the data enables the user to extract specially tailored part lists to satisfy Reflight profiles are established program requirements based on customer requests. according to the method of recovery used for the target (over land or",Sugi-11-72 Donley.txt
"pany look through the entire file. Th;s was a very Abstract time consum;ng process. 'Ie decided that a computerized system would help us handle the SAS® code has many structured features wh; ch informat;on more effectively. lend themselves to fill-in-the-b1ank menus for the naive user which, when processed, create SAS code for a specif;c task. A system which would allow for the edHing, updat;ng, and retrieval of data on a da;ly basis as new information and facts become In a work environment where information is cont;nually updated, a flexible system which available was desired. Moreover, the technique used to manage and report th;s data had to be enables the management and use of such informat;on in a Ume1y and efndent manner !luser friendlyU and allow for quick and easy enables the user to keep abreast of the rev;sions of the data so that the informat;on implication of such changes. We have found would always be current. PPD informat;on could that the SAS full screen editor, available be classified into three general categories: through PROC FSEDIT in SAS/FSP®, provides the project background information, project status, capabi1 ity of a menu-driven system which has and project t;me and event schedules. A system the added advantage of placing the user which would allow us to access information for d;rectly ;nto the SAS environment. a particular PPD project or for several PPD projects across one, two, or all three In th;s paper we discuss our system of categories of informati",Sugi-11-73 Mercker Quinn.txt
"d Newbury Park, CA 91320 (805) 373-2114 Statement of the Problem Abstract The Labor Manpower Requirement System At the Northrop Corporation, ventura (LMRS) is a tabulated display of Division, the previous method of descriptive statistics in hierarchical tracking labor expended versus budget tables. This system utilizes the ""PROC came from two different systems. One system stored the actual direct labor Scree,n TABULATE"" procedure, Full Product (interactive menu-driven facil- hours expended, 'while another system stored the budgeted manpower, expressed ities), and statistical analysis to achieve its end results. The system in equivalent people (headcount). The was developed to provide engineering goal of this project was to eliminate the amount of paper work and manual functional managers and project managers with budget visibility and calculations which the two separate replanning control. The anticipated systems created. The required manual benefits of this system are improved calculations were the following: planning capability and better manage- ment of engineering budgets. · convert actual manhours to manpower headcount by dividing total actual The output of LMRS includes a tabulated manhours by 166 (one man-month is hierarchical format which compares equal to 166 hours per month) budgeted manpower with actual expended · (actuals - plan) Variance manpower. The output shows the budgeted labor, the actual labor · IFC (actuals to date expended to date, the variance between r",Sugi-11-74 White.txt
"requires an assembler interface to translate SAS internal data structures This paper reflects my experiences in into a standard IBM calling sequence. two areas: This interface must also handle the mapping of the data returned into the 1) Writing an interface to CINCOM appropriate SAS variables, converting SYSTEMS Data Base Management all numeric data into the floating System, TOTAL. pOint fotm that SAS uses internally. 2) Adding a Write To Operator (WTO) Such an interface can be used as a facility to the SAS Data step. bridge to any product that supports the standard calling sequence. As each SAS These techniques are applicable to Data Step is compiled and executed, interfacing SAS with any vendor's CALL statements along with external software. Topics covered include FORMATS and INFORMATS (ones found on addressing SAS variables, using SAS the format library) generate external Formats, reducing interface overhead references that causes them to be and using SAS macros, along with linked with the DATA step. When the general notes, references and a DATA step runs, it will pass control t'o contact. the interface whe'n the CALL statement is executed. For conceptual overview of how and where an int'erface such as",Sugi-11-75 Merline.txt
"The information that experimenters en- Experiment design is a useful technique that helps ter is checked to see whether it is appropriate in COR- researchers and engineers plan experiments that are effi- text. For example, one cannot enter character values cient and provide valid answers. We have taught experi- for quantitative variables. As well, one cannot re- ment design at ,Eastman Kodak Company for years, but quest variance component analysis unless the design few people actually used it. The computer tools to per- and model are appropriate fOf, it. form design and analysis were inadequate, hard to use, · The SAS program that is generated hy the PL/I con- or nonexistent. trol program. This program may update the Info DESRA is a menu-driven system, developed at Ko- Files or perform analysis requested hy the user. It dak to manage the experimentation process from design is usually executed immediately, hut it can be saved specification through data collection and analysis. It for later execution. The option to save the program is based on the SAS(R» system. DESRA is unusual in is sometimes used by our more experienced experi- that it stores important information about experiments menters, to enhance the functionality of DESRA hy in SAS data sets, so that it can guide experimenters modifying the code. through the process. DESRA has some of the charac- · The output utility programs, which control the dis- teristics of an expert system. pl,,¥, hard copy output, and storage o",Sugi-11-76 Westerlund.txt
"nd a specification file that ABSTRACT describes the records to the SAS data base. A SAS program reads the specification file to Patient care data bases and clinical generate the SAS code to read the TMR data research data bases often share a large records and create or update the SAS data portion of data. An automatic transfer of base. Each of these components will be data eliminates the duplicate entry process , "" described taken from the TMR to SAS interface. and increases consistency between the data bases. This paper provides a description of The transfer system was designed to the different components necessary for the minimize the number of changes that would need transfer between patient care records of TMR to be made to the SAS code to maintain the and the relational data base records of SAS: system. All changes in the SAS data base structure, selection, and interpretation. A TMR program extracts record components for specifications come from the TMR data selected patients and places them in a file dictionary. The TMR data dictionary already for SAS to access. TMR creates a contained information that could be specification file that describes the contents transformed into SAS names, labels, and value of the data file. A SAS program reads the TMR labels, as well as some of the SAS formatting information. specification file and generates the SAS program to then read the TMR data and create or update the SAS data base. We describe the RECORD STRUCTURE SAS programming asp",Sugi-11-77 Muhlbaier Dozier.txt
"DEVELOPMENT OF AN EXPERT SYSTEM FOR DBMS SELECTION by David A. Van Rossum Boeing Computer Services Company accurate and conscientious responses. INTRODUCTION Information collected during requirements Many of the projects being developed by Boeing definition and logical design will be utilized Computer Services Company in support of The by DBMSGON to recommend not merely a single DBMS Boeing Company and commercial contracts, call but several DBMS' that most closely satisfy the for the development or design of a data base system requirements. The degree of certainty of system. Although Boeing does develop data base the DBMS' selected is also dependent on the management software, it also relies heavily on users' certainty of the information supplied software offered commerci ally. How well a data (confidence in the completeness of the base management system (DBMS) satisfies the requirements and logical design for the system). needs of a data base development project has a significant impact on the performance and There is no reason DBMS CON could not be used operational costs of the final system. during the requirements and logical design Therefore, great care must be exercised to phases to perform ""what if II scenarios and obtain ensure that the DBMS chosen is the best one for preliminary analyses. DBMSCON identifies and the information system being proposed. provides valuable intermediate information that may be used during the aforementioned phases. Selecting the right DBMS requires the presence of a DBMS expert, one who is knowledgeable about the characteristics and strengths of the DBMS' USER INTERFACE currently being offered. This is a critical problem with most companies and organizations. The user has a dialogue with DBMSCDN. During A person or group of personnel having broad the dialogue, DBMSGON asks the user various expertise on many DBMS' is very difficult to questions about the proposed information system maintain. Also, once DBMS selection has and its en",Sugi-11-79 VanRossum.txt
"STRUCTURED PROGRAflM IiIG I N A SPERRY FORTRAN PLEX ENV IRONMENT Sandra L. Fitch, Shell Oil Company William R. Lee. Shell Oil Company Background use PLEX to manipulate attached S2k data bases. Shell Oil Company's Information and Com- Introduction puter Services (I&CS) organization is involved in solving Shell's business and In a modern data processing shop, the technical problems through the use of need to write well structured, readable computer technology. I&CS has two code is a critical requirement for a num- locations the Information Center in Houston, Texas and the Credit Card Center ber of reasons -clarity, readability, maintenance, and efficiency, to name a in Tulsa, Oklahoma. The computing and few. In the GPS group we had converted to data processing needs for Shell, other ANSI '77 FORTRAN from FORTRAN V and were than the credit card division, are served making every effort to produce new code by the Information Center in Houston. and to upgrade existing code to use The services performed there are bas- structured techniques. ically grouped into two major categories- Commercial Processing and Technical Pro- Additionally in our shop, modular program cessing. development was being stressed as an important technique in order to achieve The primary function of Technical Proc- well structured code. We tried to devel- essing, a department of I&CS, is to con- op our systems so that unrelated proc- vert large quantities of raw seismic data esses or all purpose routines could be into a form to be interpreted by geophy- sicists in the Exploration divisions. isolated into a single module, preferably Technical Operations has several Sperry an external subroutine or task. The abil- multi-processor lIDO/BO's and 90 ' s, two ity to develop,test,and maintain each module independent of another module in lOU's, and one Array Processor per machine. These mainframes are connected the system was an essential tool for pro- ject management, development, and test:- by a high bandw",Sugi-11-80 Fitch Lee.txt
"USER STANDARDS: WHO NEEDS THEM? Roberta A. Armstrong, Student Support Services, University of Minnesota Introduction Tvpes of Standards The role of users in the design and operation of Several types of standards have been developed major computer applications has received in- in a number of SSS areas viewed as important, creasing attention in recent years. We have highly technical, complex, or confusing: moved from a point where data processing toler- ated users as a necessary evil to a point where · Standard terminology users are increasingly involved in the design · Data element naming standards and control of computer systems. · Billing-related standards Forms standards Users have taken on this new. expanded role at Report design standards the University of Minnesota in Student Support Screen design standards Services (SSS), which includes the areas of stu- Guidelines for procedure manuals dent financial aid, registration and student records, and admissions and prospective stu- Before discussing each of these types in more dents. Over the past five years SSS has reorg- detail, it might be useful to describe how stan- anized to better meet its computing needs, add- dards are developed and maintained. ing a fourth major.area. Inform~t~o~ Sy~tems and Services whose prlmary responslbl11ty 15 coord- ination ~f computing and related activities that Responsibilities for Standards cross unit lines. Responsibility for preparing and enforcing stan- During this period, millions of dollars have dards is primarily lodged in Information Systems been spent on system development', centering on and Services (ISS), the SSS unit with the bulk the primary data bases and functions of SSS. of activities crossing operational unit lines. Traditional data processing standards (e.g., for Within ISS, two units have major r,esponsib~lity programming and documentation) were required in for standards: Systems Development/Operatlons these developments. However, with large numbers (SOia) for s",Sugi-11-81 Armstrong.txt
"AN ACCESS LANGUAGE RETRIEVAL CLASS FOR END USERS AT CONOCO Tom Ikard, CONOCO CONOea Research Services Division has imple- A Data Base. mented three large SYSTEM 2000 (S2K) aata Data Entries. m bases and is developing a fourth data base. The Data Records. data bases were developed for our Research and Data Items. Development Department. A Personnel data base Hierarchies. Project data base, and an Authorization for Ex~ !~ Data Trees. penditure (AFE) data base have been implemented Schemas. An Overhead and Operating (0&0) cost data base i~ Schema Records. CONOea is using Release 11.0 of b~ing developed. Schema Items. S~ngle User S2K on IBM 308x mainframes under ! l~ Schema Trees. MVS/XA and T50. Similar Records. Schema Compopents. 12 The data bases are updated both in batch and Component Numbers. 13 on-line. Each division in R&D is responsible for Component Names. 14 loading and updating their records in the data Relationships Parent, Ancestor, 15 bases. On-line u~dates are made by one person in Child, Descendant Sibling. each division us~ng PL/I PLEX Dialog Manager Level, Path, Fami i y. (full screen) programs. Batch u~dates are sub- Subtree. ~itted by one person in each divis~on. Standard- Related and Disjoint Schema Records. reports are generated regularly using S2K ~zed Null Items, Null Records. ml Report Writer and PL/I PLEX programs. Control Records, Control Nodes. Item Types - Integer, Decimal, Money, No sooner were the first standardized re- Date, Character, Text. ports generated than supervisors and managers at ml Strings and Functions. a~l levels in R&D began to request different Dis~laying and Interpreting a Data Base k~nds of reports and the same reports with dif- Def~nition. ferent formats or different sort keys. The de- Creating a Schema Diagram From DESCRIBE (24) mand was so great and varied that the Research Out~ut. ~ervices Division data base support staff was Br~ef Overview of S2K Physical Storage (25) ~nundated. The only timely solution to satisfy S",Sugi-11-82 Ikard.txt
"MAKING INFORMATION SYSTEMS A STRATEGIC ISSUE Henry B. Edwards, CIBA-GEIGY major corporations regarding the importance of INTRODUCTION information systems. This paper is based on research of 60 United States firms in order to Over the past 25-35 years, the infomation gain a better insight on the issues surrounding processing industry has grown from the very the use of Information Systems. In addition to rudimentary use of the technology to a complex multi-billion dollar sophisticated' business. the survey, current 1iterature was revi ewed. The industry has matured and with that This research is an attempt to develop generic guidelines that could be used by any maturity, technology offers exciting new organization regardless of size or opportunities for dOing business differently sophistication. and more competitively than ever before. The use of technology is no longer limited by technology but by the lack of vision and This paper is organized into three major creativity of persons using the technology. sections. A brief review of the research study lays the ground for the rest of the paper. Next, the hurdles or road blocks preventing the It is not an exaggeration to say the technology challenge has moved from the machine to the top strategi c use of IS are revi ewed. Fi na lly, a five phase approach is presented to move IS management. liThe difference between now and into a strategic position. five years ago is that then technology had limited function. You werenrt betting your RESEARCH STUDY company on it,ll says William H Gruber, President of Research and Planning, Inc., A The purpose of the survey was to gather Cambridge (MA.) consulting fim. ""Now you information on the factors attributing to the are."" (4) Eric Vogt, President of Micromentor, successful implementation of strategic uses of Inc., says IIIf you speculate about the next Information Technology or Information Systems. three years, there will be three kinds of From a three page questionnaire sent to ov",Sugi-11-83 Edwards.txt
"EXECUTIVE INFORMATION SYSTEMS USING SASIAF SOFTWARE Linda Sampey, GTE Data Services INTRODUCTION eventual choice, will handle any IBM-compatible software that is well-behaved. This category includes most standard bUsiness The problem of presenting current and useful information to applications, though some special versions may be required. executives is a long-standing one. Executives require almost Mainframe communications were a primary requirement for the immediate data on the performance of the company in all major equipment. From any mainframe in the GTEDS backbone areas, as well as status information on the progress being made network, any other mainframe in the network can be accessed, in carrying out corporate strategic plans. as well as a number of Telenet applications, including Telemai!. At GTE Data Services (GTEDS), the data-gathering problem is The IBM 3270 PC provides this communications capability. further complicated by the necessity of collecting information Given the earlier requirement of ""executive-friendly"", we from ten data centers around the country. The data is collected needed to use the EWS driver program as a complete session daily through our ""backbone"" network, and must then be controller. With the IBM 3270 PC, we were able to write an arranged in a format that will provide top-level management application program using IBM's High-Level Language with easy access to the information they need. Application Program Interface'"" (API), thus taking advantage The Executive Work Station (EWS) is the solution to these of the 3270 PC Control ProgramTM facilities. business needs. It is based on an umbrella concept, creating The IBM 3270 PC package that makes up EWS includes a a framework into which any number of applications can be Program Symbols board for host graphics, as well as an all- plugged. In addition, access to existing systems, such as points-addressable board for PC graphics. T Telemail and PROFS .. , can be easily added. Within EWS, w",Sugi-11-84 Sampey.txt
"ataset]; PARMCARDS; select statement PRoe GETSQL, a user-written SAS procedure, has been developed to retrieve data from IBM Database 2 and IBM Structured Query Language/Data System (SQLjDS) relational data bases. Users code a SAS PARMCARDS statement followed by a st'andard SQL SELECT statement: PROC GETSQL OUT=DEPT20; OUT=SASdataset PARMCARDS; SELECT NANE, JOB, SALARY FROM Q. STAFF SASdataset is the name of the output SAS data set WHERE DEPT=20 that GETSQL creates. If OUT= is omitted, the out- put data set is named automatically: the first such data set created in a job is called DATAl, the GETSQL uses the standard IBM PLfI Application Pro- second is called DATA2, and so on through the job. gram Interface (API) to dynamically pre-process This is the SAS DATAn naming convention, and is the SELECT statement and retrieve rows from the equivalent to specifying OUT=~DATA-. data base. The rows and columns retrieved are written directly to a SAS output data set. The var- iable names, labels, and data types of the SAS PARMCARDS; output data set match the column names, labels, and data types of the SQL data base. except GETSQL truncates column names longer than The PARMCARDS statement signals that Structured eight characters Query Language (SQL) follows. Put your select statement after the PARMCARDS statement. If your if necessary. GETSQL translates column names SAS program contains sequence numbers in columns to valid SAS variable names 73-80, use columns 1-72 for your select statem",Sugi-11-85 Wilson.txt
"id Septoff ABSTRACT from a variety of organizational ele- ments; In the course of developing a SAS (tm) based - analyze stored data to result in a co- data management system (OMS), an end user require- hesive database which can then be in- ment was uncovered which had not been identified tegrated into upper-level management d~ring preliminary analysis or addressed by base- applications; l1ne system design. This requirement comprised - automatically isolate key occurences the capabi 1ity to ""cut"" a segmented database which deivate from statistical projec- whi~h documented business activity over a broad tions; and, var1et~ of contracted and in-house (eg: overhead) - permit the ready retrieval of data for tasks.l~ order to augment offline data analysis. offl ine analysis by authorized person- A declslon was made to execute this ""cut"" in the nel. VM/CMS environment based on the availability of It was decided, after consultation with several resources already dedicated to OMS development and System users that it was necessary to support comp~rative.familiarity of end users with this op- some form of online data query in order to sat- eratlng e~vlronment. Ou~pu~ (report) requirements isfy the latter indicated requirements. and key f1elds/character1st1cs upon which to base These criteria dictated that a high degree meanlngful data extraction were identified through of user/system interaction would take place dur- analysis and user interview and work commenced as ing the process of c",Sugi-11-86 Confer Septoff.txt
"rvices management consultant, has T~cently stated that "" ···· access to timely information will probably ABSTRACT be the overriding key to success in materials management in the next 10 ye~s"" [41. Reports One of the major responsibilities of Ameritech generated from computers promote a unified, Services, Inc. 's Information Systems Organiza- integrated approach to materials m~nagement. Of tion (ISO) is to provide data processing particular relevance to this writing is a application support and development for the fundamental reason for most 'companies' purchasing and material management operations of investment in computers: To speed the flow of the five Midwestern Bell Telecommunications information needed for making decisions and to Companies. As an Analyst within ISO, my provide those in positions of authority with functional area of concern is related to the valuable facts so they may take appropriate Material Management And Distribution Systems for action on materials problems [lJ. the warehouse Service Centers of the five Telecommunications Companies of primary Many writers have documented creative interest here is Item Balance Integrity, or applications of the computer to warehousing ""IBI"". The IBI System provides the user group functions [5) [8) [11) [14). And more with the information required to track measure- specifically, several authors have focused in ment results and to detect problem areas upon the use of data processing to provide relating to accurate item ba",Sugi-11-87 Eagle.txt
"sing a SET statement would Binary search is an efficient method for locating a necessitate examining 50,000 observations on average specific observation in a large, sorted master file. in order to locate one particular observation. A binary search would locate an observation faster by In a binary search program, each iteration through the initially examining the midpoint of the master file DATA step (or through a portion of the DATA step) instead of the first observation. Each iteration eliminates half the remaining master file observations through a DATA step (or through a section of a DATA from those that might be the sought after observation. step) eliminates half the remaining observations in With a master file of 2**n observations, a maximum of the master file from those that might be thc sought n+l iterations are required to locate any particular observation. after record. A simplified initial pass through the data might look like this: This paper develops two improvements to binary search techniques applicable when a number of records must be DATA HALF; LOW = 1; located. The examples locate 200 to 1000 target records out of a SAS ® data set with 100,000 obserR HIGH = TOTALOBS; POINTTO = CEIL«HIGH + LOW) / 2); vations. Sorting the targets before beginning the SET MASTER POINT=POINTTO NOBS=TOTALOBS; search makes possible two improvements over a standard IF KEY < 'Searched For Value' THEN LOW=POINTTO; binary search. First, since the targets are sorted, ELSE HIGH = POINTTO",Sugi-11-88 Virgile.txt
"STRUCTURED MANAGEMENT OF THE PROTOTYPING, DESIGN, AND DEVELOPMENT OF A SAS DECISION SUPPORT SYSTEM John c. stuart, Independent Consultant PROJECT DESCRIPTION The TRACS project began to help management make strategic decisions on which markets to expand or contract. INTRODUCTION TRACS is an economic model which determines the distribution and What is structure? We know when a financial costs of marketing gasoline computer project or program has good and fuel oil products. structure, and yet it is or bad difficult to define. Structure can be Figure 1 shows the distribution system viewed as an organized, controlled of a typical refining and marketing approach to system development. It is oil company. The TRACS system computes the ingredient that makes a system the marketing cost using information dependable and supportable. Although extracted from 6 computer systems. The some structure is needed on a major cost components are: successful computer project, too much Product manufacturing cost can spoil it. Transportation cost Terminal storage and handling is It almost automatic today to Credit card costs structure large computer systems, but is not as common to structure it A major design objective of the system Decision Support Systems (DSS), which was to also use the time value of are increasingly being used to help money in determining the cost of doing management make decisions using the business. Essentially this involved data from existing computer systems. determining how long product was tied Management does not have the time to up in inventory and transportation, tell the designers what they need, but and how long it took to receive cash they want it fast and they are going from customers. Internal cost of to change their minds. They say, ""I capital is used to determine the cost don't know what I want, but I'll know of: it when I see it. U The real world is a Transportation time very unstructured environment, and DSS Inventory are frequently developed by trial",Sugi-11-89 Stuart.txt
"Indiana evolved as a company by product. The products include Blue Cross (hospital). Blue Shield (medical/physician), Major Medical (catastrophic), Comprehensive Major Medical (catastrophic including hospital and medical/physician), Prescription Drug. Dental, and Vision. Because these products evolved at different -times and because each market had different requirements for these products, 13 claims processing systems were developed. These systems are very complex because they must interact in order to pay a single illness or accident. The situation was further complicated by the changing environment. The original systems were continually updated to meet new requirements. A single claims processing system was purchased and adapted to meet our specific needs. This paper will discuss the methodology used for loading account benefit coverages from the old system to the new system. The methodology consists of determining the most popular combination of benefit coverages. loading those as models. finding the closest model for each account. copying the model. and changing benefit coverages that the account has which are different from the model. The Benefit Conversion System consis'ts of approximately 50 SAS* programs. reading 4 major files. creating approximately 30 SAS data sets, and 40 reports. 1. Introduction The current claims processing environment at days. Another example of a benefit would be Blue Cross & Blue Shield of Indiana includes workmans compensation. The coverage",Sugi-11-90 Brown.txt
"A MENU-DRIVEN METHOD OF COPYING SAS* DATA SETS N. H. Wooding, Jr. Virginia Power INTRODUCTION In our department at Virginia Power, most data libraries contain only a few data files so PROC COpy with select The SAS Institute provides a number of useful tools for foreground statements is usually satisfactory. We have one project that produces many data operations on its data libraries. For example, PROC DATASETS can be used to files within a data library, however. rename or delete individual data files, These files are used for a brief period PROCs FSEDIT and BROWSE allow editing and then need to be copied to an and browsing operations, and PROC COPY archival data library on tape in order to minimize disk storage. PROC COpy has transfers files from one data library to another. Of these operations, only PROC been used jn the past but requires DATASETS operates from a menu. Usually careful punching of SELECT statements. this is no problem but sometimes a menu This process is tedious and prone to for PROC COPY would be helpful. I will more error. In short, we would benefit from a SAS equivalent of IBM's ISPF** demonstrate a solution using the base SAS product and SAS/FSP*. 3.3 menu. With the advent of SAS Version 5, it has become quite easy to PROC COpy -- A REVIEW create a menu-driven facility to expedite this type of problem. To illustrate PROC COPY's SAS OATA SET DIRECTORY operation, first consider Figure 1 which shows the contents of a simple SAS data library. To move files from this data NAME # OBS TRACKS SUB EXTENTS library to another, we may write Al 2 2 = OLO OUT = NEW; PROC COpy IN A2 2 I A3 2 I ABI By adding the statement 2 I AB2 2 I SELECT Al AB2 0; BI 2 I C3 2 I we may elect to copy only those data D 2 I files mentioned. To copy all of the TOTAL TRACKS USEO: files beginning with the letter nAil, we 17 could explicitly name all of desired HIGH TRACK USED: 20 data fil es. Figure 1. Partial output of PROC PROC COPY IN = OLD OUT = NEW; CONTENTS listing members o",Sugi-11-91 Wooding.txt
"TECHNIQUES USED FOR CONVERTING AN ON-LINE PRODUCTION SYSTEM FROM A PRIOR RELEASE OF SAS@ SOFTWARE TO VERSION 5.08 OF SAS SOFTWARE Harriet Janes, SAS Institute, Inc. Barbara Kennedy, SAS Institute. Inc. Sharon Sanders, SAS Institute, Inc. Jerry Hosking, SAS Institute, Inc. With the exception of the _MSG macro, all of our The Management Information Systems Department macros consisted of a %INCLUOE statement. (MIS) at SAS Institute supports production Modularizing the code using the %INCLUDE systems running under both eMS and TSO. When statements was necessary for ease of new versions of SASe products are developed, maintanence. The _MSG macro was unique for each we use them in our production systems as soon as system, whereas the same s'ource code was used possible. This gives us the benefits of across several systems when user tasks enhancements to existing products and the overlapped. For example, all of our users need availability of new products for our systems. to access the Installation Data Base. The SAS It also allQws MIS to test products for the code used to browse this uata base consists of development groups at the Institute. MIS has one single program accessed by more than 24 converted its computer-based systems under systems. Using the same code from a single releases of SAS software prior to Version 5 into source in different systems was simple to do and Version 5. greatly reduced maintenance time. What we hope to accomplish in this paper is The primary objective of our conversion project two-fold. While presenting a discussion on how was to enhance all systems and increase the MIS Department converted its SAS software efficiency while keeping the conversion as computer systems from 82.3 to Version 5, we will simple and inexpensive for the MIS Department as at the same time be presenting some of the uses possible. In addition, we wanted the changes to of SAS software at SAS Institute. be subtle. We did not want the user interface and the flow and struct",Sugi-11-92 Janes Kennedy Sanders Hosking.txt
"® software in 1985, the SAS System greatly SAS/SHARE software allows multiple SAS users enhanced its position as an information center concurrent update access to SAS data libraries tool. The integrated data entry and data an lysis and members within the data libraries. The applications often built with the combination of development project for this software was SAS/FSP and SAS/AF software has mandated initiated in January of 1985. The product, which development of the SAS/SHARE product. User en hances the SAS System under MVS and CMS, input from the SUGI software ballot has reflected is currently in alpha test status at several the need for the SAS/SHARE product. On the 1984 and 1985 ballots, the ability to concurrently installations. update a member of a SAS data library was the third and second highest priority item for the This paper gives an overview of the historical SAS/FSP product respectively. needs and the conceptual model and then describes in detail the SAS/SHARE software product. Actually, the product appears Conceptual Model differently to different SAS users. The SAS I n the years prior to the development project, programmer sees the product' as another means of several 'methods of adding concurrent access to accessing a data library with new flexibility hut the product were consi-dered. In the final with a few new restrictions and concerns as well. development project, the central server model The server administrator, who ensures that the Figu res 1 and 2 de",Sugi-11-93 Wallace.txt
"DEVELOPING SAS/AF e SOFTWARE FRONT-ENDS FOR SYSTEM 2000· DBMS JAMES E. NELSON SAS INSTITUTE INC. It is a simple matter to provide a menu to SYSTEM 2000 DBMS when paired with SASe directly interface with the S2K, QUEST and software provides a final product that has S2KLOAD procedures. both power flexibility. SAS/AF e software is the glue that bonds the two software systems into this final tool. i'r ... !NIl to "" .. turn SAS/AF software, allows the system developer to put together new and existing applications into a full screen, menu driven system. I will show both some practical information , .. "",,,t .. FRee SZJ: center applications as well as the ability to use SAS/AF software as a front-end into production level systems. l. ,neuh PRoe S2J:LOAt' In an attempt to pass on as much conceptual methodology of how to approach the various applications as what applications to approach, I have structured this paper to follow the technical features of base SAS and SAS/AF software. Interface Methods Available * PROe QUEST * PROe S2K This will allow direct transfer of processing * PROC S2KLOAD to the first screen of PROe S2K. * User Written Procedures * System Subtasking The QueX· Product PLEX p_rograms Several techniques are available for interfacing the SAS System with SYSTEM 2000 DBMS. Three of the techniques are self to 1I.t""""n. !N~ Pru. evident, PRoe g;2K, PROC QUEST, and PROC S2KLOAD. Three other methods of interfacing are not nearly as obvious to the non-SAS ~"" ""hat no tou ""lilt Co? user. One is centered around the ability of the system developer to write Third In~aU Pltoe 521: Generation Language extensions to System that 2 .... cute PltOC 011U! can access both the SAS System file structure J. Inc-ate PROC S2nOAIl and the SYSTEM 2000 data base. The methods are based upon the SAS System's ability to perform system subtasks while remaining resident. 474  The next screen displayed is a full screen The next screen to appear is the Data Base adaptation of the DESCRIBE out",Sugi-11-94 Nelson.txt
"The SAS System as a Tool for the Financial Systems Auditor Ferrell Drewry SAS Institute Inc. INTRODUCTION auditing programs written in SAS software"" however the software does have the general capabilities necessary for performing audit tasks. During the 1960s, businesses began to use The intent of this paper is to show that SAS computers to process their accounting data. The software can be effectively used as generalized first computerized accounting systems relied on audit software provided that a library of audit batch processing: batches of transactions from programs has been developed. The end product source documents were posted to files of is an audit software package that allows auditors accounting data which were stored on magnetic to spend more time analyzing the results of the tapes or disks. Because the number of audit tests rather than coding the SAS transactions per batch was small and source statements necessary to perform the audit tests. documents were readily available, auditors of The programs and ex~mples that have been batch processed systems' could rely on manual developed with SAS software can be found in the audit tests designed to du'plicate the appendices of this paper. computerized system's functions. 1 This paper is intended for auditors and SAS Throughout the 1970s and early 1980s, the price programmers that suppor:t the audit staff. It is of computers and related hardware dropped assumed that the reader has a basic knowledge of dramatically. In addition, computer technology data processing, auditing, and SAS has advanced such that it is now feasible to have programming. With respect to the programs for several hundred people accessing data in, adding statistical sampling, no attempt is made to data to, and altering data in files on a computer familiarize the reader with the concepts of at the same time. Although batch processing is statistics or the with the pros and cons of still being used, some newer financial systems. various sampl",Sugi-11-95 Drewry.txt
"gestions and examples for Learning to use macros can be an intimidating beginning users of the SAS macro facility. we've found the techniques presented here to experience when one is faced with either very technical explanations or trying to decipher be both useful and a good way to start people code written using the more advanced features programming with macros. Explanations of how of the SAS macro facility. This paper will the macro facility processes the 'code and the present simple macro applications that have more technical explanations are left to the been used in designing standard programs. A SAS manual. It is hoped that by following focus will be on appropriate uses, as well as ~ough the simple macro applications in this providing the inexperienced macro user with paper, many of these ideas can be adapted to examples of SAS macro code and concepts that other users needs and progr'ams. are easily understood. EXAMPLE I: Variable/String Substitution. INTRODUCTION. One of the simplest forms of macro usage is the %LET statement in combination with macro When beginning to use the SAS macro variables. The programmer incorporates macro facility, it is often most helpful to see variables (also called symbolic variables) how others have utilized it in specific into places in the program that are likely to applications that are familiar. change each time the program is -used. These Unfortunately, in many cases, these examples macro variables have the value of the are written",Sugi-11-96 Barnes.txt
"ght and power for one pur- Clearly, the SAS macro language considerably pose and medium light and power for another increased the potential power of the SAS pack- purpose. . Intricate contractual relationships age. Yet macros provided more than just power. often make a clear identification of the appro- At the same time, they promoted the maintain- priate group in a given case quite difficult. ability of SAS-based systems by allowing those Not only are the customer group determination systems to be much more structured and modular criteria sometimes inconsistent with one than before. ·Chunking"" an application into a another, they tend as well to change from year set of clearly defined, interrelated macros to year as rate schedules are added or dropped facilitates later enhancements because any or as new considerations emerge. changes are module-specific, and each module can be tested and debugged independently of the In the old CLASSKW system, the process of system as a whole. placing a customer into the appropriate custom- er group was performed by in-line code, con- Yet anyone who has struggled with writing sisting basically of IF-THEM-ELSE statements. and debugging macros of even intermediate Various subprograms of the ClASSKW system had sophistication can attest to their p~oblematic slightly different versions of this code, owing nature. One experienced SAS software consult- to the system being modified from year to year ant told me he avoids macros because their or week",Sugi-11-97 Kretzman.txt
"tatement This article describes some of ""&A &B;"" could mean ""run any proc the design issues raised'in pro- with any data set"". That is &A can gramming batch report writers of have the value of any proc and &B the 5,000 lines using the SAS* macro value of any data set. If the values facility. The issues include logical for these symbols were entered in a program structuring, the relationship batch environment, numerous lines of of macro code to SAS code, ~nd co- macro' and data step code would be ordination of referencing environ- required to ensure that the program ments or symbolic pools with the would never abend. That is, the names program structure. Some ""rules-of- of the procs and data sets would have the-thumb"" to simplify coding mac roes to be validated; and macro statements are suggested. would be required to implement this logic. The macro statements need~d to COMBINATION PROGRAMMING BLOCKS determine which data sets and wh~ch procs would be valid pairs, along Report writing applications in with the data steps and proc steps SAS without macroes -- consisting generated, form a combination pro- only of data steps and proc steps -- gramming block. This is the largest require simpler design considerations manageable section for batch report than the same applications do in pro- writing programs using SAS macroes. ced ural languages. In Cobo I or For- tran modules are often designed to The macro statements within a pro- perform a single function. A module gramming block cr",Sugi-11-98 Levy.txt
"The Use of the Macro Facility in a System Development Environment Jeff Phillips, ORI, Inc. Introduction There is no question that the Macro focility odds An important imp I i cot i on of the charact.ri at I cs of a a new degree of power to the SAS( r) system. Now that CPI system is that a key use of Macro is for the Macro hoe been ovoi lable for a few years, USers have dynamic control of the systOft'S functioning without been able to explore the various ways In which it user intervention. This fact influences the kinds of At ORI, the ~ajor thrust of SAS enhances SAS. Macro features and techniques that are used. programming since about 1981 has been in the deveI opaent of lorge-scale software systems. In One other aspect of softwore systems at 8LS eff.ct, ORI has been using SAS to do the job that should be described before procseding to a specific might be done by, for example, PL/I in a sim'ilar discussion of Macro's role, and that is how the situation. systems are developed. The scale and complexity of The single largest SAS-basod contract for ORI has each system combine to require a team development been that with the U.S. Department of Labor, Bureau 4pproach_ Briefly, th.se ore the characteristics of of Lobar Statistics (BLS). BLS has been engaged in the s1'st ... development approach taken at 8LS: what is known as the ""CPI Rev i sian"" a lIIaj or overhaul of all aspects at the Consumer Price Index. o Development taaks ora divided CIIlOng ataff Revisions of the CPt occur every years, 10 corresponding to the release of new decennial U.S. a Production (use of the system) I · ·eparated the system uaers are not Census, data. and Involve not only chong.s in sampling, from deve I oplllent data collection and statistical methodology, but also the system developers changes in the ca.puter software used to produce the CPl. One of the features of the current CPI Revision o Maintenance of the ayatem may be separate from is thot SAS Is being us.d as the major _oinfroae both",Sugi-11-99 Phillips.txt
"USER-WRITTEN PROCEDURES IN C Leigh Ihnen SAS Institute Inc. To implement a. user-written procedure in C, one must have Version The @STMTINl'I', @STMTLIS1', and @STMTEND symbols are CD semantic actions in the IDSTMT productioll. Semantic act.ions 5 of the SAS System and the SASjCTM Native Compiler for inform Ule parser ho\v to handle informat.ion specified by the f.:nd- IBM 370 Systems. As with version 5 user-written procedures in user. The@STMTINITsemanticaction causes t.ile grammar \Ja.l""ser PLI, the process of creat,jng a user-written procedure consists of to create a STMTSTRstnlcture and places t.he sl.ruclurc ill a lilll,ed three steps list of STiI·1TSTR structures. The @STMTLlST semant.ic action spc:cifies that the first field of the STMTSTR stmctlJrc, indicated 1. Writillg a Grammar by tile first parameter being a 1, will be of the list lype. The sec- ond panmeieT of the @STMTLlST sema.ntic act.ioll specifies tha.t 2. Writing the procedure body the list will conLain eit.her numeric or eha-rader variables frOlJ1 the ::L LinkIng the procedure to the SAS System. current data set. Other possible values for the second parameter can specify a list. that. cont.ains one of t.he following NEW to the version 5 SAS System is the additiOJI of a high level Jangauge grammar parser. The grammar parser operates on tables produced by a. grammar processor supplied hy SAS Instit.ute. The Ollly character variables grammar parser produces data structures .containing informa.(.ion Only numeric- variahles specified by lhe t.he end-user's SAS program. This is a significa.nt improvemellt over the parsing mechanism of 82-4 whit,h consisted N umhcr list.s of In:;titule supplied assembler macros or user written assemhler Lists of valid SAS names programs. The grammar processor produces SOUTce code for a C List. of character strings up to j 6 clwraders IOllg function which one compiles and linl;:s wit.h the procedure body. The C function prodllced by the grammar processor cont.ail]S stat",Sugi-12-02 Ihnen.txt
"Using the SAS/C(tm) Compiler Oliver T. Bradley SAS Institute Inc., Cary, NC Copyright (C) 1987 by SAS Institute Inc. This tutorial concentrates on how to Take advantage of the seoping rules to limit the time a register use the SASjC(trn) compiler to generate efficient programs. Specifically, the is assigned to a variable. tutorial first addresses ways to - If the program uses complicated expressions or does a lot of g~nerate more efficient code and then moves on to discuss how to use C I/0 indexing, it may be better to declare only 3 or 4 register efficiently. va:J:'iables. See Technical Report: C-I02 SAS/C(tm) Compiler Supplement for Built-in functions Release 3.00 for more complete functions are information. number of A library built-in that is, the compiler generates code for them. in~line Use /% optimization They include: The ""divide"" machine instruction is memcpy (copy a block of memory) expensive (relative to other memset (initialize a block of instructions) on IBM(R) mainframes as memory) on most other hardware. When using memxlt (translate a block of both / and % on the same operands, memory) take advantage of the compiler memcmp (compare 2 blocks of memory) optimization that allows both results abs/fabs (absolute value of an to be calculated with one divide integer/double) instruction. Technical Report: C-102 has details on how to take advantage The built-in code is generally much faster than the function call. To get of this optimization. the built-in code, just include the appropriate header file, for example Take advantage of !lleaf"" functions <string.h>. It's always a good idea to include the header file. That way, A ""leafll function is a function that your code automatically takes calls no other functions. This advantage of more or better built-ins property means that the function is in new releases. always at the end of a calling sequence. Thus, instead of needing a a IIleaf ll fresh allocation of stack, Structure assignment fUnction uses a fixed are",Sugi-12-03 Bradley.txt
"The Wild Side of the Annotate Facility Chip Kelly, SAS Institute Inc. Cary, NC A trivial modification of the program changes the Introduction amplitude of the waves: The annotate facility unleashes the power of the SAS® DATA step programming language for the DATA SIN; LENGTH FUNCTION COLOR STYLE $ 8; creation of graphics displays limited only by your RETAIN XSYS YSYS '2' HSYS '3' imagination. This tutorial will show several facets COLOR 'BLACK'; of that capability. The written portion of the DO START=O TO 3.14159 BY 3.14159/10; tutorial will consist solely of, the code used to FUNCTION='MOVE'; X=-2*3.14159; Y=O; generate the examples that were shown at the OUTPUT; presentation. The nature of the examples, their DO X=-Z*3.14159 TO 2*3.14159 BY .1; complexity, and the use of color gradations Y=SIN(X)*START; FUNCTION='DRAW'j prevents the actual pictu res from being included OUTPUT; in the proceedings. END; END; PROC GANNO ANNO=SINDATASYS; Your Bas;'c Line RUN; Probably the simplest form of graphics design is drawing lines. The annotate facility provides two commands, MOVE and DRAW, to respectively Adding Color and Complexity establish the beginning and ending points for a line. The following code illustrates the beginning Before proceeding any fu rther, we should begin of our journey into generating patterns with to add color to the display. Colors may be lines: specified in many different ways in SAS/GRAPH® software. This tutorial focuses on how to DATA LINE; generate displays in the DATA step, so we will LENGTH FUNCTION COLOR $ 8; assign our colors as a function of line generation RETAIN HSYS '3' XSYS YSYS '2' SIZE 1; itself. This technique is useful for associating COLOR=' BLACK I ; gradations of colors with attributes of the display FUNGTION='MOVE'j X=lj Y=l; OUTPUT; itself. FUNCTION='DRAW'; X=100; OUTPUT; PROC GANNO ANNO=LINE DATASYS; I n the previous display, we added an outside RUN; loop to control the amplitude of the SIN waves. We use the loop index variable",Sugi-12-04 Kelly.txt
"USING SAS/GRAPH® SOFTWARE WITH A PROTOCOL CONVERTER Mike Kalt Ne SAS Institute Inc' Cary J * INTRODUCTION Data are transmitt'ed via synchronous data links. This may be either via bisynchronous SAS/GRAPH® Software can he used with most transmission (often referred to as BISYNC) popular protocol converters on IBM mainframe or by a method known as Synchronous Data systems to produce graphics in both interactive Link Control (SDLC). Because SDLC is used in IBM's System Network Architecture (SNA) and noninteractive mode. This tutorial discusses how to use SAS/GRAPH software with networks, the terms SDLC and SNA are often different types of protocol converters. used interchangeably or in conjunction with each other. The following topics are addressed: * the High speed transmission (in * What is a Protocol Converter? neighborhood of 19,200 baud) is used. * Using SAS/GRAPH Software with * Data a Converter are transmitted using EBCDIC character * Special Topics representation. * ZETA~ Plotters * IBM 2780/3780 Emulation Many of the more popular graphics devices (such * IBM 3767 Emulation as terminals manufactured by Tektronix~ and * IBM 3708 Network Conversion Unit RamtekTM and plotters from Hewlett~Packard® are * Using SAS/RTERM® Software asynchronous or ASCII devices. These devices With a Protocol Converter have the following characteristics: * Unsupported Converters * They are connected to the host via RS~232 WHAT IS A PROTOCOL CONVERTER? cables. * Communications in an IBM Network Data are transmitted between these devices and the host using asynchronous In a typical IBM network, peripheral devices communications protocol. With this type of communicate with the host through a 3705 (or protocol, messages can be transmitted in similar) communications controller. The each direction at the same time. With terminals (usually 3278 or 3279 models) and synchronous protocol, messages can be printers (3268 and 3287 models) are attached to transmitted in one direction at a time. 327",Sugi-12-05 Kalt.txt
"PC Hardware Considerations for SAS/GRAPH® Software Graphics Donna Bravo, SAS Institute, Inc., Cary, NC The versatility of the personal computer is highlighted by consid~ tions adapters are the IRMA~ Forte PJTM and PCOXTN poards. ering the number of ways SAS/GRAPH® output can be generated Although these boards allow synchronous communications. very for display on your PC monitor or on hardcopy via PC-attached few of them allow graphics capability with SAS/GRAPH software plotters and printers. And ""How do I use SAS/GRAPH software at the present time. with my PC?"" is a common question received by the Institute's Technical Support Department. The answer is complicated by the In addition to the communications adapter, the PC also needs many varieties of and enhancements to the old-fashioned IBM communications software. At the most basic level, you could use PC. There are also a number of different PC graphics boards and, ROM BIOS or DOS services to set communications parameters perhaps, a communications system to worry about. fm your async adapter. However. most people find it easier to purchase terminal-emulating software rather than write their Worry over the communications system can be eliminated by pro- own. A terminal emulator Is a real-time program that transmits ducing SAS/GRAPH software .output locally on your PC. That and receives characters to and from the host. Synchronous com- makes life a lot easier, and that is the good news that munications adapters always come with their own terminal emu- SAS/GRAPH software for PCs brings. Later. we will preview a lators. IBM 3270 PCs are purchased with control programs that few of the graphics hardware-related highlights of SAS/GRAPH provide the 3270 functions. software for PCs. Now that we've considered the PC's communications hardware However, we will discuss the more complicated situation first and and software, let's look at communications protocol on the host assume that your PC is connected to a host with version",Sugi-12-06 Bravo.txt
"Once the basic concepts have been mastered, statements.) The facility is also useful for understanding the internals is the next logical processing information from your system. The step to enhancing your knowledge of the SAS® term system, in this instance, refers to both your operating system as well as your Macro Facility. application system. There are automatic macro This tutorial addresses the internals by variables which allow you to obtain information identifying the components of the macro from the operating system, &SYSJOBID for processor, illustrating their relationships with example. Special symbolic variables are also each other and their interactions with the SAS available for letting you obtain information supervisor, and examining how a macro program is from the SAS Display Manager System as well as design additional features for display manager. processed. Major components include the input stack, wordscanner, word queue, macro compiler, In addition, functions are available for macro executer, symbolic substituter and open allowing you to obtain information from the DATA step and pass information back to it. These are code handler. Special topics in macro proce.ssing include the performing of symbolic only a few of the tasks that the macro facility gives you the capability to implement. substitution, resolution, evaluation, quoting and unquoting, and autocall processing. As the macro facility is only a part of the SAS system, the macro proceSSOr must interact with",Sugi-12-07 Patrick.txt
"THE SAS R SUPERVISOR Don Henderson, ORI, InC. Merry Rabbi ORI, Inc. DATA Step, such as conditional execution I. INTRODUCTION of a read operation, or reading data within a loop. The following sections This tutorial discusses the discuss the actions of the Supervisor functions of the SAS Supervisor during during compilation and execution of a the execution of a SAS DATA step DATA Step, and the coding techniques program, and will be presented in both that can be used to control or override the Tutorial and the"" Advanced Tutor 1a1 the Supervisors default actions. A more detailed discussion sessions. will be given in the Advanced Tutorial III. COMPILE TIME PROCESSING session. The functions of the SAS Supervisor can be categorized as During the compilation of a DATA follows: step, the Supervisor creates both permanent and transient (in that they - Compiling SAS Source Code, and ""disappear"" after the compilation or execution of the current DATA Step) - Executing Resultant Machine Code entities. The primary permanent entity is the directory or header portion of The actions of the Supervisor during the SAS data set (the data is added to both the compile and execution phases of the data set at execution time). The a SAS job will be illustrated. transient entities include a variety of buffers, flags and work areas which, at When a SAS DATA Step program is execution time, control the creation of written, the DATA step ""module"" must be the desired output. The following is a integrated within the structure of the partial list of the more important SAS System. This integration is done by actions taken by the SAS Supervisor the SAS Supervisor. Gaining a more during the compilation of a DATA Step: complete understandIng of what the Supervisor does and how our ""program"" is Syntax scan; controlled by it is crucial to using the SAS System more effectively. Translation from SAS source code to machine language object code.; II. STRUCTURE OF SAS JOBS Definition of input and output There",Sugi-12-08 Henderson Rabb.txt
"A Comparison of Table Lookup Techniques Craig Ray, ORI, Inc. INTRODUCTION file. This data is used as the sample data 1· throughout the paper. This paper presents table lookup procedures The main file consists of each potential and shows how to use them efficiently with respect to CPU time. Table lookup can be customer's name and his/her address. The lookup file is .a separately maintained file of defined as cross referencing a parameter file based on the value of a variable in the primary,"" auxll1ary information for every zip code in a given area. )t would not be prudent, for (main) file. ~' instance, to inclUde the information of the lookup file on the main file. It is conceivable When processing very large data sets, table that there are many people in the mailing list lookup procedures must be carefully designed. · wi'th the same zip code and therefore information If designed poorly, these procedures can be a relatIng to each zip code would be repeated for source of program bottlenecks. each of these people. This is undesirable This paper presents table lookup tools and because-repeated information consumes more space and is difficult to maIntain. Thus, the show how to employ them. As much as possible, structure chosen for this data is very natural. the occasions to use one technique over another is presented in IIcookbookll fashion (f.e., IIfor The key variable for the lookup Is the lookup file of this size and for a main file of variable~ common between the main and lookup that size, Method A should be used""). This file, in this case ZIP. This is the key of the approach, however, is not always practical lookup file In that observations are unique by because: 1) processing efficiency varies from zip code and the file is likely to be sorted by machine to machine, and this paper is intended this variable. This is not the case for the to provide general guidelines without regard to main file, ho""ever. The key variable (the machine, and 2) each application is diffe",Sugi-12-09 Ray.txt
"components) is said to have This tutorial is intended to present a conceptual model that has conversational characteristics if it has the ability to stop at proven useful in planning and designing interactive production some point in its execution and converse with the user, pointing applications using the SASiI!l System. It recommends a out the occurrence of some significant event, possibly asking for framework for the design, development, and maintenance of such additional information it needs before proceeding, or allowing applications at a strategic level, one that addresses the usual the user to request some expansion or refinement of the scope of concerns of the systems analystand manager: the process. · minimizing the time required to design and implement the application; In traditional batch-mode applications, control-card or minimizing the time required to train the user to operate the command-statement parameters are the usual mechanisms by application, and making users'skills transportable from one which the user specifies run-time options. The principal application to another; difference between batch processing and conversational insuring that the resulting applications are easy to maintain processing is that with batch jobs, the parameters must be coded completely and correctly prior to execution. With by promoting the use of modem, structured programming conversational processes, the user must know only how to start principles. the job. Once it is executing, th",Sugi-12-10 Pulgino.txt
"ract: Martin Marietta Corporation, under a contract to assist the FAA in making an upgrade to the nation's air traffic control system, has utilized the SAS system as an engineering analysis tool for the past two years. Four types of engineering applications for SAS/GRAPH software are described in this paper. The first section discusses SAS programs for constructing US maps with symbols, labels and lines added to show FAA facility locations, Area Control Facility (ACF) borders, and facility interconnectivity. Also included in this section is a program which uses templates 10 make complex maps. The second saction describes SAS/GRAPH capabilities available for making terrain charts. Programs are discussed for topographical maps, depicting surface features of an area, and cross-sectional maps of the terrain between two sites. The third section of the paper demol'lstrates a way to utilize SAS/GRAPH software for microwave site analysis. Fresnel zones are plotted with a terrain cross-section to form a graph showing terrain interlerence to microwave signals. The final section illustrates coverage charts for several types of sensors. The System Analysis Group has developed FORTRAN programs to find the coverage area of radars and other ""Iine-of-sight"" devices. Two approaches to graphically formatting the output from the coverage programs are presented. location and Connectivity Maps Introduction The first map attempted was a map of the United States with A decision was made several yea",Sugi-12-100 Markham.txt
"A Guide to Color Hardcopy Device Purchases Daniel Lee, Hewlett-Packard Co. OVERVIEW: COLOR HARD COpy TECHNOLOGY INTRODUCTION Color hard copy technology can be categorized into Graphics is one of the fastest growing applications of impact and non-impact devices. Impact devices are computer power. Users are finding easier and more dot-matrix printers and pen plotters. Non-impact sophisticated ways to apply graphics. The power of devices are ink jet printers, thermal transfer color graphics lies in its ability to present large printers, film recorders, and toner-based systems amounts of information in an understandable way. (electro-static. electro-photographic, and magnetic People are using color graphics solutions to improve printers). their presentations, make better decisions, and to lower costs. However, today's user can be overwhelmed Impact devj.ces currently dominate the market for hard by the different technologies and the sheer number of copy froni computer images. Dot matrix printers and pen devices available. A buyer has more than 200 hardcopy plotters are in wide-spread use. They offer proven and devices to choose from. reliable technologies. This paper presents a guide to purchasing color hard Dot matrix printers use a series of wires impacting a copy devices. Today's buyer is looking for a graphics colored ribbon to transfer ink to paper. The dots of solution and not individual components. The hardest ink are combined to form characters and images. Color task for buyers is to define their needs. This graphics are created by successive printing of the same overview of hardcopy technologies and key purchase image in different colors. Color reproduction is criteria provides a framework for potential buyers. limited because brightness and saturation cannot be The framework will help users define their needs. and controlled. Resolution is also limited by the size of gain sufficient familiarity with color hardcopy to be the wires' diameter. Despite these disa",Sugi-12-101 Lee.txt
"A PICTURE IS WORTH A THOUSAND WORDS AND NUMBERS MICHAEL W. BORNHOEFT BACKGROUND: This session highlights these systems and discusses the graphic mapping New Years Day, 1984, came and went procedures used. Early attempts at without much -more than the usual digitizing and mapping telephone fanfare., There was a big parade in company boundaries, database collection California, Miami beat Nebraska in the and interface, types of display, and the Orange -Bowl, UCLA beat Illinois in the development of on-line mapping systems Rose Bowl. Most Americans -did -not are discussed. realize that as the ball dropped over Times -Square in New -Y-ork City a EFFORTS TO MEET NEW CHALLENGES: monumental change took place in the Telephone Industry. Deregulation was a A marketing philosophy labeled ""BUSINESS reality. Years -of proceedings in Judge MARKET SEGMENTATION"" was developed in Green I,S courtroom suddenly forced the order to meet the new challenges. stable Telephone Industry into the Simply put, this strategy subdivides the highly competitive telecommunications marketplace into subsets of customers an/or potential customers, where any industry. subset may be selected as a target market. Both corporate and local Telephone companies now had a marketplace instead of a regulated operating company market views had to be territory. For example, General taken into account. GTE Data Services was given the task of developing a Telephone of Florida's operating area was basically clustered on the west system that would maintain the integrity coast of Florida around Tampa Bay and of the individual market segments, but extending east toward Orlando. at the same time allow corporate planners to ""aggregate"" the segments for Deregulation had forced General Telephone Company of Florida and the GTE a complete picture of the marketplace. corporation to look beyond these old Using RAMISII as a database manager, boundaries.New market strategies for local as well as corporate goals had to several appl",Sugi-12-102 Bornhoeft.txt
"Controlling the SAS(r) System and Its Users An Information System Tutorial Thomas R. Hoffman, Lederle Laboratories INTRODUCTION same data, and similar reporting needs for different sets of data, the controlled environment provided by an During the past decade, the SAS(r) information system is required. System has played an important role in shifting many programming tasks from the data processing professional to the end WHY CONTROL? user. In general, this shift has produced positive results; users have Improve user efficiency become more involved in specifying and solvin9 their own problems. However, Improving user efficiency is the primary oftent~mes, the user's programming consideration when introducing an .. function is not supervised - traditional information system environment. Users ~ata processing standards are easily who once spent a large part of their 19nored. The user department emphasis time organizing data, can more readily is on getting the job done and not on get to the information they need. A producing efficient and well documented library of data management tools is pro9rams. This unstructured programming available to simplify the the complex enVlronment eventually leads to a d~ta h~ndling tasks and, for many collection of SAS programs and data s~tuat~ons, the required report is libraries that is nearly impossible to already available in a library of maintain. standard programs. This program library replac;:es the ""copy and modify"" technique A well designed information system can that ~s commonly employed when a similar provide a more controlled environment report is required on a different set of without limiting user involvement. In data. Finally, on-line access to the fact, more users become involved since data often leads to a simpler solution less data processing skills are required to a complex query. t? access information. In addition, s~nce a system environment enforces data Reduce computing cost convention standards, users that are famili",Sugi-12-103 Hoffman.txt
"radically different. It is very important to understand that these activities are The synthesis of data into ""useful"" and different and thus their informational ""usable"" information is different for needs also have to be different. Only each distinct level of management in a then is it possible to construct systems company. The usefulness of the which will serve the different functions appropriate information is not apparent of an organization properly. unless the presentation of the data is different for each level of management. In 1965, Anthony stated in his work, A successful analyst must develop a Planning and Control System: A Fr~m~w~rk general framework for the synthesis and for Analysis, that management act~v1~les presentation of data, and this framework could be broken down into three d1st1nct should take into account the different areas: informational needs of a heirarchical management structure in a company. This * Strategic Planning ""* paper will attempt to present some Management control practical guidelines of what data should * Operational Control be presented to each level of management. In addition, the paper will attempt to This first management activity give some practical ideas of how the to - Strategic Planning - consists of the effectively present the information to small group of high level management each level of management. personnel who work on organizational goals and the long range plans of the",Sugi-12-104 LaValley.txt
"The Design and Pmgramming of Large Systems Using SAStm Software John M Kolman. Loyola University of Chicago PROJECT DESCRIPTION The overall proj ect was divided into four phases: Requirements Definition, In late November 1985, the author was Design, Program Construction and asked to implement a programming system Software Design. that would analyze '0. S . Census Bureau data. The purpose of the proj ect was REOUIREMENTS DEFINITION to ascertain the economic activity of smaller governmental units (towns and The overall aim of this project was to counties) . For competi ti ve reasons, estimate suppressed retail and service the gross sales of industries in sales figures from smaller governmental smaller governmental units is often units. Input consisted of u.s. Census suppressed. Members of the Sociology Bureau data. Reports summarized input Department working with a Chicago area data and highlighted missing values. market research team, developed The product of this system is a algorithms to estimate the suppressed diskette for each state, with all gross sales figures. The raw data suppressed values esti.mated. No design comes from three sources: the 1980 changes were generated by the selection population census, the 1982 retail of SAS as the programming language census and the 1982 service industry vehicle. census. DESIGN PHASE Project specifications consisted of 30 typewritten pages. The overall Top down or bottom up? Low level development timetable was approximately languages (COBOL,BAL,FORTRAN) often six months. profit from a bottom-up design approach as designed routines increase the LANGUAGE SELECTION PROCESS richness of the language set. SAS procedures are effectively one-line Before approval to begin this proj ect implementations of pseudo-code was obtained, we were required to statements, thus it would appear a top- submit a general project timetable down design approach would be along with associated costs. To reasonable. As is usually the case, a develop a",Sugi-12-105 Kolman.txt
"The Busman's Holiday: Automating the Systems Development Process Roger E. Booker, sandrose Software International Julie Keenan, Midcon Corporation I. Introduction First, there is the highly variable nature of the process itself. There are Would a bus driver spend his vacation on nearly as many ways to develop system~ a bus? probably not. As programmers as there are ways to skin a cat. Des1gn and systems analysts we spend a great methodologies vary from data-based deal of time and effort developing methods to process-based approaches and computer systems that automate the tasks various flavors in between. Programming performed by our clients. But, like a efforts range from egalitarian ""egoless bus driver who would not consider taking programming"" teams, to the ""super- a bus trip for a vacation, we have not programmer with support"" approach. been nearly so successful in applying Process specification may involve a automation to our own efforts, namely, top-down structured method or results- the systems development process. oriented prototyping efforts. It is difficult to imagine an automated method Evidence of this lack of success is not that would support all of these difficult to uncover. Despite many approaches at once. But each new system advances in software technology, the presents different problems to the applications backlog at most MIS shops developer, some of which may be better remains largely intact, stretched two or served by one approach over another. If three years beyond available resources. automation limits the development Industry requirements for entry level process to a single methodology it may programmers is expected to be one of the lead to suboptimal development of brightest growth areas for employment certain classes of systems. into the 1990's. Second, there is the creative nature of Yet, effective methods for addressing the systems development process. I'm this situation have already been sure that many of you have known proposed. The use",Sugi-12-106 Booker Keenan.txt
"AUTOMATING DOCUMENTATION: OR HOW TO AVOID THE REALLY DULL WORK AND STILL KNOW WHAT YOU'RE DOING by Fred Gehm Syntex Research If some of the manipulation is not done by No experienced programmer doubts the value of machine, then the places in the programming documentation. At least, any programmer who did is likely to be made a believer by their sequence that the data is altered must be recorded. For example, at Syntex we occa- first experience with a large poorly documented sionally need to text edit program output. project or, worse, a project whose documenta- When that is done, the fact that that is tion is wrong, On the other ~and. documenta- done is text edited onto the output on the tion ;s always a low priority task, and, there- fore, is always being put off until after more source line. Also recorded on the output source line, automatically in this ~ase. is important work is finished. the job number and execution date of the program that produced the output and the Moreover, probably because documentation is programmer's initials. This information is dull beyond belief, few programmers seem to captured in the program fragment in Exhibit enjoy it. The result is that documentation is often done poorly if it is done at all. One l,which, in turn, is %INCLUDEed into the program. This information is placed in the way to avoid the tedium of documentation and output using put statements if the output is still get the benefits is to automate the created in a DATA NULL or FOOTNOTE state- programming function. This paper presents a ments if a PROC is-used~ An example of the set of conventions, techniques. and programs that allow the programmer to automate the docu- later is: FOOTNOTEl 'SOURCE: BIOCLIP &SOURCE &DATE T-l 1/5'; This results in this mentation function to a considerable extent. More important, several of the techniques will footnote: produce documentation that must be correct. SOURCE: BIOCLIP FSG#1234 (01/23/B6) T-l 1/5 Handmade documentation is under no su",Sugi-12-107 Gehm.txt
Design the primary Menu Electronic mail is beneficial to a broad range of PRIMARY.MENU l) BUILD. PROGRAM users. An electronic mail system based on SAS/AF FREE. PROGRAM and PROC FSLETTER is easy to implement and has the Implement password protection added advantage of initiating new users to the SAS* PASSWORD. PROGRAM 2) Write capability environment. The purpose of this paper is to WRITE. PROGRAM J) Send capability SEND. PROGRAM provide and describe the code used to implement an 4) BOXBUSY.PROGRAM electronic mail system using SAS/AF and FRoe BOXERROR.PROGRAM FSLETTER under MVS/TSO. Read capabilitiy READ. PROGRAM 5) INBOXALC. HELP,Sugi-12-108 Hutchison Wheatley.txt
"A Rule Based Expert System Implementation For SAS® Software H. Pat Artis Morino Associates Vienna, VA 22180 1.0 Introduction Although the rule proposed to identify big clients is quite simple, it depends on the analyst's sense of what the adjective big means in terms of annual sales volume. In reality, such values are more Artificial intelligence (AI) is a broad subject area that spans the adaptive rather than a constant in nature. If the analyst fails to range of topics from natural language query languages for end users to state of the art research projects currently'being con- identify a reasonable set of clients using one value a filter, then the analyst may reduce the threshold values and repeat the data ducted that mimic human reasoning. In this paper we will discuss selection. By reducing the threshold values, the <3.nalyst leaves the the use of rule based expert systems that apply the concepts of realm of boolean logic (i.e., clearly true or false) and enters the approximate reasoning and a proposed implementation for ex- realm of hunch playing that distinguishes the expert. Simply de- tending the SAS language to incorporate these features. In partic- ular, we will discuss: fined, the expert uses experience and intuition to make high prob- ability assertions based on incomplete or vague data. Rule based expert systems use the notion of fuzzy logic to represent the gray the nature of expert knowledge and its representation, area of rule evaluation where the rule is not clearly true or false. fuzzy logic, 3.0 Fuzzy Logic rule evaluation, and After the expert has developed polices (I.e., sets of rules) that the subroutines and functions required to implement these describe their approach to analyzing the information, they must facilities for SAS users. then develop a vocabulary that defines adjectives like good and bad for metrics evaluated by the rules. Although these definitions initially appear perplexing to the analyst, they can be defined in a While not e",Sugi-12-109 Artis.txt
"election screen, as shown below. Setting up a user~friendly PRoe FSCALC application requires knowledge of PROC FSCALC and the special tools available for developing such an application. First, the developers must think variable selection Screen about how the software works. They are gOing to be pushing, or sending, commands to the command line using the program Spreadsbeet Heme: KAI"" screen, and they must always be aware of which screen the com- SAS dah set ___ , Libref: IN lIemname: INVNTRY mand is being pushed to, as well as what effect the command Type of variable salechon A (s.select,E=e~clude,A=all): has on that particular screen. Second, they must be aware of the '0. Type Label special variables that are available within the FSCALC procedure _ ITEM """" that allow them to control the environment for the users. Finally, _OTR! '"" they need to be able to second-guess their users in order to _ Q'l'R2 '"""" _ QTRl '"" _ QTU program around any problems users may run into while using the '"" application. Tools to use There are many tools available for your use if you are developing a user-friendly application for others. These tools are often used together to make the application easy to use. A description of the commonly used tools is given below. The _COMMAND_ variable is probably the most important tool you will use. It is a special PROC FSCALC variable that is Again end users would be left in a screen they might not be able assigned a character string. This character string cons",Sugi-12-11 Brideson.txt
"MAN-HOUR ESTIMATING SYSTEM Laura Donley Background computer systems or SAS. Adding system clists to the Base SAS software permitted us to develop The Ventura Division of Northrop Corporation screen formats, or menus, that allow an inexperi- produces je't-powered and propeller-driven aeri a1 enced person to use a few simple keystrokes to target drones for both international and domestic make the system work. sales. Each aerial target system is a complex entity involving not only the flying hardware Because menu-driven systems require minimal it~ training and documentation, they are ideal for and the equipment needed to launch but also spares and repair parts and the equipment needed infrequently used systems or for systems used by inexperienced personnel. Using menus to drive for maintenance. The Ventura Divisionis Supply the system also provides good structure for Support group has three jobs in relation to the parts~ spares, repair and maintenance of the the development process. The system's data requirements dictate the menu structure and, in flying systems. The first job is to identify turn, the menu structure provides a framework for the spare and repair par-ts needed to support the modular development of the system. these systems. The second is to make arrange- ments to have the parts manufactured and shipped in the needed quantities at the right times. The Man-Hour Estimating System incorporates a The third job is to create and maintain a series of SAS programs invoked by a clist. We detailed combination picture book and parts devised a method which allows the user to log list--called an illustrated parts breakdown--for onto TSO (Time Share Option), execute a clist, related technical manuals. and call SAS interactively. The user expends very little effort to enter the system. Once the Man-Hour Estimating System program has been Statement of the Problem initiated, the main menu appears on the terminal screen. We designed the menu so that information Until rece",Sugi-12-110 Donley.txt
"STRACT demand projection. Long-term manpower allocation, then, might be based on poor The inconsistencies in the flow of work through information from a long-range capacity plan. a manufacturing floor in a high volume, low similarity environment make WIP (Work in To reduce the error in manpower allocation and Process) projections difficult for short-term long-range capacity planning, an accurate model decision making. How much work will be in each of current Work in Process and short-term of our manufacturing departments tomorrow, next workload shifts is essential. Both Production week or next month? We needed to answer these Planning/Control and Manufacturing Planning are types of questions to do effective workload interested in such a model. planning. The IBM facility in Owego, New York is the major supplier of circuit card Basis for using SAS® Software assemblies (pages) for IBM1s® Federal Systems Division. We manufacture many unique cards of We decided to use SAS Software to develop the varying demand with each card moving through planning model for several reasons. Our many different departments and build Information Systems Support Group has been operations. When combined with the volume of overloaded with work. We needed a program in individual pages processed, a large quantity of place in a short time and SAS Software provided the means for us to develop the program data is generated. ourselves. SAS Software has been installed at We used extensively the merge capabili",Sugi-12-111 Klipsch Smith.txt
"MONITORING CORPORATE PLAN IMPLEMENTATION WITH THE SAS SYSTEM Mark F. Jackman and Kathleen D. Crook Blue Cross and Blue Shield of North Carolina INTRODUCTION STORING THE PLAN STEPS Corporate planning can be an important tool for All result statement and action step numbers achieving objectives key to prospering in a are stored in an OS partitioned data set after competitive business environment. No matter division programs are finalized each fall. how well conducted. however. such planning is With them are stored their due dates. the an empty exercise unless plans are implemented division name, the names of people responsible in a timely manner. What follows is a for their accomplishment. and the senior vice description of a simple. yet useful tracking president to whom the division manager and reporting system (PLANMON) designed by the reports. Time and staff permitting. brief first author. Director of Corporate Planning at descriptions of each result statement and Blue Cross and Blue Shield of North Carolina action step could be stored in a separate (BCBSNC). and produced using SAS software. field. This is not done currently at BCBSNC since descriptions already exist for items in PLANNING OVERVIEW the written division programs. Health care financing is a rapidly changing and The above fields are defined in the SAS INPUT competitive field. Growth and financial statement. as is a blank field for each step success in this volatile environment require status (complete, incomplete, transferred to leadership in product development. marketing. another division, unauthorized, on hold, service delivery, cost containment and changed or removed). Also defined are blank administrative efficiency. Corporate planning fields reserved for coding a past-due flag for has proven to be valuable to our organization steps not completed when originally scheduled. in coordinating divisional efforts and whether the delay has been addressed. and the new target date. resources to achieve th",Sugi-12-112 Jackman Crook.txt
"INTEGRATING INFORMATION SYSTEM TECHNOLOGIES: LASER PRINTING, MODEL 204 DBMS AND SAS* Judith H. Mopsik, ORI, Inc. The following topics will be addressed in the sections that follow: INTRODUCTION o Design considerations: Acquisition, Storage, and Distribution The acquisition, storage and distribution of o Integrating the SAS system with Model essential infonnation is a cananan problem in 204 data processing. In order for the distribution o Factors that lead to success of the data to be completed in a timely manner, the data must be obtained, validated, edited, and integrated into a database as quickly as OESIGN CONSIDERATIONS possible. A computerized information system with on-1 ine access to a database, distributed The acquisition, storage, and distribution processing, and an efficient database manager of data must first be considered from the user's provides the general framework in which to solve point of vi ell. A systems approach can then be this problem. The system's design is crucial to taken, which separates these three areas into it's long range success, and a combination of their external and internal ""views"". Finally, the right technologies is needed to meet these the software and hardware must be se1 ected that requirements. Their use must be well thought most appropriately meets these requirements, and out so that extens ive data conversi ons are not unites it into a complete information system. required to go from one processing phase to the next. Future advances in technology must be Figure 1 presents the logical flow of data considered so that hardware upgrades, new in an information system, as it might be viewed versions of operating systems, and future by an end user of the data. The data can be enhancements to the programming languages can be acquired through a variety of sources including taken advantage of. interviews,' survey forms, and electronic media such as diskette or magnetic tape. The data This paper will describe how an information must",Sugi-12-113 Mopsik.txt
"Mr. TIB"": A Test Item Bank for Physician Assistants Thomas P. Reardon, University of Nebraska Medical Center proauce a prototype system, and to INTRODUCTION incorporate the acceptable portions of the prototype into the final Mr. TIB is a Test Item Bank for Physician version without re-writing all of Assistants, administered by the the code. Since there were over university of Nebraska Medical Center for 3,000 questions on the old system a consortium of Physician Assistant that had to be re-entered by hand, programs, and used to generate rapid development of a proto-type examinations from questions of known data entry system was essential. quality. Questions entered into this system are 3) SAS/AF provides a user friendly assigned a unique question (TIB) number interface to the system. and are classified by several different methods of describing the subject area. Using SAS PROCS ad-hoc reports can 4) Once the question is entered a history of be produced i n a f r act ion of the its use is maintained, along with time that would be required by a standard measurements of performance. 'I conventional language. Tests are produced by the MR. TIB Central :.1 Office (UNMC) as requested by a participating institution. They may be SYSTEM STRUCTURE generated by entering the TIB numbers for ALL the questions or by some combination The MR. TIB System consists of three of manual and random selection of major sub-systems, developed using the questions. SAS/AF facility. They are the Database, Along with the test proper, answer keys, the Test Generator, and the Report a key phrase report, and an update index Generator. The user selects the sub- is produced. system, and the operations to be performed by that system, through a After the examinations have been given, hierarchial system of AF menus. the completed tests are processed by an Information is passed to the underlying optical scanner, which produces the processes through AF user fields. grades, and the question performance sta",Sugi-12-114 Reardon.txt
"This paper describ es the develop ment of a sys- At their request we began the develop ment of a tem to circula te custome r compla int informa tion, databas e and data analysi s system. The objec- establi sh a databas e with the data, and statis- tive was to do statist ics on the informa tion tically analyze the results using SAS®f acilitie s and present the results in a profess ional and availab le on a Corpora te IBM Mainfra me. Repeat- ""not too statist ical"" format. We actuall y sat ed request s for statist ical analyse s of custome r togethe r during the program ming of almost every data in filing cabinet s precipi tated develop ment phase of their system. of the system. The paper describ es data entry into the databas e using PROC FSEDIT, forms de- velopm ent under PROC FSLETTER, and presen tation graphic s from PROC GCHART.",Sugi-12-115 Bush.txt
"BATCH ENVIRONMENT SAS AS AN AID TO MANAGERIAL DECISIOl'! MAKING Virginia N. Adams, Tennessee Department of Revenue Summarizing Files Introduction For most of our applications, information requested varies Most government agencies, and indeed probably most SAS significantly, rendering keyed access infeasible. To answer users, are restricted to a batch environment, but they must still most questions from the department's managers or tax render quick decisions often without the aid of on-line file access.- The utility of a decision is directly correlated to the auditors, the legislature or taxpayers, several tape files must be merged. Most of the taxes have a master file of demo~ quality (not quantity) and timeliness of data available. We consider batch processing a necessary evil that is here to graphic data and transaction files containing tax returns. Often stay. The volume of taxpayer records with which the Depart- there is additional data from another department such as ment of Revenue deals as well as state government's cautious Employment Security or from Internal Revenue Service to be pace toward technology prohibits most interactive capabilities, merged. menus, and other user-friendly features. This doesn't keep us Summary files have been developed that bring much of from having to respond quickly to inquiries from our legisla- the above together and make them available before the ture, the taxpaying public, lobbyists, special interest groups, question is asked. or any of our other bosses. A summary file example: Problems Germane to Large Files Sales tax data is frequently queried since it represents the The greatest part of the Tennessee Department of largest portion of our tax base. Demographic data from sales Revenue's data is financial and demographic information from taxpayers is extracted weekly from the 1MS database. taxpayer returns. Many of these files have millions of records Monthly, we read the extract keeping only current and recently closed acco",Sugi-12-116 Adams.txt
"d the baSics, there are other steps that you can take to System resources and software are just a few of the factors that insure that the available resources are used to their best advan- impact decisions regarding development of new applications. tage. If you do not want to submit commands for your users, or You should take a closer look at the specifics of SASjAF® soft~ if your users are familiar with the SAS interactive environment, ware in order to anticipate and plan for both needs and problems you may decide not to use the SAS Display Manager System. that may arise in a new system. This can save you approximately SDK of memory (OS and CMS operating systems). However, not using display manager would Hardware Considerations mean that you could not use the AUTOEXEC feature that allows you to issue OMS commands for your users. The AUTOEXEC You should consider every detail, even the hardware that will be command permits users to enter an application without needing used. How much does SAS/AF software know about the termi- to know SAS commandS. It can also be used to reset OMS func- nals that are used? The configuration of the screen is stored tion keys. Note this example in which the OMS function key 6 for with the screen, meaning that a screen created 9"" a 30 X 132 the PROGRAM, LOG AND OUTPUT windows is reset: configuration could not currently be displayed on a 24 x 80 config- uration. Also, if you want to take advantage of colors and other highlighting attributes, the term",Sugi-12-117 Harris.txt
"NUMERIC PRECISION CONSIDERATIONS IN SAS® SOFTWARE Richard D. Langston SAS Institute Inc., Cary NC One of the most common problems facing the SAS® Before discussing the limitations and user is the problem of numeric precision. The shortcomings of the floating point fact is, the SAS System stores numeric values in representation, let us first see the format in floating point representation, which can which the number is stored. I will present most introduce problems of which the casuRI 'lser may cf the examples in IBM mainframe format, that is not be aware. This paper attempts to shed some used on MVS, eMS, VS1, and similar operating light on the method of storing numerics in ~ystems. A floating point number is represented by a number (called the mantissa) multiplied by floating point representation in order to increase the awareness of the SAS user. Also, we a base raised to a power. In the case of the IBM discuss some caveats caused the use of by mainframe format, the base is 16. So, for * floating point representation. example, 1 is 1 16**0, and 32 is 2 * 16**1. Negative numbers have negative mantissas, and numbers that have an absolute value less than 1 It is appropriate first to discuss decimal have negative exponents. This is all very much the same as what you may remember being called numeric representation. This form of storing ""scientific notation"" except that powers of 16 numbers seems natural to us because it was are used instead of powers of 10. developed on the basis that we have ten fingers on our hands. We all know how to add, subtract, multiply, and divide based on algorithms we A further aspect of scientific notation and learned by rate when we were children. The floating"" point representation is the use of decimal system had been adequate for our numeric fractions. For decimal scientific notation, a needs up until the computer age, when binary number is represented as a mantissa between 0 number systems became a necessity due to the and 1 raised to",Sugi-12-118 Langston.txt
"SAS/SHARETM Software Overview and Features Bill Brideson SAS I nstitute Inc. Cary, North Carolina INTRODUCTION The concept of one SAS execution communicating with another SAS execution is This paper covers three areas. The first section certain to be new to many computer users. presents an overview of SAS/SHARE software For many years operating systems designers and describes how the software is used. The have made great efforts to ensure that each second section recounts the past year's progress user's program can be completely unaware of the existence of every other user's program. in taking the software from its research and development stage to the pr'esent. The last SAS/SHARE software turns this around and section tells you about some ideas we at SAS® introduces you to communication between Institute have in mind for new features in future programs; the formal name of this is inter- releases of SAS/SHARE software. process communication. Since this paper has a lot of ground to cover, I software transparently executed by a user's SAS program that reads and writes data via a will avoid detail during this session. I realize this will leave some of you with questions; we communication path with the SAS server hope to be able to entertain detailed questions instead of directly to disk or tape storage. about SAS/SHARE software in our birds-of-a- feather session this evening. When a DATA or PROC step in your SAS program attempts to read an observation from a shared SAS data set, your SAS execution transmits a request to the SAS server for the AN OVERVIEW OF SAS/SHARE SOFTWARE observation you want to read. Then the SAS server reads that observation from the disk SAS/SHARE software includes four related areas of function: on which your SAS library resides and transmits that observation to your SAS execution. Your DATA or PROC step then a SAS server, which manages users' requests for concurrent data access. processes that observation. A SAS server is a SAS execution that",Sugi-12-119 Brideson.txt
"An Introduction to SAS/DMI® Software Glenn H.ltano, SAS Institute Inc., Cary, NC Kerrie Brannock, CIBA-Geigy Corporation, Greensboro, NC Introduction The name of the PDS member, and therefore the panel, is PHO- NEPAN. Many of the words and symbols have_ special meaning SAS/DMI® software is a software product that binds the SAS® to ISPF and are not shown on the panel the user sees. Figure System with IBM'S ISPF product. The purpose of this tutorial is 2 depicts this panefas it appears'when displayed as' a part of an to introduce you to ISPF Dialog Management Services with an ISPF function. "" - emphasis on creating dialogs with SAS/OMI software. We Number Registered: 10 assume that you are an experienced TSO, SAS, ISPF, and CUST user. ~me ===> JOSEPH .DAVIn Phone .... > ISPF Dialogs or With ISPF you can write interactive applications, dialogs. An Press END to Exit ISPF dialog typically consists of a series of panels on which the end user fills in information or selects operations. Based on the Figure 2 Data entry panel PHONEPAN in use users response, certain actions are taken. A few examples of dia- log panels that are part of an ISPF dialog are A typical panel consists of body and processing sections. The body section is the part of the panel to be-cUSplayed, The'process- · the ISPF Primary Option Menu ing section can contain special programming statements for · the edit panel where user has to fill in data set name tasks like input data validation and cross-field checking. A ~}""-il1 · a partitioned data set (PDS) member selection Ii~t. column 1 always marks a section boundary. Thus )~ODY denotes the beginning of the -body and )PROC denotes th~ ending- of the Dialog Components body' and the beginning of the processing section. )END' denotes the end, of the pariel. An typical ISPF dialog consists of · Panels - screens the user sees The body sa'ction ca,n CQntain' text, variable input. and v-arlable · Functions -, programs that control the displaying of panels output",Sugi-12-12 Itano Brannock.txt
"(LINCOMB2)*, tern. User-written procedures allow extension and customiza~ion of the SAS system to meet specific needs llOt already met by the LIHITEMl ( @LISTVAL(2, 1) LINVAR current capabilities of the SAS system. Historically the languages (@LIST(2.1) NUMBER. 1 a.vailable to program user~written procedures have been FORTRAN ( ""*"" LIUVAR. I @MARK(3) EMPTY) and PLl. With the introduction of version 6 on the PC, the whole ). SAS system is being re-writ.ten in C. In order i.o develop version 6 on IBM mainframes SAS Institute developed a version of the LAT~ LnHTEH LINSIGH «@LISTVAL(2 ,1) LINVAR I (@LIST(2,1) TICE C compiler for IBM mainframes. With the SASjCTMNative NUMBER Compiler for IBM 370 systems, version 5 user-written procedures ( ""*"" LINVAR I @MARK(3) EMPTY) ) can be written in the C langugage. ), There are several other significant enhancements to user~written ""INTERCEPT"" I ""IKTERCEP"" @MARK(O) LIBVAR procedures in version 5. The specification and parsing of a user- ONEVAR, written procedure granunar has become simpler with the addition of a high~level language grammar parser. In 82.4 a user-written @MARKCl) ""+"" I @MARK(2) LIBSIGH procedure grammar parser consisted of either Institute supplied a..'!sembler macros or the user's own assembler code. Beginning with version 5 the parser interface has been reworked so that the use of The semantic actions @LISTVAL, @MARK ,@SPECIALa.re used C , PLI ,or assembler languages to perform parsing is supported. Also the available Don-c",Sugi-12-120 Ihnen.txt
"mpany s hou1 d be included in the output data set. ABSTRACT This parameter will be discussed in greater An efficient macro program XMERGE was written detail in the following section. to merge two or more data sets ina manner similar to MERGE except that the resulting DETAILS data set contains the cross product of observations, i.e., all possible combinations of observations across data sets. In the The XMERGE macro merges two or more data sets case where a BY statement is used, the cross in a manner similar to MERGE except that the product is generated within each BY group resulting data set contains the cross product designated according to the BY variables. of observations, i.e., all possible This allows a data set to be subset and/or combinations of observations across data expanded by merging observations according to sets. When a BY statement is used, the cross the structure of another data set. product is generated within each group designated according to the BY variables. The XMERGE differs from the normal merge in SYNTAX the following manner: The XMERGE statement is as follows: Without a BY statement = Dataset! Dataset2 ··· , XMERGE ( INDATA OUTDATA Dataset , The normal MERGE will perform a one-to-one = BYVARS ID! 102 ··· , = merge, matching the first observations of PRESORTD No · each data set together, the second = INSET Dataset! and Dataset2 observat ions of each data set togethe r, and = so forth (Example !). XMERGE will perform a or Dataset3 ··· ) many-to-many m",Sugi-12-121 Schneider Tong.txt
"of Michigan ABSTRACT: The SAS* System improves the efficient generation of analytical reports particular to the healthcare industry. A major industry-specific program (""CARS**""), in which latest SAS* Sytem releases work in combination with older IBM mainframe products, is discussed. The methodologlies reviewed often require millions of data records to enter in selection, . summarization, merging, and reporting processses-- therefore, the relative strengths of the SAS* System are compared to COBOL and Data Analyzer*** in benchmark testing. Healthcare claims are examined to determine the costs associated with such factors as medical procedures, places providers of service (~ . .8.., of service, types of service, physicians and/or hospitals), and more. The goals involve establishing summations, averages, and other simple statistics relating to healthcare claims in a broad health services region. The SAS* System is shown to be especially advantageous in the CARS** program for summarizing and merging data from different files. For some data selection needs, COBOL is found to be marginally superior, and for some data summarization requirements.Data Analyzer*** is found to be preferable. TEXT INTRODUCTION: (cont.): Even though ""SAS*,"" as an acronym, PPO plan,"" ""the Par(ticipant) no longer stands for anything, the Plan,"" etc. BCBSM*-developed application, ""CARS**,"" stands for ""Claims Analysis Reporting 2. Group -- a division of plan coverage, ~. R., ""the salary System."" It's probably",Sugi-12-122 Tate Woods.txt
"he code Is abbreviated and not meant to be complete. 'Run' statements and other goal ancillary code Is intentionally not included.) This is how many of us developed SAS® systems describe information system that is ... when the SAS® System ran only in batch mode. EASY TO DEVELOP SAS® data sets were often temporary and data editing was accomplished in the data step or by EASY TO MODIFY changing the input data on the cards. This mode of operation didn't allow for convenient data handling which is important for any information system. The paper will be divided into two parts: With the introduction of the interactive line mode it became possible for direct interactive editing of a overview SAS® data set with 'proc edito(. Data was typically input via an 'infile' statement into a permanent SAS® data set: PART 1; develop simple example data my.labdata; PART 2: infiJe myfile; apply structured techniques input drug rat bpi PART 1: SIMPLE EXAMPLE proc editor; Assume a scientist is collecting blood pressure data on rats:o proc print; PART t : example data With the introduction of SAS/FSP®, full screen SAS® VARIABLE NAME DESCRIPTION interactive input and editing of the data became possible with 'proc fsedit'. The system developer drug drugnum~ rat rat number needed only to create an empty data set in the intitial blood pressure bp data step: data my.labdata; The most primitive information system would input length drug rat bp 8; the data via the 'cards' statement into a temporary stop; S",Sugi-12-123 Bemis.txt
"SAS* based systems to monitor receipt of assessment forms and compliance with assessment date windows for the Infant Health and Development Program are described. Upon receipt of an assessment form or missed-assessment report, the coordinating center data control staff log the appropriate information into either the forms-inventory or missed- assessment inventory files. Three types of reports are produced monthly and disseminated to our eight study sites. The Window Monitoring List Report provides listings of form status for individual infants. The Window Monitoring Summary Report provides similar information tabulated by site and form. Finally, the Assessment Monitoring System Graphic Report shows plots of the percent of forms due which have been received, not received, and administered within the window, by week since the beginning of the study. Following the",Sugi-12-124 Constantine Shing Pechler.txt
"INTEGRATING SAS* SYSTEM ANALYSIS AND REPORTING INTO AN ISAM PRODUCTION ENVIRONMENT ON THE VAX* Warren Repole, Jr. Info Tech, Inc. For years, large-scale production systems shortcomings have since been addressed by the introduction of SAS/AF* product and the recent have been developed in mainframe environments, many of them based on IBM hardware and software development of the SAS/SHARE* product. However, some data administrators have been standards. The recent growth in use of other operating environments has forced some reluctant to put so much emphasis on third- organizations to look seriously at the party software, including the SAS System. when conversion of existing computer ~ystems to equivalent software can be put together with the basic tools already available. these alternatives. Among the commonly investigated options is the VMS*operating system offered by Digital Equipment on its ISAM DATA MANAGEMENT machines, including the VAX series. Acknowledging this expansion, SAS For an information system recently Institute has developed a version of the SAS developed for a VMS installation, the data structure chosen was that of ISAM files System that runs within the VMS architecture, first for the VAX minicomputer and then for the maintained through a dialog consisting of MicroVAX* Many of the benefits of the SAS interactive PL/r processes and FMS*application screens. A common data dictionary was defined System that made it popular in the mainframe containing information for four separate sub- world hol~ up well in the transition to VMS, but some organizations still prefer to keep systems within the original production system their major applications, especially day-to-day design. production systems, in architectures that match up to previous designs. either in terms of the Among the reasons for the choice of rSAM dominant IBM standards or the newly-available were: (1) direct access capabilities, (2) less architectures such as VMS. file contention, (3) compatibili",Sugi-12-125 Repole.txt
"SAS® SOFTWARE IMPLEMENTATION OF ROCKART AND TREACY'S DATA CUBE: A TYPICAL EXECUTIVE INFORMATION SYSTEM Paul OldenKamp, Group Health Cooperative of Puget Sound The Environment at Group Health There is a revolution occurring in the way businesses use computers. No longer are they the Group Health Cooperative is a staff model sole property of the data processing department. People outside the Information Systems Health Maintenance Organization based in Seattle. Its 6000 employees serve about 320,000 members profession are providing for themselves the throughout the state of Washington. Group Health information they need in their daily work. provides both health insurance and direct medical Microcomputers have played an important role in services to its enrollees. While there has always the revolution but it is now spreading to all types been competition in its insurance business, for of computers. decades no other HMO's operated in its market area. Recently about a dozen HMO's have started Executives are one group that is starting to use operations in or expanded into Washington State. A computers directly and this use was described by previously steady growth in membership at Group John Rockart and Michael Treacy in their article, Health has stopped and in the last two years there ''The CEO Goes On-line"".1 Rockart and Treacy called has been a small decline in membership because of the system of data, programs, and supporting the new competition. personnel that these executives used an Executive Information System(EIS). At Group Health While the competitive pressure has provided an Cooperative of Puget Sound the Information increased demand for an EIS, the need for better Resource Center has developed an information management information has been expressed in a system that is modeled after the system described variety of ways for several years. Throughout in the Rockart and Treacy article. The system that 1983 a task force of managers studied their is now operating i",Sugi-12-126 OldenKamp.txt
"MAKING HEALTH ANALYSTS INDEPENDENT: A USER-FRIENDLY MANAGEMENT INFORMATION SYSTEM Leslie L. Roos, University of Manitoba Andre Wajda, University of Manitoba J. Patrick Nicol. University of Manitoba INTRODUCTION A linkage module: LINKS is a series of procedures which perform record linkage Continuing concerns about the cost and between datasets, thus enabling matching quality of health care suggest the importance across files. of making it easier to analyze data relevant to questions of utilization, new programs, and technology assessment. Health Applications System (HAS) provides a fast, low-cost Command Language management information system for analyzing data available on existing hospital discharge simple A command language provides abstracts, medical claims, or cancer control over: registries. the selection and specification of The information system outlined here is background characteristics, diagnoses, designed to be responsive to the perceived and procedures which define records to be needs of an important group of end users entered into the reports or statistics: health policy analysts. Analysts should be able to access necessary 1nformation as easily the selection of time periods for which as possible with minimal help from programming reports are to be created; and staff. To the extent that programmers are involved, the software is designed to improve the presentation and detailed breakdown programmer productivity. of statistics by various classifications. The Health Applications System is a set of modules written in the SAS* System's macro Each module in the Health Applications language; these modules allow the System begins with the program call statements nonprogrammer to put in his own control and ends with the RUN statement. In order to statements and run applications which would distinguish between SAS statements and otherwise involve complicated programming. statements written usihg the macro processor, Thus, SAS' modular structure facilitates eac",Sugi-12-127 Roos Wajda Nicol.txt
"BLES Bruce W. Eagle, Ameritech Services Ralph F. Catalanello, Northern Illinois University INTRODUCTION ABSTRACT The importance and urgency for understanding A major function assumed by many of today's and controlling health care costs cannot be Corporate Human Resource Organizations is the overemphasized. According to a 1984 U.S. provision of data processing application ser- Chamber of Commerce survey, $610 billion are vices and developments for Benefits Depart- spent annually on employee benefits [3]. ments. A topic of much interest to benefit Today, more and better health care is being professionals is the cost factor associated sought by a work force that has grown to expect with maintaining the physical and mental well- easy access to health care with little or no being of the workforce and their covered depen- concern for the cost. And the reasoning: Why dents. Executives nationwide have a growing should employees care about cost when the bulk concern over the perpetually increasing pre- of the financial burden is borne by employers miums and expenses of employee health insur- through their group medical insurance policies ance. And with this concern comes a very real [4]? Well, employers are certainly reaching need for expanded and flexible health care data their limits in tolerating any such attitude analyses and reporting. ' and in fostering any such complacency toward the escalating costs of medical care coverage. Our SAS application presents a sampling of They are",Sugi-12-128 Eagle Catalanello.txt
"COMPARISON OF THE AVAILABLE EXITS The new user exit for the INFILE and FILE Let's look at the available exit facilities and their statements allows users to read and write records !"" advantages and limitations, from almost any type of data set within the SAS® DATA step. The user can set up appropriate parameters and options, define SAS User-written procedures variables for such, things as input keys and feedback codes, print messages on the SAS log, and more. Technical Report P-156: INFILE/FlLE A user-written procedure is called like any other Statement User Exits fully documents this SAS procedure, able to accept options, interface. This paper presents the features of parameters, and SAS data sets as input and to this exit, discusses appropriate applications, and create output SAS data sets and generate report outlines a sample exit. output. Many users trying to access other DBMS's in the past chose this method for its flexibility. However, the procedure is solely",Sugi-12-129 Marshall.txt
"SAS· SOFTWARE INSTALLATION--THINGS YOUR SITE REPRESENTATIVE NEVER TOLD YOU John W. Davison, Jr., FACTOTUM other materlal WOUIO walt 1n nis ""lnR Introduction 1. basket until he got around to them. On one occaSl0n lnstallatl0n ot a new This paper had its genesis at a release was delayed for several weeks Birds of a Feather session at SUGI 11 during which time end users impatiently when someone asked why SAS Institute does awaited the changes that made possible a not provide more information on some new application. aspect of system use. After several years as an installation representative The other support staff comprises knew that the help desired and more is the SAS consultants. The site rep and available on the distribution tape and consul·tants, designated as such to SAS its accompanying material, and said so. Institute. should normally be the end That led to my being asked to conduct a users' point of contact with Institute tutorial on the practice of being an technical support staff. In the case of installation representative, or site rep. Version 6, the SAS System for' Personal Computers, they are the only people to whom Institute staff will talk on the The task would have been easier had telephone. The consultants may be mem- not retired soon after. as I could have bers with the site rep of a separate kept notes on my activity for the next 9roup formed for the sole purpose of SAS few months as a guide to what a site support, or they may be identified mem- representative actuallY does. Looking bers of end user units. In either case back on the past ten years I see a few they should be familiar with both SAS main points that are easy to discuss and practice and the applications that they a lot of little tricks of the trade that support. An organization with a separate are more easily shown, like those of a SAS support group might assign end user carpenter or plumber. My formal presen- staff to it for a fixed period, say a tation will be brief, and I expect ple",Sugi-12-13 Davison.txt
"An Example of an Integrated Programming and Data Analysis System Eric M. Klusman Federal Reserve Bank of Chicago AbstraCt. ways were needed to make accessing the databases eas- ier and clearer. CERES, an integrated SAS programming and data Previous systems for data analysis and SAS program- analysis system, allows researchers to analyze pro- duction databases in a large number of ways without ming were built using, variously, CLISTs to invoke SAS for each submission from inside the ISPF/PDF ed- needing to write the SAS code themselves. Users can itor, the SAS macro language, SAS/FSP, SAS/AF and choose from a variety of panels; each panel generates SAS code based on information from the user. Users SAS Display Manager System. The current system re- presents a great improvement for our OS/MVS/XA can also write SAS programs directly on a SAS pro- shop. gramming panel. CERES builds a structured Browse Index of all submitted SAS code and the resulting SAS log and output. With the Browse Index users can re- view or print SAS input, log, and output, or recapture User's view: Avoiding SAS programming. . for resubmission any previously submitted SAS code. CERES was built by enduser programmers using IBM's The user gets to CERES by selecting an option on the ISPF dialog management facility and Tangram Systems primary ISPF panel displayed after logon. Once in Corporation's IIF, an interface between ISPF and SAS. CERES (figure 1), the user specifies the begining and ending dates of a sample period and a level of periodicity (i.e., whether to use daily, weekly, monthly, quarterly, or yearly data). Mter pulling in data from Disclaitner. production or personal' data libraries, the user moves from panel to panel, specifying statistics or transf- The opinions and findings discussed below are those of ormations to be calculated, graphs to he drawn, models the author, and do not necessarily reflect a position of to be estimated, or even SAS source code to be directly the Federal Rese",Sugi-12-130 Klusman.txt
"BUILDING CUSTOM-DESIGNED REPORTS FOR FINANCIAL EXECUTIVES Edward B. Dailey, Emerson Electric Co. Jude L. Naes, Jr., Emerson Electric Co. INTRODUCTION we developed a report writer to give executives a method to run thei r own custom-desi gned re- This paper describes a report writer that ports at any time. Our objective was to keep gives financial executives the capability to the report writer consistent and easy-to-use. custom design and run any report without consult- We wanted to: ing a SAS® programmer. The report writer was deve loped by the authors for fi nanci a 1 analysts Provide maximum flexibility. Minimize typing. and executives in a Financial Planning Depart- o ment. After some background is given, the re- Keep screens clear, orderly and consis- o port writerls specific features are coverpd, and tent. its ease-of-use is discussed. Keep instructions and options brief and to o the paint. Display the report parameters as defined. o BACKGROUND Provide shortcuts for the experienced o person. Financial analysts are responsible for rore- Provide help options where needed. o casting sales and profits on different contracts. Avoi d separate llhow_to ll i nstructi ons that This data is maintained in a SAS database. Each could become obsolete. observation in the database is a forecast of a different contract IS sales and profits and is The finished product provides a tremendous identified by a forecast number. Each forecast amount of flexibility and, at the same time, re- has variables that contain monthly historical quires little typing. Executives now have the data (actuals) through the current month of the ability to run their own custom reports without current fiscal year. monthly forecast data for feeling like technical or clerical personnel. the remaining months of the fiscal year, monthly forecast data for the next fiscal year, and REPORT WRITER FEATURES yearly forecast data for several future years. Also, variables are used to categorize the fore- THE REPORT",Sugi-12-131 Dailey Naes.txt
"Within the Quality Assurance Organ- These challenges are often addressed zation of Southern California Eqison with the management philosophies of company, a SAS-based integrated three quality experts, Dr. W. Audit System has been developed for Edwards Deming, Dr. Joseph M. Juran and Philip B. Crosby. Each of use in scheduling and conducting audits. The Audit System provides these experts describe a quality comprehensive report, log, schedule culture comprising a delicate and matrix capabilities for balance between management commit- accessing current and historical ment, structure and strategy, train- audits conducted. This paper ing, quality measurement, removal of describes the major components of problem sources, and encouraging' the system, features availabl~ to ongoing improvement. Specific management and engineering contributions by Dr. Deming include personnel, and its evolution from a ""Demingls Circle and 14 Points ll (2), small prototype to an integrated by Dr. Juran include ""Journey from tr~cking and reporting system. Symptom to Cause"" (4), and by Mr. Crosby Jnclude ""Quality Improve- ment Process"" (1) . Many at Southern California Edison believe",Sugi-12-132 Lafler Mutziger.txt
"CREATING A ""USER-FRIENDLY"" GENERAL LEDGER REPORTING SYSTEM Jerry E. Clark, Pittsburgh National Bank Developing a financial management Several programming considerations require discussion. The range of information system requires substantial accounts being grouped will not always compilation of both historical, current and projected accounting data. Data be sequential. The design and the must be obtained and organized effi- programming must allow for skipping over some accounts to create a grouping. ciently, primarily from the most accurate and direct source""'"" an auto- Another potential pitfall can occur when mated General Ledger. Using a General a file is created by appending new information, rather than total recre- Ledger (""GIL"") for management reporting and analysis, however, can be difficult. ation. Reorganization of ranges in a grouping can be very dangerous because Various database concerns, historical and current values of a group In most particularly those encountered due to may have different sources. cases it is recommended that new groups usage of TSO r must be resolved. In this project, these concerns were created by be created when more detail is needed. the design goals. The finished system Though this can lead to extra. or even vacant, groups in the file. the integ- had to be ""ideal"": user-friendly. user- controllable, highly efficient - both rity of the system will be maintained. from a user and systems perspective- With the file layout and cross- and easily maintainable. reference table completed, Phase I One of the major concerns was proceeded. The files shown in Figure 3 were created and calculations defined. manageability of the data. Equations and datasets would consist of thousands But how could the limited meaning of of variables if each GIL account were such equations as identified separately. Rather than ASSETS = SUM(OF COL1-COL50) attempt to construct and maintain such a large and cumbersome database. the be overcome? An expanded chart f",Sugi-12-133 Clark.txt
"be ""'user need to know any variable names (ie., how a partic- ular variable name is spelled), nor should he need friendly"". This can be accomplished only by to know exactly what the variable values are (ie., the requiring as little understanding about the mech- anisms of the interactive application as possible. exact spelling of one of his employees). A concep- The end user should not need syntactic knowledge. tual understanding of the application combined with A conceptual understanding of the application com- a recognition of variable names and values should be all that is needed to obtain full use of the appli- bined with a recognition of variable names and values should be all that is needed to obtain full use cation. Due to particular characteristics of the SASIAF language, we were able to design and of the application. develop a menu-based system that met this goal. The user should be asked only to choose from menu The MGMT application will be discussed in this listings that in which he is interested. Furthermore, paper, with particular attention paid to those fea- the end user should be supplied with menus that tures which enhance user friendliness. These tech- are dynamically modified according to who the end niques are rather generic and may be applied to user is and what choices he has made in previous almost any menu-based management reporting screens. If these funclions are included, the end system. user is both more likely to use the application and more able to",Sugi-12-134 Baer.txt
"B. Glaser, San Diego Gas & Electric Roger H. Sorenson, San Diego Gas & Electric James Jacob C. Epperson, Southern California Edison ABSTRACT The two companies jointly own the three-unit San Onofre nuclear generating station located in SAS Institute products have been in use for over SDG&E's service territory. SCE owns 76% of the seven years at the San Diego Gas & Electric and project and operates the station. SDG&E has a Southern California Edison companies. This 20% interest while the cities of Anaheim and paper surveys the information systems developed Riverside share the remaining 4% interest. These three generating units produce, at full and applied using the SAS System at these two major Southern California utilities. The power, 2,710 megawatts, which is enough power to organizational evolution of SAS is traced, serve the needs of 1.3 million households. An equivalent fossil fuel generating unit would focusing primarily on the aspects of applica- consume 25 to 30 million barrels of oil per tions development and product support. Although experimentation with other fourth-generation year, or nearly 75,000 barrels of oil per day. languages has taken place in these companies ~ SAS Institute products continue to be the most With respect to sales of electricity, both widely used for end-user applications. The companies are vertically integrated, producing reasons for this phenomenon~ and the behavioral and transporting as well as distributing their implications of this outcom",Sugi-12-136 Roberts Glaser Sorenson Epperson.txt
"POLICY AND THE INFORMATION CENTER'S ADOLESCENT YEARS HENRY EDWARDS,CIBA-GEIGY The Information Center concept was begun over CURRENT CONCERNS six years ago by IBM in Canada. Since then, it has crossed the border and has established When asked, ""What do you see as the most itself in almost every medium to large important concerns of your Information Center?"", organization in the United States. Even though the top concerns were; I) training and 2) the the Information Center (IC) is only six years integration of different technologies, old, many changes have taken place. When the IC 3) staying abreast of technology, and 4) top was first conceived, the idea of a Personal management support. I found that the current Computer (PC) on everyone's desk was far concerns were different depending on how long fetched. Now there are professional journals the Information Center had been established. and conferences designed solely for the IC users Those organizations with new Information Centers (one year or less) were more concerned with the and managers. issue of training than those companies whose In the early stages, there were many promises of IC's were well established. Organizations with reduced backlogs, happy users, worry free MIS mature IC's are more concerned with I} the integration of technologies and 2) staying managers and so forth. There have been some major ad~antages to those companies that have abreast of these technologies. This makes successfully implemented the IC concept. Notice intuitive sense since training is a very big that I said ""successfully implemented. II There issue for the new IC when because training must has been much written about how to ensure that be done not only on the Information Center but your Ie is a whopping success and meets all of also on the concepts of computers as well. those wonderful accolades that you promised your When the concerns of the Ie were analyzed management. against whether the IC was Personal Computer The needs for th",Sugi-12-137 Edwards.txt
"The two ways- to specify an external file are by a fully qualified file name (filename) or a shorthand reference to the file (fileref). A The micro-ta-host link, part of the base SAS0System under PC DOS, fileflame could be, for example, a fully qualified path name, the name can be used for remote SAS processing and for transferring files be-- of a file in the current directory, or a PC DOS filename. A filename tween a microcomputer and a host computer. This paper focuses on must always appear in quotes, and a fi/eref must be defined according recent enhancements to the SAS link facility, 'mdud'mg external file and to operating system rules. catalog transfer, new sample scripts, additional script commands, and To use a fi/erefin external file transfer statements you must an asynchronous terminal emulator. Support for new communications define a PC fileref with the FILENAME statement and submit cards and foreign keyboards is also mentioned briefly. Finally, a ref- it locally with the SUBMIT command prior to the PROC state- erences section is included that describes all available documentation ment on the link. define a host filerefwith the FILENAME statement (VMS hosts 1",Sugi-12-138 Burnette Garner Lloyd.txt
"e EnJw.ncements to the Micro to Host Rated here are what I feel are some of the primary issues that will link paper and discusses link hardware performance and setup affect Micro to Host Link throughput and performance. Perform- issues. Topics include some software design concepts, recommended ance comparisons are listed in the order of importance and desir- procedures for starting the link, general suggestions and hints and ability. some error recovery techniques. Also included are suggestions for working with customer support and usage of the link debug bits and 3274 local channel vs. remote SSC or SDLC I. the break window. Procedures for modifying the SAS System 2. 3270 vs. asynchronous devices Micro to Host Link ASCII/EBCDIC character set translation and host CPU size and system load 3. for defining an alternate 3270 keyboard are detailed. A few com- remote 3274 line speed and user load 4. ments regarding current link devices, protocol converter support and AT vs. XT 5. 6. 3270 or async hardware model or brand SAS/RTERM coax support are added. And fmally a look at some proposed link devices, some wish list items and future research direction. All comments regarding proposed or future device sup- 1 feel that the actual PC link hardware type has the lowest impact port are regarding experimental research only and do not imply on performance as long as you are considering 3270 only or async future support by the Institute. only. In general, the type of host connection is most",Sugi-12-139 Kolb.txt
"SOME USEFUL FEATURES OF PROC REG Rudolf J. Freund, Texas A&M University PROC REG contains an amazing number of options for making a regression analysis more useful. It is the purpose of this tutorial to explore a number of these features by illustrating their use on an example data set. The options presented are: 1. A review of the ""basic"" output of PROC REG 2. The TEST statement 3. The RESTRICT statement, comparing results to the equivalent TEST 4. The NOINT option, and a comparison of results with the equivalent RESTRICT statement 5. Outlier detection, including the use of the OUTPUT option 6. Influential and leverage observations 7. Leverage plots 8. Detection and study .of multicollinearity-the variance inflation factors 9. COLLIN and COLLINOINT 10. Estimating with one data set and predicting to another. The tutorial is in the form of a set of transparencies which are not suitable for reproduction in the Proceedings. Copies of the originals are available from the author. Rudolf J. Freund Department of Statistics College Station, Texas 77843 (409) 845-3170 713",Sugi-12-14 Freund.txt
"AN APPLICATION THAT INTERFACES PC AND HOST RESOURCES Fritz E. Lehman SAS I nstitute Inc. Cary, NC The followi""ng paper is a modified version of the Forte 3270 PJ or ForteGraph emulation card case study presented in the SAS® Processing course, which is taught through the education IBM 3278/79 Emulation Adapter running in Division. CUT mode You have a raw data fHe that contains daily weather data from three weather stations in the state of North Carolina. Your task is to read the CONNECTING HOST TO PC data on the host machine, download the SAS data In this paper, the PC used is an IBM AT with an set to the SAS System for personal computers, summarize the data and produce a report that I RMA board logged on to TSO. represents a concise summary of the weather for North Carolina. When the desired report is Put your mainframe session into TSO READY finished, it should be uploaded to the mainframe mode. Once in READY mode, shift the active for later presentation. session to the PC and invoke the SAS System for PCs. RESOURCES NEEDED FOR PC AND HOST Submit an options statement with the REMOTE= APPLICATIONS value set to your kind 3270 emulation. In this example, the statement would be OPTIONS REMOTE=IRMA; SOFTWARE To run an application of this kind takes Version Other possible values for the REMOTE;;;; option 6.02+ of the SAS System for personal computers are listed below: with the enhanced micro-to-host link. Version 5.16 of the SAS System is used on the host. The REMOTE=ASYNCn enhanced version of the micro-to-host link is specifies the asynchronous needed to upload to the host any flat files RS232C communications adapter generated on the PC. Any version of host SAS System prior to Version 5.16 will not support the enhanced micro-to-mainframe link. The operating specifies one of the supported REMOTE=CXI system must be DOS 2.0 or later. CXI native mode APL control programs HARDWARE REMOTE=FORTE specifies the Forte PJ or the Fortegrap~ cards The hardware for a PC and host app",Sugi-12-140 Lehman.txt
"Optimizing IBM-PC Systems for SAS* Patr.l Narsh. North C,jr""o.lina State un.i vers.i ty simulate a ""normal"" SAS-PC job. These Introduction tasks were not only chosen in hopes that they would simulate the analyses that There are a number of ways to configure the operating system and most users would undertake, but also related software to obtain improved SAS because they would test how well the SAS systea interfaced with the various parts performance under IBM-PC DOS. Thus, the user is not forced to keep searching for of a microcomputer system. A second study repeating the above factors except more powerful hardware to speed SAS data analysis. Some of the techniques for the changing of the microprocessor was conducted on an IBM-PC AT. The explored in this paper are: (I) altering results ot both studies, as well as the BUFFBRS parameter, (2) using a RAMdisk, (3) using disk caching inforaation from other experiments, will be presented throughout the remainder of software, and (4) using a disk optimizer. These techniques are the paper. explored both for IBM-PC ATs and IBM-PC XTs and enhanced IBM-PCs. Other Figure 1 hardware constraints such as amount of RAM memory available and the presence of Benchmark Tasks Used to Test SAS-PC a math coprocessor are also examined. in an IBM-PC Bnvironment 1. Read an ASCII file of 20 character There are basically three ways that the SAS-PC system can be sped up: (1) and 10 numeric variables to make a alter the hardware, (2) alter the master data set. software, and (3) modify the computing 2. Compute mean and standard deviation environment. In the first case, some of of one of the numeric variables. 3. Merge statistics computed in #2 the options available are obtaining a faster microcomputer, changing the back into master file and use thea crystal in the machine presently being to find the extreme points used to obtain faster speed. and adding (""outliers"") in the data set. 4. Print t3. a math co-proce_ssor chip. In the second 5. Sort #",Sugi-12-141 Marsh.txt
"EFFICIENCY AND PERFORMANCE CONSIDERATIONS FOR THE SAS® SYSTEM UNDER PC DOS Gordon W. Davis, Quintiles Inc. Scott S. Sweetland, SAS Institute Inc. utility termed a disk oEtimizer that provides A. Introduction tools ~or efficient operat1.on of fixed disks. Understanding two aspects of the method in A.I Topics Discussed which DOS writes a file to a disk will enable you to understand why a disk optimizer improves This paper is designed as a tutorial for efficiency. First, DOS places data on the disk programmers who desire to improve the so that read/write operations (which occur in perf:ormance of their PC SAS® applications on short bursts as dictated by the clock crystal currently popular microcomyuters. In addition, the issues we discuss wi 1 aid those who are speed of the machine) are synchronized wi tn the formatted sectors of the disk surface. This facing the decision of upgrading their current exact spacing of data is termed interleaving. machines or buying new ones. A variety OI microcomputer configurations In addition, DOS partitions file space sequentially in 4 KD units called clusters. and hardware enhancements will be explored that Clusters are allocated at random as free sl'ace greatly decrease execution times of the SAS system. Tips will be provided for maintaining is encountered on the disk. Since SAS f1.les the microcomputers, with l'articular attention will often be much larger then 4, Kb, they can given to fixed disks. We w1.ll then look at the contain many clusters and can therefore be PC SAS system environment: how to customize the considerably fragmented. Accessing such a file srstem for ease of use and how to manage would require the disk read/write nead to locate m crocomputer resources such as memory and disk each of the file's fragments, and this can space. Finally, we will discuss some efficiency greatly increase the time required to execute a considerations for SAS statements used in the program. The Disk Optimizer N by' Softlogic DATA step. E",Sugi-12-142 Davis Sweetland.txt
"A SPREADSHEET APPLICATION USING MULTIPLE INPUT WINDOWS IN THE SAS* SYSTEM FOR PERSONAL COMPUTERS Warren Repole, Jr. Info Tech, Inc. One of the most popular features of this task through the SAS System for Personal Computers. After a bit of experimentation today's microcomputer software 1s the interactive spreadsheet. Many computer with the WINDOW and DISPLAY statements unique applications for the home and for business deal to the SAS environment on the PC, a suitable with calculations that can be simplified using prototype was completed which used multiple spreadsheets, leading to the great popularity windows to simulate a spreadsheet application. of software such as Lotus 1-2-3*. The SAS/FSP* product on larger machines The Prototype includes PROC FSCALC, a mainframe version of a spreadsheet program, hut this procedure has not The resulting system consisted of four yet been released for microcomputers. However, input windows: a summary window containing using the unique features of the SAS System for calculated totals and subtotals, and three Personal Computers, most notably the WINDOW detail windows, one each for the labor, statement, a simulated spreadsheet application equipment, and materials components. The summary information is always displayed at the can be built. top of the screen, while the components are The primary example described in this modified in the bottom half. The command line paper, designed to assist in the estimating of is used to request switches between windows highway construction costs, makes use of and to request that information be saved when multiple windows to allow modification of the final estimates are achieved. detailed cost data for labor, equipment and material components while simultaneously The construction operations which are the displaying summary cost information. This subject of cost estimation have been prototype system was developed for the previously defined with a set of default Pennsylvania Department of Transportati",Sugi-12-143 Repole.txt
"A system of programs was designed for the and OS/MVS). The main file for the study contained about 60.000 records. and the main SAS® System under PC DOS to update and edit SAS analysis file included 1015 observations a data library for a registry of patients from the Veterans Administration randomized study of with 711 variables. In the first 10 years of coronary artery surgery. Data from yearly the study. many specialized programs were contacts with patients reporting cardiac developed for data management and analysis events, anginal symptoms, medications, and using the SAS System and other languages. The hospitalizations are entered and edited in the proposal for extended follow-up required a system using customized window modules. The re-evaluation of data management since data goals of the project were to implement the data acquisition was less frequent. less complex. and on different forms. A new procedure for management for the registry on the microcomputer while maintaining the capability data management was needed with the following characteristics: to update mainframe SAS files. and to provide a (1) Int~ractive editing and updating of the user-friendly means for updating and monitoring data. the registry_ The design of the system. (2) Easy. fast. user-friendly access to the experience with WINDOW and DISPLAY statements. data by study personnel. and an evaluation of using the SAS System Under PC DOS for the application will be presented. (3) Capability to update the study ""analysis files on the mainframe with new endpoint",Sugi-12-144 Johnson.txt
"INTRODUCTION TO THE VERSION 6 SAS TEXT EDITOR WITH EXAMPLES FROM THE SAS/FSP® FSLETTER PROCEDURE Joyce Dehaan Brenda Erickson Claire Cates SAS Institute Inc., Cary, N.C. In Version 6, one text editor provides the text windows, such as the Display Manager PROGRAM editing capabilities for the entire SAS system of EDITOR window, use the MARK command to mark software. The text editor provides the editing the text you want to use, then the STORE capabilities in all windows that allow editing. command to make a copy of the marked portion. Some of the windows that use the text editor Once the text is stored in the paste buffer, you can paste the buffer contents into the same text include the Display Manager System PROGRAM editor file at a different location in the overall EDITOR window, the FSEDIT procedure window in screen modification phase, the FSLETTER document, or into another edit window. procedure window in edit phase, and the BUI LD procedure window in the display panel and in the source panel. The Version 6 text editor provides To select a piece of text, use the' MARK many new features that make editing easier command. Simply position the cursor at the th roughout the SAS System. Featu res discussed beginning of the text you want to select, and in this paper include: press the MARK key. Then move the cursor to the end of the text, just after the character you MARK, CUT, STORE and PASTE commands want to select, and press the MARK key again. The text you mark is displayed in reverse video SMARK command so you can eaSily see the selected text. Use the CUT command to move, or the STORE command to MARK command copy, the selected text into the paste buffer. AUTOWRAP command There is a shortcut to the mark, mark, cut or eOlS and TABS commands store sequence that can save time. After issuing the MARK command to begin the selection, move TF, TS, \FLOW, and \NOFLOW commands the cursor to the end of the selected text and issue the CUT command ( or STORE command) I NDENT com",Sugi-12-145 Dehaan Erickson Cates.txt
"New CBT Features in SAS/AF® Software for Version 6 Phil Busby SAS Institute Inc. Cary, NC There are several new features in Version 6 of SAS/AF(R) software that you can use to enhance ~2 CORRBCT.PORT-AU-PRINC.! your computer-based training applications. These TH.! CAPITAL or RAITI IS , features give the course builder more flexibility '"" and variety in designing CBT questions. The Very good. enhanced branching capability allows each I t 1s south of PetloDvllle. student to proceed through the course along his 12 Hint: Haitians speak FreDcll. own customized learning path. Version 6 of SAS/ AF software supports more types of question and feedback responses, so you can make your CBT courses more effective and fun to take. Seven of the new features in SAS/ AF software are 1. fill-in-the-blank questions 2. the FRAME:: option on branches 3. the WRONG= option on question frames The answer field for a fill-in-the-blank question 4. multiple correct answers to a question is indicated by an ampersand followed by optional underscores. The answer field may be up to 32 5. multiple answer fields on a line characters long. To allow embedded blanks in 6. the music interface the correct answer, enclose the correct value in single or double quotes like this: 7. the SAVE command. ? COR.1l.BCT,,·SUndard deviation' The square root of tile varillDce is celled tbe , _ _ __ Fill-in-the-blank Questions. The CORRECT= option allows the builder to ask a fill-in-the-blank question. Only one flll-in-the- blank may be specified per fr.;me. The CORRECT= option goes oli the? line starting a frame. This kind of question tests the student's active knowledge· of the subject. A multiple- choice question tests only passive knowledge because the student need only re;ognize the correct answer from a list of possib:e answers. Here is an example using the CORRECr= option: In the case of a fill-in-the-blank question, two sets of feedback are needed: the first set is for the correct answer and the second set i",Sugi-12-146 Busby.txt
"under MS DOS. This paper will briefly touch upon the SAS system and its in- Installing the SAS system on a microcom- stallation process, present an overview puter is an eleven step process. The of the UW installation facility, and Microcomputer Resource Center (MRC) at discuss considerations about MS DOS. the Uni versi ty of Wyoming (UW) has developed an enhanced facility elimi- The SAS System and Installation nating most of the work for the end- installer. This paper presents the key The SAS system for microcomputers considerations in installing SAS currently consists of the base SAS software under PC DOS, the assumptions software version 6.02 and the three governing development of UW's installa- optional packages of SAS/STAT* software tion facility, SAS Institute's SASLOAD (v6.02), SAS/IML* software (v6.02), and batch file, and a discussion of the the SAS/RTERM* software (vl.24). These influence of MS DOS upon installation. packages are released in PC DOS archival form on 5 1/4 inch floppy diskettes.",Sugi-12-147 Kiser.txt
"BSTRACT index or listing of the entries stored in a catalog and allows you to edit, delete, rename and copy SAS/ AF personal computers software for them. combines a powerful programming language with the ability to easily create customized menu- driven applications for end users. This paper PROC BUILD syntax in Version 6 introduces the new concepts in Version 6 SAS/ AF software, including new options in the BUILD The BUI LD procedure syntax for initiating a procedure statement, the panels that make up an BU I LD session in Version 6 provides more options entry, the program screen language, and for merging and printing the entries or selected conversion of applications developed with Version entries. The Version 6 syntax is: 5 SAS/AF software to Version 6 format. FROC BUILD CATALOG= BATCH I BROWSE NOCMENU NODIR PADCHAR"""" c' TEXTLENGTH=n; INTRODUCTION PRINT DISPLAYIFIELDS SHOWFILL SOURCE ATTR XREF LISTD FORM:: PRTFlLE: HEMTYPE"""" SELECT=: IEXCLUDE: ; MERGE CATALOG'"" NOSOURCE NOEDIT REPLACE UPCASE Version 6 SAS/ AF software provides the control MEMTYPE: SELECT: I EXCLUDE: j and programming capability needed to write COMPILE SELECT=IEXCLUDE: ; powerful applications for end users. The control is provided with a programming language simi liar to the SAS data step language. The program The PRINT statement allows you to print screen language uses special functions to perform individual members of a catalog, the attributes of interactive query and handle multiple screens. an individual",Sugi-12-148 Erickson Wharton.txt
"tion. There is no known human society that does not use oral communication; writing was a later development and is absent Over the past four decades, researchers have often thought that from some civilizations. Clearly, speech is our most durable and natural mode of interaction. It is no wonder, then, that we should the solution to the problem of machine recognition of speech is ""just around the corner."" Realization of the dream has been a long desire a similar interface in our dealings with machines. t:me coming, but today speech recognition is available for limited applications on both large and small computers. At SAS Institute, Speech technology has been used most often where it is inconve- nient or impossible to type information on a keyboard. Commer- developers are building a speech interface to the SAS System cia applications such as quality control in factories use speech for personal computers using the IBM Voice Communications Adapter. recognition because the eyes and hands of the operator must be free to concentrate on the inspection process. A speech interface to manufacturing process control enables technicians to continue AN",Sugi-12-149 Fineman.txt
"Transfer Functions using PROC ARIMA SUG 12 Tutorials John C. Brocklebank SAS I nstitute Inc. David A. Dickey North Carolina State University General Transfer Function Model Feedback puts you in a circular situation where you need forecasts of X to forecast Y and forecasts of Y to forecast X. I ntrod uc'tion You can use PROC STATES PACE to model a series with arbitrary forms of feedback and crosscorrelated inputs. Strictly AR models, including feedback, can In the general transfer function you allow a be fit by multiple regression as proved by target series Yt to depend on current and past Fuller (1976). variable X. expl~natory values of the A general approach to AR modeling by nonlinear regression is given by Fuller The model is (1986). Lj =o, .... l3 j Xt Yt = a Zt _ + + j where X and Z are independent time ARIMA Model Identification series. The following statements are true for the general Coefficient Patterns transfer function: It is impossible to have an infinite number of unrestricted As with a finite data set, so you Some useful patterns of 13 j in restrict the I3s to have a certain functional form depending on only a few parameters. I3 .X - · ' Noise Y =a +1:. + J=O,- J t s J t The appropriate form is determined by an identification process for the 135 similar to the are given below. usual ARIMA identification process with the autocorrelation functions (ACFs'). B :: 0 if and only if j > q. j Instead of inspecting autocorrelations, you (Y t depends only on X t _s ' X t - s - 1 ""'"" inspect cross-correlations, but you are looking for the same patterns as in univariate xt-s-q ) ARIMA modeling. The I3s are called transfer function weights ~. ; cpj or impulse·rQsponse weights. J (Y pY - Noise) CX a ;: _ + + + You can use several explanatory variables to t1 s t t forecast the target series, but they should be independent of one another for proper or equivalently forecasting and identification of the ~s. C(1-pB) -1 X Noise) (Y t ; a/(1 .p) + _ Even if the model is i",Sugi-12-15 Brocklebank Dickey.txt
"Batch File for Sharing SAS@ Software for the Microcomputer on One PC Denny Mills, John Deere Component Works 3) could invoke base SAS® software with a simple command BACKGROUND 4) would allow for data to be saved in a default ""junk"" directory if the person simply wanted to do some testing (this John Deere Component Works is like many other organizations directory could be emptied at any time to regain disk. space). concerning the ratio of personal computers to people ~ it's not high enough! Almost all of the personal computers are shared by more than one person. Until prices drop, ""personal"" computers should SOLUTION be called ""people's"" computer. We created a DOS batch me called SAS.BAT and put on the root PROBLEMS directory of the hard disk containing the SAS System. Each person using base SAS® software on that machine is asked to start the Humans are all different. Each person may wish to use different SAS System by entering colors for windows and position windows differently. Since these SAS userid are saved by base SAS® software on disk in the current directory where userid is the persons 8-character name, initials, or employee after issuing the WSAVB command, people using the SAS System number. always get the ""leftovers"" of the previous SAS session. Like the personal computers themselves, the SAS system for microcomputers can be tailored to be very personal. But if many people have to use the same machine, the SAS system for Contents ofSASBAT (root directory) microcomputers can lose its ""personal"" appeal. CLS The file ""autoexec.sas"" is llSed by SAS® software initialization. If ECHO OFF IF EXIST \%l\AUTOEXEC.SAS CD \%1 present in the current directory, it can contain Display Manager IF \%1\ ='"" \\ GOTO NOPARM commands to do different things for different people. Again, if IF NOT EXIST \%l\AUTOEXEC.SAS GOTO MAKEDIR GOTO END more than one person uses the personal computer, conflicting :MAKEDIR opinions can result. ECHO ON REM YOU ARE ABOUT TO CREATE A DIRECTORY",Sugi-12-150 Mills.txt
"The SAS® System for personal computers 60,000 80-column ,lines of data in one field (PCs) allows researchers to use SAS software season. at locations where mainframe access is difficult or impossible. In combination with Before data -recorders became available, the normal practice was to prepare field electronic data recorders, PC SAS software sheets for each of our studies. These sheets provides an efficient system for collecting, were reproduced on rainpr.oof paper, because editing, and analyzing study data. Data can our field work often must be done in adverse be collected on electronic recorders and weather. Hundreds of data sheets would be transferred by asynchronous communications used in a normal season. The filled data software to a PC for editing and analysis. By sheets would be checked for completeness and configuring the communications port on the PC errors. Depending on skill of field appropriately, data can be read directly into personnel, the need for error checking would the Display Manager of PC SAS software. vary considerably. After collection, the data Attempts to read observations into the DATA would be entered (keypunched) into a mainframe Step from the recorders failed, but if computer. Depending on the amount of data available, this capability would make the SAS System for personal computers even more useful collected during a given season, the time between collection and keypunching ranged from in research data management and analysis. 6 months to a year.",Sugi-12-151 Graham Tonn.txt
"The SAS* System for Personal Computers allows an Types of Computers IBM PC/XTjAT* or compatible to execute the SAS sys- tem. Many users see this as a cost effective way to use ~or purpos~s of t!tis manuscript we will assume that the SAS compared to using SAS on a shared (mini or main- Important mgredIents of the personal computer envi- frame) computer. We discuss this issue pointing out ronm~nt is that the mac.hines support, only a sin~e user what costs should be considered and present some ex~ at a ~e. In some enVIronments a sIngle machIne will amples comparing the costs of a PC compared to a be utIlIZed by several persons, but primarily their use shared computer. fol.lows the one person, one computer rule. As distin- gUIshed fro~ m?st shared computers, the support costs to the organIzatIon ~or PC usage are not bundled with",Sugi-12-152 Miller Parks.txt
"The arrival, rapid growth and subsequent of a Figure 1, portrays the Computing World at Avco blossoming the microcomputer as Lycoming. At the heart of the system ;s a IBM professional workstation had dynamically Impacted corporate computing in ways never 3090-200. This system, running under MVS/XA & envisioned by the entrepreneurs who founded the SNA uses three operating systems TSO, CICS, and IMS to drive 32 megabytes of memory and 32 microcomputer industry. The proper use - and potential abuse - of microcomputers in today's gigabytes of disk storage. Attached to the modern business and manufacturing environments system are over 900 terminals with more than 250 is of vital concern to company executives as printers. In addition typical other devices well as data processing managers. This such as plotters, tape drives, external presentation describes the working approach of communications,- and high resolution graphics are large mainframe computing, specialized also available. Besides the typical common minicomputer applications and microcomputer languages (like COBOL, FORTRAN, ASSEMBLER, etc.) are user oriented tools and languages such as at a leading gas turbine engine power manufacturer. SAS, RAMIS II, DB2, TELL-A-GRAF, GDDM, and ETC. To set the proper prospective, this paper will MINICOMPUTERS a overview of Avco first present Lycoming Textron and its Electronic Data Processing (EDP) Besides the mainframe there are over 40 This will be followed by a quick minicomputers mad",Sugi-12-153 Hutchinson.txt
"maintenance time and This paper presents an overview maximize the users effectiveness. of IBM mainframe and IBM PC computer software systems (text editors data ~nalytic software, command lan~uage There is a growing trend for mainframe sites to become populated 1nterpreters, and C programming with PC's. Now, more than ever, the software) which enhance portability SAS programmer may find him/herself in and productivity. The mainframe front of a PC for part or most of each operating system is eMS, the workday. Compatible software microcomputer operating system is PC development tools to aid in DOS. The paper discusses the productivity is vital. following software tools: The purpose of this paper is to 1) CMS XEDIT and Mansfield discuss a collection of software Software Group's KEDIT as ~ystems on mainframe and PC computer the mainframe and PC system ~ysterns which are compatible, text editors, respectively; therefore, minimizing the time of development and learning to produce SAS** as both the mainframe 2) effective applications. In discussing and micro data manipulation these systems we assume the reader is and data analytic language; an experienced SAS programmer in a CMS environment. The experienced 3) The implementation of REXX programmer should have extensive (Restructured Extended knowledge of the basic SAS data step Executor) by IBM on eMS, and constructs of structured programming Mansfield Software Group's (IF/THEN ELSE, DO, SELECT etc), and Personal REXX on the IBM PC t",Sugi-12-154 Gleason.txt
"""ASK THE PC EXPERTS"" PANEL DISCUSSION E. JEFFREY HUTCHINSON, AVCO LYCOMING TEXTRON and is currently an adjunct instructor for One of the sect Ions in this years SUGI 12 was University of New Haven Graduate School. Dick Microcomputers. During the planning stages last brings nineteen (19) years of experience working year, it was thought that the Microcomputer on IBM Mainframe and microcomputers with special Section would only need two sessions. However, knowledge in the management and control of due to the overwhelming support of contributed mi crocompliters. and invited speakers, four fu17 sessions were scheduled. The final session, scheduled for Tuesday afternoon, featured papers that were Panelist Paul f. Darley, is a Research Scientist grouped into a catagory caned ""Special Topics"". at AUA Corporation, in Palo Alto, California. Included in this session, was an hour long panel discussion entitled ASK THE PC EXPERTS. Paul is a Session Coordinator, an Invited Speaker, a roundtable leader, and is supporting the PC Hands-on Workshop. Paul's presentation is for the Microcomputer Section on Using PC SAS The ASK THE PC EXPERTS panel discussion provided the opportunity for conference attendees to ask in a local area Network environment. His educational background includes a BS in questions relating to the SAS System on Chemistry froin University of California at Microcomputers and IBM compatible microcomputer Davis. Paul brings fifteen (15) years of fOP hardware and software areas. The intent was to and ten (10) years of SAS experience. His provide the audience an opportunity to ask specialities include data management and questions relating to high level, general, and statistics, working knowledge of local area interdiscpline areas, and not those type of networks, and knowledge of the SAS System on questions that would normally be directed to SAS both Mainframes and microcomputers. Paul is a Technical support. It was in this reasoning veteran of four (4) previous SUGI's.",Sugi-12-155 Hutchinson.txt
"moe INIUT OF QUllSTlOONAIRE DATA USING TIlE FSEDIT SCREIlII Michael Hudson, Ciba.-Geigy' Corp. It is worth noting that this tutorial was moe PC SAS> - FSEDIT 'lUfCRIAL developed under a beta version of FSHDIT and as such definitions and keyboard definitions could change in the final inu-.nt of this tutorial session is to The version. familiarize with the interactive yOu procedure for entering FSEDI'r and. ~ PC SAS has been started ar1d the 1. reviewing observat,ions in a SAS* dataset. Screen Program Editor is visable. Only some of the many features wi 1.1 be = enter the COIIIIlaDd. moe FSElJIT NllW covered. Upon completion of this session, = SCREENl; mlN; and TEMP SCREEN the user should be able to create a new depress the FlO key to subDi t the dtl.taset, modify the screen for c:...~tomized C<lIIIIIIUldS · input, select, variOUE at1;ributcs for the input screen and enter data 'Ibose ...... Z. Since the dataset TEMP not familiar with the mainframe version of previously defined, an Input Screen this procedure will find themselves ""right appears (Figure 1) in..trlch you can at home"". enter the Variable Name, type of variable (either C for character or ho.~t The transition from the version to a N for nURerie) and its length. Use PC has been very smooth wi th a.boost all of the following variables for this the host features retained I a few new ones exercise: added and only a few keyboard definitions being di fferent,. 'I11e following is a brief synopsis of the opt,ion differences: TYPE NAMIl LENGTH ~u Unlike the host version, PC NAMIl 30 Ii'SEDTT has a menu feature that can be C DEPT C 3 i nvnked upon entry into the procedure NllR 3 that, wi 11 allow N you to see the llIlPTNAME C 15 comnands in a menu fonn. 'l""rough Q1A 1 menus"", the CODID8llds are C ""pul I-down QIB C ""tYIJed"" for you thus avoiding 1 syntax QIC C 1 errors and increasing efficiency by QID C 1 remindi,ng you ot"" valid options. QIE 1 C = ZO Q1F or ffiINTFlLE = - Speci fies a C PRJ NT Q2A C 1 file to which",Sugi-12-156 Hudson.txt
"hypergeometric sampling plan (See Duncan et. al., 1980 and Godfrey and Mundel, 198""). This paper presents a method for obtaining hypergeometric attribute Derivation of hypergeometric sampling sampling plans. This method. an ex~ plans usually involves tbe availa- tension to a single attribute sampling bility of tables like those found in plan developed by Alexander (1985). is Lieberman and Owen (1961), Odeh and useful in developing specialized plans OWen (1983), or Military Specification for isolated lots. Examples are pro~ MIL-H-38510F for Microcircuits (1983). vided. Using these tables can be unwieldy when the interpolation of one or more parameters are involved. If such",Sugi-12-157 Alexander.txt
"lgorithm will be discussed as tions is numerically integrated in two sec- an approximation to numerical integration in the context of the analysis of data from human tions. The same approach is used when applying the trapezoidal rule. clinical trials. Several nonstandard charac- teristics of clinical data will be addressed. The algorithm will be implemented in SAse In order to apply the trapezoidal algorithm to code using explicitly subscripted arrays. these two sections of the curve, one needs to know the time at which the curve crosses base- line. This information may not be readily Background available since it may occur between two speci- In human clinical trials one often has to mea- fied sampling points. This specific time can be calculated as will be demonstrated. sure the concentration of a new investigational drug in a subject's blood. To do this, data Finally, given that one has sequential data are measured at discrete time points over a ~oints over a speti- specified interval. This is known as collect- measured at several time fied interval, the results can be represented ing information on the bioavai1abi1ity of a pharmaceutical drug, Similarly, one might be as total deviatton from the baseline value. A positive area under the curve is denoted AUC+ interested in the amount of any number of sub- while in the negative direction it is AUC-. stances, natural or artificial, typically The trapezoidal rule approximates the area un- found in blood, e.g., blood glucose lev",Sugi-12-158 Baron.txt
"is the determinant of the sample variance-covariance matrix for the The intent of this paper is to show how to use i-th period SAS/IML software through the use of an example. Y+ Multivariate control charts for both location and LCL, UCL - 3S y variability is used as the example. - Fully-documented code is shown utilizing many of 1m the facets of SAs/IML including graphics, reading where y - m I: y i SAS data sets into IML, functions and printing of i=O results. A table comparing some sample commands of PROe MATRIX to that of IML is also provided. m",Sugi-12-159 Cirulli.txt
"Using the SAS System with Relational and Hierarchical Data Robert M. Hamer, Medical COllege of Virginia, Virginia Commonwealth University This paper is derived from a tutorial, in which I pre- by recognizing, during compilation, variable names used sented tools for reading and processing hierarchical and in the SAS code, and inferring their attributes from their relational data using the SAS System. As such, the fig- usage. It also uses informalion contained in the descrip- ures used are the transparencies I used in that tutorial, tor portion of existing SAS datasets, used in any SET, and this text is a brief explanation of each of those fig- MERGE, or UPDATE statements to add variables to the ures. PDV. In this example (Figure 2), the DATA step compiler processes the INPUT statement and determines that the This paper presumes some elementary familarity PDVneeds to contain four variables, NUMBER, NAME, with the SAS System, expecially the language used in the DATE, and AMOUNT. The use if the dollar sign in the DATA step. Specifically, it presumes familiarity with the INPUT statement indicates to the compiler that the vari- use of the INFILE and INPUT statements to read data able name immediately proceeding each dollar sign is a external to the SAS System, and to create SAS datasets. character variable. Because the INPUT statement uses It also presumes some elementary familiarity with basic list input (column and formats are not described), and principles of data processing. Anyone with a few months this input statement is the first time the compiler en- experience using the SAS System to process data should counters these variable names, the three character vari- meet these requirements. ables are eight byte character variables (capable of hold- The first portion of this paper discusses the logi- ing eight characters). cal structure of a SAS job, and the activities that occur At execution time, the machine code generated dur- when a DATA step is compiled, and when i",Sugi-12-16 Hamer.txt
"SAS/GRAPH® Annotate Application Sheila Fitzgerald Evans, SAS Institute Inc., Cary, N.C. One application of the annotate facil- llseful /* KEEP ONLY THE STREETS LISTED */ ity in SASjGRAPH® software is the ability to draw maps of city */ /* IN THE DATA SET ""MAP"". DATA MERGED; streets, lakes, creeks, railroads, and political and census boundaries from geographic base files. A DATA step (Appendix 1) creates a MERGE MAP STREETS; SAS® data set called STREETS from a tape available through BY NAME STYPE; Geographic Data Technology. Another DATA step (Appendix 2) IF ID=l; is used to create an ANNOTATE= data set from the STREETS RUN; data set and a data set containing addresses. The GLSIDE pro- The MAP CITY macro now creates t.he actual ANNOTATE= cedure maps the st.reets and pinpoints specifiC addresses using the data set from the MERGED data set by adding the appropriat.e ANNOTATE::::; data set. Figure 6 is a sample application using anDotat.e functions. The macro stores the command to MOVE to input files of STREETS and ALARMS to create a custom map of the beginning of a new st.reet or DRAW to the llext observat.ion on fire calls for the city of Raleigh. The U.S. Census Bureau, through t.he current street. The wmmands to label streets are also stored. geographic base files called GBFjDIMES, has data available for most large metropolitan areas. Geographic Data Technology, Inc. / *--------------------------------- has cleaned-up versions of the data available for a reasonable fee. DECLARE ANNOTATE VARIABLES. The DATA st.ep that creat.es the SAS data set STREETS reads t I DEFINE THE ANNOTATE REFERENCE in a variety of information about the streets, lakes, creeks, rail- I SYSTEM (5=WINDOW PERCENTAGE). roads, and political and census boundaries from the Geographic ---------------------------------*1 Data 1""f:chnology tape. These variable names are it.emized and de-- DATA CITYMAP; fqled in t.he SAS DATA step in Appendix 1. The DATA step intro- %DCLANNO; duces a new variable called",Sugi-12-160 Evans.txt
"CREA~IBG SELEC~IVELY A PERKABEB~ SASo SOP~.ARE PORKA~ LIBRARY PROB A BUBOBGOUS DIC~IOBARY Judith B. Gabor University of California Davis Medical Center ABS~RAC~ Such a TLU is accomplished by PROBLEM: having the dictionary entries and codes stored in a SAS data set in alphanumeric To output for 60 variables, human- order. The database is sorted by the readable explanations from a same code and the two are merged with a dictionary of 15,000 codes with 3S BY statement. This is a useful tech- character definitions. nique and comes in bandy in some situa- tions. costs mount rapidly, however, when many sorts are performed. ORIGINAL SOLUTION: Although the example used here to Formatting via Table Lookup using illustrate this situation pertains to a matchMERGE required 60 sorts, 60 medical database, the technique is use- data statements, and 60 merges. ful in other applications Clumsy and costly. Medical problems - diseases, dis- orders, symptoms, syndromes - are uni- BETTER SOLUTION: versally described with a 6 character code. In order to meet governmental pertinent definitions Selecting only via data search to create regulations and especially to receive Medicare reimbursement, hospitals are formats. required to retain up to 60 diagnoses per patient per hospital admission. USEFUL SAS FEATURES: Many thousands such problems or · diagnoses have been defined~ To be 00& ARRAY with { *} , _ALL DIM function intelligible and reasonably descriptive, -' the English definition of each such · diagnosis needs 30 characters. The KEEP and OUTPUT online dictionary to which I have access · PROC SORT with NODUP has 15000 such definitions. Elements in a PROC FORMAT statement would look like: · DQUOTE · matchMERGE Figure I · RETAIN PROC FORMAT; VALUE $DIAGNOS IB~RODUC~IO. One advantage of SAS is the ease of 'ES04.S'='FALL FROM TRAIN-PERS NEC' outputting human-readable reports from 'ES05.2'='HIT BY TRAIN-PEDESTRIAN' compactly coded data sets. Part numbers 'ES10.O'='MV-TRAIN COLL-DRIVER' may",Sugi-12-161 Gabor.txt
"USE OF VERSION 5 SAse SOFTWARE EXPLICITLY-SUBSC1HPTED ARRAYS TO PERFORM BIOAVAILABIUTY CALCULATIONS Patricia L. Gerend, Syntex Research ABSTRACT: Most high level programming langu- If one needs to access all elements of an array in turn, the iterative-DO statement must be ages utilize the array data structure, which used for the explicit types whereas either the allows the programmer to group several related iterative DO or the DO OVER statement can be variables into one variable name. With version 5, SAS Institute has introduced into all its _used for implicitly-subscripted arrays. operating environments an array structure more consistent with that of other languages by pro- Explicit: DO I 1 TO N; = viding for explicit subscripting of arrays. 1 TO H; Implicit: DO I or DO OVER NAME; This makes it possible to access an array ele- = ment directly by specifying in a subscript af- ter the array name which element is being There are several advantages to using the ex- sought. Since arithmetic calculations can be plicitly-subscripted arrays: performed on the subscript variable. several array elements in any order can be accessed in Array elements can be accessed dIrectly. a single statement. This direct access ap- proach makes SAS code considerably easier to write, follow, and modify, features which are The code is easier to follow. very important in programs intended for re- peated usage. This paper will demonstrate the In a single statement, -one can travel through an array in either directIon by advantages of using explicitly-subscripted arrays in the calculation of bioavailability performing arithmetic calculations on the subscript variable. parameters. These values are required routinely by the pharmaceutical industry in the testing of new drugs. A current disadvantage to SAS's explicItly-sub- scripted arrays (except In AOS/VS, PRIMOS, and *** VMS systems) is the lack of a multi-dimension capability. However, this featUre is expected An array is a data structure tha",Sugi-12-162 Gerend.txt
"SOME APPLICATIONS OF PROC MATPAR: MATCHED PAIR PARTIAL CORRELATION iIRocEDURE Robert E. Johnson and Chun Chen, Virginia Commonwealth University between a pair of observations. A INTRODUCTION pair of observations, such as (x, y, z) and (x', y', z') can be: Procedure MATPAR computes MATched-pair 1. concordant, discordant, or tied PARtial correlations. It was first introduced as a SAS procedure by 2. matched or not matched 3. relevant or not relevant Johnson, Quade, and Langston (1980),. A pair is matched if z and z I are the The procedure is documented in the same or nearly the same. That is, if SUGI Supplemental Library User's Iz-z' I~T. for i;l(l)m, where T;(T 1 , Guide, 1983 Edition and Version 5 T"" .·. , 1 T ) is a given vector Of Edition (SAS Institute, 1983 and tOlerances~ The correlation is Details of the theory are 1986). computed as the riwnber of concordant given in Quade (1974) and Davis less discordant relevant pairs divided (1967). The procedure can also be by the total number of relevant pairs. used to perform an analysis of covariance by matching (Quade, 1982). For procedure MATPAR, a pa'ir is relevant if Jt is matched and not tied on X or Y (OUT by default). However A swmnary of the procedure is given tied pairs can be counted relevant below in SUMMARY OF FEATURES. Various (IN) by exercising specific options, uses of procedure MATPAR are given in prbducing four different versions of APPLICATIONS. The example appli- the index, as follows: cations include: 1. partial correlation controlling Name of Ties Ties for covariables on Y, Index on X 2. interval estimates of total and partial correlation GOODMAN-KRUSKAL OUT OUT 3. estimation of odds ratios G (default) 4. detection of ordering bias in a KENDALL TAU-A document retrieval system IN IN SOMERS Dxy OUT IN 5. nonparametric test for ordered SOMERS !)yx IN OUT alternatives A new version of procedure MATPAR is IN/OUT refers to whether ties are currently under development. Many of included or not in the coun",Sugi-12-163 Johnson Chen.txt
"A SAS® Software Macro Application in Number Theory or SAS® Software for Fun and Puzzles K. L. Kanthan CHEMICAL BANK 1.1 Multiplication method: Abstract: The following example shows how to write down the decimal equivalent of 1/29. Start with an end SAS and SAS/Macro language lends itself nicely digit of 1 and nrultiply it by 3. write the result in handlirg wide variety of problems. The intent on the let of ths last digit. Then multiply this of this paper is to show the flexibility of the digit by 3 and write it on the left of that digit SAS lal'lJuage in different areas such as m.unber When the result is more than one digit theory, autanated JCL generation and solving puzzles. sane of the examples discuss areas where lorg, write down only the unit digit and carry over the rest to be added on to the result of the BAS is not typically used. Generations of large next multiplication and so on. Continue this runbers is achieved without any exteooed arithmetic process until the pattern of the'periodic decbnal q,lerations and BAS is used to produce pericxiic appears again: decimals. Note that the SAS/Macro language does not extend division facilities beyond 1 integers. An example of SAS versatility is shown (1 x 3 = 3) 31 in autanatirrJ the JCL generation and to schedule (3 x 3 = 9) 931 job subnission which can be used for large systEms 7931 (9 x 3 = 27) ~ reduce the operation involvement and manual «--- carry over digit 2 prcxiuction run efforts. Third topic uses the (7 x 3, +2 = 23) 37931 recursive call feature of SAS/Macro to solve a «--- carry over 22 puzzle. 1/29 = .0344827586206896551724137931 Intrcxiuction: Sbnilarly with a multiplier of 5 and an end digit of 1 we get the equivalent of 1/49 as follows: First topic discussed here is about sane arithmetical algorithms which are intended to generate periodic decimals without the use of .020408163265306122448979591836734693877551 extended ari tiJnetic operations. These methods can also be very useful for hand calculati",Sugi-12-164 Kanthan.txt
"the optimal bandwidth is made. A bandwidth that is too large will cause the density estimate to Nonparametric density estimation is a recently be overly smooth and too narrow a bandwidth will applied statistical tool useful in exploratory give a bumpy appearance to the density. An data analysis and in graphical present~tion of investigator may choose a density estimate data. The underlying density of the data is smoother or bumpier than that chosen by the estimated without assumptions regarding the form approximately optimal bandwidth because of of the true distribution except that it is expectations about density smoothness, modes, continuous. We describe a macro that may be tendency for data to clump around certain values, called to give a nonparametric estimate of a etc. An univariate density.",Sugi-12-165 Longbotham.txt
"Permanent PROC FORMATs Eileen A. McGivern, The Ohio State University ABSTRACT: uses SAS as their major program ming language in a batch processing environment. Permanent PROC FORMATs is.a programming technique used for storing PROC FORMAT code for One frequent QTPS customer is the Alumni/Devel- repetitive use in SAS* programs. This permanent opment Information Service (A/DIS), another storage is accomplished using a partitioned data"" set department of Ohio State whose purpose is to (PDS) where each format name corresponds to a maintain records of Ohio State's alumni and donors. member name in the PDS. A 'format can then easily Over the past six years QTPS has written many SAS be referenced in a SAS job by including the code for programs for A/DIS. Many of these programs read the partitioned data set in the job control language the alumni database, which contains abbreviated (JeL) and using the c'orresponding PDS member data elements that must be expanded into fuller name for the format name in the SAS code. descriptions for reporting purposes. To this end, A/DIS maintains ""mapping files"" or ""look-up"" tables This technique was employed for a user who had at University Systems which are referenced by the approximately 30 files with a combined total of SAS programs in order to produce meaningful about 4000 records that had to be continuously descriptions. A/DIS has about 30 mapping files recoded as PROe FORMATs for use in SAS pro- which contain approximately 4000 records. In the grams. The USer was experiencing a lack of data past, when QTPS needed to reference a mapping integrity, data redundancy, and program inefficien- file, it was hard coded into the SAS program as a cy, due to repeatedly coding and updating the PROC FORMAT. This was an acceptable method formats in multiple programs. until A/DIS accumulated many programs that referenced multiple mapping files. It was difficult Permanently storing the user's PROC FORMATs for the AlDIS to keep track of multiple copi",Sugi-12-166 McGivern.txt
"a more interactive design, perhaps users will There are many techniques for exploring really be able to do exploratory data analysis the structure of data that are awkward to use as it was designed to be us~d. with existing SAS*~procedures, as pointed out so graphically by Paul Tukey at SUGI 11. This JITTERING IN ONE DIMENSION paper discusses'implementatton of a macro to make some of these methods of exploratory data The histogram (PROC CHART; VBAR ... ) is well known but is limited 1'n the detail it can analysis (EDA) more accessable to the SAS user. In particular, a SAS macro for JITTERing in one present. Some distortion occurs with the abrupt dimension, with or without grouping levels is shifts in the bars, and the individual data provided. EDA macros and procedures available points are inaccessable. Plotting the points in one dimension is ,fine if there are few points: to users in the SAS procedures, contributed procedures, and SUGI proceedings are reviewed. ---X-X-xx-xxx--X--x---x---x-xx-xxxx-X-X-x-----",Sugi-12-167 Muhlbaier.txt
"been documented (Roach). Additionally, SAS products may be utilized to Committees which monitor the progress and produce pictorial views of trial data. success of clinical trials often rely on the graphic representat ion of treatment group data Graphics supply easily identifiable visual to assist"" in identifying tendencies that merit summaries which allow the reader to form clear closer examination. Those who prepare the mental images of the ""data presented. The SAS graphics need to present a maximum amount of base product provides procedures such as CHART data in an uncluttered format as well as expand and PLOT to assist the programmer in the task of and adapt the plots for tracking data over a creating such visu""al expressions of study data. period of several years. However, these procedures require a good deal of intervention to finalize pictures (graphs) when Several facilities within the SAS® base attempting to produce plots and figures"". Of product and SAS/CRAPH® allow flexibility in particular note is the need to manually draw tracking ~nd reporting longitudinal data. The lines to connect data points. SAS/CRAPH, with capabilities of the PUT statement and the PRINT, its GCHART and GPLOT procedures and ANNOTATE= PLOT, and CHART procedures are established but and REPLAY facilities, provides the tools to go they are limited in their usefulness for far beyond the abilities of the base product and production graphics. SAS/CRAPH allows prepare camera-ready graphics in batch",Sugi-12-168 Owen.txt
"PROC TRANSPOSE--A Powerful Tool for Data Restructuring Bernarr Pardo, Alza Corporation Introduction Simple Reversing of Rows and Columns (Observations and Variables) Data generated by clinical pharmaceutical studies at Alza Corporation are frequently The rows and columns of a file can be easily structured in a manner dictated by the layout reversed using PROC TRANSPOSE. In the of the data collection forms, the format of following example, 9 blood analysis values both in-house andout-of-house blood and were recorded for each study subject urine analytical data, physician and nurse according to a fixed timetable. Each record data forms, as well as other constraints. of the resulting file contains all of the Data files created from such data sources subject's data in the same order. In order often do not have a structure which can be to produce a table where the time parameter readily input to a SAse PROC or 1isted in a corresponds to rows, the raws and columns report table, and therefore these data files must be reversed. The following program need to be restructured. While such accomplishes this task: transformations can be accomplished with the DATA step, PROC TRANSPOSE is often the most PROGRAM simple and powerful method of restructuring data fil es. DATA tran1; INPUT subject lev1-lev9; CARDS; 3 0 0 0 3.9 3.5 2.9 2 1.4 2 How Data Structures are Born 14 0 0 0.2 2.6 3 3.2 2.3 1.6 1.5 16 0.2 0.2 O.S 1.S 1.6 3.5 2.5 2.1 2.4 The data collected in clinical studies come 10 0 0 0 1.3 3.5 4.3 2.S 3.3 2.7 from several possible sources: analytical 2 0 0 0 1.3 2.5 2.3 2.3 1.2 1.4 laboratories, medical research facilities, 13 0.2 0.2 1.2 3.5 5.7 3.6 4.1 3.4 3.1 hospitals, clinical monitor documents, and 6 0 0 1 4.5 5.4 4.S 4.2 4.6 2.5 various data collection forms. Data may be RUN; recorded electronically or by entering data PROC SORT; BY subject; RUN; on hard-copy forms. Data collection forms PROC TRANSPOSE; RUN; should be deSigned to facilitate the accurate PROC PRINT NOOBS;",Sugi-12-169 Pardo.txt
"HOW TO USE SAS® SOFTWARE EFFECTIVELY ON LARGE FILES Juliana M. Ma, University of North Carolina INTRODUCTION ''large"" clearly depends on the computer sys- The intent of this tutorial was to present basic principles worth remembering when working tem's capacity. The principles presented here with SAS software and large files. The paper remain useful with appropriate adjustments varies slightly from the original tutorial to to the specific techniques. compensate for format differences. The meth- ods discussed are directed toward project managers, data managers, programmers, PROJECT MANAGEMENT and other users who have data files that must be processed carefully because of size. The ob- The importance of project management is jective is to present ideas for improving effi- magnified when large files are involved. The ciency in projects using the SAS system on first principle is to require advanced planning large files. for all processes and programs. Just a few of the advantages of proper planning are: The topics include: · efficient use of resources, · documentation of projects, · easy progress tracking, · data storage considerations, · cooperative programming, · efficient programming techniques. · reusable programs, · reusable databases. Examples with actual SAS statements show how the principles can be applied. Basic Planuing should begin well before a project knowledge of base SAS software is assumed. requires any programming. Early planning The emphasis is on batch processing in a insures that computing resources, both ma- mainframe computing environment, e.g., chinery and personnel, are used efficiently. A under OS. sirople example of poor planning is a project for which programming must begin, but no arrangement has been made for access to the What is a Large File? mainframe computer through an !lPpropriate A basic characteristic of a ""large"" file is that account. you do not want to process it unnecessarily. During a project, planning results in better When used",Sugi-12-17 Ma.txt
"and Haas CORpany Anthony Patal.occhi, _ Pau1 B. Schladpnbauffen, Rah:a and Baas C<mpany 02 the first iteration, since Z is zero, Z + C is still C. This result is then substituted into the ixpression for Zi the new sum is then C + C. Repeating In the mid 1970's, IBM Fellow Benoit B. this operation again for Z, t2e sum 0n Mandelbrot founded a new branch of the next iteration becomes (C + C) 2 + geometry. Influenced by the unusual C. shapes occurring in nature, he named this work fractal geometry; fractal The Mandelbrot set is the collection of meaning ""irregular"" or ""fragmented."" all ~omplex numbers C for which the size His later work in this area led to the of Z + C is finite even after an development of a truly fascinating infinite number of iterations. Complex- collection of points known as the number theory dictates that the above Mandelbrot set. algorithm will drive Z to infinity if and only if Z reaches a size of two or This set can be constructed by starting greater. Essentially, once the with all points in the complex plane operation perturbs the number C enough within a circle, about the origin; of such that the size of its result Z falls radius two. Points from this initial outside the original circle, it is collection are successively excluded excluded from the set. should they fall outside the circle following a recursive operation. The points remaining after an infinite number of operations represents the Mandelbrot set. The methodology by which thi~set can be depicted via is presented. This paper SAS/GRAPH A VS FORTRAN program (Figure 1) was also explores the behavior of the points developed which searched for the numbers at specific locations at the set C that would eventually lie in the boundaries. Mandelbrot set. First, a 400 by 250 grid was placed·over the region of interest: -3.05 - 1.25i to 1.05 + 1.25i. Using more divisions and a larger axis for the real component was necessary to take into account the shape and size of an individual _cell for a",Sugi-12-170 Patalocchi Schladenhauffen.txt
"SCREENING FOR POTENTIAL CONFOUNDERS IN AN EPIDEMIOLOGIC ANALYSIS Linda Williams Pickle, National Cancer Institute indi'vidual risk estimates can be summarized The primary goal of most epidemiologic to adjust for the confounder variable by use studies is to identify risk factors for the of the Mantel-Haenszel estimator (2): disease of interest and to quantify the degree of risk associated with each of these factors. Unfortunately, there may be many 8MHk = [!j(AjkODj)/Tjl/[};jBjkOCj)/Tjl extraneous variables that distort the for each level (k=I,2, ... K) of the exposure. observed degree of risk for 'an exposure; The degree confdunding due to a ~f Without controlling for these ""confounding"" particular variable may be measured by variables, either by study design or analytic comparing the odds ratio adjusted for that techniques, we can never be sure whether the variable (8MHk) to the crude odds ratio (8k)' associations identified between exposures and which is calculated as: subsequent disease are real or spurious. The SAS System's PROC FREQ (I) will now calculate risk estimates, both crude and confounder- adjusted, but only for dichotomous exposures. where the subscript + denotes summation over We present a SAS macro that calculates these all levels of the confounder. A statistical estimates for polychotomous exposures and test for this comparison is inappropriate (3) ranks the potential confounding variables by since we wish to ,control for any risk the degree of confounding seen for each estimate distortion regardless of whether the exposure level, adjusting for one variable at distortion is due to chance or not. However, a time. Thus the user can screen a large because, adjustment for unnecessary variables number of potential confounders in a single can result in a loss of precision of the risk run and choose those variables that shows the estimates, the data analyst would like to greatest confounding to be included in identify a small set of confounder variables s",Sugi-12-171 Pickle.txt
"A SAS® MACRO FOR ESTIMATING MISSING VALUES IN MULTIVARIATE DATA James S. Roberts, University of South Carolina Gina M. Capalbo, University of South Carolina Introduction MISSGEN has been written to give users an easy means of performing Buck's method of estimating Research in the social and behavioral missing data. sciences often involves measuring subjects on a wide variety of test it!'!ms or instruments. In these situations, it is usually the case that certain subjects fail to respond to each and The method begins with the decision of what every test item. The resulting data may pose the maximum proportion of missing data will be. problems for the analyst in that most multi- Once this decision is made, any case which is variate techniques require complete data for each missing more than the maximum proportion of data subject. However, the major statistical packages is deleted. The remaining cases are then divided available at present are very limited in their into complete data and missing data groups. The ability to deal with incomplete data in a multi- complete data is analyzed using least-squares variate context. This paper describes a SAS regression techniques and the resulting equations macro program which allows the user to estimate are used to predict missing values. The program performs one regression for each distinct pattern the missing values in a data set and thus, avoid the problems associated with such conditions. of missing variables using the remaining responses as predictors in the equation. Thus, in a study and Q of if there are P variables Most statistical packages typically offer these variables contain missing values (with Q overly simplistic options to the user, which involve either deleting the incomplete subjects Q < from the analysis, using all possible data, or p), then up to E multivariate regres- (Q) I=1 I replacing missing data with the grand mean. The first approach is intuitively unattractive in sions may be required to estimate all",Sugi-12-172 Roberts Capalbo.txt
"(yA_1)/( Ayg A-l) (A~O) In their classic paper, Box and Cox (1964) (2.3) demonstrated how a dependent variable could be transformed to satisfy simultaneously assump- ygln(y), (1.=0) tions implicit in the analysis of linear models. For the class of analyses in which the response the maximum likelihood estimate of A can be of interest is positive and where no transfor- obtained by minimizing the r,esidual sums of mation of independent variables is considered, squares SA(Z) of the fitted model (2.2) with a SASs macro is presented which makes the respect to A. estimation of thi s power transformati on rel a- tively easy. The use of the macro is illus- Within a computati,onal framework, for a trated with data taken from the original article gi ven value of A, thi s can be accompli shed by of Box and Cox. Its application in investigat- (1) calculating the geometric mean, (2) form- ing the effects of such a transformation on ing the normalized variable, z, (3) fitting non-additivity is also demonstrated. the appropriate linear model to ZA, (4) obtain- ing the model residuals, and (5) summing the 1.",Sugi-12-173 Stead.txt
"FORMING SAS TIME-SERIES DATA SETS FROM THE INTERNATIONAL FINANCIAL STATISTICS DATA TAPE OF THE INTERNATIONAL MONETARY FUND ALEX ANCKONlE III, THE GEORGE WASHINGTON UNIVERSITY INTRODUCTION 1. data being taken from the tape is indeed present on the tape for the frequency and data type of The International Monetary Fund (IMF) supylies interest to the analyst. a number of important financial, econOmic, and fiscal data series in tape format. The data cover Step Three describes and provides the progra~ monthly, quarterly and annual information where ming necessary-to place the time series SAS data available for all member countries. Coverage in- sets formed in Step Two on a direct access cludes as much as four decades of data (dependi~ storage device. upon country, frequency and specific data type). As provided, the data are not convenient for time The specific example to be used for the demon- series analysis using SAS2 procedures. stration code is to satisfy a requirement for annual, quarterly and monthly time series for the This paper provides instruction on the use of foreign exchange rates in both US dollars per an included SAS program which will read specified unit of local currency and local currency per US data from the International Financial Statistics dollar (lines ag and ae of the IFS), tor the u""S_ (IFS) data tape (which contains approximately dollar level of foreign exchange reserves minus 23 000 time series) and forms a SAS time series gold (line ll.d of the IFS) , for the consumer da~a set which can then be used directly with the price index (line 34 of the IFS), and for the various SAS analysis procedures. If desired, the local currency value of exports (line 70 of the program can place the SAS data set on a direct IFS) of four countries. The countries for which access storage device for subsequent analysis. the data are desired are the United States (IFS While the use of the IMF's other data tapes are country code=l1l), Kuwait (IFS country' code=443), n",Sugi-12-174 Anckonie.txt
"The laboratory scientist and/or the FROC MEANS, etc. In order to circumvent the extensive default forma ts of these procedures, research statistician is frequently confronted with the problem of conveniently documenting the PROC PRINTTO is invoked, with the output sent to description of experiments and presenting the an appropriate alternate device. Output may results in summary form. An approach has been then be presented with the desired information developed using SAS* software procedures and in a condensed user-selected format. ,The use of eus tomi~ed algori thma to produce a ""Laboratory SAS/GRAPH* is an integral part of ""RARE"", and Notebook"" format from the IBM 3033 mainframe. graphics output is directed to the ZETA887(TM) plotter in a non-interactive mode. A text entry algorithm is used to enter the experimental design, description, and parameters. Desired options for SAS/GRAPH* must be defined. Many may be defined at the system Statistical analyses are performed by SAS* software procedures, and the desired information level in a GOPTIONS statement. is summarized and presented in tabular form by Conclusion the use of PROC PRIli!TTO. The results may then be printed on standard output paper, as reduced The condensed format of ""RARE"" provides xerographic copies, or as microfiche. Data easier data retrieval and allows convenient plots are generated by SAS/GRAPH*. distribution of the final reports. The ""Laboratory Notebook"" may be tailored References to the individual user and can provide an alternative method of information storage with SAS* User's Guide: SAS Institute, Inc. easy retrieval. 5 Edition, Cary, NC: SAS Basics, Version,",Sugi-12-175 Bobik Singer.txt
"Comparison of PROC SORTT, SyncSort, and PLSort Janice M. B. Buck Research Department Pharmaceutical Division CIBA-Geigy Corporation Summit, New Jersey 07901 The four different jobs were repeated upon Section 1: Introduction different days and at different times to guarantee representative results. In recent years there has been discussion at SUGI on the difference between SyncSort* and Data sets containing both numeric and character PROe SORTT. In differing circumstances one data with the full assortment of characters and sort was suppose to be significantly better missing values were also sorted by the four than the other. sorts. The output data sets were compared for Proc Sorts without any options and for Proc At our site there has been concern and effort Sorts with the following options: Reverse, to maximize the efficiency of our IBM 4361. Equals, Noequals, Noduplicates and the By Computer usage estimates showed that in the statement option, Descending. Also, the output next year, usage could exceed the capacity of data sets from the efficiency and effect tests the 4361 and there were limited resources to were compared. upgrade. Much effort was put into streamlining the production programs for users. One area of concern were the number of Section 3: Results sorts in some the statistical programs and whether these programs could be made more The Table 1 shows typical results of the efficient by changing the sort. programs comparing the efficiency and effect of the four sorts, PROe SORTT, SyncSort 6.0, In 1986, PLSort* was brought on site to test SyncSort 5.3 and PLSort 86.1. and compare. It was the first competitor we had to SyncSort and seemed to test well as a The Proc Options at the beginning of each system sort. It was decided to compare program shows that the original status of each PLSort's and SyncSort's performance inside job is similar and that a comparison of the SAS* programs. Since there had also been much results of the four sorts is valid. It shows",Sugi-12-176 Buck.txt
"with the product MACLIB. In order to provide easy online access to the SAS® A diagram of how these prooedures work is shown software sample programs distributed with SAS below: . Institute's products, a system, EXAMPLES, was written in CMS REXX. EXAMPLES provides a means of r- Starting from CMS · reviewing an annotated list of the sample EXAMPLES programs available, c 1 · looking at a specific sample program, ~ Select SAS Product · copying a specific sample program, and 1 · printing a specific sample program. Qui.",Sugi-12-177 Burlew.txt
"A SAS® UTM PROJECTION FOR GEOGRAPHICAL INFORMATION SYSTEMS APPLICATIONS David J. Cowen, University of South Carolina James S. Roberts, University of South Carolina used as the basis for the new 1: roo ,000 metric map Introduction series and is the coordinate system used for many The purpose of this paper is to discuss the new digital cartographic data files. development and applications of a Universal Transverse Mercator (UTH) map projection algorithm Construct1.on within a SAS system framework. For large scale (small area) applications the UTM 'projection has The UTM projection was developed for military several advantages over the projections available applications during World War II to create a planar global reference system. The system is in· the existing SAS software options. By creating a SAS system macro it has been possible to utilize based on a series of sixty zones centered on the data base management and mapping capabilities meridians spaced at six degree intervals. There- of the SAS software system as an integral part of fore, the UTM system actually consists of sixty different map projections that extend north and a statewide geographical information system. south rather than the normal Mercator projection The objective of any map' projection is to that is a single map centered on the Equator. create a two dimensional representation of a (Fig. 1) In ,order to further minimize distortion spherical object. Therefore any ma'p projection is the UTM system actually ""moves"" the proj ection a series of equations that converts geodetic co- cylinder into a secant position so its radius is ordinates such as latitude and longitude into a smaller than that of the Earth. The resultant cartesian system. These cartesian or X,Y co- projection, therefore, has true scale at the two ordinates provide the basis for the placement of lines of tangency 180,000 meters east and west of geographical entities onto a two dimensional the central meridian. The central meridian is",Sugi-12-178 Cowen Roberts.txt
"shifting between tools or CMS environments. The LK, FS and HELP routines described below are As powerful as the SAS* System is, sometimes ~ools used by ITG consultants and end users to facilitate program and data sharing and to it I S easier to use the tools available within CMS to assist userS in the development and provide easy access to SAS help information. These routines are a combination of REXX execs debugging of their applications. This paper and XEDIT macros and will run in a VM/SP Release describes several eMS e~t'ecs and XED~T macros 3 (or higher) environment. which are used to""' invoke SAS/FSP* and. 'the SAS help facility from OMS, as well as from XEDIT BACKGROUND and FlLELIST. Their use in the ITG'consulting environment is emphasized. In an Information Center environment, the object",Sugi-12-179 Deeney.txt
"USI.G FORMATS TO E.HANCE THE APPEARANCE OF YOUR REPORTS Steve Schulz Independent Contractor apparent~ Placing the foraat on each read Introduction of a variable may be redundant. but it For_ts are one of the .,9t basic makes it absolutely clear how data is elea.ents of any co_uter Ianauace. All being read. languages require soa.e a.etbod to display data that bas been stored in the co.puter FORMATS as binary dicits and to recocnize the for. of ineo_tog data. Few of us can .ake The second function of formats is to sense of data displayed In binary output data. These are called FORMATS in representation and.. even when we can .. the SAS syste.~ There are analogous situations for output to those described there are .uch easier and .ore above for input. Again there are three presentable ways to display data. Foraats ways in which a FORMAT can be assigned are a.aRl the si.plest tools in the SAS* syste·· but like aany simple tools. they for output. If the user does not specify. can be deceptively powerful. Not only can SAS assigns a siaple list format. a ot for.ats improve the appearance fOT. . t .ay have been permanently re.... rts. they can also improve efficiencY. associated with the variable with a in both processiRl ti~ and data storace. FORMAT state8lent or the user can This tutorIal covers usine tor_ts tor explicitly assign a format at output both input and output. creatine your own While there are only a few ways to ti.e~ creatine lIbraries or custom tor.ats.. read data~ there are .any ways of writing data. There are explicit PUT state~nts your custom forlUlts.. usiq for_ts to in <DATA steps which are the coaplement of optimize and standardize your pro&ra.s and to i.prove reports fro. both DATA and INPUT·statements. but there are also many PROC steps. PROCs which report values of data. This is where associating formats with the INFORMATS variable using a FORMAT statement is necessary in order to assIgn the desired AS stated above. foraats serve two format for repo",Sugi-12-18 Schulz.txt
"PROCESSING LARGE DATA SETS INTO CUSTOMIZED TABLES Tamara R. Fischell, UNC Highway Safety Research Center Elizabeth G. Hamilton, UNC Highway Safety Research Center variables) are shown according to accident year, Introduction all accident years needed to be combined and then Manipulation of large datasets can be a formid- separated into each of the above three categories. able task. Transforming large amounts of data into custom-made tables presents even greater An overall view of the entire process is illustrated challenges. The process of producing a motor vehi- in Figure 1. More detailed informatioJ;l about each cle accident reference manual which suminarizes step follows. over 150 variables uses both the aforementioned tasks. The four steps used to accomplish these Step 1: Dividing SAS Data into 3 Categories tasks are described in this paper. In the first step, all four years (1982-1985) are com- Using efficient programming techniques, four bined using a SET statement. The DATA state- sets (corresponding to the four steps mentioned ment simply creates three datasets, by using above) of SAS® programs were developed. Before KEEP statements. Each KEEP statement improves starting, raw data were input lleparately for each efficiency by separating the three sets of variables North Carolina (NC) accident year (1982-1985) and according to the type of information (e.g. accident, converted into four separate SAS databases (one vehicle, or occupant). for each year). (For brevity's sake this simple step is not included in this, paper.) In the first step, An IF statement restricts the accident output these four tape datasets are combined and output dataset to ouly one observation per crash. There- into three permanent information dependent SAS fore, the accident oriented dataset contains only datasets. PROC SUMMARY, in the second step, 587,929 observations (one for each accident) while condenses the data into permanent Summary the vehicle and driver/occupant datasets contain",Sugi-12-180 Fischell Hamilton.txt
"~ Backing Up SAS Files Martin Fischman PROC COPY is an excellent backup program ,code onto a tool for backing up a small partitioned data set member number of SAS direct access (POS), for later execution. data files, but it is tedious to use when a large The·JCL must then be number of files is followed by the all involved. This situation important PROC COPY is common at mainframe routine. Again, a PUT installations where many statement helps write the users are continually PROC COPY cQde. A MACRO creating or deleting files. loop may be designed to Most file managers control the number of PROC confronted by this COPY' commands written, so circumstance have tr,ied to as to match the number of use a system utility to files being backed up. Of dump entire disk volumes to course each COPY clause magnetic tape. must refer back to the Unfortunately, for many appropriate pair of 00 systems, changing ,the statements, previously storage device results in created. scrambled direct access files. We now have two programs: a backup program, which is An inel~gant solution is to written to a POS member, view the volume table of when the ini tia'ting program contents (VTOC) of each is executed. Submitting disk, and record the the POS member, then causes dataset name of each SAS the backup program to file. The names are then execute. transcribed to DD statements in the JCL An additional refinement preceding a PROC COPY can reduce the number of procedure. Submitting this program submissions to just program on a regular one. The PDS, containing schedule saves disk files the backup program, may be to tape, for use in sent to the internal reader disaster recovery of the computer, so that it operations. is executed at the end of the initiating program. A better solution is to let This one single job can be SAS base software read the submitted by clerical staff VTOC of each disk volume, to run overnight, thereby allowing the computer to securing all SAS data fi'les identify the SAS data f",Sugi-12-181 Fischman.txt
"SPELLER. A MAINFRAME SPELLING CHECKER Bruce Guthrie, U.S. Department of Commerce using WYLBUR's line editor, reformatted with Spelling checkers. Every dinky little PC WYLBUR's document formatt'er, and saved in spe- seems to have untold numbers of programs that quickly and effectively search documents for cial WYLBUR files. For such an environment, the SAS-language misspelled words. These same programs do word spelling checker {called ""SPELLER""} was written. counts, warn you of sexist jargon, produce -readability· indices, and do a variety of other Special WYlBUR consjderations: remarkable things. Every installation has its unique quirks of Unfortunately, programs which have bred like rabbits in the micro world and to a slower ex- course. NIH's WYlBUR is no different. Among tent in the mini-computer world have been slow its peculiarities: to catch on in the mainframe world. This ;s for ~ Most word.processors store text documents in a variety of reasons, primarily word processing formats which are unique to that software. They in general isn't very practical on mainframes. have to handle tabs, format lines, special Even if i t were, most programmers in the toggles, headers, footers, and all the rest. mainframe world push text editors (used for While WYlBUR gets around the use special writing programs) instead of word processors and toggle characters (using ""marker"" commands to do text editors seldom come with a spelling the same thing), files created in WYlBUR are checker. typically stored in a special ""Edit"" format. So~ here for your use, perhaps amusement, While very efficient to use in WYlBUR, the files and probable modification is a spelling checker have to be converted to standard fixed files written entirely in the SAS@ language. It before they can be used in any batch program. was written for a batch environment and wasn't NIH fortunately provides an efficient conversion designed to provide all the bells and whistles program that automatically creates regular",Sugi-12-182 Guthrie.txt
"The listing of the macro and its use is illustrated in Figure 1. The options statement The COMPUSTAT financial data base is distri- requests an output data set TEST, containing the variables CONAME YEAR QTR V1-V4 for a specific buted by Standard and Poor's Compustat Services, Inc. The expanded annual industrial file from company number. An observation is created for each of the quarters in 1985 through 1986. this data base can be assessed using the macro SPYR as described in the 1982 edition of SAS/ETS. MACRO SPQTR100 Following a similar format, two macros were developed to read the COMPUSTAT quarterly SPQTR100 reads the data from the 100-item industrial files and output the selected data items to SAS data sets. The macros default to quarterly industrial file and creates a data set building data sets of all variables for every with the selected companies and variables. The DCB of this file should be DCB = (RECFM = VS, quarter for every company on the file. Options LRECL = 9728, BLKSIZE = 9732). The default data allow for selection of data items, years, and set will contain the data for 20 quarters for companies. every company on the file. The available options A third macro, FINSTATQ, is listed that to delimit this data set are the same as those in allows for inclusion of all data items in the SPQTR40. This macro is listed in Figure 2. IOO-item file pertinent to a balance sheet state- MACRO FINSTATQ ment. The data is transposed and labe11ed and thus presented in a familiar format. FINSTATQ selects the variables that are",Sugi-12-183 Hirsch.txt
"Strategies for Development of a Corporate Graphics Center Jerry J. Hosking, SAS Institute Inc., Cary, N.C. Suzanne S. Gordon, SAS Institute Inc., Cary, N.C. INTRODUCTION hardware may require options specific to the_characteristics of each device. Selection of colors, fonts, and patterns for each component of a visual is a large number of options to choose, Many businesses face increased demand for quality graphics output for both presentation and publication purposes. In evalu- particularly for users unaccustomed to designating so many ating methods to meet these demands. a corporate graphics cen- pieces of information. The variety of formats used to display data ter structure stands out as a good choice to provide the greatest graphically can also be overwhelming to users of graphics soft- access to a variety of graphics devices for the entire population ware. Given a limited familiarity with graphical design issues, of your company. This paper presents ideas related to the devel- other ideas that present difficulty to users include developing a opment of a corporate graphics center with emphasis on issues layout for graphics output with consistency in color and design, to be considered by those making decisions that will affect the placing realistic limitations on the amount of text- for graphics structure and use of your center. Primarily discussed are the soft- used as visual aids, and producing visually pleasing graphics out- ware tools necessary to meet the needs of your users. Other top- put for greater value or impact. ics included are rationale for the corporate graphics center approach, choice of output devices, training, and support. Although the previous considerations primarily affect the users and technical support staff of a graphics center, concerns focused on reduced costs due to centralization of hardware can MEETING GRAPHICS NEEDS OF YOUR USERS be easily recognized by others in the organization who would not otherwise be affected by improved grap",Sugi-12-184 Hosking Gordon.txt
"lete program listing identified with either line Document your SAS program wi th an atmotated numbers or reference numbers along with an program listing and word cross-reference. This annotation area highlighting the main macro and poster displays,a SAS program that will document step features of the program. your other SAS ,programs. The atmotated listing highlights DATA and-PROC statements as well as all macro features. The cross-reference listing CROSS REFERENCE includes all program words not found in comnents. The documented program listing and cross- A cross-reference of all program words reference report are far superior to a simple that are not found in comments is displayed program listing. after the annotated listing. Each item is followed by all the line numbers or reference numbers in ""which it appears in the annotated OVERVIEW listing. The cross-reference listing includes much more than: just the variables that appear in Trying to locate all references to a the program. It includes everything that is not variable in a large SAS program can be difficult. part of a comment. This includes statement A variable cross-reference report would greatly keywords and data constants. Qelp in such a search. Since SAS does not provide such a report, a SAS program was written to create the report. In addition. an atmotated HOW TO RUN THE PROGRAM listing of the program is printed. The result is a program listing and variable cross-. To identify the program being documented. refere",Sugi-12-185 MacHose.txt
"MANAGEMENT GRAPHICS IN A QUALITY ASSURANCE ENVIRONMENT Shirley J. McLelland The following is an example of itA picture is worth a thousand words"" SAS Code used to produce the is a familiar cliche. Southern graph, California Edison Quality Assurance Organization is an environment which has made the words of that cliche come '%ZETA1S; alive by using graphics to reflect the PROC FORMAT; progress of a variety of QA Programs. VALUE MONTHFMT 1-' JAN , 2='FEB' No longer is it necessary to use 3='MAR' volumes of typed or printed material 4='APR' to see a clear and concise picture. 5='MAY' Graphics are a Summary tool used at all 6='JUN' levels of the organization. 7='JUL' 8='AUG' A typical example of a QA program area 9='SEP' that has utilized graphics is the lO='QCT' Program Audit Assessment And Report ll-'NOV' Group. About 200 audits are issued 12-'DEC' ; per year reflecting various management DATA ONE; evaluations with categories such as INPUT MONTH TOTAL; Security. Internal Security. Suppliers CARDS; and Internal Organizations. Using a 1 8 Master Audits Data Bas,e to extract 2 12 information; graphs can be produced 3 5 to give management at a glance the 4 14 progress of an au~iting program. 5 15 6 9 Figure 1 is a typical example. A 7 7 simple bar chart depicting audits 8 10 completed to date. If the total audits 9 6 completed do not reflect the audits 10 14 originally scheduled this would give 11 8 management a picture as to the number 12 17 of audits scheduled. which months did , not meet their completion date and the PROC GCHART DATA-ONE; responsible department for not GOPTIONS NOTEXT82; completing the schedule. Additionally. AXISI LABEL-(H-.8 F-DUPLEX 'TOTAL') the graphs can show areas where VALUE-(H-.8 F-SIMPLEX) improvement has been made. ORI~IN-(10,65 PCT) LENGTH-20 PCT ORDER-O TO 20 BY 10 MINOR-NONE; AXIS2 LABEL-(H-.8 F-DUPLEX 'MONTHS') VALUE-(H-.8 F-SIMPLEX) SlTB AUDITS COMPlZI'ED AS OF HC - 1&86 ORIGIN-(10,65 PCT) w:~~!~,~!'!'!~ MINOR-NONE; TITLEI H-l.5 C-BLACK",Sugi-12-186 McLelland.txt
"USING SAS® SOFTWARE TO PROVIDE INFORMATION FEEDBACK TO SUBJECTS IN A LONG-TERM STUDY Carolyn J. Oakley, USAF School of Aerospace Medicine INTRODUCTION Some preliminary SAS statements are executed in order to prepare the data for input to the PLOT Medical information is collected every two procedure. The cholesterol means are calculated years on subjects in a long-term cardiovascular by PROC MEANS for each year. After mergi ng and disease study. As a courtesy, each subject is sorting, the data set is ready for PROC PLOT. provided with a summa~ of his data and a graph For example: of his cholesterol values with the mean of all subjects for each year. This feedback DATA ALLDATA; SET MAIN.DATABASE; has helped maintain an excellent returnrate X=I; for the study group. KEEP NAME SSAN YR OOB CHOL SBP DBP SUBJ Wi X PROBLEM PROC SORT; BY YR SUBJ; For each of 500 subjects, a single page report PROC MEANS NOPRINT; BY YR; was desired, containing both tabular informa- VAR CHOL; tion and a plot. Calling PROC PRINT and PROC OUTPUT OUT=MSET MEAN=MCHOL; PLOT the ""usual ll ways waul d produce a two .. page report for each subject. DATA ALL; MERGE MSET ALLDATA; BY YR; YEAR = 1900+YR; SOLUTIONS PROC SORT; BY SUBJ YR; Two solutions are given. The first uses base SAS software in batch mode on the IBM 434l. * To left justify PLOT; This solution shows how to generate a single OPTIONS NOCENTER; page report for each subject in the data base. PROC PRINITO is used to capture the graph from In using the following SAS statements, the PLOT PROC PLOT output, and a summary table is pro- output is written to a temporary disk file with duced using report writing features in the DATA the ddname FT20FOOI. The UNIT=20 option on the NULL step. The second solution features the first PROC PRINTTO must agree with the 20 in VAX* command language and base SAS software the ddname of the JCL. The first PROC PRINTTO in a non-interactive mode on the VAX 11/780. wi th the NEW opti on changes the output to the The",Sugi-12-187 Oakley.txt
menu (Figure 1). (LINK is a PC DOS 'batch' file that contains the instructions for starting the micro-to-host application.) A quick The proliferation of personal computers has made effective scan of the main menu will begin to familiarize you with the capa- micro-ta-host links increasingly Important. The SAS® System bilities of the micro-to-host application. provides a set of tools for facilitating micro-ta-host applications. This paper shows how SAS/AF®~software for PCs can be used to create a user-friendly interface to ~e SAS System's micro-to- Main Menu host features. Seleet Option .... > to return. Puss END select one of tbe OpUOI!S and press DlTER.,Sugi-12-188 Roberson.txt
"LIS files. When cal led as BSAS, the command procedure sub- Abstract J. mits a SAS batch job, uSing the same parameters that SETSAS does. When no parameters are given, A VAX/VMS command procedure Is presented which both SETSAS and BSAS retrieve the parameters helps SAS users submit JobS more easily and more from a file that Is written by SETSAS. reliably. When the procedure Is called as SETSAS It remem- II. Sample SessIons bers the name of the fl Ie containing your SAS code from session to session, the queue to which Two sample sessions are shown below to the job Is to be submitted, and the detal Is of demonstrate the use of SETSAS and BSAS and the any tape mounts that the jOb requires. It sets resulting messages. What the user enters Is In- up loglcals CODE, LOG and LIS which point to the dicated by Italics. PLEASE SELECT SYSTEM: vaxc Username: SMIT~JD Password: Academic Computing Services, VAXC, VAX/VMS V4.5 $ setsas suglxmpl Default SAS fl Ie set to: SUGIXMPL.SAS Jobs are sent to queue: SYS$BATCH by default. $ create code %Include defaults · · Standard options, Ilbrefs, etc.; proc contents data-Jdsdb.tultlon; <CNTL-Z> Exit $ set def saswrk go to directory pointed to by logical SASWRK $ bsas submitting SAS job SUGIXMPL.SAS to queue: $YS$BATCH Job SAS_SMITH_JD_155031 (queue SYSSBATCH. entry 1435) started on SYS$BATCH_VAXC $ logoff logged out at 18-JAN-1987 15:51:39.02 PLEASE SELECT SYSTEM: vaxc Username: SMITH_JO Password: Academic Computing Services, VAXC, VAX/VMS V4.5 sets",Sugi-12-189 Smith Barbour.txt
"E A SAS DATASET: ABSTRACT °The PRINT and QPRINT procedures are used .to print;: data from a SAS dataset. The reports produced by these procedures can DA,TA SALESPH; INPUT @01 DATEPAID MMDDYl6. be as simple or complex as needed, de- f08 tIAME ,CHAR20. pending_ on the options used. U9 SOCSEC i. 7.2 f39 COMEQUIP f47 COJIlSERV 7.2 f55 SALEZONE $1.; INTRODUCTION '1'O'l'ALPAY · CO)IEQUIP + COMSERV; CARDS; PROC PRINT can produce anything from a 010486 MARTINSON, DEBRA 889678544 1250.00 0510.00 A 010886 LEGOULLON, JIM 557599466 0489.00 0063.00 C very simple line-by-line listing of ob- 102686 O'NEAL, GARY 892792712 0850.00 0110.00 C servations to a ""customized"" report for- 120586 BERRY, STEPHANIE 755454354 2050.00 0600.00 C mat with subgroups, subtotals, labels and 1~0586 BOWARD, CASSIE 918167169 0975.00 0430.00 B JAMES, BRAlmON 786956495 0450.00 0647.44 B 120586 more. QPRINT is an alternative to the 120985 SOALANO, CRAIG 891673478 0250.00 0027.53 B PRINT procedure, and although it does not 120686 COLEMAN, TANYA 981281080 1150.00 0635.90 B 100386 CAMBELL, DALE 000000000 0150.00 0030.00 C offer all of the features of PROC PRINT, 102286 MORALES, MARY 007259265 3050.00 0315.16 A it may provide the programmer with great- 102386 L'TALIIEN, JEFF 827827626 0750.00 0210.00 A 102186 TANNER, GARY 837437892 0175.00 0015.23 A er control over the report layout. I Both the PRINT and QPRINT procedures can only print data stored in a SAS dataset. FIGURE #1 For information on creating a SAS data set r",Sugi-12-19 LeGoullon Martinson.txt
"A MULTI-YEAR OCCUPATIONAL HEALTH RECORDS SYSTEM WILLIAM M. TAYLOR DATlSOFT DATA COLLECTION INSTRUKENTS ABSTRACT: Designed for governMent and The occupational health and industry to Monitor health risks lifeatYle ··sessMent product associated with personal lifestyle allows an organi%ation to Monitor or potential occupational hazards, the level of health of their and to provide eaployees with eaployees. Four sources of data specific personal guidelines to are used to co. pile a databank for iaprove their health, over 300 each participant: paraaetera are Monitored over a Multi-year periOd. Health profile Eaployee-coapleted aue.tiorinaire: data, including personal The eaployee responds to inforMation, aedical history, approxiaately 200 questions current syaptoMs, aedications, use dealing with their aedic.l of alcohol and tobacco, diet and history. diet, exercise, exposure exercise and ··ny other ite·· are to cheaicals including cigarettes coapleted by the eMployee on an and alcohol, and stress annual baaia. data ia Thi. evaluators. The fora is designed COMbined with a physician'. for ease of coapletion a. well as ex ·· ination, blood laboratory work- ease of data entry. x-ray. up, electrocardiogra., vision and audio.etric teat. plus Physician-coapleted queationnaire: occupationally-related teats to Standard physical exaaination data establish · cOMprehensive databank such as blood pre.sure and weight are recorded by the physician for each person. exaaining the eaployee. The software, dependent upon tables and cOMputation foraula., Blood Laboratory report: relies extensively on the use of A standard blood work-up recorda Macros. It is well structured to values for white blood count, red allow for easy update and blood count, and other factors are revision. Coaputationa and recorded either onto a data recoM.endationa are baaed on capture fora, or directly entered responses to specific questiohs into aachine readable fora. controlling for aex, age group, ~itional teet res",Sugi-12-190 Taylor.txt
"The Carbon Dioxide Information Analy'sis Center (CDIAC), sponsored by the Carbon Dioxide Research Division' of the U. S. Department of Energy I h'as developed a Management Information System (CDIAC/MIS) that records and tr,acks a large number of the data center's varied information r,equests. CDIAC/MIS comprises a menu-driven, front-end program written as an three procedures: IBM/TSO CLIST; full-screen data entry and edit options written in SAS/FSPi and SAS execution modules written in SAS/Graph, SAS/BASE, or both. The CDIAC/MIS contains two SAS data bases: one records information requests and the other SAS data base is a distribution list for CDIAC's newsletter and other C02-related publications. ,The data bases can be manipulated to produce statistics and graphics that illustrate the information requests made by CO 2 researchers and, policy makers and the types of persons on the distribution list. CDIAC/MIS facilitates the recording and processing of data by organizing and maintaining a permanent record of information center activities and by providing a mechanism to analyze information requests.",Sugi-12-191 White Fowler Farrell Gross.txt
"SAS' SYSTEM STATISTICAL PROCEDURES APPLIED TO THE ANALYSIS OF WATER QUALITY DATA Paul D. Mowery, SCI Data Systems, Inc. To motivate the statistical model, the INTRODUCTION paperts first section provides a brief historical perspective of environmental change in Chesapeake Bay. Section 2 describes the This study deals with the multivariate water quality data base, which was develQped over a six year period and includes field data statistical assessment of environmental collected by several research institutions and ohange. Changes over time and space in government agencies in the Chesapeake Bay Chesapeake Bay water quality. Water quality 1s defined as the ability of a body of water to region. Section 3 presents the conceptual environmental model and its statistical support aquatic' life and to provide a counterpart. Results obtained using PROC commercially and recreatlonally viable resource CANDISC are described in Section 4. for everyone to utilize and enjoy. The objectives ot the study are to develop a conceptual framework for analyzing historical water quality data, and to develop the statistical methodology for detecting future 1· THE ENVIRONMENTAL PROBLEM changes in water quality. The statistical questions addressed herein are: HISTORICAL PERSPECTIVE How can we estimate, for some fixed time period, the way in which water quality The Chesapeake Bay is our nations's largest estuary. The Bay proper is approximately 200 varies from one area of the Chesapeake Bay miles long and varies in width from about four to another? to 30 miles. The Bay's water surface is How can we measure historical changes in bordered by approximately 4600 miles of shoreline and thousands of acres of wetlands. water quality? The water surface of the Bay proper encompasses How can we detect, with some level of more than 2200 square miles. Including tributaries, that figure nearly doubles. The statistical power, future changes in water Bay holds about 18 trillion gallons of water. quality? This",Sugi-12-192 Mowery.txt
"EFFECT OF ITERATIVELY REWEIGHTED LEAST SQUARES (IRLS) ON TEACHING A COURSE IN QUANTAL/CATEGORICAL RESPONSE James E. Dunn. University of Arkansas Rita C. Berg, University of Arkansas obtained by IRLS using the model INTRODUCTION = Yi E[Yi] + ei 121 The IRLS methodology as applied to quantal = g' (9 ) where E[Yi] 131 i res}X)nse is not new. The framework was given by Nelder and Wedderburn (1972) and was 800m and var[YiJ ( 41 followed by a pac~e known as GLIM. GLIM vJ1J;;I implemented Nelder and Wedderburn's result (51 with t..'eight, wi' proportional to v;hieh was to use IRLS to find the MLE for an provided the weights are re-evaluated at each appropriate linearized transformation of the iteration using current estimates of the quantal response. TIlis is the same approach as parameters. that of classical probit analysis as ,given by Finney (1952). Jennrich and Moore (1975) took Note that the model given by (2) need not advantage of non-linear estimation packages to be linear. Indeed, for the distributions find the NLE of the expected values of the non- reviewed here, the models will be non-linear, transformed quantal response. The methodology thus requiring t.he use of PROG NLIN. given here is similar to that given by Jennrich and Moore with the except.ion that we ~dll r'e- The lectures in a categor,ical response evaluate the weights at each iteration whereas course could be changed. in the followin.fit way. Jennrich and Moore did not. The capability of First, present NeIder and Wedderburn's result, rew~ighting at each iteration has been and""then move into binomial sampling (i.e. available in SAS* PROC NLIN since 1979, but probl t analysis), poisson regression. etc. as Ii ttle application of IR1...s t.o quantal response specific cases of NeIder and Wedderburn's has been made in the classroom. The goal of result. This saves time in that the r--lLE is t.his paper is t,o provid~ instructors with a new derived. in general as opposed to being deri veel and more general ap",Sugi-12-193 Dunn Berg.txt
"on. I attempt only a brief This paper provides computational support outline here. The interested reader is for a data analysis technique proposed by Ramsey encouraged to consul t the original text. and Marsh in B1gmetrics 40(3) (1984). Their paper, ""Diet Dissimilarity,. outlined a method It is first observed that the dissimilarity of quantifying the relative importance of prey between two groups of environmental samples taxa in determining overall dissimilarity of should be directly related to our ability to diets between groups of prada tors, using a Bayes correctly classify an indiVidual sample into one classification procedure. The method can be of the groups, based on the observed values of extended for use as a general dissimilarity its descriptor variables. The problem is then index between any two groups of multivariate posed as a Bayes classification procedure. The environmental samples. SAS code is provided to probability of belonging to class s is implement the dissimilarity calculations under a proportional to variety of sampling models. It is hoped that this will stimulate further research into the theory and applicability of this technique. 1fs fsex) TntrQdUQti OD where x is the sample vector of' descriptor values, !s(x) i. the joint probability density Environmental research often generates data function of the descriptor variables for class which are essentially multivariate in character, s, and 11""s is the prior probability of with each ""sample"" consisting of",Sugi-12-194 Rinehart.txt
"sequence Yo, Y 1, has the desired ·. Edition, lists nine random number generators distribution. (not counting the UNIFORM and NORMAL, which are older implementations of generators for the -1 uniform and normal distributions respectively). The computation of F (-) presents problems for Of these, five are correspond to common some distributions. Well known methods, such as continuous distributions in statistics. The Box-Muller for the Normal (Box and Muller, importance of the RANUNI generator lies in the 1958), and acceptance-rejection for the Gamma fact that all the other continuous generators use (Fishman, 1978), are available to get around this RANUNI and transform methods to generate their difficulties for these common distributions. respective streams. The RANUNI generator is a Marsaglia (1984), gives an ""Exact-Approximate"" member of a general class called ""Multiplicative method for generating random variates for a 31 given distribution F( -) without ever computing Congruential Generators with Modulus 2 _1"". A F- 1 (0). description of the algorithm for these generators s given, along with a description of the transform method used to obtain the RAN NOR generator from the RANUNI. Finally, some In the applications described above it is clear common missuses of the random number that the validity of the results depend crucially generators in SAS programming is discussed. on the ""randomness"" and the distributional properties of the generators. Before discussing validation, we",Sugi-12-195 Killam.txt
"USE OF SAS* PROCEDURES FOR ESTIMATING DESIGN BASED LOGISTIC REGRESSION VARIANCES BY BALANCED REPEATED REPLICATION (BRR) Martha Livingston Bruce, Yale University Daniel H. Freeman, Jr., Dartmouth College Philip J. Leaf, Yale University DESCRIPTION OF PROGRAM INTRODUCTION The SAS code for this program is Because the assumptions of simple presented in Appendix A. The program is random sampling are inappropriate for written in two steps. The first part calculating variances 1n survey data creates a set of 60 weights which are collected with a complex sample design, used as ma kers for half sample a number of other methods have been 2 inclusion. These markers could be saved developed. However, no computer permanently as part of the user's data software is currently commercially set, in which case the first part of the available which estimates adjusted program only needs to be run once. Or, variances for logistic regression to save storage space, the markers can coefficients. This paper presents a program written with SAS code which be created with each run of the program. calculates design based variances for logistic regression using Balanced The second .part of the program runs a logistic regression model for each Repeated Replication (BRR). half sample. The CATMOD procedure is BRR is one of the more frequently used with a wefght statement and the OUTEST option. (Note, the LOGIST used sampling variance techniques for procedure could also be used.) The use in design based analyses of complex MEANS procedure then calculates the survey data. Results derived from the standard deviation of the 60 different BRR method of determining adjusted estimates of each parameter. These variances for means, proportions and standard deviations are the new adjusted · linear regression coefficients are standard errors of the full model comparable to those generated by another logistic regression coefficients. common method, Taylor Series Linearization (Freeman at al., 1985; APPLICATION",Sugi-12-196 Bruce Freeman Leaf.txt
"t and it does not permit estimation of McFadden's conditional multinomiallogit model. Multinomial logistic regression (MNL) is a powerful The purpose of this paper is to take a step in tool for the analysis of-problems with a categorical the direction of remedying this problem, by explain- dependent variable having more than two values. It ing in simple terms what the MNL model is, how to has had applications in evaluation of clinical trials, interpret the coefficients, and how to reduce the out- market research, transportation research, and has put from the model to a readily understood form. It been applied. in virtually every social science and is possible, with effort, to compute the diagnostics manag~ment analysis context. Nonetheless, most ~e discuss in the standard release of SAS, but there potentIal users are unfamiliar with the principles 18 no reasonable way to estimate the conditional underlying the model, are not aware that there are MNL model. However, the diagnostics and both two radically distinct versions of the MNL model . versions of logit are fully automated and efficiently ' cannot Interpret the typically confusing output programmed in PROC MLOGIT, an after-market correctly, and do not know how to assess a model SAS procedure. for goodness of fit. This paper seeks to address this The layout of this paper is as follows. In sec- problem by laying out the basic theory underlying tion 2, we outline some of the formulas underlying the model, shows how the coeff",Sugi-12-197 Steinberg.txt
"representation algorithm by minimizing the weighted sum of loss of population distances for A random vector is assumed to belong to one the case when the populations are multivariate of several multivariate normal distributions normal distributions with equal covariance matri- possibly having unequal covariance matrices. The ces. Gnanadesikan et a1 (1982) present a two- goal is to find a low-dimensional hyperplane dimensional projection that satisfies specific which preserves or nearly preserves the separa- criteria that are meaningful for studying separa- tion of the individual populations. We present a tions among objects or clusters. Schervish (1984) computationally simple method of .deriving a investigates the equal covariance-matrix case with linear transformation for low-dimensional repre- known parameters when the number of populations is sentation and give conditions under which the Bayes classification rule is preserved in the restricted to m-3 and derives the best one-dimen- sional representation for both the Bayes and mini- low-dimensional space. Finally, we utilize max rules. However, he notes that the extension SAS/GraphS to present several examples to demonstrate the graphical low-dimension represen- of his method to four or more populations is not immediately feasible. More recent lo~dimensional tation method. representations include projection pursuit methods (Huber, 1985; Friedman and Tukey, 1974), minimal spanning trees (Friedman and Rafsky, 1981)~ and",Sugi-12-198 Marco Young Turner.txt
"sA!"" USING SOFTWARE GRAPHICAL PROCEDURES FOR THE OBSERVER AGREEMENT CBART Shrikant I. Bangdi~ala, Department of Biostatistics, University of North Carolina at Chapel Hill Hope E. Bryan, Department of Biostatistics, University of North Carolina at Chapel Hill 1. INTRODUCTION If two raters independently classify N items software features utilized to automate drawing into the same set of k nominal or ordinal the agreement chart are described. Finally, the categories, one wishes to develop a measure of techniques are illustrated with two examples in Section 4. agreement between the raters. The data can be 2. DESCRIPTION OF THE AGREEMENT CBART presented in the format of a two-way contingency table, where the cell entry, X.. , i,j=l, ··· ,k, The motivation for developing a new measure denotes the number of items clk~sified into the of agreement was to provide a visual representa- jth category by rater A that were classified tion of the contingency table as well as have a into the ith category by rater B. The row and statistic with an intuitive interpretation. Few graphical representations are available to k k represent cross-classified data. Riedwyl and column totals, X. E X .. and X. E X .. , = j=l ~J i=1 1J oj Schuepbach (1983) use colorful grids to denote L cell frequencies in their graphical display of a denote the total number of items classified contingency table. The ""mosaic"" of Hartigan and into the ith category by rater B and the total number of items classified into the jth category Kleiner (1981.1984). in which the individual by rater A, respectively. cell entry counts are represented by rectangles Agreement can 'be regarded as a special kind or tiles of area proportional to the count. of association: perfect association implies the makes it possible to visually compare sets of ability to perfectly predict the category of one counts. suggest hypotheses. check assumptions, rater from knowledge of the category of the and interpret results for up to a practical o",Sugi-12-199 Bangdiwala Bryan.txt
"Getting the Most from PROC TABULATE Andrew A. Norton, ORI, Inc. I. l/hy use PROC TABULATE? II. The Table-Development Process PROC TABULATE is more difficu lt to master While PROC TABULATE tables are easy to than the typical SAS* procedure. Many people modify, they are tricky to set up from scratch. have learned alterna tive methods of producing Many people search the extensive documentation complex reports, such as PROC PRINT or DATA in vain, trying to figure out how to use the steps. It is reasonable to ask what advantages complex syntax to produce a particu lar table, of the procedure makes it 1I0rth learning. perhaps trying to copy an existin g table or to follow a detaile d design specifi cation. There The most distinc tive advantage of PROC are t""o problems with this approach. The first TABULATE is that it dynamically adjusts to the is that PROC TABULATE is a package (albeit a data. If a new value of a classif ication pOllerful one) rather than a full-fle dged variable is added to a report PROC TABULATE programming language. There are many table adjusts automatically. The nell values are added deSigns that PROC TABULATE simply cannot as new ro\'iS and columns, in their correct accommodate. The procedure can probably produce positio ns. If the size of the table expands a table that effecti vely presents the suffici ently, PROC TABULATE will automatically information, but if a particu lar table design is break it into sections so that each section lIill required, it will probably have to be fit on a page. custom-programmed using PUT statements in a DATA step. This dynamic expansion capabi lity allO\<5 the table to be specifi ed in abstrac t terms, so that The second problem encountered is that the the computer code remains applicable even if the solution to producing a table is often found not categories change. The exact shape and in the syntax of PROC TABULATE, but in the dimensions of the table are determined using the structu re of the dataset input to the i",Sugi-12-20 Norton.txt
"to graphically display data clusters and their surrounding space. By displaying the properties This paper details a macro SAS/GRAPH~ of Cormack's (1971) definitiOn it is hoped that library- that aids in determining the number of these macros will aid in determining the number natural clusters present in the data. Two of natural clusters present in the data. The macros are available to display the results of macros provide the user the option of selecting nonhierarchical cluster solutions: TWOD which which set of variables should be displayed, generates two dimensional scatter plots; and whether lines should be drawn from each cluster THREED which generates three dimensional centroid to the data points in that cluster, and representations of the cluster space. The whether a circle representing the dispersion of variables used on the axes are selected by the the points should be drawn. user and these axes are automatically scaled. This paper also demonstrates how PROC Optionally, users may select to represent VISUALS, an SAS dynamic e~perimental cluster membership or display the dispersions of hyperdimensional graphics procedure, can be used all points within a cluster. The use of PROe as an aid in the selection and interpretation of experimental dynamic VISUALS~, an SASl cluster analysis solutions. Graphs produced by hyperdimensional graphics procedure, as a PROC VISUALS and the macro library are similar, further aid in interpreting cluster analysis but the interactive features of PROC VISUALS solutions is also demonstrated. makes this procedure the superior method of cluster analysis interpretation. Since the",Sugi-12-200 Larus.txt
"· SAMPLING WITH SAS ® SOFTWARE: A MACRO FOR DRAWING PPS SAMPLES Eleanor M. Dillon, Westat Inc. Jam~s E. Smith, Westat Inc. important to have reliable and proven sampling software. INTRODUCTION Seemingly obvious and intuitively convincing algorithms for sampling often have hidden flaws. For example, one Sampling is an integral part of modern research commonly recommended method for drawing a random methodology. A properly designed -and selected sample is sample (without replacement) of size N does not always crucial to the success of rnO$t research, and it is Dot yield a, sample of the specified size. 1 surprising that preparing for and drawing samples requires substantial computing as well as statistical expertise. DRAWPPS is a SAS macro for drawing a ""Statistical packages"" tend to emphasize analytical rather sample of a specified size by the PPS Or EPS method. than sampling functions, thus requiring programmers to Because EPS sampling is mathematically a special case of reinvent the wheel when performing sampling operations. PPS sampling (in which the measure of size is unity for The inefficiencies and risks of undetected errors in this each case) it is feasible to use the same macro for both can be minimized through the use of SAS macros which sampling methods. The DRAWPPS macro uses the SAS follow established statistical sampling algorithms and have direct file access feature (SET statement with POINT been tried and tested. option) to iterate where necessary thus avoiding the creation of intermediate files and manual iteration that This paper presents one such macro. would other wise be required for PPS sampling. DRAWPPS, that is part of a larger body of SAS software which the authors have used extensively in complex survey The DRAWPPS macro is part of a larger body sampling projects. While this software- does not includ~ all of SAS sampling software that automatically handles of the optional features and sophisticated checking various sampling tasks, including a",Sugi-12-201 Dillon Smith.txt
"h Carolina Douglas P. Kent, SAS Institute, Inc. Abstract analysis; redundancy analysis; canonical correl- ation -analysis; and response surface regression. SAS Institute is funding a software research and development project at the University of North TRANSREG is a transformation procedure. It Carolina at Chapel Hill whose purpose is to transforms variables to optiuize regression develop a package of Psychometric and Market models. The independent and dependent variables Research procedures. To date, this project has may be categorical, ordinal or quantitative. developed three SAS' procedures, one stand- Any mix is allowed. Categorical variables may alone program, and one SAS macro. Four addi- be transformed by scoring the categories to tional procedures are under development. In minimize least-squares error, or may be expanded this paper we present a brief overview of the into dummy variables. Ordinal variables may be entire project, and then discuss PROC CONJOINT transformed monotonically by scoring the ordered and PROC TRANSREG, new procedures for trans- categories so that order is preserved and leaat- for.ation regression which performs conjoint squares error is minimized. Ties may be analysis, preference mapping, external unfold- optimally untied or left tied. Ordinal vari- ing, 'nonmetrip regression, and a wide variety of ables may instead be transformed to rank ·· additional analyses. Quantitative variables may be smoothly trans- formed using spline or monotone spline",Sugi-12-202 Kuhfeld Young Kent.txt
"C. Takima West Corporation, Chapel Hill, N.C. is required, and no functional form is Abstract assumed for S (t), . the ""underlyi ng"" The analysis of survival-time data often survival function~ involves an examination of relationships that Mixed Empirical/Cox Model: By stratifying 3. are complex and difficult to display. This is on some of the covariates, Cox- particularly true when there is more than one Kalbfleisch-Prentice survival estimates [3] covariate (independent variable) or when one of can be obtained wherein PH is assumed with the covariates is continuous. Some examples of respect to some covariates, but nothing is displays that are frequently needed but for assumed for the relationship between other which programming is tedious are: covariates and survival. For example, I. Plots of Kaplan-Meier [I] 2-and 4-year suppose that one wants to examine the survival probabilities vs. sex and deciles relationship between X. and S(tlx.) without of age. making any assumptions' wi th respJct to X., 2. Plots of one or more survival curves (with while assuming PH with linearity f3r followup time on the x-axis) stratified by quartiles of blood pressure and adjusted Xi2 ""·· 'X · Let the possible values of iR XiJ be de oted by v l' v?' ... , v. The for 5 other covariates. stratified Cox model fs t~n c 3. Plots of Cox [2] survival estimates vs. a cont i nuous range of blood pressure, drawn = vj ' = separately by sex group. S(tiX il X ' ··· , X ) i2 iP OS SAS currently has the tools f",Sugi-12-203 Harrell Pollock Lee.txt
"stone University of Alabama at Birmingham Abstract advantages of parametric analysis: the PROC HAZARD and PROC HAZPRED are two user graphical portrayal of the results including contributed procedures that are used for the predictions demonstrating the effect of risk parametric analysis of survival data including factors and demonstrating periods of high (or the incorporation of concomitant Information. changing) risk. The parametric model is a flexible model that consists of up to three phases that are PROt HAZARD additive in the hazard domain. Each phase is scaled a log-1 inear function of the by PROC HAZARD is used to build the model and PROC HAZARD builds concomitant information. estimate the"" shaping and regression parameters. the model and estimates the shaping and It contains several stepwise options and regression parameters. It contains several several different algorithms for optimization. stepwise options and several different algorithms for optimization. PROC HAZPRED The Input data for PROC HAZARD must contain a computes predictions for the survivorship and time variable and an event variable. The hazard functions along with their confidence procedure can handle right censoring, interval limits. Input for HAZPRED includes model censoring and count data. The input data can specification, parameter estimates and also be risk factor variables when estimation covariances, and a set of observations of risk factor coeffictents is required. The consisting of values for ti",Sugi-12-204 Naftel Blackstone.txt
"Improving Statistical Methodology with the SAS® System in an Industrial Environment Robert V. Baxley Monsanto Chemical Co. INTRODUCTION 2. Construct the model: Wrlte an equatlOn relating the performance What are the res pons i bil it i es of a consult; n9 measure to the independent variables. Take statistician in an industrial organization, and data by observing normal system operation how is SA5® statistical software useful in ex- or from a des; gned sequence of man; pul a- ercising those responsibilities? These are the tions. Use the data to estimate model para- questions to be addressed in this paper. The meters and verify that assumptions are met. statistician's job could be viewed as waiting for a client to come along and then devising 3. Derive a solution: optimal experimental designs or methods of data Use the fltted model to modify the present analysis to address the client's problem. In system in order to optimize the performance industry, however. a more pro-active approach measure. to the statistician's job is needed - one where the technology goals for the division or com- 4. Test the model and the solution: pany are identified, and where programs are Compare the actual performance of the formu 1ated to encourage the use of stat i st i ca 1 present and modified system to insure that methods in achieving those goals, not only by the model prediction is correct. the consulting statistician but also by many other research and appl ied scientists in the S. Implement and control the solution: organization. The first part of this paper will plan the lmplementation to avoid upset. discuss this latter view of the statistician's Compare actual with predicted performance job in more detail. and then, because the and find and correct discrepancies. availabi1ity of good software is of critical importance, an example of using SAS software in What is seen here is a comprehensive approach support of organ; zational goal s will be to problem solving which will result i",Sugi-12-205 Baxley.txt
"CONFIDENCE LIMITS FOR THE PRODUCT MOMENT CORRELATION COEFFICIENT BASED UPON NORMALIZING TRANSFORMATIONS Herbert Hamilton University of Illinois-Chicago forming between the r (or rho) and Z values. It is well known that the sampling distribu- Naturally, the MACRO also performs the needed tion of the Pearson Product MOment Correlation calculations entailed in constructing confidence Coefficient when rho ~ 0 approaches normality limits and intervals. only for very large sample sizes, particularly in the case of larger values of rho. Thus, use BASIC FLOW CHART FOR THE PROBLEM of asymptotic normal theory applied to untrans- The logic of the method is shown in Figure 1- formed values of r can easily lead to serious The inverse hyperbolic tangent function used for errors of inference when inappropriately app- transforming from am observed r value to the lied. The formula for the exact distributions corresponding Z value is of r for samples of any size drawn from the re- quired bivariate, or multivariate. normal popu- 1+r 1 (Fisher and Yates, 1963: ""2 loge y-:-r lations is known (Fisher, R.A., 1915; David, Z '"" p. 64) F.N., 1954). But only limfted tabulation of these distributions is available (David, F.N., The less widely known formula for retransforming 1954; Subrahmaniam and Subrahmaniam, 1983; Odeh, from the Fisher Z limits to limits for rho is 1982). A general method for inferences on rho Zz in the so-called non-null conditions, use of the rho _ (e 1) (Fisher and Yates, 1963: Fisher variance stabilizing, Z transformation Zz + 1) p. 64) (e (Fisher and Yates, 1963; David, F.N., 1954; Sokal and Rohlf, 1981), has become standard practice. The general normalizing transformation allows For a bivariate correlation the formula for the for applications to various forms of inference standard error of Z was given by Fisher as on rho. Here a SA~ MACRO is given for computa- tion of confidence limits and intervals on rho, 1 and issues pertaining to appropriate applica- tions are con",Sugi-12-206 Hamilton.txt
"on, University of South Carolina II.. STATISTICAL MODEL AND LIKELIHOOD THEORY The statistical method for the two stage ABSTRACT procedure may be described as follows: In the investigation of a disease often a Stage 1: Screening. Draw from frame a single continuous variable is measured for each preliminary sample of N people. Give each individual and on the basis of the value of this person a test in which a continuous score will variable an individual is classified as result with a higher score indicating a greater belonging to the diseased or nondiseased group. probability of the disease being present. Assuming that the variable is distributed normally for each group with a possible Stage ~: Reference test. Take a subsamp1e of n different mean and variance then the observed people from the first stage and give them an data for a sample is distributed as a mixture of exam in which the disease status (disease normal distributions. In addition if, in a present or disease absent) is determined. The second stage, a subset of the overall sample is probability of selection into this sample may measured on a vari·able that allows determination depend upon score on screening exam. Denote the of the individuals true classification then more diseased group as Group 1 and the nondiseased accurate estimation of the parameters for each group as Group 2. normal distribution is possible. In this paper a procedure is developed using maximum likelihood estimation to estimate the parameters As",Sugi-12-207 Kemmerlin Jackson.txt
"A SAS® macro for the ana lys ; 5 of mapped second-order methods, and IItest-set"" approachs spatial point patterns is described. The nearest (Ripley 1977). The distance measure and nei ghbor and nearest event di stance tests are second-order methods further permit spatial implemented along with second-order tests pattern model fitting. A SAS macro was written described by Ripley (1977). These tests permit to perform tests of CSR using distance and the classification of patterns into aggregated, second-order methods with additional output regular, or random point patterns. Monte Carlo available for use in model fitting. tests permit further testing for randomness as Additionally. graphical displays are used to well as testing against other alternatives. The further enhance interpretation of results. The first test incorporated within SPATIAL SAS/GRAPH® procedures are used to di sp 1ay these is based upon the first nearest neighbor (NN) functions to aid with their interpretation. A distribution or distance y from an event to the Poisson cluster process is fit to redwood nearest other event in the region, A. These seedling data using PROC NLIN. distances are found by computing the Delaunay triangulation (Upton and Fingleton 1985) of the",Sugi-12-208 Moser.txt
"PERFORMING THE FRIEDMAN TEST AND THE ASSOCIATED MULTIPLE COMPARISON TEST USING PROC GLM David Ipe, Syntex (Research) The F-approximation of the Friedman test and The hypotheses tested are: the associated Rank Sum multiple comparison test (Conover)l can be performed using the All treatments have identical effects. procedure 'PROC GLM'. This procedure is ap- plied after ranking the data within each block At least one treatment tends to yield from lowest to highest value using the proce- larger observed values than any other dure 'PROC RANK'. In this paper an overview of treatments. the F-approximation of the Friedman test and the associated rank sum multiple comparison test will be first presented. It will then be The test statistic is: shown that by appropriately specifying the 'model' statement and the IlS Means' statement in the procedure 'PROC GLM ' one can arrive at bK (K+ll 2] exactly the same results. (b-l) [B - 4 - (1) 2 A2 - B2 Consider a data set of b mutually independent k-dimensional random variables Xil. Xi2. b K 2 ...· XiK where i 1, 2, b. For exam- = ,.Of Where A2 = i!l j!l [R(X ij )] ple, in a pharmacological study a human subject represents a block. and K represents the number of treatments administered to each subject over and R is the sum of the ranks for treatment j. j K weeks. X~j is in block i and is associated with the jt treatment. The b blocks can be If T2 exceeds the l-u quantile of the F-dis- arranged in K columns where each column cor- tributlon with Kl :K-l and K2 = (b-l )(K-l) degrees of freedom then the null hypothesis responds to a treatment. HO is rejected at the level ~. TREATMENT If the usual Randomized Block Design (RBD) describes the experiment. then the model statement in the procedure 'PROC GLM' is given BLOCKS 2 3 K by Model VARIABLE = BLOCK TREATMENT. Xll X12 X13 Under the RBD assumption, the F-statistics for treatment differences is given by 2 X21 X22 X23 F = Mean treatment sum of squares (MTSS) - (2) 3 Mean error sum~f squar",Sugi-12-209 Ipe.txt
"Writing Customized Reports Using the Data Step Howard Levine, Levine Software Systems code. INTRODUCTION Before examining use of the data step for report writing, one thing that is important When it is necessary for you to write to notice is that SAS system options can reports that cannot easily be generated by affect the way your reports will look. The SAS® System procedures, you will need to options that are most important to .consider write a customized report with the data step. are PS=value, OVP/NOOVP, DATEINODATE, and This tutorial. covers SAS system statements LS=value. If these are not set correctly, your and programming techniques that will make data step may give you a poorly formatted your report writing code both easier to write report. . and modify. This tutorial is meant to be used The SAS System statements you should in conjunction with the SAS Users' Guide' be familiar with for generating reports are Basics. That is where you can read detailed the DATA, FILE, PUT, and RETURN statements. explanations of the statements; this tutorial You should also understand labels. In addition, is designed to show you how to use the you should know how to read data into a data statements as effectively as possible. step using the SET, MERGE, UPDATE, and INPUT The main pOints covered in this paper statements. It is also important that you are the PUT statement, FILE statement, BY understand BY group processing. These are group processing, and creating headings. In. the documented in SAS lJsers' Gllide' Basics. FILE statement, the options to pay especially The FILE statement is used to define a close attention to are N.PS, HEADER=label, . file that you are writing a report to. Although and LL=variable. Three different techniques it is possible to define several files in one for generating headings will be demonstrated; data step and write out several reports from they are using code (the traditional approach), that data step, it is usually a bad idea to do using a he",Sugi-12-21 Levine.txt
"The kappa statistic incorporates the level of chance agreement into the assessment of This paper demonstrates how PROC CAl MOD may interrater agreement. For example, if two raters be used in the construction of generalized kappa employ completely differept and independent statistics. Furthermore, it is shown how criteria for distinguishing between the occur- relevant hypotheses concerning interrater rence or non-occurrence of an event, then all agreement may be tested using PRDC CATMOD, agreement is due to chance. Kappa considers the within the conceptual framework of the GSK level of chance agreement in its formulation. method. A general form of the response function Let p~~ be elements of a probability matrix transformation matrix, F, is given. Hypotheses P associated with the I X J contingency table considered concern overall and category specific V, with I=J, where the rows correspond to the measures of agreement and the equality of kappa observations of rater 1, and the columns values in multiple populations. An example is correspond to rater 2. Let p~ denote the given to illustrate the flexibility of the observed agreement between the raters, where PO:' CATMOD procedure. is",Sugi-12-210 Terry.txt
"SAMPLING VERY LARGE DATA SETS FROM SAS' SOFTWARE: PROC RANDOM AND PROC RANSTRAT Gail W. Johnson, University of South Carolina, College of Health William Douglass, Office of the Attorney General, State of Texas 1. Introduction The value Xo is the ini tial value in the generation program, and it is referred to as Because 0""£ the CPU time and dl-sk I/O the 'seed' ,of the generation process. By requi red t'i convert a very large raw data file defining xo' it is possible to reproduce the into a SAS data set,' it is sometimes same pseudo-random numbers, and therefore, the impractical - or impossible - to do .so on a same random sample if desired. limited or highly utilized system. pltoc RANDOM and PROe RANSTRAT provide simple mechanisms -for The integers produced are in the interval choosing either a simple random sample (RANDOM) (O,M). They are transformed by Xi I Minto or a stratified randan sample using one (0,1) over which they approximate a U(O,I) stratification variable (RANSTRAT) of unwieldy process. To transform the U(O,I) deviates to data sets. The raw data samples can be stored discrete uniform (O,N) where N is the number of in temporary data sets, or they could be stored observations in the original data set, multiply permanently on either tape or mass storage. by N, add 1 to the result, and truncate the The sFple raw data files can then be read into result to ail integer. a SAS program using the usual INFILE and INPUT statements. All processing after the The pseudo-random deviates are the DATA step is custcm.ary. observation numbers of those observations to be kept in PROC RANDOM. In PROC RANSTRAT, the Please note that PROC RANDOM and PROC deviates serve as pointers to the observation RANSTRAT 'are designed ,.only for use with raw numbers of those observations to be kept for data sets, not on SAS data sets. the stratified random sample. 2. Input Data Set Specifications 4. PROC RAIIIlOM The user must provide the necessary The statement to control PROC RANDOM i",Sugi-12-211 Johnson Douglass.txt
"COMPARISONS OF DATA PROCESSING PROCEDURES FOR THE STATISTICAL ANALYSIS OF VISUAL FIELDS Katherine Freeman, Montefiore Medical Center Thus, a single representative measure of fluctu- OBJECTIVE ation for the visual field is not readily ~xperience apparent; one estimate can be derived by pooling Practical with regard to analyzing visual field data is rare. This paper intends to estimates of variability obtained for each of 74 points in the visual field across the six visual illustrate practical and efficient methods of handling and analyzing data that are represented fields. as coordinates of a matrix. Data Management Problem: Data for 74 threshold measurements (printed in an octagonal matrix pat- STATEMENT OF PROBLEM tern) represented one evaluation(visual field) for one eye of a patient with glaucoma. There Medical: The visual field is defined 74 by points in ones's field of perception, depicting a were five patients, each of whom had two somewhat octagonal shaped matrix. The measure- glaucomatous eyes. Evaluations were performed at baseline, 1.1' 2 and 3 weeks after baseline, and 2 ment taken at each point in the matrix is the and 3 months after baseline) twice a day--once in threshold or the lowest intensity of the morning and once in the afternoon. Several light(measured in decibels) perceived by the eye problems existed with regard to managing the at that point in the visual field. The technique data. Firstly, the data were not submitted in a of static automated perimetry has been used ~UC format that could be keyed onto tape readily. cess fully in glaucomatous eyes to detect visual field loss over time by examining changes in cor- Secondly) in order to streamline procedures for responding threshold points from visual fields working with this volume of variables, it was considered an advantage to name each variable by obtained at two points in time. However, a prob- the variable's 'location' or (x,y) coordinate lem still exists with regard to defining those point",Sugi-12-212 Freeman.txt
"ESTIMATION OF VARIANCE COMPONENTS IN MIXED FACTORIAL MODELS INCLUDING MODEL-RASED DIAGNOSTICS R. R. Hocking, Texas AIM University R. H. Brener, Texas AAM University The key to our resul ts 1i es in an a1ternat ive 1_ INTRODUCTION description of this model in which we simply descrihe the mean and covariance structure In this paper, we consider the problem of es- which is implicit in (1). Thus. we see that timating both fixed effects and variance com- ponents in mixed linear models. For brevity, E(Yijkr)=~ we restrict ,the discussion to factorial models, but the basic concepts apply to the general Var(y i j kr)= 00=~O+~1 +~2+~12+~/~13+ ~23+~123 class of ANOVA models. We are particularly * interested in what is known as the unbalanced * * Cov(Y··k .Y * * * *)=01=~1 i=i j.j k.k data situation since that is an essendally 1J I'"" i j k r unsolved problem. The results on diagnostics * * * apply as well to the balanced case where op- i ti j=j k.k ~2 =°2 timum estimates are known. An interesting * * i =i j=j * k.k feature of the diagnostic form of the estima- =0 ~1+~2+~12 12 tors is that the source of negative estimates * * * of the variance components is often revealed. i ti j'j k=k ~3 =°3 * * i =i * j.j k=k 2. MODEL STATEMENT ~1 +~3+~13 =°13 * i ti * j=j k=k * We describe the model and the notation in terms °2+~3+~23 =°23 of the complete three-factor model since it contains the essential ideas. The extension to =01~3 ~1+~2+0p the k-factor model will he indicated. In clas- +° 3+~13 +°23 +0123 sical form. the model is written as a linear combination of parameters (fixed effects) and * * * i=i j=j k=k r<r * rand01""l variables as follows: (2 ) Note that we have introduced new parameters 0~ as linear functions of the original variance Thus, 00 is the variance of an ob- c01""lpon~nts. servatl0n and 0~. ~=1,2.12, ···· 123, are covar- iances as indicated. In particul aI""', o =cov(y. . . .y... ) '1'2 3r J1J~3s , i .=1, ···· a .· j=1,2,3 r=O,l, ·· ,n . . . ' J J '1'2 ' 3 kf;~ for ik=",Sugi-12-213 Hocking Bremer.txt
"VARIANCE COMPONENT ESTIMATION WITH THE SAS' SYSTER R.C. Littell, University of Florida B.G. McCutchan, Westvaco Corporation Abstract.--The use of the SASR System for model is most efficiently written in matrix variance component estimation is illustrated notation as: with an example. Properties of the several m methods are discussed for balanced and unbal- Xa + I Z.b. + Y E anced data. j=l J INTRODUCTION where classification matrix of fixed X The SAS System offers several methods for effects estimating variance components (Ves) (SAS parameters for fixed a = vector of Institute Inc. 1985). The question of which effects variance component estimation method to use classification matrix of jtb random Zj arises when the data are unbalanced, i.e., when effect there are unequal numbers of observations in vector of random variables for jth b. the subclasses. If the data are balanced, then J random effect the analysis of variance (ANOVA) estimates have vector of residual error terms. optimal properties. However, with unbalanced data, there are no uniformly best estimators. Example of a 3x3 mixed model The choice of an estimator can be based on the theoretical properties, computational ease, 1 10 y.. [~: ] and in the absence of uniform properties, 1 10 yu simulation studies. This paper will present 1 10 y"" information on each of these three aspects. We 1 01 y"" will first discuss the various means of VC 1 01 y"" estimation available in SAS and illustrate the 1 01 y"" results with an unbalanced data set. It is our goal to provide background information to aid ,,, the user in choosing amongst VC estimators 1 0 0 ,,, [~:] available in SAS. For a general review of the 1 0 0 "", +001 literature on VCs, see Hocking (1985), Khuri ,,, + and Sahai (1985) and Searle (1971, 1979a). More 10 0 "", specific details on the derivation of these 1 0 0 ,,, estimators can be found in Searle (1979b), 1 0 0 while details on SAS computation are described by Searle and Grimes (1980). There is a technica",Sugi-12-214 Littell McCutchan.txt
"Strategies for Repeated Measures An.-'llysis of Variance Phil Spector, SAS Institut.e, Cary, NC To understand the muH.inJ.riat.e approach to repeated measures 1. INTRODUCTION analysis, it is important to llndel""si.and the hypot.heses which arc Although repeated measures designs arise natmally in many dis-- being t.est.ed. As it simple example, suppose we have measured ciplines, it is only within th"" I1'Isi l.eTl or 15 years t.hat. t.hey have someone's blood pressme at three different times, and we wmlt to hecome widely used. Part of the )llit.inl problem was the lack of know if the blood pressures ha.ve dJalJged across the t.hree times. If appropriate computing fa.cilities. The mult.ivariate a.pproach t.o re- we run a stanchu'd lllultiv;niai.e analysis of VariaJlCe, fitting only an peated measures ANOVA, whil"" arising naturally from a theoretical illt.ercept and using the three measurements as depelldent variables, point of view, df'manded compul.ing resources not generally avail- we ,.""ill be testing t.he llypot.heses t.hat the scores are a.ll equa.l to able when it was first. pr""sented in the literature (Cole and Grizzle, zero. One way to t.est. t.he null hypotheses of HO change across time 1966). Thus, many researchers tried t.o force repeated measures is to create a set of transformcd variables, such tllat if the I.rans- designs into the traditional nnivari:Jt.c ANOVA model. Whi.le this formed variables are equal to zero, then all t.hree measurements made ana.!ysis of t.hese cksigns more accessihle, it, also obscured are equal to each other, and vice versa.. Many simple ~rausfor some of the hasic aspeds of repeated measures allalysis, most no- matiolls will acheive this gORL for eX[lmple, subtracting the t.hird tably the inilerent. correla,tion of observations made on the same measurement f\'Om tIle other' two. TJ1l1s, a multivariat.e analysis individual. With easy-to-use software [or bot.h univariate and mul- of vari,mce for a repeated measures factor is nothi",Sugi-12-215 Spector.txt
"KEASURES OF KULTIVARIATE SKEWNESS AND KURTOSIS Ha.Jun Kang Ron Kalinoski Syracuse University. York Ne~ 1. Introduction nates it. The observation that Assessing the dietributional assumptions in multivariate statis- makes the largest contribution to the multivariate kurtosis measure is tics is one of the most neglected picked and deleted. After that. areas in modern statistics. Viola- this program oalculates the multi- tion of the assumption of multivari- variate skewness and kurtosis again. ate normality can have a serious based on the remaing data. effect on the validity of the esti- The soon-to-be extinct PROe mates. The Qidely used maximum MATRIX of SAS Version 5 is the major likelihood estimate. for example, is tool used to develop this program. not robust with regard to non- The code can be easily converted to normality (Boomsma. 1983; Harlof.J'. SAS/IHL code in the future. Multivariate 1966; Tanaka. 1964). normality represents only an ideal. approximations of which are rarely 2.Hultivariat. ExpanSion of Skewness seen in empirical data sets. With- and Kurtosis out proper tests tor the distribu- tional assumption of the observed Let Xl =(X,.L9 ······· X,;. variables. multivariate statistical estimations. like maximum likeli- (i=1929 ······· n) be a random sample of size 'n' from a p-variate popula- hood. might not yield appropriate tion with random vector X' statistical statements. =(X1........ Xp). Let""i' There exist many different meth- ods to test the normality of data. =<X19 ······· XP) and S={S.c.j} denote the sample mean vector and the Shapiro and Vilk(1966) compared nine different methods in their study. covariance matrix respectively. Based on findings from five differ- Then the multivariate skewness, ent sample sizes ranging from 5 to denoted by b.p, may be obtained by 50. they concluded that a combina- considering the canonical correla- tion of both univariate skewness and tions between X and S (Hardia, 1970, kurtosis usually provides a sensi- P.520).",Sugi-12-216 Kang Kalinoski.txt
"1) where the user How much will the 205th widget cost your may select any of a variety of functions. company to build? What is the average cost of any given production unit? What will the pro- Terms used by 'learning Curve Calculator jected cost of any future production lot cost? UNIT These questions and many others can be answered The manufacturing sequence of an item. The by applying the 'Theory of Learning Curves', first one produced is unit #1, the second is sometimes known as 'Improvement Curves'. #2 etc. Proper unit numbering is critical to the accuracy of the results. Basically. a learning curve ;s a line on a graph that represents two primary facts [1J the time COST required to do a job decreases each time that The actual observed cost of a particular unit. job is repeated, and [2J that the amount of de- This cost may be expressed in terms of mone- crease will be less with each successive unit. tary units, such as dollars, or labor units, such as man-hours. Learning curve theory began as far back as the early 1920's, with the first published work PREDICT on the subject in the February 1936 'Journal of The predicted or estimated cost of a given Aeronautical Sciences' by Thomas Wright. unit. Engineers and Project Managers recognized that employees engaged in manufacturing and assembly AREA functions could work more quickly as more units The approximated cumulative cost (Area under were produced. This per unit reduction in labor the Curve) between two units. This would a",Sugi-12-217 Sisemore.txt
"TABLETS - A TABLE GENERATOR Bernard Costa, Hoechst-Rollssel Pharmaceuticals Inc. placed in the ROW, in Exhibit 3, they have TABLETS is a powerful table been placed in the COLUMN, and in Exhibit 4 generating macro developed at Hoechst- the table has been PAGEd by variable. Roussel Pharmaceuticals Inc. to reduce the programming effort needed to produce accurate and pleasing aesthetically EXHIBIT 2 tabular output. Prior to the introduction of TABLETS, most table requests were custom Test Drug A (HRPI 999) Protocol 301 coded using base SAS as a procedural language. ~ABLETS has eliminated most of VERTICAL ORIENTATION OF STATISTICS this program code. VARIABLES APPEAR IN THE ROH Tables are described to TABLETS in EFFICACY terms of content and form. The CONTENT DRUG A DRUG B VARIABLES parameter describes both the variables to be analyzed and the statistical test used BASELINE VARIABLE ONE to perform the analysis. The parameters 29 15 Number PAGE, ROW, COLUMN, and ORIENT are used to 17.2 11.3 Mean control the form of the table. The general VARIABLE THO orientation of the table (horizontal or 29 15 Number vertical} is controlled by the ORIENT 5.0 7.4 Mean parameter, and variables of interest can be ordered within the table using the PAGE, VARIABLE ONE WEEK 1 ROW, and COLUMN parameters. Addi tional 23 13 Number parameters are also available to control 10.2 21.5 Mean the processing methods and spacing, and to VARIABLE TWO provide the textual content. 23 13 Number 11.5 Mean 5.3 The content of Exhibit 1 consists of the counts and mean of two variables VARIABLE ONE HEEK 2 (variable one and variable two). 'l'he Number 8 10 table is ORIENTed horizontally, ie the 16.0 Mean 12.3 functions used to produce the cells of the VARIABLE THO table differ horizontally across the page. 10 Number 8 The drug groups were specified using the 5.7 Mean 4.4 parameter COLUMN, and the variables and the visit were specified using ROW. Protocol was specified ~sing PAGE. EXHIBIT 3 EXHIBIT 1 Test Drug A (E",Sugi-12-218 Costa.txt
XRECALL is most useful when it is in the XRECALL is a SASs Display Manager system (OMS) library or concatenation of libraries made command macro. It serves as a functional available to the SAS system using the macro replacement for the DMS RECALL command and adds autocall facility. All examples in this paper the capability of recalling more than one or assume that XRECALL is available via the all submitted statement blocks at once. autocall facility and that the MAUTOSOURCE and CMDMAC (CoManD MACro) options are in effect.,Sugi-12-219 Frank.txt
"d observations for the month of June are selec- This tutorial introduces the SAS macro facility ted. later in the program, a report of sales and describes what macros are, why they are results for June is printed. If we now want to necessary, common applications, and how SAS use this program to create a report for July, we must actually go into the SAS code and processes them. No prior experience with change all instances of June to July. While macros is necessary, but an understanding of the DATA and PROC steps is assumed. this would be easy to do in this simple exam- ple, if the program were several thousand lines long and if there were more than one kind of What Are Macros? change, the process could be both difficult and error prone. Hence, we 'needed a capability in Macros are a facility within SAS for writing SAS to write programs in a flexible way where flexible code. To illustrate what flexible parameters are specified at execution time. The macro facility provides this capability. code means let's look at a program written in a traditional programming language. PROC FREQ is a SAS procedure for constructing and analyzing contingency tables and is itself a program Uses of Mac ros written in PL/I in the mainframe and minicom- puter versions of SAS or in C in the PC ver- The following list shows typical uses of macros: sion. let's examine the two examples below. Get system information Example 1: Two-way table Conditional execution of steps Data dependent code PROC FREQ; R",Sugi-12-22 Rosenberg.txt
"al world"" Linear programming has been a modeling tool of - Formulate a mathematical model practical importance in many industrial and - Measure model parameters business settings. The technique enables analysts - Build model to study systems in an effort to improve - Solve for decision variables performance increase efficiencies. - Implement solution and Production, transportation, and scheduling are three areas that have been modeled extensively Figure 1. A paradigm for problem solving. using linear programming. Management Science, Interfaces, and Computers & Operations Research Once a general problem is stated it must be are examples of journals that have published narrowed to a manageable size. For example, in numerouS articles showing applications. the general framework one may have identified the Analyzing systems using linear programming manufacture of a cereal as an area were models usually involve several types of tasks. efficiency can be gained. On closer examination, These include; mathematical model building, data identifying the least cost mix of several grains collection, data keying, model solution, and that meets the nutritional needs of the cereal is solution reporting. Often the most time consuming of particular interest. This reduction from a work is associated with data collection and the general question of manufacture to the more data handling tasks involved in building, specific one of particular product mix not only solving, and reporting. Although the",Sugi-12-220 Cohen.txt
"ases it may be unavoidable. Abstract situations SAS Macros can spee:::i up this process This paper will present several llmensely. There are often occasions in the reporting techniques and suggestions which I have found to of analysis results when the following con- be very helpful in designing customized macros straints apply: for rep:>rt writing awlications. It will show how the user can design his own macros to rnass- A large number of tables are to be 1. produce tables. By creating a generalized macro produced. that inputs table pararret.ers fran the user, producing a large voluma of tables can be a A specified format must be followed; 2. relatively sinple task. This paper will also i.e. tables are to appear in a fom offer a ""real-world"" exarrple of how the SAS not available through PROC PRINT, Macro Facility helped to produce canera-ready PRCC TABUIATE, or sare other tables with limited programner intervention. convenient procedure. Quality control neasures dictate thet 3. SAS Macro Language '!boIs the mmilers not be transcribed and typed manually into correctly The neat and precise presentation of formatted table shells. results is often as :inportant to a deta analyst as the methods he used to achieve those results. Normally, the use of PUT statements and a The way in which he chooses to display the data FILE statement would be the logical solution. to the audience can effect the way the data is PUT staterents offer a great desl of flexibility interpreted. Often tines,",Sugi-12-221 Gabel.txt
"SAS/AF is without a doubt one of the single %TSO ALLOC F(SASDB) DSN{DCW9.SAS508.AFMENU'); most important improvements to the SAS® product %TSO ALLOC F(AFOUT) DSN(SASAF.DOCUMENT) MOD; %AFlIST(CATALOG;sasdb.sasmenus,FILE;afout, line because it provides the ability to tie INOEX= YES ,VARLIST;YES); numerous individual program modules into a COm- plete ""user-friendly"" system. However, its These statements will read all of the entries biggest shortcoming is the inability to provide detailed documentation as to the contents of the in the sample SAS/AF library provided by the libraries. This paper presents a SAS macro de- SAS Institute and write the results, including veloped at General Dynamics/Convair Division index and'cross reference, to a file called 'SASAF . DOCUMENT' · to solve this problem. NOTE: The disposition of ddname specified in",Sugi-12-222 Sisemore.txt
"ate this data set to the standard SAS input ABSTRACT (SYSIN DD'statement) via another DD statement (lines 14- 16) that refers back to the first. There can be a number One of the most powerful features of SAS software is its of fancy variations on this basic theme, but we find the data ~tep programming language which offers map.y of the procedure illustrated in Figure 1 adequate virtually all of features of standard high-level languages like PL/I. This language opened up the possibility of having a SAS the time. program write another SAS program, which can be a very FIGURE 1. useful way of eliminating a lot of tedious programming in certain applications. By customizing the useT interface, so IIXEETNR JOB (XEET,Q68) , 'B. HCCANDLESS',TIHE=(,30) 1. that once a set of input parameters in simple format has II EXEC SAS 2. been specified. the SAS software can then take over the IISASPROGM DD DSN=&&SASPRQGH,DISP=NEW, 3. II UNIT=3350, SPACE= (TRK, (2,2) ,RLSE) 5. writing and execution of the program. IISYSIN DD * 6. 7. This paper teaches by example how to overcome three DATA _NULL_; FILE SASPROGH; 8. rUT 'DATA _NULL_."" 9. hurdles in using a SAS program to write other SAS POT' '* PUT t INSIDE' ' j ' , 10. programs. Simple working examples are followed by a STOP: 11. full-fledged example of a SAS system to translate survey RUN: 12. 13. data file specifications into a SAS program for creating a DD DSN=*.SASPROGM,DISP=(OLD,DELETE), 14. 1/ SAS file and performing range checks on the data.",Sugi-12-223 McCandless.txt
"BUILDING A CLINICAL DATA REVIEW SYSTEM USING SAS/AF* SOFTWARE James F. Sattler, Syntex Research llAssisted Review SYstem INTRODUCTION Early in the development of the Last year a team of researchers pre- Review System, a conscious policy was sented a report to SUGI about work in implemented to document each menu and progress on"" Clinical Data Review Sys- program screen with accompanying help tem. At that time, the system was a screens. This design policy went beyond simple prototype based to a considerable simple help screens, however. In addi- extent on demonstration software pro- tion, a group of parallel tutorials WI' vided with SAS/AF. Since then, the provided for the System's program Clinical Data Review System has grown screens. considerably and is serving as the basis for other automated review systems. The parallel development of review This paper will summarize the experience procedures and tutorials is a unique of the production version and discuss design feature of the Syntex system. some of the system's technical features. Users of differing skills can use the same system, rather than two or more different systems - i.e., a 'training BACKGROUND system' and a production system. A beginning user may find it necessary to Before a new drug can be approved as break out of each program screen into an safe and effective, it must undergo a accompanying tutorial. Later on, the wide range of tests. following pre- user will select fewer and fewer tutor- liminary laboratory and animal studies, ials as' his or her skill level human testing takes place in the form of increases. This Assisted Review System clinical trials. Physicians, working provides the flexibility needed to make together with the drug's sponsor, admin- the system usable by everyone in the ister the drug to volunteer patients. department. The following diagram The physicians then record information illustrates the design o·f this parallel about the drug's safety and efficacy on tutorial feature. spec",Sugi-12-224 Sattler.txt
"features of the SAS system which can be used to effectively make an interface system both Several Version 5 features of the SAS system flexible and generalized. A reporting system have been combined to demonstrate one way to recently designed for a nationwide survey will create a generalized, easily maintainable user serve as an example. interface without sacrificing flexibility and response to user growth. A reporting system is Structuring the System used as an example. The steps taken in designing such a system are outlined, and the The dile1ll11a of general izeabil ity vs. use of SAS/AF*, SAS/FSP*, the Display Manager flexibility really comes into play on two System (OMS), SAS macros including command-style levels: the inner workings of the system, and macros, and AUTOCALL are highlighted. the system presentation. The system presentation will be dealt with first.",Sugi-12-225 Hubbell.txt
"re SAS/FSP Softw are, SAS/AF Softwa re and SAS/DMI Softwa as tools for work statio ns David T. Bean Morino Assoc iates, Inc. vienna , VA are using SAS as an adhoc others (IPPs) Produ cts The Instit ute progra m With all of these report ing tool. have become some of the most popula r users there is always questi ons about: tools for use by Inform ation Center person nel during the past decade . With ""I've had this type of proble m. Is it menuin g the of introd uction the a bug or am I doing someth ing wrong? "" facili ties and data entry facili ties of recent ly most and SAS/AF SAS/FSP, The Instit ute provid es a early warnin g SASjDM I, even more applic ation area's vehicl e to assist in the answe ring of have been opened for the use of the this type of questi on. SAS Usage Notes IPPs. provid e the admin istrato r with a data set about most the know proble ms in the SAS/FS P provid es basic data browse and progra m code and user docum entatio n edit capab ility into data sets. User Our goal which the Instit ute suppo rts. define d screen s can be used to provid e here is to develo p an inquir y system data. the a custom ized layout to which will permi t the SAS admin istrato r an be to design ed was SASjAF to query the notes. provid e ation Center tool to Inform Simple capab ility. menuin g basic Hypot hetica l Proble m decisi on logic has been built into the th~ applic ation user allowi ng produ ct The requir ement s for this hypot hetica l to option s or to select applic ations system are simply to provid e a full run. screen intera ctive enviro nment which access to the Usage easy the permi ts to writte n origin ally was SAS/DMI Notes. In additi on the admin istrato r System Intera ctive IBM's interf ace must be allowe d to search the data for (ISPF) tables Facili ty Produ ctivity intere st. observ ations (recor ds) of power ful The with SAS data sets. Furthe rmore the applic ation user would select ion and the menuin g, of nature like to view ZAP data associ ate",Sugi-12-226 Bean.txt
"t we have discovered the meta problem of U maintaining coherency In our analysis SUbmitting SAS code to SAS for execution Is only one use for the code we write. This paper ex- paths. We can do so much so quickly we now plores the Idea of SAS code as data about the must pay attention to organizing and know- work we are doing. If we explore these data-- Ing our voluminous output."" even with the simplest tools--we' I I learn useful things about our work. This idea is I I lustrated To solve these problems, Nuget proposes a set of with examples of what it Is easy to do today, programs that represent a stream of existing with proposals for what Is certainly possible source code in such a way that the code can be with a little more effort and with a discussion examined"" In fairly sophisticated ways. This of what would be desirable in the future. Think- paper deals with these problems on a level that ing and talking about how we use SAS code as Is Intermediate between Muller at al. (1981) and data today could help guide the development of Nugent (1986). more powerful tools for SAS users tomorrow. We need to be able to manage the cumulated SAS II. I nt roducO on code and outputs from many sessions, even though this paper focuses on tools to examine an In- Submitting SAS code to SAS for execution Is only dividual session (a single fi Ie). ConceptualIz- one use for the code we write. We also read it ing the data analysis path across files and ses- and quote It to each other to describe",Sugi-12-227 Smith.txt
"Giving people access to the inFormation serves over three-quarters o£ a million they need is the basic mission of data custom~rs in six di££erent states. To processing departmeots~ To perform the people in Rates & Regulation this this mission, DP professionals often means that the in£ormation they must employ interface tools desIgned to produce to satis£y agency inquiries and shield people ""ho need the information support £ilings varies greatly. Speed store i t . from the camp 1 ex Mays ....e We and £lexibility in meeting these In£or- use menu driven systems, code gener- mation demands are nearly as important ators, query systems and other devices. as accuracy .. While i t may lack some of the flash of My primary support duties for Rates & n~er tools, base SASR soft""sre Regulation involve the Load & Statis- provides people Mith a Kay to obtain tical Research group. Peop,le in Load and use the information they require. Research per£orm a variety o£ data And, a SAS file that provides a high collection, reporting and analysis level of self-documentation and simple activities.. They have been ,using the access to its information is an SAS system £or several years. Though effective user interface tool. not trained in data processing, they need to perform statistical reduction This paper is a study on a set of ful1- and analysis o£ large numbers o£ obser- featured SAS files. These files vations. They are pro£essionals Mho incorporate general design and special SAS £eatures that pr",Sugi-12-228 Langill.txt
"program. Appendix B contains a copy of the SAS portion of the program after the program has been executed. Appendix C contains a copy of the first An occasion may arise where data reside in a few lines of the output listing. data base that is not easily access able to base SAS software. One solution to this difficulty In the first part of the program, denoted by is to create a fIle using a language that can readily access the data base and then use base STEP 1 in the JCL (Appendix A), SMART is used to retrieve from the IMS data base selected data for SAS software to process the data in the file. This paper will discuss how this two step process four different entity types which were active on can be accomplished. We illustrate with a pro- December 31, 1985. The data are then placed in a gram used at the Federal Reserve Board to sequential file, created by the SMART command SUBFILE: (USERI ,FD,INTEGER), which is then writ- generate an alphabetical listing of depository institutions. The program uses an in-house pro- ten to a disk pack. This portion of the program gramming language to retrieve data from an IBM took 81.40 CPU seconds or about 1 1/2 minutes to IMS data base and then uses Version 5 of the SAS execute. language to process the data. It Is run on an IBM OS system. In STEP2 of the program, base SAS software is used to read the newly created file and process the",Sugi-12-229 Leddon Fry.txt
"rogram becomes, the This basic tutorial discusses tips for improving harder it is to shake out all the bugs in it. the overall efficiency of your SAS code. The more space your SAS data sets take up, the less room you have for others. At the Too often, talking about ""efficiency"" in coding end of this vicious circle lies an ironic truth: raises unwelcome images of abstract nitpicking misuse of the freedom given to you by the just to save a millisecond or two of CPU time. capabilities of the . SAS language ultimately With the power of SAS software, however, fences you in, and you can't get the results users can sometimes fall into bad habits that have a tremendous negative impact on the you need. amount of work they can get done. When effi- This trap has never been so permclOus as in ciency considerations are totally ignored in recent years, as we have seen the SAS lan- SAS programming, bugs tend to proliferate and resource requirements can mushroom. Users guage evolve from a powerful (but still basi- then encounter what they falsely see as ""limi- cally ad hoc) tool for statistical analysis into a tations"" in the SAS software, shrug their virtually unlimited software system designed to meet all the computing needs of its users. shoulders, and give up. Large interrelated systems are now developed The goal of this tutorial is to show users spe- using SAS software. My installation routinely cific ways to focus on tightening up their pro- processes well over three million observatio",Sugi-12-23 Kretzman.txt
"ges: ABSTRACT Following on the heels of the 3rd generation programming lan- guages such as FORTRAN and COBOL came the 4th generation In the past, reports have been generated by mapping on a piece of report writers, which, it is said, makes ad-hoc reporting something squared paper exactly how the report is to be laid out. The report is then written using WRITE statements or their equivalents (such for unsophisticated users. This is true, but the reports available as PUT in the SAS system) and specifying line by line the infor· from these languages, or at least the reports that an unsophisticated mation to be printed, and the columns in which to print them. A user can produce are basic tables of the row/column type. 1lis user (or progranuner) could not .actually see the report layout may not meet exactly the user's requirements (especially a& '. is shown in the case of the telephone account). To produce anything properly until the program was at the testing stage. more complex than a row/column table in base SAS requites a Conversely, panel generation routines have_ advanced to the point where now it is possible to 'paint' a panel so that the panel more sophisticated knowledge of the SAS system (especially within is generated as the user would see it. . a DATA step) than just the PROC PRINT statement. This paper discusses the use of SAS macros to eliminate the re- The PUT statements within a OATA step can make the code for port coding step, and the design of a report layout usi",Sugi-12-230 Johnstone.txt
"omer can enter parameters via the Interactive System Productivity Facility (lSPF) under the Multiple Virtual Systems I Extended Architecture (MVSjXA) operating system, causing a Statistical Analysis System (SAS) job to be submitted to create SAS reports. ISPF routines allow a menu-driven interface to receive parameters, which are eventually passed on to the modified SAS programs. In this application, previously written SAS programs are modified to include SAS macro-language statements. This paper focuses on the general methodology needed to use this technique. Implementation of an Interactive Method Introduction MVSjXA contains the basic elements of infonnation that Monthly reports distributed by the Field Data department describe the field performance of a machine. A method was contain considerable information at a generalized level. needed, by which a customer, usually a nonprogranuner, could However, many customers (individual product areas) often pass variables to SAS programs. Using an IBM licensed need specific, detailed information. A new technique, called the program called Interactive System Productivity Facility (ISPF), interactive method, allows a customer to generate that the customer can enter into a dialog with the system and infonnation. construct the JCL required to execute an existing SAS program. A dialog is an interactive application designed to run under the control of ISPF, which manages interactive Prior to this interactive method, the Field Data departm",Sugi-12-231 Bond.txt
"DECISION SUPPORT SYS1EMS USING SAS® SOFIWARE AND ISPF® (OR HOW ISPF TABLES CAN ENHANCE YOUR SAS LIFE) David Howe, General Dynamics Data Systems Division Christine Hendrick, Genera1 Dynamics Data Systems Division Walter Mereier, Genetal Dynamics Data Systems Division ABSlRACT query modules were written in base SAS software and SAS/GRAPH® software. The system met many of the project goals, however response time was slow and the code In 1983 a small group was fanned at General Dynamics Data Systems Division Eastern Center to research and lacked the modularity necessary for easy maintenance. develop Decision Support Systems (DSS). Short term goals were to develop a systern which would provide consistent After evaluating several DSS packages, System W® data for management reporting, provide an easy way to from Comshare, Inc. was chosen as a JK>Ientia1 corporate access a variety of data types, present the data as usable standard Decision Support tool. Data Systems Division information and decrease dependence on end-user Western Center developed and implemented several System programming for ""one-shoe' reports. Long term goals were Wapplications. We at the Eastern Center chose to continue to support ""what-if' analysis and modeling. refining the SAS DSS software while prototyping Sys(em W. At the time, connnercially available DSS software did not To improve response time and modularity, we switched from a direct SASIISPF link to an indirect link. We had adequately satisfy the goals. The DSS Group then set out to develop software in-house using SAS software, TSO avoided t1tis approach in the past because we thought that the CLISTs and ffiM's ISPF Dialog Services®. The software overhead of invoking and reinvoking the SAS sys(em from a has undergone continoal refinement during the past 3 112 CLIST would cause unacceptable response time. Reinvoking years and has evolved into a flexible DSS development shell the macro code to display a hierarchy of menus proved much The shell g",Sugi-12-232 Howe Hendrick Mercier.txt
"SAS® Prototype Applications: Bringing Power to the End User Richard Roach, SAS Institute Inc., Cary, NC The following menu asks whether you want to use data you INTRODUCTION: already have or if you would like to create a new project. Existing data is used in this example. The SAS Prototype Application series from SAS Institute Inc. is designed to bring the power and flexibility of the SAS System to the end user without requiring knowledge of the SAS language. project lIanagement lIenu This is accomplished using SASjAF@ software to provide menu- Select Option _==> 1 ing capabilities and SAS/FSP® to provide full-screen data access. Other SAS products provide data analysis and data manipulation capabilities, such as Base SAS® software, SASjOR® software, SAS/ETS® software, and SAS/QC@software. The prototypes are , lIork witb an eJ[i$ting project easily changeable to more specific user needs, since they are 2 Crute a new project written in the SAS language. They run under MVS, VM/CMS, or D Description of tHs option VMS in interactive mode. R Rehrn to the Kain ""eno WHAT IS A SAS PROTOTYPE APPLICATION? It is an interactive approach to solving a business problem. The user supplies data and the prototype performs the analysis and reports results interactively. The only required user knowledge is to understand the type of problem being solved. For example, if the problem is project scheduling, the user should understand concepts of the critical path method (CPM). To guide the user in using the prototype, there are interactive help facilities at every step. The prototype has many basic capabilities, but is not meant Next is a screen that asks for the name of the data file to use. to solve a problem of any complexity. However, a SAS program- If the name is not known it can be found by selecting the ""To mer at the site can add features as needed. browse saved models ... "" option. EXAMPLE: THE OPERATIONS RESEARCH un a Saved ProJect PROTOTYPE Following is an example of how a user",Sugi-12-233 Roach.txt
"AN ENHANCED SAS/AF"" SOFTWARE CONSISTENCY ERROR CHECKING ROUTINE J. David Burks, Consultant Error Routine Objectives: What 1s the best way of controlling the output generated by a program:' The answer to this The following objectives were defined and question is simply - by controlling the input. adhered to during the development of the new Input in its simplest form consists of data and ConSistency Error Checking Routine. program parameters. Assuming the data is valid <which 1s a very great assumption 1ndeed). we then 1) Check the validity of input for each need to concentrate on insuring the validity of the user variable. program parameters. If we can insure that only 2) Check combinations of the above input valid para~ters are passed to the executable code values. by means of a para_tar' f 11 ter I we can then be Assign default values. 3) relatively sure that the output generated will also 4) Automatic continuation when all be valid. criteria has been met. 5) Allow one consistent method of execution (ENTER key). COMPONENTS OF A DATA PROCESSING SYSTEM The result obtained by keeping the above objectives in mind was an error routine which would assign default values to the variables, check for errors, and if no errors were found, would issue an EHD command. The program portion of the module would then be executed. However, if an error was detected, an alarm would sound, an error comment .... :. . EXECUTAIIlE : : FltlER co.. would be displayed, and the cursor returned to the point of the error. ,m Error Routine Structure: The basic structure of the new error routine consists of three parts. They are 1) the variable initialization loop, 2) the user variable validity check, and 3) the error CODment check. The variable initialization loop will be executed only the first tine into the module. Within the do loop are %LET statements which assign default values or a null value to each of the user variable fields and to any other macro variables used within the routine. The",Sugi-12-234 Burks.txt
"This paper describes the efforts and results of The system must contain plenty of on-line 3. writing a ful1®screen menu®driven application help. In addition to the example situation, using base SAS and SAS/AF software. The additional explanation of all inputs requir- application involves making the calculation of ed is given. References are also listed in sample sizes required in various situations such case further explanation is required. as estimation and hypothesis testing for both 4. The programs must display the result on the variables and attributes as easy as possible. same screen as the input. This would avoid The goals were minimizing the number of screens confusion as to what input parameters a user had to go through before obtaining the produced the result. result, individual help screen for each prompt with an example and reference and, finally. to A user of the program must view as few 5. have the result appear on the same screen as the screens as possible. For any application, prompts. These goals were all accomplished only two screens need to be viewed by the using commands and options available in SAS/AF user. software. Examples of the programs and various screens and III. SAS/AF PROCEDURES problems encountered using SAS/AF software are included. SYSTEM DEVELOPMENT Developing the system involved five steps: 1.",Sugi-12-235 Johnson Cirulli Bebar.txt
"AN END-USER SYSTEM FOR REPORTING USING SAS/AF ® SOFTWARE ® AND SAS/FSP SOFTWARE AS CODE GENERATORS Honda Motor Co., Inc. Lynna Yamasaki, Nar~ ~ric.n The amount of time needed to produce SUMMARY results is decreased by putting the computing power directly into the end The end-user system creates and submits ® users' hands, without sacrificing an ad hoc batch job coded in SAS software and the necessary operating information integrity_ system (JeL) statements. Run-time parameters are input by the user, who This system and others like it will help to lessen the burden on the limited never sees any code, but instead works with menus with PF key selections, input number of Info Center support personnel who are producing many ad hoc reports. screens, and when needed, help screens. Once more 'canned' systems are in place, The system, which was created using the level of support to other areas can ® ®, increase. SAS/AF and SAS/FSP was wr i tten for an OS/MVS mainframe using T50. Management's concerns are very important, but abo~e all, the user must be thought BACKGROUND I SYSTEM REQUIREMENTS of as the customer: Does the system meet My department, Service Systems, has the customers' naads? Is the system uS,er-friendly, .nd is it a valuable outlined an Info Center environment using the SAS system for the Service division resource to the user? of American Honda Motor Co., Inc. My customer for this system was the There are two categories of end-user Ser,vice Operations department, which was systems u~ing SAS software: specifically concerned with receiving reports on an ad hoc basis that would A ~canned' or 'push-button' end-user help them with warranty expense dealer system, which is menu-driven and audits. Report selection criteria would Which requires no programming change from report to report, and no one knowledge or experience of the user, in the department had ever used SAS or software, nor had anyone any familiarity with the mainframe batch environment and a 'research' s",Sugi-12-236 Yamasaki.txt
"A Codebook Template for the Creation and Use of Permanent SAS*Oatasets and Format Libraries (CMS'Appllcatlon) John podgurski Syracuse university CODEBOOK CONCEPT INTRODUCTION Recognizing the need for clients to Preparing a thoroughly labeled SAS* describe their variables and variable Dataset Format Library combination, values from the outset In concise, clear especially when there are many Engl Ish. a code book template was variables, can be time consuming. The developed for use by clients of the entry of numerous programm I ng I I nes and Research Consulting Services at Syracuse the debugging process required because University. Using a text editor. of syntax misunderstandings and typing Information on variable names. variable errors discourage the ful I use of labels. format names, and value labels documentation features within SAS. This can be systematically arranged Into a Is especially the case for relatively fl Ie according to the codebook template. Inexperienced users. Students and The code book fl Ie can be edited four faculty In need of the assistance of times to set up separate files for the consulting services at academic INPUT, LABEL, FORMAT, and PROC FORMAT Institutions are quite often SAS users statements basic to preparing a wei I with such limited experience. Many labeled SAS dataset and associated employees of business or governmental format library. organizations are also unaware of how to efficiently construct and use the A text editor macro facl I Ity or a extensive labeling features available In programming language with appropriate SAS. character string functions can be used to do the same job. In this paper a This paper presents an approach which general-use SAS program Is presented can help relative novices In SAS quickly which wi I I read the code book fl Ie and set up fur Iy documented data bases. A output program lines to CMS files In codebook template and general-use SAS proper SAS syntax. A text editor can be program to read It and crea",Sugi-12-237 Podgurski.txt
"ected areas on the screen. Panels actually permit the user to edit a SAS data set. While many approaches have been used in writing full-screen, menu-driven SAS"" systems for CMS, SHOWPAN was written for a menu-driven report system in which the users update SAS data sets by none proved completely satisfactory for our selecting different menu options and then produce purposes. Therefore, we wrote our own Display Manager: SHOWPAN. reports by making other selections. This report system, AMARS (Acquisition Management and SHOWPAN is a SAS macro which displays menus Reporting System), displays close to 200 panels and and data entry panels from within SAS using the menus. It is written entirely in SAS, except for the CMS full screen editor, XEDIT. It will work in any REXX execs and XEDIT macros used by SAS 82 or version 5 system running under CMS SHOWPAN to format the screen. The SAS macro Release 4. It was developed in an attempt to correct language is used to selectively include and execute some of the problems encountered with other other SAS code based on menu selections. display managers. These problems are: At the time AMARS was being developed, our installation was using SAS 82.3. The screens were · The data set being edited must exist prior to displaying the screen. being displayed using a SASIFSp® procedure called PROC FSEDlT. The FSEDIT procedure allows SAS · Code must be written for each screen to edit check fields and to validate responses. data sets to be edited on screen",Sugi-12-238 Fowler.txt
"Tools for Accessing SYSTEM 2000® DBMS Using SAS® Software Nancy J. Wills, SAS Institute Inc., Cary, NC Henrietta Cummings, SAS Institute Inc., Cary, NC name can be entered in the column labeled SAS NAM E, or one This tutorial provides SAS System® and SYSTEM 200Q® DBMS wilt be generated from the first eight nonblank characters of the users with the fundamental tools needed for using the interfaces SYSTEM 2000 name. The generated format can be changed by between SYSTEM 2000 and the SAS System. This tutorial is typing over it. System 2000 DBMS accepts character and text geared to experienced SAS users, who are familiar with the con- fields longer than the defined size and places the overflow portion cepts of the SYSTEM 2000 data base. in the Extended Field Table. By expanding the default format size that appears on the screen, you can extract character or text SYSTEM 2000 Data Base Management System (DBMS) is a product of SAS Institute Inc, It is a hierarchical data base that data from the Extended Field Table up to a limit of 200 characters. runs on IBM;ID CDC~ and Sperry systems. At the bottom of the screen is room for a where clause. User- defined conditions that specify criteria for selecting certain In a hierarchical data base, data records are related logically records from the data base can be entered here. The C-number into data trees. There is one record at the top of each entry and must be used in the where-clause condition. All SYSTEM 2000 usually one or more subtrees extending down. Data coming from where-clause options are supported except HAS, NOT, NON- a hierarchical structure to a SAS data set must first be flattened KEY, and SAME. out. The SAS data set will contain the flattened data. The same is true for data moving in the opposite direction; data coming from There are several restriction that apply to the selection of data. a SAS data set to a SYSTEM 2000, data base must first be flatten. Selections can be extracted from only one path. Next to the R",Sugi-12-24 Wills Cummings.txt
"DL/I Physical Data Bases, Program Views, and DL/I Calls A Data Base Description (DBD) is required to define a physical The SAS/IMS-DL/I@ software product is an interface that allows data base to the Dl/l system. The DBD is a Dl/l control block processing of DL/I data bases through use of SAS@ program- that defines the hierarchical data structure and the physical char- ming slatements under IMSfVS DB. IMS/VS DB/DC. CICSI acteristics. A data base name (DBNAME) is included in the DBD. OSfVS. CICS/DOSfVS, and DL/I DOSfVS systems. This DBname will be used for accessing the data base. A DDname for the data base is also defined in the DBD as well as This paper demonstrates how to make the interface user friendly other pertinent physical descriptions. using the SAS macro facility that is a part of the base SAS soft- ware.",Sugi-12-25 Cummings.txt
"Introduction to SAS/DB2m and SAS/SQL-Dsm Software Emily P. Wallace, SAS Institute Inc., Cary, NC For those of you who are not familiar with Database 2 or DB2 and The SOL/OS interface consists of the following procedures: Sal/Data System or SOLIDS, they are IBM's relational data base · PROe SOLEXT - extracts data from SOL/OS tables into management systems. DB2 runs under the MVS/370 or MVS/XA SAS data sets operating systems, and SOLIDS runs under the VM/SP operating · PROC SOLLOAD - creates and loads SOL/OS tables from system. Both DB2 and SOLIDS store data in tables made up of SAS data set input rows and columns and use the Structured Query Language, or · PROC SOLUTIL . updates SOLIDS tables using SAS data SOL, to access the data. set input · PROe FSEDIT interface - allows PROC FSEDIT to update SAS/DB21M and SAS/SQL-DSTM software products were devel- SOLIDS tables. oped to provide SAS® users with a way to access and analyze their DB2 and SOLIDS data using SAS software. For the past PROC DB2EXT and PROC SOLEXT execute in full-screen mode, several years, interfaces to these data base management sys- line mode, and in batch. To invoke the procedure in full-screen tems were highly requested items on our SASwar8 Ballot~ and mode, type we have also received numerous letters, phone calls, and verbal requests letting us know that you were interested in these inter- PROC DB2EXT; faces. SAS/DB2 and SAS/SOL-DS software are very similar in RUN; function and will be discussed together because of this similarity. Differences between the products will be pointed out as the spe- or cifics of the software products are presented. PROC SOLEXT; The DB2 and SOL/OS tables are similar to SAS data sets in con- RUN; cept; the rows and columns map nicely to SAS variables and observations. For that reason, interfacing the two software prod- ucts became an easier job and gave us the ability to provide addi- You then see the Data Access panel (Screen 1), which allows you to supply information",Sugi-12-26 Wallace.txt
"SAS® System to IDMS/R~ Interface Overview Nancy J. Wills, SAS Institute Inc., Cary NC This paper is designed to provide an overview of the current To access the procedure, under full-screen mode, type development being done on an interface between the SAS® Sys- tem and IDMS/R~ The paper is geared to experienced SAS users PROC IDHSEXT; who understand the concept of a data base and are familiar RUN: with IDMS/R. The first screen (Figure 1) is the Data Base Access Panel, which IDMS/R is Cullinet Software, Inc.'s data base management sys- requires information about the data base and the SAS data set. tem (DBMS). It runs under as, DOS/VSE and eMS operating sys- In the OUTPUT SAS DATA SET field you enter the SAS data tems. IDMS/R has both network and relational capabilities. The set where the extracted data are to be written. In the data bases are controlled by IDO;r- the Integrated Data Dictionary. SUBSCHEMA NAME field you enter the subschema where the record or table is defined. Use the SCHEMA NAME and SCHEMA The interface between IDMS/R and the SAS System is being VERSION NO. fields to indicate the schema and schema version developed because of the interest expressed by both SAS and that contains the subschema. Use the RECORD/TABLE NAME IDMS/R users. We have received numerous letters. phone calls, to indicate the name of the logical record, table, or view that will and verbal requests from customers. The interface was a very be accessed from the data base. In the NODENAME field you highly requested item on our SASware Ballof.ID enter the name of the node or central version that will process the program's database requests. This field is filled in if you are Let's take a look first at the network capabilities of IOMS/R. running a Distributed Database System (DDS), which is com- To begin with, let's define a set. A set is a relationship established posed of multiple central versions. between two or more record types. One record type is the owner of the set; the other(s)",Sugi-12-27 Wills.txt
"BEYOND DEFAULT COLORS: AN INTRODUCTION TO CUSTOMIZING GRAPHIC OUTPUT Janet Lasher, University of California, San Francisco presentation-quality graphic output without a thorough AI!&lm! This paper serves as an introduction to customizing understanding of all of the options of GRAPH. If you can't find an example that meets your needs, you should read through the SAS/GRAPfi® output. It covet;s the basic form of the most examples in the manual similar to the graphs you want to frequently used and flexible SAS/GRAPH statements which produce, to see how the statements are put together to create are used to manipulate the default graphic output with simple the graph. techniques readily achievable by the beginning SAS® programmer. It is assumed that you already know how to GOPTIONS Statement create default graphic output, and you are now in the position The GOPTIONS statement defines the system options to be set of trying to alter these graphs. for the SAS/GRAPH session. These options are set at the invocation of a SAS session, and remain in effect until the end of Introductign the session, unless you issue another GOPTIONS statement Not all of the options available with the statements described later in the program. The default GOPTIONS set for your below have been covered. These options cap be found in the installation can be found by running a PROC GOPTIONS. The SAS/GRAPH manual. It is my intention to explain the general form of the GOPTIONS statement is the keyword GOPTIONS form and methods of these customizing statements, not to cover followed by all the options to be set for this session: (e.g. every option available. I hope that with this introduction, you GOPTIONS N0TEXT82 DEVICE = mM3179;). These options will have the confidence and knowledge to open the are described fully in Chapter 6 of the SAS/GRAPH manual. SAS/GRAPH manual and try graphics with a minimum of Some of these options include setting the device type, the stress. As with trying to learn the SAS sys",Sugi-12-28 Lasher.txt
"PROC GREPLAY -- Developing a Presentation That Your Users Will Appreciate Nancy Palmer Roath, SAS Institute Inc The Template Facility I ntraduction The template facility in PROC GREPLAY is an excellent tool to enliven a presentation. This paper illustrates how templates are created in It seems that much emphasis is placed on full-screen mode. Templates can also be created SAS/GRAPH procedures such as GMAP, in line-mode,. but without the full screen this GCHART, and GPLOT. But an extremely useful, method can be frustrating. maybe some what underutilized procedure of SAS/GRAPH® software is PROC GREPLAY. I intend to discuss some techniques that you may To create a template in full-screen, first invoke be interested in using to prepare professional the GREPLAY procedure with the following and interesting presentations for yourself or statements; others. The followi n9 poi nts will be covered in this paper: PROC GREPLAY; RUNj organizing pictures creating templates The screen displayed is the SAS/GRAPH GREPLAY Screen. previewing presentations production presentations SAS/GRAPH CRHLAY Oevlce: IllM32793 ~~~~i8ta: ICOUTl GR.PRE$EltT ::.c:..-_-_--- Scroll: PAGE TC: c,,""p: CC, 1'1' ' ' Crtlated oescription Sel Type This paper is intended for an audience with some O~fEB87 RECMAP I RogiOn Map O~FEB87 ENlI TIlE ENO I O~fEB87 basic knowledge of SAS/GRAPH software. Beginning Slide of Boo~ BOOK I lI~FEB87 R(GMAP I Region Map O~FEB87 YBAR Of SALES FOR Nt REGION NtVOAR I lI~FEB87 (NOBACK , I backvards THE EMlI 0"" ZOOM m O~FE887 ,~ NE REGION MAP O~fE887 Annual Sale& Heating In Triangle TRI I O~FEB87 TEMPLAtE GRAPH PROOUCElI BY GREPLAY T£MrLATE I ..,,* 05FEB87 VOAR GROUP .... Organizing Pictures O~FEB87 VBARNC YOAR YEAR - NORTHCENTRAL O~FE887 VBARNE YBAR YEAR - NORTHEAST O~FEBB7 VBARS YOAR YEAR - SOUTH OllFEB87 VBARW Y,BAR YEAR - WEST A presentation may be acceptable, however, PROC GREPLAY supplies a number of features that you can use to enhance your presentation and make it more inte",Sugi-12-29 Rooth.txt
"determine which device drivers require a device token. If a device token is needed, the token is passed to GDDM via the GDDM- This tutorial is for those users who use the SAS/GRAPH@ soft~ TOKEN= option. Listed below are the most widely used device ware interface to IBM's GDDM (Graphical Data Display Manager) tokens: product. SAS/GRAPH software provides a set of device drivers that use GDDM routines to display graphics on terminals and to Token Device prOduce hardcopy graphics output on printers and plotters. This L79A3 IBM 3279 Model 3 terminal tutorial covers the following sections: L5279A1 IBM 3270 PC/G. 32 rows by 80 cols L3179G 1.",Sugi-12-30 Mincey.txt
"Network Performance and Resource Management David R. Daner Sun Company, Inc. Introduction Performance and Measurement is intended to As the Data Processing function has matured into provide and monitor consistent quality service today's Informat ion Systems or ServIces for all processing on the netw::>rk. ATI the departments, the requl rement for avai Table, major areas of classical computer performance accurate, timely information to properly manage and evaluation are covered here. These include the IS function has significantly grown. IS hardware and software avai labi 1 ity and departments have a successful history fulfilling the information needs of other reliabil ity, host service time, netw::>rk response time, end user response time, batch throughput, business areas, Accounts Payable, Inventory batch turnaround and the like. Performance and control, etc. , but have generally failed to Measurement uses these performance metrics along develop comprehensive, automated systems to with actual resource utilization data and provide the information required for IS benchmarks for capacity planning and consistency management to direct, plan, monitor, and control all aspects of their business function. rron Itor i ng ·. Network Performance and Resource Management (NPRM) is a wholly integrated collection of Financial Management plans, projects, monitors, programs, policies, procedures, and processes and controls all the cost and expense functions, to inc 1ude the obv i ous areas of budget, actual designed and to provide such i~lemented expenses, and the requi red var i ance report i ng i nformat i on. A1though not wr i t ten ent I re 1y when the two do not match. It also Includes the using the SAS System, NPRM reT ies extensively standard/factory cost subsystem. Thl s SAS ® , SAS/AF ® SAS/GRAPH ® upon subsystem is a cost accounting model that and SAS/ETS ® SAS/FSP ® , SASIIMS-DLI ® , allocates budget or expense dollars to services for data collection, data reduction, dat",Sugi-12-31 Daner.txt
"ical Data Manager (NLDM) is a software tool that collects end-user response time statistics from a Response Time Monitor (RTM). The RTM is a hardware feature that can be placed on 3274 control units and is standard on 3174 control units. Unlike some other network software tools, NLDM reported response times are measured, not calculated response times. The data collected by NLDM can be made available in several different ways. Of specific interest in this paper will be the ability of NLDM to write an SMF (type 39) record. A SAS program can be written to extract the data from the SMF record. The data can be used to identify problem areas in the network, to report response time 'information to management or users and to set end-user response time objectives. . KEYBD - When the user's terminal Introduction keyboard is unlocked. Network Logical Data Manager (NLDM), now part NLDM collects the response time data from of Netview, is an IBM program product. It requires Network Communication Control the control units by-the issuing of a 'COLLECT' command or at session Facility (NCCF) and Virtual Storage Access Method (VSAM) as prerequisites. NLDM runs as termination. By taking advantage of NCCF services it is possible to issue the an application program under NCCF and can COLLECT command automatically using an collect and display three types of session NCCF timer-initiated CLIST. We found it data for System Network Architecture (SNA) environments: desirable to collect the response time",Sugi-12-32 Yount.txt
"Profiling User Group Activity With SAS® Software H. Pat Artis Morino Associates Vienna, VA 22180 the user's daily activities. The reader should note that this same 1.0 Introduction technique could be used to quantify activity at other levels of One of the most common requests made to CPE analysts respon~ granularity like hourly, weekly, or monthly observations, sible for performance reporting by their management is to develop As a measure of a significant difference, the standard deviation report formats that highlight or easily identify significant changes that occur in an environment. For the performance analyst to provides an adaptive measure that allows us to quantify change. To accomplish this objective, one need only calculate the Z- understand tlie managers motivation for asking for such reports, it statistic for the observation to be evaluated. Simply described, a is important to remember that the one of the most basic concepts Z-statistic is a measure of how many important differences a of management is the by control and understanding changes. measure is larger or smaller than the mean of the population form which it was selected, The Z-statistic is calculated: Unfortunately, the development of such reports is not a trivial task. To quantify and identify changes, the analyst must first determine XCi) -X what magnitude of variance of a given measurement is a sign of a Z(i) significant change, and second present the information in a form s that is easily understood by the recipient of the report, One other results of the Z-transformation is that the range of In this paper, we will examine a graphical reporting tool that is Z-statistics Over which Z can be expected to vary is well under- based on the use of the Z-statistic to address these management stood. For most cases (i.e., 99%+ of all observations), the result- reporting requirements. The quantification of the activity of TSO ing Z~statistics can be expected to range between -3.5 and + 3.5. user groups",Sugi-12-33 Artis.txt
"Unfortunately, in each reporting period the sum of the perform groups' CPU from TYPE72 This paper summarizes a method to records will always be less than the develop capture ratios. The following system CPU from the TYPE70 records. topics are included: the or191n and reason for capture ratios; gathering RMF captures the total system CPU busy and clustering data; calculating for each time interval. RMF does not capture ratios with PROC NLIN; and capture all of the CPU busy at the using capture ratios. perform group level. A capture ratio is an expression of the percent of the CPU that RMF does capture at the Introduction perform group level. Because circumstances continually change, What do you do when the sum of your capture ratios continually change. applications' CPU usage is greater than 100% of your CPU capacity? At my The difference between RMF TYPE70 and site, where I am the Computer the sum of RMF TYPE72 records in each Performance Evaluator, we decided it reporting period is system overhead. was time to revise our capture ratios. System overhead is the amount of MVS As you probably know, a capture ratio work not specifically attributed to a is the percent of each perform group's perform group by RMF in TYPE72 CPU that the Resource Management records. However, most MVS system Facility collects in TYPE72 records. overhead is done on behalf of some perform group. The problem in my shop was that the sum of the RMF TYPE72 records adjusted The amount of system overhead in",Sugi-12-34 Chapman.txt
"A step reading and manipulating model ABSTRACT results to be input into SAS/G RAPH procedures This paper discusses the effort and co m pletion of generating graphical output quantifying the performance impact of specific fourth generation languages on OST's CICS systems as well as Finally, we discussed analytical modeling and its informing management of the potential resource resuli:s with key personnel responsible for providing shortage to support these syste rns at reliable and co m puter syste ms. resources to these CIC S consistent service levels of response tim e. Emphasis is preliminary remarks on analytical modeling were placed on performance tuning and design introduced to set the proper role of the developed improvements enhancing good performance as a model in the capacity planning process and to establish re m edy to the im minent threat to providing these the appropriate interpretation of its results. services. Rationale, methodology, and results are Afterwards, a more detailed discussion on the The primary tools are queueing theory, included. graphical resuli:s was presented. Graphical output prohahilfty, numerical methods, the base SAS® included bar charts outlining components of average software, and the SAS/G RAP H® system. transaction response time for varying Cles rates. Cartesian plots of response time distribution curves indicating thresholds for CIC S loads were also BACKGROUND provided. With increasing use of 4th generation languages in new applications",Sugi-12-35 Paynter Wood.txt
"library (optional), loaded th,e HELP library (optional), and loaded the SAMPLE library (optional). In Step 5 you are directed to install When you install the SAS® System under OS, you must set many 0: Do this before completing Part I. the SAS SVC Routine system options and choose several installation options. This paper discusses the implications of these choices and suggests Creating the SAS.CNTL Data Set and Tailoring the JCL some tuning techniques that could be used at your site. The paper a!so addresses some common problems encountered by IEBGENER: Enter the IEBGENER job which is listed on cover Installation representatives over the past year. letter. Submit this job to download the SASUPDTE job from the tape to any data set of your choice.",Sugi-12-36 Brinsfield.txt
"Tuning the SAS® System under eMS Daniel J. Squillace, SAS Institute Inc"" Cary, N.C. Nonshared segments You can also elect to install the nonshar- OBJECTIVES able portions of the SAS System in saved segments. There are no re~1 memory savings to be had by doing this, but there could The objectives of this paper are to acquaint you with the SAS sys- be significant 110 savings. Also, depending on how your billing tem options that significantly affect performance in the VM/SP algorithms work, users may incur lower charges when running eMS environment and with other external tuning considerations. with nonshared saved segments. Your choice of option settings and tuning decisions can substan- tially affect the resource requirements required to run SAS pro- grams. Topics we will cover include Load Library Management Considerations · program management considerations BLDLTABLE option When looking for a program or format, the SAS System 1/0 considerations · SAS system searches (1) saved segments, _(2) load module · macro processing options libraries, (3) text files, (4) text libraries and finally, (5) module files. · other SAS system options Even with full implementation of saved segments, there can still be a considerable amount of search activity against library direc~ · sort considerations · PL/I ISASIZE. tories on the system disk. The BLDLTABLE option reduces this search activity by maintaining a table of program names and loca~ tions on an LRU basis. When the option was implemented on the PROGRAM MANAGEMENT CONSIDERATIONS Institute's production SAS system, 110 to the SAS system disk was reduCf;!d by about one~third. The table size is 32 entries. Program management is a very important tuning area within the Consolidated load library As shipped, each SAS software SAS' system under eMS. There are a several things you can do product resides in a separate library on the SAS system disk. You with saved segment implementation and load library manage~ can re:duce directory sea~",Sugi-12-37 Squillace.txt
"Performance and Feature Enhancements in VMS SAS 5.16 Tom Cole, SAS InS,titute Inc .· Cary NC Introduction 1.3 What's Special About SAS Release 5.16? This paper is an overview of the cu~rent This paper describes Release 5.16 in some performance and features of the SAS product under the detail, and covers both feature and performance VAX/VMS operating system. Many performance enhancements to the product. There have been improvements, enhanced features, and new samples have eKtensive re ... rites of some major subsystems which been incorporated in the newest release of the SAS provide significant improvements for most SAS users. System under VMS. This ne ... release of the SAS System incorporates additional support for ne ... VAX processors such as the ne ... 8000 series processors and MicroVAX-based systems. It also has the capability of licensing a single copy 1.1 Product History of SAS software to run on a multi-cpu cluster using a shared disk. The SAS System has seen a steady progression of improvements in its performance and capabilities on SAS Release 5.16 is the first version of the minicomputers since the inception of its development SAS System under VMS with the new CPE ToolKit. This over five years ago. first release of the ToolKit consists of a collection Early releases concentrated on bringing most of of SAS programs, user written functions and formats, the functionality and ""feel"" of the SAS System to and VMS batCh jobs for collecting and organizing VMS minicomputers. Emphasis was on creating a framework performance data using VMS data gathering utilities. The CPE ToolKit is provided in subdirectories of the in which additional features and products could be SAS sample library. added at a later date. Performance was a concern but it was not the main priority during the first releases of the SAS System. The user community began to use these versions 1.4 Summary of Features Performance Ne. and of the SAS System for Minicomputers and provided the Enhancement",Sugi-12-38 Cole.txt
"MVS SECURITY AND THE USE OF SAS* SOFTWARE TO GATHER SMF DATA Bruce Blank, Empire Blue Cross & Blue Shield Michael Mirabile, First Boston Corporation' hi a result,' MVS system serurity with the lN1ROOOCI'IDN use of Software to r...n- SAS"" h~ With the increasing cx:mp1exity of data vulnerabilities, should receive a 1wel of management attenticn. processing equipnent, progrBIIB and operating systens, assurances and verifications of the In h~l~liI>g IBM philOSOIi""'Y, there are MVS system oomponents are rO\1tlnely neoessary. swen _ys to implement a total security The purpose of this document is to identify package that can po:-otect systems and data; and h~l~t the ilIlportsnt MVS system's they are: security aspects. This peper does not serve Item 1/1: Risk Analysis and kceptance as a ''cure all"" for sewrity breames by any means, but rather as an in:formtive lock_ at n.termlning >!:tich data and data processing the internal romponents of MVS and where equipment .... t/ abould be protected and heM. security breaches ,can result. SJS* Software is the tool that can be utilized to review many of the aspects relating to. assurance and Item 1/2: Serurity Policies and Practioes review of the system security MVS oomponents. l!dditicnel1y, (System n.fining >!:tere in the organizational 00' Management l'llcility) provides the IIBjar inl""t structure the responsibility for security to our SA'l* Software rode fur assunnce and lies and developing a serurity policy, with guidelines, instructions, and recommendaticns review purposes, since 00' collects and rerorda a wide variety of related infurIIBticn. for implementing such a policy. '''!be protecticn of data against persros Item 1/3: Physical Security deliberate or accidental access by Selecting serure sites fur data processing unauthorized peraons is rapidly becx:ming a IIBjar preb1em. ULtiIIBte1y, the security of equipment/systen, controlling jhysical acoess data dependa en some ronblnation of lod<s, or to the system, and planning fu",Sugi-12-39 Blank Mirabile.txt
"COMPUTER CENTER CHARGEBACK USING 'SAS' AND MICS Jeanne Buse. SOFTWRIGHT Summary Number- of accesses to the data (e.g. EXCPs, tape mounts). This paper is an overview of the process of billing customers or users of shared Data Processing facili- ties for the resources they consume. It concen- Usage of a teleprocessing system such as IMS trates on usage based, flat-rate billing systems or CICS3 (e.g. transactions entered). where customers' charges are calculated by multi- plying the amount of resources they used by the Numbers of terminal or PCs in IIser areas. annual billing rate for the resource. Volume of traffic over teleprocessing net- This paper starts by reviewing the major billing works (e.g. transmissions, bytes transmitted. functions. Then it shifts to the specific task of gathering usage statif>t.iCB for mainframe resources There are several methods by wbicb the costs of using IBM's! SMF records as a prototypal case. It shared facilities can be apportioned to the various discusses the steps required to process SMF records users of the facilities. The method discussed in and identifies the associated problems and solutions. this paper is usage based. The customer is billed It shows how the SAS system solves many of these for the amount of use made of a specific resource, for example, the number of lines printed. other problems by itself. Also it shows how the HIes methods such as billing on a fixed percentage, or Accounting Component of Morino Associates Inc. of billing based on a user statistic (e.g. number of Vienna, Virginia uses the SAS software to solve the remaining problems and to provide a full featured cars sold) will not be addressed. billing system. In addition, the paper will limit itself to flat rate These are systems where the MIes is of interest to SAS system users because it billing systems. billing rate for a resource is set for some long is a large scale, vendor supplied system written period of time, typically a year, and user charge- almo",Sugi-12-40 Buse.txt
"A Menu-driven CPE Reporting System (CPE Starter Set) R.A.Russell, SAS Institute GmbH, Heidelberg, W.Germany 1. INTRODUCTION (BUILDPDB). The BUILDPDB job is This paper describes an described in Ref 1. and can be treated as separate from this application, written using the Base application. The PDB contains a SAS(*) System along with SASjAF(*) software and SASjGRAPH(*) software. number of datasets, these are :- The application attempts to provide RMFINTRV - Resource utilisation a reasonable starting point for and workload users who wish to use the SAS System JOBS - TSO,STC and Job statistics for evaluation of computer Performance data, specifically STEPS - Step level statistics evaluation of SMF and RMF data IPLS - One record for each IPL of produced by IBM's MVS operating the system system. The application (normally called The CPE Starter Set allows for the CPE Starter Set) does not analysis of each of these datasets. attempt to teach the user concepts of Computer Performance Evaluation (CPE) but is directed more at the It would be a fairly simple user who understands what indicators matter to adapt the CPE Starter Set may be important for the system in to accept data from a source other than the MXG PDB. The only question and allows him to produce a variety of reports without having to dependencies are in a few places get involved in coding SAS where explicit SAS dataset names are statements. A secondary goal is to expected. provide example code which the user can modify to suit his own needs. 3. SOME DESIGN CONSIDERATIONS It is expected that after a few sessions using the CPE Starter Set A major problem encountered when the user will begin to modify the conducting performance analysis is application and to steal techniques the large number of different from the application to integrate indicators available. In the into his own systems. RMFINTRV dataset of the PDB there are some 118 different variables. 2. TOOLS USED AND DATA SOURCES The 8 characters of the SAS var",Sugi-12-41 Russell.txt
"ND AttRIBUTES I VARIABLE TYPE LENGTH POSITION FORMAT 3 CITY CW 20 15. 30 SYSTEM 2000 Data Management Software excels in the produc- 3.1 4. 15 COOl!: CHAR tion data processing world, of entry, retrieval, integrated applica- so 5 COHPANY CW 53 ... tions development, and data management. The- SAS System 591 27 31 DOCK CHA' offers tremendous versatility in data extraction, analysis, and pre- 32 CW 23 OS ... '"" 24 DSADDJi 1 CHA' 32 sentation. The complementary nature of these two SAS Institute 25 DSADDR2 CW 32 product lines is exemplified through day-ta-day management .96 32 26 DSADDR3 CW activities of Garcia Truck Leasing Company officials. Some mar- 32 528 27 DSADDR4 CHA' .,. keting and accounting problems are addressed by company man- , 560 28 DSPHOHE CHA' "" agers with the aid of these software products. ' 14 ~XPlRES 333 DATE7,. '""'' · 16 fIRSTYR 345 8.2 32 8 IIfVADDJi 1 CHAR 155.32. Gerry Garcia started Garcia Truck Lessing Company in 1977. He 9 IlfVADDR2 CHAR 32 187 32. specializes in medium-sized trucks (10 to 22 feet in length) that 219 32. 10 IIfVADDRJ CHAR 32 pull trailers. The home office is in New York. The business has 11 IlfVADDR4 CH.l.R 32 251 32. grown into a nationwide enterprise with offices in five regions. 32 12 IlfVADDR5 CHAR 283 32. The company grosses about $9.~ million annually and is working """""" 20 IIfVAKT 370 COKlL\I2.2 """""" 1 INVDAT2 4 DATE1. hard to enhance its return on a considerable.investment in trucks 13 IIfVPROHE CHAR 315 18. "" and service centers.",Sugi-12-42 Senger.txt
"ELOAD This paper briefly discusses Release 11.5 of REORGANIZE *RESET ROLLBACK AFTER SYSTEM 2000r DBMS for I BM mainframes operating under as and eMS environments. The *RESTORE *SAVE DATA BASE ON topics covered include user- requested *SUSPEND enhancements that were implemented in part due to recent SASware BalloW results, Genius enhancements that affect the interactive report generator, and operating system specific Using the DBA Password in PLEX Programs enhancements. Even though you can use a DBA password in a USER-REQUESTED ENHANCEMENTS PlEX program, the master password holder must use the SCF to assign the password and to DBA (Data Base Administrator) Password authorize its commands. The commands with asterisks in the preceding list are the PLEX Release 11.5 introduces the DBA password which, like the master password, performs data commands that DBA password holders can issue if they have the authority. base administrator functions in PlEX (Programming Language EXtension) and the SCF (Self-Contained Facility). Unlike the master Even if the master password holder has not given password, -the OBA password cannot access any data in the data base. The following SCp the DBA password holder the authority to issue commands, which can be issued only by the any of the commands listed above, the OBA password holder can issue the following PLEX master password holder, have been added to implement this enhancement. commands. START S2K COMMBLOCK Command Function STOP S2K SUBSCHEMA REC",Sugi-12-43 Rakes.txt
"Interfacing SYSTEM 2000· DBMS with Fourth Generation Languages Gary A. Egan Gel Systems Inc. In this paper, a Fifth Generation Whac is SYSTEM 20001 Language is defined to be a software SYSTEM 20000 is the Data Base Management product that is able to ""learn n using Artificial Intelligence techniques. The System (DBMS) marketed by SAS Institute language develop~r need not code for all Inc. It has been in existence since the possibilities because the 5GL system is early 1970·s. As with all DBMS, SYSTEM able to expand its knowledge and store 2000 contains a number of separate it for future reference. components. Included in these components are a query language (Quest), In order to ""learn"", the 5GL interacts a report wri ter and a procedural with the user. If the users asks a language interface (PLEX). question that contains words or syntax not already known to the 5GL, the 5GL will prompt the user with a question or What is a Fourth Generation Language? series of questions to attempt to understand what it is that the user A Fourth Generation Language (-4GL) is a desires. When the 5GL ""understands"" software product that is meant to the new words or syntax, this knowledge replace the procedural languages used in is recorded in its ""knowledge bank"" for writing programs and developing systems. future use. Some examples of procedural languages are COBOL, FORTRAN, C and PL/l. Why develop a 4GL/5GL Interface? Every 4GL has its own language syntax An obvious question is why bother to which must be learned to use the 4GL. design and develop an interface between SYSTEM 2000 and other software products There are tWO major classifications of such as a 4GL or a 5GL. 4GL. The first type actually generates a procedural language program. This SYSTEM 2000 is an excellent DBMS and is generated program is then compiled. used in hundreds of companies world- However, all changes to the program must wide. Thousands of data bases have been be made via the 4GL and a new program bUilt and tho",Sugi-12-44 Egan.txt
"ures of the QUEST and Report Writer languages. It operates as an interactive -dialogue between a terminal user and a SYSTEM The Genius Report Writer system is one of the 2000 data base. The result of this dialogue is a retrieval languages available for the SYSTEM Report Writer program that can be run 200()® Data Base Management System. This paper immediately or saved for future or repeated use. gives in-depth description of the Genius system Typical Genius reports are columnar, but Genius and an overview of the various retrieval can be used to produce special forms output such languages. as mailing labels. SYSTEM 2000 DBMS offers a number of access When you invoke the Genius system, you are methods. For retrieval purposes, there are four prompted to supply report specifications. These different interactive languages: QUEST, Report include page headings (up to eight lines), column Writer, QueXTM software, and Genius. contents, column headings, and subtotals. The first section of the Genius dialogue is the Pa rameter Change Section. SYSTEM 2000 DBMS offers an English-like query Parameters include language called QUEST. With QUEST, you can issue one-line commands such as DESeRI BE to page width and length view the data base definition or schema. The TALLY command shows frequency distributions. maximum number of digits for counters and The PRINT command will display data values from accumulators selected records and can be used to· do calculations (+, -, *, j) and system function",Sugi-12-45 Rakes.txt
"SAS® System Interfaces to Data Base Management Systems Emily P. Wallace, SAS Institute Inc., Cary, NC The following example updates the same IMS data base to In order to extend the analytical, reporting, and graphics capabili- ties of SAS® software to users whose data are stored in Data change phone numbers of current customers. Base Management Systems (DBMS), SAS Institute has devel~ DATA_NULL; oped interfaces to some of the major DBMSs. The products cur- SET NEW. PHONE; rently available are SAS/IMS-DL/I@ software for access to DL/I LENGTH SSA 1 $40; data bases, the SYSTEM 2000® DBMS interface procedures to access System 2000 data bases, SASjDB2TM software for access DBNAME~DB CALL~FUNC to DB2 tables and SAS/SOl/-DS'"" software for access to INFILE ACCTUPDT DLI SSA~SSA1 STATUS~STAT; SOL/OS tables. Currently under development is an interface to DB~'ACCOUNT '; IDMS/R data bases. .; FUNC~·GHU SSA1~·CUSTOMER(SSNUMBER ~·IICUSTNO II·) .; SAS/IMS-DL/I software runs under the MVS/370. MVS/XA. VS1. and VSE operating systems. You can read and update DL/I data INPUT; bases using either IMS/VS or CICS/VS. Under MVS, the access IF _ERROR_ THEN ABORT ABEND; can be batch DL/I, IMS/VS Batch Message Processing (BMP). or CICS/VS Shared DL/1. Under VSE you can access the DL/I FILE ACCTUPDT DLI; data bases in batch or through CICSjVS Multiple Partition Sup- FUNC~·REPL·; port (MPS). The type of execution is controlled by the value of ; SSA1~· the DLiRGNTP option set on the OPTIONS statement. The DLiRGNTP option defaults to DLI if it is not specified. PUT _INFILE- @; There are two methods of accessing Dljl data using SAS soft- PUT @172 NEWHPHON; IF _ERROR_ THEN ABORT ABEND; ware. They are the DATA step interface and the DLiTEST proce- dure. The DATA step interface allows users to read and update DLjl data bases using the INFILE and FILE statements. The For users who want to manipulate their data interactively, there INFILE statement has options that may be used to define the is PROC DLi",Sugi-12-46 Wallace.txt
"SAS(r) SOFTWARE DATASETS FROM NOMAD2(r) John M. Rinehart RMC Environmental Services include water chemistry and physical data from Ahstract grab and continuous sampling, in addition to collections of phytoplankton, zooplankton, and This paper discusses the use of SAS( r) benthic macroinvertebrates. We also maintain a Software in' a research environment for the record of daily river flow and temperature data analysis of' data stored in NOMAD2(r) databases. from 1928, and since 1980 we have kept a log of The rationale for segregating data storage and the hydroelectric plant water release schedules. data analysis Is presented, along with an outline of the process of transferring data from Clearly, implementation of an historical a NOMAD2 database to a SAS dataset. NOMAD2 research database of this size and scope demands procedural code Is provided which largely a lot from a computer data system. Data automates this process, making aqy permanent or capaci ty and processing speed are important created NOMAD2 database segment readily considerations. Additionally, the nature of available as a SAS dataset. most environmental research imposes several important requirEllDents on the data system: that it handle hierarchical data structures, that it The research data peoressing environment have relational capabilities for data retrieval, and that it be sufficiently flexible to adapt to RMC Environmental Services 1s a private the evo! ving research programs. environmental consulting firm providing study design, data collection, data processing, Much environmental research data seems to analytical and interpretive services for be inherently hierarchical, with information environmental research and mOnitoring programs. recorded at several levels of increasing detail. One of our major clients for the past two We might begin, for example, with a fisheries decades has been Philadelphia Electric Company ""collection,"" using several scalar values to (PECo). RMC bas conducted environment",Sugi-12-47 Rinehart.txt
"A SAS/AF"" SOFTWARE INTERFACE TO CONVERSIONS BETWEEN FOCUS+ AND SAS"" SOFTWARE UNDER CMS Charles F. Sprague, Pacific Bell Dale C. Peters, Independent Consultant OVERLORD. A representation of the main menu This paper describes a utility to convert for the OVERLORD system is shown in Table 2. between FOCUS and SAS data bases using a SAS/AF interface and eMS EXEC2 programs. Option 1 distributes the programs that users must have on their accounts to invoke an We first explain the rationale behind our application. For our conversion utility, this facility and how we expect our clients at consists of a single CMS EXEC2 program called Pacific to use it most. Next, we describe some of the more interesting features of the FOCUSSAS. The application manager has the interface, including a companion SAS/AF system choice of distributing software to either that distributes updates of the utility and individual user accounts or all existing keeps track of its usage by clients. Lastly, accounts on a particular machine, for example. we describe some of the enhancements we expect to provide updates of programs. to introduce in the near future. Option 2 distributes the additional programs Rationale for the Interface required to run an application to master accounts on each machine. The software ~n We work in a division of Pacific Bell concerned these master accounts is accessed by users on with managing information and systems for the a particular machine when they execute an Marketing Department. Specifically, our district application. FOCUSSAS, for example, requires functions as an ""information center."" Our one additional EXEC2 program to check users' responsibilities include guiding clients to virtual storage. a SAS program to invoke appropriate data bases; building small-scale PROC DISPLAY. the appropriate SAS/AF catalog, software applications. and; lending subject a library of SAS macro programs, and a SAS/AF matter expertise, for example, statistical function key profile. interpre",Sugi-12-48 Sprague Peters.txt
"SYSTEM 20000 Data Management Services and the SAS® Macro Language Mike Killam SAS Institute Inc. Cary, NC INTRODUCTION Using component numbers is much easier than component names if you can remember them. SYSTEM 2000 (R) Data Management software The correct component names, numbers, and a adds the powe,r of a fully funcbonal data base wealth of additional information are available by entering a DESCRI BE command. management system to the software offerings of SAS Institute. Some of the features provided by Although the command allows for specifying a SYSTEM 2000 are hierarchical data structure, indexed retrellial$, eaceUeM 3GL jnterfaces compon.ent number or a range of component AS~l.£R'. fttAiIbers) t au often unsure of the correct FORTRAN. PUt and (COBOL, tlpdate _Iti-threaded 8C(;Sla, eotfJPOft$l1' number or of valid range values. fRult'i-user The output from a DESCRI BE command without automatic rollback aAd recovery, aft ar:countift9 any operands (in the case of the EMPLOYEE log, and an interface to CICS. data base) lists information on 48 items and 10 records. It would help to see a nicely The'se and other features compliment the SAS formatted list of item component names and System's data management, report writing, numbers. statistical, and graphics capabilities. As I began to master the syntax, I became more But the introduction of SYSTEM 2000 software bold. Sooner or later it was bound to happen. brings with it new concepts, terminology, I entered the following; syntax, and procedures. What follows is a description of a set of SAS macros that assist the SAS user who wants to use SYSTEM 2000 pr /namej c3,c2,c6,clOl,cl02,c1l1,c1l2,c121.c203 wh c2 eq GIBSON, Data Management Software. I got the follQwing response: A CASE STUDY - Confessions of a frustrated end user -326- ACTION-Ct.AUSE COMPONENT'S MUST BE IN ONE PATH Since the C following all the dots was under the I began using SYSTEM 2000 in July of 1985. C2 item number, I thought maybe there was As a Sales",Sugi-12-49 Killam.txt
"ur site. The linkage editor, and know how to invoke it at The SAS(£) System allows users to write programs in your site. third generation languages (PL/I, C). These programs are interfaced to the SAS supervisor and operate using The PLEX precompiler, and know how to invoke the same familiar SAS syntax. it at your site. The SAS System to SYSTEM 2000® DBMS interface The SAS Programmers Ouidefor PL/J, Version 5 Edition. procedures are general purpose tools that serve it wide · The user-written procedure modules, and source variety of uses. However, they may not be suitable for samples. These are (l,vailable on the SAS inst.alla- some situations. Recovery and error checking are impor- tion tape, but are often not insta,llecl '""on-line."" tant in ma.ny update situations. Some free time! vVe consider a. program tJUtt must update the employee da.ta base from informa.tion supplied a.~ a SAS data. set. The program itself is quite simple: it updates the em- Benefits ployee record) based on the employee number. However, o it does illustrate all the points thaJ. need addressing when writing a user-written procedure. \Vhy go to the trouble of writing a program as a SAS All you need to lmow about writing user written pro- proced llre? cedures is documented in SAS Programmers Ouide for PL/1, Version 5 Edition. The synt.a.x will be familiar to existing SAS users, a.nd the PROe that you \vrite will be capable of exchangiJlg information with an other SAS proce- Outline dures. The SAS Display Ma",Sugi-12-50 Kent.txt
"the work produced by the Research and This paper describes the Development Departmen_t is done using application of PROC FSEDIT in SAS/FSP SAS products on a mainframe computer. and Base SAS by an intermediate size health insurance company. The need BLUE SHIELD DATA ENTRY AND CLAIMS for the application arises when our PROCESSING SYSTEMS - - - - - data processing company's production computer is down. During these The Blue Shield data entry system periods our data entry operators are is made up of approximately 30 data idle, claims become backed up and entry operators entering claims on a substantial costs are incurred. system which is owned and operated by private data processing company. The Wi th the acquisition of a new data entry operators key in the claims computer system in our Research and at a rate of 45 claims per hour. The Development Department we decided to claims information is transferred to set up a claims entry backup system to the data processing company's main be used when the production computer office located in Albany New York {150 is down. PROC FESEDIT provided· the miles} via telecommunications lines. flexiblity to replicate screens with over 200 entry items and edit capacity When the data processing company to minimize data entry errOrs. receives the claims information it processes the claims and writes the The paper wi 11 examine the payment checks. The claims development and implementation of the information is then turned over to project from screen creation to Blue Cross and Blue Shield for production of raw data files which are research and analysis purposes. integrated back into production. Problems arise when the data",Sugi-12-51 McCabe.txt
"UTILIZATION OF SASe SOF'lWARE TO SOLVE TRANSPORTATION PROBLEMS Jack Hudson, Jr., The Coca-Cola Company Ginner Weatherby, Weatherby Hudson Associates three products marketed will be INTRODUCTION produced in one location. The transportation moving example products include 12 ounce A problem, cans, 2 liter one-way bottles, and 16 products from a series of supply points to a series of demand points, ounce one-way bottles. These goods will be designated products 1, 2, and presents an excellent opportunity to 3 respectfully. The empty packaging utilize linear programming materials are named X for product 1, methodology and in particular the SAS system itself. In general terms, Y for 2, and Z for 3. Table II illustrates the demand of finished this problem has a special graph goods by the seven facilities. Table structure that allows for III shows where supplies of these six considerable simplification of the products will be available. solution process. This trait will be ignored here because in many real world problems this special structure TABLE I Mileage Matrix is lost from the necessary inclusion r t, City of complex constraints. Also, it is !l. 11. ~ £ Q the purpose of this paper to find a A 0 workable solution procedure to the 290 190 450 475 650 325 problem using SAS/Lp®. Sophis icated 0 290 150 180 350 400 5 B software such as SAS/LP can C 640 0 440 460 500 significantly decrease the need of D 0 220 80 480 such a special structure. The 260 490 E 0 obj ecti ve of the problem will be to 0 700 F minimize the systemwide over-the-road 0 G transport miles incurred from supplying demand while staying within eXisting physical constraints. TABLE II Demand for Finished Goods (In Truckloads) The constraints utilized in the solution of this problem will deal Product with the following areas: 1 1 £ City 1) Supplying demand for finished A 25000 15000 10000 goods at Distribution Centers. 6000 8000 B 6000 C 10800 1800 5400 2) Allowing necessary amounts of D 9900 9900 10200 raw m",Sugi-12-52 Hudson Weatherby.txt
"presents a transportation problem and we can use ""network theoryll to solve it. The The purpose of the telephone ~llocation problem consists of transmitting telephone process, an important part of corporate traffic (in circuits) through all branches' planning processes, is to outline the (the available facilities) of the network facilities needed to accommodate Teleglobe's as' efficiently as possible. In our case, traffic efficiently fOr the next 15 years the demand for eaoh country is known and in order to optimize use of available IIfixed"" for the next 15 years. facilities under prevailing traffic condi- tions. This paper describes the develop- A network is defined as a series of nodes ment of a general model for a network with arcs or lines connecting each node. linking Canada and a foreign country, and In our telecommunications network, .nodes applies the TNETFLOW procedure from SAS/OR represent Canadian and foreign countries, when flow through arcs of a network have to Canadian and foreign gateways and stations, obey some additional linear constraints. as well as launching and landing points for submarine cables. Arcs, also called Wi th the",Sugi-12-53 Therrien.txt
"A SAS/ETS® SOFTWARE FORECASTING AND INVENTORY PLANNING SYSTEM Patrick Cardamone. Jersey Central Power & Light Company David Brauer, Jersey Central Power & Light Company Introduction Jersey Central Power & Light Company procures, Exhibit I is a sample of the System's planning sheet. The forecasting segment detail on the stocks and distributes' over 3000 items for trans- planning sheet consists of four lines; two lines mission and distribution work in a 3256 square (FORECAST and PLANNED) for the previous 12 mile area providing service for 787,000 custom- months of history and two lines for 12 months ers. Material is procured from a central loca- ahead. FORECAST represents the results of time tion, delivered by suppliers to two service area warehouses. and ultimately distributed to several series models. while PLANNED is input as a dis- crete known quantity. The aggregate FORECAST outlying locations. This effort requires exten- and PLANNED quantities determine gross item re- sive planning and logistical support to ensure that adequate inventory levels are maintained to quirements. Each item is assumed to be indepen- dent, henceforth, forecasting models for every satisfy demand at the least possible cost. In item must be selected. order to aid in achieving these desired objec- tives, a detailed forecasting and inventory plan- In order to evaluate and select models with ac- ning system was developed using SAS/ETS and base ceptable performance, test items representative SAS 1$ software. of a common group were chosen for model testing This paper presents the development and method- and evaluation. The test group included a cross section of transmission and distribution mater- Ology applied in designing the forecasting and ials chosen on the basis of dollar value, usage. inventory planning systems. The planning logic, and volume. The test group contained 30 items including the selection of various forecasting models, and the dynamics of the system with re- consisting of ma",Sugi-12-54 Cardamone Brauer.txt
"THE BAYESIAN ESTIMATION OF LINEAR MODELS, AN APPLICATION OF THE LINDLEY-SMITH HYPERPARAMETER MODEL par amet er Mode 1 . One area of growing interest is in use of Baye- sian Models for the analysis of panel data. It To define the hyper parameter model we propose is frequently .the case that an investigator is the specification: primarily interested in the values of parameters - N(O ,2 1 for an ind! vidual data set but would also like £i t n '1 i to incorporate information available from the 1,··· ,n ) (t .. set of microuni ts of observations. One method i that has been proposed is the empirical Bayes N(O, 0 u- method as implemented by Rubin (1980) based on i the hyper parameter model proposed by Lindley and Smith (1972). ! '"" 1, ··· ,K, n .'"" no. of observations in set i, i Y """" n x vector of dependent variables, The present paper describes a program called i i LSHYPER which is designed to estimate the \ niX p matrix of independent variables. Lindley-Smith hyper parameter model employing the 1 EM algorithm that Rubin proposed. We can form the moments of 8 from the posterior i distribution of 8 when we have a prior location In a general setting. we investigate the s1 tua- i tion in which a series of observations have been 8 and corresponding covariance E: made on related micro phenomena. In the case of Rubin's (1980) paper it was the first year grade point average of law students as a function of X!X. )-1 11 scores on the Law School Aptitude Test and their L- 1 8) undergraduate grade-point averages. These rela- tionships were to be estimated from data avail- able over a panel of law schools. Rubin pro- posed an empirical Bayes estimator which is formed as a combination of the regression coef- ficients from the individual law schools. The equation for Y can be written as: i . The LSHYPER program is designed to combine the Y. X.B X.u. + + £i' parameter estimates from a number of related 1 1 11 - N(O'Oi)' regressions which contain the same underlying x.8 Y. or n, + ni p",Sugi-12-55 Hirschberg Aigner.txt
"has no practical use. It can be seen that the problem is NP-hard «3) or (6» meaning that it is unlikely that a poly- The paper describes the SAS tools to nomially bounded exact algorithm exists. solve the Traveling Salesman Problem That threshold in the macros of this pa- (TSP) numerically and to present the per is ten cities. For more than ten solution in graphical form. The paper cities, some kind of approximation is consists of two main sections: needed. The literature of the TSP ap- 1. Defines the problem and describes the proximations is very broad, (1) provides possible methods of the solution. In- a good survey of the different methods. troduces three SAS macros that yield the numerical solution of TSP. The Usually the following fundamental meth- solution is either exact or approxi- ods are distinguished: mate depending upon the number of 1: Tour building (starts with a city and cities. Illustrates an interesting the other cities are succesively in- programming technique using the DATA cluded until a tour is reached), step. 2: Tour-to-tour improvement (starts with 2. Presents some SAS graphic macros that an initial tour which is improved by generate the graphical solution of replacing some of its edges), TSP. The graphic macros introduced 3: Subtour elimination (an assignment here are more general. They draw the problem is solved and then its sub- tour of the specified cities on the tours are eliminated until a tour is US map along with the names of the obtained) . cities. The tour can be polygon-type or ""hub & spoke""- type tour. There are many realizations of these fundamental methods, even the combina- tions of them. E.g. the ""Composite meth-",Sugi-12-56 Felsovalyi Felsovalyi.txt
"TIME SERIES INTERVENTION ANALYSIS USING SAS® SOFTWARE Terry .J. Woodfield, SAS Institute Inc. Introduction where O(B) , 7(B) = ¢(B) = 1 ~ .,B ~ "",B- ~. Time series intervent.ion analysis is used to ascertain the im- pact that one or more interventions have on a time series. For ex- The model may be generalized to include llonst.ationary behav- ample, the t.ime series may be monthly revenues from the sale of n ior. For nonstationary series, ¢(B) may include differencing oper- product with t,he int.ervention being the implementation of a new ators. The usual factoring displays the characteristic polynomial for the AR component as a product of stat.iollary and 1l011station- marketing strategy. Using the ARIMA procedure in SASjETS@ ary characteristic polynomials. The general nonstationary model soft.ware, a large class of time series models are available to pel'- is given by form a t.ime series intervention analysis. Quest.ions arise concern- ing the nature of the model employed and the differencing of re- sponse and predictor variables used in the analysis. Sevel'a! exam- ples are considered to indicate how different modes of analysis can which is more easily expressed as affect the inferences made. 1',(B)I',(B)(1'; ~ f(w. 0, X, t)) = 00 + O( B)e,. (4) 1. Overview of Time Series Intervention Analysis where I',(B) = 1 ~ ¢,B ~ .,B' ~ ... ~ .,B', Intervention analysis may be viewed as a type of regression anal- ysis in which one or more predictor variables observed at equally D II(1 ~ BU;), spaced time points are postulated to have had an impact on a "",(B) = response variable observed at the same time points. In the sim- , plest case, the intervenf,ion predictor variable is an indicator vari- I:¢;). Oo=p'P,(I)=p(j~ (5) able that takes the value zero before the intervention occurs and the value one after the intervention occurs. However, the predic- ;=1 tor variables in an intervention analysis need not be indicator vari- In the ARlMA procedure, the value MU corresponds t",Sugi-12-57 Woodfield.txt
"APPLICATION OF INTERVENTION ANALYSIS TO POWER PLANT MONITORING DATA Linda E. Bireley Nort'-l Utilities Service Company NU Envlronmentallabor6lory Introduction CT During the 1960's and 1970's, public awareness and concern developed over the effects of inoostry on the environment. Such awareness prompted !J)IIernmental reoulatlon of power plant NY Il construction and operation. Many of the resulting reoulatlons ~~~---%~~r-lOkmi N stipulated requirements for environmental monitoring and Imp..,t assessment studies. Some of these studies heYe produced long time- series of data. This peper describes the result of a research effort that summarizes long-term biological monitoring date collected at a nuclear power plant end applies intervenllon analysis to the data series for assessing impect. The power station The Millstone Nuclear Power Station (MNPS) complex Is Figure I. location of the Millstone Nuclear Power Station In Long located on the north shore of long Island Sound (LIS) (Fig. I) In Island Sound. Waterford, Connecticut (Fig. 2), and is a Northeast Utilities (NU) faclllty. Three power plants are located on Millstone POint, which is bounded on the west by Niantic Bay, on the east by Jordan Cove and on the south by Twotree Channel (Fig. 3). Electric generating capacities (MW-e), cooling water flow retes (m3/s) and Important dates are listed In Table 1. I .... ...---. o Table I. capacities and dates of construction and operation for the I m1 three power plants at Millstone Nuclear Power Station. Capacities Start dates 3 Unit MW-e m /s Construction Operation 12/15/65 652 26.48 11/29170 870 34.55 6/30170 10117175 2 Figure 2. location of the Millstone Nuclear Power Station In 1150 56.63 6/30175 4/2B/86 3 Greater Millstone Bight. Wllilltoru, Nuclear Poww swtIon All three plants have once-through condenser cooling water systems. The necessary water Is drawn by separate shoreline intakes located along Niantic Bay (Fig. 3). The intake structures have trash racks and traveli",Sugi-12-58 Bireley.txt
"SAS/ET~SOFTWARE TREATMENT OF LAGGED DEPENDENT REGRESSORS AND AUTOCORRELATED ERRORS IN Thomas B. Fomby and Joseph G. HirsChberg Dept. of Economics. Southern Methodist University, Dallas, 75275 1. Purpose The included sample program in the User t 5 Gui de The purpose of this paper Is two-fold. (pp. 192-3) is intended to provide an estimation First, we wish to critique the current documen- procedure for the model of equations (1) and tation of the PROe AUTOREG proced~re as des- Unfortunately, the illustrated method (2). cribed in the SAS/ErS User's Guide (Version 5), appears to be inconsistent and thus asymptoti- especially as it relates to the discussion of cally ineffiCient. Lagged Dependent Regressors (pp. 192-3). In particular. the problem we are interested In is Our second purpose is to review some recent characterized by the regression model contributions to the literature in this area which go undocumented in the User's Guide. (0 EmphaSiS is placed on the Hatanaka--rf974)-metllod and a first observation correction suggested by -apv t-p' t=2.···,T,(2) Harvey (19al). This method is asymptotically efficient and, because of the first observation correction, appears to exhibit good small sample where is a sequence of independent normal ~t performance as well. :t 2 error terms with mean zero and variance 0 , The outline of the rest of the paper is as follows. In section 2 the SAS/ETS PROC AUTOREG denotes a (K-2) x 1 vector of observations on procedure is examined for its applicability in nonstochastic explanatory variables at time t. the context of the model of equations (1) and a~ s are such as < 1 and the values of the' 16 1 Also the User's Guide sample program is (2). 1 examined and the statistical properties of the to guarantee the covariance stationarity of the recommended estimation procedure are discussed. error process \It. The lagged dependent regres- In section 3 a review of the recent literature sor - auto correlated error model of (1) and (2) Is presented",Sugi-12-59 Fomby Hirschberg.txt
"Incorporating Management Judgement in Forecasting Joel FtnQa'man, _ _ UnftJeraIty INTRODUCTION Table 1 In this paper we consider the aituation In MmI!h Sold Shown Interest Rate which a company has a computer-based forecastina BYstem. Management uses the forecaats from this JAN83 15 ISS 14.011 system in the duelaiOR . .kine process. We wish to FEB83 12 320 10.1 incorporate Management's subjective judgement 8S MAR83 18 11.5 350 part of the formal foreeastioa procedure. By APR83 12 131 12.8 ManaKements· incorporating judgement _ in the MAY83 25 228 16.5 foreeastine procedure we hope to lain more ,accurate, JUN83 13 512 14.1 useful forecasts and areater acceptance of the fore- JUL83 19 182 13.0 castine Iystem and procedure by Management. AUG83 16 11.3 430 SEP83 28 408 14.0 16 OCT83 240 13.5 ILLUSTRATIVE EXAMPLE NOV83 5 350 16.4 DEC83 10 14.2 280 We shall use the example of a fictitious JAN84 24 428 12.2 company called TEXAS HOMES. INC. Texas Homes is FEB84 9 92 13.9 a regional real estate company which haa been MAR84 18 150 13.4 keepin& records of the monthly number of homes APR84 30 306 12.9 sold by its agents. the monthly number of homes MAY84 36 11.5 S50 shown by its agents, and the corresponding interest JUN84 "", 380 10.0 rates during these monthly periods. This JUL84 35 217 11.1 information is listed below from January 1983 to AUG84 26 436 11.6 December 1986. SEP84 25 536 12.0 466 9.6 OCT84 42 These data sets are illustrated below in Figures 1, 2 NOV84 22 472 11.5 and 3. DEC84 30 142 9.5 JAN85 26 321 10.2 The foreeastinK situation for Texas Homes, FEB85 20 240 10.0 Inc. is to estimate the number of homes that will be MAR85 8 182 16.2 sold each month during the next twelve months. We APR85 15 168 10.0 shall use the information on Homes Shown and MAY85 31 410 10.9 Interest Rates to aid in the forecasting of Homes JUN85 18 341 13.7 Sold during the next twelve months. JUL85 43 400 9.5 AUG85 21 352 12.1 SEP85 35 9.4 580 COMPUTER-BASED FORECASTING USING SAS' 0CT85 52 47",Sugi-12-60 Fingerman.txt
"adjusted data. Section 4 contains a brief-re- This paper purports to discuss the opera- view of some of the computerized tools related to tions involved in the production and dissemina- Sections 2 and 3. tion of seasonally adjusted data, with special 2. STEPS IN SEASONAL ADJUSTMENT reference to the key functions available in the 2.0 An-OverView X-II-ARlMA seasonal adjustment method. This meth- od has recently been developed as a SAS procedure There are three major steps involved in the seasonal adjustment of time series, namely: PROC XllARIMA. The topics discussed are: (Dagum, 1979): (1) an ex-ante seasonal analysis CAl Key functions involved in each of the follo- of the original series; L.2) the seasonal adjust- ment per se; (3) an ex-post seasonal analysis wing three steps: (1) an ex-ante seasonal analy- of the seasonally adjusted series. sis of the original series; (2 ) the seasonal The results from the first step detennine all adjustment per se; (3) an ex-post seasonal ana- the necessary parameters on the seasonality of lysis of the seasonally adjusted series. eB) How the original series in question. A successful the seasonally adjusted series are disseminated analysis requires close consultations between sub- by means of publications, CANS 1M and TELICHART. ject-matter specialists (who are familiar with (c) A brief review of computerized tools includ- ing PROC XllARIMA. the subject on which the series is observed) and methodological experts on seasonal adjustment. 1.",Sugi-12-61 Dagum Gratton.txt
"COMPARISON OF FOUR UNIVARIATE METHODS FOR FORECASTING SEASONAL DATA WITH SAS Jeffrey Jarrett, University of Rhode Island Introduction More traditional methods of forecasting univariate seasonal data have employed the Forecasts provide useful numerical concept that one can utilize the principle of information concerning the expectations of a classical decomposition. Specifically, if a firm's or organization's future prospects and forecaster can isolate, measure and separate the indicate management's ability to anticipate the seasonal component, in turn, the deseasonalized organization's changing internal structure and data can be examined and forecasted by external environment. The accuracy of forecasts regression based procedures. The Box-Jenkins have been given much attention in recent years. method does not strictly assume that seasonability can be isolated and separated from Previous studies including. Elton and other systematic components but seasonality can Gruber [1974]. Johnson and Schmitt [1974J, Basi still be modeled. The resulting predicted trend et al [1976J. Lorek et al [1976], Brown and can then be reseasonalized to complete the Rozeff [1978], Lorek [1979], Brandon, Jarrett, process of forecasting the original time series. Khumuwa1a [1983] and Deschamps and Mehta [1980] in SAS, the U.S. Bureau of Census Method II-Xll have shown the usef.ulness of various [1967] is criticized because the estimates for extrapolative and Box-Jenkins models. These observations of the most recent years do not results gave rise to a previous study of this have the same degree of reliability as those author and his colleagues. observations near the center of the data base. Hence. method 3 is included. ,Brandon. Jarrett and Khumuwa1a [1986]' compared .several extrapolative forecasting In response. Statistics Canada XII-ARIMA models to provide useful information to those developed by Dagum [1983] in 1975 extrapolates who utilize time series forecasts. for one year new observati",Sugi-12-62 Jarrett.txt
"TEACHING TECHNICAL SUBJECTS TO ADULT LEARNERS Linda J. Stewart, Idaho Power Company The Information Age is upon us and American boredom, or even worse, a sense of complete businesses are trying desperately to keep abreast bewil derment. The techni ca 1 tra i ner, faced wi th of current developments. Accountants, engineers, this result time after time, will more than likely transfer the blame either onto the student economists, managers, and supervisors are turning more and more to the power of the personal with the comment nthat person is incapable of learning anything new. I do not know how they computer and large mainframe to help unravel the mystery and harness the power of corporate function on the job,n or turn the blame inward with feelings of inadequacy. Both responses can information. Computing power has escaped the be avoided when a complete understanding of the Data Processing Department and found its way to the desk of many employees. The challenge facing adult learning process is explored. most companies today is how to successfully train First, it is important to understand one key non-data processing employees to use the powerful tools they have at their fingertips. element in the learning method that most techni- cal people use when first exposed to a new piece Most large companies are at least making the of software or a new programming language. This attempt to provide this needed training through learning technique is usually employed uncon- the auspices of the Information Center. Informa- sciously, and unfortunately, it is probably the tion Centers have employed a variety of instruc- foremost reason the technical person is unsuc- tion methods in order to fulfill their goals. cessful as a trainer his first couple of times at Such methods have included live classroom in- the front of the classroom. When first exposed struction either on or off site, computer-based to something new, the data processing profession- training, commonly termed CBT, or a",Sugi-12-63 Stewart.txt
"Training Support for the SAS® System for Personal Computers Janine J. Huff, SAS Institute Inc., Cary, NC Defining the Target Audience Characteristics Introduction We needed to look closely at the PC user and focus on those who Development of the SAS® System for Personal Computers under represent our potential training audience. In our examination, we PC DOS has sparked a new approach to training support by the Institute's Education Division. Training is being tailored to match looked at the characteristics that might affect the types of training the PC and its aura of friendliness, personal control, and toucha- that would be both appealing and effective. When we collected our data. we compiled a profile of the prospective PC trainee. bility. In the PC target audience, as in both the mainframe and minicom~ Mainframe training, like the machines it supports, traditionally puter user bases, a dichotomy exists between technical specjal~ has been broad in scope and presented in large batches. Train- ists and end users. end users are persons who use the SAS ees expected this type of training and were generally satisfied. System to get information they need to solve problems or answer But personal computers have changed both the complexion and expectations of data processing trainees. The new target trainee questions in their work. Technical specialists are programmers has no more curiosity about how the computer runs than the and analysts who use the SAS System as a programming tool average driver has about how the engine works. This trainee is to create applications. They may also be highly skilled end users task~oriented and impatient to start using the PC to solve infor~ such as statisticians, mathematicians, or scientists who have mation problems immediately. learned programming as part of their research skills. The Education Division is responding to the demands of the new The majority of our mainframe software users are programmers, analysts, and highly technical en",Sugi-12-64 Huff.txt
"TRAINING MANUFACTURING MANAGEMENT USING THE SAS SYSTEM Linda T . .Jolley THE FUTURE IS ·.· management. This audience's frame of reference is not going to match either ""In case (your company was] too busy your own or that of today's line manager. redeploying assets offshore to' notice, You're going to have to customi~e your U.S. compan1es in 1985 produced 88 approach to reach this diversified million tons of steel and 13 .111ion cars audience. and trucks. They also turned out 67,000 tons of paper, 884,000 tOD8 of coal, 131,000 pieces of tarm aachinery, 3.5 .This paper will suggest some and 25. million metric tons of aIu.inum, approaches for training that new type of million tons of fertilizer. Stick that manufacturing management in the use of economy.""~ up your service the SAS* System. Topics are: 1) How is the manufacturing management audience unique?; Why train manufacturing 2) According to the February 2, 1987, managers to use the SAS System? j and 3) FORTUNE special report, The Economy of Bow to structure the training to meet the the 19908, manufacturing will hold onto unique needs of that audience. its 20% share of America's gross national it product and do with fewer people. Less than one-fifth of Americans now earn MANUFACTURING MANAGEMENT paychecks in manufacturing and the numbers are decreas ing. But ""( t} he Smokestacks Won't Tumble""l and the How are the managers of survivors of the 1990s restructuring aanufacturing operations different from u · · · should emerge as low-cost, others that you will train to use the SAS quality-driven winners.""l System? What are the keys to getting them to respond positively to your training? Let's consider a hypothetical FORTUNE believes that the hordes of first line supervisor of a bottling "" ... number-crunching minions and operation. report-writing middle managers ... "" 1 will as disappear machines begin to "" ... perform many traditional management Our John Doe is a line supervisor chores more cheaply than people .... "" l",Sugi-12-65 Jolley.txt
"SAS training offerings to serve the needs of our diverse users. Where appropriate, the SAS Although information centers seem to be model will be applied to training for other pro- flourishing and continue to grow in number in ducts over the next several years. business and academic settings across the coun- Our SAS System users at UNM come from try, clients and information center staff identify all disciplines and backgrounds, e.g. faculty, training as a weak point in most information staff, students from the Sciences, Engineering, centers. At The University of New mexico we Humanities, Physical Education, the Arts and so have made training a focal point for improvement on.; Administrative users from the Museums, the within the Information Center by designing a University Hospital, Contract Archeology, In- multilevel, integrated SAS® training program to formation Systems, Commission on Higher Edu- meet the diverse needs of our great variety of cation, Division of Goverment Research, academic and administrative users, This paper Institutional Research, etc. We also support demonstrates how we are successfully achieving such external users as the City of Albuquerque, our two main objectives: quality training and Albuquerque Public Schools, The Forest Service, self-sufficient clients. The Veterans Hospital, Sandia Laboratories -and others. In fact, we are as likely to see a Biology faculty member in class as a Psychology student",Sugi-12-66 Robinson Teaf.txt
"two to six full time staff members. students have access to the VAX This paper is intended to share the computer system in two computer labs on problems and solutions of educating campus containing a total of 40 computer users of the SAS. system in an terminals. Twenty-four dial-in lines academic environment. Briefly the are avaiable to students who have the problems were the obvious of how to necessary equipment. The computer labs educate students, faculty and staff are staffed at all times by student with various levels of SAS knowledge. workers and are open generally from 8 The range of instruction needed was a.m. until 12 p.m. wide, from what is the SAS system and why should it be used, to how to deal with large data sets on tape, to the THE PROBLEM specific problems of using the SAS system on the DEC* (Digital Equipment How do you go about educating and Corporation) VAX. computer. Our supporting a population of users, the problems were further complicated since majority of which are new to the SAS we were not only new SAS users but also system and the computer system? There had new computer equipment and new are several directions available but manpower and money are as always operating system (VMS*). restrictions. It is also important to The solutions involved the development have solutions available in a resonable of short seminars and workshops, amount of time. At UALR, one staff various information handouts, DCL consultant is available to support all commarld files, as well as a staff of the users of statistical packages. person available for consultation with Money was allocated for photo coping, research and teaching faculty. printing, and purchasing manuals. The users and prospective users of the SAS system at UALR can be separated",Sugi-12-67 Whiteside.txt
"ANISATION OF THE ""ASSURE"" is a software package developed in INFORMATION CENTRE house by the Company for use by agents on IBM PC XT's. It provides a client/policy database with a report generator, letter writer and general ledger facility. ""SPEARS"" is a dial up presentation program The role of the Centre is to provide direction and on-going support to AEtna personnel in the system which enables an agent to produce a introduction and operation of end-user computer client presentation via a portable telex type technology, that conforms to AEtna's strategic terminal/printer. data processing development plan. Microcomputer configuration Organisation The standard corporate PC configuration is: The Centre is part of the Information Services Department of the Corporate Services Division of IBM PC XT with 640k RAM. *: the company and the Information Centre Manager Internal Tallgrass 25mb hard disk & 20mb reports to the Information Services Manager. *: tape backup unit. The Organisation of the centre is: Taxan Vision IV colour/graphics monitor. *: * A Manager, IRMA 3270 communication board *: * An Agency support Group of four staff, * AST Rampage 1mb memory expansion board. A Marketing Manager Agency Computer systems, User support and * The centre supports all mainframe software A Corporate Support Group of two staff. packages and all PC hardware and software. Training courses at intra and advanced level are conducted for all PC software packages and DOS. User Profile Purchase of equi",Sugi-12-68 Sweeney Renneberg.txt
"INTRICACIES AND RAMIFICATIONS OF PC SAS® SYSTEM MANAGEMENT AND DISTRIBUTION AT LARGE ACADEMIC INSTITUTIONS Victoria W. Dingler University of Illinois at Urbana-Champaign authorized by the academic institution's legal There are four issues of particular importance per- department. The license agreement is also a useful taining to PC SAS System management and distri- tool to gather pertinent information about the end bution at large academic institutions. First, legal user's address, telephone number and hardware matters arise when licensing institute program pro- specifications (information also required by the ducts. These entail contract negotiations between SAS Institute license agreement). SAS Institute Inc and the academic institution. Second, distribution issues range from pricing to Distribution methods are the most varied. The installation. Third, support issues are both short- issues involved are pricing, copying, delivery and term and long-range in scope. Fourth, installation. There are three common ways to deal advertising/ notification issues are concerned with with pricing the licensed products. The most com- disseminating policy and system changes. mon: charging for cost recovery of the software only. Since the software is licensed on a yearly SAS Institute recently completed a survey to deter- basis, the licensing fee can be divided by the mine how the academic community distributes and number of possible end users. For instance, if the administers the PC SAS System, and also to deter- license fee is $2500 and the estimated number of mine how the user community is notified about end users is 100, the cost recovery fee is $25 per availability of PC SAS System products. The end user. The next most common approach is dis- results show that there seems to be little difference tributing the software for free. In this instance, in the way legal issues and advertising issues are the academic institution carries the cost of the handled. The most significant d",Sugi-12-69 Dingler.txt
"COORDINATING A SITE LICENSE THROUGH A UNIVERSITY MAINFRAME COMPUTING CENTER Trina Rosmer, Computing Center, University of Massachusetts B. Installation I. Introduction The University Computing Center at the Uni- Installing a program on our mainframe is versity of Massachusetts, Amherst Campus has been always performed by one group specifically train- coordinating a SAS/BASE* and SAS/STAT** site li- ed and experienced in performing the task. Con- cense for microcomputers since the initial re- sequently, the task is usually straight-forward lease in January of 1986. The University Comput- and uses minimal resources. The SAS-PC System ing Center has Control Data Corporation (CDC) comes with very clear installation and testing mainframe equipment. We serve a student body of instructions. As long as the user is familiar approximately 18,000 undergraduate students, with PC-DOS and PCs, there is no problem. How- 5000 graduate students and 1500 faculty. We ever, we have many new users buying a PC just so coordinate and support many popular mainframe they can use the SAS-PC System and who therefore statistical packages such as BMDP, SPSS, MINITAB, have no prior PC experience. We find these users are taking an extraordinary amount of consulting IMSL, and TSP. Presently, the SAS System is not available time, not necessarily to install the SAS-PC Sys- on CDC equipment so the Computing Center was very tem but usually to install and explain the PC- eager to obtain a site license for the SAS-PC DOS operating system. We are trying to solve System to make it available to our users. How- this problem by requiring that these people at- ever, we were unprepared for many of the issues tend a PC-DOS class before they attempt to in- encountered when coordinating a PC site license. stall the SAS-PC System. We will present these issues below and discuss our solutions. C. The Cost of a Site License II. Issues Does the site licensor pick up the total cost or should one try to recover some of",Sugi-12-70 Hosmer.txt
"EFFECTIVE METHODS OF TESTING USING THE SAS SYSTEM Neil Howard, ORI, Inc. Linda Williams Pickle, National Cancer Institute James B. Pearson, Jr., Pearson and Associates Introduction affected by the one in error. While costs of correcting errors in smaller systems or The quality of a programmer's work is segments of code do not increase so evaluated by results. When results are dramatically over time, early testing can ~ncorrect or the program fails to meet still reduce total costs substantially and expectations, consequences range from annoyed improve system accuracy and reliability. users to frantic calls in the middle of the We will describe techniques that can be night. What can we do to avoid these useful for testing and debugging at all unpleasant occurrences? Use of a fourth- stages of the software development life generation language such as the SAS System cycle: determination of functional should improve quality by providing an requirements; systems or program deSign; improved environment for the programmer. coding, unit testing, and implementation; and Such a system handles the coding detail at validation of results. Many features of the the bit and byte level and provides libraries SAS System can facilitate testing and of pre-tested functions and procedures, debugging and can introduce time-saving, freeing the programmer to concentrate on programmer-efficient, cost-effective program concepts. Despite these improvements over design into your daily routine. earlier programming methods, no SAS PROC Incorporation of these techniques into the TEST-MY-CODE exists -- the responsibility for design, from the smallest module to the ensuring program quality remains with the overall system, will result in a higher programmer. In today's world, high quality quality product delivered in a shorter time, programming requires not only the production not to mention reduced stress and increased of accurate results, but also reliability, self-esteem among the programming staf",Sugi-12-71 Howard Pickle Pearson.txt
"APPLICATION PROTOTYPING IN A DECENTRALIZED ENVIRONMENT Donna Breslin. Breslin Consulting unknowns, this Leadership, Planning and Support With are all of these any good to was a prototyping undertaking. the keys I~ project I will The important thing was to show how a SA candidate. particular. midwest utility get something working quickly, so that project for a was Then ideas it would be more real. structured to include these factors. would flow. In general. centralized information systems departments are in trouble. An ideal project has the following The work backlogs and the problems with components: communications end-users are · Important to the company with well-documented. People in the user · A clear benefit to the users departments are looking for ways to · Evolutionary in development. keep the application development These are' explored more fully in process more consistent with their Implementation.of Strategic Planning by needs and bypass the long waiting Peter Lorange. As mentioned. this period in the central department. project was important and evolutionary, ar~ Currently. some businesses we did have some immediate user experimenting with decentralization and resistance. More about that later. prototyping. The project was supported by a network Prototyping is a method in which a of people. They each play an important project is developed in small parts role. with early, modifiable ""deliverables··. This allows for changes throughout the High-level Management Support development instead of ""nailing all of This is the first and most important the specifications down"" first. We all part. People can say that an idea is know the specs ALWAYS change. important, but it isn't until a budget is set and the political will is from created that anything can happen. Decentralization is the swing back centralization of application Without this support, the project can programming under a separate be drawn off course, especially when it department. Some companies now u",Sugi-12-72 Breslin.txt
"UNKETT SOVRAN SERVICES representative of the type of ABSTRACT computing non-data processing This paper discusses the professionals will do. authors' experiences using SAS on VAX mini-computers as a teaching language for first-time THE INTRODUCTION TO computer students in a INFORMATION SYSTEMS COURSE university environment. The results of a survey of students' Located in the western appraisal of their experience suburb of Richmond on a 350 with SAS is included. acre campus, the University of Richmond is the largest private university in Virginia. The INTRODUCTION evening college, University The Information Systems College, traces its history career field has attracted many back to 1920, and this division individuals during the past 5 to has undergone many changes over It is difficult to the years. University College 10 years. find a college that does not currently includes the Evening School, the Summer School, offer some form of Information ', Systems education, and many have Special Programs, and the formal programs on Women's Resource Center. It offers many non-traditional undergraduate, certificate, and graduate levels. Typically, education opportunities to the these programs include an Richmond area community, introductory class that is awards a Bachelor of Applied to provide stud~nts Science degree, and offers designed several certificate programs. with foundation concepts that will be expanded and augmented in later classes. In these The Academic Computing classes where",Sugi-12-73 Plunkett Plunkett.txt
"Eight Key Questions Determining the Future Direction of Established SAS* users Groups Hallett German, GTE Laboratories INTRODUCTION Little has been written in (e.g. SAS' Institute the SUGI literature on policies, suggestions for product enhancements, l?rovide established SAS* users groups or providing a list of SAS* bugs not 1n framework to help define usage Notes and any quick fixes to them.) choosing a their future direction. (For this paper, an established SAS* Institute liaison from users group is defined as your membership will enrich this relationship. The reader having existed for greater than a year.) Established is encouraged to read the users groups will begin to sullivan reference to see ho,"", reexamine at least three personal computer users group major topics: meeting and develoDed into an effective lobbyi~g force. organizational techniques, users group mission and relations with other associations. AnS\1erS to one OUESTION ~ EVALUATING ~ topic will shape the answers lWllfr COMBINATION JrQ.B A to the other two. Eight key MEETING FORMAT questions on each of these topics and their suggested answers are provided to help An established users group (after 30 members) abandons the planning efforts of SAS* Users Group officers and the informal general practices it started with and members. The suggested answers are a result of the becomes increasingly more author's two year experience formal. choosing the correct combination of informal and as a co-chairperson of BASUG (Boston Area SAS* users formal meeting functions is Group) · important in developing your group's membership and image. Too much informal elements OUESTION .J...;. .IlMRS. .GBQlU' will lead to great personal INTERACTIDN ~ :nil: networking but long and ~ INSTITUTE unorganized meetings. On the other hand, too much formal elements makes meetings The question of users group appear too distant and interaction "",lith the SAS* members very restless. Institute is very important. Each side has tremendous",Sugi-12-74 German.txt
"meeting of SAS users, and another long running users group is that of IBM users, The author has experience in starting and called SHARE, with over 20 years. supporting user groups that include the Northrop SAS Users Group, the Southern The difference between a club and a user California SAS Users Group, and the Northrop group is that a user group is a more Macintosh Users Group. He is a member of professional activity and meets on company the board of directors of the Los Angeles time. Still, the user group can be fun and Macintosh Group (LAMG) and started the fulfilling if the product is easy to use and Special Interest Group connecting Corporate greatly increases productivity. (Macintosh) User Groups. The benefits of user groups are felt at four The difference between user groups and clubs levels: the individual level, the department is explained, and the different leadership level, the corporate level, and the vendor or styles are discussed. Techniques that build international level. The individual benefits by in risk but have potential for spectacular learning, by presenting material, and by success are analyzed and contrasted with meeting other people. The department techniques for moderate success but a greater benefits in that user group activity extends guarantee of continuing success. the base of talent focusing on the department's current projects. The The paper discusses the benefits of user corporation benefits by the increased groups to the corporation, the individual user, capability of the individuals who are doing the user's department, and to SAS Institute. important work. And the vendor benefits because, not only are there more expert users who know what they want from the vendor,",Sugi-12-75 Shipp.txt
"ESTABLISHING A SAS® CONSULTING SERVICE AT A LARGE RESEARCH UNIVERSITY Ron Kalinoski, Syracuse University John Podgurski, Syracuse University INTRODUCTION SAS system under VM/CMS continues to be the most popular SAS software environment by far. Data analysis is an essential component of research In the past, SAS consulting was provided at two in almost all fields of study. With SAS software, hierarchical levels: introductory and advanced. Us- researchers can analyze any kind of data using vir- ers first went to a walk-up general help desk, tually any statistical method. Nevertheless, in a het- staffed by trained undergraduates, where basic SAS erogeneous research environment typical of a uni- questions could be answered. Users with sophisti- versity, a consulting service is' an essential adjunct cated problems beyond the scope of these student to efficient data analysis with SAS software. Re- consultants, were referred to senior staff members searchers frequently encounter problems which are at ACS who provided expert SAS advice. As SAS beyond their grasp of the SAS system, and thus use by researchers grew, so did the number of re- must seek expert advice to proceed. In this paper ferrals to senior staff. At the same time, staff mem- we describe the consulting service we implemented bers were in the process of expanding and diversi- at Syracuse University which has successfully fying o.ther services to the user community. A new helped researchers make more effective use of SAS approach to consulting was needed, one which software. We feel that Syracuse University's active would expand the services available to researchers research environment typifies that at many research and yet relieve the senior staff of a growing consult- institutions, so the strategy we followed here could ing load. be implemented elsewhere. First we describe the consulting service and its implementation, and then In February, 1986, the Research Consulting Serv- we discuss the clientele we hav",Sugi-12-76 Kalinoski Podgurski.txt
"What's New from the Education Division at SAS Institute Inc. Lee H. Evans, SAS Institute Inc., Cary. N.C. Ann Lehman, SAS Institute Inc., Cary, N.C. Advanced Annotate Applications is a half-day seminar that dis- INTRODUCTION cusses using the SAS/GRAPH® annotate facility to label charts and plots and to generate customized pie charts. Course topics In less than two years, the number of training courses offered by cover advanced features of the facility such as relative frames SAS Institute has tripled. SAS® software and SYSTEM 2000® of reference, GROUP and SUBGRP variables, the stack mecha- Data Management Software users can now select from more nism (PUSH and POP functions), and the TXT2CNTL and than forty-five courses delivered as computer-based, video- CNTL2TXT functions that update values that monitor cursor posi- based, or instructor-based training. The Institute's Education tions. Division is also offering new training options and new training locations. Programming with SAS/IMLTM Software is a one-day seminar · In addition to existing Institute training centers in Cary, describing the use of SAS/IML software on the personal com- North Carolina, Austin, Texas, and Rockville, Maryland, puter for processing data, accessing external files, building public instructor-based courses with hands-on computer tables and lists, developing user-friendly full-screen systems, and workshops are offered in two new geographic areas. SAS performing useful mathematical and statistical operations. The Institute, in conjunction with Ryerson Polytechnicsl conversion of PROC MATRIX code to PROC IML is discussed. Institute, is offering Institute training courses in Ryerson's ThiS seminar is designed for those who have completed an Centre for Advanced Technology Education (CATE) in advanced course in statistics and have a working knowledge of Toronto. A new Institute Training Center also opens in the matrix algebra. Although the course is designed for SAS/IML Chicago area in July 1987",Sugi-12-77 Evans Lehman.txt
"Instructional Building Blocks Of Computer-based Training Jane C. Krupnick, SAS Institute Inc., Cary, N.C. INTROOUCTION ke""pt to a minimum. Your goal is to provide lean training that teaches only what is necessary for students to master course In many ways, developing a computer-based training (Can objectives. You do this by carefully matching content to objec- course is similar to building a house. There is a planning stage, tives. a construction or development stage, and a testing and cleanup stage. At the most fundamental level, for any instruction, your content must be accurate and clearly presented. It must teach what it pur- ports to teach in the most efficient manner possible. It must be You wouldn't dream of building a house without extensive plan- presented in a manner that is appropriate for the target audience, ning and preparation. In this stage, you select the site, consult an architect, determine the arrangement of rooms, and draw the and it must be free of bias against any group of people. blueprints. Likewise, you need to plan and prepare extensively for CST development. You determine that a training need exists But it is not enough simply to provide information. You need to and that CST is an appropriate mode of training to address this present examples of how the information is applied. It is easier need. You identify the audience to whom training is to be directed to grasp a concept or understand how to use a skill when it is and the content to be covered. You pinpoint the exact behaviors placed within a context illustrating its application. Examples you expect students to perform once they have completed the should be relevant and as universal as possible so people can course successfully. These are your behavioral objectives. Then easily transfer the idea to their own situation. You may want to you design an instructional strategy (the instructional blueprints) use an analogy to common everyday occurrences if the idea is for the entire course, o",Sugi-12-78 Krupnick.txt
"EXPERIENCES WITH TEACHING EXPERIMENTAL DESIGN USING THE SAS(R) SYSTEM FOR PERSONAL COMPUTERS Robert A. McLean, University of Tennessee Richard D. Sanders, University of Tennessee Introduction activity with the necessary computing power. The ability to do the computing OUr experiences in teaching design without delay enhances the engineers' of experiments is an outgrowth of a creditability with the production staff strong continuing education program and the manager. This leads to better offered through the Department of communications and realistic results. Management Development Programs at The We were able to convince the University of Tennessee. These Management Development Program programs, outlined below, have been Department that this type of course offered with the idea that business would be in harmony with their managers and their employees need to philosophy of structured growth of continually evaluate their performance quality programs. The following outline in terms of productivity and of the programs offered by this effectiveness to keep pace with today department will aid in the visualization and to prepare for tomorrow. They must of how experimental design fits into fill in knowledge gaps, sharpen old their overall program. It will also techniques, and acquire new skills. give the reader an idea of the type of The Institute for Productivity base that is required to support and Through Quality was initiated in 1981. justify the initial investment required It was established in response to a need to obtain hardware and software for such on the part of lJlany American industries a course offering. to reestablish a reputation for quality. The institute advocates the statistical The University of Tennessee management approach that Dr. W. Edwards Executive Development Program Deming taught to the Japanese after 1972 - Present World War II. The graduates of these programs expressed the need for another General Management Programs statistical program that wo",Sugi-12-79 McLean Sanders.txt
"ONE APPROACH TO SAS* TRAINING Geraldine M. Resheske, AT&T Graphics. Seventeen people attended INTRODUCTION the Basics course and twenty-one attended the Graphics course. The The Information Center at AT&T in students' backgrounds were essentially Reading, Pennsylvania was started in either engineering or information 1984 in an effort to promote end user systems. Only one student was neither self-sufficiency in data analysis, data a programmer nor an engineer, but he manipulation and reporting from existing data files. The specific did have extensive experience using software packages on our mainframe. A mission of the center is to provide prerequisite for registration in either training, support and consultation to of the courses was some experience the non-data processing community at using a computer. The students were our location. Our services are accepted into the classes based on this available for everyone from clerks requirement and their degree of need. right up through managers. The combined courses ran for one week - three days of Basics and two days of The scope of the IC's services is Graphics. The training was limited to mainframe software. There supplemented by two sessions, taught by is a PC located in the center, but the myself, instructing the students how to Reading Works has a separate user access SAS software on our system. support group for personal computers. Also covered were the SAS Display Manager, the use of PF keys and the editing commands. SAS TRAINING - THE BEGINNING Requests for training and support of The courses were well received. The the SAS System increased in early.Fall only major complaints were that there was too much material to cover in the of 1985. The interest originated from the engineering universe and the time period and there was not enough quality control organization, as well time to finish the exercises. One as some programmers. Our users wanted student suggested that it would be a software package for statistical e",Sugi-12-80 Resheske.txt
"MAKING SAS/GRAPH® SOFTWARE WORK FOR YOU Roger Chenoweth, SAS Institute Inc. New features in Version 5 of SAS/GRAPH® Developing testing strategies for the software have made the product much more Metagraphics facility led to the conclusion that it flexible. New procedure options, AXIS and would be nice to be able to display the picture LEGEND statements, and the ANNOTATE facility described by a metafile on any supported give you control over almost every aspect of your graphics device without actually writing the graphics output. Everything anyone could ever external driver for that device. The solution to ask for in a business graph, right? Well, maybe the problem was to write a fairly simple SAS you want to have control over a few more items. DATA step program (which I call METATATE) that could read a metafile and produce as output an ANNOTATE data set that describes the same picture. This is a presentation of a graphics tool that gives you additional control over SAS/GRAPH procedure output. The tool is a SAS® DATA step The ANNOTATE Facility program called METATATE. It reads a Metagraphics facility metafile and produces an An ANNOTATE data set is a special SAS data set ANNOTATE data set. This ANNOTATE data set that enables you to customize SASiG RAPH can be used with PROC GANNO to exactly procedure output. Its most common use is to add replicate the original graphics procedure output. special labels or markers to charts and plots. By modifying the ANNOTATE data set you can However, it can also be used to describe a whole alter the output from any graphics procedure to picture. For example, all of the word slides in suit you r needs. this presentation are purely the creation of an ANNOTATE data set used with PROC GANNO. To understand the METATATE program, we need background information on the Metagraphics and Each observation in an ANNOTATE data set ANNOTATE facilities. describes all or part of a graphics function that you want performed. Three of the required vari",Sugi-12-81 Chenoweth.txt
"TABLE 1 BOx-whisker plots are graphical rep~e Box plot Calculations sentations of data, primarily used in exploratory data analysis. They dis- n = number of observations in the group play the median, the box which spans D() - the depth (rank) of the ordered 50% of the data, and the whiskers observation to be selected which extend to approximately 95% of the data; any points beyond the a) Depth of median whiskers are outliers. The algorithm used here is a modified version of D(M) = (n+1)/2 Tukey's (1977) design. The ANNOTATE if the answer has a fractional part, facility is enlisted to plot the then take the average of the boxes, while PRoe GPLOT is used to set observations at D(M) - 1/2 and up and label the graph. This D(M) + 1/2 procedure puts the display in the user's hands and allows for flexibili- b) Depth of hinge ty of graph size, axes, width of boxes, and information contained D(H) - ((D(M)] +1)/2 within the display. where D(M) is the integer part of D(M) defined above.",Sugi-12-82 Scott.txt
"strated by the Becker and Cleveland system pro- vided much of the impetus behind the development Graphical techniques have long been known as pow- of an interactive color graphics system at the erful aids for data analysis. Numerous papers General Motors Research Laboratories, internally can be found on computer generated static graphi- named DataProbe. cal methods for data representation. Due to advances in computing, recent research in this The DataProbe system is a highly interactive sys- area has principally focused on highly interac- tem developed solely with commercially available tive and dynamic methods. This paper describes a softWare for use with commonly available graphics high-performance color graphics facility for devices. It was developed to exploit the new exploring mUltivariate data. It was developed as technology offered by intelligent terminals and a procedure under the SAS® statistical system graphics workstat·ions for more effective data using commercially available software. Although analysis. It combines recent statistical graph- designed to be device independent, it is most ics techniques with advanced computing facilities effective with high-end graphics devices. to provide a high-performance environment for Through simple movements of a graphics locator exploring multivariate data. the analyst can rapidly examine many different subregions of high-dimensional data. This facil- DataProbe is extremely easy to use. Through sim- itates the discovery and interpretation of struc- ple movements of a graphics locator, controlled ture imbedded in complex data. by a hand operated input device, such as a mouse or tablet, the analyst selects operators from a 1.",Sugi-12-83 Gugel Wang.txt
"Using SAS/GRAPH~ SoftMare on IBM Mainframes Mith Coax-attached PCs Gregg Ledford, Teknigraphics adapter board is used to connect Introduction coaxial cable to the PC. 3278 emulation generally refers to With the introduction of the IBM-PC, monochrome and 3279 refers to color many companies have purchased personal using the extended attributes of the computers in large quantities to 3270 data stream. increase productivity. The need arose for pes to communicate with the The emulator boards are equipped with company mainframe to access corporate software to perform the actual data. The need also arose to access terminal emulation. File transfer mainframe graphics such as SAS/GRAPH. software and other utility software Using PCs as mainframe graphics may be furnished with the emulator terminals eliminates the need for board. separate stand-alone terminals, resulting in a significant cost Digital Communications Associates savings for corporations. (DCA, of Alpharetta, GA) introduced the first 3278 emulator board called IRMA. Forte Communications (recently The ""icro-to-Mainframe Connection purchased by DCA) was the first company to introduce a 3279 emulator The preferred method for connecting board capable of providing graphics. PCs to IBM mainframes by most large Other companies that manufacture and corporations is to use a 3276 or 3279 sell 3278/79 emulator boards include emulator board. Coaxial cable is used IBM, CXI (Palo Alto, CA), Micro Plus to connect the PC to an IBM 3174, (Boca Raton, FL), Attachmate 3274, or 3276 cluster controller. The (Bellevue, WA), and several others. controller can either be channel attached directly to the IBM mainframe or remotely attached through an IBM o~ Types 3270 Sraphics '3705 or 3725 communications controller. This type of connection Graphics terminal emulation for uses synchronous (SDLC/SNA) or personal computers using IBM 3270 coax bisynchronous (BSC) communications. communications are either based on programmed symbols (PS) or al",Sugi-12-84 Ledford.txt
"ata set should be Price sensitivity Meter (PSM), consisting of responses to the four developed by Peter H. van Westendorp price questions and any (A-D) provides algorithms to determine additional relevant variables. Use various pricing points for a given Proe FREQ to examine the data set. product. Van westendorp's PSM An output data set generated on the algori thms have been implemented in va lid responses is needed to obtain SAS. SAS GRAPH is used to display cumulative frequency distributions. the results. PROe GPLOT with cubic The resulting cumulative distribution splines is used to smooth and display to price question A is referred to as the various price curves. ANNOTATE ""too The cumulative high"". is used to labe 1 the price curves, distribution of valid responses to and to highlight various theoretical price question B must be subtracted pricing points. from 100 at each unique response value. This results in an inverse PSM Description cumulative distribution referred to as ""too low"". The same procedure is The implementation of PSM involves employed to price question C, collecting respondents perceptions of resulting in an inverse cumulative product/service prices. Each distribution called ""not high"". The respondent must provide a response to resulting cumulative distribution to each of the following four questions: price question D is referred to as ""not lOW"". A. Print the letter ""An next to the price where it is so The computer code used to generate expensive that you w",Sugi-12-85 Rose Morwitz.txt
"T: unless additional points are included PRoe GMAP does not provide the to correct the graphed map. establishing of a viewport in the world units of the map data. Hence it is not THE PROBLEM: possible to extract a subarea of a map (zoom) by the bounds of some window The ability to zoom is strictly a which are independent of a maps poly- user responsibility of adequate map data preparation. An algorithm can gons. This paper describes a single data provide the proper manipulation of map step that provides line clipping and data sets so that by only inputting the polygon reconstitution. One can then bounds of the window to be viewed all graph only what one wants to see at the polygons that fallon the edge can be scale desired. Response variable reconstituted. What is required is an features of PRoe GMAP, as all other algorithm to handle objects{polygons) features of PRoe GMAP, are retained. A that may appear full on-screen, par- working knowledge of PROe GMAP will be tially on-screen and fully off-screen. assumed. We can narrow down the solution by keeping the objects that are fully on-screen and eliminating the objects INTRODUCTION: that are fully off-screen. What is left In this paper I am going to are the partials to be truncated by our explain the concepts and utility of window. While testing for inclusion in sub setting a map data set by stipulat- our output map dataset we will make note of the first point that is within ing the four corners(bounds) of some desired window o",Sugi-12-86 Decker.txt
"consuming. Developing presentation quality graphics GDDM provides two methods for generating using SAS/GRAPH often requires more advanced charts. programming skills. Using the Interactive Chart Utility (ICU) of the Graphical Data Display 1. The lCU in stand-alone mode. Manager (GDDM). non-programmers can produce 2. An application program can be done with high-quality graphics, but considerable time GODM to generate charts through the must be spent on data entry. This paper high-level application program outlines a technique to pass data to GDDM using interface with a program call to the TSO CLlST, FORTRAN, SAS, SAS/FSP and SAS MACRO. lCU. By using the second method with TSO CLlST,",Sugi-12-87 Ramotar.txt
"DCF consists of two component parts, SCRIPTjVS and GML (Gen- Integrating graphics into publications was a manual task, usually in~ volving paste-up, until we were able to combine SAS/GRAPH~utput eralized Markup Language). SCRIPT/VS is the text processing pro- gram. It processes a [tIe of text and typesetting commands (markup with our text documents. We now produce quality documents (man- or control words) to produce a page output fIle for the printer being agement reports, newsletters, papers, and documentation) using IBM's used. If only SCR IPT IVS was used, you would need control words Document Composition Facility (DCF) and the IBM 3800 model 3 to specify each detail of the document. GML functions as a macro laser printer. The key to integration lies in the use of Page Segments, facility for SCRIPT/VS. GML markup consists of tags that result in which can easily be produced using SAS/GRAPH once you know several SCRIPTjVS commands being processed. GML comes with a how. This paper will present the techniques involved in a compre- starter sct document profile designed for general documents. Many IBM manu'als are done using this facility, so the appearance should be hensive document, which should' eliminate most of the work involved familiar to you. in gleaning the necessary infonnation from the multitude of manuals provided by IBM and SAS Institute. The SCRIPTIVS command used to include graphics in the text stream is the Segment Include (SI) command. The graphic must be stored in a Page Segment library, such as NSYS I.PSEGLIB N Usually the page .",Sugi-12-88 Mathews.txt
"Ronald P. Tymcio, Intermountain Research Station ABSTRACT: The Universal Transverse Mercator UTM coordinates are planimetric and are (UTM) grid is used to reference all forest data continuous except for small breaks in the easting collected in the Rocky Mountain States by the scale between zones. UTM coordinates are the USDA Forest Service, Forest Survey P£oject. fundamental map reference system used by the USDA Display of these data with SASjGRAPH mapping Forest Service, Forest Survey Unit in the Rocky Mountain States (fig. 3). procedures requires a conversion of UTM coordi- nates to geographic coordinates ~latitude and longitude). In this paper a SAS DATA step is given for conversion of UTM to geographic coordi- MONTANA nates. Also given are examples of Forest Survey maps using the SASjGRAPH with converted UTM data. INTRODUCTION DAHO WYOMING The Universal Transverse Mercator (UTM) grid is a map reference system for almost the entire world (USDD 1973). Only the North and South Poles are NEVADA lITAH geo~raphical COLORADO excluded. The grid consists of strips or zones 6 degrees in width (fig. 1). UTM GRID ZONES MEXIC ARIZONA Figure 3--The Rocky Mountain States. All forest land sampling done by Forest Survey is referenced to the UTM system. An initial 1 000- meter UTM grid is marked on U.S. Geologic Survey maps to identify forested land and ownership ·.. categories. Then field locations are subsampled from the 1 OOO-meter grid sample for ground observation and measurement. By",Sugi-12-89 Chojnacky Tymcio.txt
"ning of the 2-D pattern, quantification of the spot (protein) data, It is theorized that a comparison between the protein databasing, and terminal display. The terminal composition of normal versus cancerous tissue display system is based on a MASSCOMP may provide a clue to the underlying cause of the microcomputer which can display images from cancer. 2-Dimensional (2-D) Gel Electrophoresis the database in a variety of ways. While acceptable provides a method of separating the proteins for for visual display the system does not produce each tissue into a 2-D map. called an any hardcopy output, which is a serious drawback. electrophoretogram. Examination of the map for Also, the system does not allow overlaying in a a normal tissue overlayed onto that of a cancerous manner useful for our scientists. In addition, there tissue is critical to this research effort. A are frequently over 1000 spots or proteins in a commercially available microcomputer-based system sample and a relatively small screen display can can analyze 2-D gel electrophoretograms, scanning hardly provide the resolution necessary to determine and quantifying each protein in the map. differences between the proteins of cancerous and normal tissues. Unfortunately, some aspects of this sytem are unsuitable. However, one can produce an output file containing descriptors of all the spots on a The system, however, can compute various indices map and then process it with Version 5 SAS software on each ""spot"" which de",Sugi-12-90 Lajiness.txt
"with the same name as the macro that Is 3 A flexible mean-standard error plot accessed. macro program was developed using the HILOT Some initialization of the data is and HILOe options in PROe GPLOT, Version 5. required. A variable TRT_TPLT must be added Using these options t the means of two to the data one wants plotted. treatment groups can be plotted with standard error bars so that the bars do not interfere Treatment or Response (1): TRT TPLT='A'; wi th each other. This is true even If Treatment or Response (2): TRT:TPLT='B'; treatment means crOSB at any point In the plot. The macros are demonstrated with two After the data has the variable biological examples. ·Furthermore, possible ""TRT PLT"" as a member then nine ""%LET""'s have modifications for this macro program are also to be initialized. They are: discussed. %LEt YVAII.- or Y VAll.WU ImRES'I' [Sec. 1]",Sugi-12-91 Sullivan Yuh.txt
"A means of predicting and graphically illus- river discharge, wind direction and speed, etc.) were compiled for the same time period. The trating degraded water qU~ity in estuaries was developed using various SAS statistical procedures environmental variables were assumed to poten- and SAS/GRAPH software. Expected water quality tially impact the water quality conditions over conditions, as represented by a series of discrete the area in question. Input from point sources and identifiable ""pollution profiles II , are was assumed constant. illustrated with GCONTOUR and G3D. Geographical Briefly, identification of the major re- orientation is provided by configuring SASMAP data current profiles was accomplished by clustering sets as ANNOTATE data sets and overlaying with the units of time for which the spatial pattern of data-generated pollution isobars or response coliform levels throughout the bay system was surface. Mean conditions for each discrete similar. Seven such dominant profiles were profile are i11ust,rated, along with standard obtained for the Barataria Bay system. Each profile was then characterized by the conditions, errors. This allowed easy identification of potential ""trouble zones"" of consistently high both environmental and water quality, present pollution levels, plus areas with high variability during the time periods which clustered together. which may require concentrated sampling efforts in The idea was to then discriminate between the the future. pollution profiles on the basis of the environ- mental conditions that were associated with them.",Sugi-12-92 Millard Moser.txt
"Bvolution of a Plot Chris Potter Syntex Laboratories, Inc. A picture may be worth a thousand words, but it is a Graphics may be used to: rare picture that can adequately describe a thousand word set. We often assume that a graph or plot of Show the structure in the data data will automatically convey our message. Summarize large amounts of data However an inapproprla te or poorly designed plot Demonstrate how things are connected may raise more questions than it answers. Bffective Show organizational relationships graphics must be designed to communicate. I hope to Provide advertising show some of the ways that this communication can mustra te training be assured. Communicate ideas Display humor In this paper I will be discussing: Set up a situation or feeling 1. The purpose of graphics. In statistical graphical analysis the plot is generally 2. Knowing your capabilities. used to show the structure in data. In Figure 1 the S. Typical Chart Errors. four sets of data are almost indistinguishable when 4. Effective Chart Design. their linear models are examined. However, the plots S. Chart;unk, data ink, and the lie factor. clearly show the different structures. 6. Steps for creating a plot. "" '"" "" Before continuing, I should mention an excellent x x ---- reference book on this subject: The Visual Display of ~--~- H.n HJ~ 10.0 9.14 1f1.0 7.4<> ('.SH l(I,n Quantitative Information, by Edward R. Tufte, H.II 6.95 HJ) 6.71 H.14 loUl H.n 5.76 Graphics Press. Several examples and definitions 7.5K 13.11 13.0 13,0 H.74 12.74 tW 7.71 were obtained from this source. In addition examples 9.n 8.81 9.0 9.0 7.11 lUi 8.84 '.77 8.33 Illl 9.:!<t 11.0 7.81 11.0 of typical chart errors were taken from an IBM 8.47 '.0 14.n RH4 9.% 14.0 7{l4 14.0 8.10 8.0 reference manual ""Pointers on Effective Chart 7.24 0 .· 6.0 fi.OH (,,(J 6.13 H.n 5.25 Design"". Unfortunately I have no other information :uo 4.2(, 4JI 4.0 4.0 539 19.0 12.50 on this manual. J2.o toM 5.5(' 9.13 12.n IUS 12.0 lUI 7. 4.M2 7.",Sugi-12-93 Potter.txt
"The paper introduces a SAS macro that builds a frame' around the graph by repeating a motif along the edges of the graph. The frame motif can be chosen from 101 predefined motifs available for the user! The user can also define his or her own favorite motif by setting up a simple annotate-like data set. Another macro enables the user to select sections of the frame and to move them to a new location. Utilizing the latter macro, nested mul- tiple frames can be created, or smaller F 9ure parts of the graph can be framed. display area. When that data set is",Sugi-12-94 Felsovalyi Felsovalyi.txt
"t College, University of Maryland phenomena present in and around the system under ABSTRACT study. The development of a computerized approach to display environmental data in maps can provide Often there are no readily available tools which an important tool to those interested in the provide the analysis and repres,entation of en- analysis and representation of environmental vironmental data in a form desired by the data. Once the domain of cartographers or individual investigator. Conventional tools, skilled graphics design personnel, customized such as one of the many statistical packages, maps are now available to anyone with access to which provide standard tabular or graphic output the graphic capabilities provided by the SAS· (e.g., a correlation matrix or an X-Y plot), are System. This paper is a howwto guide for those used and often provide less than desirable interested' in producing specialized mapping results. When an accurate depiction of data in programs. The example presented is a mapping a map is required, one solution is to consult system developed to represent environmental -data with graphics design personnel or a carto- on the Chesapeake Bay. CHBSMAP was written grapher. This may prove to be time-consuming or costly. Another alternative is to acquire a using the macro facility features of SAS and the graphics procedures of SAS/GRAPH*. The user is generalized Geographic Information System (GIS) which produces high quality maps. ,However, only required to cr",Sugi-12-95 Jacobs Swartz.txt
"has been developed that allows their plots to such a metafile. These two drivers SAS/GRAPH users to output plots in ISSCO's metafile accomplish this and can be selected in both batch and format. This interface allows increased portabllity for SAS interactive modes. graphics output, as well as the possibility of taking The Linkable-based driver advantage of a site's existing local and ISSCO-related software. The program was written in FORTRAN and has The Linkable driver is written in FORTRAN 77 and uses two versions. The first uses SAS's Linkable driver, while the Linkable device driver described in the SAS/GRAPH the second uses its Metagraphics driver. installation instructions (Ref. 1). Its use is restricted to IBM The Linkable version provides for 15 colors and is systems. The code to create the load module on an OS applicable only to IBM processors. The Metagraphics system is included here in Appendix A. If a load module version can handle up to 256 colors, has potentially more named DISSDMF were created and made available to the SAS system, then it would be invoked by specifying capabilities (such as more dense shading), and is DEVICE~DISSDMF on the GOPTIONS statement. Plots applicable to VAX machines as well as IBM machines. Aspects of installing the Linkable version at an IBM OS are output to a file in a metafile format. site are discussed. The implementation of a seven-color Metagraphics version for the VAXNMS system is The features of the Linkable-based driver include",Sugi-12-96 Ball.txt
"SAS/GRAPH*: Data Analysis, Presentation Graphics, or Pretty Pictures? Paul Marsh, North Carolina State University The use of graphic displays to ensure Table 1 accurate data analysis (see Table 1 and -Four Bivariate Relationships Exhibiting Figure 1) is an integral part of the the Same Summary Statistics field of Statistics. As computer II III IV hardware capabilities in this area I increase and software providing this X Y X Y X Y X Y --------- --------- --------..... -------- service becomes plentiful, these machines are becoming increasingly 10 8.04 10 9.14 10 7.46 8 6.58 utilized to perform this vital task. 8 6.95 8 6.77 8 8.14 8 5.76 Much research is ongoing in computer 13 7.58 13 8.74 13 12.74 8 7.71 graphics, including how people interpret 9 8.81 9 8.77 9 7.11 8 8.84 visual information. While it is not 11 8.33 11 7.81 8 8.47 11 9.26 possible for SAS/GRAPH software to 14 9.96 14 8.10 14 8.84 8 7.04 decide for the user the best 6 7.24 6 6.13 6 6.08 8 5.25 illustration of the data, it is possible 4 4.26 4 3.10 4 5.39 19 12.50 for the package to provide documentation 12 10.84 12 9.13 12 8.15 8 5.56 that outlines examples of proper data 7 4.82 7 7.26 7 6.42 8 7.91 presentation and procedures that 5 5.68 5 4.74 5 5.73 8 6.89 implement those techniques. SAS/GRAPH n·ll ~.9 ~·7.5 should not only help the user present data (presentation graphics); but should correlation coefficient=.67 also provide the tools to illuminate equation of regression line: Y=3+0.5X information that might otherwise be overlooked (data analysis). This paper Figure I attempts to point out several Graphical Dissimilarities of Four shortcomings of the SAS/GRAPH software Bivariate Relationships Exhibiting and documentation, and to provide the Same Summary Statistics examples of how better graphics can be produced using the package. I II 16 Edward Tufte's classic The Visual Display of Quantitative Information [IJ states that graphical software should tt not only present information in a clear and c",Sugi-12-97 Marsh.txt
"AN INTERFACE FOR EPIC AND SAS"" SOFTWARE by James Lichtenstein This paper will describe an interface between SAS/Graph® Step 1: Fix the Inconsistency In Epic Version 3.1 - and EPIC Version 3.1 which will allow users to specify: = EPIC; GOPTIONS DEVICE The inconsistency lies in the fact that each of Phase 1 and Phase 2 has a labeled COMMON section named ASCII. in their SAS® jobs and get graphic output on their 9700 laser However the common sections have different lengths and printers. formats in different phases. When the phases are linked together First some basic information about the EPIC software: this causes a-problem. However the problem is easy to fix. There are_ three Phase 2 routines which declare Phase 2's ASCII EPIC runs in two phases. common section: Phase 1 implements Calcomp type calls which may be used ENDIMG, HDRFLD and P2DATA. in a high level language (Fortran. PUI etc ... ) to define a picture Simply change the name of the section to something else (I and outputs a Vector File as a result. There is control information at the END of this file needed by Phase 2. used ASCII2) in these three routines and recompile them into EPIC.VER31.0BJECT library or wherever you keep your EPIC Phase 2, using the control information and vectors created software. in Phase 1, creates a raster image in 9700 native mode suitable for sending directly to the printer. Step 2: Create GMAIN1 - The important point here is that the vector file is used by The following is my GMAIN1 routine: both phases and that Phase 2 uses information at the end of the file to tell it what to expect in the file from the beginning to that C MAIN PROGRAM TO ESTABLISH FORTRAN ENVIRONMENT point. c INTEGER FLAG And some basic information about the SAS Linkable driver: FLAG=O The Linkable driver implements a graphics driver interface CALL GINIT2 CALL MOONEW(FLAG) between SAS graphics procedures and external plotting software IF (FLAG.NE.O) GO TO 10 that conforms to Calcomp type calling sequences and g",Sugi-12-98 Lichtenstein.txt
"stitute Inc. Warren F. Kuhfeld, University of North Carolina ABSTRACT that may be hidden in their multivariate data. PROC VISUALS is designed to help you The goal of VEDA is to aid in forming hypotheses visually discover and formulate hypotheses about about the data's hyper-dimensional (hD) struc- structure in multivariate data. PROe VISUALS ture, even though we can only see in 3D. To do does this by constructing a window into your this, the graphical representation must multivariate data. Through the window you see a > respect the three-dimensional (3D) cloud of objects which data's hyper-dimensional geometry, represent your multivariate observations. You can smoothly spin this cloud in order to better r~spect > understand its 3D structure. You can also move the user's three-dimensional percep- tion, the window throughout the high-dimensional (hD) space, giving you insight into your data's hD the respect > structure. You do not use numbers, equations, wor~station's computation~l limits. or programming statements to control PROe VISUALS. Rather, you use single key-stroke, Of course, while we see in 3D, we can only draw highly interactive commands. In addition to in 2D, either on paper or on the computer introducing PROe VISUALS, we review previous visual exploratory data analysis techniques, and screen. The problem that all VEDA methods we suggest future directions. tackle is presenting hD information in a 2D plane, such that our 3D perception can under- stand the hD geometry",Sugi-12-99 Young Kent Kuhfeld.txt
"other form of data. This paper explores some of the practical uses of the loadm and loadd functions of USING DYMANIC LOADING the compiler under CMS. Both SASIC benefits and drawbacks are discussed, Dynamic loading and unloading is along with tlgotcha'slf which accompany accomplished using seven functions. These some uses of these functions. are: addsrch, delsrch, buildm, loadm, loadd, unloadm, and unloadd. INTRODUCTION The first two, addsrch and delsrch are used to create a search order for the Dynamic loading of both executable code LOADLIB's or DCSS's that you desire to and data as provided by the sAs/e runtime library can be used in a number of load a module from. valuable ways to augment the capabilities buildm can be used create a function of eMS, and to make up for some of the pointer from a character pointer which UNIX functionality which is missing in points to a load module entry point. the CMS environment. loadm is used to load executable code Three general reasons for using dynamic into storage. The function returns a loading will be discussed in this paper. function pointer which may then be used They are: ' to invoke the module just loaded. With loadm, you can load functions or entire modularity of code and data emUlation of UNIX fork programs into storage. providing user exits loadd is used to load data (non-executable code) into storage. The function returns a character pointer DYNAMIC LOADING, IN THEORY (char *) to the first hyte of the data. Generally C progr",Sugi-13-02 Newton.txt
"Developing Full-Screen SAS/C- Applications on the IBM® Mainframe Patrick Graham, SAS Institute Inc., Cary, NC count field and a number of attribute INTRODUCTION pairs. This paper discusses developing C language application pro- an order followed by an address and a Repeat to grams that perform full-screen terminal input and output on IBM® byte of data to be replicated up to that Address mainframes. The architecture of IBM terminal communication address. and the difficulty of interfacing to this architecture is presented. an order that specifies the coordinates Insert Cursor A library of functions designed to be called from C programs that on the display to position the cursor. addresses these problems is introduced, and examples of their use are given. Attributes Attributes specify properties for a field (and on dis- plays that support them, for a character field or an extended Unlike some other operating systems and hardware, IBM main- field). Different fields can have different attributes. Each field attri- frames and terminals do not support single-character unbuffered bute byte occupies a position in the display's character buffer and terminal 1/0. The common IBM 370 terminal architecture (the on the screen. (Every 3270 display has what is known as a char- 3270 Information Display System) instead maps each character acter buffer. Each position on the display maps to one position on the display to a storage area known as a character buffer in in the character buffer. Thus, a 24-by-BO character display has the device. The application program uses commands to send or a 1920-byle character buffer.) The field attribute is displayed as receive data from this buffer. The following overview is based on a blank and cannot be modified by input from the user. If ten fields information from IBM documentation. are defined in the data stream. ten field attributes are required, which means there are ten fewer possible data entry positions Overview of the 3270 Data Stream on t",Sugi-13-03 Graham.txt
"Stephen L. Maier? Inc. HADRON~ The task of interfacing any two languages requires a great deal of analysis to determine whether or not they conform to the same standard, and This paper addresses the interfacing obstacles and solutions if not~ just how the interface on both identified while developing a library onds is designed. This analysis must of 'C' programs to be used as a include the assembler code generated by subroutine library for a VS FORTRAN the compiler. Two items of interest program. The initial difficulty in need to be determined. the first~ interfacing program modules Ulritten in transition oL control :from program to these two languages is in the calling subroutine~ and second~ the method of conventions and the run-time transferring arguments or program environment. the task does variables from the program to the However~ stop basic language subroutine. Both the IBM VS FORTRAN not there~ differences such as data structures and compiler and the SAS/C Compiler conform format complicate the issue. The SAS/C to the IBM 370 linkage convention for transfer of control. so it is not Compiler addresses many of these issues through the use of a compiler option to considered an issue in this paper. generate independent code that can be The argument passing conventions do called from any host language which and are covered in detail in differ~ the following section. One other conforms to the IBM 370 linkage conventions. To complicate the issu(-.! problem that arises is the difference in envirorunent required by the turo even more ~ IBM ""s VS FORTRAN does not fully conform to the IBM 370 linkage languages which is discussed in the convention. The result requires a section on Run-Time environments. sophisticated interface library of the arguments themselves Finally~ subroutines which 'bridge' the passed from calling program to interface between the IC· functions and subroutine differ widely between the the FORTRAN main program. The languages and are discussed in",Sugi-13-04 Maier.txt
"K.~atts. 8001e and dabbaqe Inc ·· SonnyYale, CA 94086 INTRODUCTION Portabilitr fev ago. sfsteas ,ea~s 1 Progcaas written In C ace forrd"" .ainfraaes softwa~e beliewed easilJ conYertible to de~aDded .irtQally asseabl, othee enyiroDs. This process is language program.lng. ot~er not always tciylal. 50.e alternatives ve~e fev. and laden proqraas require extensiYe vith handicaps_ FL/l and Pascal revork before theT finallT work have been tested replace.ents. as planned. is we de.elop-anT C The sitaation hdS briqhtened progea.. there is alvaJs the considerablY a5 C compilers haye ndqqinq vorey: ·Will it be Decome available. There is a art of portable?-. The chance we proqrd ·· e~s vill no proqra ·· laq portable software is lonqer be shackled to the blact indeed. Ldnquaqe~ library. level of direct ~acbiDe's and enyiron.eat coapatibilitr coaprehension. This paper is an are ter to all conversion dtte.pt to describe the author's efforts. proqress aloDq this journey. OBJECT-ORIENTED PROGRAftftIHG I have nuaerOU5 discoveries to Object-oriented proqra ·· laq share. Due to spacd limitations, eaised its head a decade ago. I viII focus on ] principal Yet. this cODcep't has Bot been the.es. each fundameDt~l to extensively utilized bl C productivity gains: progea ·· ecs. Perhaps with C it object-a~iented peogea ·· lng is too easy to hack out a developMent aftd debuqqinq aids solutioD~ and thus the noble progcda.inq foe portability. softvare engioeering force is deflected. Though this trpe of :1hject-ociented programming proqra ··ing reqoires auch tiae The environ.ent .ainfra~e and discipline in preparation~ enables C pcoqr~~minq on a very the eventual rewards are well larqe scale. Oesigning at this worth the effor~. Ovec ti.e an level tries the isagination, eItensiYe, cellable libeary of While posing m~nl orqanization softvare can be defined base challenqes. ~bject-oeiented upon which .anr products, tools, program.log helps focus design. dod aids caR spcout. It also leads to i.proved",Sugi-13-05 Boole.txt
"Writing Portable C Code: The SAS Institute Experience Richard D. Langston SAS Institute Inc. This paper illustrates how SAS Institute Inc. went the VM family, so the emphasis was placed on per- about converting a large software system from PL/I formance within OS systems instead of portability. and IBM® 370 assembly language into a new ver- Of course, the user community quickly recognized sion written almost entirely in C. The paper briefly the usefulness of the VM family and began an alle- discusses the history of so~tware development at giance to those operating systems that precipitated the Institute's need to convert the SAS System to the Institute, then explains the rationale behind the company's decision to convert to a new language. run under VM. From there, the Institute's experience in writing This effort was accomplished while maintaining portable software is discussed. In addition, the pa- the aforementioned hybrid of languages. Very little per touches on the development process the Institute used, including the adaptation of software coding PL/I code was added to support VM; most of the system modifications were to the supervisor. There- standards. fore, most modifications were m_ade in assembly lan- Let us begin by tracing the history of program- guage. The conversion goal was to change as small amount of procedure code as possible and allow the ming language usage at the Institute. SAS® soft- supervisor to recognize the environment and deal ware was originally implemented for OS-type oper- with its eccentricities, relieving the procedure writ- ating systems (MVT, MFT, MVS, VSl). The SAS ers to once again concentrate on their specialties. System was implemented using a combination of PL/I and assembly language. The assembly lan- guage portion was known as the ""supervisor"" and However, certain aspects of the VM operating system certainly made their way to the procedure was implemented as such for efficiency, speed, code writer's level. For example, the",Sugi-13-06 Langston.txt
"e &. Babbage, Inc. (panelist) Larry Sch1llll8Cher, Stagg Systems, Inc. (panelist) Keith Watts, Boole &. Babbage, Inc. (panelist) Carl Kass, SyncSort, Inc. (panelist) So PANEL DISCUSSION TOPICS 1. ABSTRACT Bo. BIggIa, This panel discussion will focus on the use of the SAS/CN compiler in the IBM mainframe ·C· - An MVS Systems Language 1 environment. The panelists are all experienced software developers and have used SAS/C in a wide 1. Background range of applications. The topics to be discussed span the spedrum of software development; from high-level system architectural considerations to Performance software design and development interfacing with system-level services provided by IBM and PCM marketplace the operating system. MVS, VM, and VSE Major lMS and CICS products Most products written in S/370 assembler 2. PANELISTS Assembler inappropriate for many functions Difficult to maintain and debug 1I.on IIIgIa is a Senior Scientist with Boole &. Babbage, Inc. He is responsible for the overall 2. Objective architedure, design, and development of certain Boole &. Babbage products. He has been an active participant in the GUIDE user group where he has Develop products in a high-level langnage held task force, project, and group management 3. Requirements positions. Ron has also published papers on a wide range of topics pertinent to large users of IBM Able to assume most assembler duties computing systems. Clean interface to other langnages Able to execute in any addressing mode",Sugi-13-07 Gimarc Higgin Schumacher Watts Kass.txt
"c....ALIAS 18 J ; long FUNc....5PECIAL-CASE; The SAS® System for the VMS'"" environment supports usef- long FUNc....R'LSPEc.....cASE; written functions written in Pl/I, MACRO, and C. This presenta- long FUNCJlIN....ARG; long FUNCJlAlL.ARG; tion provides an introduction to SAS user-written functions, with FUN~RG-'1'YPE; long an example, written in the C programming language, that extracts FUN~CCESLCOnE; long Job Process Information (JPI) without exiting the SAS System. long FUNc....RETURlLLENGTH; Jpt includes characteristics of a user process such as user name, ): account name, privileges, limits and quotas for system typedef struct FUNCDCL *FUNc...JlCL.J>TR; resources, and priority. This function serves as a sample to other users interested in writing user-written functions. It is not '* Tools for building tbe parameter types descriptor use */ intended as a complete implementation of the GETJPI service. /* CV(n) and NV(n) or'd together to build a longword *' /* containing the bit array used by the compiler where *' '* ""n"" is the number of the parameter (1-1Sj. *' INTRODUCTION 'def ine CHAR....VAR 1 Jdefine NULVAR 2 A SAS user-written function, like a SAS function, is a DATA step Ide fine VARTYPE (t,X) (t«{2*(x-l))) statement and is invoked the same way. SAS user-written func- ,define ev{x) VARTYPE{CHALVAR, xl tions provide access to frequently used, complicated computa- ,define NV{xj VARTYPE{NUlLVAR, xl tions with a single SAS statement, or you can make calls to an operating s",Sugi-13-08 Bizzell.txt
"RUNNING SAS® JOBS IN BATCH UNDER VAXIVMS Michael D. Rhoads, Westat user to set a maximum CPU time for the job, request Introduction notification at the terminal when the job has completed, etc. This paper presents a number of suggestions and techniques For example, a user has used a text editor to create a SAS related to running SAS jobs in batch mode on VAX program with a filename of MYPROG.SAS. S/he then computers using the VMS operating system. Specific topics creates the COM file MYPROG.COM, which contains the discussed include the following: combining all job output single command $ SAS MYPROG. (Note that, in a (VMS log. SAS log, SAS procedure output) into a single commmand procedure, each command line must begin with file, changing the default directory, displaying process a dollar sign.) To snbmit MYPROG as a batch job, the user quotas, using multiple versions of SAS software. and then types the following line at the tenninal, after receiving displaying the total turnaround time of thejob. Most of the VMS dollar-sign prompt: these tasks are accomplished by using small, modularized subprocedures, which can be called from the user's main $ SUBMIT!NOTIFY!CPUTlME=OO:OS MYPROG command procedure. The paper concludes by presenting a generic command procedure that may be used to submit any batch SAS job. Batch Job Output VMS batch jobs produce log files, which contain such items Why Run Batch Jobs? as accounting infonnation and messages returned by DCL commands. This log file also contains any outpnt written by In this age of interactive computing and the SAS Display a program to the defanlt outpnt file (SYS$OUTPUT). Manager. running jobs in batch mode might seem to be an anachronism, belonging to an era of vacuum-tube These batch job log files are initially written to disk as the computers, machine-language programming, and punched batch job executes. By default, the log file is printed and then deleted from disk as soon as the batch job completes. cards. Despite i",Sugi-13-09 Rhoads.txt
"2 AN INTERAcrIVE/BATCH SAS i ENVIRONMENT UNDER VAX/VMS Thomas J. Scott, Ph.D Spring Hill college INTRODUCTION Each user's available memory is controlled For many small colleges with limited computing through several ·Working Set"" parameters. resources, choosing a statistics program is These parameters are defined when the user's often a real compromise. Certain faculty account is generated and can be changed prefer one program, often being quite vehement downward by the user himself. The three main about the lack of merit of other products and parameters are called WSDEF, WSQUOTA, and offering nothing but praise for their favored WSEXTENT. product. Computing center directors usually solve this problem by ultimately providing more WSDEF is the default amount of memory given to than one package. a user process, and Digital recommends that WSDEF initially be set to 200 pages. WSQUOTA Such has been the case at Spring Hill College. is the amount of free memory initially given to The litany of statistics programs licensed a~d a process that needs more than WSDEF pages of tested for at least one year reads ""SPSS · memory. VMS always tries to give a user SPSSX3 · MiniTAB4. SAS PC I J SAS VAX III . After process WSQUOTA free pages if it requests them. four years of effort, we now use only the VfX DEC recommends that WSQUOTA be set to at least for statistics, and provide SPSSX. base SAS · 500 pages. SAS ETS1, and SAS GRAPH 1 . WSEXTENT is the ""credit limit"", so that a This paper describes the VAX/VMS performance process gets WSEXTENT pages if it asks for them issues involved, and then describes our and free memory is available. If not enough solution to running statistics programs on a free memory is available, then the request for heavily used VAX system, while attempting to the additional pages beyond WSQUOTA is denied. keep other users' performance at an adequate DEC initially recommends that WSEXTENT be set level. at least to 1000 pages. VAX software programs need differ",Sugi-13-10 Scott.txt
"ALTERNATIVE DESIGN FOR CORPORATE INFORMATION SYSTEMS BASED ON THE SAS SYSTEM* John G. Lord, Jr. Pawtuckaway Mountain Institute should show what is going on for meaningful Introduction groups such as territories, regions, customers-types. Many companies have existing information systems that collect large amounts of data about 3. Point out exceptions - Final series of· their business and are used to produce reports data should indicate either exceptions to with that information. The systems referred to norms or situations that exceed well defined are those that have evolved over time as the (but modifiable) values. company has grown and its information needs have grown. The systems serve as repositories of Information systems should not produce listings business transactions which are used to produce The volume is usually too of all transactions. either lists of customers and/or reports about great and the individual numbers are usually the current status for those customers. The only meaningful to staff who know the individual problem to be addressed here is that many times situations personally. these reports get to be so voluminous that the If these reports are well-designed~ they system becomes too cumbersome to serve the should cause the reader to ask a set of well- reporting needs of the company. defined questions or at least ask for a finite amount of additional information which should Hypothesis explain the aberrances seen in the previous reports. Some of these questions can only be the volume, complexity and Because answered by contacting the customer and the volatility of the information needed to manage system has served a valuable purpose by many of today's companies is so great, systems directing the user to interview the right must be designed to produce a manageable volume people. of information--- to indicate where people who In general tenms~ what should happen is that understand and operate the business should focus after reviewing a series of rep",Sugi-13-100 Lord.txt
"LES ABSTRACT A SAS based data management system in a mUltisite clinical trial environment has benefited from the development of a SAS code generator implemented in the dBase 111** programming language. A code gener- ator is a program that generates other programs or portions of other programs. SAS PROGRAM TEMPLATES It can play an integral role in the auto- mation of a production system where a series of similar programs is needed. System input is extracted from existing ASCII word-processing files and a menu Figure 1 driven data entry system. The output of the system consists of a series of ASCII THE PROBLEM files that include SAS dataset INPUT specifications, variable labels, macro A large proportion of programmer time was variable assignments, and repetitive SAS spent generating the rote SAS code located macro invocations. Benefits of the system in the %INCLUDE files associated with each include greatly reduced programmer time form. (Larger forms required over 6000 spent keypunching rate SAS code, increased lines of code in the %INCLUDE files.) data and p~ogram integrity, and more With an ever increasing number of forms easily maintained programs. The system requiring processing, it became desirable has also facilitated efforts to work to reduce the programmer time necessary around a SAS compiler capacity limitation. for this task. Some of the larger forms were incurring a BACKGROUND SAS Error 344. On the IBM 3090 under OS, this error results from a SAS internal This paper",Sugi-13-101 Branagh.txt
"erating system; a variety of VMS and Unix~ based MicroVAXs~; and the Cor- Researchers that use secondary data files, such as nell National Supercomputer Facility's IBM 4381 those produced by the Bureau of the Census, face R14 and IBM 3090-600 with attached array proces- the problems of obtaining information about the sors. contents of such files and of formatting these diverse Consulting on the use of files in the CISER Data o files for analytical evaluation. A data archive is Archive and computing consulting is provided by charged with the responsibility to maintain and CISER provide access to the data. An electronic informa- o 'Mainframe' system developments include: tion and data retrieval system would seem an ideal o eMS Utility Panels (ISPf'M) interface between a data archive and its users. o OASIS [Online Archive Statistical Information System] Phase I (Data Retrieval System) An information subsystem might allow users to Phase II (Information Retrieval System) obtain information about the databases by browsing or entering specific characteristics of interest, obtain- The Problems ing information about which data bases contain such information, inform the user about the specifics of There is no one standard format for files distrib- o each field or variable in the database, and indicate uted by governmental and other agencies. The data any problems with merging disparate databases. A files are frequently organized in a hierarchical data retrieval subsystem could let the",Sugi-13-102 Boggess.txt
"RACT SQL*Plus or SQL*Calc can be used to generate This paper describes the combined usage of simple reports. For complicated reports with ORACLE and SAS to present adverse experience (AE) variable numbers of columns or/and rows, PRO*SQL data for large clinical trials. Large-scale may be used. trials are characterized by the large c~inical volume of data which is collected from multiple CLINICAL TRIAL DATABASE centers with different study designs. The majority of the database usually consists of CI inical Trial is defined by S. J. Pocock information related to safety'. Among all the as: safety data collected, adverse experience is some r~I!::.rm~~a~ T=~ii!: of the most important i nformat i on correspond-i ng to the safety of a patient. Adverse experience awropriate II1iSt · elUCIdate data collected on case report forms includes at treatment of futu~. pW>lentS WIth a given ne:lical corditlon . . . least the following: date/time of the occurrence, severity, course, duration, There are three main phases of relationship to the study drug and the experimentation in a clinical trial before any description of a particular adverse experience. Investigational New Drug (IND) can be fi led as a Adverse experiences can be presented in many. New Drug Application (NDA). Phase I experiments different ways. Most commonly, they are grouped are usually performed on healthy male volunteers by body systems, and the number of patients between the ages of 18 and 45 to study the reporting these AEs",Sugi-13-103 Chang Pun.txt
"SASjAF software has many changes, including the format, appearance, and actions of AF program screens. A program screen that in Version 5 had a display, attribute panel, and possi- Because of the many enhancements available with Version 6 bly an associated list screen can now have many more panels SAS/FSp<!!I and SAS/AF® software, all Version 5 SAS/FSP and associated with it. Screen 1 shows some of the screens that can SAS/AF applications need to be converted to Version 6 format be associated with a program entry. in order to be run on a Version 6 system. This paper explains the steps of a conversion and its results, as weH as new Version 6 features for enhancing Version 5 applications. Also discussed are +BUILD, --------------------------------------------+ DISPLAY BOOKEX.PROGRAII (BI the CPORT, CIMPORT, and DOWNLOAD procedures available IC=~nd ~~~> I ""TTR BOOKEX.PROGRAM (B)------ ------------------------ -------_______ + ~BlIILD: I with base SAS software. Conversion of SAS/AF program screens I I Command .. s> I I I fBU11.D: GAUR BOOKEX.PROGRAM (B)--------------------------------------- ___ + from Version 5 format to Version 6 format is examined in detail, I I ICommand ___ > I fEnrLD: SOURCE BOOKEX.PROGRAM (B) --- ___________________________________ + II including the various conversion options. Icommand _~:> II I BOOKEX.PROGRAM (E)----- ----__________________________ + I +BUILO; II EDPA~MS I I Command E<~> II I II I I fBUILD: LISnTTR BOOKliX.L!ST (5)------------- -----------------------i I I ICommand ___ > II I",Sugi-13-104 McGrath.txt
"UPGllADlNG USR-WJUTTEN PROCEDUIlES rOil VZIlSION i s~ sorTW.um A. USR'S PEIlSPIlCTIVE Richard L. Gimare, Boole .II; Babbage, Inc. Furthermore, there is a SAS System document L AJlSTIlA.CT ISAS86bJ which descn""bes user-written SAS proced...... contributed to, and distributed by, SAS The oerviees provided by the SAS System for Institute. user-written proced...... were significantly enhanced in version 6. Although pre-version 6 proceduree Due to the change in the style of user-written still execute under venion 6, the new version proceduree in venion 5, there have also been several provides the procedure writer many new services. papen presented at SUGI conferences by SAS Thill paper describes the author's experience Institute penonnel descn""biDg how to write a upgrading a user-written procedure. Special procedure in the version 5 style JBetan85J (Park86J emphasis will be placed on upgrading custom [Thnen87aJ [Thnen87bJ. procedure statements to the version 6 style. These paper!!, along with [SAS860I, provide an 2. INTItODUCTlON excellent set of reference material on version 5 user-written proceduree. However, there are some EJdenoJ1>ility is a term that charaderizes the SAS notable deficiencies: System. What this means is that the SAS System provides documented interfaces which can be utilized 1. An the paper!! have been presented by SAS to expand the capabilities and functionality of the Institute penonneL There has not been a paper One of the methods available for SAS System. presented from a user's penpective. extending the SAS System is user-written proceduree. These proceduree are invoked with the 2. There is no record of experience regarding famiIar PROC statement. Other procedure upgrading pre-version 5 proceduree to the statements may be used depending on the design of venion 5 style. the procedure. 3. The Implementation of non-list type (custom) There are several reasons why you might choose to procedure statements has not been fully psckage your code in a us",Sugi-13-105 Gimarc.txt
"this form of call. You must write the resulting data to another file and read them in using the SAS language. In the SAS log, the SAS supervisor prints the return code from the called program. During many SAS® applications it is often more convenient and If you need to return results directly to the SAS DATA step, con- efficient to perform TSO or system functions while still in the SAS sider writing a SAS function or CALL routine. environment. This paper offers tips on running external programs or commands and demonstrates techniques for submitting batch For example, the following program demonstrates how to modify jobs from within the SAS System. It also describes several meth- all or selected members of a POS library. First, PROC SOURCE ods of testing return codes and explains the relationship of the unloads the POS into a temporary sequential file. Then the DATA SAS environment to the ISPF environment. The discussion step reads each line, makes the necessary changes, and writes focuses on tasks that can be completed using base SAS soft- the line out to a second temporary file. The PROC statement then ware. calls IEBUPDTE to load the modified sequential file back into a POS. You can accomplish the same sequence of events by exe-",Sugi-13-106 Brinsfield.txt
"OF THE PROBLEM ABSTRACT Don't you just hate it when they say it can't Material estimating becomes a problem when be done · · · and you have a week to do it? the calculations required to provide the es- Tbis Material Estimating (MEST) System was timates are so complex or so numerous, that developed under critical time constraints due even if manpower limitations were not a fac- to user requirements for the product. Addi- tor, dozens of analysts/statisticians would tionally, it suffered from the oommon dilemma be required in order to complete the request of flexibility VB. applicability and ease of in the time allotted (turnaround is generally use for non-computer-oriented technical per- very short). With an RFQ on the doorstep, management requested an automated solution. sonnel. These problems were resolved utiliz- ing a combination of PROG TABULATE, PROC FSEDIT, a few macro variables, some well-placed DESIGN CONSIDERATIONS screen massages, and eLlST menus. (Note that SAS/AF® was not available at the time, but One deSign factor is the way in which the could easily be used here to replaoe the eLlST data must be presented. It may be necessary menus and other se1eotion functions). to provide an estimate for an entire air- craft, by sections or by material categories, or for a wing section only, or fUselage only, BACKGROUND etc. We wanted to provide enough flexibility Among many other functions, the Materiel Organ- so that the system could be used ror any ization of the Northrop A",Sugi-13-107 Cermack.txt
"USING SAS@ TO MiET BUSINESS PROCESSING NEEDS IN A MAINFRAME ENVIRONMENT Lynn M. Huckert, Freddie Mac Mary G. Pulling, Freddie Mac George P. Riner, Freddie Mac INTRODUCTION NT then sent the conversion form to the We represent a corporation that purchases Commitment Processing Office (CPO). A mortgages from savings and loans, contract was generated along with loan commercial banks, mortgage companies and numbers to identify individual mortgages other lenders~ These mortgages are pooled under the contract; these were then mailed and interest in the pools is sold to to the seller. The entire cycle: investors in the form of securities. The processing the request, obtaining the end result is increased availability of contract, and mailing the contract to the mortgage financing for the average seller took three days minimum, with potential homeowner. A large percentage of multiple opportunities for mistakes and mortages are purchased according to terms delays. Among the drawbacks: laid out in a Master commitment contract. Master commitments are long term agreements o Manual files would be misplaced or not between Sellers and Freddie Mac which updated with the latest amendments specify programs, prices, waivers, and other options under which loans may be o The MA could be away from his desk when purchased or swapped by the submission of a NT needed information about a deal in conversion. The Master states a dollar order to continue processing. amount to be delivered, a time-frame in which the mortgages are to be delivered, o The panafax machine malfunctioned. and various requirements and options for delivery. o Mail was not shipped out, delivered on time or was lost. Before implementation of the system that we will present today, the process of The Master Commitment System (MeS) was accepting commitments to deliver under a developed to automate this process, Master was for the most part, manual--a resulting in improved customer service, process that required much paperwork",Sugi-13-108 Huckert Pulling Riner.txt
"the data were (and are At Novacorj AGEe. three process-control still) available, as a series of monthly tapes: computers are used to automate the one set for each calendar month for each production of a world·scale petrochemical plant. The number of data-points in each manufacturing facility that consists of two month's file would vary from 1.2 million to ethylene plants and one polyethylene plant. more than 11 million, depending on which They have to deal with readings on some plant had transmitted the data and the time 20,000 tags (variables) per hour. An hourly, at which the tape for the next calendar running record of these measurements is very month was initiated. Each data-point is a useful in day to day and longer term single hourly average of as much as one planning, engineering and management reading every six seconds, and has attached activities. to it the name of its tag and a date and time-stamp. There are as many as three In order to manage the storage of the large tapes for each month's worth of data, for volumes of data involved, this process each plant. information is transmitted on an hourly basis, around the clock, to a remote mainframe running MVS and TSO. There it Selection of data from the tapes is costly, is collected and periodically moved into a set and the cost is relatively independent of the of SAS data libraries, using parameterized amount of data actually selected. After SAS macros. These data libraries are part of selection. additional non·trivia",Sugi-13-109 Mahoney.txt
"Commercial distribution of UNIX operating systems began around 1977 with the release of the Programmer's Work Bench. The use of SAS!!» software as an application solution for the In _1981, Bell Labs released UNIX System III, which combined UNIXI6t environment is presented in three parts: an overview of some of the features of PWB/UNIX and Version 7. Momentum UNIX operating systems, a discussion of the fundamentals of for AT&T's interest in UNIX operating systems increased as com- UNIX operating systems. and a tutorial on using SAS software mercial products flourished. However, in January 1983. the in the UNIX environment. United States Government announced its proposed Modified Final Judgement, which ultimately brought about the dissolution",Sugi-13-11 Zeigler Betancourt Kelly.txt
"mewhere down the line (e.ge, the ABSTRACT reported information needs to contain greater detail). That change would have This paper describes a system of SAS* Macros for checking and editing errors in to be made in as many places as the total research data. Representative applica- number of individual checking routines tions involving inter-item consistencies that were written. and skip patterns are illustrated. The Macros are contained in a SAS AUTOCALL The Macro Facility provides SAS program- library and constitute a key component of mers with a tool to parameterize (see also the File Update System (FUS), a SAS-based Reges, 1987) the error check and thus make data management system developed for the a piece of SAS code that can be used for Infant Health and Development program. different inter-item consistencies: Advantages of using the Macro Facility in this context are structured modular code 1 'MACRO iicck(condl-,cond2-,iicvarl-,iicvar2=); resulting in efficient software mainte- IF &condl AND &cond2 THEN DO; 2 nance. Potential dangers are compiler 3 PUT / recordid-"" Inter-Item Consistency Error"" overflow problems and SAS programs that Condition l~ &cond.l AND "" 4 /"" Condition 2: -&cond2 .. 5 / .. are difficult to read. Variables involved: "" 6 /"" 7 /· M &iicvarl- &iicvar2- e+l, iic+l, 8 9 END; STRUCTURE AND FUNCTION OF ERROR CHECKING 10 'MEND Hcck; MACROS Example 2 When processing research data it is im- portant to ensure the quality of the data We can then provide meat to",Sugi-13-110 Pechler.txt
"btain a therapeu- ABSTRACT tic effect. Once sufficient information is gathered and hypotheses about the The pharmaceutical indust-ry, in conjunc- drug1s efficacy in var10US indications tion with the Food and Drug Administra- tion, has been experimenting with ways of have been formulated, large scale Phase III testing in human volunteers begins. using computer technology to facilitate and accelerate the process of introducing The research process takes five or more new drugs to the market. Some of these years. Throughout the process additional experimental approaches include information is gathered concerning the ""electronic1t NOAs (new drug applica- safety of the drug in both humans and tions), remote data entry, and computer animals; the stability of the drug (how assisted monitoring of clinical trials. long it can remain on the shelf without The SAS system has long been the standard degrading); and the ability of the com- pany to manufacture the drug in software used in the pharmaceutical production quantities. industry for performing statistical anal- yses on clinical trials data. However, When all the required research is com- the SAS system has capabilities that go pleted, the drug company submits its far beyond those of a statistical pack- information to the FDA along with a age, which make it an excellent choice request for permission to market the drug for these new applications. Since most in specified diseases. This registration pharmaceutical companies already have",Sugi-13-111 Rosenberg.txt
"AN INTEGRATED CLINICAL DATA MANAGEMENT SYSTEM AT ALLERGAN, INC. Jeff S. Kouba, Allergan, Inc The Process INTRODUCTION A diagram of the Clinical data entry Allergan, Inc., a subsidiary of SmithKline Beckman Corporation, located process and a description of each step in Irvine, California is involved in is provided below: the research, development, manufacture and sale of ethical drugs and devices. Allergan specializes in CRFs received ophthalmologicals, contact lenses, ! contact lens solutions and dermatologicals. Keypunch instructions written and data keypunched As manager of a programming support group for Allergan Research and ! Development efforts (deemed R&D SAS Datasets generated Scientific Information Services), my responsibilities include support of the R&D Data Management department which Usting programt written and run ensures the integrity of clinical data, ! and of the Biostatistics department responsible for the analysis and Data errors corrected reporting of that data. OVer the ! course of several years in support of Final data signoff these activities, we have developed a ! series of integrated SAS* programs an our IBM 3084 under VM/CMS to manage the Audittrail offurther changes ever-increasing volume of clinical data and speed up the process which brings that clinical data from the Case Report Form (CRF) to a New Drug Application (NDA) or device Pre-Market Approval 1. CRF's are_ received by R&D Data (PHA) · Management after a preliminary These programs are divided into two visual check for errors and major areas: omissions by the Clinical Research Associate (CRA) .. This check 1. Clinical data entry and editing removes most obvious data 2. Standardized Table Generation omissions and deficiencies on the CRFs. CLINICAL DATA ENTRY AND EDITING CRF keypunch instructions are 2. written and data sent to an My discussion of clinical data entry outside service for keypunching. will begin with a short description of the data flow from the raw CRF to the SAS da",Sugi-13-112 Kouba.txt
"EXTRACTION FROM ENORMOUS SEQUENTIAL HEALTH CARE CLAIMS DATA FILES USING MULTIPLE FORMAT TABLES Nancy A. Fox, Pracon Incorporated Craig Ray, ORI, Inc. from enormous sequential health care Introduction claims data files. The format of health care claims data sets used for analysis The cost of medical care has become an and the types of fields to be extracted increasingly major concern among in each record are discussed. Advantages government, third party insurers, and disadvantages in the various methods business coalitions, private industry and available for data extraction of health the ge-neral public. Health care costs care claims are presented (the compara- have increased dramatically during the tive strengths of these methods were past two decades, creating pressure to previously discussed in the paper, ""A investigate and evaluate costs at all Comparison of Table Lookup Techniques,"" levels of the health care system. To by Craig Ray, in the SUIGI12 economically evaluate an illness, drug or proceedings).1 Finally, generalized SASe other medical innovation, it is necessary macros that perform the extraction using to assess the changes in the associated multiple format tables are described. costs and benefits. Research related to health care utilization and costs include Data Source the following types of studies: cost- effectiveness and cost-benefit analysis; Medicaid claims represent a record of quality of life and productivity studies; each health care encounter of program adverse reaction analysis; and epidemio~ eligibles submitted for reimbursement to logical studies. the Medicaid program. These data files include health care services from Research of this nature utilizes a wide pharmacies, physicians, laboratories, variety of secondary data resources. One hospitals and nursing homes. Thus, use of the most important data sources used of these data allow the tracking of is state Medicaid claims data. Detailed patients throughout the health care health Gare util",Sugi-13-113 Fox Ray.txt
"Option 2. Display Selected Fields By utilizing various SAS* software packages This option gives the user the ability to Merck & Company has designed and implemented an retrIeve specific records and list subpopu- information system for the Food and Drug lations of raw and derived variables. Administration (FDA) that can effectively be Option 3. DescriptIve Statistics · Computations used for the review of clinical data, submitted as adjunct to the hard copy of a New Drug Application (NDA). This option has three selections which perform the following computations: Frequency tables",Sugi-13-114 Bauer.txt
"Teaming SAS/FSpOOSoftwa_l'e and the SASOOMacro Language to AUow Data Base Maintenance and Report Writing by Nonpl' by M. Jill Trumper -. ........ j~ pletad .--ect ,theIIllSt ferable). After a f?el""i the aaster file avoiding J:r ~~:rd:ignation. type gram balow, the areas are assigned to a sent their position in the strUcture below! ~_ _ _ _ _ _ J 0 II' O..,.R_G_'_N_f Z AT etc. J09io Jo,io JO'fO DEPART,: HENT , - - : - r - -etc · I OOl4l Ol~1 OO~41 01to O SEctION r--r- I ..,. I I 'r""1~ ~.~ l A ' ett. atc. ~ ! ok. C AREA ID A 'OfANGES' FOR EACH DEPARTMENT FILE, i"" 1 1 COURSE 1. COUflSE 9.; 1. COURSE 9.; 'RPTREQ' FOR EAOt DEPARTMENT FILE; $40, .... A SAS 001 ibrary aiSt be allocated for each editing cIepartJMnt as BACKUP DATA SETS USED IN lATCH UPDATE J08.; vell as two backUp data sets, -also a l1tlrag for the taastel' fHe along _~n~1~' ~~~da:!·se~~ch.C m.OH~l~:e'ov~ MooBI.IIEF; DUr-LUlEF; diasifln. of corresponding JCL * CflUTION; · NOTE: ESTABLISHING DATA SETS IN DEPARTMENT FILE AND THE DATA ; . - - SETS IN THE MASTER FILE ; ~TlONS MPRIHT SYMBOlGEN; ; toSTDATA' ON EACH DEPARTHf:NT FILE; 'XMACRC .-- · ON THE MASTEII FILE. tIIen~~~:: Note: 1iIF "" DATA A; .edit apai)11tty. ~r.h'(PE' .. 2- ~H ..00' ...., Typa.2 ca 11 Ha""O for ..aster file only. D&UflIWSTR{. )HASd.; DATA r~:tH PART $11 DESCRtPT $188 Ell'GRGSlI' S3 AREA1-AREA8 $13 574  -- =ro:: (lYPE~~~UN¥~!I; ~s ~ should reflect tile keyvorcIparaHtt hard coded in progr.. - -1- __ TYPE _ 1 ,- - - - - - I ----- ?UE~TR(. )COSTPATA P f KEYS ···· RIIICTtDII key\fordparaIIe 'REF' - - ~;alpha =;tg~:~lu~l~ HI I I Pf'U ··· m dePartMnt I ~ rut::: 1I l0910A.COSTDAT"" I I'f4 !'fl···· , _____ k~ 'UNIV'- ____ TYPE _ 2 etc. I PtS f'f17 ··· I m;~, 11 ?&UtlIV1.STR(. )MASTER r.m ::: taCil tty;system code 1 I PA3KJ.MASTER Wto' WJ::: 1,_'_, QA3MJ.MASTER f'fll Pf23 ··· Pm ··· I'fl2 I tD0910A .UPOATE.A.CT01131, ~j ~j~ElETE),UNIT-SYSDA, j~80910"" -ierol131 ··· (actual depar1:aent f11e) ~~ TE) ,UNIT:$ySDA, II ) .·. (front end file backUp) IIL0910",Sugi-13-115 Trumper.txt
"a base access language of IBM's Systems Applica- ABSTRACT tion Architecture (SAA). SAA is the IBM blueprint for creating por- table programs that can run on all IBM hardware. This paper provides an overview of Structured Query Language (SOL) and its implementation in Version 6 of the SAS® System. SOL Statements The History of SOL There are six main statements in the nonprocedural component of SOL. The Relational Data Model, proposed by Codd (1970), represents data in tables. Structured Query Language (Sal) is a language SELECT retrieves values from data base tables used for accessing data stored in tables. The SAS data set con- that meet a user's specification. cept blends very nicely with the concept of a table in the relational INSERT inserts rows into data base tables. data model. Both have columns (variables) and rows (observa- tions). SAS data sets are a little more liberal than true relational DELETE deletes rows from data base tables. Generally a DELETE statement is model tables because they allow duplicate rows and have an inherent ordering. Nevertheless, they are similar enough to make qualified with an expression as to which Sal a useful language for accessing SAS data sets. The terms rows to delete. data base table and SAS data set are interchangeable in the con- UPDATE modifies the values of rows in data base text of this paper. tables. CREATE creates data base tables; views, and There are many commercial products that support SOL Early indexes. Sal-based systems",Sugi-13-116 Kent Church.txt
"COMPUTER AIDED NDA REVIEW A MICROCOMPUTER APPROACH Gary N. Griffiths, The Upjohn Company INTRODUCTION There were three obvious questions This paper describes The Upjohn to answer during the first phase of the project: Computer Assisted New Drug Companyt s Application Review, (CANDAR) system 1. How well does the the SAS pilot project which allows the analysis and review of large datasets, associated system for microcomputers download procedure work? with a new drug application (NDA) using a microcomputer. The original project 2. How fast is the download goal was to demonstrate that the results procedure? of analysis using SAS* software for the 3. How large of a dataset may be downloaded? mainframe could be reproduced using the SAS software for microcomputers and to The download procedure was used evalugte the performance of the SAS extensively in transferring mainframe so-ftware for ~icrocomputers using SAS datasets to the SAS system for various hardware configurations. As the microcomputers datasets; and in all cases, the download was accomplished project progressed, this goal was without any serious difficulty. In expanded to include the development of an ad hoc query system. particular t when the mainframe system broadcast a message to all terminals SYSTEMS DESIGN during a download procedure, the SAS system recovered without any difficulty. Since the specifications of the system were vaguely defined, at best, it was decided that the most successfully Table 1 below lists the size and approach would be to build a prototype download time for several mainframe SAS sys tern; and during its development, to datasets. involve professionals from many MAINFRAME DOWNLOAD disciplines in evaluation and feedback. SAS DATASET TIME IN This involvement of the potential users of the system provided much valuable SIZE IN MBYTES MINUTES ************* ******* -feedback and yielded excellent direction 0.17 to the project. 3 21 0.79 First a brief description of the 1.03 23 2.54 60 comp",Sugi-13-117 Griffiths.txt
"rce, Rahm and Haas Company James F. Koch, Rahm and Haas Company Paula D. Williams, Rahm and Haas Company ABSTRACT: how to use the application. Second, it helps to serve as documentation. Approximately eight The AeCIS computer system at Rahm and Haas versions of this SAS/AF scheme are used by the various screening groups at Rohm and Haas Company is an integrated information system used by the Agricultural Chemicals Group. It consists Company. of many computer programs, files, and databases Chemical Entry: spanning three computer environments designed to provide the user, either biologist, chemist, or manager, with information on the biological Users enter chemical structures and other chemical information into an-MS-DOS based activity -of 'queried chemical compounds. personal computer database using CHEMBASE. a INTRODUCTION: software package from Molecular Design Ltd. Worksheets containing other information are Rahm and Haas Company is a producer of a wide also imported into CHEMBASE after they have been range of high quality specialty chemicals. One manipulated using PC SAS programs. Daily, the of the major divisions within Rohm and Haas information in CHEMBASE databases is exported Company is the Agricultural--Chemicals Division, to a central database o'ri -the VAX us-ing a software a producer of fungicides, insec'ticides and package called MACCS from-Molecular Design Ltd. herbicides for the' world markets. Their The database package, MACC$, is 'a chemical Agricultural ""Chem",Sugi-13-118 Partelow Pierce Koch Williams.txt
ative efficiency FIQure 1: A List-Style Historical File (Usn of two ways of organizing historical data files in the SAS® system -- as lists and as vectors of events -- s.s.N M.QY 00 Y.AJ.. A.Q.I and presents the code for and a discussion of two 07DEC77 08FEB85 hire WG-2B92-08 009999999 useful variants of the SAS merge. These variants are 09FEB85 GS-1152-09 08NOV87 promotion 009999999 (1) the date merge -- for the look-up of status 09NOV87 31DEC88 promotion GS-1670-11 009999999 information from historical data files and (2) the cross 111111100 24JAN81 WG-3806-08 merge -- for generating the cross-products of 23SEP81 temp appt 111111100 BY-groups. The American Institutes for Research 24SEP81 020CT83 appt end [nulll has found these two merge variants to be of WG-3806-08 111111100 030CT83 29NOV85 hire substantial value. Their use has improved the 111111100 30NOV85 31DEC88 resignation [nulll efficiency of some extractions from large historical files by as much as 500%. Historical Data Files Figure 2: A Vector-Style Historical File (VECn Historical files represent dated events. They typically have a subject identifier and a date as the M.[lY.1 Q.ElS. s.s.N A.Qli YAll two values minimally required to specify a unique event. The subject identifier specifies the 1 WG-2B92-08 07DEC77 hire 009999999 individuals described by the file. The date specifies 2 111111100 24JAN81 WG-3806-08 appt the time when some action affecting a relevant property of an individual occurred. Additional M.QY2 .,Sugi-13-119 Lutomski.txt
"er for the Model 20 had allocated DASD for the SAS System and defined the system storage layout so saved segments could be installed, installation of the SAS This paper gives a brief overview of the IBM® 9370 processor System took approximately two hours. series and offers some observations about installation of the SAS® System in the eMS environment and its maintenance and The systems programmer for the Model 60 copied the SAS Sys- performance on these machines. tem installation from his mainframe system- to tape (via VMFPLC2 DUMP/LOAD for CMS minidisk files and DCSS BACKUP/ IBM 9370 PROCESSOR SERIES OVERVIEW RESTORE for saved segments). He estimated that for the SAS System only this process takes less than a day. The IBM 9373 Model 20 processor features In both installations, the speed of the 9347 tape drive was a signif- · one internal 110 bus that accommodates up to four 110 icant factor in the elapsed time. For those more familiar with tape controllers drives normally channel-attached to mainframe systems, the 9347 seems inordinately slow. · 4, 8, or 16 megabytes of processor storage The only SAS System maintenance performed was during instal- · floating-point facilities. lation of the SAS System on the 9370 Model 20. The IBM 9375 Model 40 and Model 60 processors feature SAS SYSTEM PERFORMANCE ON THE 9370 · a maximum of four internal 110 busses that accommodate up to sixteen I/O controflers SERIES · 8 or 16 megabytes of processor storage The series of tests run on both o",Sugi-13-12 Weathers.txt
"LINES The sharp division between the traditional technical require- ments of DP accountants versus DP system perfonnance ana- lysts compelled IBM to develop the SMF as well as the RMF log record types to provide alternative levels of system resource ABSTRACT measurement detail and precision. The SMF log records were provided by IBM to meet the functional needs of EDP auditors according to their job accounting functional requirements, and The use ofjob accounting to provide for nwre cost-effective sys- will continue to be their standard of choice for the forseeable tem resource management is a traditional function within both future. large and small host processing environments. Chargeback and DP cost accounting have evolved bared upon the business princi- The fundamental differences between DP accountants and tech- ples of management accounting and variQUS methodologies cur- nical specialists will undoubtedly always exist but the introduc- rently exist to support a variety of specific management objectives. The application of such methodologies to network. tion of the RMF log records, as well as other precision software monitoring tools to support advances in ePE technnology, gave processing environments, however, is sliD in the early stages of both accountants and technical professionals tools to support development. Network job accounting methodologies must rely management decision-making. ibis has also served to create equaOy upon statistical as well as traditional managem",Sugi-13-120 Jones.txt
"ABSTRACT We assumed two key ideas: Preclinical laboratory scientists often have a need for rapid statistical analysis 1. Laboratory scientists possess an of their data. Many of their experiments follow standard protocols and can be analytic approach to problem solving. They are not, however, classified into a few basic statistical designs e.g. to compare pre- and computer scientists or stati sti ci ans. Nor are they post-treatment responses, or to compare the effects of two or more treatments. The computer illiterate or statistically illiterate. They do laboratory scientist's need for rapid evaluation of his data requires him to understand the importance of distributional assumptions for perform some statistical analyses immediately following the experiment. In establishing the validity of their statistical inferences. this process, he may not test the 2. Much <about 80%) of the distributional assumptions of the statistical analyses that lab parti cul ar stati sti cal test he chooses. sci enti sts need is what a Failure to meet these assumptions can professional statistician might invalidate the inferences. call routine. PBS, an intelligent menu-driven system, was Thus, the goal was to provide a developed at Ortho Pharmaceutical user-fri endly system for the sci enti st to Corporation using SAS/AF and the MACRO perform his own analyses on the routine facil ity to allow 1aboratory sci enti sts to 80%. At the same time, we wanted tests for statistically analyze many of their r",Sugi-13-121 Altan Devlin.txt
"desired but often ig- The first principle in byte reduction is to know nored on mainframe computers, has become a your data. If we know the maximum absolute necessity for SAS® microcomputer users. This value of each numeric variable, and whether or paper examines how SAS data and ASCII files not that variable is decimal or integer, and if become larger than necessary, and provides we know the maximum length of each character numerous strategies for more efficient storage. variable, we are in a good position to construct more condensed ASCII data files and SAS data sets. I NTRODUCTI ON It is appropriate to begin with a look at the Although microcomputer hard disks and floppy ASCII data file, LAB.DAT -- data files like this disks continue to grow in storage capacity, byte are often the start of most SAS processing. shortages continue to be a problem for microcom- figure 1 shows a partial listing of this file puter users. Large and numerous files result in for patients 409 to 510. Visual inspection of these data shows that there is probably more a lack of space to store files, space between variables (which are column reduced performance of software, specific) than is necessary, and some lengthy including job failure due to memory character variables are mostly missing data. limitations, Because SAS can only read rectangular files, all - a loss of files when the user can't find lines contain the same number of bytes, even if a moved file or when a file is acciden- those bytes a",Sugi-13-123 Young.txt
"Version 6 Macro Features for the PC Jeff McDermott, SAS Institute Inc., Cary, NC . Bruce Tindall, SAS Institute Inc., Cary, NC complete successfully, but if one or more RUN groups fail INTRODUCTION SYSERR is still greater than 4. The macro facility, part of base SAS® software, is a programming %* If the procedure runs successfully, SYSERR is 0; tool for extending and customizing SAS software and reducing hf 'syserr = 0 %then %str(endsas;); the amount of text required to do common tasks. This paper !!'* A control-break signal sets SYSERR to 2; focuses on macro language features new to Release 6.03 of base :lif 'syserr=2 :lthen Jstr(dm 'recall';); SAS software including macro variables, macro statements. macro functions, interactive macro windows, DATA step inter- · SYS1NFO contains return code information provided by faces, and enhanced macro debugging tools. some SAS procedures. Values of SYSINFO are documented with the procedures that use it. Currently the COMPARE procedure makes use of SYS1NFO by turning MACRO VARIABLES on different bits depending on the outcome of the comparison. The coded values are ordered and scaled to Macro variables include those you create and those created by permit you to teli the degree to which the data sets differ. the macro processor (automatic macro variables). Table 1 gives SYSINFO codes for PROC COMPARE. Table 1 PROC COMPARE SYSINFO Codes Support for many Version 5 macro variables has been added to Release 6.03 including Description Code SYSDSN SYSMENV SYSBUFFR SYSSCP Data set LABEL = options differ Sl5ENV SYSDATE 1 SYSDAY SYSTIKE SIS INDEX Data set TYPE = options differ 2 SYSDEVIC SYSVER SYSJOBID 4 Variable has different informat Support for macro variables new to the SAS System includes the 8 Variable has different format following: 16 Variable has different length · SYSCMO contains the last command from the command 32 Variable has different label line of a macro window that was not recognized by the 64 Base OS has OBS not in co",Sugi-13-124 McDermott Tindall.txt
"data perm. survey; infile 'c:\sugi\pcsurvey.dat'; Users of the SAS® System for Personal Computers are con- input 011 id II. GIS address Sll1. 0119 phonenum $S. fronted with lengthy processing time and storage limitations not a27 adults 1. 012'8 children 1. il29 pets 1. a36 housing 1. a30 income 6. 0137 hometype 1. usually encountered when running the SAS System under other i38 rooms 2. aliO baths 1. Gl41 fire Sl. operating environments. Therefore, efficient programming, while il42 garage S1. i43 cars 1. ill4 stereo $1. certainly an ideal in the mainframe and minicomputer worlds, i4S tv S1. ii1IlS vcr Sl. 0147 cable S1. becomes a necessity in the microcomputer world. On the other ailS freezer Sl. 01119 microwv $1. iSO dishwash S1. hand, users of the SAS System for PCs may have greater flexibil- aS1 washer $1. 0152 dryer S1. 0153 pool $1. aSIi leisurel 2. 0156 leisure2 2. ilSS leisure3 2. ity than their mainframe and minicomputer counterparts in the i60 grade S 1. .62 fastfood S1. i63 sitdown S1. method they use to fun their SAS jobs and in how they configure 0164 creditcd 2. 4166 grocery II. a70 meat 3. their PC environment. Utilizing common sense programming il76 fr_veg 3. 0173 dairy 3. 4179 luxury 3. techniques, as well as Release 6.03 syntax and configuration OIS2 bevl 1. aB3 bev2 1. ilS4 bev3 1. specifications, improves the efficiency, reduces the processing iSS travelfo S1. aS6 travelus $1. Gl87 char it 4. 0191 religion 1. .92 politic 1. 0193 vote Sl. time of SAS programs, and cuts down on storage space for out- il9~ radio 1.; put SAS data sets. run; Because all of the numeric values in the raw data file were inte-",Sugi-13-125 Horwitz Thompson.txt
"THE SAS® SYSTEM ON THE ApPLE® MACINTOSHTM IT: THE BEST OF BOTH WORLDS A. M. Best, Ashland Vineyards Software You would then have to figure out how to transfer data Introduction between the two machines. but this could be done any number In this paper I have set out to determine whether the SAS of ways. System can be run under DOS on the Macintosh II. In short, Enlightened Option 2: For $1400 (list price) you could it can, but why would you want to do such a thing? At the purchase an AST® Mac286TM coprocessor board for your Mac outset, let me state my biases. II (or you could mail-order it for perhaps $1200). There Who is this for? would also be a need for a 5.25-inch drive for the Mac II. The Macintosh operating system is much better than This lists for $399 (you do not need to buy the Mac II PC DOS, so why would anyone want to use DOS? For me, the drive card because the drive plugs directly into the Mac286 only good reason I can think of is to run the SAS System. card). You would then have an AT inside your Mac II. Keep There may be others. All day, every day I work on my Mac, in mind that you would have to spend $7000 (list price) for often using SAS on the mainframe. As I have recommended your Mac II but my assumption is that you already have spent at a previous SUGI (Best, 1986), the Institute should bring this money. No one would suggest that you buy a Mac II and out a full implementation of the SAS System for the Mac286 board to just run SAS - that makes little economic Macintosh. Until that day comes, I still have work to do. sense. Presently, I am tied into a VAX so I can use it do do my SAS EveroresentOption 3: You could decide that $1900 for a data management, number crunching and data displays. But mail order clone or less than $1800 for a Mac II addition is still when I produce my final reports, I download my tables and too much. The fonner figure may come down somewhat but I data lisrings produced by SAS into Microsoft Word on my doubt it will come dow",Sugi-13-126 Best.txt
"THE BEST OF ALL POSSIBLE WORLDS: USING THE SAS SYSTEM® UNDER MVS, PRIMOS AND MS/DOS@ Frederick Pratter, Abt Associates, Inc. There are a number of advantages to us- One of the most remarkable, though log- ing local computing resources (the Prime and ical, developments in the evolution of the SAS the micros) as opposed to a remote main- System has been the success of portable SAS. frame. First, lt is considerably cheaper. As recently as 1982, the task of rewriting the Although we occasionally require the level of SAS System for mini and micro computers, while processing power and the data storage capacity preserving its ease of use and function~lity, that only a large mainframe installation can seemed nearly impossible. At SUGI 8, 1n New supply, much of our work can readily be done Orleans in 1983~ it was announced that Version at a lower cost on a smaller machine. Even 5, the first portable version of SAS, h-:d :-e- were cost not an issue, however, there are qui red the development of over half a m11l10n still advantages to a distributed system. The lines of code, most of it from scratch. After Prime is particularly well suited to fast five years of further refinement, I am glad to turnaround jobs, as for example when a tape be able to say that most of it works. comes in, files are merged, and mailing labels This paper is intended to document the generated that same day. Sending the data out experiences of one group of users with Version to the service bureau and getting output back 5 under MVS and Primos, and Version 6 under rarely takes less than a day. Finally, as MS/OOS, and our efforts to develop a distr~ those of you who have used PC/SAS have surely buted processing system that would make maX1- discovered, the fixed monthly cost of a micro mum use of the SAS System in these environ- computer (as opposed to the metered use of a ments. This effort should be of interest both time sharing system) encourages the kind of to applications programmers running SAS in a",Sugi-13-127 Pratter.txt
"hat a USEFUL Abstract benchmark should either be a typical program, or should test those features which our typical program will use How fast does PC/SAS run on one computer compared to most. another? One general comparison is the time required to run the TESTBASE installation program. This paper com- SAS speed mainly depends on two aspects of a computer's pares times for a variety of PC's, mainframes. and mini- performance: its CPU (brain) speed and disk speed. This computers. makes sense because SAS can be used to do a lot of calculations (say with a statistical PROC); it may read and PC/8AS Is slow?! write a lot of data; or it may do both. Suppose a given SAS program mostly does calculations and doesn't handle My first experience with PC/SAS was on a PC/XT with a a lot of data. For that program. a fast CPU is important; a hard disk that was slightly faster than IBM's. TESTBASE, fast hard disk won't improve performance very much. the installation test job. took 22 :m1nutes. Worse. I Conversely. a very fast disk is cIitical to a program that watched the lines of of SAS code scroll down the we reads and writes a lot of data. window with agonizing slowness. realizing that my jobs would scroll just as slowly. And it gets worse: when I got Vendors provide numbers which give some useful informa- my own PC. Testbase took 27 minutes to run! Clearly. all tion on these two performance measures: PC's are not created equal when it comes to running SAS -processor speed (in megahertz). A",Sugi-13-128 Pardee.txt
"nc. Abstract Three Configurations This paper provides performance data on the The performance tests on SAS lookup facilities were run on three different machines to examine the comparative efficiency of four methods in the SAS® stability of results across architectures and determine system for the use of enumeratively defined functions the degree to which general statements about or table lookup procedures. The methods tested are method selection could be supported. Two of the (1) MERGE, (2) formats with PUT, (3) binary search, architectures chosen were PC systems and one was and (4) golden section search. The simulations are a mainframe. run with three configurations: (1) SAS Version 6.02 on a PC's Limited® 80386, (2) SAS Version 6.02 on The first PC architecture used was a Sperry IT a Sperry IT® 80286, and (3) SAS Version 5.15 on an 80286 running SAS 6.02. The machine had a clock Amdahl 470N8. Within the implementation speed of 7.33 MHz, a nominally zero wait-state constraints imposed by each configuration and memory, two megabytes of random access memory method, the benchmarks are run varying the number (RAM),and an 80276 floating-point co-processor. of observations in both the data and lookup files on a logarithmic scale from 20 to 219. The results are The more advanced PC architecture chosen was summarized in a set of tables selected to facilitate the a PC's Limited 80386 runnning SAS 6.02 with a user's selection of an appropriate method. Data clock speed of 16MHz. The m",Sugi-13-129 Lutomski Mullally.txt
"STRACT After our scoring program was initially developed, it was scheduled to be used in a The SAS(R)Companion for the eMS Operating large scale multi-centered research project. System (1986 Edition) states on page 1, Each of the five centers in the project ""Generally speaking, SAS programs and their extensively reviewed and critiqued the code results are the same, regardless of the host over the course of a year. After this review operating system. n The purpose of this paper process was complete, the sentiment was to is to determine the extent to which SAS freeze the code. In this way other users Institute is generally speaking. could use the same exact program and compare their findings to those in this large scale In the Department of Psychiatry at Washington project. Such standardization would greatly University. we have developed a large SAS facilitate cross-study comparisons in a field program of over 1 1 600 statements which scores plagued by inconsistent definitions and Widely a standardized psychiatric interview and variant measures. creates a data set of over 1,700 variables. Other institutions often wish to run this It was only after SAS Institute greatly scoring program on machines other than an IBM expanded the types of machines and operating mainframe. In addition to aiding such users of systems under which SAS software could run our own program, it is hoped that this' that we had to think of how the program could exercise of running large SAS code under be use",Sugi-13-13 McEvoy.txt
"almer, University of Southern California ErlC Wang, university of Southern California ABSTRACT analysis were virtually unlimited, thus The purpose of this paper is, to file size and variable storage was not describe the transition from a mainframe considered a problem. This environment SAS system environment to a networked was a breeding ground for poor file 386 PC enviroment using the SAS~ system management (several data sets of similar for - personal computers. We found that nature were created and stored), and lar~e scale analysis can be performed programmers did not worry about space efflciently and effectively within a 386 constraints (very large merged data sets IB~ PC, Token-Ring network environment, containing hundreds of variables). utilizing various methods of system In subsequent years, due to enhancement and data management and increased computing cycle demands, manipulation. monies for additional mainframe computer Three basic issues are presented: time became more difficult to obtain. (1) Our network hardware and software USC like other large institutions began accurate and cost confi~rationl (2) to encourage the decentralization of efficlent data set transfer methods computing to relieve strain on the from mainframe to PC and (3) effective system. Late last year, seed money was control file templates for handling thus granted to our Institute to several large merged and unmerged data develope an alternative computing sets simultaneously. environment. 'A brief d",Sugi-13-130 Dent Palmer Wang.txt
"2.1 The Complete Picture The steps for remote processing of graphics procedures are as fol- This paper discusses the latest enhancements to the micro-to-host lows: link: and some planned enhancements for future releases. Among the newest features implemented in the current PC and host ver- L Execute the SIGNON command as usual to establish the link sions are catalog download, remote processing of full-screen graph- between YOUI PC and the host. ics procedures, protocol c.onverter support, and batch processing with DM commands. 2. Use tile RSUBMIT command to remote submit the following GOPTIONS statement: goptions device=grlinkj",Sugi-13-131 Garner Kolb.txt
"perative studies Program Joan Derrico, West Haven Cooperative studies Program onto the microcomputer to reduce ABSTRACT timesharing costs. When a new study involving Percutaneous Transluminal The emergence of the SAS* System for Coronary Angioplasty(PTCA) was assigned to personal computers generated enthusiasm for the Center, it was decided to attempt to setting up the data proc'essing for a new manage the entire study on the Cooperative Studies Program clinical trial microcomputer. Since all of the staff was in a microcomputer environment. Part of familiar with the mainframe sAs System~ we this involved transferring a generalized VS FORTRAN datachecking routine from a thought that most of the routines could be large-scale mainframe to a microcomputer written in the SAS System for personal computers. using the SAS System for personal computers under DOS. This program is part of a larger data management procedure used for BACKGROUND cooperative clinical trials. It was The CSPCC has in place a data management immediately apparent that the mainframe system that is utilized in all of our routines would require major redesigning in clinical trials. The Center receives and order to operate under the SAS System for processes thousands of computerized forms, personal computers and that our approach either paper or transmitted. Once the data would require different methods than we is loaded onto the computer, every variable would have used for the mainframe SAS System. This paper will",Sugi-13-132 Collins Derrico.txt
"the C:\SAS directory. You may use TTY.EXE, or you may use ABSTRACT another asynchronous terminal emulator. The asynchronous ter- minal emulator you use must be Data Terminal Ready (DTR) high The SAS® micro-ta-host link provides the ability to transfer files when you exit from the terminal emulator software and enter the between a microcomputer and a host computer and to use local SAS System. This is usually the default and prevents VMS from or remote SAS processing. The SAS Guide to the Micro-la-Host dropping or disconnecting your logon id when you drop out of Link, Version 6 Edition fully documents this feature of base SAS the terminal emulation program and enter the SAS System on software for the enhanced 6.02 release of the SAS micro-ta-host your PC. The sample script file, VMS.SCR, is for manual SAS link and the TSQ, eMS and VMS"""" host operating systems. This remote invocation after you logon to the VMS operating system. paper discusses the SAS micro-ta-host link between a PC SAS LOGVMS.SCR is a sample script to be modified for your site Release 6.03 session on a microcomputer using MS-OOS® and specifications for automatic logons. a SAS Release 5.16 session under the VAXTMjVMS'"" operating system. Suggestions are made for integrating the SAS System under VMS and the SAS System for pes for use in SAS applica- GETTING STARTED: SHORT CUTS FOR MANUAL tion development, or for using the SAS System for PCs as a work- LOGONS station for VMS. Areas discussed include how to download",Sugi-13-133 OConnor.txt
"initial window displays the patient The SAS System for microcomputers was used to identification (ID) selection. The patient monitor study medications in a Veterans summary window displays an old ID summary, new Administration Cooperative Studies Program ID data and coding error screens. The change clinical trial of vasodilators in congestive in study medication window displays the heart failure. This program was designed to medication(s) discontinued or restarted and facilitate data entry of discontinuation and incorrect drug code(s) screens. The update restart of study medieations. The SAS medication window displays each medication (E. software system using WINDOWS was utilized H, I) and two date checking screens. because of the requirements for end-user data entry, easily accessible files, and Figure 1: WINDOW FLOWCHART comprehensive data analysis. .-----t> ENTER ID <11----",Sugi-13-134 Hope.txt
"series of windows which prompt for The SAS® System for Personal Computers input, display the question, and give implements several features not yet the user feedback after responding to found in mainframe or minicomputer each question. The welcoming window versions: the WINDOW and DISPLAY prompts for the user's name, the level statements and the Stored Program of expertise at which he/she wishes to Facility. An application of the SAS be tested, and the desired number of System for Personal Computers was multiple-choice questions. There are designed and written to take advantage three levels of expertise (beginner, of these unique features. This intermediate, or advanced) and a maximum It is a interactive program uses the WINDOW and of ten questions at each level. DISPLAY statements to quiz a user on simple matter to add more questions and his/her knowledge of SAS syntax. The modify the code to allow many more compiled program was saved using the questions per level. Should the user Stored Program Facility. By storing and enter anything other than one of the subsequently loading compiled code, appropriate choices of expertise level, about two minutes of waiting time is or anything other than an integer avoided to start the application. between 1 and 10 for number of desired questions, a window appears to inform him/her that the input was not accepted.",Sugi-13-135 Howard.txt
"A Data Base Interrogation System with the SASR System for Personal Computers Stephen A. Mandel, Washington University J. Philip Miller, Washington University Operating System criteria. Direct inquiries of selected The SAS System for personal computers is ideally suited for providing an easy means of accessing experts is required if more than one software product information to end users who are neither familiar with and/or operating system is listed as neither the personal computers nor SAS. The Data Base registry information sheet nor the software correlate Interrogation System was created to demonstrate how expertise in one area with any other area. the powerful tools available in PC SAS can be made available to information consumers in a ""user friendly"" Selections are matched via two array statements. One way. WINDOW statements and programmed function array references the WINDOW input selection criteria keys are used to invoke SAS. This application can and the other the consultant data base. Array items are all possible areas of expertise. Any mark users become part of a larger information system. The make by a selection item is matched against the the system could point to a printer for hard copy output, a separate program for editing/adding to the data base consultant file. Matches result in the consultant being or a report generator for various types of reports. added to the data base. These matches are then System expansion can be achieved with more viewed with FSBROWSE. The SEND command can WINDOWs statements and more programmed then be used to print the data base. function keys. Alternatively, the system could be driven under SAS/AFR. Users can run the system The Data Base Interrogation system is an application from the display manager or, for users of PC SAS of the data step WINDOW statement. The submitted program presents a WINDOW to users listing the five 6.03, from batch mode. areas of expertise, a HELP screen and DISPLAY The Data Base Interrogation Sy",Sugi-13-136 Mandel Miller.txt
"AUTOMATIC FOOTNOTING OF SPECIFIC DATA IN A LISTING: AN EXAMPLE WITH CLINICAL LABORATORY DATA James P. Young Syntex laboratories Footnotes in data listings are often highly desirable. Aberrant clinical laboratory test The sample output below notes the footnotes with values, for example, need to be qualified with arrows. footnotes, especially when data that may appear life-threatening are only the result of a known By automatically adding footnotes using SAS® laboratory error. The program demonstrated in processing, we avoid the tedious and error-prone this PC Poster session lists clinical laboratory procedure of attempting to do so with a text data and editor. a) flags any data that need a footnote, SAS is a registered trademark of SAS Institute Inc., Cary, NC, USA. b) specifies footnote symbols, and c) when flagged data are encountered on an For more information contact the author at: output page, Syntex laboratories I) assigns footnote symbols to print Mail stop L-2500 beside each flagged datum, 3401 Hillview Ave. 2) puts the symbols and appropriate foot- P.O. Box 10850, notes at the bottom of the page in Palo Alto, CA 94303 the order of first occurrence on the page. ·· . · [Study 06-9445] Laborato""!""), Data listing by Dosage by Patient Hupine 90 mg (continUed) .,.. -------------.--------------------------------------------------------------------------------------------- TEST AND NORMAL RANG[: PlIos- Potas- ehlor- Creat- BUN-ere Pa· Vh- Speci..en Glucose Cale1l11i1 phorus Sodh.. .UN Id. CO2 tnine Ratio tient it D... Age Sex 70-110 8.5-10.5 2.5-4.5 135-1SO 3.5-5.5 95-110 22-34 6-25 .6-2 7-24 · c/ 10.10 111 119 16.0 OS/22/85 36 M 144 102 2D 2.20 3.' '.3 t:.e"" 1: 24 m 17.0 08/05/85 36 "" 10.00 2D 1.80 "" 3.' II .... 23.009/17/8536 "" 10.20 4.4 139 Z7 23 1.80 13 . .... ··· 100 lUIt"""" 121 1.0 08/08/84 49 M 4.1 18 1.10 24 "" 13' ··· 100 ··· 3.0 09/05/84 451 94 141 101 "" 17 1.30 13 ··· 103 7.0 10/03/84 49 9.70 142 1.20 "" 23 3.' 19 . 11.0 11/28/84 49 9.60 138 1.10 3.' '.3 IS",Sugi-13-137 Young.txt
"Windows without Pains Ross Z. Merlin ''Windows withcut Pains"" was presented at '!he DISPIAY etatenart: causes the text to be SUGI 13 as a Fe lIands-on workshcp. '!he follow- displayed; execution pauses until you. press ing notes am exanples were used in the enter. '!he Sl'OP etatenart: is needed because the DI\TA step nonnally continues loq;>ing until an presentation. en:l.-of-file or en:l.-of-<lataset con:lition oocurs; since this step does not read a file or dataset, '!he winiaws that we will be learning about are not the three rns (Display Manager System) the Sl'OP etatement is needed to keep the pn>jLam fran loq;>ing forever. I f you fin:i yourself windows that you see when you start SlIS [1]; we stuck in an infinite loq;>, you may be able to will be learning about windows that are oem- 1:1:o11ed by the DI\TA step. You decide what these break out by entering the ""END"" ccmnand on the win:l.ows look like, where am when they ~, ccmnand line at the top of each win:'low. what text am variables are displayed, am which variables will aooept inp.rt: fran the win:l.ow or '!he program in Figure 2 adds attributes to be for display only. the displayed fields. 'lhese am similar speci- To get an idea of what can be done with fications are referred to as field q>tions, since they pertain to the field (variable name Win:lCMS # execute the SUGIHII.D PJ:ogLdlU that is in or text etring) that they follow. An attriliute the SlIS sample libJ:arY. On a typical Fe, the is specified by ""attr="" or ""a="" follOirlErl by one file would be C:\SlIS\SlISSAMPL\SUGlliIID.SlIS (not all installations choose to install the sample or nx>re of the following: highlight, blink, library; check with your installation represent- rev_video (reverse video), or urrlerline. If nx>re than one attriliute is to apply to a field ative). I f the file date is 1-15-88, you should fiJ:st. make the follawirg changes to the program: (as in the tenth line of Figure 2), join the oc:mna am enclose in in the line that beg",Sugi-13-138 Merlin.txt
"DEALING WITH LIMITATIONS OF SAS/STAT"" SOFTWARE ON A PC Thomas Birkett, National Agricultural Statistics Service 2. Install a COPROCESSOR Introduction for Computational Speed. The biggest obstacles in moving SAS/STAT software use a processing from a mainframe to a PC have SAS/STAT will coprocessor one is present, if speed~ been inadequate memory and otherwise the floating point storage space. These limitations were operations are done by software. primarily in the PC hardware, rather The accuracy is the same, but the than in the SAS* software. In recent hardware operation is faster. years, the advent of 32-bit Applications with many calculations microprocessors, faster clock speeds, will benefit from the installation expanded memory, disk caching and ample of a rna th coprocessor. An example fixed disk space have- made the constraints less restrictive. would be fitting a least squares model with a large X'X matrix, Res ponding to thes e increased hardware capabilities, the SAS Institute has where solving the normal equations would be calculation intensive. added options in version 6.03 which allow the SAS System to more efficiently use the OOS operating system and the PC Use Expanded Memory. 3. hardware. These configuration options are contained in the CONFIG.SAS file, Much more will said about be analogous to the CONFIG.SYS file of OOS. expanded memory in the second part CONFIG.SAS is executed each time the SAS of this paper. When expanded System is started. memory is invoked- (the details will be given later), the SAS System This paper discusses a number of configuration options available in the loads as much of the SAS supervisor CONFIG.SAS file and other aspects of the into expanded memory as possible. If SAS procedures are invoked, they SAS/STAT software which influence speed, are also stored in expanded memory, memory and space. The use of these and if they are invoked again options along with minor hardware during the same job they don't have upgrades will gi",Sugi-13-139 Birkett.txt
"SETTING COMPUTER CHARGEBACK RATES USING THE SAS® SYSTEM, CICS & LOTUS® 1-2-3® Jeanne Buse, SOFTWRIGHT Summary When approved, the expenditure budget The charter of the IS department provides the legal authorization but not in a Washington State County govern- the funds for the Department to spend. ment requires it to be entirely self-sup- The funds come from the charges made. porting by charging its customers for The second and most obvious set of the resources they use. It should show outputs are the new rates to be charged neither a profit nor a loss. Further, one for the use of the billable resources during the coming year. customer may not subsidize another. To accomplish these goals, customer billing The third set of outputs is an IS is done by a usage based, flat rate chargeback budget for each customer. chargeback system. System Inputs Moreover, for the billing system to perform within the extremely stringent There are two basic inputs to the criteria laid down in the charter, a rate setting process, plans and historical rigorous process for setting. chargeback billing data. Actual billing history pro- rates is required, and a Rate Determina- vides a basis for forecasting future tion System (RDS) was developed. In usage. Plans impact both resource usage 1987, the system was renovated to up- estimates and the annual expenditure budget. grade the technology and to reduce the cost of setting rates. Plans corne from many sources. This paper discusses the revised Customers may have ideas on how they intend to use or what they want done to RDS which includes SAS, CICS and Lotus their systems. Applications may know of components. It describes the system out- needed maintenance or enhancements. puts, inputs, functions and architecture as well as the interfaces between the Technology and Operations may plan for different components. hardware or software upgrades. Vendors may anticipate price changes. And System Outputs ultimately, the Budget Office may set limits on e",Sugi-13-14 Buse.txt
"EXTENDING THE SASI!J SYSTEM ONMICROCOMPlITERS WITH SAS/IML'"" SOFTWARE, THE INTERACTIVE MATRIX LANGUAGE Linda P. Atkinson Economic Research Service U.S. Department of Agriculture This can be viewed with a PRINT command: Introduction print z; The same variable can be redefined as. for The SAS® System contains powerful software example, a row vector: for data analysis. However. i t c~ot be a~l z={1 2 3}; things to all people. With SAS/IML software, print z; the IML language (Interactive Matrix Language) can be used to extend the SAS System to include If you would like to see all results printed tailor-made features or personalized procedures automatically. use the RESET command: to suit individual data processing needs. reset print; is a programming 1M!.. language based on Rows of a matrix are separated by commas: matrix algebra notation. A formula for a A={1 2 3, 4 56}; statistical method expressed in matrix notation Character values can be entered direct ly or can be easily -programmed with IML commands. Thus, a statistical technique which has not yet enclosed in quotes if they include spaces: been incorporated into SAS (or which Is part of alpha={a bed e C g}; a SAS product not yet available at a particular agencie~{~Economic Research site) can be coded without great difficulty in Service' , IML. 'USDA/NASS' , SAS/IML as it is -implemented for personal ·U.S. Postal Service'}; computers also contains display features A particular element of a matrix is referenced allowing the creation of windows for with brackets: full-screen data entry or menuing. Data A[2,31=8; processing commands can query and extract information from SAS data sets. User-friendly A subscript can be left out to refer to an applications can be developed which exte~ the entire row or column: SAS S~em similarly to the way SAS/AF and b=A[2,1; do. SAS/FSP A matrix can be defined as a submatrix of another one: rows={l 2}; colUllBlS={2 3}; The basic entity in IML is a C=A[rows. columns]; two-dimensional",Sugi-13-140 Atkinson.txt
"y using the GFONT procedure. INTRODUCTION For each character of the custom font, the symbol is plotted on a grid. The shape is described as x,y coordinates that make up (O.3~) the data set for the new font. , ..... The MARKER font, used here as an example, is made up of trian- gles, arrows, male and female characters, and an assortment of symbols to be used with SAS/GRAPH® procedures (see Figure 1). -- · t Figure 2 Arrow ·· data arrow; input char ptype x y segment Ip; cards; t w thin arrow pointing left I 64 P v 32 32 P ., "" 42 P ·· ,. "" P 38 P +t v """" v "" 30 P v 38 30 P v "" 26 P ·* 22 "" P J2 J2 P <----- ""trick"" point * 0 l2 99 P Figure 3 displays the center point for each symbol in the MARKER font. Figure 1 The MARKER Font Creating a Symbol ···t4J+*CJ·~· Each symbol is drawn on the same grid. The horizontal coordi- . . . nates for each symbol are independent of the horizontal coordi- nates for another symbol. The vertical coordinates, however, must be defined on the same baseline. By plotting each symbol on a grid with the x,y axes ranging from 0 to 64, the PROC GFONT option baseline is set to 0, while the two options CAPLINE = and MWIOTH= are set to 64. The center for each symbol becomes the coordinate of x=32, y=32. When positioning each symbol on the grid, the centering becomes important for sl!ch symbols as the arrows (see Figure 2). For those characters that are asymmetrical, such as arrows where it is important that the point be positioned at the center, the addition o",Sugi-13-141 Blettner.txt
"st Research Abstract The volume of paper work generated in a visualization of coordinates for the templates. research facility requires that reports be as The use of PROC GREPLAY allows a polished and concise as possible. FROC GREPLAY in SAS* compact presentation incorporating material from software offers the ability to place several SAS* data sets. plots, notes and/or explanatory material on a single page. Acknowledgment Introduction The authors wish to thank June Deitz for her valuable assistance. This information is presented primarily for the new user to aid in the efficient use of FROC References GREPLAY. It is a valuable tool in the technical report. After the syntax has been established, SAS Institute, Inc. SAS* User's Guide: it may be copied, with slight variations, into Basics, Version 5 Edition, Cary, NC: SAS many programs. Institute, Inc., 1985. 1290 pp. Discussion SAS Institute, Inc. SAS/GRAPH* User's Guide, Version 5 Edition, Cary, NC: SAS A SAS* software template catalog offers Institute, Inc., 1985. 596 pp. pre-defined templates for this purpose. For a * SAS is the registered trade mark of SAS customized report, user-defined templates are frequently more suitable. A smaller plot may be Institute, Inc., Cary, NC, U.S.A. placed within a larger one, showing, for example, actual values versus predicted values. Zeta (TM) is a trademark of the Nicolet Data plotted using PRoe G3D may be rotated for Instrument Corporation. examination with all desired rotations displa",Sugi-13-142 Bobik Singer.txt
"Using SAS(RI color Graphics for Video Image Analysis James Borek, Computer Sciences Corporation Alan Huber*, U.S. Environmental Protection Agency leeward face of the model building. The PROBLEM vertical, lateral, and longitudinal scales are normalized by the height of Wind-tunnel studies are conducted the model building (H). The video to evaluate the temporal and spatial intensity level is normalized and distributions of pollutants in the wake represents a percentage of the full- of a model building. As part of these scale intensity. studies, video pictures of smoke are The SAS/GRAPH PROCEDURE step, being used to study the dispersion GCONTOUR, was used to display a three- patterns of pollution in the wake of dimensional image of the plume. The buildings. The video image format has potential as a quantifiable electronic contour levels from the GCONTOUR medium. Analysis of series of selected procedure for the time-averaged pictures pixels (picture elements) for video graphically represent the regions of the building wake flow. images is used to evaluate temporal and spatial scales of smoke puffs in the wake of the building. Thirty black-and- white video pictures per second of a full field of view are recorded with a camera connected to a standard VHS recorder. The video luminous analog signal for each video image frame was digitized by a video sequence processor. The digitized luminous Signal from the picture is on a 0 to 255 (8 bits) unitless gray scale. These values of video luminous intensity correspond to the density of smoke through the field of view. The resolution of each video image frame is 525 vertical pixels by 768 horizontal pixels. The digital representation of selected picture segments are stored on magnetic tape for later analysis. A comprehensive package of software is needed to manage the -- large database, to statistically evaluate the temporal and spatial scales of the images, and to generate visual displays of the results. SOLUTION Base SAS (R) so",Sugi-13-143 Borek Huber.txt
"ORATORIES COLUMBUS, OHIO ABSTRACT Presenting results of c1101ca1 research At the time of the original request for often requires customized graphics not a plot, the allocation of resources to ;~;j~~~~~® ~~e~~~:~~rd T~:ti~~~ota~~ these tasks was justified. The programming for the original request facility in SAS Version 5 is a powerful served as a pilot version. After the tool for use in meeting these needs. original request was completed, the code However, the required programming time was reviewed to determine how to best is often unacceptable and the convert it into a macro for future y modification of previous code is applications. The added time to develop inefficient. At Ross Laboratories, our the macro quickly was recovered after approach is to genera 1 i ze the additional requests for graphics. This application and formulate a solution dramatic reduction in response time to using SAS macros. These macros are subsequent requests a 1so permits placed in a permanent SAS macro library replacement of a ""quick and dirty!! that may be ~ccessed by any user in the result by a more polished presentation Ross Medi ca 1 Department. Therefore, for rush requests. custom; zed graph; cs can be qui ck.ly produced without an extensive knowledge Using macros to create graphics is not a of SAS/GRAPH. new idea. While requiring more initial programming time and skill, there are Five graphics problems and solutions are several long-term benefits. One of the presented: Scatter plot of values",Sugi-13-144 Bryant Wahrenberger Ruey.txt
"SAS/GRAPH® Scatter Maps Sheila Fitzgerald Evans, SAS Institute Inc., Cary, NC Robert John Dolan, SAS Institute Inc., Cary, NC This paper describes how to use the Annotate facility in Map Type Description SAS/GRAPH® software to illustrate graphically the density of some geographic distribution function. For example, you may use 1) Scatter map Dots are plotted for each observation in such an illustration to study a market for the location of a ware- the input data set. The number of dots house or manufacturing plant. plotted per observation is based on t/:le value of a response variable. Dots are The types of maps represented here are known as the choropleth placed on the map in concentric circular (Greek choros, meaning place, and plethas, meaning number or rings, starting from the center of the quantity) map (Schmid 1983). Choropleth maps display range- county polygon and working outward in a graded values for geographic areas by shading, coloring, or plac- constant pattern. The number of ing symbols on those areas. concentric rings used per county are proportional to the number of dots to be The areas that may be represented in a scatter map are ZIP code plotted per county. (The program appears boundaries, counties, precincts, census tracts, states, regions, below.) and entire countries. Counties are the basic graphical area repre- sented in this paper and application. However, with the use of Users may specify dots or other symbols 2) Scatter map the Nationwide 5-Dlgit ZIP Code Boundary File supplied by Geo- for plotting with this type of map. As in using the graphic Data Technology, Inc. (13 Dartmouth College Highway, map type 1, the number of symbols RANUNI Lyme, NH 03778-9713), you can edit the application to use ZIP plotted is based on the value of a distribution code boundaries instead of county boundaries or you can merge response variable. Unlike map type 1, a function the ZIP CODE data base, available from SAS Institute Inc. (Tech- random pattern of dots",Sugi-13-145 Evans Dolan.txt
"RACT The predictor variables Xk 1. One assumption of the ordinary least (k = 1 to p) are fixed and known squares (OLS) regression model is without e'rror; that the observations on the response variable Yare statistically The expected va~ue of E given X 2. uncorrelated. In data sets obtained is 0, i.e. E(eIX) - 0; from cluster sampling (usually a more cost-effective sampling method than simple random sampling), this . The conditional variance of £ 3. assumption is violated; observat1ons given X iSla constant parameter, i.e. Var(e X) - 0 2 ; may be uncorrelated between clusters, but correlated within clusters. Application of OLS methods to such The £i are statistically 4. uncorrelated, i.e. data can lead to serious * underestimates of the precision of Cov(ei,ej' i j) - O. estimated regression coefficients. To estimate the variance of Y Many methods have been proposed for for hypothesis testing, it is dealing with such intracluster. necessary to assume that the £i are correlation, including genera11zed independent random variables, or are least squares (GLS), random from a Normal (Gaussian) probability coefficient regressions, and distribution. Assumptions 3 and 4 jackknife estimators of variance. together imply a specific variance- This paper describes two algorithms covariance (or ""dispersion"") matrix written in the SAS Interactive Matrix structure for the vector E of Language (SAS/IML~) to fit GLS models residuals, namely based on work by scott and Holt (1984) and Fuller and",Sugi-13-146 Gillespie.txt
"nne National Laboratory ABSTRACT A study was undertaken using .sAS® software were conducted using SAS software to explore and to investigate the origin of anomalous tempera- characterize the anomalous TC readings, and to ture measurements recorded by thermocouples test hypotheses advanced to explain their or1g1n. The SAS-system macros developed as part (Tes) in an instrumented fuel assembly in a liquid-metal-cooled nuclear reactor. SAS macros of this investigation are quite general and can that implement univariate and bivariate spectral be applied with only minor modifications to decomposition techniques were employed to explore and characterize any experimental time analyze data recorded during 'a series of experi- series that are suspected to contain periodic ments conducted at full reactor power. For each components. experiment, data from physical sensors in the Experimental Data test assembly were digitized at a sampling rate of 2/s and recorded on magnetic tapes for sub- A sequence of flow-change experiments was sequent interactive processing with CHS SAS. Results from spectral and cross-correlation performed to provide data used for this invest- analyses led to the identification of a flow- igation. During the flow-change experiments, rate-dependent electromotive force (EMF) phen- the values of some 800 plant parameters moni- omenon as the origin of the anomalous TC read- to red by the EBR-II data-acquisition system were recorded on dedicated magnetic tapes at a samp-",Sugi-13-147 Gross Planchon Poloncsik.txt
"gton State Department of Transportation ABSTRACT Research by Washington State Department of Trans- Washington. Specifically wanted was information to portation provides information about behavior of traffic improve conversion of short 4-hour or 6-hour samples to for use in SUbsequent data collection and to improve estimate 24 hour totals. Another major component of predictions of vehicle volumes and truck weights used the objective was to search for new ways of aggre- for highway design. Using previous obtained data, a gating information regarding behavior of trucks and to system of SASI programs utilizes descriptive graphics determine optimum hours for sampling traffic to obtain interspersed with computation and inductive the most representative truck mix. Trucks carry the observations. weight loads whose long-term cumulative effect is responsible for most pavement damage. Twenty-four hOUf traffic profile models with hourly mean volumes of 12 vehicle types were developed from Background actual data. Models were put through a moving array matrix producing all possible consecutive 4-hour Highways have only one purpose and that is to carry samples to develop expansion factors for converting traffic. Traffic itself is very dynamic and behavior short samples to 24-hour volumes by time of sample. changes take place in both quantity (number of vehicles) and quality (vehicle mix) due to variables such The entire process (which uses SAS means, plots, as hour of the day, day of week,",Sugi-13-148 Hertzog.txt
"MULTIVARIATE NORMAL PLOTTING USING ORDERED MAHALANOBIS DISTANCES Namjun kang Syracuse University II. Probability Plots and Plotting I. Introduction Positions The assumption of multivariate For evaluating multivariate normality underlies much of the normality, Andrew et al. (1973) have standard multivariate statistical suggested an informal graphical pro- methodology. The effects of depar- cedures that utilizes a distance- tures from normality on the methods from-mean representation of multi- are not easily and clearly under- var ia te data. The stood. Thus, it would be useful to distance-from-mean in multivariate verify the reasonableness of assum- oI data, or Mahalanobis distance ing normality for a given body of multivariate data. Such a check l.. - -, - would be helpful in guiding the D.i = (Y.. - Y) '*S*(Y, - Y) subsequent analysis of the data, by will have approximately a chi- suggesting the need for transforma- squared distribution with v degrees tion of the data to make them more nearly normally distributed. of freedom in the v-variate case. The exact marginal distribution of of The methods for assessing nor- is known to be a constant multiple mality can be grouped into two of a beta rather than a chi-square genres; i) single-statistic-based distribution (Gnanadesikan and Ket- formula test such as multivariate tering, 1972). But, when the popu- skewness and kurtosis (Mardia, 1970; Kang & kalinoski, 1987); ii) graphi- lation is mUltivariate normal and both sample size (n) and (n-v) are cal techniques using a probability greater than abour 25, the differ- plot. Although a probability plot ence between using the beta and chi- does not provide a formal test, squared approximation appears to be probability plotting techniques have insignificant (Johnson and Winchern, proved very valuable for the detec- 1982) . tion of systematic non-normality and Often it will be informative to of outlying values. Marked skew- supplement the information about the ness, such as mi",Sugi-13-149 Kang.txt
"The SAS code for the on-line performance tracking system was written from scratch An on-line performance tracking system has since at the time of development no starter been developed at General Electric - Plastics code existed. Even though this performance Business Group using MXG® and SAS®. This tracking system was written from scratch, it system depicts important performance and took only one person part-time, i.e., capacity statistics for batch, IDMS/R [1], approximately five hours per week, for six network, system and TSO processing. The months to write the code necessary to support system features a top-down reporting all the performance areas except network. It approach, both short-term and long-term took a college student full time for two performance and capacity graphs and hardcopy months to complete the network performance options. A demonstration of this system will area. However, the college student also had be presented. Also, an overview of the to learn SAS during this two month period. collection process necessary to support this Today however, skeleton SAS/AF starting code on-line performance tracking system and ideas can be acquired from the SAS Institute at no for future enhancements will be discussed. charge [3]. Such an acquisiton should expedite the development phase considerably.",Sugi-13-15 Reish.txt
"S~SYSTEM DIGITAL MAPS AND THE James J. Knitis, Federal Express Corporation Digital mapping has seen an upsurge ""in re-cent years. The literature is rampant with mapptng software. techniques. and algorithms. The SAS System enables one to replicate many of the common map graphics. A Geographic lnformation System (GIS) can be established by adding geographic information to a customer data base. On page two, the contents of a GIS is shown. The geographic data ""include state, county, city, SMSA and address. The address can be located on a map by address matching and the generation of x and y coordlnates of Lonqitude and Latitude. Recent papers have shown how to perform this using the SAS system~* The five maps that are presented in this paper use very basic SAS commands. They demonstrate the versatility of the SAS system with respect to presentation graphics. This chart displays state level aggregates. It is a very general map but has a use in presentation graphics. The map data set used is the u.s. data set which comes with SAS/Graph software~ The second chart uses the Counties level data set which offers a finer level of detail compared to Chart L This map data also is available w""ith SAS/Graph. This chart uses a ZIP Code level map data set which must be obtained from an outside supplier, such as Geographic Data Technology, Inc., of Lyme NH. The ZIP level polygons offer finer detail but one must be cautious of ZIP Code limitations, such as constant change, incomplete coverage, and point ZIP Codes (no land area). This chart utilizes the ZIP file described in Chart 3 and also the x, y variables from the GIS. This map style is very useful in location of facilities based on customer characteristics. The last chart is very similar to one shown at SUGI 12*, but uses PROC GMAP instead of PROC GSL1DE which allows easier projection techniques. This chart utilizes the Census Bureau's Dime files. the GIS, and SAS Graph for effective presentation graphics. This type of graph is u",Sugi-13-150 Knitis.txt
"Several assumptions are needed for Friedman's test. First, it is assumed that the above layout holds (and no x .. ' s are missing). This paper discusses the development of a Second, it is assumed that m~~surements within macro to perform the EXACT Friedman test and an each block represent continuous variables Third, these measurements within a block can b~ associated multiple comparison procedure. Also provided is an overview of the Friedman test and ranked. Fourth, there are no interactions the multiple comparison used. SAS code for the betwe~n treatme~ts and blocks. Unlike the macros is provided. claSSical randomized block ANDVA, no assumption about an underlying error structure is necessary.",Sugi-13-151 Barg Kraemer.txt
"A SAS® Procedure (PROC DICHOT) is presented relationship to the median. We present a SAS which (a) computes the median for a given set of Procedure (PROC DICHOT) which will compute the numeric variables, (b) performs a median split on median for a set of continuous numeric values and those variables, (c) determines whether or not the subsequently create new logistic variables based on numeric variable is above or below the median and the continuous variables relationship to the creates a new variable (DICOTn) whose value is median. either 1 or 0, and (d) outputs the variable(s) to a SAS DATASET. PROC DICHOT provides an option PROCDICHOT which allows processing the data in either sorted or non sorted form as well as an option which allows PROC DICHOT options; users to determine the logistic values of scores VAR varlist; which are equal to the median. These new dichotomous variables may then be used as input to Proc DICHOT will compute the median and procedures which perform analysis on categorical create new dichotomous variables from an input variables. Examples of using PROC DICHOT are SAS DATASET. The following restrictions apply: presented along with data regarding time and memory utilization using input SAS datasets with (a) The variables must be numeric. varying numbers of observations. (b) The number of variables is limited to 999 per execution ofPROC DICHOT. (c) Currently no provisions are made for",Sugi-13-152 Lambert.txt
"animal occupying a subquadrat. This probability will be the same for each subquadrat in the Spatial pattern analysis is used extensively in field or pasture. For example, if there are 20 studies of plant ecosystems. In recent years, animals and 100 subquadrats, p is .05. If a animal ethologists (behaviorists) have used quadrat is made up of 4 subquadrats, the mean spatial pattern analysis in studying number of animals expected in a quadrat is (n*p), or using the figures above, (4 * .05 = distributions of animals over fields and pastures during grazing experiments. The .2) · analytical foundation for pattern studies is the application of the Poisson distribution, which If it is desired to determine the probability provides a useful approximation of the binomial that exactly three of the subquadrats within a probability distribution. Other measurements, quadrat will be occupied, the equation such as the chi-square goodness of fit statistic, variance, mean crowding, index of patchiness, and Morisita's (1959) measure of dispersion can provide .further insight regarding can be used, which is the binomial probability. randomness of population distribution. C is a constant which is equal to the number of ways r animals can fit into n subquadrats. C is This paper discusses advantages and equivalent to: disadvantages of the different measurements of dispersion, and describes SAS code which c = n! computes all of the relevant measurements from (n-r)! r! quadrat count data. which in this case (three animals in ,four",Sugi-13-153 LaBore.txt
"AN EXPERT SAMPLE ALLOCATION PROGRAM James W. Mer&erson INTRODUcrION where A univariate optimum allocation formula for a L - number of strata stratified sampling design with simple random sampling within strata may produce Dh > Nb in some strata. CochraD (1977) gives a procedure - popUlation size of stratum h for determining the optimum allocation for this situation when equal costs among strata are - standard deviation of data assumed and a fixed desired precision level is in stratum h specified. When costs among strata differ this procedure is not applicable. An explicit - average data collection cost procedure for this case does not seem to be in stratum h available in sampling textbooks. L N ~ When costs differ greatly among strat8$ and - N h=1 h especially when low costs are associated with strata having high variances and high costs are - desired size of s D associated with strata having low variances. the total sample size may exceed the sum of the number of population units. An example is presented involving such a situation. Also. a general procedure for determining allocations - standard error of the estimate s when some initial n h are greater than the corresponding N is presented. The procedure is of the population mean applicable for aetermining optimum allocations for a stratified sampling design. with simple - mean of data in stratum h random sampling within strata. for a fixed desired level of precision when costs among strata are unequal. The procedure has been Applying (2.1) n = 307. The allocations to each implemented using Pascal. Input standard stratum is computed using the formula: deviations are computed using SAS. (2.2) · FXAMPLE Given a desired coefficient of variation (CV) equal to 0.02. consider determining the optimum allocation using the following data: = = 17. = ttl 8. tt2 and n3 282. This allocation is impossible since n 3 ) N · 3 Also. n > N implies that attempts to follow,a h procedure similar to the procedure in Cochran y (1977) is",Sugi-13-154 Mergerson.txt
"default, the respective values for the variable number of surgeons would have been used. An example is presented which uses PROC GMAP to represent a map with two response variables. The ratios of surgeons per 100,000 population The first response variable is indicated_ by were computed for each county and ranked from shading patterns while the second is indicated highest to lowest. These lists were produced for the years 1978 and 1985, and the block height. The resulting map by simultaneously indicates the distribution of distributions were compared using a paired t- board-certified surgeons and population by test on the ranks. This procedure was completed county in Oklahoma. In addition, maps are for total surgeons and again for thoracic produced using data from two points in time for surgeons. comparison, and also for one surgical RESULTS subspecialty, thoracic surgery.",Sugi-13-155 Murray Lane Elkins.txt
"a SAS® Abstract data set appropriate for use with PROC GFONT is created. PROC GFONT is then used to build the symbol. By combining the use of procedure options with the annotate facility in SAS/GRAPH®, you have 2) The data set being charted is processed with virtually unlimited control over picture a DATA step to determine the general production. This paper utilizes this combination characteristics of the chart. The number of to produce customized bar charts with bars bars and the height of the smallest and largest constructed by stacking symbols either bars are determined for use in scaling the axes produced with PROC GFONT or selected from and in selecting the number of units of the SAS/GRAPH fonts. PROC GFONT is used to response variable to be represented by a single construct the custom charting symbol, PROC symbol. GPlOT is used to produce axes scaled for the data set being charted, and the annotate An ANNOTATE= data set is created which 3) facility is used to stack the appropriate number places the appropriate number of correctly sized of symbols to produce each bar. symbols in position to form the bars. XSYS, YSYS, and HSYS values of '2' are used to take advantage of the axis placement and scaling I ntraduction done by PROC GPLOT. 4) PROC GPLOT is invoked for the data set Stylized bar charts constructed by stacking being charted. The response and midpoint axes symbols which relate to the data being are scaled based on the information obtained in processed have become p",Sugi-13-156 Powers Martin.txt
"A Condensed Picture - Twenty-one Graphs on Two Pages Madelyn A. Remsburg IU.S. Army Medical Research Institute of Infectious Diseases Physical Findings 120 -l-----=---=----.-:~~~-"" en 110 /, >- -/~-:""'"":..../~""-4...~_ _;/~-- -.: .... ~'~.L:: en 100 -_-----...;- a. r - m 90 / Exhibiting statistical results of several variables on one graphical page is certainly a 80j,__, -__, -__, -__, -__, -__, -__~ 42 goal of many programmers and end users. Often, the end users are presented with stacks of graphs 38 a. on which each page expresses the results of only 35 a. one variable collected during a study.. SAS/ Graph ® has the capability of displaying several 31 variables on one graphical page, thereby offering 27 100 the statisticians and end users many advantages. Some major advantages are easier comparisons, w 90 en enhanced decision making capability, improved 80 ..J organization of data, increased efficiency of :::> a. 70 time management, and lower error rates. Specifically, my presentation deals with the 60 27 display of medical research data in a compact form. One graph displays actual values for 11 24 a. ,, variables which the investigator chose to view at en 22 w one time. The remaining graph displays mean a: 19 values for only five physical symptom variables, '- _ . / ..... / ..... - 4 but each chart plots bigh- and lo~va1ue lines. 16 Reference lines for normal values are also 40 included for two of the physical symptom 39 a. variables. TWo pages containing this very large :;: 38 amount of information is more desirable than -._.-._ ...... _.-. W I- having 21 separate pages showing the equivalent 37 '- ...... _ . / ........ results. SAS/Graph makes this concise display 36 possible. 3 6 0 12 18 21 9 15 To accomplish the task of creating stacked graphs, special uses of the GOUT, AXIS, DISPLAY, Days Post Treatment and GRKPLAY statements are necessary. The program code begins with a GOPTIONS selection of Pharmacokinetic Patients NODISPLAY. NODISPLAY is used so that each",Sugi-13-157 Remsburg.txt
"iversity and/or changing the order of terms in the ABSTRACT model. This flexibility has left many users quite confused as to which set of sums of Missing cells in a two-way. cross- squares, if any, is appropriate. The SAS GLM classified fixed effects model with interaction procedure, one of the most widely used packag- create problems in the estimation of treatment es, offers the user four di fferent types of means and in the tests of hypotheses regarding sums of squares. Type III and type IV sums of main effects. This paper presents an alterna- squares· can handl e mi ss i ng cell s but only in tive method for analyzing such data in two certain cases. However, for convenience, situations: (1) unobserved but existent treat- users frequently calculate F-statistics asso- ment combinations, and (2) nonexistent popula- ciated with missing data without understanding For unobserved treatment combi nations. ti 005. which hypotheses are being tested. Not only modified marginal means can be used to test is this logically backwards, but the hypothesis hypotheses about mean parameters. For nonexis- is often neither of use nor of interest. tent populations, linear relationships of means The purpose of thi s paper is to exami ne of all filled cells should be constructed, and simp 1e procedure that may be used wi th mi ss i ng the hypotheses tested according to the purposes cells in two situations: (1) the missing cells of the researcher. This alternative method occurred by chance and not",Sugi-13-158 Sanguanruang Koonce.txt
"antine Infant Health and Development Program stanford University fusion likely to result when the different ABSTRACT types of correlations are misinterpreted as if they are interchangeable. Two or more separate groups are sometimes combined to compute a product-moment cor- At about the same time Simpson (1951) relation coefficient between a pair of illustrated and explored the effects, variables based on all individuals in the sometimes paradoxical, of first and second combined group. The resulting correlation order interactions in three way con- may be substantially different from the tingency tables. He warned against individual intragroup correlations, as amalgamating across classification vari- well as from the intergroup correlation ables. simpson's paradox also has been calculated on group aggregate statistics. shown to apply to correlations among con- Discrepancies are most. likely to occur tinuous or dichotomous variables in the when the groups differ strongly with presence of a third classification vari- respect to one or both of the correlated able (see for example Paik, 1985.) variables, or with respect to a third confounding variable. Which type of cor- Kraemer (1978) developed a theoretical relation is appropriate for a particular model which formally relates sample esti- application is a logical rather than mates of population parameters for the statistical issue. There are times, for interunit (Robinson's ecological), example in multisite clinical trials, when",Sugi-13-159 Shing Constantine.txt
"SAS was selected for the analysis and Efficient utilization of disk storage reporting system due to its ease of is a critical issue for many data use. Originally this system used SAS processing operations. Physical size to map the disk volume tables of reductions and decreasing cost per contents (VTOC' S) . We discontinued megabyte of storage seldom keep pace this practice in order to reduce the wi th rapidly growing storage needs. maintenance necessary when new types of Rarely used files are commonly kept for DASD or new VTOC organizations are years because it is difficult to find introduced. We found that we could use out who is responsible for all of the FDR COMPAKTOR to perform the disk files and whether they are necessary. mapping required for this proj ect. In Existing free space is frequently this way COMPAKTOR keeps the DASD and unused because those who need more disk VTOC characteristics straight and lets are ignorant of the existing free us concentrate on accurately accounting space. for the DASD use. A flexible disk accounting and PROCESSING DESCRIPTION reporting system for an IBM MVS/XA user was developed using SAS (1) to process Processing is based on three small data gathered by FDR COMPAKTOR (2). datasets used as tables. The first This system provides chargeback by disk table contains disk volume serials, and volume and/or dataset name, free space device types (EXHIBIT A). Billing accounting, dataset name convention account codes are included so that a assurance, and disk volume default account code is charged for the reorganization guidance. entire disk volume. The second table consists of account codes and the names",Sugi-13-16 Boyle.txt
"There is certain required information that ""VBAR "" statement with options IISUMVAR II and must be displayed in graphs used for technical ""GROUP"". A graph resulted which was all in reports. One who is involved in presenting one color, had three titles (the first larger graphic information has a format which than the succeeding two), crosshatched bars, particularly appeals to that person. The an ordinate-axis label of ""MEANSUM"" (which is format to which a given software package meaningless to most clients), and some defaults may not be the desired format. abscissa labels with dingbats. Let us call Enhancement is possible by experimenting with this a ""Bare Bones"" representation. The available options for presentation until the labels for this first attempt were due to desired format is obtained. This poster SAS/BASICS*, not SAS/GRAPH*. The user may session presentation deals with application of desire that appropriate labels appear, and PROC GCHART to data as an example of graphic extraneous dingbats and labels be removed. format enhancement for technical reports. The use of patterns other than crosshatching to discern columns is also desirable.",Sugi-13-160 Singer Bobik.txt
"WEIGHTED STATISTICAL MEASURES FOR GROUPED DATA Nancy Stevens, Texas Education Agency essential for calculation of the statistics INTRODUCTION are: Research in the social and policy sciences 1. One observation for each school district - often combines a methodology that defines the group (DISTRICT) the individual as the unit of analysis with data that is available only at the group level. 2. A variable representing the number of There are two directions the research design pupils in each school district - the unit of can follow--either modify the data to analysis (PUPILS) correspond to the unit of analysis or modify the calculations for use with grouped data. 3. Per-pupil revenue equal to total revenue The major benefit of the second approach is divided by number of pupils (PERCAP= the smaller data set--one observation for REVENUE/PUPILS) - adjustments to revenue each group compared to one observation for (cost of living or price differential indexes) each individual. The advantages of working and number of pupils (need equivalence with a smaller data set sometimes outweigh scales) are made before computing the the additional time required to modify average statistical calculations for use with grouped data. 4. Variables for number of pupils (PUPILS) and per-pupil revenue (PER CAP) appear in the This paper describes a procedure for data set in that order (matrix configuration) calculating weighted statistical measures for grouped data. The procedure entails (1) 5. Data set is sorted by per-pupil revenue creating SAS® data sets, (2) modifying statistical formulas, (3) using SAS It is also assumed that the number of pupils statistical procedures, and (4) writing basic in each school district varies. SAS code to calculate statistics. Statistical measures include general statistical STATISTICAL FORMULAS dispersion measures as well as income inequality measures and measures developed The following statistical notation is used through research in school finance. The throu",Sugi-13-161 Stevens.txt
"The M-estimate was first introduced by provide the inital estimate and the scale Huber (1964) and was shown to be a powerful parameter estimate in order to use PROC NLIN robust method for location and regression to obtain the M-estimate with a specified parameters. With a specified weight function, weight function. In Section 2, a brief review a macro program was developed, utilizing FROC M-estim~te of the is presented for the one UNIVARIATE, PROC LAV, and PROC NLIN, to sample case and the regression problem. automatically obtain M-estimates for the Section 3 reveals the algorithm and the code simple linear regression morlel. The one for this automatic M-estimate macro program. sample location problem can easily be solved A-biophamaceutical example is used to as a special case. The maero procedure is demonstrate the application of this macro shown to be very flexible and easily mortified program in Section 4. Finally, possible for a variety of Wfunctions, as well as, modifications for this macro program and more complicated models. In addition, for concluding remarks are found in Section 5. comparison, the traditional least squares estimate and the least absolute value estimate are listed in the output. II. A BRIEF REVIEW OF M-ESTIMATE I.",Sugi-13-162 Yuh Sullivan.txt
"RACT INDIVIDUAL DATilSET CONSIDERATIONS The level of detail of SAS datasets can The compentency of SAS datasets is based on vary by application. If we think of a SM the datasets' structure, content and dataset as no more than ~ collection of SAS relationship to other datasets. For the variables then a competent SAS dataset is structure of 2 SM data sets to he no more than a collection of competent SM equivalent every element in the 2 sets must variables. To be a competent SAS variable be the same. That is, each data set must the variables attributes must meet the be a subset of the other. Data editing for criteria below. completeness and consistency can be described at 4 levels. Three levels exist The NAME assigned to the variable within a SAS dataset, the fourth is between should be a meaningful acronym and/or data sets. Internal integrity can be be restricted to less than 8 characters assessed with inter, intra variable checks to allow for concatenating characters as well as intra observation checks. in array or MACRO processing. Inter-dataset logical scans for structural consistency can be facilitated with the use The choice of variable TYPE (character of the contents pcocedure with an output or numeric) is important. out option. This four tiered approach to Representation of numeric information data editing is described with emphasis on must address exceptions by the use of structural integrity. Examples of the lack special missing value codes. It may be of structural int",Sugi-13-163 Aitchison McLaughlin.txt
"THe KID C.:;RE SVSfEM: OOCTDR-FRIENDL'/ REPORTS If-a A. Bader-, New York City Health ~, Hospitals Ccrpocation Dcodu::::ed in a DATA NULL step. To make 'things easy for thp~ doct;r, the report should The Kid-CarE Svstem (pot its ,8-a1 ;;affi2) was devised as a quality assul""ance and be layed out in sections pal~alleling the medic.al education tool far pediatJ ic: car-e patient's chart. g11.'en in public hGspitals. Each physicldn newly assigned to the Pediatr""ic Emergency The Individual Case Report was designed Room is given do set of g-tndel ine rules to bE-' in just this way to retrieve from the dat.3 used when treating somE cOiflmonly seen base as much infol-mation as the doctor would illnEsses. Close to 300 items of inform.J.tion look for when reviewing patient records. listEd On the Pdt-ient's chart may be entered into a SHS4 data base. f(id-Care evaluates t.hH Wha t abo"", t the pcevious 1 y ment ioned missil1g data problem? I f we just label 300 doctors' actions for adherence to thp. spac.es on the repoct and leave 85% of them guidelines and identifies each instance when blank, we'd be back whel-e we started wi th a non-authOl-izeij ""exception"" to the rule~~ has In pl~act-ice, our solution w,as a PRINT~ PROC occur-red. compromise. A few items of information al-e so basic tha~ a special place is r-esecved for The Chief of Pediatrics receives a report: For ttl£> morlth of June in County them on each report~ '-.lhethe!- or not they General, 17Y. of the pharynqi tis cases ,""Jere appear fa, a particular case. Thus, spaces are fu,l1is~led for patient and physician 1.0., misdlagnosea as U.R.I., 13i'. of pneumonia received unnecessary tests, whi le 9~~ of diagnosis, date and time of visit, age, pneijffiOnia had tests omitted, 22:1. of asthma tempel-ature. etc. The balance of the had incorrect follow-up, etc. information appear's in the ""chact"" fOI-mat. lhe Problem It-IE' ""char~fQrmat - For the information that typically varies from patient to patient~ a different techn",Sugi-13-164 Bader.txt
"HAPPY HAVEN PSYCHIATRIC CENTER: DATES IN DO LOOPS Ira A. Bader, New York City Health & Hospitals Corporation The Problem keep in mind that since the DO loop is bounded by SA5* dates. the inde~ value at each iteration of the DO-Loop will also be a The Special Services Division of a psychiatric hospital has four units: SAS date. Alcohol. Geriatric. Special Nursing, and Secure Care. Each uni t is housed in one 0\- Next. merge the two datasets by ward and two wards, and these wards have typically date, resulting in an RX dataset wi th the propEI- uni t added to each obse!~vatiol""l. changed several times overta period of eight years. Such things as renovations, changing hospital census patterns, and new PROC SORT OATA=UNIT; BY WARD DATE; construction have led to moves from ward to PROC SORT DATA=RX; ward. BY WARD DATE; DATA ALL; The hospital director has requested a ""simple"" data base that will allow reportIng !""IERGE UNIT RX (IN==INRX) j BY WARD DATE; what medications ,were used in the different units on any particular day. Unfortunately, IF INRX; this may not be so simple. Although for the Now, when the director picks a date far past few years all drug orders have been tt.e drug order report, the right unit will entered into a data base, the drug order form appear. Figure 1 shm>ls a sample report, witt> does not record the patient's unit, only the the pr""Oper unit designation appearing. ward. And the uni t-ward relationship has been do changing one. The problem now is how to best ddd uni t designat ions to the The Lost Datasets drug-order file. Before you even have a chance to tell your director the good news, you get a call Description of Datasets from the Data Center. All your data has been inadvel-tently wiped out by a patient in a Create a dataset called UNIT where each work-release program. However if you can observation contains the first and last dates fw-nish a. list of all catalogued dataset that a particular ward belonged to a certain unit. For example, Ward",Sugi-13-165 Bader.txt
"lahan Associates The purpose of this paper is to describe two Abstract macros, %BREAKUP and ioSPLITUP, which were It is often difficult to follow the results developed to break one data set into many for a particular BY group, when a series of data sets, each of which could then be SAS@procedures with a common set of BY analyzed by the same stream of SAS PROCs. variables is processed. The output from a First, the macro %BREAKUP is described; series of SAS procedures and data steps are %BREAKUP creates one data set for each often used to ""tell a story"", and while the unique combination of BY values. Secondly, results of any given procedure may be easy macro %SPLITUP is presented. %SPLITUP is to read, it becomes more difficult to follow similar to %BREAKUP except it utilizes a a particular BY group from procedure to control data set and has the ability to procedure when the results are separated by create non-mutually-exclusive data sets; the results of the other BY groups. In i.e .· one observation from the initial data other words, multiple analyses on each BY set can occur in more than one of the group result in output ordered by PROC, resultant data sets. rather than by BY group. Macro %BREAKUP Processing can be further complicated when large data bases need to be split for Macro '%BREAKUP divides a large data set into analysis into smaller more manageable or smaller data sets, one for each unique more appropriate BY groups, or when the combination of BY values, and then al",Sugi-13-166 Carpenter Callahan.txt
"had a fairly small number of heavily sampled stations at fixed locations where Data sets are typically merged with at least biological information was collected one BY variable. Usually the values of each (biological stations), and a large number BY variable are unique in at least one of of randomly located stations used to the data setS. The MERGE statement is monitor the physical and chemical designed to deal with data sets that contain environment (pIc stations). These pic distinct BY groups. When these BY groups sampling locations were scattered and may are not distinct or do not exist, BY or 'may not have been located close enough to variables may need to be adjusted or added the fixed biological stations to be truly to one or more of the data sets before the useful in the analysis. merging process can take place. 5~ Consider two data sets, each of which contains observations collected at various locations deSignated by a coordinate pair 4 (X, Y). The resultant merged data set should contain all possible pairs of observations 3 from the two data sets, that are taken Y within a stated distance of each other. In 2 this case BY variables, which will create the desired data set, do not exist. A set of BY variables must be created that will 1 contain not only information on location but also distance. The problem is compounded when the data sets are large and multiple passes of the data are not o 2 1 3 4 5 6 7 8 feasible. X So~gle · B,,,,og,oo, LOoatlons · Pic Sa"",'e '-""O~""Ohs FIGURE",Sugi-13-167 Carpenter.txt
"SAS/AF® UTILITY MACROS Karen Crandall Eastman Kodak Company INTRODUCTION %* parse FT; = %SCAN(%QUOTE(%SUPERQ(DSNAME».l); %LET FT This poster presents three macros to be used with SAS/AF®: %* validate; CKVAR, CKDSN. and CKNBR. %CKVAR(%QUOTE(%SUPERO(FT») %IF &ERRNBR = 0 %THEN %IF %SCAN(%QUOTE(%SUPERQ(DSNAME».2) A= %THEN %DO; CKVAR checks that proper SAS® nomenclature has been used for %* parse FN; naming a variable. This macro is used in situations where the user %LETFN= specifies a variable range (for example, NUMBERI-NUMBER8). %SCAN(%QUOTE(%SUPERQ(DSNAME».2); %* validate; The NA¥E attribute finds an error because the variahle. exceeds a %CKVAR(%QUOTE(%SUPERQ(FN)) length of 8. CKVAR parses the string into two variable names and %END; checks each one for proper syntax. %IF &ERRNBR = 0 %THEN%DOj %CMS SET CMSTYPE HT; CKDSN checks that proper SAS nomenclature has been used for %CMS STATE &FN &FT A; naming an output dataset. Once verified, the output dataset name %IF &SYSRC = 0 is compared to the datasets that exist on the user's A disk. If a %THEN %00; dataset of the same name is found, the user must use another %LET ERRNBR = 5; dataset name. CKDSN is analogous to the INPUT attribute except %LET DSNAME = ; it is used to cheek OUTPUT datasets. %PllT ERRNBR '"" &ERRNBR; %END; %CMS SET CMSTYPE RT; %END; CKNBR validates a number that has been parsed fwm a string of %END; information. This is analogous to the DATATYP macIO function %ELSE %DO; except it permits the use of signs and decimal points. %CKVAR(%OUOTE(%SUPERO(DSNAME») %END; %END; %ELSE %LET ERRNBR '"" 2; THE MACRO CODE %MEND CKDSN; These macros can be placed in a MACLIB and simply invoked %MACRO CKNBR (NBR); within the SAS/AF programs. %* Acceptable cbars for first position; %LET CHARI = %STR(OI23456789.+-); %LET SIGN = %STR(+-); %MACRO CKVAR (NAME); %. define valid ,characters; %LET CHARS=ABCDEFGHUKLMNOPQRSTUVWXYZ; %IF %DATATYP(&NBR) '"" CHAR %LET ALL=&CHARS.0123456789; %THEN%DO; %* determine length of SAS name; %LET",Sugi-13-168 Crandall.txt
"basis. The idea of letting the machine perform what can be a tedious task was the A file organization scheme for SAS® files in motivation behind writing BEAUTIFY. CMS and MVS environments and an EXEC to make SAS programs more readable (written in 2. File Organization REXX on an IBM/3090) are presented. Both these_ tools are intended to be of use in The motivating idea behind the File enhancing programmer productivity. Organization scheme: - gives a hint of file contents Introduction - sets up psuedo-subdirectories on CMS - is mnemonic This is a report with two themes which are - is task Oriented actually inter-related. A file organization - develops use of meaningful filenames scheme is described. This presents a plan for the disciplined naming of CMS files and for Anyone who has done enough program easy access to files on disks. BEAUTIFY is a development realizes that for large projects, CMS EXEC which takes as an argument the there is a need for being systematic in keeping f""llename of a SAS program and converts it to a track of the different files. There are, typically, more readable form. program files, outputs, plots, reports, etc. A systematic naming scheme for all these files is The file organization scheme is very handy. suggested, which makes it easy to keep track Keeping track of CMS files can be difficult them. because there is no way to create sub- directories. Another problem with data analysis 3. A Program for BEAUTIFYing SAS is the naming of files as progl, te",Sugi-13-169 Jares.txt
"Producing Efficient SAS® Applications Daniel J. Squillace SAS Institute Inc. Cary, N.C. OBJECTIVE DATA B; INFILE A; INPUT X Y Z; The objective of this paper is to acquaint you is equivalent to DATA step coding techniques, PROC usage consideration-s, and SAS System options which generally result in more efficient SAS DATA B; INFILE A; applications. Topics we will cover include INPUT X Y Z; OUTPUT; RETURN; Motivation for efficient applications Processing performed during each loop iteration DATA step considerations includes resetting all variables which have not If you refresh been RETAINed to missing. Commonly used procedure considerations each variable during each iteration of the DATA step yourself or are willing to forego having SAS/FSP® the variables reset to missing, you can saVe some time by explicitly controlling the looping SAS/GRAPH® yourself as shown below: SAS Display Manager DATA B; INFILE A END=EOF; Some SAS system options DO UNTIL(EOF); INPUT X Y Z; Data set block sizes OUTPUT; END; MOTIVATION FOR EFFICIENT APPLICATIONS The percentage CPU time reduction resulting from this technique will depend on the number of variables in the DATA step and the amount When an application begins to cost more than of processing done within the DATA step, the user is willing to pay, then we have a There are other things to consider when using motivation to make it more efficient. The cost For one, _N~ will always be this technique. of an application may be expressed in terms of one. For another, ""INPUT @;"" will have to be resource utilizations or data center charges. terminated with an explicit ""I NPUT;"". Applications which are resource intensive or which are run frequently are usually the first to require attention. Consolidating Constants In general, the additional effort you put into making an application more efficient should be The DATA step compiler does not recognize and consolidate duplicate constants. Therefore, you in proportion to the savings which can be gain",Sugi-13-17 Squillace.txt
"MULTIPLE CONCURRENT UPDATES OF A SAS® SOFTWARE DATA SET, AN ALTERNATIVE TO SAS/SHARE® SOFTWARE Jude l. Naes. Jr.. Emerson Electric Co. Edward B. Dailey, Emerson Electric Co. Introduction SASISHARE is an excellent product designed own forecasts. In addition, a data step needs to allow multiple people to edit and update a to be run after each edit session to assign single SAS data set at the same time. Howeller~ additional variables, so that error lists and there are reasons lihy SAS/SHARE may not work for individual reports can be run. everyone. Thi s paper descri bes an alternat i ve method of allowing concurrent updates of a SAS At Emerson, SAS is licensed and running under data set. The method is used in the Finance TSO on an IBM'"" mainframe. SASISHARE, ho""ever, Department at Emerson Electric Co. is not licensed. Our solution to the needs of the Finance Department was to keep a sAs data set with all forecasts on its own TSO database, and Why SASISHARE Isn't For Everyone also to assign the relevant forecasts to a SAS data set on each analyst's TSO database. There are three reasons why you may not be ab 1e to use SASISHARE. Fi rst, it may not be The analysts edit their own data sets. Addi- available at your site. Second, you may need to tional variables are assigned with a data step process the data set after it is edited. Third, after each edit session. Analysts can run re- you may want to restrict aCcess to certain ports against their own data sets. After all observations on the data set. editing is completed, a manager or the lead ana- lyst consolidates the individual data sets and Many departments and campan; es are on a 1 im- runs reports against the consolidated data set. ited budget. It may be diffi cult to cost just i- fy a product whose purpose is to allow multiple The database structure is illustrated in fig- concurrent access to a data set. The benefits ure 1. We have several SAS systems that use of licensing SASISHARE may not outweigh the this structure",Sugi-13-170 Naes Dailey.txt
"Menu Driven Statistical Defect Analysis Ed Jurgensen Tom Lorman Tom Pineo people had no knowledge of SAS or how to use a program. To make the system usable to these people, an ISPF system of menus was set up. These menus prompt the user to enter the desired selection criteria. The. end 1.1.1.1 Abstract. A common system for tracking and product is a common format graph and detail data that is reporting Inspection and Test hardware performance was easily understandable r"";th a minimum of instruction. needed by three functional areas. This paper shows how we solved the problem of getting statistical defect 1.1.1.3 The System. The 'System' is made up of several information out to our users in a form that is easy to distinct parts. These consist of the following items use and understand. and will be discussed in detail under separate sections. The user enters the selection criteria via a menu o The database driven system to generate graphics and tabular support o The menus data. The system.utilizes IBM products (ISPF o The statistical gr~phics (Interactive System Productivity Facility), OMS o The supporting detail data (Dialogue Mana¥ement Services) and ClIST) in combi2ation For the non-programmer, the parts are transparent. with SAS (tm). The graphs (SAS/GRAPH GPlot (tm}) The menus control the operation of the programs. This contain the defect data along with the median and makes the system easy to use. The users can get the Standard Deviation lines. These graphs easily show the needed information with a minimum of training. If a user if there are any problem areas requiring corrective person is more knowledgeable in SAS, the databases are action. available to them to write their own programs. This system provides a problem determination tool The method of creating these statistical charts is as that can be uti 1 i zed by non-progralllllers throughout the follows. facility with a minimum of training. o Access the menu and select the option to create a statistical defec",Sugi-13-171 Jurgensen Lorman Pineo.txt
"Research Institute Segment 3: When data generation is completed, the user is asked to ABSTRACT choose a graphic output device for the plot. The user may plot the graph on In a computer system that is based primarily on applications the Zeta 8 plotter or display it on a Tektronics 4208 graphics terminal. written in a high level language (eg FORTRAN), the integration of SRS Other device types can be supported when the need arises. G6F"" always Software may present some problems for both programmers and users. saves the graph to a graphics catalog, even if the user is running it on a These problems include data accessibility, program and file maintenance, unsupported device. The graph can always be replayed later by running and user interface. This paper will present a FORTRRN program, running GBFn on a supported device. under uns, that addresses some of these problems. Using both user inputs and data retreived from specific data files, this program will generate a Segment 4: The DeL command procedure GBFn.COtl is built (Appendix SJlS program to process and plot toxicology data such as animal body 3). This procedure assigns the correct names for SVS$IHPUT and DATA. It weights and food consumption. This FORTRAN program also creates a Del then invokes GBF"".SAS, which will be created later in Segment S The log command procedure that invokes the SAS program. Control is passed to the file created by GIlFM.SRS IS automatically deleted at the end of the command procedure at the end of",Sugi-13-172 King Yao.txt
"INT) to produce a global macro variable This paper describes a Macro system to aid enVlronment. When the variables are needed users of the SAS system in report writing. they are referenced by macros provided to Traditionally, customized reports are produced generate code for printing the headings (%TH) by writing PUT statements to place the heading footings (%TN) and body (%TB) of the report. ' text, body of the report, and footing text on These four macros plus one utility macro the page. The disadvantages of this method are (%REVERSE) make up the template macro sytem. that it is tedious to program and difficult to The macros use techniques that may be of change. The system described here changes the ~nterest general to users of the SAS system who traditional coding technique with the use of a are not lnterested in report writing. Macro template and macro calls. The user enters the %TPRINT uses CALL EXECUTE to execute %GLOBAL heading text, locations of variables, variable statements to create global macro variables names and their formats, and the footing text from an executing data step. %TPRINT also into a text editor producing a template. This constructs macro expressions and stores them in user defined template is processed by the macro variables to be used in %IF statements in macros to position the data on the page. The macros %TH and %TN. Macro %TB uses the advantages of this system are 1) the user can PARMBUfF option so it can be defined to accept see the format of t",Sugi-13-173 King.txt
"the use of the PARt.4BUFF the SAS® System allows is ten. the parameter list uses keyword parameters to accomodate ali ten TITLE option in calculating the number of parameter values statements even though only one may be used. (N) supplied in a macro coil. Once N is calculated, a This preset limit of ten allows this macro to be predefined global macro variable is defined for each placed in the outocan facility for use with no respective value of N. The primary advantage of u!ling revisions. This macro may be invoked in the following ways: this macro with the PARMBUFF option is that user need 0 only supply the appropriate porameters. The macro Scanner calculates the value of N and subsequently invokes the user's macro via the 7.&VAR statement. %""Tffi.ES{2.Tl =ONE,T2=1WO) %1lTl.ES(4,T1=ONE,T2=TWO.T3=THREE.T4=FOUR) Ere. ItmlOIJUCTION When invoking macro, parameter values ore supplied Note that the first parameter is a positional Q parameter which serves as the ending value in to the macro by use of positional or keyword parameters. the DO loop. If the value of N is two, then two For some tasks, the number of parameter values may keyword parameters are defined in the call. vary and cannot be predicted prior to invocation. Ukewise. if the value of N is nine, then nine Moreover, certain tasks may need to be performed an keyword parameters are defined in the call. unknown number of times (N). These problems can be However, if the value of N is eleven or greater, alleviated by using",Sugi-13-174 Kreamer.txt
"annot be customized by adding or removing terms. The CADAE computer program guides non-statisticians through experimental The resulting simplicity allows users design, data entry/management and to carry-out the multi-objective statistical analysis of a response surface searching scheme with multi-objective searching scheme based only a little expert assistance. upon Response Surface Methodology (RSM). The program consists of 2~ Some Expert Assistance is Required - screens written usin~ the SAS/AF Model diagnostics are produced with the system on a MicroVAX II. recommendation that they be examined by a knowledgeable data analyst. The searching strategy is to fit a response surface model for each of several performance attributes GETTING STARTED (dependent variables) over a single factor space and to utilize contour The instructions for using CADAE are to plots and grid searches to identify the fill in all information requested by factor level combinations which meet each screen, moving among fields within objectives on multiple performance a screen by pressing ""key pad 4"" and attributes simultaneously. ""key pad 5"", and then press ""PF3"". Central composite and 2k designs are The initial screen is a menu with the offered with options to block following offerings: orthogonally and to choose sample size according to the size of the factor effects to be detected. Randomization is applied. PUIlPOSE. PROGRAI'! Data entry employs SAS/FSP * to retrieve Co ....... nd .. --) the design fa",Sugi-13-175 Levine.txt
"urdue University ABSTRACT PROBLEM For the past seven years the Division of The simple modification of the programs Financial Aid at Purdue University has run a initially saved manhours. However, examination standardized set of annual tables to produce of the costs in machine time indicated that demographic information on financial aid method was very CPU expensive. To produce one recipients. All the change in financial aid complete set of the fourteen tables broken down policy brought about during the Reagan by school CPU cost was approximately $880e The administration has created an increased high cost generated questions regarding the interest in the impact of financial aid on the value of the goodwill created by providing the student population. Several schools within the tables to the schools versus the cost to the University expressed interest in knowing the office. DFA made the decision to continue to types and amount of aid their students received provide the information to the schools. In an and how the figures compared to those of other effort to keep costs down, other alternatives schools. As a result, last year the annual were examined. tables were broken down by school for the first time. This proved to be CPU expensive. The Division of Financial Aid made a decision to DECISION continue to provide this service to the schools so a new approach was desired. The programs The choices available were limited. At the had been written in RAHIS. SAS seemed a present time,",Sugi-13-178 Muffett.txt
"rch Institute of Inf'ectious Diseases Fort Detrick Frederick, HD 21701-5011, USA 2World Health'Qrganization, Geneva, Switzerland Abstract provided by their CHW, the name, distance from The SAS system was used in a twelve year household, and duration of service provi~ed by population registration-based epidemiological the nearest dispensary, and the geograph1c study conducted by the Hospital Albert Schweitzer location of each village (Le., mountain or in the rural Artibonite Valley of Haiti. The valley). A total of 190,862 CHW records were study incorporated vital statistics and health Coded for this study. status data obtained during home visits by community health workers and mortality and Disease-specific morbidity and mortality data morbidity records obtained from the hospital were obtained by review of hospital admission and admission and outpatient reCOrds. The outpatient clinic records over 12 years. epidemiological analysis included the first Information coded and entered from the hospital detailed census of the area, disease morbidity and clinic records included a diagnoSis code for and mortality rates, and the effect of the selected illnesses, hospital number, location socioeconomic, health program, and geographic of reSidence, date of admission or clinic visit, factors on disease rates. number of days of inpatient care, and outcome (i.e., death or discharge). A total of 98,741 Base SAS and SAS/GRAPH8 provided the full hospital and clinic records were coded for this",Sugi-13-179 Oland Stansfield.txt
"I\EW 1'£I\St.REJ'ENT DATA 5OLI<CES FOR MVS X/A ANJ ITS 5Ll35YSTEMS H. W. Barry Merri 11, Merri I I Consultants OVERVIEW in wh i ch Test MVS 2.1. 7 reversed the order Pending Interrupts (TPI) 1/0 is serviced. Formerly, TPI interrupts were serviced from low to high CPU number; now} the selection for hand ling TPI is from high to low CPU number. 1. TYPE 70 CPU DATA The TYPE70 1/0 interrupt rate on 30905 is (5%7) than the TYPE7810 lOP somewhat higher activity rate. The difference may measure 1/0 2. VECTOR FACTILITY 1'£I\St.REJ'ENT redrive requests. The recursive scan of the dispatcher queue ~CHITECTLRE 3. TYPE 71 EXTENJEO STORAIE before entry into the wait state, the primary cause of the law ut j I i zat i on effect discussed on page 98 in [lJ, has been significantly reduced. 4. TYPE 72 WORKLOIlIJ I'£I\St.REi""ENT al I instead of scanning address spaces the MVS (including logically swapped ASIDs), 2.1.3 dispatcher scans only address spaces in 5. TYPE 74 DEV ICE 1'£I\St.REJ'ENT memory. MVS 2.1.7 eliminates the recursive scan entirely, which has produced a measurable reduction in uncaptured CPU time. See CPlXM-ITM b. TYPE 78 IID FOR 3090 in the RMFINTRV section of Chapter 40 in [2J. 1.1 SERVICE LNlTS PER SECONJ 7. TYPE 78 VIRTUAL STORAGE The Service Units per second value (SU_SEC, also cal led the Machine Dependent Constant, MOC) is now contained in the type 72 record. The table 8. 1 MIPS 2 MEG laok-up in VMAC7072 , whieh set SU_SEC fram CPUTYPE and CPUVERSN, is not used after RMF 3.3, and updates to VMAC7072 with each new processor are no lanser necessary. The importance of SU SEC is unchanged, and its value can sti II be determinedj see [lJ, pp b86-687. 1. TYPE70 Because the SU_SEC is derived by IBM from RMF CPU Activity benchmarks (analyzed with you who's know software), the value has proven to be an There have been several significant changes to excel lent estimate of the processor capacity TYPE70 since 1984. prior to the avai labi I ity of actual hardware A major ben",Sugi-13-18 BarryMerrill.txt
"tment Ortho Pharmaceutical Corporation Raritan. New Jersey 08869 Abstract - the capability for users to select an In the CMS environment. a user-friendly appropriate measurement unit for each test system written in REXX language allows an parameter, interface between the SAS~ system and the Interactive System Productivity Facility - the capability of handling the output for- (ISPF) while creating panel Screens for users mat for periods and nested periods, to enter information for generating standardized vital signs reports. Based on the type of study - the effective use of the VM/BATCH facility design~ users are able to enter specific page for submitting multiple SAS jobs titles for-the reports. control input SAS data simultaneously. sets, enter period codes (with nested period codes if they are appropriate for the study). and specify the measurement unit for each vital ISPF/CMS Used to Create SAS Source Code sign parameter. This system will generate the properly formatted outputs based on the specific Under CMS, the ISPF is used to generate the information entered by users. panel screens. REXX files are written to work with the panel screens so that the information This system requires: (1) a SAS format entered by the user can be transferred into REXX library which contains investigator codes, variables. The REXX variables are then placed treatment codes and sex codes, (2) a SAS data in SAS statements, whereby the information set which contains the patient randomization asso",Sugi-13-180 Pan.txt
"me. This I imit may be set by the System 1. ABSTRACT This coomand procedure wi II permit the user to Manager and can be detenn i lied by i ssu i 09 the following commands at the system prompt. submit $AS jobs for execution as a background process, thereby freeing the terminal for other activities. S x=fSgetjpi("",'PRCLM') $ show symbo I x II. INTRODUCTION As might be expected, there will be an increased demand for system resources each and every time A. DESCRIPTION OF COMMAND a $AS job is spawned as process and image a,~subprocess activation are two very cpu intensive The SPOOL coomand wi II spawn named activities. Therefore, the user should not be identically to the SAS file being submitted for surprised if the number of subprocesses execution. This permits the user to easi Iy permitted is I imited to one or two. In identify which subprocess is executing which SAS addition, spawned jobs take over the attributes fi Ie. of their parent processes. This means that-the subprocess will compete on an e<:Jua I bas is wi th The user will be notified via a broadcast the parent process for the cpu {execute with the message when execution of the subprocess has same priority as the parent process). completed. The system will pass logical names and logical B. COMMAND SYNTAX name tables to the subprocess by default. All system logicals marked CONFINED wi II not be SPOOL [fi lename] [.sas] passed to the subprocess. The user may enter: FOR ADDITIONAL INFORMATION CONTACT the name of the fi Ie,",Sugi-13-181 Rosen.txt
"SAS USER GENERATED INQUIRY (SUGINQ) A. S. SCHLEGEL B. E. LEE EXAMPLES INTRODUCTION The following two screens show what is seen by As quick and efficient as programmers can become the user to generate a report usi""ng SUGINQ. at producing SAS systems there are some problems that come up once the system is complete. Programmers can quickly create reports for users, however a lot of time must. be invested in teach; n9 the user enough SAS to create the; r own reports. This can really waste a lot of a programmers time generating reports. EDIT SAS DATA SET, ilQRI(.T~P SCREEli Many times what is really needed is a way to inquire against the SAS file. For example, if l'alP;; SYSTEM REI'aRT SfitcTIOH REl""UC~arr you want to know how many records meet a certain . . . . FORESTlty DEI'UTMElfT . . . . GIUD _IEIt, _ _ _ "" ..... lID, _ _ criteria there is no easy way to list those DISTIlICT, 11 HT JCL ... ss, PUTI' ....1'. alD I'IIlE lID, without creating a report. If you use FSEOIT DAIIGEit pall"", x OATE Ta EltOIIIFFIIJI'G, TOR INSPECTED. 16 then you must press PFS/17 to see each individ- TItAIlSNISSION palP;;, _ ~~~~!: NUTN OF IVII. _ DISU,NCE FItO!! CENTER UNE, _ tR. _ _ ual record that meets the requirements. You do not have a list of the records that succeed. . .. . ENOtllEERIMG DEPARTMENT . . . . lAYOUT """"N ""'SSIGNEO. _ UMITtAlSI There is also a limitation with timeliness. If IIELEASED DATE, _ _ tlOIU( NDEIt DISTIUCT, RETtRED. the user needs some information and cannot write .... LINE DEI'ARllIElIT ...... the report himself then he is at the mercy of COllf'lfTED DATE, COMTIUICTOR. the programmers time constraints. By including the SUGINQ macro in your SAS Description Here the user entered 11 in systems you allow the user to do inquiries District, an X in Danger Pole~ and an 86 in Year against the system. This will have several Inspected. Requesting a list of all danger beneficial side effects. The user will feel poles for district 11 during inspection year much more i tJdepen",Sugi-13-182 Schlegel Lee.txt
"& Lifestyles In presenting the SAI.T. process it is critical that a ABSTRACT prospective client gain a clear understanding of the relationships which exist between these seven steps. This is difficult due to the technical nature of the methodology. Estimates of a manufacturer's monthly retail sales By presenting an example with charts and graphs key of product can be derived through the tracking concepts of the methodology can be highlighted. The reg/stratton cards. The Sales And Inventory illustrations help to tie each step together. SASIGRAPH® Tracking (S.A.I. T.) system is a method by which software is an excellent tool for effectively building these these estimates can 'be obtained. By Inserting a tables, charts and graphs. manufacture dale stamped registration card Inside Let us now walk through an example of how the SAI.T each packaged product and monitoring both the works. Each step along the way is illustrated through the number and rate of cards returned, a mathematical model Is developed to forecast future card receipts. use of slides which were developed using PROC GSLIDE and These card projections yield card response rate PROC GPLOT. The Annotate facility was also used to est/mates which, In turn, provide retail sales enhance the plots. estimates. an The fntent of this paper Is to present S.A.l. T. illustrative example of the methodology. The presentation materials were developed using HOW llf WT. WOOK& This gives an effective SASIGRAPH® software. means of highli",Sugi-13-183 Schneider.txt
"AN INTELLIGENT INTERFACE TO THE SAS@ SYSTEM FOR USE BY PRODUCT DEVELOPMENT ENGINEERS Debra Spencer. Sandia National Laboratories D~ Introduction complex, and varied database. Until recently, the only access to the data was by batch An intelligent interface to the SAS System for processing of card decks; these retrievals and a limited set of data analysis needs is being routine analyses were run by clerks supported by developed at Sandia National Laboratories for a programming staff. The data and programs were use in a VAX/VMS environment. An existing data then moved from the batch environment to retrieval and analysis system has recently been VAX/VMS, with the SAS System and a few other updated and made interactive, with the intent commercial data analysis products available. that non-statistician users (mostly engineers) become able to satisfy their simpler analysis The old batch programs were made interactive, needs themselves using the SAS System. Since and the system is gradually evolving to a more early attempts to make the SAS System accessible friendly environment. The major functions, in to all users have not been very successful, an addition to SAS capabilities, are data experimental, intelligent interface to the SAS retrieval, subsetting, display, contents System, tailored to the particular needs of this information (e.g. how much data, what variables group of users, is being developed. The are available), and some analytical choices. interface has three modules of knowledge: data manipulation, graphics, and routine statistics. An important element of developing such an environment is the provision of a very friendly This paper describes the target users and analysis tool. The SAS System was chosen as the their environment, the problems they have had analytical basis for this system due to its using the SAS System, and the intelligent statistical power and because several potential interface under construction. users were familiar with SAS programming. Th",Sugi-13-184 Spencer.txt
"1. Obtain a listing of files from the The backing up of files stored on disk disk volume of contents (VTOC). on our IBM mainframe is done once the 2. Select files (from list obtained in 1) statistical analysis for the clinical or that are not being backed up onto preclinical study is completed. This backup storage tape, are no longer needed, is necessary so that precious disk space can and can be deleted off the disk. be freed up for ongoing studies. Select the files that are to be backed 3. A menu-driven -backup system has been up onto storage tape(s), (from listing written on our IBM mainframe using SAS/AF®. obtained in 1). This SAS/AF® application is used to copy SAS® 4. to create the Submit the program Data Libraries, SAS® programs (stored as backup tape(s). members of partitioned data sets) and, also 5. the backup tape Restore files from data stored in flat sequential files, from back to disk (to check if the files disk to tape. This system also deletes files Were copied successfully to tape in from the disk after the backup tapes have 4. ). been created and generates listings of files 6. Obtain a hard-copy listing of the stored on the backup tapes. files stored on tape(s) (using The SAS System is used to generate the in-house Tape Management System). code and JCL for all programs in this Backup 7. Delete the files on disk that have system. Programs are automatically submitted been backed up onto storage tape(s). to the operating system through the SAS/AF The options must be selected in the program screens. above order; selecting each of the above options causes a specific program screen to",Sugi-13-185 Strauss Antony.txt
"EXPERIENCE THE THRILL OF LABEL CREATION: THE POWER OF THE FORMS PROCEDURE Rebecca Swartz, Frito Lay, Inc. Why The Fuss About Mailing Labels? businesses to use the 9-digit zipcode by charging more for mail which used a 5-digit zipcode. Unfortunately, most of our At fust glance, it does not appear that departmental lists used 5-digit zipcodes. mailing labels can make a significant impact in business. However, Postal costs can and do create variable expense costs to every The following objectives were identified: company. In fact, Fdto Lay, Inc. could save at least $ 138,000 annually with the 1. Maintain one master list for all implementation of a corporate database for locations both bulk and direct mail mailing addresses. 2. Update or modify the master list to There are several hundred mass mailings made maintain aocuracy by our corporate headquarters to field locations each year. The problem is to 3. Provide labels in a timely fashion lower postal expenses while increasing to each department as needed timeliness and accuracy of mail delivery. 4. Promote the use oflower-cost bulk Like businesses everywhere, management mailing suggested that variable expenses be curtailed when possible. The solution To accomplish these objectives, it was required streamlining the method to obtain determined that the following had to happen: labels, providing accurate addresses, and migrating to bulk mailings whenever 1. Build a single corporate database possible. Bulk mail cost less than regular first-class business mail. 2. Design labels to meet postal regulations A SAS database and the FORMS Procedure let 3. Provide database update capabilities us meet our mailing needs and foster more accurate and less costly mailings. DATABASE First we built a preliminary corporate What's the Problem_ database. We consolidated the 20+ user lists into one master list. Frito Lay Mail Inaccurate addresses or out-of-date mailing Services took ownership and scrubbed it for lists contributed to increas",Sugi-13-186 Swartz.txt
"AN IMPUTATION SYSTEM FOR A LARGE-SCALE SURVEY1/ Eugene M. Burns, Energy Information Administration G. Douglas Valcour~ Energy Information Administration in a timely mannner. There is a division of INTRODUCTION 1. labor in the imputation process between the statistician (responsible for specifying the The Nonresidential Buildings Energy Consump- imputations to be performed) and the programmer tion Survey (NBECS) is a large-scale survey (responsible for the file management). The conducted triennially by the Energy Information potential for problems in integrating the work Administration (EIA). In the each round of the of the programmer and the statistician is great. suryy~ data are collected on 500 to 600 items Fortunately, the SAS System allows the integra- for approximately 7,000 buildings. The data are tion of their work in an efficient manner. The used in various reports (Energy Information 1986 NBECS is the second round of NBECS in which Ad~:linistration 1985, 1986) and are also released the SAS System has been used heavily for imputa- on a Public Use Tape. tion, and this paper describes the application Each NBECS round is conducted in two stages. in detail. In the first stage, building managers and owners are interviewed to obtain information about 2. IMPUTING BUILDING CHARACTERISTICS various characteristics of thGir buildings. such as square footage, operating hours, heating and 2.1 Imputation Data Groups cooling systems, and energy sources supplied to The size and interrelatedness of the NBECS the building. In the second stage7 billing data questionnaire data set suggest that the building showing the quantity supplied and the total characteristics item imputations deal with expendi tures for an entire calendar year are chunks of data~ rather than with individual requested from each building's energy suppliers. items. Specifying hot-deck cells and choosing As is the case with any other large-scale donors separately for each of the 212 variables survey, NBECS i",Sugi-13-187 Burns Valcour.txt
"This command tells the LSE where the initialization file exists that it can execute it at the beginning of the edit- A unique full-screen editing tool was custontized to the ing session. There are two other files that are required to SAS® System for the VMS® operating environment. It set up the SAS LSE editor described here. One file is the was developed using the V AX® Langnage Sensitive LSE environment file that contains all the syntax, and the Editor (LSE®) and the VAX Text Processing Utility other file is the LSE section file that contains all the spe- (TPU®). Four attractive features of the editor include a cial procedures to run SAS programs interactively as LSE initialization file, langnage templates that contain described in this paper. SAS syntax, the ability to run short SAS programs and look SAS LANGUAGE TEMPLATES at output quickly, and access to on-line help. The last three features of SAS LSE editor can be used by striking a few pre-defined keys. The features of the SAS LSE The SAS langnage templates contain all the necessary editor make it an attractive development tool and an al- information to write a SAS program that uses Base SAS, ternative to the SAS Display Manager, particularly for the except for PROC EDITOR and SAS macros. The VMS operating environment. templates were defined by using special LSE commands. The templates consist of placeholders, menus, and SAS",Sugi-13-188 Weaver.txt
"come Company Sue Allen, Burroughs Well come Company Janna D. Young, Burroughs Well come Company summarized ""categorically,"" with frequencies and Abstract percents. SUMSTAT requires a good deal of information The Macropedia, written by members of the from the user. The name ofthe data set to be Burroughs Wellcome Company Clinical Statistics analyzed, a list of variables to be summarized, and Department, is a group of macros which handle an option for including a ""total"" column in the routine programming tasks. The first ofthree output are parameters for the macro. The finished macros prints summary statistics, by treatment group, for any number of numeric or remainder of the information is put into a special categorical variables. The others handle clinical SAS data set whose name is a parameter for the macro. The default value for the name is VBLES, so laboratory data. One prints results and attaches we generally refer to this data set as the VBLES data flags to values which are above or below normal set. Figure 3 shows the VBLES data set used to ranges. The second prints and plots summary statistics by time. The programs allow the user to create the sample output. For each variable, the type, variable name, format, and label are given. specify labels and formats as well as variables for analysis, and produce output suitable for inclusion ""Type"" specifies whether a variable is a subsetting variable, like center in the example, a treatment- in final reports. This flexibility i",Sugi-13-189 Wold McSorley Allen Young.txt
"To be successful in Capacity Planning at This paper provides an overview of an Online least the following five capabilities are System, ""CAPLAN"" designed at the Overseas required: Telecommunications Commission by the Capacity Planning group using SAS Software. a) Mechanism to establish and agree on Service levels. This Online system provides Managers, Computer Support, Data Centre, Systems - Availability of system and SUbsystems. programmers, Information Centre and Capacity - Batch turnaround Planning with graphs and reports related to - Response time etc. the performance of the system, as well as workload analysis and forecast. b) Measurement and analysis of: The whole system runs daily and is fully - Existing workload automated. It generates daily, weekly, - Usage of Computer Systems monthly and historical graphs. - Are the service levels achieved? - Is the availability being met? MERRILL's Software collects data from the RHF/SMF and builds Performance Databases. c) A means of Forecasting the future workload Then using SAS/BASEC') SAS/FSPC') SAS/AFC') - By looking at the past and SAS/GRAPHC') the information is - By interviewing users retrieved and manipulated to create reports and graphs that can be accessed online by d) A method of assessing future hardware authorised users. requirements: 2",Sugi-13-19 Noisier.txt
"t P. Yerex, Lowell Yerex and Associates, Ltd. ABSTRACT This paper covers applications of expert systems to Statistical consultants find much of their time is assist users of complex statistical analysis pack- devoting to helping clients choose the most appro- ages in the areas of model determination, model priate procedure, setting up model statements, and statement specification, and pre-diagnostic specifying necessary options to provide a desired warnings. Methods and techniques involving analysis. For the consultant this task is often mun- knowledge representation, rule based schemata, dane and fairly simple once he or she has mastered particular packages and procedures. To and user interface are briefly reviewed. Emphasis clients this process is often intimidating-they know is upon practical considerations of implementing a what they want to accomplish but do not know how working system called Stage One for SAS® (or S.O.S.). S.O.S. is an expert system designed to to do so in the format required for a particular help both new and experienced users construct package. model and procedure statements for the analysis of linear models. S.O.S. guides users through a Frustrated users, after wading through the large consultation oriented interactive system which runs manuals, often conduct an analysis that is inappro- priate because they could not find the ""right"" proce- on XT or AT class micro-computers. Necessary information concerning the variables and their use dure. It is not",Sugi-13-190 Meredith Yerex.txt
"produced from the normalized par- This paper discusses the SAS® MACRO used ameters over a functionally related to support the technique for data analYSis group of parameters (e .g., hepatic proposed by Sogliero-Gilbert J Mosher J and group). Zubkoff. Their paper ""A Procedure for the Simplification and Assessment of Lab The transformation chosen for nor- Parameters in Clinical Trials"", Drug malization (Le. division of each Information Journal, Vol. 20 (1986), value by its upper limit of normal introduced two concepts to simplify the range) satisfies the following: display and the interpretation of lab parameter data: 1) a normalization of each 1) All transformed values are posi- lab parameter value so that it can be tive. interpreted without reference to its normal range and 2) a multivariate scoring system parameters have an upper that combines lab parameters into 2) All normal limit of of and all functionally related groups. The SAS code values are bounded below by O. used to carry out the normalization and multivariate scoring will be provided upon 3) Values outside the upper limit request. are easily found.",Sugi-13-191 Arthur.txt
"Iowa Abstract or both of the variables are ordinal, unsaturated association Consider the situation when both the column and row models exist. These models are more realistic than the inde- pendence model. variables of a. two-dimensional table are ordinal. A simple log- linear model that -utilizes the orderings of the TOWS and the Consider the situation when both the column and row columns is the linear-by-linear association model. A disad- variables of a two-dimensional table are ordinal. A simple vantage of this model is the necessity of assigning scores to loglinear model that utilizes the orderings of the rows and the categories of the row and column variables. Although the the columns is the linear-by-linear association model (Agresti, integer scores are most commonly used in practice, there is no 1984, pp. 76-80). Since this model has only one more param- obvious choice of scores for many variables and the researcher eter than the independence model, the degrees of freedom for may not wish to assume equal spacings. testing goodness orfit is (T -1)(c-1)-l. In this paper, we consider the alternative of treating the An obvious disadvantage of the linear-by-linear associa- scores a.s parameters to be estimated from the data rather than tion model is the necessity of assigning scores to the categories of the row and column variables. In many applications, the as numbers to be supplied by the researcher. The resulting model was first discussed by Goodman, who referred to it c",Sugi-13-192 Davis.txt
"University Medical Center, Durham, NC Abstract models and the testing of the proportional odds The LOGIST procedure fits the multiple assumption. An example of a situation where logistic regression model of Walker and Duncan proportional odds does not hold is found in a (1967) to ordinal response variables that take on coronary artery disease dataset collected at Duke University Medical Center. Her~ the log odds k+l possible values. In this model, logits of ratio for the relationship between a 6-1evel cumulative probabilities are expressed as linear ordinal measure of coronary artery disease and a functions of the predictor variables. The dichotomous smoking status variable is the resulting regression coefficients are identical for each of the k cumulative probabilities, except for greatest when the disease variable is the intercept terms, CXJI j=l, ···,k, which are dichotomized as ""no disease"" vs. ""at least some ordered to reflect the order of the cumulative disease,"" and the log odds ratio is the smallest probabilities. The assumption of identical when the dichotomization is ""less than most regression coefficients, referred to by McCullagh severe disease"" vs. ""most severe disease."" The (1980) as proportional odds, implies that the log log odds ratios for the intermediate odds ratio for the relationship between a dichotomizations are ordered between these two dichotomized response variable (Y ~j vs. Y <j) extremes, suggesting a linear trend. A test for and a predictor variab",Sugi-13-193 Peterson Harrell.txt
"i=l i=l IJ IJ 2 C In this talk we describe a method for combining concordant pairs and Q = I: I: n.. D.. is equal to twice i=l j=t IJ IJ a measure of association from several 2xC contingency the number of discordant pairs. tables. The columns in the 2xC tables are assumed to In the population let ne be the proportion of be ordered and the method uses the weighted least randomly selected concordant pairs and let nn be the squares methodology of Grizzle, Starmer and Koch (1969). The method uses a transformation of the proportion of discordant pairs. The population version gamma statistic, a statistic proposed for the analysis of of gamma is ordered contingency tables by Goodman. The procedure gives an estimate of the overall gamma statistic and a test for association. The CATMOD procedure of SAS can be used to calculate the estimate and the test statistic. In this talk we describe an SAS macro which integrates the results of this method into The sample version of gamma the usual output from the FREQ procedure. An example from the health sciences is presented as an (1) illustration.",Sugi-13-194 OGorman Woolson.txt
"where f3 is a M X 1 vector of unknown parameters. The Logistic regression is a widely-used technique for analyz- Newton-Raphson iterative method is often used to find 73, the ing data from epidemiologic and observational studies. Since maximum likelihood estimate of j3. Predicted probabilities the maximum likelihood fit of a logistic regression model is sen- can then be found using: sitive to outlying responses and extreme points in the design space, the use of diagnostic tools similar to those developed for the standard linear model (see, e.g., Belsley, Kuh, and Welsch, _ 1980 and Cook and Weisberg, 1982) is recommended. While Pregibon (1981) and Cook and Weisberg (1982, Section 5.4) have developed diagnostic tools for logistic regression, these In extending the standard linear regression diagnostics to techniques are not readily-available in most statistical pack- the case of logistic regression, it is useful to view the process ages. In this paper, an easy-to-use SAS@ macro for calculat- for determining j3 using iteratively reweighted least squares. ing and displaying logistic regression diagnostics is described. Using the superscript (k) to denote estimates at the kth iter- The macro requires only the data set containing the values ation, let of the dependent and independent variables for each case and S~k) = Yi - nd>!k) the output data set from PRDe LOGIST containing the pa.- rameter estimates from the fitted model. and let W(k) be a N x N diagonal matrix with diagonal ele- ments 1.",Sugi-13-195 Davis.txt
"THE ANALYSIS OF COMPLETE BLOCKS USING METHODS BASED ON RANKS · Ronald l. Iman Sandia National Laboratories The famil iar F tests associated with 5. Four shapes of liquid dishwashing tests of main effects in the analysis of soap bottles are each evaluated for complete block designs rely on a linear ease of use on a scale from 1 to 5 by each member of a panel of eleven model with a normal error term, and are based on calculations that adjust for consumers. The shapes of bottles are the presence of main effects. When the treatments and each consumer is. a block. necessary assumptions are satisfied, the parametric F test is the preferred procedure to use. However, the neces- The experimental design that leads to sary assumptions frequently cannot be the blocks and treatments data layout is satisfied, and analysts turn to methods usually called a block design. A com- employing ranks. In this paper recent monly used block design is the ran- literature will be reviewed and examples domized complete block (RCB) design. presented, to provide guidance on the Randomized refers to the random assign- selection of proper procedures for the ment of experimental units within a analysis of complete blocks. The mater- block to the various treatments. This i a 1 presented in th i s paper is excerpted is done to avoid introducing bias in the from a new text in preparation by Hora assignment of units to treatments. The and Iman (1988a) that presents rank term complete, in the phrase complete based methods for performing statistical blocks, refers to assignment of the analyses. experimental units in each block to each of the treatments. Each treatment and The concept of matched pairs extends block combination is represented in a quite naturally to blocks of data that complete block design. contain three or more related measure- Each of the fi ve exampl es presented ments, such as measurements made on the above represents a complete design. same subject with each measurement made Example",Sugi-13-196 Iman.txt
"New Features in the REG Procedure for Version 6 Sandra D. Schlotzhauer, SAS Institute Inc., Cary, NC INTRODUCTION statement. The other eight methods involve various ways of including or excluding variables from the model. Five methods (BACKWARD, FORWARD, MAXR, MINR, and STEPWISE) are as SAS/STAT"""" software contains several procedures that perform regression analysis. PROe REG is the most general tool of these previously implemented in PROe STEPWISE. Another method procedures. In Version 5, REG is a noninteractive procedure that (RSQUARE) is as previously implemented in PROC RSQUARE. fits the model specified. In Version 6, REG is an klteractive proce- Two additional methods, new in Release 6.03, are ADJRSQ and CP. These methods are very similar to the RSaUARE method but dure with nine model selection methods. Additional enhance- ments include the ability to add or delete variables from the use a different criterion for including a variable in the model. model, reweight or exclude observations from the model, plot the data and many model statistics, and highlight selected points in CHANGING THE MODEL plots. The next several sections of this paper give a summary of new features in FROe REG. The final section, EXAMPLE. gives In Version 5, you could change the model in the sense that you an annotated program (with output) that illustrates many of the could submit several MODEL statements, and PROC REG would new features in PROC REG. fit each model. In Version 6. you can still use this method. How- ever, you can also change the model just by adding or deleting variables. INTERACTIVITY Starting with Release 6.02, PROC REG is interactive. This means Starting with Release 6.02, the ADD statement allows you to interactively add variables to a model, and the DELETE statement that you can submit a group of statements, look at the results of the analysis. and submit additional statements without re-calling allows you to interactively delete variables from the model. Both of the",Sugi-13-197 Schlotzhauer.txt
"weights. This weighted average may have In a two factor (treatment and investigator) substantially lower variance than the unweighted clinical trial design, ""pooling"" usually refers average. If, however, the weighted average is to a model reduction from the full cross used when interaction is present, the resultant classification to a -main effects"" model. The estimator is biased. In §2 below, the model removal of the treatment by investigator parameters corresponding to SAS® Type I, Type interaction terms is typically decided by the II, and Type III sums of squares are defined for size of the p-value for the test of no the two treatment. two investigator case along interaction. This decision process historically with the ""treatment difference"" of interest. In is due to Type I and Type II error §3, the treatment estimators, their considerations. In clinical trials, possihle expectations, and their variances are provided bias incurred by model reduction is of prime In §4. the mean for each parameterization. concern. In this paper, parameterization squared error of the weighted estimator is .corresponding to SAS® Type I, Type II, and Type contrasted with that of the unweighted estimator III sums of squares is illustrated and the when interaction is present. The results of decision to pool is examined from a bias this calculation are discussed in §5. perspective. An inspection of mean square errors in the estimation of treatment 2. Parameterizations differences suggests that when the F statistic for the interaction hypothesis test exceeds In this section, parameterizations for the two unity, pooling should not be done. treatment, two investigator clinical trial are provided which describe the model under",Sugi-13-198 Schwemer.txt
"A MULTIVARIATE APPROACH TO SOCIAL INEQUALITY M. Ribe, Statistics Sweden 1 Introduction income. In this Section same general properties Statistics on welfare in Sweden are are listed, and in the next the properties are obtained by the Survey on Living Conditions, specified further. After that the inequal ity which is regularly carried out by Statistics index is defined in Section 4. (1) Basic aim. The inequality index shall Sweden. Seve_ral aspects of welfare are cover- ed, such as consumption, employment, housing, quantify the extent to which the existing health, and leisure. Reports from the Survey inequalities in some given welfare indicator, also give statistics on the social inequality such as car ownership~ depend on some given in welfare between population groups; cf. background factor, such as family situation or Statistics Sweden (1981, 1987a, 1987b, 1987c), socia-economic group. Nordi c Council (1984). (2) Comparabil ity over time. The index The purpose here is to gi ve a method for numbers should properly show the development measuring welfare inequality as comparable over time and not be subject to drift by index numbers. Consider a specific welfare irrelevant circumstances. (3) Separation of background factors. The indicator of yes/no type, such as lI own ing/not owning a car"", ""employed/unemployed"", or index numbers shoul d refl ect the impact of ""living/not living in a dwelling of acceptable each background factor separately. An index standard ll · The purpose is to measure to what pertaining to the impact of (e.g.) socio-eco- extent the social inequalities in this indi- nomic group shoul d not be affected by mere cator depend on the respective background implications of the fact that different socio- factors: family situation, sex, socia-economic economi c groups have di fferent a~e structures group, nationality (immigrants/Swedes), and or different geographical distribution. It geographical region. (The factor ""family should reflect the pure effect",Sugi-13-199 Ribe.txt
"Efficient Use of a SAs"" Data Library as a Pseudo-relational Data Base Vladimir Svirsky, IBM Corporation (observation number) is called, in data basc jargon, the normal· Introduction ization process. This article discusses: If all the records of one type are transformed into one SAS Data Set (table), this table is in the first normal form and carries a great 1. How to build a SAS Data Library based on the principles of deal of redundant data. In order to eliminate all the redundancy, pseudo-relational Data Base where each SAS Data Set in this information from one record type is transformed into various library represents a table with data pertaining to a single area numbers of SAS Data Sets (tables), and a special LINK·TABLE of knowledge. One additional SAS Data Set, referred to as points to all of the associated observations in each table. 'LINK-TABLE', keeps track of which observations in all other Data Sets are related to each other. Structure of RMF records 2. How to build queries with direct access to any group of ob- All resource utilization measurements are reported by RMF over servations from as many tables (Data Sets) as are needed to a span of time that is called the RMF measurement interval. De· satisfy given criteria and perfonning the necessary analysis on pending on the type of the resource being measured, either one the pertinent part of the Data Base in one DATA step. or a number of records of that type will be created, and this num· her usually varies from one interval to another. A Standard Header Section , of varying length across record type, and an As an example of this approach, a Computer Performance Eval- RMF Product Section, are present in every record. The number uation (CPE) analysis system based on data records type 70-75 of other sections varies with the record type, where any section can and 78, collected by Resource Measurement Facility (RMF), was be repeated various number of times, depending on the intervaL built. Normalization/trans",Sugi-13-20 Svirsky.txt
"A SAS«> MACRO FOR ESTIMATING THE ERROR RATES OF TWO DIAGNOSTIC TESTS, NEITHER BEING A GOLD STANDARD James J. Ashton, The Ohio State University Melvin L. Moeschberger, The Ohio State University 1. Introduction populations with differing prevalence rates With the profusion of new diagnostic (possibly differing age or sex groups,. Then tests coming to the market it is imperative one need not know the error rates of the that adequate methods for assessing accuracy reference test. but again one must assume be available. There are basically three conditional independence of the two tests. strategies. First. a ""gold standard"" test may This method utilizes Maximum be available - that is. a test having perfect likelihood estimation to find estimates of all sensitivity (the ability to properly diagnose error rates and variances of these estImates. the presence of a characteristic) and The Model For Method 3: h specificity (the ability to properly diagnose let 1-a, , the specificity for the jt the absence of a characteristic). If such a 'J test eXists. the performance of a new lest can test from the ith population be judged against this gold standard. ( J More often it is the case that a reference the sensitivity for the jth test is available with known sensitivity and specificity. The new test can then be test from the ith population measured against the reference test. taking the error fate for the reference test into the prevalence rate for the account. \21 Finally. a reference test may be available but the sensitivity and ith population specificity are not definitively known. Then a maximum likelihood method is availabl?3fo Ni = sample size from the ith population estimate the error rates of both tests. - Now it will be assumed that a,. = a and 2. Methods of EstiMation j 'J The first method is quite straight- fl .. = flj for i=1.2. Under these forward. When a gold standard test is 'J available. one uses it to classify a sample of conditions. the likelihood function is the",Sugi-13-200 Ashton Moeschberger.txt
"variables measured under several conditions, for several independent groups (or levels of explanatory variables). Logit models are presented for repeated observations on To analyze repeated categorical data, we could formulate a an ordinal categorical response variable. The models describe model for the cell expected frequencies. Such a model would how the marginal distribution of the response depends on values describe the dependence structure of the entire cross- Primary attention is given to a of explanatory variables. classification. An alternative approach is to formulate a model cumulative logit model that generalizes models proposed by for the marginal distributions of the response within the various Also diocussed are an a.ljruoent- McCullagh (1977, 1980). conditions and levels of the explanatory variables. In Table 1, categories logit model that is equivalent to a loglinear model for there are four such marginal distributions: for each treatment, marginal response probabilities, and a mean response model. there is a patient's response distribution before treatment and The models are illustrated with an example in which a drug and after treatment. placebo are compared with respect to treatment of insomnia For descriptive and inferential purposes, the full multivariate problems. When the covanates are categorical. a weighted least dependence among the repeated responses is often of less interest squares fit for each type of model can be obtained using PROC than the behavior of the marginal distributions of the response. CATMOD. Modeling the marginal distribution permits investigation of questions such as, ""For a particular treatment, does the response L",Sugi-13-201 Agresti.txt
"BS. Henry A. Anderson, MD Jerry Burns, MS. Wisconsin Division of Health PO Eox 309, Rn 318 Madison, WI 53701-0309 status (case di sease, control '"" no disease). The program Abstract E STRATRAN described here facilitates the selection and construction of matched case-control sets for conditional logistic regression analysis. Epidemiologic case - control studtes associate causal and risk factors to elucidate disease processes. In addition to State health departments typically may have a relatively small modelling, matching cases and controls on confounding factors case series of a disease to investigate as well as a much larger limits their impact on the e~posure - disease relationship. PROC pool of all other disease cases to choose from for controls. for MCSTRAT SAS analyzes matched case - control datil using in example. this situlltion arises when utilizing death certificate condi ti Dna 1 1 ogt sti c regress; on (CLR), preserving the matei'd n9 or data for the surveillance and research of occupational, strCltCl information. STRATRAN facilitates the construction of environmental or communicable diseases. Thus an access method for case~control matched sets for ClR analysi s. randomly selecting controls from this larger pool of records is desirable. STRATRAIf is designed to operate within these Using the FREO procedure. STRATRAN generates tables of cases and I or conditions. If records are matched on effect modifying and controls according to any user specified strata (eg., age",Sugi-13-202 Hanrahan Olson Anderson Burns.txt
"COMPARISON OF QUANTILE ESTIMATION METHODS IN THE UNIVARIATE PROCEDURE Rudolph S. Parrish, Computer Sciences Corporation Robert F. Carsel, U. S. Environmental Protection Agency 1. INTRODUCTION nit ion 4) is used by default; however, users may There are many circumstances under which it select any other definition by use of the is desirable to know percentiles of a given PGTLDEF option of the UNIVARIATE procedure or distribution. It may be of interest to estimate the DEF option of the PCTL procedure. The numerical levels below which (or above which) given proportions of population values lie. UNIVARIATE procedure can provide estimates of quantile levels 0.01, 0.05, O.lO~ 0.25, 0.50, Such estimates of probabilities commonly form the basis for decision making and regulatory 0.75, 0.90, 0.95, and 0.99. The PCTL procedure action. In some environmental applications this permits any quantile level to be specified via type of information is associated with risk the PARMCARDS option. assessments as, for example, when it is impor- Depending on sample size, quantile level, tant to focus on chances of exceeding critical and underlying distribution, the different concentration levels. Other examples center methods used for estimating a given distribution around the analysis of output from complex sto- quantile can have a significant impact on the chastic models that simulate the fate of envi- estimate itself and on subsequent inferences ronmental pollutants. (see Figure 1). Performance characteristics Distribution quantiles (or, synonomously, such as bias, variance, and mean squared error percentiles or fractiles) communicate informa- of these estimators can differ considerably, tion about the probabilistic nature of random especially for small sample sizes. These pro- processes. They help to characterize statisti- perties can be useful for determining which cal distributions. In most circumstances, quan- estimator is most appropriate in a given situa- tiles of a given populatio",Sugi-13-203 Parrish Carsel.txt
"Corp. Dan Steinberg, Economics, SDSU, San Diego, CA 92182 ABSTRACT GIT. Similar models could be estimated with PROC MPROBIT or any other probability pro- The regression analysis of a categorical dependent cedure pennitting the use of negative weights. We variable becomes complicated when the data has begin this paper with a brief discussion of how the been gathered via a choice-based sampling scheme data problem might arise, and where supplementary (i.e. stratified random sampling from values of the samples might be found. We then provide the intui- dependent variable.) An extreme case occurs when tion behind our results and explain the data data is available for only one level of a binary preparation technique. Formal proofs of our results dependent variable. In another paper the authors can be found in Cardell and Steinberg(1987), and (Cardell and Steinberg(1987)) have shown that even details of the derivations for the special case of the in this case binomial probability models may be binary logit appear in Steinberg and Cardell(1987). estimated provided that an appropriate supplemen- tary sample can be found. The result is of practical 2. Data Generation significance because the supplementary sample need not contain any information on the dependent vari- In our experience, choice-based samples are ubiqui- able. We discuss this result and show how such tous. Data restricted to one value of a binary vari- models can be estimated using SAS procedures. able are routinely gat",Sugi-13-204 Steinberg Cardell.txt
"ANALYZING FOR INDEPENDENCE OF SEQUENTIAL EVENTS WITH MARKOV CHAIN MODELS IN SAS® (vers. 6) Paul F. Steblein, Syracuse University INTRODUCTION be calculated for a first order Markov transition as follows: Testing for the independence of sequential events is a useful analysis for many disciplines. An event is defined as a discretely identifiable occurrence or incident. Examples of events might where n is the observation of an event (Fagen and be behavioral acts in sociology (Morgan 1976) or Young 1979). The transition probabilities (Pij) can succession of plant communities in ecology (Usher be summarized in a transition matrix where all 1979). Markov chain models have been suggested possible initial events (Ei) in a two-event as an appropriate approach for identifying patterns sequence are listed as rows, and all subsequent in sequential events. The objective of this paper events (E) are represented as columns. Thus, a is to describe how to use Markov chain models I with SAS (vers. 6) to test for independence of cell value identified by its row (i) and column (j) sequential events. An example is provided that notes the probability of that transition occurring. employs the technique to examine patterns of behavior in birds; specifically, the detection of 2nd Event R sequences in maintenance behavior by nestling 3 1 2 broad-winged hawks (Buteo p/atypterus). 1 Pll P13 P12 METHODS 2 P23 P2l P22 3 1st P33 P3l P32 MARKOV CHAINS Event There are situations where one type of event always follows another event (e.g., a heavy object R always falls when it is released). When the Pi3 Pi2 Pil outcome of event transition can be predicted with certainty, it is a relatively simple matter to Furthermore, the column and row totals should construct a web or pattern of event change for each equal one, since events are mutually that system. However, in many situations the exclusive and all possible sequential events are transition of events is not deterministic, but represented. Depending",Sugi-13-205 Steblein.txt
"Promotl.on In March of 1985, a major Oil The capabilities of the SAS system Company mailed its regular Spring have recently been extended by the program promoting its Motor Club availability of the CHAID technique as a membership to its credit card holders. SAS procedure. CHAID (CHi Squared The mailing included 2.4 million credit Automatic Interaction Detector) is a card holders out of a universe of tree-based-classificatIon technique approximately 5.6 million eligible designed to select a set of categorical households. Eligible households consist independent variables that best predict of current credit card holders who are respqpse on some categorical dependent not delinquent on their account, and not variable. CHAID is useful for current members of the Motor Club. segm~nting COnsumers in market research as well as in general exploratory data The oil company's original analysis. unlike its most related segmentation model was constructed in a technique, (AID, or Automatic traditional single variable fashion. Interaction Detection), CHAID is based Variables representing credit card on Chi-Squared statistics, is not members' recency, frequency, and value limited to binary splits and (RFV) of their credit card purchases incorporates a Bonferroni correction for were categorized and then crossed collapsing categories. CHAID is against each other to create mailing contrasted with a ""single variable"" groups. Decisions about which groups to approach in an analysis of a direct mail mail were made based on past performance promotion by a major oil company. of comparable groups in prior Motor Club mailings. In addition to the sample selected",Sugi-13-207 Magidson Rooney.txt
"DEVELOPMENTS IN STATISTICAL GRAPHICS Lawrence H. Cox* National Academy of Sciences (NAS) movie. Instead, I will use 35mm slides Introduction and will attempt to serve as a tour The explosive growth in the availabil- guide to the audience through some of ity, power and flexibility of local, the history in this field, from its single-user computing over the past beginnings in 1786 through the present. decade, and its concomitant decreasing My intention is to highlight the prin- cost, has revolutionized todayts office cipal trends in the science of statis- and research laboratory. For statisti- tical graphics, point out relationships with computing and cognitive sciences, cal science, the effect has been a and engage the audience in a dialogue shift towards computational methods-- on a few of-the issues and developments modern computing provides both the need and the means for new statistical meth- presented. odology such as the bootstrap. The synergy between computing and statis- An Outline of the Tour tics is evident when viewed from the perspective of conferences such as the William Playfair published the Commer- SUGI and INTERFACE conference series. cial and Political Atlas in 1786. The The effects on the discipline of stat- Atlas was a chartbook depicting impor- istics run deep and are described tant economic trends and factors nicely in a paper by Jerry Friedman affecting Great Britain--not the least (Friedman 1987) presented last year at of which was the Revolutionary War. the MAS Board on"" Mathematical Sciences· The Atlas was not only the first pub- I1Symposium on statistics in Science, lished statistical chartbook but, with Industry and Public pOlicy.1I subsequent publications by Playfair, presented several new graphical forms. It is appropriate that computer graph- Some of these have not survived, but ics is playing a significant role in others certainly have: the line graph, these changes: on the one hand, com- the barchart and the circle graph all puter gr",Sugi-13-208 Cox.txt
"able Ti such that Yi = log(Ti) follows a location-scale dis- tribution, G, with location parameter Pi and constant scale iP. This paper describes a SAS"" macro for the assessing local in- where ~ ,-:;:: parameter iT. We also assume that Pi = fluence in regression analysis with censored data. The macro (ZiQ,Zil, ··. ,Zip)' is a vector of explanatory-variables and allows one to identify those observations that have the great- P = (Po, ... ,Pp)' is a vector of unknown regression coeffi- est local influence on the estimates of the parameters or func- cients. These assumptions imply that the cdC and pdf func- tions of Y; are given by G(t;) = '1;(>;) and g(l;) = (Iju)<fo(>;), tions of the parameters of one's model. where>; = (y; - p;)ju, y; = log(t;), and '1;(.) and <fo(.) are the standardized forms of the location-scale distribution (i.e. 1",Sugi-13-209 Escobar Meeker.txt
"Food and Drug Administration ABSTRACT The IBM OS/VS2 Multiple Virtual Storage/ Extended Architecture (MVS/XA) is the current This paper discusses the financial modelling operating system at PCC and the Job Entry and rate-setting used at a large government The discussion includes how Subsystem (JES2) receives jobs from local and computer center. remote devices, routes output, and schedules to build a workable financial model and the job processes. Among the available software selection of data sources for the forecasting process. Several SASjETS* procedures were used are various language processors (COBOL, to predict workload growth for a six months FORTRAN and PL/l); file management systems period, and the results were tracked against such as MARK IV; the database management actual usage. Guidelines and recommendations systems Oracle, Mode1204, and ADABAS; statis- for forecasters based on this study are tical packages and simulation software; included. graphics software, and interactive systems including WYLBUR, TSO/SPF, and APL. The SAS THE PARKLAWN COMPUTER CENTER System is the most widely used batch software system at the Center. The Parklawn Computer Center (PCC) was established to fulfill the automatic data BUILDING A FINANCIAL MODEL processing needs of the United states Public Health Service and its constituent agencies. PCC has been performing annual revenue Among the many organizations serviced are the forecasting since its inception in 1968. -The regional offices of",Sugi-13-21 Carrico Harris.txt
"ExtrapoIation Sampling - Model-Based Sampling in Litigation Support Timothy Wyant, Independent Consultant The applied statistician typically encounters A sample of resolved clah"""" provides a database problems involving some quirk that limits the applicabi- from which one can estimate not ouly the historic lity of standard results. Effective statistical consulting frequency of claim characteristics, but also the nature of requires that the statistician address such quirks in a the relationship between a claim's characteristics and its likely value in the eyes of the legal system. manner that is statistically reasonable, while meeting The consolidated unresolved claims constitute a client needs in terms of cost, relevance, and timeliness. target population. A sample drawn from this One such quirk arises in toxic tort and product population provides a basis for estimating the liability litigations. Such litigations - those involving distribution of claim characteristics for claims yet to be ashestos, Agent Orange and other dioxin exposures, the compensated (or dismissed). To the extent that the Dalkon Shield contraceptive device, and DPT vaccine come to mind - typically begin with a few individuals two populations - the calibration and the target - differ primarily in the frequency with which different suing the manofacturer. If some of these suits are succesful (or appear to have that potential), litigations claim characteristics OCCllI, and not in the way in which may snowball. Eventually, cases of many individuals the characteristics determine value, one can use the two samples to estimate the total value of unresolved may be consolidated into a class action. claims. In some instances, so many litigants come for- ward, each with sufficiently high probability of court- Urgency (the injured need compensation, the room success, that the manufactur declares bankruptcy. manufacturers need their legal problems resolved, the Such was the case with Johns Manville (ashestos",Sugi-13-210 Wyant.txt
"USING SAS/STATTM SOFTWARE'S REG PROCEDURE TO DEVELOP SALES TAX AUDIT SELECTION MODELS Kirk L. Johnson, Tennessee Department of Revenue Richard W. Kulp, David Lipscomb College - to screen variables and rank INTRODUCTION them in order of importance - to predict, forecast, or The Tennessee Department of Revenue estimate the dependent (TDR) uses SAS/STAT REG procedure to variable. develop statistical models to predict which sales and use tax field audits As noted above, we are primarily will yield the highest return per interested in using regression hour spent on the audit. To perform analysis to predict the hourly return the analysis, the TDR uses the SAS from sales tax field audits. It is System computer software which runs important to state clearly the on both the state's mainframe purpose for which a regression model computer and on personal computers in is to be used since a model that the Department. This process predicts well may not necessarily be involves running SAS programs against the best model for estimating taxpayer files on the state's parameters or performing some other mainframe computer and downloading task. subsets of data based on taxpayers' business types to a personal Model Selection computer. The downloaded data is analyzed using PROC REG. We have chosen to develop a different model for each business type for This paper reports on our use of SAS which there is sufficient audit diagnostics to compare competing history to justify the analysis. By models and to analyze potential a different model, we mean that the problems in the data. Since the independent variables used in the formulas used to calculate the models will differ from one business statistics discussed in this paper type to another. This is based upon are readily available in SAS our experience as well as the documentation, we have chosen, for experience of other states which the most part, not to include this indicates that the variables which information in the paper. We, of cours",Sugi-13-211 Johnson Kulp.txt
"tt, SAS Institute Inc., Cary, NC' W.T. Federer, M.P. Meredith, and Z.D. Feng, Cornell University, Ithaca, NY ABSTRACT that it is easy to provide all detailed computations to illustrate how each number is obtained. You may want to skip the detailed com- The analysis of covariance for split-unit and repeated measures putations (see Federer, 1955, Chapter XVI). The third example experiments is not always straightforward when using a statisti- comes from Winer (1971). The detailed computations are given in his book (p. 803). cal software package such as the GLM procedure in SAS/STAT"""" software. In order to demonstrate correct analyses. several data sets are examined. and annotated SAS® output is given. Hypo- REFERENCES thetical data are analyzed first without and then with the covariate included. The whole plot units are arranged in a randomized com- Federer, W.T. (1955), Experimental Design· Theory and Applic- plete block design (RCBD), and the covariate is measured on the ation, New York: MacMillan Publishing Co. Inc. subplot units. A second example has whole plot units arranged Federer, W.T. and Henderson, H.V. (1979), ""Covariance analysis in a completely randomized design (CRD) and the covariate mea- design experiments x statistical packages: An Update,"" Proc., sured only on the whole plot. Compo Sci. an Stat. 12th Ann. Sym. on the Interface. Meredith, M.P., Miles·McDermott, N.J., and Federer, W.T. (1988), This paper demonstrates the commonly employed approach '""The Analysis",Sugi-13-212 Miles-McDermott Federer Meredith Feng.txt
"versity N. J. Miles-McDermott, SAS Institute Inc. W.T. Federer, Biometrics Unit, Cornell University ABSTRACT This is the second of two papers on the analysis of means that the correct ANOVA table is easy to obtain via a single procedural call to the GLM covariance in split-unit and repeated measures procedure by gleaning the appropriate Type I and studies. The first paper (Miles-McDermott, et aI., Type III sums-of-squares. If adjusted treatment 1988) documented analysis difficulties using SAS® means and standard errors of differences amongst PROC GLM and illustrated a two-step approach to adjusted treatment means are required then addi- conduct correct analyses for several examples. A tional work is necessary. However, it is shown that one-step approach is presented in this paper and is the cost of this additional work is minimal and illustrated with the same examples. The first exam- ple has whole plot experimental units (EUs) in a subsequent calculations may be pertormed on a hand calculator. Cost is an important factor be- RCBD and a covariate measured on each subplot. cause the analysis of split-unit experiments in GLM The second example has whole plot EUs arranged can quickly become prohibitively expensive by in a CRD with a covariate measured on each whole requiring large amounts of CPU time and memory. plot. Both Type I and III sums-of-squares are necessary to construct the proper ANOVA table when using the one-step approach which requires The ""classical"" (Le., typical",Sugi-13-213 Meredith Miles-McDermott Federer.txt
"EXACT AND MONTE CARLO METHODS FOR COMPUTING NON-PARAMETRIC SIGNIFICANCE TESTS Cyrus R. Mehta, Harvard School of Public Health~ and Cytel Software Corporation Nitin R. Patel~ Harvard School of Public Health Pralay Senchaudhuri~ Harvard School of Public Health 2. EXAMPLES 1. INTRODUCTION for Adverse 2.1 Wilcoxon Rank-SUm Test A very rich class of non-parametric two- Reactions Data. sample tests are of the form k santoro, Bonadonna, et a1. (New England d(x) E a. (m. l'x.) Journal of Medicine, 306:763, 1982) reported i=1 ~ 1- ~ on adverse reactions in 44 children being where the Xi'S are the entries in row 1 of the treated for Varicella on a randomized clinical 2xk contingency table x: trial. Twenty-three children were treated Row Total with interferon and 21 children received placebo. The question of interest was whether m interferon could reduce the adverse reactions relative to placebo. Thus a one-sided n Wilcoxon rank-sum test, against the alternative that interferon is no better than Column Total N, placebo, is appropriate. The Wilcoxon rank- sum test is of the form mi = x 1+x2+ ··. +x i , and ai(mi _ 1 , Xi) is a real d(x) = a 1x 1 + a 2x 2 + a 3x 3 + anxn where the ai'S are given in Table 1. The SAS valued function. An important special case aix i which, by arises when ai(mi _1 , Xi) procedure NPARlWAY yielded an asymptotic one- suitable choice of scores, ai' yields the sided p-value of 0.05. HoweverI' because of the small sample size, the usual normal class of linear rank tests for the two sample approximation to the Wilcoxon rank-sum test is problem. suspect. The exact one-sided p-value computed Inference is based on permuting the by our algorithm was 0.074. This is a 25% entries in the cells of the 2xk table in all increase over the asymptotic result and could possible ways subject to fixing some of the lead to different conclusions about the table marginals. Let r be the reference set of efficacy of interferon. all such permutations. Let H be the null hypoth",Sugi-13-214 Mehta Patel Senchaudhuri.txt
"& M University Laura L. Bauer. Federal Abstnlct the classical theory, the resulting te::Ls represenl either modified A SASTM macro designed to perform hypothesis tests versionl> of traditional nested tests or else asymptotically valid ap- hetween cumpeting non-nest,eel linear regression models is pre- plications of these tests under all indu~ed nesting scheme. These ;.;ented. WriUen primarily in SAS/IMLTM , this macro is de- methods emc()nlpass the two main approaches to tesling nOIl- ;.;igned for smaller sample sizes (n ::s; 50) and demonstrates the nested models which have been termed the centered log-likeli- usefulness and easy implemem:llion of IfvlL's matrix operations hood ratio (CLR) criterion and the artifical nesting (AN) crite- in statistical analysis. An example of the macro's use as well as rion (see Fisher, 1993 and l'.lacKinnon. 1983). In addition, rderellces to the testing melhudoiogies employed afe provided. sil1~e the hypothe~es are separate, it is necessary to perform the tests (lB a given pair of hypotheses twice, allowing each model tu lake iL<; turn as the maintained, or null. hypothesis. Introduction I. The CLR criterion developed by Cox (1960, 19(1) ap- In many regression studie:;, the rese<lrcher needs to proached the general problem of testing between separate dis- choose the must appropriate model from a set of t\\;O or more tributional families through a test statistic which compares the feasihle alternatives. Model selection criteria which evaluate",Sugi-13-215 Bauer Smith Capps.txt
"in this paper. Three new SAS® procedures, PROe TRANSREG (regression Young (1985) and Kuhfeld (1986) announced the IDPLOT proce· analysis with nonlinear variable transformations), PROe dure, a Version 5 plotting procedure (see Kuhfeld, 1986, ""The PRINQUAL (principal components analysis with nonlinear vari- IDPLOT Procedure,"" in SAS Technical Report P·146, Changes able transformations). and PROe CORRESP (correspondence and Enhancements to the Version 5 SAS System). PROC IDPLOT analysis) will be available in a later version of Release 6.03 of produces line-printer scatterplots of labeled points and optionally SAS/STAT"""" software. These procedures were developed initially can stretch axes to avoid point-label collisions. at the University of North Carolina at Chapel Hill under a grant from SAS Institute. This paper discusses the current design of Also at SUGII O. Young (1985) announced plans for a PATHANAL these procedUres. procedure (path analysis or covariance structure analysis). This procedure, under the new name CALIS procedure (covariance",Sugi-13-216 Kuhfeld Young.txt
"programs for simulating an M/M/k queue (exponentially spaced arrivals. exponentially spaced service times and k This paper describes a program written in the SAS servers; see Gross and Harris, 1974 tor details) in system which allows constructing a simulation using a FORTRAN and GPSS. The FORTRAN program is adapted s~bset of the GPSS language. Using this program, a from Brately, Fox and Schrage (1987). While only the dIscrete event model can be encoded as data (following main program is shown in figure 1 and the complete the CARDS statement) and then run in the SAS program in figure 2, some major differences in writing in environment. The advantage of this approach is the each languages is apparent. The principal difference is ability to use the statistical and graphics procedures in that in FORTRAN the code must be written to correctly SAS for monitoring of the simulation during the run and sequence each event in the order in which it occurs for post simulation analysis. while in GPSS it is sufficient to describe the process which occurs for a single entity moving through the 1.",Sugi-13-217 Jones Greene.txt
"USING SAS/GRAPH SOFTWARE TO CREATE GRAPHICS FOR DATA ANALYSIS Glen Buckner, Church of Jesus Christ of Latter-day Saints Terry Allen, Utah State Bureau of Medicaid Fraud The past twenty years have FIGURE 2: Scatter Plot with Bar Charts witnessed a remarkable growth in the as Symbols development of graphics for statistical analysis. This rapid This graph allows us to track the growth has been made possible by crime rate by year over a ten-year capable and sophisticated computer period. With the bars representing systems -- hardware and software. the percent of each crime solved, we can focus on any particular year ~or The ability of SAS/GRAPH to more information. produce quality graphics for presentation purposes is well known. FIGURE 3: Bar Chart with Error Bars What may be less well known is the tremendous flexibility in SAS/GRAPH to produce non-standard graphics for the Confidence intervals on proportional bars allows us to see the purpose of analyzing data. That flexibility is demonstrated in the lack of statistical difference in following eight graphic examples. murders committed by the day of the week. On a regular bar chart the rates may appear significantly LIMITATIONS dif.ferent .. One of the promising areas of analytical graphics is interactive FIGURE 4: Standard Deviation Ellipses dynamic methods using techniques such as painting, brushing, rotation and Each standard deviation ellipse While SAS/GRAPH cannot outlining. is constructed through the majority OT currently handle dynamic methods, the points of a speciTic group. This interactive modification of terminal- allows a visual analysis oT the displayed graphics did appear on the location of groups without the clutter 1987 SAS ballot (#311). It did not of the actual points. receive strong support from SAS users, but hopefully, as animated methods become more popular with the FIGURE 5: Framed Rectangles availability of pioneering computer systems, user demand will encourage The visual impact oT area charts",Sugi-13-218 Buckner Allen.txt
"r, Oklahoma City, OK J. Paul Costiloe, University of Oklahoma Health Sciences Center, Oklahoma City, OK Andrew -J. Cucchiara, University of Oklahoma Health Sciences Center, Oklahoma City, OK ABSTRACT present problems to researchers, since the behaviOr of the statistic is not known when computed for The caution extended by SAS Institute Inc. to small sample sizes. Computational difficulties occur users of their categorical model procedure, CATMOD, when transformations, such as the logit or the cell does not clearly identify the risks involved when proportion, are performed on the response analyzing models with small sample size. A SAS probabilities in the presence of one or more empty program was written and executed to assess these cells. Furthermore, ,the effect that addition of a risks by variation of three binomial parameter values small value to empty cells has on the Type I error under the null hypothesis (P0=0.1, 0.3, 0.5) with rate has not beeR investigated. constant sample sizes of 2 to 120. For sample sizes less than twenty, the 4 dimensional sample space for The purpose of this paper is to determine the a 2 3 categorical model was formed and the Type I error rate of CA TMOD when the expected coordinates of each point used to construct cell size of the critical region is equal to 0.05 for sample frequencies for a categorical table with two factors sizes of two to one hundred twenty observations. and one binomial response,. The significance of the For sample sizes les",Sugi-13-219 Kenny Costiloe Cucchiara.txt
"RTTis sometimes used in SAS for small sorts Collection and analysis of large data files is CPU and with a limit of 64,000 observations. According to Dan I/O intensive. Using SyncSort CMS with SAS applica- Squillace of SAS Institute (Share 68, San Francisco, tions however, can substantially reduce CPU time, SIO 3/87), PROC SORTI is most appropriate for small sorts with less than 300 observations. and elapsed time. Further, with new SAS interfaces, SyncSort CMS can PROC SORT, (as distinct from PROC SORTI), uses decrease resource consumption up to 80%. The new SAS the system sort, in our case, SyncSort CMS, and can sort an unlimited number of observations. The stan· interfaces are: dard interface for PROC SORT passes records to the sort, one record at a time. · PROC SYNCSORT replaces PROC SORT within SAS applications. PROC SYNCSORT, a new SAS sort interface, permits · SYNCSORT SAS, (a CMS command), can sort the SyncSort CMS to read and sort records more efficient· SAS data prior to invoking the SAS system. Iy by replacing PROC SORT or PROC SORTI in any SAS application. PROC SYNCSORT, which may be These features of SyncSort CMS are here delineated used only from within an SAS job stream, offers substantial savings in system resources and perform- focusing upon user performance benefits. ance benefits over other methods. 1Ypical SAS Application SYNCSORT SAS Following is a description of a typical SAS application, SYNCSORT SAS is a CMS command that allows sort- the sorts within it,",Sugi-13-22 Mahan.txt
"Power Analysis in an Enhanced GLM Procedure: What It Might Look Like S. Paul Wright!, University of Tennessee Ralph G. O'Brien2, University of Tennessee Ho~ will be rejected. This is what most investigators want Abstract. Power analysis calculations for fixed-effects to do, so they try to design their studies to be as powerful ANOV A designs can now be done in SAS®. Step I uses as possible. Our focus here is on the normal-theory, PROC GLM to calculate noncentrality values. Step 2 fixed-effects general linear model. In this case, involves entering those values into a separate SAS program that converts noncentralities into tables of power (I) Power = Prob[F(sample) Faid ;0, probabilities for various scenarios (O'Brien, 1986a). With just a modest effort, the calculations done in Step 2 could where F(sample) is the usual sample F statistic: be incorporated into PROC GLM itself, making GLM an effective tool for statistical planning as well as for F(sample) = [SSH(sample)/dfHlfcr2 . (2) statistical analysis. An example illustrates how easy it should be to perform comprehensive power analyses using SSH(sample) is the hypothesis sum of squares having dfH an enhanced PROC GLM. A proposed syntax for a degrees of freedom. ,,2 is the mean square error (MSE) POWER statement to set parameters and options is with dfE degrees of freedom. Calculation of SSH(sample) described, and the output that could be produced by it is and &2 for various hypotheses is covered in many texts, shown. Both retrospective and prospective power e.g., Freund, Littell and Spector (1986). Ferit is the critical analyses are demonstrated. How the POWER statement would operate in an interactive GLM session is also value of the F statistic. That is, it is the value of a random variable, F, having a central F distribution with dfH and discussed. dfE degrees of freedom such that Prob[F ;0, FeriJ = fJ. where is the chosen significance level for the test. 0. 1. Introductory Remarks Here we treat two kinds of powe",Sugi-13-220 Wright OBrien.txt
"JONCKHEERE'S TEST PROCEDURE FOR DOSE-RESPONSE TREND Sue H. Huang, Organon Inc. Armand Robles, AMR Associates JOOCKHEERE'S TEST PROCEDURE ABSTRACr = Ek=l The da ta cons ist of n' DATA. N th~ <;bservations, ~i th nj observations flrom program is presented for performing the A SAS distribution-free test for ordered ]th treatment, ]=l, ··· ,k. alternatives or dose-response trend by A.R. Jonckheere. This program computes Treatments Jonckheere's statistics for small sample as k 2 1 well as large sample approx~tion; for large sample it also provides the p-value for hypothesis testing. This program is especially useful for large samples with unequal sample- sizes in each treatment group and with missing values. The number of treabment groups are flexible in this pocogram and examples are given. INTROOUCTION In a dose-response study, an experimenter often wishes to see that the magnitude of l\SS!I!Pl'IOIiS response increases or decreases with the 1. The basic model is quanti ty of the dosage that is applied. For =p example, suppose that an experiment which + TJ"" + EiJ""' i=l, ... ,n., XiJ"" j=l,. .. ,k~ consists of four treatment groups: placebo (0 mg), 10 mg, 50 mg and 75 mg of an ~ is the (unknown) overall mean, Tj is where experimental drug, is performed to detennine ~he (_unknown) treatment j effect, and the effect of the different dosages upon the Ej=l Tj-O. reduction of the attacks of a disease. me experimenter, based on his/her experience or 2. The ~'s (random errors) are theory, expects to see that the number of mutually independent. attacks of this disease decreases with the 3. Each E' comes from the same increasing of dosage of this experimental continuous population. drug. That is, he/she wishes to test the hypothesis that the four samples have come PBIlC&JORE. from the same population against the alternative that the populations are in an To tes t Tl = Tk against H: alternative~ of the form order of decreasing value as the dosage increases. Hence a test of signifi",Sugi-13-221 Huang Robles.txt
"o be Given (1) a set {xlI x21 ..... x n } of n positively autocorrelated; if they observations on some spatially tend to have very different values, distributed variable of interest X they are negatively autocorrelated. and (2) a rule to determine which pair {(xi,Xj):i ~ j} are considered If the values are distributed to be ""neigflbors"", then spatial independently of their neighbors, autocorrelation is defined as a then they are spatially uncorrelated. condition where the values of individual observations are dependent Spatial autocorrelation is upon the values of their respective relevant in many fields4 Geographers neighbors. An index of have long been interested in the autocorrelation is thus dependent not spatial autocorrelation of only upon the observations on X, but distributions of human settlements, also on the hypothesis of structure flows of technology, and the spread of epidemics. Much of the early work implied by the rule used to define neighbors. This permits researchers in spatial autocorrelation analysis to develop and test hypotheses of was done by geographers I and is being relationships among spatially adopted by researchers in other distributed data. Such tests should fields. For example, ge'ologists be made before assumptions of spatial study spatial autocorrelation to autocorrelation are built into a improve their ability to predict oil model. well locations based on core samples. Ecologists study the spatial A program called SP~, written in autocorrelati",Sugi-13-222 Gillespie.txt
"used as front-ends for DATA step programs to construct designs. Recent developments in industrial quality control have resulted 2. The DEX system of macros is included in the sample in a resurgence of interest in statistical design of experiments. libraries for Release 5.18 and Release 6.03. DEX can Two new SAS/QC® software procedures are available for con- construct a fuller complement of the same types of structing experimental designs. The FACTEX procedure is a gen- designs as the Version 5 menu system, as well as eral construction procedure for orthogonally confounded designs for mixture experiments. fractional factorial designs. Fractional factorial designs, or designs that are based on them, form a large part of the list of 3. More significantly, two new procedures are being added commonly used experimental designs. The OPTEX procedure to SAS/OC software in an update release for Version 6. searches for an optimal design from a set of candidate points. The FACTEX procedure constructs general orthogonally This facility can be useful for generating designs in nonstandard confounded fractional factorial experimental designs, and situations. Macros and SAS/AF® menu systems have been devel- the OPTEX procedure searches for optimal experimental oped that use these procedures, together with existing SAS® designs. facilities for manipulating data, to provide the user with a full com- plement of design construction tools. 4. Besides becoming the basis for a new system of macros, ADX, the new procedures are also incorporated into a new SAS/AF menu system, also called ADX.",Sugi-13-223 Tobias.txt
"Data analysis frequently involves fitting curves to data. measured in terms of the total change in slope of the curve Often the investigator has no idea what the underlying over the entire range of the data. Spline smoothing is a hybrid of ordinary least squares functional relationship is and ordinary functions or polynomials fit poor/yo This is especially common with regression in that it minimizes lack of fit, but it is constrained to meet a specified smoothness criteria. The experimental data that has a lot of noise and/or measurement error in it. In these cases, spline smoothing fact that spline smoothing optimizes both smoothness and good fit, while also allowing the desired smoothness to be can be used to estimate and fit curves with excellent results. Nonparametric cubic spline smoothing is a specified by the user, makes spline smoothing a powerful remarkably accurate and widely applicable approach to curve tool. Example estimation that has been inexplicably underutilized. This powerful tool can be used in the exploratory, descriptive, To see how well smoothing splines perform, let us go and predictive stages of bivariate data analysis. back to our previous example of Figure 1. Figure 2 shows Many examples of curve fitting using spline smoothing the same data with a spline smoothed curve superimposed on are given. Smoothing splines are compared to several other it. Also included is the actual source function the data were generated from. The Y values were created from the common methods of curve fitting. Methods are detailed for implementing spline smoothing on SAS® software. source function perturbed by adding a random standard normal deviate with variance = 25. The fit appears to be very good.",Sugi-13-224 DeHaan.txt
"A SAS® PROGRAM FOR SELECTING SUBJECTS FOR A CASE-CONTROL STUDY Terry L. Leet, Monsanto Company Kientzel~ Gerald A. Monsanto Company Summary The Case-Control Selection Program (CCSP) was The CCSP offers the flexibility of selecting a developed to assist occupational epidemiologists specific number of controls per case based upon any combination of matching variables~ which may in selecting subjects for case-control studies. This SAS program identifies the cases for the include race, sex, age and length of employment. study and matches each case with R controls, The controls that most closely match the cases based on certain specifications. The controls are selected using a formula that was originally can be matched on sex, race, birth date, hire developed by the National Institute for Occupa- tional Safety and Health (1980). The following date, and/or length of employment, and can be selected with or without replacement from a pool formula generates a weighted summary score of of eligible controls. The controls can also be differences between the cases and controls with restricted to those employees who have not regard to the matching variables: developed other exposure-related diseases. = (Wi(DOB ca-DOB co ) + Score w .. (DOH -DOH ) Demographic and disease-related information for ca co ~l the cases and controls selected for the study is stored in a permanent SAS data set for further analysis~ and appropriate printouts are where DOB =date of birth for the case generated. DOBca=date of birth for the co control Purpose and Description DOHca=date of hire for the case DOH =date of hire for the Case-control studies are often conducted among co employee populations to measure the health risks control associated with prior occupational exposures. Serviceca=length of employment for the case A hybrid study design - a case-control study nested within a cohort study - can be used to Serviceco=length of employment for the control estimate the relative risk of developing wi=wei~",Sugi-13-225 Leet Kientzel.txt
"c Jon L. Kosanke, Mayo Clinic ABSTRACT Sample 2 Sample 1 The TWOSAMFLE procedure performs two- sample ~ tests as in PRoe TTEST and rank sum (Z=O) tests as in NPARIWAY. It also provides placebo (p) experimental extensions of these two test procedures when treatment (E) the assumption of a linear relationship between the log~dds of group membership and the variable of interest does not hold. Descriptive statistics, plots, tests of assumptions and an option for an output data set of results are available. w INTRODUCTION This procedure is concerned with comparing two independently obtained samples (X ll ····· Xln ) and (X Zl ' ···· XZn ) with cumu 1 at1ve dol °b ut10n f unct10ns Fl an d F2 Z 1str1 0 0 0 respectively. The output from this procedure consists of three parts: description of the data (using both graphic displays and summary statistics), conventional tests comparing the N o two samples (t and rank sum tests), and ~ extensions of-these tests which relax the ""0 ""0 underlying linearity assumption between log- o odds of group membership and the continuous '"" o variable of interest. Descriptive output includes univariate statistics, and side-by- w side stem-leaf plots. Along with the equal variance t-test on the means, the conventional Fig. I.A analysis includes tests for normality and common variance, and the results of Welch's t test. Finally, extensions of both the ~ and- rank sum test are also printed out to detect Samp:le Z Sample 1 situations in which the log odds of",Sugi-13-226 OBrien Offord Kosanke.txt
The problem statement follows: The relative merits of SAS/IML and IBM/APL as scientific pro- gramming languages are discussed and illustrated using a num- The populations of predators p{t) and prey q(t) at time t are related ber of algorithms from current scientific literature. It is argued that by the following -set of coupled differential equations. The con- SAS/IML is sufficiently powerful for most scientific programming stants k and a determine the relative decayIgrowth of the popula- problems. Moreover it is easier for both the SAS user and the tions. uninitiated to acquire the necessary level of expertise than is the case with IBMjAPL. dp -kIP + alqp dt,Sugi-13-227 Breytenbach Erens.txt
"we will define and examine the issues involved in ABSTRACT writing programs in multiple high-level languages. For purposes of this paper, a high-level language is defined as a third- A multilanguage program is composed of routines written in two generation language, such as C, PL/I, COBOL, FORTRAN, or or more high-level languages. Multilanguage programs are useful Pascal, including a runtime library of supporting routines pro- in the IBM® 370 environment for several reasons. Many subrou- vided by the compiler vendor. Communication with Assembler is tine libraries in various languages are available to perform stan- not addressed, as Assembler is not a high-level language, and dard or specialized functions. such as mathematical or statistical the issues are not as complex. This paper describes how the next analysis. Additionally, it is often desirable to migrate gradually release of the SAS/C product will approach these issues and from one programming language to another, such as from PL/I illustrates with a brief example of a C program calling FORTRAN. to C. Thirdly, there are functions that are best performed in a par- ticular programming language, such as producing a complex report with COBOL. A typical multilanguage application wlll freely INTERLANGUAGE COMMUNICATION ISSUES combine routines in several languages. This mingling of lan- guages often requires that the programmer have a detailed Execution Framework Requirements understanding of the varied environmental requireme",Sugi-13-228 Ammondson.txt
"dor-specific extensions and does not exceed the Standard's minimum requirements in any area. A strictly conforming program The C programming language has evolved since its original defi- would not, for example, be dependent on an underlying operating nition by Kernighan and Ritchie (1978). The proposed ANSI C system's filename format or assume that the value of a plain int Language Standard incorporates many new features and defines could exceed 32k without overflowing (it generally cannot on 16- the language with greater precision. This paper describes and bit machines) or use more than 509 characters in a string literal demonstrates how to use the most significant new features. It (which is the most that the Standard requires of an implementa- also explains ANSI terminology so that advanced programmers tion). Put simply, a strictly conforming program is one that is fully can study the proposed Standard. portable.",Sugi-13-229 Gass.txt
"III HOW SAS MAKES IT EASIER TO USE THE IBM REALTIME MONITOR Greg Hawryschuk, Rochester Institute of Technology Initial involvement with performance quence be keyed into the terminal to generate each performance data screen. management or capacity planning demands I found these various formats to be dif- that one become thoroughly familiar with ficult to remember and difficult to key a computer complex. General areas that in correctly as demonstrated in Example need to be understood are CPU usage, I/O activity, and individual user activ- 1. I also felt that the information presented in most terminal displays, al- ities. Computer performance monitoring tools are usually a good way to learn though very extensive, was difficult to about your system. comprehend. An inexpensive and straight forward tool Typical RTM Commands Entered By User that can help a person gain greater sys- tem knowledge in the IBM/VM environment is IBM 1 s Realtime Monitor (RTM). The documentation supplied with the product VMC SMART D provides reasonably good description of computer functionality and performance VMC SMART D SRC : CPU tuning. The product itself generates a wealth of generally useful information. VMC SMART D DEV 180 CU The purpose of this presentation is to suggest a technique for simplifying the Example 1. use of RT~ and also providing perform- By using ance data in a graphic form. SAS with the features of RTM and some very mild exposure to VM REXX command ,To overcome the difficulties, I estab- language, I strongly believe that many :lished two objectives. The first was to newly assigned performance professionals simplify the keying in of RTM commands. can get an intimate understanding of The second objectives was to clean up what is happening inside the computer the clutter presented in an RTM output without having to rely on large and com- screen. Both these objectives were easy plex performance reports or complicated to achieve using SAS and VM REXX command explanations from th",Sugi-13-23 Hawryschuk.txt
"RACT operation is unsupported, you can even upload or download SAS files to a PC or to another VMS system with KERMIT as long as you specify that the files are of file type FIXED. Note that you can- Supporting the SAS® software products in a VMS"""" environment not use a data set that was downloaded by KERMIT with the SAS requires some knowledge about how SAS software and the VMS System for personal computers. operating system interact as well as a general kn9wledge of pro- gram debugging. This paper will help you support SAS software logical Names The SAS System uses logical names to locate by discussing the following four areas: the pieces of the SAS image. The logical names SASUTL, · the more important interfaces between SAS software and SAS$MSG, and SAS$GRM all point to pieces that the SAS Sys- the VMS operating system tem needs to be activated. If these logical names are not defined, the SAS System fails immediately. The logical name · a debugging guide for tracing problems to the appropriate SAS$SASLIB points to the load able images that the SAS System system area uses. The logical name SASTAPE points to your tape drive. SAS$HELP points to the SAS System help files. If any of these · information to gather before calling the SAS Institute logicals are not defined, SAS software fails when the pieces they T echnleal Support Department to speed problem paint to are referenced. SAS$USERLIB is used to reference user- resolution written images or any patched images that are not",Sugi-13-230 Slater Dineley.txt
"e much of the processing to set-up or Abstract compile-time so execution just performs tasks requested with as Explanations and examples provide the basis of this tutorial that little overhead as possible. Making execution time come at any explains the new screen control language available in Version number of arbitrary points later entails saving and porting com~ 6 SAS!AF and SASjFSP software. The screen control language piled code which is done in version 6. provides the ability to develop interactive applications. The Comparison vs Data Step functions available in the Sel provide the basis for developing conversational systems for end users. Examples will be used In comparison to the data step, a transaction record is the screen to demonstrate how the language works. Differences in Sel after the user strikes an attention key, where in the data step a usage in SAS/FSP applications and SAS/AF applications will transaction record is the next line of input from a file or the next also be demonstrated through examples. Similarities and differ- observation from a setfor another data set. Variables are impiicn ences between the SAS Data Step and the screen control lan- itly retained in SCl, where they are not retained unless explicitly guage will also be emphasized. requested in the data step. More timing control is given to the SCl programmer through reserved labels, which are started at Contents predefined times. 1. Requirement analysis labels that control the Sel monitor timin",Sugi-13-231 Bailey Chen.txt
"THE SAS® SUPERVISOR Don Henderson, ORI, Inc. Merry Robb, ORI, Inc. I. INTRODUCTION · Definition of input and output files including variable names, their locations and attributes; This tutorial discusses the functions of the SAS Supervisor during the execution of a SAS DATA Step program and is a repeat presen- · Creation of the Program Data Vector; tation of a paper given in the Tutorial and the Advanced Tutorial · Specification of variables to be written to the output SAS data sessions of SUGI 12. The functions of the SAS Supervisor can be set; categorized. as follows: · Specification of variables which are to be initialized to missing · Compiling SAS Source Code, and by the SAS Supervisor between executions of the DATA Step · Executing Resultant Machine Code and during read operations; and Theactions of the Supervisor during both the compile and execution · Creation of a variety of ""flag variables"" which are used by the phases of a SAS job will be illustrated. Supervisor at execution time. The last four actions in the above list will be discussed in the When a SAS DATA Step program is written, the DATA Step following subsections. ""module"" must be integrated within the structure of the SASSystem. This integration is done by the SAS Supervisor. Gaining a more A. Creation of the Program Data Vector complete understanding of what the Supervisor does and how our ""program"" is controlled by it iscrucial to usingtheSAS System more The Program Data Vector (PDV) is a buffer which includes all effectively. variables referenced either explicitly or implicitly in the DATA Step. It is used at execution time as the location where the working values of variables are stored as they are processed by the DATA Step ""pro- II. STRUCTURE OF SAS JOBS gram."" The PDV is created at compile time by the SAS Supervisor. Variables are added to the PDV sequentially as they are encountered TherearedistinctcompileandexecutestepsforallSASjobs. Thisfact during the parsing and interpretation ofSAS s",Sugi-13-232 Henderson Rabb.txt
"ADY ANCED SET AND MERGE PROCESSING ROBINA G. THORNTON, ORI, INC MERRY G. RABB, ORI, INC INTRODUCTION rei nforce the capabilities of the SET and MERGE Most SAS* programmers are familiar with statements with respect to the following: the followi ng uses of the SET and MERGE statements for processi ng SAS data sets: 1) To read a SAS data set 1) Every SET statement ina data step sequentially, one observation at a activates its own READ poi nter, time, 2) The FI RSTOBS option on a SET statement 2) To concatenate two or more SAS can be used to perform a LOOK AHEAD MERGL data sets, 3) The IN = variables can be reset by the 3) To interleave two or more SAS programmer, data sets, 4) The POI NT option on a SET statement can 4) To perform a ONE TO ONE be used to read a specific Observation, or group MERGL of observations, 5) To combi ne observations from 5) The NOBS option on a SET statement is two or more data sets into one available for use at COMPI LE time, observation, 6) A JOI N, or ALL COMBI NATIONS MERGE can be achieved by creati ng POI NTER data sets and This paper will build upon these standard uses usi ng SET with the POI NT option, of the SET and MERGE statements to demonstrate sol utions to complex programmi ng problems, The problems have been si mplified for the Each of these topics will be covered in the purposes of ill ustration in this paper, The followi ng sections, concepts behi nd these examples make the power of the SAS programmi ng language evident in L EACH SET STATEMENT controlling the processing of data in the data ACTIVATES ONE READ step Some of the concepts presented in the POINTER. paper entitled 'THE SAS SUPERVISOR' (reference 1) are reviewed through practical Problem: An employee master file with all examples, The sample problems will include current employees must be ""updated"" by a a discussion of the END Of DATA STEP flAG transaction data set of new employees, A (EDSF) and the INITlALIZE TO MISSI NG VECTOR program must be written to add the new",Sugi-13-233 Thornton Rabb.txt
"s for A are $75 versus $150 for B. Assuming that both programs are run monthly, the following Saving money is uppermost in the minds of DP managers, and the formulas are used to evaluate the total costs: SAS System is certainly a ""programrnercfficient"" tool: minimal SAS Approach X :: $30,COO + « $60 + $15) ~ months) code is required to perfonn traditionally code intensive tasks. « S50 + Sl00)· months) Gratification and and results are immediate. Approach Y = $5,000 + Afamiliarquote suggests that the SAS System is easy to use, and just Thecostofeachapproachat1, 10, 100,and 1,000 months is illustrated as easy to abuse. Because the SAS System is becoming increasingly in Figure 2. popular as a development tool, it is essential to evaluate techniques for its effective use. This tutorial will define efficiency, suggest TOTAL COST TOTAL COST factors to be considered in measuring efficiency, and provide com- MONTHS APPROACHY APPROACH X parisons of techniques that improve efficiency. 5,150 30,075 1 6,500 30,750 10 20,000 A primary area where the SAS System can be used more effectively 37'soo 100 Sl55,OOO SlO5,OOO isl/O. It should be noted that over 90% of the processing time in any 1= given program involves reading and/or writing data (reference 1). This tutorial will illustrate how to avoid unnecessary I/O, minimize Figure 2 passes of the data, and control read-write loops. A natural question arises: How long will it be befor~ Approach Y These efficiency techniques also will be discu",Sugi-13-234 Howard.txt
"IMPIEMENTATION OF A HASHING ROUTINE IN SAS SOFTilARE Craig Ray I ORr, IN::. Result of Lookup - the variab les needed 4) 1. INTROOUCTION from the lookup file. Hashin g may be the fastes t genera lized Seek - One conpar ison in attenp ting to 5) techniq ue for table lookup. Table lookup refers perfon n a lookup. For exampl e, if a to the crOss referen ce of a parameter file based table lookup was succes sful after on the value of a variab le in the primar y (main) looking at three observ ations, then the file. lookup require d three seeks. While the concep t of hashin g is well For exampl e, the data in Figure 1 represe nt doCl..lIreIlted in conput er scienc e texts and is a mailing list as the main file and a file with often imple mente d in third gener ation unique records for each zip code as the lookup progran ming languag e applica tions, hashin g has file. The main file consis ts of each potent ial receiv ed very little attent ion in the SAS custom er's name and his/he r addres s. The system . This may be due to altern ative lookup file. is a s6J?CITately ~intained file <;,f non -proce dural techni ques of table lookup auxilI ary lnform atlon relatm g to every ZlP availab le in the SAS System such as MERGE and code. Table lookup attenp ts to relate , each PROC FORMAT with the PUT functio n. (The tenn obser vation of the main file with the non-pr ocedur al means specify ing what is to be corresp onding observ ation of the lookup file by done, not how to do it; there fore utilizi ng the key variab le. In this exampl e, non-pr ocedur al table lookup techniq ues require for each observ ation in the mailing list (main less progran roing). While other techniq ues are file), the corresp onding observ ation in the zip availab le in the SAS System, they should not be code file (lookup file) is related by ZIP (~ used interc hange ably. Depen ding on to obtain the resulti ng number of piano tuners circum stances , one techni que may be clearl y indica ted by the value of",Sugi-13-235 Ray.txt
"Using the TABULATE Procedure Holly S. Whittle, SAS Institute Inc., Cary, NC INTRODUCTION TABLE OF AD APPEAL STUDY This tutorial introduces the TABULATE procedure to people who are familiar with the SAS DATA step. Topics covered in this paper ! I 1 BATHING SUlt AD BUSINESS SUIT AD j +------------___________ 1 I I---_~------------------ are I DISLIKE i OK ! LIKE iDISLIl!:Ei OK I LIKE I I I-------+-------+-------t-------+-------+-______ I I · output that can be produced by PROC TABULATE I ININININININI 1------------------+----- --+------_t _______ t-------+------- 4- ______ 1 I I I I ISEX IA""GE I I j I ! I 1 I 1 1--------+---------1 · essential concepts and statements for running PROe ~I InMALE IUNDER 30 I 51 71 .1 31 31 I 1________ 4 _______ +-------+----___ + _______ +-------+-------I TABULATE 1 130-39 I 31 11 .1 11 11 21 I 1---------+-------+-------+-------+---____ t-------+------- J · how to define the table you want to produce I~O-49 1 I 31 21 .1 21 11 21 I 1---------t-------4-------+-------+-------t-------+-------I I 150-70 I 101 31 .1 61 31 41 I---------+-------+-------+-------+------+--___ ~_t-·------I 1 · simple techniques for improving the appearance of a ~I I IOVE1I70 1 71 21 .1 51 .1 table. 1--------4---------+-------+-------+-------4-------+-------+ _______ j IMALE leNDER 30 I 111 61 51 71 .1 151 1 1---------+-------+-------t-------4-------+-------+-______ I I 130-39 1 .1 21 21 11 11 .1 Why Use the TABULATE Procedure? 1 1---------+-------+-------t-------4-------4-------+--_----1 I UO-49 1 11 41 11 61 .1 .1 1 1---------+-------t-------+---____ +_______ +-------4-------I The TABULATE procedure is a powerful reporting procedure. I 150-70 1 71 61 31 101 61 .1 PROC TABULATE helps you analyze the relationships among I 1--------t-------+-------4-------+-------+-------f--- ----I I lOVER 70 I 31 21 51 61 41 .1 variables in your data set and produce summary reports in a table format. Figure 2 PROC TABULATE Table of Responses to Ad The two reports shown below illust",Sugi-13-236 Whittle.txt
"REGRESSION WITH THE SAS SYSTEM A Tutorial Rudolf J. Freund The tutorial consists of a set of transparencies which have been reduced for the proceedings. Full size copies for making transparencies may be obtained from the author for $5.00 to cover repr""oduction costs. IT IS THE PURPOSE OF THIS tUTORIAL THE DATA TO TO LEAn YOU THROUGH VARiOUS ASPECTS AJRLINE COSTS OFA OBS UTlL AVSTAGE SEATS SPEED LOAOfACT PASSCOST SEATCOST TYPE REGRESSION ANALYSIS , , 5.65 0.821 0.1290 4.01 0.378 4.137 , 1.791 USING 0.541 6.31 0.823 0.0943 4.06 4.024 2.176 0.84(1 0.1390 4.25 0.410 2.646 9.62 1.166 A NUfIIBER Of THE REGRESSION PROCEDURES · 0.409 3.044 9.00 0.845 0.1390 4.2S 1.245 0 ··105 9.51 0.1390 4.26 3.313 1.343 5 0.863 AVAILABLE 0.495 8.44 0.871 0.1186 4.38 2.954 1.461 S 4.37 0.486 3.140 1.528 7 8.29 0.871 0.1060 IN THE SAS SYSTEM. 0.394 7.94 0.949 0.1488 4.00 3.689 1.452 8 0.476 1.411 8.91 0.961 0.1236 4.16 2.962 9 7.52 0.975 0.426 3.462 1.476 "" 0.2025 3.96 2.911 "" S.B4 1.008 0.1150 4.13 0.539 1.600 1.431 "" 1.031 0.1365 4.22 3.392 0.422 8.35 NOTE 0.466 2.404 l. 119 "" 9.38 1.123 0.1481 4.24 "" 1.55 1.164 4.22 0.452 3.760 1.700 0.1210 "" 7.70 1.236 0.1221 4.2B 0.455 1.507 3.311 IN ORDER TO SIMPLIfY MATTERS, A SINGLE DATA SET IS USED FOR ALL THE 0.412 2.341 "" 7.91 1.350 0.1920 4.42 0.965 "" 8.71 0.1148 4.44 0.478 2.906 1.390 1.392 ANALYSES IN THIS TUTORIAL. HOWEVER. NOt NEt:ESSARllY ALL OF THE 1.408 4.7(1 0.504 3.306 "" 9.-47 0.1345 1.662 7.27 1.416 0.1145 4.38 0.-476 3.437 1.636 "" ANALYSES PRESENTED ARE USEfUL fOR THIS PARTICULAR SET OF DATA. \).400 8.-42 1.495 0.3597 4.44 2.833 20 1.133 "" 4.43 \).362 1.432 0.1356 10.80 1.518 3.959 to 22 8.09 1.528 4.32 0.287 3.3OS 0.949 0.3522 THIS TUTORIAL IS INTENDED GIVE AN OVERVIEW OF VARIOUS METHODS AND 2.425 1.297 23 10.80 1.576 0.1361 4.81 0.535 "" 8.43 1.584 0.1607 4.47 0.439 2.743 1.203 PROCEDURES. THEREFORE IT ODES NOT INCLUDE All Of THE NUMEROUS OPTIONS 0.381 1. 179 25 10.20 1.692 0.3007 4.65 3.096 0.591 2.258 1.333 2S 7.87 1.790 0.1375 4.6",Sugi-13-237 Freund.txt
"REPEATED MEASURES ANALYSIS WITH THE SASR SYSTEM Jane F. Pendergast, University of Florida Ramon C. Littell, University of Florida and a varial?le hol~ing the value of the response (Y). An INTRODUCTION example usmg a direct approach to creating such a data set WIth three repeated measurements is given below. In many different fields of study, it is often of interest to DATA OLD; collect multiple observations on each primary sampling INPUT SUBJ_ID $ GRP $ TIME $ Y; unit. In agriculture, this unit might be a plot of land, CARDS; called the mainplot, which is divided into smaller plots, 01 0 1 3.7 called subplots, on which the response variable is 01 1 4 4.3 measured. If the levels of a treatment factor are 01 8 1 5.8 randomly.assigned to the subplots within each mainplot, 02 0 2.6 1 the eXJlenmental design is known as a split. plot design. 02 1 4 5.1 If multiple measurements are taken on each mainplot at 02 8 7.7 1 various time points, the design can be called a split-plot etc~ in time design, where time is taken to be the subplot factor. In most other disciplines, especially those in The more multiple measurements one had on a which the primary sampling unit is often a person or given subject (or the more subplots within a mainplot) animal, it would be known as a repeated measures the more tedious this method became. Many users ' design. The expression split~plot analysis of variance preferred to structure the data so that each repeated would be replaced with repeated measures analysis of measurement on a subject would be read in as a variance, and the term plot with subject. Mainplot and separate variable. Programming statements in the data subplot portions of the analysis would be known as the step would then be used to restructure the data set between- and within-subjects portions of the analysis, created. For example, respectively. A repeated measures (or a split-plot in time) DATA OLD2; design differs from the usual split-plot design in that the INPUT SUBJ ID $",Sugi-13-238 Pendergast Littell.txt
"rial, should provide a guide for the implementation of the ANOM technique using SAS software. The SAS code for the examples This tutorial is designed as a sequel to the presentation entitled used in this tutorial is given in Appendices 3 and 4. 'Application of the Analysis of Means' given by Dr. Peter R. Nel~ son in the Econometrics, Operations Research, and Quality Con- trol Section. It includes a very brief review of the concept of THE BASIC STEPS analysis of means but focuses primarily on how SAS® software can be used to perform analysis of means. The following steps present, in their most general form. the ANOM technique. Listed for each basic step is the SAS software",Sugi-13-239 Fulenwider.txt
"ctivities of the organization. The Abstract majority of the SYSTEM 2000*-based This paper describes the major application systems are in support of SYSTEM 2000*-based systems -that have been these administrative functions. developed at the National Bureau of Financial Systems Standards (NBS). Three views are presented the Application Systems, There ar~ many data bases within the SYSTEM 2000* Usage, and the Data Base Administration views. Financial system. Background the Accounting Data Base is the * primary one within the financial area NBS is the Nation's measurement laboratory in the physical and the Payroll Data Base : keeps track * engineering sciences. The mission of of the Time & Attendance of NBS is to help provide for the employees NBS Nation's measurements and standards AccQunting Data Base needs. Especially in support of national goals such as economic growth and equity in commerce, these standards Figure 1 shows the general type of provide the basis for the exchange of information within this data base, e.g. goods, the accurate specification of Accounts which are established to products, and quality control methods * for production. record all costs and obligations Object Class indicates the nature of * The three views that I wish to se-rvices or articles for which share with you on the NBS environment obligations are incurred. & the Usage of SYSTEM 2000* are : From the data base point.of view, Figure * Appl ications which are developed 1 shows that : using SYSTEM",Sugi-13-24 Lee.txt
"USING PROG NLIN TO FIT SEGMENTED REGRESSION MODELS George A. Milliken, Kansas State University, Department of Statistics, Substituting for the above two parameters in 1. Introduction equation (1), the model becomes Often a simple mathematical function cannot describe the underlying unknown model generating data. Oue may know some of the properties of the model or one may know very little about the (2) underlying model. Often such data can be described by a series of segmented models, where the forms of the models being segmented are Define the indicator function known but the points at which the functions join if x ~ 0 are unknown and need to be estimated. Segmented I (x) _ {l models can be applied in many diverse situations 0 if x < 0 + from tables of numbers without variation to data with substantial variation. The model in (2) can be expressed as The numbers in Table 1 represent the cost to haul a ton of fertilizer the specified number of miles. The cost-mile relationship is shown (3) in figure 1 where for short hauls the cost is almost constant (the cost of loading and The model has four parameters which need to be unloading) and the cost of driving time estimated and the model is nonlinear since it is gradually dominates the cost. This relationship a nonlinear function of a and P · If a is can be adequately described by a model with a 21 quadratic segment for the curvature part of the known. the model in (3) is a linear model and a graph with a linear segment for the remainder. linear regression program can be used to fit the The two models segmented together are segmented models. linear models but when the point where the The process is easily expanded to more models join is unknown. the resulting model is a complex models. The model in equation (4) is a nonlinear model. The class of segmented models quadratic model segmented to a quadratic model, considered in this discussion must satisfy two i.e .· (1) the pairs of models join conditions: together (they are",Sugi-13-240 Milliken.txt
"Arrays are powerful, flexible and confusing. Using arrays in SAS code Tools and strategies have been developed makes the code more compact and to deal with different problems. One of effective. By looking at how arrays the most common strategies people are work and why we use them, we can enjoy taught is how to deal very large, the advantages and avoid the angry bite complex problems. Different terms are of an abused array. used: decompose, partition, factor. Often Julius Caesar is cited as an example of how to ""divide and conquer"".",Sugi-13-241 Langill.txt
"SAS® Functions - Simple But Powerful Techniques Steve Holson, General Dynamics Jenny Putman, General Dynamics Introduction give the resulting variable, Avg, the value 4. The SUM function adds the values of the arguments. This tutorial introduces SAS® functions. If you have In this example, the first argument is a variable and ever asked: the second, an expression. - What is a SAS® function? Data; - What exactly do SAS® functions do? Set IP.Expenses; - How are SAS® functions used? Interest = SUM(Home_lnt,(Pers_lnt * .65)); Run; you've come to the right tutorial. These questions, as well as several examples of popular functions, will be discussed. Familiarity with the DATA step is Functions By Categories assumed. The following functions will be discussed in this What Is A SAS® Function? paper. A SAS® function is a routine that acts upon one or Arithmetic Date & time more arguments (variables, constants, expressions) - MAX - DAY and returns a value. The syntax for a function is: -JULDATE - MIN - MDY FUNCTIONNAME(argument,argument, ... ) Truncation - MONTH - TODAY - CEIL Functions are used in programming statements and - FLOOR - YEAR are useful as programming shortcuts for: - INT Special - ROUND - Performing numeric calculations - PUT - Manipulating character and numeric data Sample statistics - Creating new values from existing data - MEAN -SUM As previously mentioned, an argument can either be Character a constant, a variable or an expression. The - INDEX following examples demonstrate the three argument - SCAN forms. - SUBSTR - TRIM The INT function returns the integer value of an argument. In this example, the argument is a constant. The value is 2.5. MAX(argument,argument, ... ) The statements The MAX function returns the largest value among Data; the nonmissing values of the arguments. Arguments . Wholenum = INT(2.5); must be numeric. MAX requires two or more Run; nonmissing values. give the resulting variable, Wholenum, the value 2. The following program outputs",Sugi-13-242 Holson Putman.txt
"T16.ACTIVE: DATE=TODAY(): THSMONTH=INTNX('MONTH',DATE,O): Elements of programming style and technique aff eet the LSTMONTH=INTNX('MONTH',DATE,-l): amount of effort required to maintain programs. In IF OAT CLOS=. THEN DELETE: many cases. the ""necessity"" to maintain programs is a IF DAT=CLOS < LSTMONTH OR DAT_CLOS direct result of the tools and techniques used when >= THSMONTH THEN DELETE: writing the original program. DISP=F_DISP_C: MAT_COST=M_COST: HRS=M HRS+PA HRS4+ENGHRS: An ultimate goal would be zero maintenance: a program IF HRS=. THEN HRS=l: that can be submitted at any time, with no changes to PROC SORT DATA=D: BY IRNUM: the code, for any set of input data. In practice, DATA 02: SET 0: BY IRNUM: IF FIRST_IRNUM: this approach demands a broad range of skill and DATA I (KEEP=DISP IRNUM MAT_COST HRS): knowledge using SAS@ software. creativity. and a SET INPUT17.IRS: DATE=TODAY(): willingness to put in extra programming effort up THSMONTH=INTNX('MONTH',DATE,O) : front. The final program should require little or no LSTMONTH=INTNX('MONTH',DATE,-l): attention on the part of the programmer. IF 0 CLOS=. THEN DELETE: IF D=CLOS < LSTMONTH OR D_CLOS >= THSMONTH This paper investigates some of the techniques that THEN DELETE: reduce maintenance, gives examples of relevant syntax. DISP=DSP1: and applies the techniques to sample programming HRS=MHRS+EHRS+QHRS+OHRS: problems. IF HRS=. THEN HRS=l: For many reasons, this program is difficult to Where Does the Time Go? decipher. Contribut",Sugi-13-243 Virgile.txt
"SORTING MASSIVE DATA SETS David S. Rubin, MPA Empire Blue Cross & Blue Shield INTRODUCTION: In Chapter 46 of the SA~User's Guids There is a fourth reason that PROC SORT is used; habit. Many times Basics, there is a small note on large beginning, and not so beginning data sets. ""Sorting Large Data Sets. programmers will sort a data set Occasionally a data set is too large unecessarily but automatically in for the sort utility to handle. If your order to avoid the SAS error installation uses an IBM or equivalent PRoe message ""DATA SET NOT SORTED."" system sort utility, SORT prints a message explaining the situation when Planning prior to programming is this happens. ff In the notes are ,-vari6us::c preached by instructors at all levels, suggestions on how to calculate the but when dealing with large data sets appropriate ""5"" or sort size for your and sorts, it is planning that will data set. However, there are no sugges- help avoid uneeded sorts. By planning, tions on what to do when the size of the programmer can create a strategy the data set exceeds the capacity of tailored to the specific data set that the system. will decrease the overall size of the set, eliminate uneeded variables, and Sorting data sets with large numbers of records presents various problems. cut down on the demands placed on the system. In larger sets, such as those with more than 1 million records, certain systems LARGE DATA SETS MEAN LARGE PROBLEMS: will not have the capacity to handle a sort, no matter what capacity or sort The problem with using PROe SORT size you request. This paper presents a either necessarily or by habit, is strategy for sorting massive data sets that sorting uses a lot of computer in severely limited environments. time, memory and hard storage cap- acity. As the data sets increase in For the purpose of this paper a large size it becomes possible to exceed set is defined as one in excess of \ the capacity of the system and ""kill"" million records. Different systems will",Sugi-13-244 Rubin.txt
"shou1 d be the easi est phase of the project For SASR users needing capabilities if the desi gn was properly attended to. over and above those provided by the reporting Overall system considerations come into procedures this paper discusses the techniques play here as well as the mechanics of the for and the process, of generating periodic SAS data step. Finally, the implementation production reports. The design. construction, phase includes considerations such as who and implementation phases of the report writing will be invoking the report writer, how, project are discussed as necessary and with what data source. With prerequisites for acquiring a superior end implementation comes the need for macro product. The FILE and PUT statements, system based reporting and other sophisticated options, and data step functions are front-end control. Again, design is most demonstrated to control the placement of important for a successful implementation. variable and constant data on the printed Just a word about the level at which report. Additionally, the Macro Facility I have chosen to present this topic. I is explored as a method for generating periodic feel that it is most important to gain a reports. Since most of the material discussed conceptual understanding of the report writing is well explained, along with examples, in process. I do not intend to teach syntax; SAS System documentation, the emphasis is the SAS Institute's documentation does a better job than I ever will. Although not on a conceptual understanding of the report writing process. wanting to over simplify a potentially complex process, I will clearly demonstrate the",Sugi-13-245 Dickstein.txt
"DDIYSTIFYIXG PROC FOR:\LAT HAllEn GERMAN, GTE LABORATORIES Introduction (creating axes or output rangelvalues) MEANS, PRINT After having grasped its fundamentals, most (determining output range/values on SAS@ users will spend a considerable amount all report variables) of time learning ways to control and enhance SUMMARY report output. Formats -- both system-supplied (limit number of class variables) and user-defined provide an easy and flexible FREQ,TABULATE means of determining how values will be dis- (change display of output) played or printed. 2. The following procedures will give informa- This paper has two aims: alto provide begin- tion about formats and format libraries. ning SAS@ users with an easy-la-understand approach for learning formats and b)to illus- CONTENTS trate how to use this approach for enhancing (can display informatlformat information your SAS reports. about SAS datasets) FMTLlB What Are Formats Anyway? {list/output format library directories (this is in supplemental library) Formats are a set of instructions to tell the SAS PDS (list/delete all or some members of a format system how to read values (generally called IN FORMATS) and how to display or print values library)' (generally called FORMATS not PDSCOPY OUTFORMATS). Another way of thinking about (copy formats between format formats is as a table lookup - finding a value in libraries and to list the another file based upon the value in the main relative size of a format.) file. Let's look at a brief example. Suppose you wanted to order a pizza but only remembered With this brief listing, you can sense the power the name of the pizzeria and not the phone and flexibility of formats. Whether it is chang- number. For most of us this would not be a ing the data values for graphs, reports, or sta- problem -- we would ""look up"" in our phone tistical analysis, formats can easily produce the book ""phone number table'"" the name of the desired result. pizzeria and next to it would be the ""associa",Sugi-13-246 German.txt
"WHATEVER HAPPENED TO THE OLD SAS* DATA LIBRARY? Erika Mares Stone Carolina Population Center, The University of North Carolina at Chapel Hill 1. Introduction Then, when you turned the pages of your Version 5 SAS Basics manual to those familiar procedures _PROe eOPY, PROe CONTENTS, and PROC DATASETS, possibly you felt, as I did, that you One of the consequences of having been a SAS didn't recognize them any more. Not only had programmer since 1980 is that I can remember ""librefs"" replaced ""ddnames,"" but an option we when things were a whole lot simpler than they had not seen before, MEMTYPE=, could now be used are today; when the main SAS reference on my to tell these procedures what type of SAS file desk was one manual, containing all the to process. procedures--statistical and non-statistical--in the- SAS System at that time. In this manual, the SAS User's Guide: Basics. 1979 Edition. we Finally, when I found that I could no longer bring up my pre-Version 5 FSEDIT modified read on page 29 that: screens until I converted them to something called ""catalog entries,"" I decided to embark on a project to try to understand the essence of A SAS data base is a specially formatted OS the changes in the Version 5 SAS System relating file that contains one or more SAS data sets. to SAS data libraries and that is what my talk is about. When the SAS Applications Guide 1980 Edition In particular, we will look at: joined the User's Guide on my desk, a SAS data base became a ""SAS data library"" which was still Describing a Version 5 SAS data library and described in essentially the same way. Thus in 1980 we read on page 109 of the SAS Applications naming SAS files: Why has the terminology changed? Guide that: Types of SAS files and how they are created: A SAS data library is an OS data set that A summary and examples. contains one or more SAS data sets. The data library can be stored on disk or tape, and The DATASETS, COPY, and CONTENTS procedures can contain only SAS data sets. in",Sugi-13-247 Stone.txt
"PROCESSING LARGE FILES: THE SUMMARY PROCEDURE AND OTHER EFFICIENCY TIPS Juliana M. Ma, Qnintiles, Inc. For computing environments using micro- INTRODUCTION computers or minicomputers, the definition of The intent of this tutorial was to present basic ""large"" clearly depends on the computer system's ideas and tips worth considering when working capacity. Large file processing might be called with SAS® software and large files. The paper ""walk away"" processing on a microcomputer, i.e., differs slightly from the original tutorial to you submit a program and walk away for a cup of compensate for format differences. The coffee while your microcomputer is working. No discussion is directed toward programmers, data matter how small your large file may be, the ideas managers, project managers, and other users presented here remain useful with appropriate who have data files that must be processed adjustments. carefully because of size. Batch processing in a Processing a large file is expensive in terms of mainframe computing environment, e.g., under both programmer time and computing dollars. OS, is emphasized although the principles apply Any production run, which processes an entire in appropriate minicomputer or microcomputer file, becomes a significant event. Put another settings. Basic knowledge of base SAS software way, discovering a mistake after processing a and the SUMMARY procedure is assumed. large file is to be avoided. Thorough program The topics covered include: testing to catch programming problems as early as possible becomes relatively more important. · characteristics oflarge file processing, In particular, since machine efficiency signifi- · efficient programming techniques, cantly effects processing time and cost, the extra · strategies for testing programs, programming time spent testing complex, · examples using the SUMMARY procedure. efficient code pays off in comparison to the possi- bility of a wasted production run. LARGE FILE CHARACTERISTICS Befo",Sugi-13-248 Ma.txt
"QUESTION: The macro facility in base SAS® software is a powerful ""I %INCLUDE-d my macro. Why didn't it run?"" tool which can increase the functionality and flexibility of SAS programs. The macro language is also very complex, and misunderstandings about how the PROBLEM: language works can cause problems for beginning users. This question comes most often from people who are used to including open SAS code from external files. The basic problem is that ""including"" just reads the This tutorial will discuss a few of the common problems SAS code from the file, and only defines the macro. that beginners (and experienced users) have with the Simply defining a macro does not execute it. The SAS macro facility. Intuitive, plain-English answers will macro must be invoked as well. be given to some questions that are frequently asked.",Sugi-13-249 Westerlund.txt
"PROC FSEDIT Applications with large SAS® data sets may benefit by using SAS Institute's SYSTEM 2000® Data Management Software. Indexes It is easy to try out an application by using PROC FSEDIT to are available to speed queries, and selection criteria can be create a SYSTEM 2000 data base. If you have ever created a new applied to subset the data. Redundant values can be eliminated. SAS data set using PROC FSEDIT, then you are already familiar Sorting and visual display of data relationships are provided. This wtth this process. paper examines new options available in Version 5 of SAS/FSp® software's FSEDIT procedure on IBM® computers for Example: The SALES data base has four files or record types: SYSTEM 2000 data bases. · The ENTRY record (CO for short) has general information for each sales region.",Sugi-13-25 Barrett.txt
"es or programming Oneofthe most common questions asked bySAS programmers who statements, however, the program code is processed. differently, as are just beginning their introduction to the macro facility is: ""Why shown in Figure 2. As the program is read from the input stack, use macro ... what's it for?"". This tutorial attempts to demonstrate macro statements will not be sent to the SAS processor, but to the the advantages that macro can offer and the motivations that a SAS macro processor instead. Here the macro statements are evaluated, programmer who uses macro will have. Starting with an example any logic defined by the macro's programming language will be SAS program that uses no macro; features are added which demon- executed, and the results of the evaluations - program text - will strate the common uses of macro and the exceptional power it can bereprocessedasifitwerepartoftheoriginalSASprogram.lnother words, the macro code in your program is used to generate SAScode give the SAS programmer. that will be substituted in place of the macro code before the SAS processor sees it. 1.2. What Is the Macro Facility? To understand how the macro facility works and how to best use it~ you first must completely understand what it is and how it fits into a conceptual model of the SAS System as a whole. Input ·/ SAS Program / Stack - Themacro facility can best be thought of as a separate languagethat works with the standard SASlanguage. Itcontainsmanyofthesame type of programming",Sugi-13-250 Nicholson Pulgino.txt
"TEFLON AND TANG: FORGING GENERIC MACRO TOOLS Peter Kretzman, BR Associates ABSTRACT: The SAS programming language arose originally as an ad Conventional languages, of course, have featured these ca- pabilities for quite some time. FORTRAN has its sub- hoc tool for quick data base subsetting, manipulation, and routines, PL/I its procedures, C its functions. In a C pro- statistical reporting. Reusability or generic application of gramming environment, for example, a programmer has a code was not really an issue. Now, though, large SAS sys- bottled library of reusable tools and routines, some specific tems are being constructed with tens of thousands of lines to the applications being worked on, some general enough of code. Unfortunately. SAS, unlike a language such as C, to be considered language extensions. Construction of is not particularly designed for the development of many C programs often involves little more -than an adroit reusable, generic small tools (""black boxes"") which serve as combination of existing functions, with a little mortar system ""building blocks."" The SAS macro facility can, slapped between the bricks. however, do something to fill this gap if appropriately used. The SAS language has no direct and easily accessible counterpart. There are no real subroutines (LINK does not This tutorial outlines a standard idiom and philosophy to count) and no user-designed functions (written in SAS it- use when constructing and documenting useful and usable self, that is) which can return a value. The macro facility, macro tools. Using this idiom, you can identify and de- however, can simulate many of these functions. The key velop the tools you need as you go about your ordinary difference, of course, is that macros actually write SAS programming. In other words, not all of your ad hoc work code (albeit selectively), rather than serving as equal run- has to be disposable. Rather than placing all the emphasis time compatriots with the code that calls them. W",Sugi-13-251 Kretzman.txt
"Getting Started with SAS/AFlM and Doing It Right Howard Levine, Levine Software Systems When you are building systems in SAS/AF, the goal you Introduction should be striving for is to build systems with the following characteristics: SAS/AfTh' is a very effective tool for making SAS® applications user friendly. The purpose of this paper is to acquaint you with some ideas that will help you get started Easy for end user to use when you begin using SAS/AF. Flexibility - Use parameters The topics that are covered in this paper are ideas to think about when using SAS/AF,SAS/AF procedures, the types of Easy Maintenance. screens in SAS/AF, useful techniques, and examples. Although some people might interpret these objectives as implying that systems should be kept simple, that is not the SAS/AF is used to make screens for users that convey case. A programmer might have a very sophisticated task to information and prompt a user to fill in the blanks. By fllling in the blanks and submitting the screen, SAS code is perform in order to keep systems simple for the end user .Also, easy maintenance does not imply simple code. Instead, generated based on what the user typed to fill in the blanks. This is valuable for experienced programmers as well as for it means designing your system so that maintenance tasks are as menu driven and automated as possible. The code for non-programmers because it is often easier and more reliable doing this is not always beginner level code. to have automatic procedures set up for tasks than to have to wtite code each time the task has to be performed. Every software product has some enthusiasts who go overboard. They think that their favorite software is so great General Ideas that it eliminates the usefulness of other software products. Some people might try to tell you that SAS/AF eliminates the need to use ISPF® panels and SAS macros. Nothing could Some principles that apply to programming in general or to be further from the tmth! While SAS/",Sugi-13-252 Levine.txt
"the user for information and contains programs that are executed during the A goal of end-user applications is to be user-friendly. It is impor- application. tant that the applications programmer anticipate issues and questions that the user may have. The programmer must provide These tools provide implementation support for creation of inter- for a dialog between the user and the application so that deci- active applications at a basic level. This allows the developer to sions can be made while the application is in use. In Version 6 create as simple or as sophisticated a system as needed. The SAS/AF® and SASjFSP® software, currently available in the PC applications programmer can choose the appropriate tool based environment, Screen Control Language {Sell is used to design on the task to be accomplished. For instance, the creation of help applications that can prompt the user for all the information for applications, individual tasks, or even specific fields on a needed to complete a task. screen is an operation that is readily accomplished. CBTs can be designed to provide additional levels of help or training that can This tutorial expands on the ideas presented in the tutorial, ""The be accessed at any time in an application. CBTs can also be used Screen Control Language in Version 6 SAS/AF Software and strictly to meet traditional computer-based training course objec- SAS/FSP Software."" tives.",Sugi-13-253 Kramer Wharton Kumar.txt
"Printer selection list The SAS® System provides a variety of methods to generate COlllllland ~n) reports. You can use the DATA step with PUT statements. Alter- .x IBM 667a _ IBM laOO natively, you can use the PRINT procedure, the MEANS proce- 2700 _ Xero~ dure, or the TABULATE procedure. This paper focuses on using _ .xero~ 57GO _ Xeror 9700 the FSCALC procedure in SAS/FSP® software to generate mean- _ Line Printer ingful, detailed reports with a minimum of effort. rom Description: _ _ _ _ _ _ _ _ _ _ __",Sugi-13-254 Cochran Brideson.txt
"input x y @@ ; cards; There are a number of ways within the 13 21 33 42 55 Annotate Facility to describe the location, or RUN ; display coordinates, that will be used by a DATA range function. The Annotate Facility accomplishes RETAIN xsys ysys 121 style 'Sf color 'YELLOW' the task through reference systems. These x=.;y=.; reference systems permit the specification of function = 'FRAME'; output; display coordinates in a number of different RUN measurement systems. For example, the location may be expressed as percentages of the screen SYMBOL I=SPLINE C=WHITE V=STAR ; area, or as actual data values. We will be PATTERN V=SOLID C=GREEN ; addressing the actual data value specifications TITLE 'PROG GPLOT DATA SYSTEM AREAf and how they releate to particular SASiGRAPH® PROC GPLOT DATA=xy ; p raced u res. PLOT y * x / ANNOTATE=range AREAS=l RUN ;",Sugi-13-256 Friebel.txt
"calendar data set, extract those events scheduled for the current day, and display them (and a calendar). The Calendar and Note- A simple ISPF application using SAS® software is developed in pad dialog distributed with SAS/OMI software displays a scroll- this paper. The application allows you to enter and update events, able calendar and a list of notes. The notes are ISPF profile vari- such as meetings and appointments, in a SAS data set and to ables. If those notes are set to the day's events, the Calendar and display the events scheduled for the current day along with a cal- Notepad dialog can be invoked to handle the display part. (See endar. Screen 1.) The application consists of an ISPF panel and SAS source code. The Calendar and Notepad application distributed with ------------------- ----- ___ NOTEPAD AND CALEIUlAlI ----------------------------- SAS/DMI® software is also used. Edit models are used to ease COIlIlAHD ~~~> Today: 88/01118 SS.Ol~ 11:0S Iuterval Calclllator: the development. days. Jullau 88.018 Urn as.OS1 18JAD19S8 thrn 2111AR198S is 70 IfONDAY thru SDNDAY induding SO weekdays and 20 weekend days NotePad SIITWTfS i-iii~jii-Ji99-~;i~~-I;;i;;~~t~ti~~---------------i-J;~8~--21-28-2;;-30-]1-ii-22-1",Sugi-13-257 Ingold.txt
"Abstract: Interactive development and INTERACTIVE CODING testing techniques can significantly reduce the time and resources required to o Using an Edit-and-Include produce reliable applications. This loop for development tutorial will present concepts and methods which allow interactive o ISPF/PDF EDIT Models (optional topic) development and testing of SAS code. Online Documentation Operating System: MVS only o *---------- * ------* *- o Introduction Lets begin by looking at how we can improve the coding phase of development. o Interactive Coding We will be covering these three basic topics. The EDIT-and-include loop. Edit o Interactive Testing and Models. and online documentation. Debugging ------- -- ---- * * o Summary INTERACTIVE CODING o Question and Answer Period Using an Edit-and-Include 0 loop for development * ---- -------- * * This tutorial provides an introduction to some of the interactive development and It is likely that you are already using testing techniques that are available the Edtt-and-include loop technique for with SAS/DMI. development. *-------------------* Using the edit-and-include loop INTRODUCTION technique, you build the final program in a series of step. Beginning with only the ~keleton of the program you alternate The SAS/DMI software product links the SAS system to IBM Corporation~s between filling out the program and Interactive System Productivity testing the features as they are added. Facility (ISPF). SAS/DMI allows all of the features of b",Sugi-13-258 Walker.txt
"interactive retrieval and analysis system (MIRACLE). The SAS System provides a high-level program- The integration of SAS software is based on three ming tool for data analysis. However, the flexibility of design principles: the SAS language and its numerous options can both · Separation of the embedded references between intimidate and confuse a casual user. This report dem- the SAS data and the proc steps. onstrates how the full power of the SAS System can be · After separating and compartmentalizing the SAS integrated, so that end-users with limited training can code, reintegration is controlled with VMS com- perform their own analyses without sacrificing flexibili- mand procedures and is accessed through menus. ty. SAS software has been integrated into a menu- · Data references are made logical with SAS macro driven system that can be adapted to an extensible set variables and then integrated to physical datasets of SAS procedures in a dynamic data environment; it by using on-line forms. operates under VMS@ and uses the DIGITAL@ FMS The next three sections in this paper describe the Forms Management System. implementation of these three principles.",Sugi-13-259 Lee.txt
"UE, and REPORT commands. Combine these SYSTEM 2000 commands with the During the past year, the Institute has spent SAS macro language to create shorthand requests considerable effort to improve and expand for predefined reports or queries. You can even SYSTEM 2000 Data Management Software across use the macro language to develop your own the three major hardware systems: IBM ®, query language. And, of course, you have on-line Unisys ®, and CDC®. This effort ranges from new HELP to all SYSTEM 2000 commands. releases to documentation and new procedures. This paper gives an overview of these current and PROC FSEDIT (Full Screen Editing) future developments. The most recent addition to the interface family is the enhanced FSEDIT procedure. This full-screen data editor permits direct access to SYSTEM 2000 SAS® System Interfaces to data bases. With PROC FSEDIT, you can build SYSTEM 2000® Software custom screens, check data entries, and browse and extract data. You can query data as well as The SAS System and SYSTEM 2000 Data graph the structure of your data base. Additionally, Management Software are a great match. The you can interactively design new data bases. marriage of these two products provides the end user and programmer with the features and The benefits to SAS users can be summed up in benefits of both systems in one integrated one word: ""speed."" Imagine having 10,000, package. 100,000 or 1,000,000 observations and being able to display any of them equally as fast; that'",Sugi-13-26 Hults Nelson.txt
"SHARE and SHARE ALIKE Michael R. Gibson, The Gates Rubber Company As The Gates Rubber Company's SAS® Wizard, 1 To allocate departmental libraries, I have adopted needed a way to share SAS libraries efficiently the follOwing conventions: among several groups of users. SAS/SHARE®, a relatively new product in the SAS system, helped 1. SASLIB is allocated as ""dept. "" me accomplish this objective. This paper will 2. SASPROF is allocated as ""deptuser. "" show the three key features of my implementation 3. CNTL is allocated as ""deptcode. "" SAS/SHARE at Gates, using examples from my TSO CLIST for operating in a MVS/XA Similarly, my one divisional application, for our environment on an IBM 3084, and my SAS Operations Division, is named to ""OPERDlV,"" and AUTOEXEC files. their libraries are allocated as ""oper"" and ""opertiser."" There is no ""opercode"" at present. STANDARDIZED LIBRARY NAMES: Standardized library names greatly simplifies The first key to the effective use of SAS/SHARE is implementing SAS/SHARE as my TSO CLIST will standardizing library names. The SAS system at show. Gates is supported by the Computer Information Center, therefore, I use ·CIG"" as the high-level TSO CLlST: prefix for all library names. The following suffixes form the last element of all SAS libraries: For convenience, my entire TSO CLIST is appended to the end of this paper, but I would 1. SASLIB data libraries. like to draw attention to a few major points. 2. SASPROF-- SAS/AF catalog libraries. 3. SASFMT permanent format libraries. · Lines 26 - 30 set up the default library names. 4. CNTL code libraries that are standard This is greatly simplified by using the naming OS partition data set with PS conventions discussed in the previous section. organization. Lines 32 - 38 allocate a special, permanent, department level format library. This must be Middle level names are based on application done before starting SAS, and is the only time I usage. At Gates, applications fall into one of have to hard-co",Sugi-13-260 Gibson.txt
"The Diagnosis Query System Gary L. Katsanis, Strong Memorial Hospital Introduction Enable Information Analysts to use the data with no programmer involvement; This is a description of the process we went through while developing our query system. It covers our Develop a research request form for steps through the process and describes the methods completeness of parameter collection we used to deal with some problems. Although we and recording purposes; worked to deal with a specific requirement, I think our approach was general enough to be of help to Automate validity checking for parameters anyone developing a query system. where possible; We are a clinical analysis group that works in a 700 Develop a computer audit trail. bed teaching hospital. In addition to Analyst! Programmers, our staff includes Information We felt that a paper request form would help make Analysts, who specialize in medical terminology sure that all of the necessary parameters were and who work with requestors to develop clinically collected beforehand. This was important because meaningful specifications for reporting. many of our requests come in over the phone. We also used the request form to keep a signed record The hospital sees about 28,000 inpatients a year. of the request, in the event that we were asked for We have a relational series of files containing confidential data. We emphasized validity checking information on hospitalizations, some online and since the users, our Information Analysts, were not some on tape. Files vary in size from 1 record per accustomed to using the data base directly and we patient stay to an average of 400 records per patient wanted as much feedback as possible. We wanted stay for our detailed service file. While our files the computer audit trail for recording requests; we are not fully populated for the entire time period, also found that the audit trail was very useful to the we have some data back to 1965. programmers during debugging. Project an",Sugi-13-261 Katsanis.txt
"HELPING NAIVE USERS: AN EXPERT SYSTEM TO PREPARE INITIAL SAS® ANALYSIS Shoko Tsuji, Teknowledge, Inc. Laurie Zant, Teknowledge, Inc. David King, Teknowledge, Inc. This paper examines how an expert system was built In this paper, we first describe knowledge systems technology, focusing on its benefits for data that prepares exploratory analyses with SAS®. We management, and then examine the kind of knowledge focus on the knowledge used in the system and how it is used in Statistical Planner and how it is represented. represented. New. users of SAS often have difficulty utiliZing SAS effectively due to the tasks of preparing Knowledge Systems Technology DATA steps, selecting appropriate PROCs for the type of analysis desired, as well as learning SAS's syntax. Knowledge systems are computer programs designed to Expert systems can enable a new user to tap the power assist with particular tasks, using strategic, factual of SAS immediately by writing a SAS program based and judgmental expertise of specialists. In the past on a description of the user's data and requirements. decade, knowledge systems have moved from the universitiy research laboratories into industry and At Teknowledge, we have written an expert system business. using our expert system shell, COPERNICUS TM, which produces a syntactically correct SAS program to Diagnostic expert systems are the most common analyze data using descriptive statistics. We assume commercial application of knowledge systems the user of the expert system is familiar with statistics technology. NCR Corporation, for example, streamlined and has the data in hand. During a consultation, the its ability to maintain remote computing equipment with user is asked questions about the nature of the a system called ESPm. The system interprets the error variables used in the study. The expert system logs produced by mainframe computers, ascertains constructs appropriate DATA steps to enter the user's when a problem is emerging, and writes a",Sugi-13-262 Tsuji Zant King.txt
"ppear straightforward, but in practice users frequently leave out critical steps which can unwittingly lead them into In general, statistical software requires more drawing inaccurate conclusions about their data. analytical sophistication on the part of its users than most software. Users must be familiar with the syntax of the package, knowledgeable about For example, a common problem new statistical software users encounter is proper development of statistical theory, and be able to converse with a variety of systems in order to use the software the multiple regression model. Often users neglect looking for problems in the data and decide they optimally. This places a tremendous burden on the have a good model when R-squared values are high amateur and occasional statistical software user. and the F statistic looks significant. However, these values can be convincing in the presence of a strong One answer to this common problem is to have a interrelationsh ipbetween explanatory variables. user-friendly front-end system to help users in being more productive with statistical software. This problem, more commonly known as This implies an interface which could access data multicollinearity, means that some of the from a variety of sources and run desired explanatory variables may be surrogates for others procedures. But more importantly, it also implies and one of the damaging results is that parameter the ability to assist the user in applying basic statistical theory to the",Sugi-13-263 Elston Purdon.txt
The software tester is presented with a main menu. from which the needed options A dynamic user-friendly IVP (Installa- can be selected to perform the desired tion Verification program) system was functions. designed to assure quality testing of online and batch software products. us- ing several features of SAS. This menu system. driven by the user input. runs TPNS script simulations. generates vCL 2. IVP SYSTEM STRUCTURE and Jobstreams for the objective of au- tomated software testing. It facili- tates browsing the results of the Menu system: 2.1 requested tests. Base SAS. SAS/AF. and the Display Manager software (OMS) made The IVP Menu system is a set of inter- the development process easier. thus connected menus of several types of making the end product a flexible front- screens (CBT. HELP. MENU. PROGRAM etc.). end interface to testing of software that provide easy to use interface for products. the IVP test application. Some menus are shown in Appendix A. Foundation for this is laid through SAS/AF soft- ware. Very minimal or no knowledge of the SAS syntax and structure is expected of the user. User's responses are,Sugi-13-264 Kanthan.txt
"data set when the command is executed. If 'DATA' is used, the ,This paper is for those SAS* software users who wish to retrieve data will be written to the data set in nonstandard form, whereas and process cL1.ta residing in an IBM Database 2 (DB2) data base, if 'REPORT' is used, the data will be written in standard fonn. but who do not yet have the newly released SASjDB2* software. The fonn of the data is signillcant in that it will determine how the We will illustrate a method to use in the interim which enables a file can be later read using SAS software. SAS user to retrieve data from a DB2 data base and then process that data using the SAS language. This paper may be of interest After allocating the data set, exit from ISPF back to the QMF to other SAS users because the mechanics of this procedure can REPORT PANEL. The EXPORT command can now be exe- cuted by entering on the command line of the panel either 'EX- be applied to other situations which might arise where data reside in a data base that can not he easily accessed by base SAS soft- PORT DATA TO dsn' or 'EXPORT REPORT TO dsn', ware_ depending on what was used as the lower level qualifier when the data set was allocated. When the EXPORT command is executed, the lower level qualifier will automatically be appended to the data",Sugi-13-265 Leddon.txt
"A Documentation And Retrieval Strategy Using The SAS* System John Podgurski Syracuse University INTRODUCTION SAS programs to create permanent labeled SAS dataset-format library com- It is possible using the SAS* system to binations can be developed several ways attach extensive documentation informa- within the SAS system. The program tion to SAS data sets. This is done lines necessary for the INPUT, LABEL, FORMAT, and PROC FORMAT statements can using the labeling features available in the SAS data step. Longer labels can be be entered separately for each statement in the SAS data step. PROC FSEDIT with added for the dataset name and variable names when a permanent SAS dataset is the DATA=NEW option can be used to pre- created. Descriptive labels for the pare all but the PROC FORMAT statement. PROC FORMAT program lines can then be values of variables can also be created and permanently stored in format librar- entered and processed in a separate SAS ies. data step. Starting with Version 5 the SAS sys- Procedures for establishing the con- tem can be used to output SAS datasets nection between permanent SAS datasets containing the labeling information. It and format libraries have been described is then possible to merge other informa- elsewhere. Useful information is con- tion to the documentation SAS datasets, tained in the various manuals serving as operating system companions to SAS. and develop customized data dictionaries or other reports. Detailed instructions on the process were published as part of the Proceed- ings of SUGI 12. That paper was entitled In addition to customIzed reports on the documentation, ~t is possible to use ""A Codebook Template for the Creation the INDEX function ln SAS to search for and Use of Permanent SAS Datasets and common character strings within the val- Format Libraries (CMS* Application)"". ues of variables in the documentation What must be remembered is that two data sets. This can be the basis for steps are required. The perman",Sugi-13-266 Podgurski.txt
"case, the language is being defined, so the keyword LAN- GUAGE is nsed. Also in the DEFINE command is the A unique full-screen editor was developed for the name SAS, standing for the SAS System. The langnage is SAS® System in the VMS® operating environment. defined by qualifiers that begin with slashes. Special Digital Equipment Corporation created an editing pack- keywords follow the slashes. They define the follOwing age, the Langnage Sensitive Editor (LSE®), for their specifics for the langnage: V AX® computers nsing the VMS operating system. LSE was nsed to create templates that represent SAS syntax. File type of the file - /FILE_TYPE Also needed was the VAX Text Processing Utility Help library to search - /HELP_LIBRARY (fPU®). It was used to write procedures nsed to run SAS Letters to be used in names of placeholders - programs interactively. The LSE feature is an extra fea- /IDENTIFIER_CHARACTERS ture of VMS and mnst be licensed tonse it; however, VAX Initial string - /INITIAL_STRING TPU is available with any version of VMS 45 or greater. Optional placeholder notation - IOPT & IOPTL This paper will be concerned with describing how the SAS Required placeholder notation - iREQ & iREQL LSE editor was created. Pnnctuation characters - /PUNCTUATION Topic string for help library- /TOPIC_STRING",Sugi-13-267 Weaver.txt
"ract Other SUGI contributors have been voicing similar concerns for the continued use of structured analysis and Structured system analysis and design techniques have design techniques, at least back to 1982. Authors Bemis, Mopsik, Phillips, Puigino, Trimble, and others listed in the come to be commonly used in ""traditional"" data processing environments, with the goal of producing information systems bibliography have all offered important observations_ on many aspects of structured methodologies as applied to the SAS characterized by modularity, top-down structure, dear functionality, and maintainability. The increasing use of System. This paper primarily addresses just one problem area: the implementation of interactive, or menu-driven, ""fourth generation languages,"" with their reduced coding, simplified file management, and quick prototyping, has systems in a manner consistent with structured design principles. tempted some system designers to side~step these recently learned and proven techniques and implement systems ""on the The goals and long·term benefits of structured analysis fly."" For Shame. and design techniques can largely be summed up in terms of Structured analysis uses the Data Flow Diagram as a accuracy and completeness of function, as well as system maintainability and changeability. These are achieved tool to describe the logical ""what"" of an information system. Several past SUGr presenters have noted the direct though top·down design, which might also be ca",Sugi-13-268 Rinehart.txt
"TRICK 1: Many people have written systems interfacing SAS with ISPF. Most use ISPF to generate SAS code ~sed on user input, then invoke SAS to process the request, then have ISPF display the results. This process is usually repeated for each request. The first trick is a way to avoid invoking SAS for each request. SAS is invoked once It processes the first request, then waits for the next for the entire session. request. TRICK 2: Have you ever been in a SAS Display Manager session and wanted to swap back to your ISPF session? Most people exit SAS to return to ISPF, then invoke SAS again with the GO option. The second trick is a way to call ISPF from within SAS. You can call ISPF from within your SAS session, do what you want to do in ISPF, then exit ISPF to return to your SAS session.",Sugi-13-269 Whitaker.txt
"Data file A single SAS file that contains a self-documenting set of records This paper is divided into two parts. The first part or observations. The is an overview of the Multiple Engine Architecture documentation consists of (MEA). The MEA allows the SAS® System to variable descriptions and the process any file type as if it were a SAS data set. observations contain variable The MEA is described in terms of its inner values. A SAS data set can be workings, its advantages, and its end-user interface. The second part of this paper describes seen as a table in which the some advanced data base features of the portable observations are the rows and base SAS software I/O engine. It focuses on the the variables are the columns. index processor by explaining the architecture of an index, special features of the index processor, Index file A single SAS file that contains and how the engine uses indexes. record location information for SAS data sets. Record locations are based on the Not all of the features described in this paper are keyed available in all Version 6 releases. values of variable variables. PART I A single SAS file containing Catolog file multiple entries, each of which Multiple Engine Architecture has an entry name and an entry type.",Sugi-13-27 Beatrous Clifford.txt
"TOOLS AND TECHNIQUES TO FACILITATE END-USER COMPUTING IN AN OS/TSO/ISPF ENVIRONMENT Dan M. Hess, Utah Power & Light SllM""II\RY IMI'.L.EMENl'ATON An inventory of six tools designed to help Problem 1): Provide autanatic file allocation, users run SAS * 1.IDder lINS/OS, TSO and the SAS custan1zation of the SAS Display Manager Display Manager System are presented to session and a menu. individuals resp:msible for helping users invoke Solution: The l\!JTOEXEC function of the Display The tools SAS via CLISTs, ISPF panels, etc. Manager via the reserved Fileref SASE.XEX:. required to implement these techniques are: SAS Display Manager System, SAS macros, and TSO = Figure 1. shcMs id.SAS.DATA(SASEXEC) as it techniques require SAS/AF*. CLISTs. looks when copied to the user's standard files as pert of the setup procedure. With minor changes INl'ROIXX:TION this is the sarre list as the 'sarrt>le list of When version 5 of SAS, with the Display stored ccmnands' on page 479 of SAS User's Guide: Manager System, was released users -were given a Basics. Users are encouraged to custc::rnize the powerful set of tools with which to run SAS in an The last 3 lines file to fit individual needs. interactive self-contained environrrent. This make available a site library and invoke a menu paper details heM these tools are implemented at in that library. 'Ihis sarre sequence of ccmnands Utah P<:Y.-.er & Light Co. (i.e. TSO FREE, TSO ALLOCATE) is replicated by the user for any additional files he may wish to F'Rl\Mao,ORK The site library contains a catalog allocate. Certain standard data sets are created for for the menu system invoked by the last line of users who wish to access BAS (see Table 1). the AUI'OEXEC, a catalog for CBT courses made Users invoke SAS via a series of ISPP panels and available fran the menu, a catalog for the sample The individual's deta sets along with CLISTS. system provided with SAS/AF (also available fran certain 8ite data sets are allocated to the menu), the map",Sugi-13-270 Hess.txt
".THE INFORMATION CENTER INTERFACE (TICI) Robert C. Haering, Houston Lighting & Power Company Inc. The first menu displayed upon entry In 1982, Houston Lighting and Power into ISPF is the one shown below. Company Inc. (HL&P) did a feasibility TICI has been included as an option in study to evaluate the benefits that this menu, and can be selected by could be realized by establishing an typing in 'TICl' Information Center (IC). When the study was completed it was determined that the concept of an IC would benefit --------- PRIMARY OPTION MENU the corporation and a pilot project was started. When the pilot project was SELECT OPTION ===> tici completed, one of the primary end-user tools selected was SAS.- o ISPF PARMS DASD MGMT D BROWSE FILE-AID ~ F As the IC user base grew, training 2 EDIT PANVALET P demands grew also and it wasn't long 3 UTILITIES TUTORIAL T before the consultants in the Ie had 4 FOREGROUND IN INFO/MVS more work than they knew what to do 5 BATCH TICI IC INTERFACE with. Users were making demands for 6 COMMAND formal training classes, product 7 DIALOG TEST workshops, manuals and easier access to X EXIT the IC products. In an effort to address the needs, video and computer based training was offered to the user An ISPF table file is used to record community, and TICI was developed to information relating to each user. access the IC products. Upon entry into TICI, this table is checked to see if the current logon id TICI runs under an MVS/TSO environment is in the table, and if it is not the and is comprised of approximately 30 user is prompted for name, department CLIST programs and 60 ISPF Dialogue and other information that would be Manager panels. Through the use of required for submitting batch jobs, and menus, users can create, modify, copy, then added to the table. The TICI sort, and do inquiries into SAS primary option menu is then displayed. datasets. In addition to the SAS modules, users can, via menus, route printouts to various form types and",Sugi-13-271 Hoering.txt
"Miami (FL) ABSTRACT the SAS distribution tape provides a large number -of programs for each SAS The programs in the SAS Sample product, each complete with data. As Library were placed on a read-only such, it serves as a useful tool both system disk, together with usage notes, for those who are already familiar with the SAS system and who want to explore tutorials, and several locally developed sample programs. Sample programs, new procedures, and for those who are tutorials I and usage notes were stored learning the SAS system and who would as individual files. Starting at the benefit by seeing a variety of actual level of the CMS system HELP menu, users programs. Although it is not difficult are able to progress through a series of to place the programs on the system, the HELPTASK menus, through the various fact that such programs are available statistical packages available, down .to was not widely known at our site. Even the level of a specific sample program if the presence of such programs were known, it was felt that they would be or tutorial, or to the usage note file. Users are thus able to quickly and used infrequently if an extensive easily access the SAS sample programs, knowledge of operating system commands tutorials, or usage notes without or diSk/file configurations was needing an extensive knowledge of necessary to access them. We felt that operating system commands. Any sample by incorporating the sample programs, program can easily be copied to a write- usag",Sugi-13-272 LeBlanc Syren Garriga.txt
"systems. Version 5 of the SAS® System for minicomputers has limited sup- port of the macro facility. This paper demonstrates programming MACRO VARIABLES techniques that utilize the power of the DATA step. as well as the %INCLUDE statement, %lET statement and the macro functions Macro variables differ from DATA step variables in that they can SYMGET and CALL SYMPUT.ln particular, we demonstrate how be defined anywhere in a SAS program except after a CARDS several examples from the SAS Guide to Macro Processing, Ver- statement. The value of a macro variable remains constant until sion 5 Edition, can be adapted for use in the minicomputer envi- it is changed. A macro variable is defined by using a %LET state- ronments. ment or the SYMPUT routine. Once the macro variable is defined, you can use the value of the macro variable through a macro vari- able reference. The simplest type of macro variable reference",Sugi-13-273 Dineley Trott.txt
"UTILIZING SAS® SOFTWARE TO GENERATE COMMAND LANGUAGE PROGRAMS: - USING CA-TELLAGRAF® AS AN EXAMPLE Dorothy Hu Huang Hoechst-Roussel Pharmaceuticals Inc. c;.~ TElLAGRAfii code I. INTRODUCTION AND HISTORY OF DEVELOPMENT GRAPH IX is a user friendly graph generat- ,. ing program written in the SAS® macro 4. G ,MIH_25 ,MAX.50,STEP.S. , language. It allows users to produce high quality graphs without knowledge of CA-TELLAGRAF®, SAS®, or the SAS® macro 1,21.4 2.31.4 2,27.7 5.25.' 7.30.' 1,32.2 language. It has been developed at · 33.3 Hoechst-Roussel Pharmaceuticals Inc. to minimize the effort spent in producing standardized graphs. Prior to the intro- duction of GRAPHIX, many graphs were custom coded in the cumbersome CA- TELLAGRAF® command language, and data points were often entered by hand. With GRAPHIX, the coding of CA-TELLAGRAF® commands is eliminated and data points are directly obtained from SAS dataset. Graph generation has changed greatly at 'ROC MEANS; 8Y f'ROT TGRP VISIT; HRPI over the years. We have improved VA~ ATI~UO; OUTPUT our_MSET MEAH_MX; from coding CA-TELLAGRAF® for each graph and entering data points manually to writing a SASTAG program (a technique, developed at HRPI, of using SAS® to ',HlI'_I,MAX_S,STEP.I.' I CROSS 15 ENABLED _'/ ' generate CA-TELLAGRAf®'commands and input II ,MIH_25 .I'U\X~SIl.Sn:P~S. '/ · _' I data points), and to using GRAPHIX. -HR 1- ""OAY 2"" ""OIlY 4"" ""DAY I"" ""DAY '"",""/ ~~ i.u ............. u Presently, graphs can be generated by a u ····· o .... u u** .. .o *** ... u u o ..... ""uno .... u ***"". ···· INPUT CLIST, which drives DMS panels that ' ..................... Hu_""* ···· ** .... "" .... ** __ ............... u u....... : IF FIRST _TGRP ANO lGRP_l TtlEII 00; · collect information from end users, and which then makes subsequent macro call to GRAPHIX. "" I '[ND OF OAT.... ·; - ':·',,~:::""':,.ll'\ th~~=~~~~~}""' .**. : ""'0. fILE PRINTOUT r ····· a a aau ""**""""""""""."""""" ·· '- .. <A . . ""U"""""" ·· u**"" ·· u n ..... *"" OATil ~NULL~; INFlL",Sugi-13-274 Huang.txt
"MULTIXY - A User Friendly Front-End to Proc' GPLOT HALLETT GERMAN, GTE LABORATORIES THOMAS HIGGINS, MASSACHUSETTS RATE SETTING COMMISSION This paper will give an overview of MULTIXY - their results and not an ends! As a result, there an ISPF-driven system that generates SAS@ is a strong need for a user friendly front-end to code. The following topics are discussed: Proc GPLOT. 1. The user environment at GTE Laboratories A History of the Development of MULTIXY and why there was a need for MULTIXY. MULTIXY was originally developed in 1985 as a 2. A history of the development of MULTIXY. clist-driven program that used FORTRAN to generate the SAS code necessary to produce 3. An overview of MULTIXY and some ISPF the plot. By answering a series of questions techniques: (generated by Clist WRITE statements). users were able to quickly produce and re-produte · system capabilities SAS/GRAPH X-Y plots. It was a HUGE success. · ISPF review By 1987, users wanted more capabilities in · system design and a typical run of MULTIXY MULTIXY. The most popular sLiggestions were producing log and semi-log plots, placing a · starting MULTIXY border around plots, and adding footnotes, An · ISPF tips and tricks · generating SAS code. effort was also underway by the Computer Cen- ter to increase awareness and use of ISPF. Be- User reaction to MULTIXY and future capa- 4. cause of its capability to a) perform sophisti- bilities. cated input validation, b)retain values on a screen, and c)produce SAS code, MULTIXY was User Environment at GTE Laboratories selected as a test application for ISPF. GTE .Laboratories is a research branch of the It should also be noted that the authors were GTE company. It employs about 700 people to influenced by their experience in developing a conduct practical and theoretical research in major update to the system described by Hack- areas such as robotics, artificial intelligence, ett. As a result, this system took 7 man days to and superconductivity. Computers",Sugi-13-275 German Higgins.txt
"Efficiency Techniques for SASjAF® Software Applications Annette Harris, SAS Institute Inc., Cary, NC ""else Uf ';str{Uieldl).,=""stqYEARLY) and lIiStr(~fieldl1""""= There are several techniques that save you creation and execu- ""str{HONTHLY) ""then ""do; tion time with SAS/AF® software applications. %let .-dm.sg=Please enter a valid report value.; %let -CIerron=fie1dl; ""end; THE INCLUDE COMMAND ""end; '* ""else ""do' Else give error message.*1 Uet -dm~g""Yon are not authorized for this info. The type of terminal on which the application will be executed is Press the END key.; important in any full-screen application. In Version 5 SAS/AF soft- Uet field2""main.menn; ware, the terminal configuration is stored with the screen. This ""end; means that you must be careful that the terminal on which you ""end; do the development work has the same configuration as the ter- ""mend move; minal your users will be accessing. Should a problem arise, there '"" is a method of restoring the screens without manually having to flfield2 fe-create your entire application. In Version 5, one relatively quick »> Uield2 '* If field2 not blank, branch to screen specified.*/ means of screen retrieval is to write the screen to an external file. Then, edit a new entry in the catalog, and use the INCLUDE com- Note: both fields have associated macro variables specified that mand to bring the information from the external file. This enables are the same name as the user field. FIELD2 has protect and non- you to restore the display screen and SAS® code, but the attri- display attributes set. butes for the screen need to be respecified. Version 6 SAS/AF software addresses this problem by enabling you to modify the size of display windows. CUSTOM KEY SETTINGS Another technique to save execution time is to modify the keys FAST BRANCHING settings for the end user. In Version 5, reserved names are used to identify the keys for particular screens. For example, Systematically, the number of DISPLAY procedure statement",Sugi-13-276 Harris.txt
Growing worldwide competition has led manu- facturing managers to focus on quality and pro- ductivity improvements as key factors in reducing costs and increasing product quality. The Kohler Company's Cast Iron Division is uti- lIzing several SAS* software products to build an integrated manufacturing information system to support these improvement efforts. The Cast IlW1ELEII CASI IRON PIIODllCIS Iron Division has maintained control and end- PROCESS FLOII QIlRI user focus during construction of the system by adopting an incremental implementation strategy using engineering staff to write most of the code. ELECIIIIC IlELI This strategy along with the flexibility and integration of the various SAS products have af- forded this build-as-you-go approach. This ap- proach has contributed to acceptance of the new system and increased use of statistical process control techniques in managing the operation. Substantial cost reductions have resulted from the qualIty and productIvIty Improvement efforts durIng the past two years. CASI IHOIt I'OONIIRY,Sugi-13-277 Mackenzie Felten.txt
"be short on paint. The process was repeated, which gave them enough paint to finish the User training is a sensitive area for Information Center/IS Training person- job. Done at last, the workers stepped back to admire their work. It didn't nel. How do you train a new SAS user look quite even, but it was probably quickly, yet minimize the frustration often felt by an adult learner? Can you good enough. Certainly it was better motivate experienced SAS users to work than it was before wasn't it? Suddenly with new technology when the old code the sky darkened, and a torrential still functions? Is there a way to rainstorm broke out, washing the new introduce new coding methods without paint from the church walls. Agast, one challenging ""the way we've ALWAYS done of the volunteer painters looked up and cried ""Why, Lord?! 11 A voice boomed out it""? from the heavens:' ""REPAINT, AND THIN NO MORE!"" There is no single solution to the training dilemma, because each user Have you ever had the feeling that community has different needs. But, no matter what mix of CBT, VBT, classroom you've been ""thinned out ft too much? or one-on-one training is employed, a That because of a small training budget, tool can be developed to help both new an understaffed Information Center, or a and experienced SAS users. large user corrununity, you""'re not able to provide ""one-coat coverage""? At times I The proposed user training tool is a sure do. With some 600 SAS* software prototype SAS/M catalog. Not ap",Sugi-13-278 Allsing.txt
"STRACT facilities will be discussed later. SAS/AF and SAS/FSP provide the tools to PROGRAMMING UTILITIES MENU build interactive programming utilities. This paper describes two such utilities. tt~e One assists in management of permanent in-house SAS formats. The F Format Library other allows users to reposition U U"".ga Not .. "" variables in their SAS datasets. CN Compute .. Netwo .. k INTRODDC'J'ION The FSFORMAT facilities are accessed by selecting F. is our FSFORMAT utility to manage permanent in-house SAS formats. This DETAILS OF IMPLEMENTATION OF FSFORMAT utili ty uses SAS/FSP. SAS/AF. and PROC FMTLIB to allow creation and editing of The FSFORMAT facilities reside in a SAS formats. Format library management catalog called FORMAT. A PROC BUILD facilities can be used to list, print, invoked on this catalog would yield the or delete formats. New formats can also following: be created from SAS datasets. OIRECT~Y FOR CAT4LOG: S4SSVS.FORM4T COMM4NO "" ·· > SAS Version 5 introduced an interactive N4M£ TYPE DESCRIPTION UPDATED option for PROC DATASETS. While useful. PIUMARY MENU I 24UG67 this procedure CQuid not be used to BUILD PROGR"",M PROC BUILD ON FORM""'T C4T4LOG 12JUl61 EDIT PfWGRAM EDIT FORMAT 26JUL87 change the type or length of variables, FMTDAT4 PROGRAM CREATE FORMAT FROM S4S D4TASET 26JULB7 or change their positions. It also LlST PROGR ... M LIST ALL FORMATS OS4UG87 PRINT PROGR4M PRINT OR BROWSE A FORM4T OS4UG67 lacked the ability to add or delete CFOAMAT SCREEN SCREEN FOR",Sugi-13-279 Hutchison Wheatley.txt
"applications with a minimum of training and support. SAS/SOL-OS'"" software is a powerful new tool for end-user com- puting in the information center environment. A wide range of APPLICATION DEVELOPMENT USING SAS possibilities is now available to integrate SQl/OS data into exist- SOFTWARE ing SAS applications. The SAS/SOl-OS interface speeds new application development and enables you to take full advantage The new SAS/SOl-OS interface allows for the development of of the powerful report writing and graphics capabilities of SAS easily maintained applications that use the full capability of SAS software. This paper discusses the use of this new product, and software without the high cost and time delays associated with an example is presented. applications developed in a more traditional way. All of SAS soft- ware's reporting, graphic, and statistical capabilities can be inte-",Sugi-13-28 Schell Edds.txt
"The MARK and SMARK commands identify the text you want to manipulate. The STORE and CUT commands store marked text into a paste buffer (a temporary storage location). The STORE This paper concentrates on the expanded report writing capabili- command copies the marked text but leaves the original text ties available with Version 6.03 of SAS/FSp® software. Each intact and unmarks it. The CUT command deletes the marked text SASjFSP procedure is discussed separately and in combination, from the window and copies it into the paste buffer. Use the with emphasis on ways to enhance report writing with the new PASTE command to insert or paste the text in the text buffer int.o available features. A discussion of the cut and paste facility and the current window. the SAS text editor (available with Base SAS® software) and how they complement the features available within the SAS/FSP pro- cedures is included. Also discussed are the SAS/FSP global com- Where Can You Use the CUT and PASTE Commands? mands (for example. SPRINT, FORM NAME, and PRTFILE) that You can mark and store information from all display manager win- are useful in generating reports. A discussion of effective use of dows and from all SAS/FSP and SAS/AF® windows. You can also FORMS and ways to use your SASUSER.PROFILE catalog is use the CUT and PASTE commands in all SAS text editor win- included. dows that allow editing. What is the Difference_Between the MARK and SMARK",Sugi-13-280 Berryman.txt
SAS were created by making a copy of the produc- tion version of the files. To execute SAS online a The development of an efficient and productive copy of the production CLIST was made and the file way of providing easy access to compressed files names changed to reflect the test file names. A test using a fourth generation language has always been procedure library was created to handle the batch in the forefront at Pizza Hut Inc. Most of our finan- test procedure for SAS with the appropriate name cial system files are quite large and are also com- changes. Due to system conside.rations an addi- pressed making access impossible by languages such tionalline of code was added to the batch execution as SAS. The vendor for the financial systems at JCL to point to this test procedure library instead of Pizza Hut is McCormack and Dodge. This paper the production which is the system default. addresses the Payroll Master and Personnel Master files of the Payroll System. Subroutine Requirements The assembler subroutine P AYRECMP reqUired the,Sugi-13-281 Ambler.txt
"SAS/GRAPH® Software Competition First Place Best Presentation of Data - Color Linda W. Blazek and Douglas M. Scott Alcoa Laboratories Response surface analysis is an effective way to model much of the data generated by Alcoa laboratory trials. However, interpreting the results of the analysis can be difficult for engineers and scientists not familiar with statistical techniques. Graphical displays of the analysis can often help the interpretation by demonstrating the shape of the response variable with changes in the independent variables. The two types of plots which display the response surface information are the three dimensional plot and the contour plot. The three dimensional plot is most effective in presenting the general shape of the surface; however, determining the exact quantitative relationships between the response and independent variables is virtually impossible using the three dimensional plots. Contour plots furnish the quantitative information directly; yet, unless the viewer has excellent visual perception, the overall shape of the surface is difficult to perceive just from the contour plots. We have found that the best way to present both the quantitative and qualitative information about the response surface is to display both the three dimensional plot and the contour plot simultaneously. In the application displayed in our figure, containers were made from three different materials varying two operating parameters, ""RATIO"" and ""SETTING"". The containers were then graded on an ordinal scale from 1 (best) _to 4 (worst) judging the quality of each base and sidewall. PRoe RSREG was used to generate response surfaces for both base and sidewall grades by material as a function of RATIO and SETTING, and PRoe G3D and PRoe CONTOUR were used to create the respective graphs. ANNOTATE was used to create the legends for the three dimensional and contour plots as well as label the axes ·for the three dimensional plots. (There is no statement in G3D to enla",Sugi-13-282 Blazek Scott.txt
"SAS/GRAPH® Software Competition First Place Best Presentation of Data - Monochromatic John G. Blodgett - University of Missouri St. Louis This choropleth map presents the distribution of housing units constructed in St. Louis City from 1980 to 1985. The map's annotation includes 1980 census tract labels, city label, county outline, and major streets. The Urban Information Center disseminates data for the St. Louis Metropolitan Area and the nation with a concentration on census data and data from focal governments. In response to this challenge we have developed a number of macros to aid in the presentation of demographic data using the SAS/GRAPH GMAP procedure. The generation of annotation for this map is made possible by the use of three macros developed at the Urban Information Center: ANNOGEN, GENLABS and GOUTLINE. The ANNOGEN macro, used here to produce the major street line segments, street labels and city label, converts annotation data stored in varying length sequential format to SAS/GRAPH annotate datasets. Storing annotation in the form of annotate datasets can be expensive in terms of storage because the SAS dataset must contain all variables relevant to any observation in the entire dataset. In addition it is often easier (particularly for student assistants) to work with sequential data. ANNOGEN parameters include: textin(input), annoset (output dataset), x & y factors, offsets and limits, default values for standard annotate variables as they apply to text or lines, and a ""userexit macrotl for subsetting or final modification of the data. The GENLABS macro creates annotate observations for plotting P9lygon labels, in this case tract, at the centroids of polygons. The label here is the census tract label. Other options would be to plot the value being mapped, or the label and the value. The outline for the City of St. Louis is created by the GOUTLINE macro which inputs a GMAP dataset and converts it to a series of draws for the boundary of each polygon",Sugi-13-283 Blodgett.txt
"SAS/GRAPH® Software Competition First Place Most Creative Use of the Software - Color Mark O'Brien - RMS Technologies, Inc. Stephen Shepard - Health Care Financing Administration The Health Care Financing Administration (HCFA) Data Center was required to provide schematic representations of the various existing and proposed communications networks for planning purposes. A survey of available in-house graphics software resulted in the decision to use a PC product named Diagram Master from Ashton Tate for its ease of use in creating schematics and for its pre-defined symbols. As schematic development progressed, the need to produce graphics in a variety of sizes for presentations and publication arose. No appropriate devices were available for the pc. The Data Center's more versatile graphics devices are driven from the IBM mainframe. But the available mainframe graphics software does not provide the ease of drawing schematics that Diagram Master does. Steve decided he could produce a viable translation from the ASCII data stored by Diagram Master on the PC into executable SAS code on the mainframe. On-Line Business Systems' Excellink is used to upload the Diagram Kaster file to the mainframe. on-Line Business Systems' WYLBUR, Release 8.0, execute processors perform process management functions and conversion of all internal data parameters and elementary functions to equivalent SAS statements. (WYLBUR was chosen because Steve is a wizard at using it.) SAS annotate macros (%ROVE, %DRAW, %RECT, %LABEL) are used to reproduce moat Diagram Kaster functions. Originally %SLICE was used to reproduce arcs and circles but proved ineffective when radius and centroid were outside the plotting area even though they were not to be plotted. SAS Technical Support suggested plotting arcs using multiple straight line draws. This is implemented using an in-house developed SAS macro named %ARC. The conversion software does not include all Diagram Kaster capability due to the lack of SA",Sugi-13-284 OBrien Shepard.txt
"SAS/GRAPH® Software Competition First Place Most Creative Use of the Software - Monochromatic Kernon M. Gibes - The NutraSweet Company The attached graph was generated using SAS/GRAPH running on a VAX/VMS computer system. PROC GLSIDE was executed using the ANNOTA1E option to direct the creation of the plot from an annotate data set. The data set was created in a data step using as input the mean attribute values for each sweetener as well as the p-values for the test of no difference between sweeteners for each attribute as generated in a PROC GLM step. The graphics output was printed on a DEC LN03 laser printer using a VMS PRINT command. The purpose of the plot is to be able to compare two sweeteners with respect to their (multivariate) attributes as perceived by a group of trained sensory evaluation judges. This type of plot, often called a ""spider plot"" because of its web-like appearance, is in common use for the graphical display of sensory profIle information. Although the SAS/GRAPH procedure GCHARf has a STAR plotting feature, it plots multiple classes (in this case, sweeteners) as separate ""stars"" instead of overlaying the classes on the same star. It is much easier to see the differences between the sweeteners when they are overlaid on the same set of axis rays. An additional feature of the ""spider"" plot as implemented using ANNOTA1E, is that the origin (zero mean) is a polygon with a fIXed, non-zero radius rather than a single point. When a sweetener does not have a given attribute present in its profIle a Single-point origin can tend to make it very 4ard to see what is happening with the ""web"" of the sweetener. Because spider plots are used frequently for displaying this type of profile data, the determination of the required axis ray length scaled to fit the data, the implementation of a varying number of attributes and sweeteners, and the capture of the p-values from the GLM hYpothesis tests were automated into a single SAS job. 1500  Attribute Means o",Sugi-13-285 Gibes.txt
"INl'ERFl\CIN:; 5OIy'I:S Il1\TABASES AND T!!E>S1IS ® SYSTEM: FRlC 5 0 = Paul M. Roesti l\m:XX> Pet:J:oleum 1Id:!itives caJpany Abstract. FRlC SQIElIT is a procedure in SlIS® Institute's 50L is 5OI,IL'S' s data manip.llation extracted. = new SlIS/SQL-IE"" pra:Iuct. '!be procedure nay be language; is the camman:i that retrieves used to create a SlIS dataset ~ data data from a table. extracted fi:an 1m's V1VSP relational database, '!he basic format of SEI.ECI' is: 5OIy'I:S' · = SQIlL'S naintains data as tables of rows and oolname1, 00lname2\* oolumns. SlIS datasets are also logically kept in tablenamel, tablename2 FRCM search con:lition; this fashia> with ciJservations analagous to WHERE SQIy'I:S rows and SlIS variables to SQIlL'S oolUllU1S. list of oolUllUl names An asterisk instead of a retrieves all oolUllUlS. If no WHERE seardl similarities and differences between the SQIlL'S oordition is specified, all rows are extracted. data manip.llatian l~, SQL, and SlIS data step statements are presented. When extractirq illustrate, consider these exanples. '!he data fi:an several 5OIy'I:S tables, there is To S= contents of t:r..:J tables fran JE.!'s STl\Rl'ElIDB djso1ssian of whether or not to use a COIlPlex SQL = database have been replicated in Figures 1 and 2. statement or a sinpler 50L follCJNed by SlIS data step transfonnations. SQlDBA.SUPPLIERS is a table of parts suppliers ani SQIDBA.~ONS gives price, delivet.y t:bre, '!be paper diso'sses use of FRlC 5 0 = in rns and on order quantities for parts available from noninteractive m:xle. SlIS programs that nul in SUl'Pliers · this m:xle require 00 intervention fi:an terminal users. Teclmiques for prepar:in;l SlIS program To create a pennanent SlIS dataset SlISL'SN.SUPPIERS = from the SQIlL'S table 5OIDBA. SUPPLIERS, where all statements to invoke FRlC fi:an SQIElIT ro.rt:ines are presented. oolUllUlS and rows would be extracted, FRlC 5 0 = would be coded as: Exanples are given us:in;l t:r..:J tables provided with FRlC SQIEl",Sugi-13-29 Roesti.txt
"SAS/ACCESS- to IDMS/R- Belinda T. Weinbrecht, SAS Institute Inc., Cary, NC The SAS/ACCESS- to 10MS/R- software products enable SAS· In the OUTPUT SAS DATA SET field. enter the name of the SAS users to access and modify their IDMSjR data by using the SAS data set where you want the extracted data to be stored. If no System under the MVS operating system. SAS data set is entered, the default data set, WORK-DATAn, is used. IDMS/R is Cullinet Software, Inc:s data base management sys- tem that runs under MVS, VSE, and VM/CMS operating systems. In the SAVE SELECTIONS field, specify either that you want the IOMSjR provides both network and relational capabilities in a sin- procedure to extract the data or that you want to create a data gle system. set that contains the necessary information to do the extraction. The latter choice causes a mapping data set to be created. The Each IOMS data base consists of data records that are grouped mapping data set contains information that is used to map or into similar record types. Record types are linked together assign the selected elements to a SAS data set. If an N, the through different logical groups called sets. Using the record default, is entered. no mapping data set is created, and the proce- types and sets, the DBA defines logical records and logical- dure extracts the data. If a Y is entered, the mapping data set is record paths in the subschema. Logical records are concatena- created; and no data are extracted. This mapping data set is tions of the elements of one or more record types. Logical-record defined in the OUTPUT SAS DATA SET field. This feature is use- paths contain the necessary data base manipulation commands ful when the lDMS logical record or ASF table is large or when to access the data in the logical records. Then, the Logical the same element extraction process is performed frequently. Record Facility (LRFj is used to access the logical records. You can create the mapping data set, save it in a SAS data",Sugi-13-30 Weinbrecht.txt
"A DATAEASETM TO SAS(R) INTERFACE Frank E. Harrell Jr. Lawrence H. Muhlbaier Duke University Medical Center, Durham, N.C. writer. Introduction SAS has many recognized capabilities for statistical analysis, data manipulation, and graphics. However, In DataEase, the data entry screen and the data file are actually one and the same. The file is designed many projects require data management and data entry through the use of ""screen painting"" with a built-in full functions that SAS does not provide. For example, SAS/FSP(R) (Full Screen Product) meets many data entry screen text editor which has such features as cut-and- and retrieval needs, but its lack of indexing and table paste and insertion of fields from other forms. Field lookup facilities limits the number of problems that it can names, attributes, edit checking, derivation formulas, handle. Also, Since SASjFSP data entry screens are not table lookups, and security are defined by positioning the intimately tied to the database structure (i.e., forms design cursor where the field is to appear on the data entry through ""screen painting"" is performed after the variable screen, pressing a function key, and answering a series of attributes are defined), it is frequently cumbersome to im- questions. ""Nice"" multiple-page data entry screens and plement or to revise data entry screens involving many complex data files containing many fields may be defined quickly. variables. In addition, the lack of some commonly needed data DataEase provides for the following data types: text, types places restrictions on SAS data entry and data man- 1-, 2- and 4-byte integer, 4- and 8-byte floating point, agement capabilities. A common data type is the mUltiple fixed point, formatted numeric string, date, time, yes/no, choice or classification variable (e.g., one having values and choice. Missing values are allowed for each data I=good, 2=better, 3=best). Such variables are typically type. Choice variables are handled in a particularly",Sugi-13-31 Harrell Muhlbaier.txt
"These keys are 0 based, and no key specification means use the primary key. Alternate keys can have values from 1 to 254. The A user-written external file interface (UFI) replaces the standard driver finds them by looking for the # symbol. SAS I/O routines with another set of routines. These routines may allow a functionality not inherent to the SAS System. The inter- Example face communicates with the SAS System through a data struc- ture called the EXTIO communications vector. The ISAM driver A sample SAS job using the ISAM interface file follows. provided by SAS Institute is an excellent example of a simple external file interface. I' The data file must exist because the interface does not provide access to any file creation routines. A sample FDL file is",Sugi-13-32 Hester.txt
"ford, NY 12188 ABSTRACT A qual ity control chart system has been sampling and analyzing reaction samples and developed at General Electri~ - Silicone recording the data to an on 1 ine database. Products Business Division using SAS/QC®. The quality control manager enters the upper This system has saved the Business thousands and lower control limit and mean target for of dollars by displaying out-of-spec trends the application product associated with the during the manufacturing process. reaction samples. These data are recorded to Additionally, the system provides a the qual ity control database. These data competitive weapon when marketing GE - constitute the specifications by which the Silicone products. The control chart system quality of the product is measured. The consists of three phases: technicians fill in an on line screen with the quality control test data. For instance 1. Result entry the process variables being analyzed and 2. Control chart creation recorded might be specific gravity, density 3. Control chart display and the application rate of the product. These data are in turn stored to a An overview of each phase and a demonstration relational quality control database. This Future enhancements will wi 11 be presented. analysis and reporting phase typically takes also be dis·cussed. anywhere from twenty to thirty minutes to complete. I NTRODUCTI ON General Electric - Silicone Products Business [!J.---------------------: Division embarked on the task to develop",Sugi-13-33 Reish Leet.txt
"FORECASTING THE ECXJN<:I1Y USING THE CXl1RlSITE LEADING INDEX. ITS <::CMroNENTS. AND A RATIONAL EXPECTATIONS ALTERNATIVE Lung-ho Lin, The University of Akron Steven C. Myers r The Uni verst ty of Akron The purpose of this paper is to evaluate the I. The Benchmark Model usefulness of the composite index of leading indicators and that of its component series and In order to illustrate the forecasting to propose a new approach to compile a more potential of the composite leading index with the reliable and versatile leading index. The new series we construct a individual component approach is called the rational expectations using monthly transfer function-noise model approach. The procedure used for this paper is observations the composite leading index as the primarily the ARIMA for time series analysis as input and the index of industrial production as the output. The mathematical model is written1 : developed by Box and Jenkins. We have made extensive use of the SAS/E'l'Si product and much of = c+inp.(B)/out,(B)X'_b+ma.(B)/ar.(B)e. S~ software including the macro the base (1) Y. language. is the original output data or a where Yt There are basically two approaches in the difference of the original data time series analysis for forecasts: the is the original input data or a X. univariate and the multivariate time domain difference of the original data models. The multivariate time domain models use is independent disturbance or random transfer function-noise models to predict a error term variable by relating the variable to other indexes time t variables in a casual framework. The univariate is the backshift operator B approach instead bases the prediction of a is the delay parameter b variable solely on the past behavior of that is the constant term c variable only. This paper concentrates on the is the noise model moving-average rna. (B) multivariate approach in which a leading index is factor 1-ma1B- ·.. -maq BQ used for economic forecasting. is the noise model",Sugi-13-34 Lin Myers.txt
"Forecasting as a Tool for Decision Making Joel Fingennan Roosevelt University Introduction Some Illustrative Numbers For illustration, let us imagine that the manufacturer's Forecasting with the SAS 1 system can be very effective needed raw material is plastic and that the current price for this and efficient. There are a variety of forecasting models available particular plastic ~ 82 cents ~ pound. And that the inventory for the forecast analyst. Ultimately though, forecasting is a tool, carrying charge is ~ cent per pound per month. C~nsequently, if not an end, for decision making. Thus, it is the plan of this the manufacture were to purchase now the cost IS 83 = 82 + 1 paper to show how SAS forecasts may be integrated into a per pound for use in two months: The manufacturer requires decision making framework. 20,000 pounds of this plastic so has budgetted $16,600 to be able to purchase the plastic immediately if necessary. Thus, for the manufacturer, if the future price 2f the Why Forecast? plastic i§ greater than -83 cents ~ .QQ..!!.lli! then the plastic should A key to successful business operations, planning and be purchased now and stored for later use. If the future price 2f strategy is the use of business foreeasts. Since business planning the plastic equal 12. QI less than 83 cents !!IT. pound, then, the and strategy entail decisions or actions at the present time which manufacturer will purchase the plastic later. Figure 1 illustrates will have consequences in the future, useful forecasts about futUre the data on price as a time series over the last three years. uncertain events are essential. Business forecasts are thus an Using an ARIMA model for forecasting, we produce a important source of information for management. price forecast for the next 12 months. Figure 2 illustrates the The need for business forecasting is found in all areas forecast and the upper and lower confidence intervals of the and at all levels of business. Often it is the sales for",Sugi-13-35 Fingerman.txt
"NONLINEAR SIMULTANEOUS EQUATIONS MODELS A. Ronald Gallant, University of Chicago an applied level. The reader who was not Methods of estimation and inference for present at the talk, or who was and wishes to nonlinear,. simultaneous equations models were discussed at an applied level. These are review some of the details, is referred to the above listed sections of Nonlinear multivariate models which cannot be written with the dependent variables equal to a Statistical Models. vector-valued function of the explanatory The talk went as follows. The basic variables plus an additive error either notation was introduced and the point that it because it is impossible or unnatural to do is possible to analyze only a subset of the SO; in short, the model is expressed i-o an equations from the system was stressed. An implicit form e = q(y,x,9) where e and yare electricity pricing example was used as a vector valued. cross-sectional example. The example was taken from Sections 5.1 and 6.1 of Nonlinear There are two basic sets of statistical Statistical Models where the data is given as methods customarily employed with these well. The notion of instrumental variables models, those based on a method of moments was introduced, the moment equations defining approach with instrumental variables used to the estimator were set forth, and the form the moment equations and those based on estimator was derived by analogy with a maximum likelihood approach with some univariate nonlinear least squares methods. specific distribution specified for e. The SAS code illustrating the computations'was talk was restricted to a discussion of the method of moments approach, called two- or displayed; this code is given as Figure 1, Section 6.2, of the reference. An asset three-stage least squares in cross-sectional pricing example was used as an example of a settings and generalized method of moments in dynamic system. The example was taken from dynamic settings, because it is by far the Section",Sugi-13-36 Gallant.txt
"incurs capital costs. In addition, reducing the number Abstract of DC's generally lowers the cost to replenish the As part of its strategic planning process, DC's from the plants but increases the cost as well as transit time to ship to the pools. Warner-Lambert regularly reviews its domestic Because of the many tradeoffs and lack of distribution network. The objective is to determine experience with the matrix generator, Warner- the optimum number, location and size of its Lambert attacked the problem in two phases: distribution centers which receive almost one 1. A simplified version treating Warner-Lambert as million orders from approximately forty thousand one line of business with nine alternative DC customers. To fUrther complicate the problem, locations each at its existing or suitable size. Warner-Lambert is comprised of three business 2. A final version wi th three lines of business and groups with different service requirements. In the spring of 1987, Warner-Lambert formulated the different size options for the DC's. The considerations and results of these two phases problem as a mixed integer program with several afe described below. hundred equations and almost two thousand variables. The difficulty was how to solve the problem in a short period of time. Modeli!!! Approach: Single Line of Business Model SAS-OR* and the matrix generator developed by Marc-david Cohen l and SAS/OR* were the answer. Within a three-month period, Warner-Lambert with Initially the simpl",Sugi-13-37 Gangoli Jenkins.txt
"to problems mvolvmg the f""mdmg of afixed point of a function (correspondence). A fixed An algorithm to solve problems m Applied pomt of function f (x) is a pomt x * such that General Equilibrium Analysis and Operations f(x*) = x*. The central equilibrium existence Research is described. Typical problems m these theorems are based on statements about the areas are descibed along with an explanation of existence of fixed points. One generally reduces how the software can be used to solve them. The the GE problem to one where equilibria exist if pwpose. in making these routines available from and ouly if there is a f""IXed pomt for the within SAS@ is for ease of use and wider transfonned problem. Computationally, the accessibility. concern is with the problem of finding these fixed pomts. Details, with fully solved examples from Economics. are provided later in this paper. The basic theorems on the existence of 1.",Sugi-13-38 Prasad.txt
"THE TVA WATERBORNE COMMERCE ECONOMIC SIMULATION MODEL: OVERVIEW AND APPLICATION Larry G. Bray, Tennessee Valley Authority Reba L. Copeland, University of Tennessee INTRODUCTION THEORETICAL FRAMEWORK The Tennessee River Waterway System consists of 650 miles The economic environment in which inland waterborne com- of main channel and ,approximately 150 miles of tributary and merce operates dictates that demand factors, as well as resource secondary channels. The waterway is formed by a series of main constraints, determine the tonnage levels that move at any point in river locks and dams and two tributary dams, one of which has time. Thus, the general form ofthemodel weestimateisas follows: a lock and the other utilizes a canal. All but one of these facilities Commodity Terminations = f (Demand factors, Resource were initially constructed by the Tennessee Valley Authority Constraints). (TVA), which has primary federal responsibility for navigation on the Tennessee River and Tributaries, as charged by an act of In the Mississippi River System Model, Howe et aL identify related economic activity and transportation cost as important Congress on May 18, 1933. TVA operates the reservoir system with navigation as one of the primary objectives in a multipurpose considerations in a river traffic model. Specified in this form, the system that includes hydroelectric power generation and flood model is incorporating the general form of a derived demand or control. The U.S. Army Corp of Engineers (USACE) operates the input demand function. locks as it does on the other inland waterways. Such a function was laid out and tested for labor demand by Since the dams and locks were initially constructed over 40 years Adams, Brooking, and Glickman (1975) in their study of the ago, however, changing technologies and increased demands on Mississippi economy: the waterway have produced a new environment. Larger locks have + + 0'2lnQ + 0'3 (W/P), In L = 0'0 O'lt been added on the lower rang",Sugi-13-39 Bray Copeland.txt
"PR<X:ESSING AND ANALYSIS OF SUPERMARRET SCANNER DATA Charles F. Hofacker, Florida State University multiplying units by price. We could then use PROC FREQ, say, with dollar volume treated as a Why Scanner Data are Valuable to Marketing WEIGHT variable. The TABLE statement would specify brand as the variable to be analyzed. Scanner data are beginning to have a large To ·look at unit share instead of dollar share, impact on the marketing of frequently purchased we need only use units as the WEIGHT variable. packaged goods. There are at least four good reasons that this is so. First, scanner data Scanner Data for Marketing Strategy are timely. The lag between the time of purchase and the time that information is in the Due to the objectivity of the data, scanner marketer's hands is shorter than ~ith previous records are quite valuable for strategic marketing data. reasons. The numbers represent actual sales in the market, so naturally they can be quite Second, scanner data are objective, and not revealing about the nature of each brand, and subject to many of the types of errors the nature of the competition between brands. associated with surveys or panels. Consumer's The mathematical tool we use to reveal the memories are notoriously fallible when it comes nature of the brands and their competitive to- reconstructing previous purchasing structure is called a market response model. A activity. In addition, there are powerful further summary of competitive effects can be demands of prestige seeking and politeness which achieved by using multidimensional scaling to are placed on the consumer when we ask him or produce a competitive map, often refered to as a her what she has been doing or what he thinks of product space. The rest of this paper will be our products. In contrast, when the trade concerned with building a sales response model collects scanner data, they do not ask anybody and deriving a competititive map. anything. They simply record behavior. Market Share",Sugi-13-40 Hofacker.txt
"COMMEiT ON Proc~ssing and lnalysis of Supermarket Scanner Data Yilliam M. Stanish. SAS Institute Inc. The previous paper requires some clarification about the use of the The following statements fit the simple-effects model. The design CATMOn procedure to fit the given market-share models. It should matrix was copied directly from the PROC PRINT output, except be pointed out that there is no R:::;; option on the MODEL statement that a comma in the last row was changed to a right parenthesIs. in CATMOD. The author is apparently referring to the feature in Maximum-likelihood analysis can be obtained easily by specifying which the design matrix can be specified directly by the user. This the I..'fL and NOGLS options on the MODEL statement. feature allows CATMOD to fit a much wider class of models than it proc catmod data=complete; could otherwise fit. The design matrix may be large, but it is easily ~eight units; population week; generated by a IO-line data step. This, combined with 1 PROe model brand ( PRINT statement, and 4 CATMOn statements, enables the user to o o 0.9 fit the simple-effects model, the differential-effects model, and other o o -0.3 types of conditionallogit models with very little effort. +------------------------------------------+ SOME LINES NOT SHOWN TO SAVE SPACE As an example of how to fit these models with CATMOD, consider +------------------------------------------+ the following hypothetical data containing prices and sales for 4 dif- o o -0.3 ferent brands for 6 weeks. 1 o o 0.4 data prices; input lieek price1-price4; cards; (1 2 3 'Intercept', 4 'Price sensitivity'); 1 2.2 1.0 La 1.3 2 2.1 1.0 La 1.3 3 2.2 1.1 1.5 1.2 4 2.2 1.0 1.5 1.3 The output includes a goodness-or-fit test, parameter estimates, and 5 2.0 0.8 1.6 1.3 6 2.0 0.·9 1.6 1.2 the corresponding test statistics. The goodness-of-fit test indicates data sales; input week brand units @@; cardsi that the simple-effects model does not fit these data. 1 3 3a 1 2 77 1 1 37 1 4 66 Fit",Sugi-13-41 Stanish.txt
"USING SAS/OR* PROJECT MANAGEMENT TO PLAN AND MANAGE A MAJOR ELECTRIC GENERATION FACILITY OUTAGE Wayne Maruska. Basin Electric Power Cooperative I NTRODUCTI ON The project management procedures in the SAS/OR* In October 19B6, as part of a conversion of its modules provide the capability to plan and man- data processing systems to IBM, version 5.08 of age projects of varying complexity and size. SAS was installed. In July 1987, the system was With the addition of the SAS/AF* product. this upgraded to version 5.16. The cooperative has capability can be simplified for the user Basic SAS*, SAS/FSP*, SAS/AF*, SAS/OR* and SAS/GRAPH*. Two people are responsible for sup- through the creation of a menu-driven project management application. This paper will de- porting the SAS* software; one full-time and one part-time. scribe one user's experience with this kind of application. OVERVIEW OF SAS/OR* PROJECT MANAGEMENT PROTOTYPE BUSINESS BACKGROUND Included in the installation of SAS* was a menu- driven SAS/OR* prototype that SAS Institute de- Basin Electric Power Cooperative ;s a member- veloped. This prototype provides SAS/AF* menus owned electrical power generation and trans- and programs for each SAS/OR* procedure, includ- mission supplier. It serves an area of more than 400,000 square miles in portions of ing project management. The SAS/OR* project management prototype provides the ability to Colorado, Iowa, Minnesota, Montana, Nebraska, North Dakota, South Dakota and Wyoming. The Co- schedule multiple-activity projects within a specified period of time. With SAS/AF* menus operative provides wholesale electricity for 120 rural electric systems which serve more than and fill-in screens the planner identifies the 440,000 meter installations representing about name of each activity, its unique i~entifier, the duration of the activity in days and the 1.2 million consumers. Basin Electric owns and start date of the project. With this informa- operates electrical generating plan",Sugi-13-42 Maruska.txt
"STRACT Predicting engine failures is a two-step process. First, the parameters must be Ball bearings, aircraft engines and missile estimated. Then the estimates are used to predict subsequent failures. We shall begin guidance systems have one thing in common: they are all subject to unexpected mechanical with a brief discussion of the theory behind failure. Practically every industry is Weibull analysis. Next, we shall describe a concerned with increased cost~ and loss of step-by-step procedure for estimating the productivity and customer satisfaction Weibull parameters. Then we shall consider associated with equipment failure. Although the unique circumstances surrounding breakdowns are inevitable, it is possible to predicting engine failures and some typical predict when a failure is likely to occur problems that might arise during an using statistical techniques.' analysis. We shall conclude with a description of how the analysis might be used This paper will investigate a method for to forecast engine failures. estimating failure parameters and how to use these parameters to predict equipment BACKGROUND failure. In particular, it will examine Weibull analysis, a statistical technique of Although there are a variety of techniques wide applicability. Using this technique in for analyzing failure data, three conjunction with historical data, we can requirements are common to each: an predict failures more accurately and minimize unambiguously defined time origin, a scale the",Sugi-13-43 Kay Price.txt
"APPLICATION OF THE ANALYSIS OF MEANS Peter R. Nelson, Rensselaer Polytechnic Institute A common problem in industrial statistics is time, and this was exactly the motivation for Ott, who that of comparing k treatments in order to identify any was interested in being able to plot the sample means that are different. For example, one might be for each treatment together with a pair of decision lines. . interested in comparing four different television tube coatings in order to ascertain if there were any In order to compare the ANOM with procedures differences in their conductivities. The analysis of that are more familiar_ to most people, and to motivate means (ANOM) is a graphical procedure for making the ANOM procedure itself, consider a simple example this kind of comparison. I will start with a brief with only two treatments and equal sample sizes. The history of the ANOM, followed by a discussion of its problem is to compare the percent yield of ethisterone relationship to Shewhart-type control charts, the two when it is made from ethyl alcohol with the percent sample t test, and the analysis of variance (ANOV A). yield when it is made from t-amyl alcohol. Eight In the process I will look at examples of the ANOM experimental trials were run (four with each alcohol) applied to some simple balanced experimental designs. and the results are given in Table 1. Finally, I will discuss some more recent results associated with the ANOM. Specifically, I will consider the power of the ANOM and the ANOM applied to more complicated experimental designs Table 1 - Percent Yields of Ethisterone Made from where both interactions and unequal sample sizes may Two Different Alcohols exist. The ANOM can be thought of as an alternative Ethyl t-Amyl to the ANOVA in the fixed effects situation. The first 85.0 91.8 application of the ANOM was due to Laplace (1827) 86.0 91.7 and predates the ANOVA by almost 100 years. 87.8 92.3 Laplace was interested in studying the homogeneity 82.8 94",Sugi-13-44 Nelson.txt
"This paper will look at a single This paper introduces the user to thickness of 0.0083 inches and the min- the basic code needed to utilize SAS/QC imal code required by SAS/QC and SAS/GRAPH and SAS/GRAPH to generate histograms and to generate charts and statistical anal-:."" bar charts to analyze product character- ysis and some of the conclusions that can istics and process capabilities. The min- imal code provides the novice user a be dervi""d. better understanding of product and pro- OBJECTIVES ceSses involved in their manufacturing. With the many thousands of possible The code is simple and provides. the basis for more complex- and sophisticated prog- ways processes can be monitored in a man- ramming and statistical analysis. It is ufacturing enviroment, certain factors the intent of this paper to -demonstrate must be considered as primary indicators. First the items must be considered that with simple code and data the potential the consumer of these pr~ducts consider wealth of information SAS/QC and SAS/GRAPH as major quality factors. In the steel software can provide. industry one consideration is gauge or thickness and the ability to consistently",Sugi-13-45 McHenry.txt
"is often two- ABSTllCT fold: (1) to make an accept/reject decision and The quality of a product could depend on (2) to sort the acceptable material into shade several characteristics. In such cases, multi- differences according to previously established variate statistical techniques cah be used for specifications. improvement of quality. This paper uses multi- Our objective is to develop numerical color- variate statistical techniques to establish difference tolerance regions to determine if a numerical color tolerances in plants which manu- color sample is acceptable, as compared with a facture colored products. Often the colored standard. The overall goal is to improve the quality of color matches. product is a component subject to assembly mating with other objects of the same color The -esta.blishment of such tolerance regions manufactured at other locations. Currently, consists of two parts: (1) the preparation of color matches between a sample and a standard color samples which form a basis for the color are made by visual inspection. The availability tolerances and (2) the actual construction of the color tolerance regions. of color-measuring instruments such as colori- meters or spectrophotometers which produce 2. PROCEDURE multivariate color-difference readings from standard could assist in providing better color matches. Discriminant analysis is used to 2.1 Sample Preparation evaluate the consistency of instrumental readings with visual observation and to For each",Sugi-13-46 Vance.txt
"SUBGROUPING AND SUBSETTING BEFORE INVOKING THE SHEWHART PROCEDURE Mark A. Sobos! ai Wheel ing-Pittsburgh Steel Corporation the SAS/QC procedu res gives the qua Ii ty I. BACKGROUND AND INTRODUCTION eng ineer the abJ I i ty to customize data input and output to his exact needs. Whi Ie SAS* software was 1 icensed at Wheel- we at WPSC appreciated this power, it ing-Pittsburgh Steel Corp.(WPSC) primar- quickly became apparent that we needed ily for quality control work. The major to enhance our programming ski 115. focus of this was to be Statistical Process Control (SPC) implementation. The reasons Two programming tasks usually requir- for chasing Base SAS* and SAS/Qt. soft- ed when building an SPC application with ware were several, and were la.rge1y dic- SAS/QC are subgrouping the observations and tated by our partiei lar situation in 1986. subsetting the database. There are sever- al subroutines I have found useful in th is A wide network of remote terminals o regard. There is nothing unique in them. and printers already existed which The important point is that they have were tied to our corporate mainframe worked and helped better uti Ize an already At the time, there were computer. good tool, SAS/QC software. very few personal computers in these locations. As the title of this paper indicates, the examples and explanations discussed A significant database was stored o herein refer particularly to use of the on tape and/or disk at the computer Shewhart procedure. This is where we have This included such things center. concentrated our efforts. Moreover, our as order specifications, rejection operations generally require use of vari- and claims data, and production ables data. However, I b.el ieve that the records. programming concepts can be extended to use with other Proc's within the SAS/QC Our plants are vertically integrated. o reperto! re and also to attributes data. Each of our finishing plants gets 100% of its semi-finished steel from II. SUBGROUPING other",Sugi-13-47 Soboslai.txt
"Regional SAS User Groups - the NESUG Experience HAlLETI GERMAN, GTE LABORATORIES Introduction on local SAS user groups and- SAS resources (training, consultants, vendors), and vendor de- SUGI 12 provided much insight into the opera- mos. tion and future of SAS User Groups. Castell dis- cussed her analysis of 15 nationwide SAS This is where the regional user group can com- groups. She examined meetings (techniques, plement the local user group activities. By hav- topics, and formats), starting a user group, and ing the group manned by people not involved reasons for forming a user group. Shipp talked with running local user: group events -- many abOut corporate and area users groups and the regionatljoint activities that were considered lack of-a liaison' between the local user groups too time-consuming before become possible: and the SAS Institute. Finally, German reviewed a model for established SAS Users Groups 1. Members from various user groups have (that is groups existing a year or more). He many other occasions to interact with each mentioned meeting and organization tech- besides just once a year at SUG!' niques, user group mission and relations with external groups. A major point of his talk was 2. A ""'regional identity'"" results through inter- the potential productive relationship between action with other user groups and publish- the SAS Institute and user groups. To the Insti- ing local user group activities. tute. user groups are a potential marketing tool and information resource. To user groups, 3. Increased knowledge of what other user communications with the SAS Institute allow groups are doing through 1} publication of a them to serve as a lobbying force. It was from regional resource guide, 2) publication of this environment that the idea of a regional the best of local group papers, and a re- ~,users group was born to serve Northeast local gional user group newsletter. SAS. user groups. 4. A means is provided to bring SUGI-quality This paper wil",Sugi-13-48 German.txt
"tape and are scanned for zap type and zap availability. Zaps are then collected and ZLMS is a system developed at SAS Institute written to the appropriate files. When monthly Inc. to collect, verify, maintain, and processing is complete, the zaps are also made re-distribute ""zaps"" from a multitude of available to be included on new product sources. The purpose of ZLMS is to assure the installation tapes. quality of zaps, to enhance the information regarding zaps, and to improve the process of SAS® software maintenance. Zaps can be distributed in two other ways--verbally or in printed form. These forms work best if zaps are kept short. Short zaps have a better chance for clear verbal",Sugi-13-49 Ward.txt
"he first time you teach them, you develop the course in Many experienced users are faced with the challenge small units or topics, and you can update topics easily when necessary. of developing a course to train others. Although experi- enced with the software, these users may be bewil- dered by a course development project. This paper There are five course development steps. Each of describes a structured approach to course develop- these five steps has a distinct purpose and a desired outcome. ment, an approach similar to structured programming familiar to most programmers. 1. Investigate needs and resources. Collect Following a course design method,ology helps ensure enough data about the trainees' needs so that you that the training accomplishes desired outcomes. can plan the course goals and objectives. Then Courses written without a development strategy may (or write a student profile and the global course objective. may,not) provide the desired training. These courses are frustrating to develop ~ and frustrating to attend. 2. Analyze tasks to be learned. Develop skills The techniques described here can be applied to the yardsticks and use them to conduct an analysis of development of any training: a one-hour lesson or a the tasks to be included in the course. Identity three-day course, training to use a software package or subtasks within each task to produce a task list. improve writing skil1s, or training developed in different formats such as instructor-led or video",Sugi-13-50 Ussery.txt
"screen images from SAS and non-SAS products must often be included in course materials. Another requirement is the ability to include graphics images from SAS/GRAPH software and This paper focuses on the development of course materials at SAS Institute and describes other mainframe or PC products. the features of the Education Division's Course Composition System, a system developed at the Historical Perspective Institute for the production and maintenance of course materials. The discussion centers on system capabilities that allow SAS programs, Historically, the production of course materials output, screen images, and graphics to be at the Institute was a two-stage process and included in text, and how these features are demanded tremendous time commitment from the provided using IBM's lSPF product, base SAS®, staff of both the Education and Publications SAS/OMI®, and SAS/GRAPH® software. The Divisions. The first stage was a preliminary structure of the system is discussed, along with text produced by the Education Division in book benefits of its use from a time and cost form, but not typeset. The second stage was perspective. Although the primary use of the an optional typesetting stage, involving the Course Composition System at the Institute is in Publications Division. the development of course materials the system I could be equally useful for preparation of professional papers, presentations, or any type In the preliminary stage, SAS sessions were of technical materials. initially simulated in the text using a text editor, with the screen border added by simulation or by paste-up. Eventually, the",Sugi-13-51 Wagoner.txt
"A ""Flow Chart"" for Users to Solve SAS® Programming Problems Joy Reel. SAS Institute Inc., Cary NC There are many places to find examples INTRODUCTION of a particular technique or the use of some of the SAS software programming statements. The two most popular places One of the most frustrating things about are the SAS Sample Library and the SAS computer programming is dealing with Application Guide Series. The sample messages or results that are unexpected. library contains on ""INDEX"" member which Perhaps the messages seem to be generates a keyword listing of the ambigious or out of place. Perhaps the samples included. Application guides output is just not right. Presented here have indexes in the back of each book to are some tips and guidelines to help guide you. eliminate some of the frustrations when using SAS® software. It is almost impossible to work with data that you do not understand. In Much time and effort can be saved if a order to describe the dat·a to the SAS reasonable amount of energy and System in an INPUT statement, yOll should concentration is expended before look at them carefully. If you cannot actually beginning a project. As in look at your data with an editor~ you IIw hen all else fails. read the can use the SAS System as illustrated directions"" so it goes in programming. below: The SAS System offers extreme power to all those who need calculations, DATA _NULL; statistics, graphics, and so on without INFILE fHeref; requiring a great deal of background in INPUT; computer science or data processing. In PUT _INFILE_; fact, people of any background can learn to use the SAS System effectively in a The SAS System will dump the input very short period of time. buffer to the SAS log for you. Then you will see exactly how the raw data look and can writ.e your INPUT statement BEFORE YOU START accordingly. Always make sure that data created for In order to solve any problem, you must testing includes as many cases as have the facts to start. This is al",Sugi-13-52 Reel.txt
"HOSTING A MINI SUGI AT YOUR SITE Loretta Golby I Alberta Government Telephones John Chenier, Alberta Goverrunent Telephones cal data, processing it in some manner, and producing a printed report. OUr Information Centre has a large number of users who range in experience from the novice to the advanced user. It is a very considerable task to support, train, and keep informed this variety of users. 1. To refresh and enhance users I knowledge of the many SAS* procedures, since it After attending SUG! 12, we decided that a was noted that some of our users had USER DAY approach would allow us to inform our SAS* user community of current and new not had any training for over 6 years. facilities in SAS* as well as pass on in- 2. To pass on information gained at SUG! formation gained at SUGI 12. 12 to all of our users in the quickest and most efficient method possible. describe how we created ""SAS USER We will DAYS at Am"" by putting together a ffiJ.1l1 show procedures that exist in the 3. TO SUGI. The benefits and some of the problems SAS* system, user application systems, we encountered will be presented. and sample programs to other SAS* us- ers. With the variety of users-and the variety INl'ROoocrroN of- backgrounds, we felt that we had to come up with some method that would suit all needs. At Alberta Goverrunent Telephones (AGl'), we support approximately 500 users across the province of Alberta. our SAS* users can be classified into two groups. The first ALTERNATIVES group, which comprises 30% of all the SAS* users, are those people who use SAS* to ac- cess their awn data or data generated from other applications, and to analyze and 1. The first alternative we looked at was produce reports comprised of text or graph- offering a course. The major drawback ics. This group is distinguished by the of this was the amount of time required to develop a course and the limited fact that one individual looks after all aspects :_ of the application, is quite know- number of topi",Sugi-13-53 Golby Chenier.txt
"AN INS'I.'RIlIIENl FOR EVALUATIR> TIlE QUllLITY OF TIlE STATISTICAL CCNSULTIID EXPERIENCE David A. Ludwig, UNC at Greensboro Judith M. Penny, ONe at Greensboro James A. Penny, UNC' at Greenslx>ro The Consultant Evaluation Section consists Intr<Xluction of 25 bipolar items on five subscales (five items per subscale). Items for this section were Most of the literature concerned with selected by a three-stage process. First, a pool statistical consulting focuses on the of 60 items were devised from a variety of interpersonal aspects of the client-consultant sources including graduate students, faculty and relationship or the mechanics of operating a staff, and researchers within the univerSity. statistical consulting service. Evaluation of These 60 items were reduced to 40, partially the quality of the consulting service has been a based on redundancy, readability, etc. The 40 neglected issue. A paper and pencil evaluation items were then placed into subscale categories instrument has been developed at the University by a panel of 6 statisticians and three graduate of North Carolina at Greensboro's Statistical students. A random sample of 30 people were then Consul ting Center. The instrument evaluates asked individually to sort the items into the three major areas of the consulting experience: subscales (Q sort). Items that did not sort with at least 70% accuracy were dropped. The final I. Educational Worth/Need, inventory has five subscales with five items per Admdnistration, and II. subscale. III. Consultant Evaluation. Demographic information is also surveyed. The ~nistration and the Worth/Need Along with basic infocmation as to the client's section contains 18 statements (nine positive and department, rank, etc. two questions attempt to nine negative) in which the client responds to a assess the client's level of statistical Likert scale anchored on each end by strongly expertise and computing ability. Appendix A agree and strongly disagree. contains the complete",Sugi-13-54 Ludwig Penny Penny.txt
"SAS® AND THE UNIVERSITIES Rudolf J. Freund, Texas A&M University 1. BACKGROUND 2. THE PAST This symbiotic relationship was a natural For many years SAS Institute and the outgrowth of a number of favorable factors: Universities have enjoyed a symbiotic relation- ship. Faculty and graduate students at A. A truly remarkable software product Universities have found the SAS System to be an for data handling, statistical excellent research tool. In addition, the analysis and report writing. The SAS simplicity of the SAS language has enabled the System was and still is a flexible use of the system as a valuable aid for the and easy to use tool for data teaching of statistics. Not only does this management coupled with a compre- provide students with a better understanding of hensive line of statistical analysiS a subject which is often erroneously perceived procedures. as an exercise in plugging numbers into formulas, B. A reasonably complete, compact and but it also increases the pool of students who will fondly remember the SAS System as a low priced Users' Guide. As is the (relatively) painless way to use computers. case for much software documen- tation, it was primarily a reference SAS Institute has benefitted from this work and required some additional relationship in that a very large number of introductory instruction. However, students have taken their knowledge and considering the price, it was not an appreciation of the SAS System into the work- unreasonable reference work for place where they have been instrumental in student use. promoting the v/ide use of this system in C. Excellent lines of conununication industry and academia. Also we must not forget between the users and the software that SAS Institute owes its very existence to developers at the SAS Institute. the farsightedness of a number of Land s~a11 Grant university statisticians who were instru- 3. CURRENT STATUS mental in providing the funding required to As the world changes, so has this re1atio~",Sugi-13-55 Freund.txt
"ULIE WILDMAN - PEPE, M.S. DEPARTMENT OF STATISTICS UNIVERSITY OF CENTRAL FLORIDA ORLANDO, FLORIDA COURSE GOALS Abstract Two goals are given to the students at the In this paper we present our experience in beginning of the semester. The first goal is to teaching statistical packages including SAS to undergraduates at the University of Central enable the students to use statistical packages to solve the types of statistical analyses they Florida. The goals of the course are teaching the students to perform statistical analyses learned in the two-semester introductory using statistical packages and teaching the course. The second goal is to enable the students to interpret the output they obtain students to interpret the output from the packages to perform an appropriate statistical correctly. Students are primarily majors in analysis. This includes the ability to statistics and in computer science and have recognize when the output is in error and what usually had at least two previous courses in the problem might be. statistics. We discuss the topics covered in our course and discuss some of the feedback The two groups of students view these goals received from the studen""ts. differently. Both statistics and computer science majors are quite happy to meet the first of these objectives. The second goal, however, The Department of Statistics at the is not embraced as quickly by the computer Universi-ty of Central Florida (UeF) teaches a science majors. By the end of the semeste",Sugi-13-56 Kraemer Kheoh Wildman.txt
"reasons why toolboxes are advantageous. Toolboxes are often used by data processing groups in the develop- Many of them are the same reasons why the SAS System itself is so ment of computer systems. The concept of a toolbox is straight- popular and widely used. Among the more prominent reasons are: forward; generalized tools (e.g., software modules) are developed · they minimize theamountofapplicationspecificcode that needs and packaged so that they may be easily used by an entire team or to be written; staff of people. PROC PRINT isan excellent example. SAS program- mers do not have to write PUT and FILE statements each time they · if a common function needs to be perfonned ina variety of places, want to display a report of data; SAS Institute has developed a tool the use of one toolbox routine increases the reliability of the (PROC PRINT) and put it in a toolbox (the procedure library) application; available toaH SAS users. Macro tools presented at this and previous SUGIs provide other examples. · the availability of easy to use tools can lead to the development of more robust, reliable and effective systems; Unfortunately, toolboxes have traditionally been used only for · they increase the productivity and, through time, theexpertiseof generic routines which can be taken ""off the shelf"" and used as is toolbox users; and <e.g., the SAS procedure library and user developed libraries of procedures and Macros). Toolboxes have a much broader applica- · their use increases the p",Sugi-13-57 Henderson.txt
"ery little programming Historical research often involves the collection .. when using the SAS® System. editing, manipulation .. and analysis of varied types of data. My dissertation research design SAS@ System data sets are was a complicated process that involved easy to build, save, merge, the collection, manipulation, and analysis of subset, and maintain, and I varied bits and pieces of information from many felt the sorting routines in differing types of archival, census, newspaper, the SAS® System were easier aggregated report, business record, and other than some of the routines in historical sources. This design called for other software pack ages. a software package that provided tools that could be used to accomplish all these tasks The major purpose of the dissertation was to efficiently, easily, as well as inexpensively. examine and understand the dynamics of the The SAS® System fulfilled all these interethnic contact that occurred in New Mexico at requirements for me. Through the use of the the time of the immigration of the Anglos, and DATA STEP, I was abte to build many different concurrently, the immigration of the Mexicans from types of permanent SAse System Mexico. The primary interest was in determining data sets which could then be SORTed. the relative influence of the demographic and MERGEd, FSEDITed. to produce final data sets economic changes that occurred as a result of the that fit my custom requirements. differing immigrations and settlement patterns.",Sugi-13-60 Turpen.txt
"TRACKING INFORMATION CENTER ACTIVITY Theresa J. Hart, The Upjohn Company Janet S. Thieme, The Upjohn Company Bela Lahner, The Upjohn Company Information centers have taken a variety of Inforwetlon Center IlMI\ faces since their creation by IBM in 1976, but Help LIne C411 for- services common to most information centers include help-line assistance~ training for end users, and responsibility for a variety of Oate of Call: Tlme of Call: Receher: special projects. The Upjohn Company, based in Phone: _ _ __ Who called: _ _ _ _ _ _ _ _ __ Kalamazoo, Michigan, has a number of information centers, each serving a particular -user group, leU (if !tall: _ Syst@lll code: Application code: _ _ often based on division or physical location. Each information center varies in the services Request/Problem: _ _ _ _ _ _ _ _ _ _ _ _ _ _ __ offered. The Information Center in the Division of Medical Affairs (DMA) offers a mix of the three services common to most information centers. Because of the variety of services provided, First helper: 04te helll started: _ __ tracking activity in the DMA Information Center is a formidable task. From the inception of the Time help started: Tlme spent (in "",inutes): _ _ OMA Information Center four years ago, tracking activity has been viewed as a necessary task, Action: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ __ however, in order to provide key people with the information needed to correct problems and, realistically, to justify the existence of the center. This paper will describe the services provided by the DMA Information Center and how the SAS® System is used to track activity in Second helper!-__ Date help started: _ __ those areas. Time help started: _ _ _ Time spent (In mln1Jtes): _ _ Help-Line Assistance If the llroblelll!request WIl$ not resolved IIIIIIed1ately after help was started Common to most information centers is some by the first or second helper. fill in date and time of ~solutlon below. central focal point where end users can come for",Sugi-13-61 Hart Thieme Lahner.txt
"d programnlng style cannot be under- USE r-EANINGFUl VARIABlE NArES. rated. Unfortunately. progranmers have a strong tendency to do SQ. We all I ike to believe that once a piece of code is A name can carry an enormous amount of information (and put together. however haphazardly, the code wi II work properly from the point it is put into production until for- misinformation). Therefore. names should be as meaningful ever after. Besides, why waste cleaning up the code if it as possible. For instance, the following statements ~ute is only going to be used once'? Writing code cleanly the scales tax and sales price of an item and calculate the first time not only increases the chance of getting it right amount of change given, if any. buT also eases the task of fixing it in case it is not S = -T ... P; right. Furthennore. chances are likely that the program wi II be used more than onoe and it wi II probabl V be used by C = P + S; someone other than the author of the code. So in the CH=A-C; interest of those writing code and those having to use code Without any type of identifying information these statements that has already been written. some elements of good pro- gr-anming style wi II be discussed. are meaningless. The variable namas have no significance and so the intent of the code is not clear. In general, mixtures of similar characters, such as the letter 0 and the I NTROOUCT ION digit 0 or the letter I and the digit I, are unsafe. Long identifiers that differ only at the en",Sugi-13-62 Caron.txt
"A STATISTICAL ANALYSIS OF THE ZIP + 4 DATABASE Peter Weiss, Arthur D. Little, Inc. INTRODUCTION relationships within the data, (3) to identify certain ""worst-case"" conditions, and (4) to The Arthur D. Little, Inc. Technology itemize all the occurrences or formats of Resource Center _(TRC), section of the a several parameters. Cambridge, Massachusetts consulting firm, is under contract to the Technology Resource of the frequency The determination Department (TRD) of the u.s. Postal Service distributions for postal data would help in (USPS) to examine new technologies and help understanding how addresses and add~ons (the 4- introduce them into postal operations. One of digit code appended to the 5-digit ZIP- Code) the areas of research in postal automation were assigned and used within the database. The includes a study of the national ZIP + 4 distributions would also reveal the likely database. operating modes for the mail. A significant nonuni:formity or skew in a frequency The USPs maintains a ZIP + 4 database which distribution would allow the use of a variable- contains the 9-digit ZIP + 4 Code for every length code, such as a Huffman code, to deliverable address in the nation and is represent the data and thus provide compression. approximately 3.1 gigabytes in size, with over 24 million records containing street, post Substantial data compression can be office box, rural route number, general obtained if a mathematical relationship can be delivery, postmaster, firm, and high-rise derived from the data. A simple example of this address information. The database, which is principle is using a polynomial equation to maintained at the USPS San Mateo, California represent a curve. It takes much less space to postal Data Center (Poe), is used internally by store the coefficients of a polynomial than to many organizations within the Postal Service and itemize all the discrete points on a curve. The is also used as the basis for many ZIP + 4 second objective in the st",Sugi-13-63 Weiss.txt
"Version 6 SASjAF® Software Enhancements for CBT John Boling, SAS Institute Inc., Cary, NC Susan Strozier, SAS Institute Inc., Cary, NC question, you can provide a hint following the first incorrect INTRODUCTION answer, then branch them to remedial instruction following the second incorrect answer. The enhancements to Version 6 of SAS/AF® software add flexibil- ity and power to computer-based training (Can applications. ?2 WRONG=cbt.fun.no1.cbt Enhancements to SAS!AF software for CBT courses include the powerful new Screen Control Language (SeL), extended ques- You can design a multiple-choice question with multiple correct tioning features, a multilevel, menu-linking facility, and the ability answers. If a student chooses at least one correct answer, he to vary screen size and color. New features that help in the devel- receives the message 'Your answer is partially correct'. opment of a course include new printing options, additional course maintenance utilities, a user-friendly command menu, and Another new CST feature is the MUSIC= option. A tune is played the ability to test part of the course while in the interactive BUILD either when a frame first displays or as a result of a student's procedure. This paper describes and illustrates some of the new answer choice. Specify the tune by listing each note and its dura- features that enhance both the development and the display of tion in the MUSIC= option. a CBT course. The SAVE command allows students to exit a course and the _ SAS System in the middle of a lesson and automatically return CBT ENTRIES to the place they left off when they relnvoke the course. Some of the new features available for CBT type entries are MENU ENTRIES · fill-in-the-blank questions With the multilevel, menu-link facility, several menus can be · the WRONG= option, which allows for branching linked, thus increasing the number of selections available to stu- dents from a primary menu. A student experienced with the struc- · multiple correc",Sugi-13-64 Boling Strozier.txt
"A MACRO FOR All SEASONS Robert P. Beeman, Three Mile Island Nuclear Station The purpose of this brief overview is to with knowledge which no one else had. provide the commercial applications Expertise Is where you find it, and many a programmer/analyst with both a general manager drafts a motivated amateur to write approach. and also a startup coded framework, local systems when the corporation's mainframe for producing interactive stand-alone data administrators are too slow, or simply assembly and retrieval systems to meet uninterested. virtually any normal business need. While this may seem to some like a fairly ambitious Most of these small and forthright undertaking In a presentation of this short systems exhibit three general phases. We can length, there is a real point to be made here group all the efforts to enter the system and concerning the versatility which this SAS add or change data as THE IN. We might system allows. 1 usefully combine the emission of reports and direct screen summaries under the general To try to step around several tempting, heading of THE OUT. And the effort to make but for our purposes unprofitable sidelines of something of the data which has been inquiry, our discussion will exclude the assembled, which usually goes on In background low-probability fringes of system design which driven by the source coded itself, we can demand highly specialized methods of data generalize as THE CRUNCH. extraction or rigorous statistical interpolation. If we split our basic system into these three segments, and consider each of them as a We will instead focus on the broad self-contained subsection of the entire central band of applications programming which development process, then it is possible not analysts such as we rely upon to respond to only to address contiguous and complimentary everyday business problems. actions in one, but also to endow our resulting code with the advantage of deriving SAS has features enough to address the from a tr",Sugi-13-65 Beeman.txt
"THE INFLUENCE OF ECONOMIC VARIABLES ON SEMINARY PARTICIPATION: A SAS/ETS® APPLICATION Archie J. Calise, City University of New York (Queensborough) Joseph Earley, Loyola Marymount University THEORETICAL MODEL INTRODUCTION The initial ordinary least squares regression The purpose of this paper is to present the model used for estimating Catholic seminary results of an econometric and time series participation is investigation concerning the relationship between economic variables and the partici- MODEL 1 THE FIRST-ORDER pation of individuals in Catholic seminary activity. The reason for investigating this + time series is that an abrupt and continuing drop in the number of Catholic seminarians in the United States started in 1965. This trend is a time trend variable obviously has important ramifications for both where : YEAR members of the Catholic faith as well as for starting in 1912 is a dummy variable 0 Pre-Vatican II society in general. See the diagram below. V 1 Post-Vatican II A multiple regression model is developed with VYEAR is V times Year used to capture the regressors selected to control for other than interaction between V and the time trend economic variables. In-sample forecasts are calculated in order to assess how well the GNP is the percentage change from model predicts. For this purpose the MAPE preceding period of gross national (-mean absolute percentage forecast error) is product in constant dollars 1912-1987 W 0 used as a measure of model prediction accuracy. is a dummy variable Non-War Pwo time series approaches were used for ex- War 1 ante forecasting purposes. The first approach, REG is a dummy variable 1 Recession o Non-recession referred to as the Jack-Knife, uses a time- trend, .dummy variable and an interaction term. u the disturbance term with the usual A complementary time series approach, PRoe econometric properties ARlMA, is also used in order to extend the forecast horizon into the future. The statis- A second model developed as a",Sugi-13-66 Calise Earley.txt
"TEST SCORING AND ITEM ANALYSIS USING SAS' SOFTWARE Patrice Gregory, University of Medicine & Dentistry of New Jersey Ronald Cody, University of Medicine & Dentistry of New Jersey A turn-key system was developed to the users interactively provide facilitate the scoring of multiple information that is stored in files choice examinations using SAS* software with FILE and PUT statements and for the microcomputer and an optical recalled later with the %INCLUDE statement. For example, users supply mark sense reader4 The system performs data entry, corrects, scores and the name of the ASCII file that is analyzes the results of test data in stored in the variable called ""FN"" and standard multiple choice format. the number of test items that is stored The first step in the process, in the variable ""ITEM"" through a window. initiated by a single command, is the The following code illustrates the first automatic data entry provided by the technique used to read the ASCII file: optical mark sense reader. The exams must be marked in pencil on special forms containing a nine digit LIBNAME TEST 'A:\'; identification number, a single digit FILE 'TESTCODE'; test version number, and up to 200 test PUT 'DATA TEST.'FN';'; items. Using software supplied with the PUT 'ARRAY QUEST""j $ Ql-Q' ITEM ' ; ' ; optical reader, an ASCII file is created 'INFILE ""C:\SCAN\'FN'.TXT'· PUT by passing the answer key and test LRECL=211 MISSOVER;'; papers through the scanning device. The next step automatically invokes Note that each time the file ""TESTCODE"" written, the ""FN"" and ""ITEM"" is the SAS software. The WINDOW, DISPLAY, and SELECT commands generate the variables are replaced by the user- following main menu: supplied values. These lines of code are then incorporated later in the program with a %INCLUDE statement. EXAM SCORING MAIN MENU 1. Correct Errors in the Raw As shown below 1 the second technique uses display manager commands to permit Data. the values of variables to change each 2. Score and",Sugi-13-67 Gregory Cody.txt
"USING SAS/GRAPH* SOFTWARE TO INTEGRATE AND ANALYZE ENVIRONMENTAL SPATIAL DATA J.J. Wind. American Management Systems, Inc. R.W. Matheny. U.S. Environmental Protection Agency ** of the National Acid PreCipitation Assessment Introduction Program. Our goal here was to identify the impacts of various Sulfur Oxide emission In this paper, we describe three recent scenarios on Critical Receptor Areas across the projects at the U.S. Environmental Protection Eastern Seaboard. Agency (EPA) using innovative spatial analysis capabilities of SAS/GRAPH software. For each As a basis -for Sulfur Oxide emissions and project. we describe the SAS/GRAPH geographic deposition, we obtained two data sets developed analytic capabilities we developed. In addition. by EPA's Atmospheric Sciences Research Laboratory we share insights about some of the roadblocks we (ASRL) using the Regional Lagrangian Model of Air encountered along the way. Pollution (RELMAP). The first data file The three applications involve: consisted of Sulfur Oxide emissions recorded as I-degree by I-degree concentrations for 216 · Projecting sulfate deposition across the tlsquare degrees"" across the Eastern Seaboard. Eastern Seaboard. based on Sulfur Oxide The second file contained estimated Sulfate deposition from each square-degree (source) to emissions each square-degree (receptor). for four seasons. · Overlaying underground storage tank and groundwater vulnerability data Our first challenge was to compute a weighted-average transfer factor, to enable us to ai~pol1ut;on project the impacts of emission scenarios by · Assessing cancer risk from in a major metropolitan area. state for the years 1990-2010. We computed these coefficients by overlaying state boundaries on This past decade. EPA data managers have the source grids and assigning a predominant invested significantly to provide a central state to each source. A problem we encountered archive of environmental data accessible to a here was to determine within whi",Sugi-13-68 Wind Matheny.txt
"diagonal 1 ine indicates a decrease from the baseline value. The identification number of The adage, II a picture is worth a thousand the patient who has the abnonnal value is words"" is especi ally true when graphically printed beside the point so that reviewers displaying clinical safety data such as vital can associate this abnonnal value with other 5 igns, 1aboratory assays, and reGs. assays ~ concomitant therapy, and medi ca 1 Si nee clinical abnormalities generally depend on events of the same patient. The ID is to be printed at the right hand s ide of the normal ranges and/or the magnitudes of changes from baseline values, a data plot corresponding point if possible. When there which is able to clearly reveal these kinds it is is no space at the right hand side, printed either at the left hand side, above of information and also label the ""abnormal patients"" by their identification numbers is the point, below the point, or searching very helpful to medical reviewers. This cant i nues all the way down unt i1 a space is paper presents a SAS macro which performs found. this task on an x-v plot using the X-axis for baseline values and the V-axis for follow-up Patients with only a baseline value are not va1'les~ This macro autor:1atically extracts included in the plot because baseline values the necessary infannation from the input data alone do not provide information on drug set to produce the desired graphs. It also effect. . But patients with only a follow-up handles points with missing baseline values value are included in the plot because without excluding these points or distorting abnormal follow-up may be drug related and the graphs. . should be presented. They are plotted along a dashed vertical line appearing on the right hand side of the graph.",Sugi-13-69 Lai Schneider.txt
"DISPLAYING FOREST RESEARCH DATA WITH SAS/GRAPH® SOFTWARE, PROC GPLOT, PROC GMAP, and PROC G3D David C. Chojnacky, lntennountain Re-search Station Caroline K. Wraith, Intermountain Research Station Mark E. Rubey, Intermountain Research Station ABSTRACT: Graphic data display is an integral JUNIPER part of research at the Intermountain Research Station's Forest Survey Project of the Forest 10 ·"" · Alligator Service, U.S. Department of Agriculture. o Utah Graphics are used to explore data relationships · * Rocky Mtn. and to produce customized graphs and maps of . · o. V research results. Applications of SAS/GRAPH · t procedures GPLOT, GMAP, and G3D have been used 0 ° to study tree growth relationships, map forest L t..: t. resources, and display response surface models. U5 o ·· ."". .. This paper discusses GPLOT, GMAP, and G3D as ·· · M well as several graphics enhancements, the · 8"" "" ' ANNOTATE feature, NOTE statement, AXIS E statement, and LEGEND statement. Also - fj,_1k =M mentioned are experiences running SAS/GRAPH Open · Solid = S software on a Data General MV8000 minicomputer *.a,t"" °* and plotting results on Hewlett-Packard HP7475 0 and HP7550 pen plotters. Examples are given of 5 0 3 graphs with oversized labels suitable for camera-ready slide production. SIZE I NTRODUCTI ON Figure I--Four data dimensions on a two-dimension graph. In addition to Graphic data display is an integral part of tree volume and size, symbol shape research at the Intermountain Station's Forest indicates species and symbol fill Survey Project, Forest Service, U.S. Department indicates multiple (M) or single (S) of Agriculture. Graphics are used to examine stem characteristics. data relationships and to produce customized Data display and axis labeling (with an AXIS gra~hs of research results. Because we rely on statement) as in figure 1 is relatively fast SAS System for computing most statistical analyses and data reductions, SAS/GRAPH is a and simple. However, customizing the legend wi",Sugi-13-70 Chojnacky Wraith Rubey.txt
"Using SAlVGRAPH® Softwore with the Mi.... -Th-Hoat Link Roger Chenoweth. SAS Institute Inc.. Cary N.C. SAS MICRO-TO-HOST LINK INIRODUCTION The SAS Micro-to-Host Link. first introduced with The introduction of Version 6 SAS/GRAPH® Software for Version 6.01, allows a PC SAS session to communicate the personal computer broadens the possibilities for with an active host SAS session. With this facility you This paper discusses new Micro-la-Host Link. users. can submit SAS statements from the PC program editor Version 6 features that allow you to submit SAS!GRAPH screen directly to a host SAS session. The output and log statements from a PC SAS GIl session to a host computer produced by this remote submission is displayed on your SAS session. The graphics output is produced on your PC PC in the output and log windows. For those not familiar screen or on an attached graphics device. This capability with the SAS Micro-to-Host Link. the following is a brief can be used to access large host databases from the PC, discussion of six important components: the script me, the conserve host resources. provide access to graphics devices signon. remote submit, and signoff commands, and the available only to your PC, incorporate host graphics into UPLOAD and DOWNLOAD procedures. text tiles on the PC, and to download graphics catalogs. First is the script rile. This is a me of SAS-like Other Micro-to-Host Link graphics applications are statements, on the PC, that invoke the SAS System on presented that don't use this new feature. These your host computer and establish the link across applications use the link to collect data from many sources asynchronous or synchronous lines. The script statements for graphics display on the PC or to access host graphics are powerful enough to do everything necessary to devices to produce pictures developed on the PC. establish conununication between your PC and host computer, including dialing the host from your modem, logging on to your host, ~d in",Sugi-13-71 Chenoweth.txt
"re in The Production Department of Exxon USA has moved geologic work for Prudhoe Bay and other early towards the use of SAS software for solving projects, we have begun a 10 work-year project geologic problems. Geologists' tools are highly to enhance our SAS procedures for geologic graphic in nature and the high volume of data applications. We estimate that our production department geologists will eventually use SAS involved for these specialized displays make the for 90% of their computer analyses. use of standard SASjGRAPH® procedures inappro- priate. To help resolve this problem, SAS Institute has developed an experimental library of GKS-compatible graphics subroutines that The Need: Graphics Subroutines interface with SASjGRAPH. These subroutines were used at Exxon to develop SAS procedures Our main goal was to produce geologic displays that produce geologic displays, including log in SAS. We had two possible solutions: displays, cross sections, base maps, and contour maps. · Use ANNOTATE= datasets with SASjGRAPH. · Obtain graphics subroutines to develop new graphics procedures. A BRIEF HISTORY We felt that the use of ANNOTATE= datasets was In the past several years, the geologists in our inadequate for several reasons: Production Department have increasingly used SAS software to solve their geologic problems. · Geologic maps are usually scaled. Initially, SAS software was used for work on the · Geologic datasets are very large and Prudhoe Bay Fie1d. Prudhoe Bay is the l",Sugi-13-72 Hobby.txt
"USING THE IBM PC AS A HOST GRAPHICS DEVICE Sarah Darden SAS Institute, Inc. INTRODUCTION With the exploding market -of new hardware and software products, the personal computer is quickly becomi-ng a versatile work station for the SAS/GRAPH® software user. Its use as a host graphics terminal has become a popular choice for the PC user who needs access to large mainframe data bases and production jobs. Because there are so many choices in hardware and software, configuring the PC as a host graphics device can be a complicated issue. Several factors, such as host communications software, communications boards, display adapters, and emulation software must be considered. This paper will analyze these factors and provide information on the different ways to use the PC as a host graphics terminal. THE PROCESS There are three very basic steps in generating host graphics. software, running on the host, must generate graphics commands in the language that the target device can understand. The commands must then be sent to the device, and the device must be able to interpret those commands and create a graph. For this process to work, the IBM PC must be attached to the host c0ID;puter. Many standard personal computers do not come with the equipment needed to provide a host connection. The transformation of the PC into a terminal requires the following items: hardware in the PC that establishes the physical connection between the host and the rC software in the PC that can handle communications to and from the host a graphics display adapter in the PC hardware or software that can take graphics commands from the host and convert them into a format that the graphics adapter can use to generate a display on the monitor There are many different combinations of hardware and software that can be used to fulfill the above requirements. The products that you use and how they will fill these needs are dependent on how the PC will communicate with the host. Host systems provide two c",Sugi-13-73 Darden.txt
"SASIGRAPIfSoftware and the Computer Grapbics Metafile David Muck Teknigraphlcs ABSTRAcr COMPUTER GRAPIDCS METAFILE SASJGRAPH Software can easily be integrated into PC These concerns were addressed by the American National graphics products, desktop publishing - products, and Standards Institute and their solution for this challenge graphics hardcopy devices by using the American National introduced the Computer Graphics Metafile. The CGM Standards Institute's Computer Graphics Metafile. The standard was designed by the ANSI X3H3 Committee, the procedures for converting SAS/GRAPH to CGM, the same committee that has given the graphics industry such benefits, and the importance of the CGM are all graphics standards as GKS, PHIGS, and the CGI. The discussed in this presentation. ANSI X3H3 committee, which is comprised of representatives of the computer graphics industry, is the most qualified entity for the implementation of a INTRODUcrION graphics standard such as the CGM. One of the most important aspects of the CGM is its implementation and the adherence of the vendor to the specifications of the The personal computer has evolved into a complete design of the CGM. When comparing any two graphics workstation over the past several years. It implementations of the CGM ~ere is little likelihood that began with the displaying of mainframe graphics, such as both implementations will be identical or even completely SASjGRAPH. on the PC, with the PC acting as a compatible. This incompatibility is typically due to mainframe graphics terminal. Once PC graphics adapters variations or customizations of the CGM made by a with acceptable resolution were introduced, particularly vendor during the implementation, or a different the IBM Enhanced Graphics Adapter (EGA), the concept interpretation of the specifications of the CGM. The of using the PC as a graphics terminal be came standard cooperation of various manufacturers with regards to for most companies. From there, graphics ha",Sugi-13-74 Muck.txt
"STRACT: I'IETHODS: Combining different graphics output on one Rotation: page can aid in. comparisons and comprehension. Similarly, display of graphics output in verti- There are a large number of device drivers for which SAS does not support the rotatel cal, or portrait, style can facilitate viewing and emphasize a point. These two concepts can norotate option. In these cases it becomes be combined to generate multiple plots per BY necessary to find an alternative rotat-;on method. The SAS/GRAPH® template facility pro- variable on the same page through creative use of the SAS/GRAPH® template facility in PROC vides this. GREPlAY. The template can be called numerous The template facility makes use of the fol- times to produce such graphics output via batch computing for all values of the BY variable. lowing coordinate system: INTRODUCTION: (0,100) (100,100) The presentation of data through graphics rather than tables can be extremely useful in making a point. SAS/GRAPH® provides us with a number of good tools for doing this, one of which is the template facility. In this pre- (0,0) (100,0) sentation, I will discuss three features of All panels defined through this facility this facility which can be taken advantage of to convey and emphasize certain points and to must specify four boundaries within the above ranges: lower left (LL), upper left (UL), do so economically through batch computing: upper right (UR), and lower right (LR). Bya simple 90° clockwise shift of this coordin",Sugi-13-75 Gerend Raftery.txt
"A computerized approach to displaying environmental data in maps is an important tool to those interested in analyzing the data. With the development of CHESMAP, customized maps are now available to anyone with access to SAS·. CHESMAP was written using the macro facility features of SAS and the graphics procedures of SAS/GRAPH·. The program creates data point, contour, overlay, time-plot or response surface multicolor maps in two- or three-dimensions. The map may be of the entire Chesapeake Bay region or a subregion based on longitude and latitude or by common areas (e.g. rivers, upper, lower, or mainstream Chesapeake Bay). This paper demonstrates the various options available with CHESMAP using some historical dissolved oxygen data from the Maryland portion of the Chesapeake Bay. While the environmental mapping program was developed using the Chesapeake Bay map coordinates, it can also produce maps of other geographic locations by using new map coordinates. CHESMAP can create a map of the entire",Sugi-13-76 Jacobs Swartz.txt
"ertical variable The contour lines are created through the to the two horizontal variables in a three use of a macro that can be inserted into the dimensional plot is easily shown by the user's program. The contour lines, which surface produced by PROC G3D. It is, consist of a series of points, are placed on however, not always easy to determine the the G3D plot using the LABEL function in the value of the vertical variable at some point ANNOTATE facility. The locations of the on the surface. What is needed is the points are eaSily calculated along lines of ability to plot contour lines or points of constant X and Y. Whenever one of these constant vertical value on the plot 1 s lines crosseS one of the user's designated contours and the point is not masked, an surface. observation is created in the annotate data A macro was written that can be inserted in set. the user's code prior to the PROC G3D step. The locations of_ the constant vertical The location of the viewer's eye and the points are calculated; those points that line of sight determines if a particular are not masked, hidden by the plot surface, point will be masked. Any point may be masked or may mask other points depending on are then placed on the plot as labels using the ANNOTATE facility. its relative height (value of Z) and the location of the viewer. A line of sight consists of all points that appear to be on the same line when viewed from a fixed. I ntraduction location. For computational purposes the PROC",Sugi-13-77 Carpenter.txt
"Several laser printers are supported for the first time in Version Users of Version 6 SAS/GRAPH® software will find that programs 6. New drivers include those for the Hewlett-Packard® LaserJet, written for Version 5 applications on other systems will run in Ver- Imagen .... 2308, Apple® LaserWriter, and Xerox® 4045, as well as sion 6 with little or no modification. However, a number of new a driver for PostScript® devices. Laser printers that have been features have been implemented for Version 6 that give users supported in previous versions of SAS/GRAPH software and are new capabilities while retaining upward compatibility with Version also supported for Version 6 include most OMS® models, Xerox 5. This paper discusses some of these new features. lM 2700 and 3700, and Digital LN01 (Tektronix 4014 emulation). Dot Matrix Printers",Sugi-13-78 Kalt.txt
"tups, and control of movement from screen to screen. The SASjGRAPH® program- mers provided help with annotate, fonts, and This papex discusses the development of a devices. At the time SASj AF® software system for producing word slides for pre- was- very new, but all of the programmers sentations. The system uses SAS/ AF®, quickly learned to build applications using SASjFSP® and SASjGRAPH®. Much of the BUILD procedure. the discussion of graphics design and user in- terface could he applied to other projects. Design",Sugi-13-79 Bulkley.txt
"tells SAS/GRAPH software to substitute the specified font for the SIMULATE font wherever SIMULATE would normally be used. Version 6 SAS/GRAPH® software offers an intuitive and flexible For example, many Israeli keyboards substitute Hebrew charac- approach to national character display. It has direct support for ters for lowercase letters; an Israeli site might create a font in French, English, German, Italian, Spanish, Danish, Norwegian, which the lowercase letters are replaced by the characters in the Swedish, Finnish, Japanese. and other languages. This paper Hebrew alphabet. If this font were called HEBSIM, you could sub- discusses the problems with and methods of producing national stitute it for SIMULATE by adding the following line to your characters on hardcopy and CRT devices. AUTOEXEC.SAS file: GOPTIONS SIMFONT=HEBSIM;",Sugi-13-80 Walker.txt
"CALL SYMPUT('DISTR'!! LEFT(PUT(CNT,3.)),OISTNUM)· CALL SYMPUT ( 'FRST' ! ! ' IN THE INDUSTRIAL SETTING, THERE IS AN EFFICIENT LEFT( PUT {CNT ,3. ) ) ,fRSTNUM) . WAY TO GENERATE SERIAL CUSTOMIZED PRODUCTION CALL SYMPUT('XTRA'!! ' GRAPHICS FROM MULTI-INPUT DATA. CURRENTLY, RE- LEFT( PUT(CNT, 3. )), XTRANUM)· PORTS ARE RECEIVED FROM A COMMERCIAL REPORTING CALL SYMPUT( 'LAST'!! ' AGENCY ON A PC DISKETTE. A REPORT IS RECEIVED LEFT(PUT(CNT,3.)),lASTNUM); ON A BI-WEEKlY BASIS PROVIDING TRACKING OF A PRODUCT'S MARKET SHARE IN ALL U.S. DISTRICTS FOR IF EOF THEN CALL SYMPUT(' ALL' ,CNT) ; A 13 WEEK PERIOD. THE CURRENT ROUTINE TO HANDLE PRODUCTIQN OF THE REPORTS AND GRAPHICS IS LABOR THE FOLLOWING EXTENDS THE LOWER AND UPPER LIMIT INTENSIVE. THE REPORT OATA ON THE DISKETTE MUST TO THE NEXT HALF UNIT TO PROVIDE A UNIFORM Y-AXIS BE REFORMATTED TO A FLAT FILE USING COBOL AND THE FOR All GRAPHS. REPORTS AND GRAPHICS ARE PRODUCED BY USING SEVERAL SOFTWARE PACKAGES. EACH OF THE PLOTS WERE PRE- If EOF THEN CALL SYMPUT('SUBDlVO',SUBDIV); VIOUSLY GENERATED INDIVIDUALLY. IF EOF THEN DO; A MORE EFfICIENT ROUTINE WAS DESIGNED USING SAS* MINYAX""&MNYAX; IN A CMS OR TSO ENVIRONMENT TO pRODUCE THE RE- MAXYAX=&MXYAX; PORTS AND GRAPHICS FROM THE REPORT DATA GENERATED MINYAX=(INT(2*MINYAXll/2; BY THE COMMERCIAL REPORTING AGENCY. THE REPORT MAXYAX3(INT(2*MAXYAX)+I)/2; DATA IS REfORMATTED AND A SAS DATASET PRODUCED CALL SYMPUT('MNYAX' MINYAX)· USING SAS CODE. SINCE VERSION 5, SAS/GRAPH* SOFT- ENg~LL SYMPUT(",Sugi-13-81 Joseph Horman.txt
"This paper describes a prototype connecting a piece· of non-IBM equipment SAS/GRAPH* driver for the HP LaserJet that was developed at HP's corporate to an IBM mainframe and having them computing Center. The paper also converse is the most obvious problem which must be overcome, but fortunately, discusses several important issues that is one of the easiest to solve. were uncovered during that development, including data communications between IBM and the LaserJet, vector-to-raster Electrically speaking, the serial and parallel connections of the HP LaserJet conversion, and selecting a protocol cannot be connected directly to the IBM converter. These issues are presented in mainframe. Serial connections are a manner designed to assist the reader in creating his own LaserJet driver. sometimes available from a Front-End Processor (like an IBM 3705 or 3275), but Finally, a few commercially available solutions are presented as well. these are not addressable by the spooler, so they wouldn't be suitable for this 1.",Sugi-13-82 Case.txt
"Color Hardcopy Technology: Plotters and Printers Daniel Lee Raster Device: Output is an array of dots. Resolution INTRODUCTION is determined by the dot density, size of the dots, and There is such a wide range of plotters and printers accuracy of dot placement. Resolution is specified as available in taday's market that people purchasing color the number of distinguishable dots that can be placed hardcopy devices need to understand the features and along a linear measure; usually I inch. A line would be benefits that different hardcopy technologies offer. a ray of dots. Raster devices can also control the color Today. color graphics systems are more widely available of each dot. and easier to use. The increased availability of color technology is helping people obtain the benefits that Line quality in a vector device depends on the color graphics can provide. combination of - addressable and mechanical resolution. Figure 2 shows how a vector line is drawn. When a pen Color helps present complex information by adding plotter draws a line between points A and B, it is actually drawin~ to the points on a grid between A and another dimension to graphics. Recent academic studies have shown that using color graphics leads to greater B. The grid POlDts are the points that are electronically comprehension and retention of information, which in addressable by the plotter. The spacing between grid tum leads to more persuasive presentations. Color points equals the addressable resolution. A typical graphics turn data into information by showing trends, addressable resolution for pen plotters is 0.00 I inches. patterns, and inter-relationships. Using color graphics can shorten meetings, save time analyzing data, and Most vector devices have mechanical resolution equal to improve decision making. addressable resolution. If the mechanical resolution is lower than the addressable resolution, then the pen This paper reviews color plotter and printer technology. plotter can not phy",Sugi-13-83 Lee.txt
"driver uses IBM's Graphical Data Display SASjGRAPH was intenaced with the IBM 3820 Page Printer, Manager (GDDM)-·an interface between application software, using the GDDMFAM4 driver from SAS Institute Inc.· Cary, such as SAS/GRAPH, and IBM graphic devices. North Carolina, USA, and the Plot3820 driver from Image Research Corp., Santa Barbara, California, USA. Tests included To create an IBM 3820 ADMIlV1AGE print file, GDDM 112 illustrations from the SAS/GRAPH User's Guide. translates requests from GDDMFAM4 into a raster image--for nearly 240 X 240 X 8.5 X II addressable dots on a page. A lot Driver features, reliability, quality, print speed, computer resource of processing has to be done on the computer, a lot of data requirements, and ease of use are compared. temporarily stored, a lot of data- handled by the network, and a lot of processing done by the printer. Introductiou GDDMFAM4 does not use IBM 3820 hardware fonts. In the SAS/GRAPH User's Guide, it suggests that omission of the IBM 3820 Page Printer FONT (abbreviated F) parameter, or specification of F = NONE, will result in use of ""default hardware characters"". With The IBM 3820 Page Printer is a black-and-white laser printer that GDOMFAM4, text is converted to a raster image--no IBM 3820 uses standard 8.5-inch by ll-inch cut-sheet paper. It can handle hardware fonts (that I can recognize as such) are used. And, as is to be expected, if a SAS/GRAPH software font (e.g., tabular reports, text, graphics, fixed-width fon",Sugi-13-84 Bessler.txt
"mer: The opinions expressed below are those of the author and do not necessarily reflect a position of the Toronto Board of Education. When the ~ign-on is complete, the user's PRO- FILE EXEC fires the system by executing the following code. ABSTRACT TBETAS is a menu-driven system developed un- PROC DISPLAY CATALOG·=ctlg.staff .primary .menu der the CMS environment using SAS software, list; EXEC, XEDIT macros, and COBOL. The system is used to allocate teachers, based upon various As shown in Screen 1, there are four options. factors, to 163 of the Toronto Board of Edu- In the discussion that follows, I have pre- cation elementary and secondary schools. sented only the first option in this paper About five years ago this system was ori- i.e., Elementary Staff Allocation. ginally developed using IBM's ISPF dialog management facility, EXEC, and COBOL. The +--------------------------------------+ old system did not meet the user's require- ments. The user wanted multiple access to PRIMARY MENU the data base and a comprehensive on-line locate/search facility. This was possible to provide using SAS softwarei therefore, about 1. Elementary Staff Allocation 2. Secondary Staff Allocation two years ago the old system was converted from ISPF to SAS software. This system also 3. Class-size Statistics 4. Human Resources' Statistics uses COBOL to access centrally maintained : VSAM tables (table of school related parame- +--------------------------------------+ ters) to generate reports inst",Sugi-13-85 Dhanota.txt
"DATA-BASED WATER QUALITY INFORMATION SYSTEM Susan Campbell~ U.S. Environmental Protection Agency Jeff Finkeldey, Computer Sciences Corporation Louisiana. To obtain all the raw data INTRODUCTION records and even calculate a simpl'e The Water Engineering Research mean of the data would require several Laboratory (WERL) o~ the U.S. Environ- days. Another, more complicated calculation of carbon-use rates would mental Protection Agency in Cincinnati, Ohio has been involved in various require even more time. The proj ect research activities to improve the officers also requested the ability to create graphics from the data and to quality of drinking water. Since 1976, produce succinct reports. the Drinking Water Research Division (DWRD) of WERL has conducted extramural TIlE DWRD COMPUTER· INFORMATION SYSTEM field-scale research evaluating granular activated carbon (GAC) for the removal of trace organics from drinking The final choice for implementation of the system was to be known a·s DWRD water. This ongoing effort has produced thousands of pieces of data Computer Information System (CIS), a which were, due to volume and differing combination of IBM command procedures formats, usable for little more than and SAS Institute software. The IBM producing final project reports. command procedures form the framework for the system, allowing the user to As the need arose to perform more or enter one-word commands to build SAS® different evaluations of the data code which performs routine functions within a project or to compare data upon the stipulated data. Figure 3 shows the overview of the DWRD system. from different projects, it became Some of the more frequently used evident that a system had to be developed for making the data readily commands in the DWRD/CIS are shown in Figure 4. available and interactively manageable. To accomplish this required two major efforts: (1) deve lopment of a For example, suppose a proj ect officer consistent data format, and needs data_ sup",Sugi-13-86 Campbell Finkeldey.txt
"competitive marketplace, end-users are This paper explores the creative uses approaching computing requirements of information systems using the SAS using_ a variety of innovative methods. System. As the list of new features The SAS System has numerous products available on the SAS System for and tools to assist end-users in the mainframes and for personal computers development of their applications. grows, the capabilities for developing As noted by Curtin and Porter {2}, sophisticated end-user applications software application strengths can be seen in such diverse areas as (I) become limitless. Numerous techniques and examples are presented integrated capabilities, (2) illustrating the strengths found (3) integrating programs, project within the SAS System. management, (4) idea processing, (5) desktop management, (6) accounting (database), (7) utility, (8) vertical applications, and (9) expert systems.",Sugi-13-87 Lafler.txt
"o be developed. back to the 1890 United States The parameter driven programs Census when Herman Hollerith were not very friendly, one had reversed the idea employed in to know what went in columns 2-6 Jacquard's loom to count people. and had best not make a mistake Both devices were a response to anywhere, but at least one did the need to handle a large number not have to write a new program of similar operations systematically for each analysis of variance and quickly. The loom was used problem. with these programs the computer user expanded beyond to combine diverse colors into complex tapestry; Hollerith was, the nimble-fingered and if you will, unravelling the social nimble-minded programmer. tapestry of the United States The introduction of SAS® was a and recording what was where. in forward revolutionary step Well into the middle of the user-driven the development of twentieth century data processing concept of software.. wi th the methodology had developed l,i ttle the SAS® dataset and access to from the turn of the century. very sophisticated procedures, Those who remember uni t record the user had a dramatic increase equipment will confirm that they in computing power available to were more mechanical that him. The ease of using the DATA electronic. Programming, when step is probably only appreciated it occurred, was carried out by by old programmers who struggled connecting terminals on a removable with uninitialized variables, board with a set of copper wires. inco",Sugi-13-88 Moore.txt
"Information Systems In The Pharmaceutical Industry Theresa J. Hart, The Up john Company applications in humans. If the results of the According to The Encyclopedia of· Computer animal stUdies are encouraging, an Science and Engineering, an information system Investigational New Orug (INO) application is is a collection of people, procedures, and filed with the fOA. In phase I of human equipment designed, built, operated and test i ng, low dosages of the drug are tested in maintained to collect~ record, process, store, 20 to 80 healthy volunteers to determine how the retrieve, and display information. (1) Or. drug is absorbed, distributed and metabolized in Andrew Targowski states in an article he wrote the body and how long it is active. In phase for ""Oata Management"" magazine that the first II, the drug is tested for effectiveness in up information system was paper money, i ntraduced to 300 volunteers with the targeted illness. In in China in 970 AO. Other Significant the third and final phase, the drug is tested in information systems that he sites are a cost 1,000 to 3,000 affected volunteers to confirm control system began in Venice in 1410, printed earlier efficacy stUdies and identify 101'1- books, made possible by the invention of the incidence adverse reactions. A New Drug printing press in 1440 and double entry Application is then filed with the fOA. A bookkeeping in Venice in 14594. All those typical NOA runs to thousands of pages and methods used hand methods of calculation. The conta ins the resu 1ts of a 11 tests, drug mechanization of information systems was first formulation information, proposed manufacturing possible in 1884, with the invention of the procedures and proposed 1abe 1i ng. Even after Holerith PUnch Card Machine. The fOA approval, the manufacturer must continue to computerization of those tasks began in 1951 provide reports to the agency, including adverse when the first business computer, the UNIVAC I reaction data, quality control in",Sugi-13-89 Hart.txt
"FUTURE DIRECTION OF BIOMEDICAL INFORMATION SYSTEMS IN THE PHARMACEUTICAL INDUSTRY BASED ON THE SAS® SYSTEM James F. Sattler, Syntex Research Type II CANDA The title of this paper promises a ~ro~der subject than the paper actually The second type of CANDA deserves 15 1ntended to present. Therefore, at to be called a II system "" because a clini- the outset it is important to state cal data review system accompanies the that the following will deal with only data. A clinical data review system is one biomedical application a set of automated procedures that en- computer-assisted NDA review systems. ' ables a medical reviewer in a regulato- ry agency to interact with the data. COMPUTER-ASSISTED NDA SYSTEMS The sponsor thereby turns over to the regulatory agency a powerful mechanism In the second half of the 19805, U. S. pharmaceutical companies and the that the agency hopes will facilitate or improve the quality of the review. Food and Drug Administration have begun to apply computer technology to New It is this type of CANDA that is under the most active development today. Drug Applications (NOAB), i.e., to the formal submission of data to a regulato- ry agency required for approval of a Type III CANDA new drug. Medical reviewers at the FDA As might be imagined, Type I and II now are starting to have direct access CANDA systems raise the prospect of to clinical trials data which the spon- still another, more highly evolved type soring companies present as evidence of of CANDA. It is possible to conceive a drug's safety and efficacy. These of a Type III system as a kind of super computer-assisted NDA (CANDA) review Type II· In addition to providing a systems are on the way to becoming a data review mechanism, such a CANDA standard feature of the drug develop- ment process. would encompass the entire NDA pack- age.. Cl inical results, statistical analysis, toxicology, manufacturing, TYPES OF CANDA SYSTEMS chemistry, and all other information comprising the total NDA pac",Sugi-13-90 Sattler.txt
"WE-R-ORUGS PHARMACEUTICALS CORP.: SAS. PROGRAMMING WRITTEN BY MACROS Ira A. Bader, New York City Health & Hospitals Corporation Wouldn't it be nice if the programmer could omit all mention of visit-specific Background variable names (VQOl, VOlA, V002, etc.) from the programs. Let base SAS software figure BP-Down is a new treatment for high out what the variable names are, what visits blood pressure that is being tested by the they pertain to, and then write SAS code to We-R-Drugs Pharmaceuticals Corp. process the specific pattern of visits. Will our programmer be able to write a program Multi-center clinical trials for the new only once that will execute 14 different ways drug require a fixed schedule of patient for 14 different patterns of visits? visits over the course of each e~periment. In one research protocol, each patient must The Solution report for blood pressure readings and a new supply of medication on Mondays of alternate The visit designations 000, 001, 01A, weeks, for a total of ten visits. A two-week etc. will be read from the variable names supply of BP-Down is dispensed at Visits 4 supplied by PROC CONTENTS, and inserted into through 9, with placebo given at the other a series of macro variables by calls to the visits. SYMPUT function. This list of visits will then furnish the building blocks to Although the patients are required to reconstitute the list of visit-specific adhere to this visit schedule they sometimes variables. Here~s how it's done. come on other days. Cars break down, vacations interfere, people get sick, etc. List of visit-specific variables - Run Blood pressure readings taken at these PROC CONTENTS with option NOPRINT and create unscheduled ""interim"" visits must also be an output dataset. The variable called NAME recorded and entered into the data base. in the output dataset has as its values all the variable names found in the original Description of Data dataset. Use the SUBSTR function to identify and keep only those variable",Sugi-13-91 Bader.txt
"The Federal government and the insurance Government health insurance programs and private insurance companies routinely industry continue to show interest in screen masses of patient claims data to finding new and more effective ways to monitor the cost and quality of health care. find clues to what appear to be inefficient The Health Care Financing Administration use of hospital resources, or care of substandard quality. Using the capabilities (HCFA) began in 1974 to monitor care of SAS, techniques were developed to delivered to Medicare and Medicaid analyze data from health care billing beneficiaries by means of a network of systems. The UNI-PRO system uses Professional Standards Review specifications embedded in SAS FORMAT Organizations (PSRO). Nine years later, libraries, tables stored in sequential files, as the PSRO system was replaced by the Peer well as more complex hard-coded criteria. Review Organization (PRO) program. Also It is possible to locate unusual patterns of established was a pre-paid capitation care based on patient demographics, system for the health care of Medicare disease/procedure (ICD-9-CM) coding and enrollees JOIning health maintenance other combinations of data on organizations (HMO) and competitive hospitalizations that help to guide medical plans (CM P). The quality subsequent manual review of detailed assurance function of peer review expanded medical records. Algorithms using and became more definitive by requiring RETAIN statements and SET",Sugi-13-92 McDonald Veloski.txt
"SAS Server The SAS server is a separate SAS execution that controls the Administering SAS/SHARE® software in an information center is execution of input and output requests to your SAS data library. a matter of understanding the functions necessary for creating Your SAS execution reads from and writes to your SAS data and maintaining the SAS® server. Once the information center library through the server. Figure 1 shows two SAS executions understands these functions. decisions need to be made on how within a single CPU and shows the way a data library can be these functjons will be delegated. This paper discusses how the shared without the SAS server. information center at SAS Institute delegated these functions, the toofs that were developed to help in the administration, and the user support provided by the administrators. It is not the purpose CPU of this paper to present a comprehensive discussion of the tech- nical details of SAS/SHARE software. SAS User",Sugi-13-93 Janes Penland.txt
"TM SASjSHARE SOFTWARE, IMPLEMENTATION AND EXPERIENCES Janet C. Lind, San Diego Data Processing Corporation ABSTRACT, one little programming change. A programmer can not update the member With the availability of SAS/SHARE until all users have released the software in February 1987, new library. SAS/SHARE also does not opportunities for developing information provide a ""status-type"" command to systems became a reality. Although the interrogate a ""member"" to determine if product initially addresses only the any user has exclusive control before concurrent access and update of ""data"" attempting to gain exclusive control for type members, i t significantly expanded update. the versatility and interactive potential of SAS-based information systems. This paper will first discuss INSTALLATION CONSIDERATIONS (mS), what is SASjSHARE, what will SASjSHARE do and not do, and how to SAS/SHARE installation is not install/implement SAS/SHARE. Secondly complicated. However SAS/SHARE does I i t will discuss writing macros to require systems programming assistance. control SAS/SHARE server assignment, Follow the ""OS SAS/SHARE Installation programming considerations and Instructions"" carefully. There are no conversion hints. short cuts. You or your systems programmer must install SVCO, install SASIUCVO in a link list library, define WHAT IS SAS/SHARE? an inactive MVS subsystem to provide an anchor point of SAS/SHARE control SAS/SHARE software provides concurrent blocks and provide a started task for I acces& and update to data-type members each server in 'SYSl.PROCLIB'. If within a SAS data library by means of SAS/SHARE is to be supported from server. The server is a program which multiple CPUs then VTAM defintions must 1 synchronizes the input/output requests be defined. A word of advice is test for access and update to the members of out SAS/SHARE on one CPU, without VTAM, the SAS data library. There can be before attempting the VTAM use. multiple servers to improve performance. IM",Sugi-13-94 Lind.txt
"USING SAS/AF® SOFTWARE TO DEVELOP PRE-CLINICAL INFORMATION SYSTEMS Kerry G. Bemis, Eli Lilly and Company Pre·clinical information systems are The critical information that's missing in the characteristically interactive with small to medium CATOUT output is the relationship among the size databases. ~SAS/AF® software is therefore the objects, Le. the program flow or structure. This ideal tool for developing these systems. While the needs to be clarified in an external document or development of these user friendly systems is flow chart as illustrated below: becoming increasingly popular so is the emphasis on system validation. Although the exact meaning Flow Chart for Example Program of 'system validation' isn't clear, it is clear that documentation is an important part of it. The r----------- ----------. objective of this paper is to describe a method of l ~J automating the documentation of a SAS/AF program. SAS/AF is an extension of SAS® that consists of a collection of objects (also called screens). There are five object types which are described in the table below: Nonhierarchical Program Flow SAS/ApID Object Types: This flow chart is relatively simple, but you can imagine how complex it would get for a SAS/AF - interactive branching · Menu program of more than a hundred objects. If you · Program · execute SAS® code have to modify your program that means you have · Cbt - question and answer tutorial to modify the flow chart. It becomes clear why good · Help - user information documentation is seldom implemented or rarely · List - values for Program Object user fields updated. It is especially difficult to maintain a program that utilizes non hierarchical program flow The SAS® procedure CATOUT provides a minimal indicated by the dashed lines. I propose level of documentation for the collection of objects eliminating the nonhierarchical program flow and that make up your program. For each object in your adopt the following strategy: program CATOUT provides the fo",Sugi-13-95 Bemis.txt
"The Selling of SAS® Software: Toward a Unified Analysis Environment in Basic Research Mark H. Bradshaw, Syntex Research BACKGROUND: SAS/FSp®; 2) statisticians in the group are per- The mission of Basic Research at Syntex is to identify new compounds with marketable biological forming most of the requested statistical analy- activity for potential therapeutic use in humans. ses of experiments and pilot studies using SAS A compound's biological activity is determined software; and 3) end-user analysis applications through a series in vitro, ex vivo and/or in vivo for routine screening studies are being built with SAS software for the PC by modifying data experiments conducted by a large number of biologists and experimental pharmacologists. entry screens and statistical analysis programs already written in 1) and 2). Recently a statistical support group was formed 1) PC Data Entry System for Statisticians' specifically to work with scientists in Basic Analyses: SAS/FSP is being used to build simple Research at Syntex on experimental design and data entry screens with simple validations. An statistical analysis. COMPUTING ENVIRONMENT: analyst can build a screen quickly and provide a When the statlstlcal support group began to work copy to Data Entry along with the laboratory data sheets from an experiment. This procedure yields with scientists in Basic Research a wide variety of approaches to statistical computing were dis- a SAS dataset directly, it eliminates the need covered. Hardware in use included IBM-compatible to extract or convert data from another database PCs, non-ICM-compatib1e PCs, hand calculators, or data file, and it gives the analyst control mini-computers and limited use of the corporate over the structure of the dataset so that statis- IBM mainframes. IBM-compatible PCs were tical analyses can proceed with a minimum of data manipulation. Typical turnaround time for a predominant. Software for data summarization and analysis on small study is less th",Sugi-13-96 Bradshaw.txt
"The first step was to evaluate the quality and quantity of bar A unique shipping information system was designed using SAS-® codes produced by the printers currently used by the Institute. software and bar coded labels to get quick and accurate informa- Finding quality paper with a sticky backing that could be used for tion. Bar coding data saved time, reduced errors, and elimin'ated the bar codes required much testing. The bar code'paper had to keying. SAS software was used to read and process the bar meet standards for not smearing, durability, reading legibility, and coded information, producing reports for UPS® (United Parcel printing compatibility with a laser printer. A laser printer was Service), RPS® (Roadway Package System). other shippers, and selected that SAS Institute Inc. management. A master shipping data base was created to track packages. The system allows the user to have · used different paper sizes and types (transparencies, immediate enhancements as the postal regulations and rates labels) change and provides the best service at the least cost for the Institute and customer. · printed quietly at a speed of ten pages per minute · combined high quality resolution character formation with",Sugi-13-97 Dietrich.txt
"lary, University of Ottawa ABSTRACT modular system was designed to provide such results. With several single word changes in one file a large range of output results are rapidly available. The system, utilizing macro, AUTOCALL facility and all The operational (functional) components of this Basic procedures under version 5.16 of the SAS product, system is one SAS file which primes and drives it, and produces customized outputs for statistical analysis. It three types of Macro Modules (Storage, Assembler and was designed to do exploratory data analysis and Processor) which are members in a MAGUB referenced by generate reportable outputs from a number of large data the AUTOCALL facility. sets. The system can be functionally categorized into the following modules: 1) Primer; 2) Storage; 3) Assembler; 4) Processor. THE PRIMER MODULE The Primer module defines the key and current Symbolic macro variables utilizing the system editor. The Storage module contains and catalogues all DATA and PROC step information for a specific predefined output. The Primer has one basic function: to define macro . The Assembler constructs the data set required for variables for the global referencing environment. These processing in either a permanent or temporary form with symbolic variables can be classified by their function into either standard or arrayed variables. It automatically three types: 1) System; 2) DATA step; and 3) PROC step. generates the data set for one of three levels: sample, Thei",Sugi-13-98 Orban Alary.txt
"As a result, a Project Scheduling Monitoring System (PSMS) was developed using SAS/FSP® to collect schedule data and This paper discusses the aspects of schedule commitment SAS/OR@ to set activity relationships to time scales for hard monitoring in a Project Management environment, with the use copy reports and plotted output. TSO CUST was used to allocate of SAS® products featuring the data management and display necessary user files, to invoke SAS@ macro libraries, and to capabilities of the Full Screen (SAS/FSp®) and Operations navigate the user through the SAS/FSP ® screens and through Research (SAS/OR®) products. The concept of schedule report selection criteria. commitment monitoring offers an effectlve alternative to the traditional, and often complex, critical path method of network System Overview presentation and maintenance. PSMS consists of four modules designed for collecting,",Sugi-13-99 Hardy.txt
"RETRO-ENGINEERING A SAS® REPORTING SYSTEM FRONTEND Brent Turner, City o f New Y o r k I n c l u d e d tn P A Y G Y C L E p r o c e s s i n g is a series of twelve S A S programs which had ea^h a c c e s s e d a s e q u e n t i a l -file p r o d u c e d by P M S , c a l l e d t h e P a y C y c l a E x t r a c t F i l e Th« Financial Infornation Services (PCEFJ. PCEF is a comprehensive A g e n c y ( F I S A ) o-f t h e Citv of N e w Y o r k h a s b e e n c r e a t e d as a r e q u i r e m e n t for f e d e r a l repository for all employee data s u b s i d i e s U s e d t o a s s i s t t h e C i t y in p e r t a i n i n g to p a y r o l l p r o c e s s i n g . The meeting its financial obligatians. SASH p r o g r a m s e a c h r e p o r t u p o n some These subsidies had i n i t i a l l y been a s p e c t of P C E F w h i c h 4s u s e d to m o n i t o r r e q u e s t e d by t h e C i t y in r e s p o n s e to i t s the outcome of the PAYCYCLE. A fiscal crisis in the mid~1970·s. FISA preliminary examination of these has t w o p r i n c i p a l f u n c t i o n s , w h i c h a r e : programs had revealed opportunities to reduce t h e processing t i m e , which had b e e n over f i f t e e n h o u r s , b y m o r e t h a n 50 · to p r o v i d e financial information percent. e n a b l i n g m u n i c i p a l a u t h o r i t i e s to budget f o r s h o r t - and l o n g - t e r m cttpital e x p e n d i t u r e s ; · to tnanage t h e payroll for t h e IH.E. PRDBI,Ei1 m u l t i p l e a g e n c i e s of the city of H e u York. The o r i g i n a l P C E F S A S r e p o r t p r o g r a m s h a d not been designed as a system! further, To f u l f i l l t h e s e -functions) FISA e m p l o y s they h a d n e i t h e r b e e n w r i t t e n b y t h e same c o m p u t i n g h a r d u a r e M h i c h i n c l u d e s an X B H person nor even at the same t i m e . Each SOB^f r u n n i n g in p a r t i t i o n e d modei a n d program had been written as a standalone an I B M 3 0 a i ,",SUGI 89-130 Turner.txt
"EFFECTIVE METHODS OF TESTING USING THE SAS SOFTWARE Neil Howard. Alantic Research Corporation Linda William~ Pickle, Geo~getown Univ. Jr~, Ja.mes B. _Pear50I1, GTE, Inc Resea~ch Greg Raines, Alantic Corporation Intr-oduct ion the typo in the code corre~t; slightes~ The qualtly of a ppogrammer's work or ing of t.he program' ... mi'~U:ndef'st.and i!;; evaluated by f'esult.s. When :results Can cause errors during reqwiremen~s ;9,1',e inca£' reel Ur' t.he program f ai Is to l"".l9r ex e..-::ut.icm . meel consequences expe~tations, ~ange The purpose of testing is to from. annoyed ussrS to frantic ~al1s in idehlify any errors and inconsistencies t.he middle of the night.. What can """"e do that exist.. in a system. Debugging is to avoid t.hese un.pleasa.nt ot::curf'eril::~S? the art of -locatin-g the source of· these Use of a fourlh-genE!'rat.itlM lal.no;}u<:l.gEi sue"" eprors and cor~e~ting it. Tog~ther, th~ a5 ths SAS Syst.em should improve qu~lity t~5t..ing and debllgiJin~ tasks are t.hought b,y providing a.n improved envil'""onm~rtt. (or to cost 50'l. to BOY. of th~ tO~Ql CQ~t of the programmer~ On~ 3dvan~age t.he SAS developing the rirst wo~ki~g version of sy'Stl!!!!m holds ovep t.r-aditionCtl language-s Cle!a.rly, any t9(::hniqu9§ t.hat .a syst.em. is that it. ha.s be..an implemented as an will facilit.ate these task5 will le.aO to interprat@. B$ opposed to a compiler. improved p~Dductivity and reduced cost~ This incr~ases m~Lhin9 co~t fop the of system develcproeo~_ pr-ogram, -but it. reduces t.he time We mu=-t.. broGa.dan OUP ph i lQsophy ot neccessary t.o find syntax and runtime testing to go beyond the -syntax check. Tn~ BAS system is often c~lled errors. As shown in Figur~ 1, th~ cost of ;a system of dera\""ilts. This enab-les i cop r~c::t_l,nlJ F;'-1'l""'nl'~ f11;'·l""e~se5 users to produce simple code to handl~ eKponentially with the st~ge of routine la~k~ th~t often take months to detet:t.ion. An error in a large system design Q,nd code using third -generation di$c",Sugi-89-02 Howard Pickle Pearson Raines.txt
"onthly CO$l$for A are $75 venus S150 1. ABSTRACT fot"" 5. Assuming that both progc-ams are run monthly, the Saving money 15 uppermost in the minds of DP managers. and the foJlDwing formulas Me ""Ulled 1-0 evaluate the total COlts: SAS SY$le III il ce:rlainly a ""pr-ogram mer efficient"" Lool~ minimal + {( ~60 + Approach X .. $30,000 $15)· months) SAS code is: req\Jired to perCorm traditio.D.ally code intensivE! lasks. Gratification and and results immediate. ar~ Approaeh Y - $S.OOO «( $50 .$100 ) .. mon1hs-) + + Afamillarquate su.gge,U that tbe SASSys-lem is easy to use. and The cos1 of each approac~ a1.1. 10. 100. -and 1.000 month:i:.is just 8a easy to abuse. Beoe:auS>e the SAS System is becoming iIIus:traled in Figure 2. im:reasingly popular as a development loot 11 is ('""eotial 10 . eV!lIuatil;l' 1ecbnique:s for lis effective use. This tutoda~ will d.efiD.e efficiency,,:suggest fal;.'ton to be wnsi~ere.:! in Pleasuring TOTAL COST TOTAL COST efficiency. and provide compari:tODsof lecho.iqueslhal im.prove MONTHS APPROACH X APPII.OACH Y efficiency. 30.07) 1 5.150 10 30.7)0 6.500 A pritnary area where the SAS System Clln be used more 100 37.500 20.000 efflt-ctively is: lIO. It shouJd be noted that -over 90J. CJt 1be Sln.ooo S105.000 1000 proce""ing time in any siven p:rogram involVe, readin& and/ol' writing data (reference 1). Tbi:; tutorial will illustute how to Pigure 2 avoid unnece:;:sa.ty 110. mini-mite pD:ssesoC the data, and oontrol rell,,-write LQQPs. ·A natural que·slion ar",Sugi-89-03 Howard.txt
"THE SAS SUPERVISOR AND SET/MERGE PROCESSING A;rna..n M_ Ze;cI,. ARC Pro-Fess;onal s e t - v ; c a s Group Xnc .. II' For example, through the use of the Macro I. INTRODUCTION Language, the programmer has control over This tutorial discusses the functions the sequence of OATA/PROC steps seen by the Supervisor and the statements of the SAS* Superv;s'or as they pertain to the execution of SAS set and merge contained ea.ch The within step. following sections discuss the actions of 'statements and is a combination of two papers pre$~nted in the Advanced Tutorial the SAS Supervisor during compilation and ,session of SUGI 13. There will be a execution of a DATA Step. genera lover..,. i ew of the SAS Super:-v isor followed by advanced examples of set and marge processing. The six coded examples III. TIME ACTIVlTIES COMPI~E will focus on the activities o~ the Supervlsor during data step e~ecution~ During the compilation of a DATA Step, the Supervisor creataa both permanent and transient (in that they II. SAS SUPERVlSOR ""disappear"" I;l-ft-er the compilation or"" execution of the current DATA Step); entities. The primary permanQnt entity The function of the SAS Supervisor can be categorized as follows: is the directory or header por-ti'on of the: SAS data set (the data is added to the, - Compile SAS Source Code. and data ~~t at execution tlmel. The"" transient entities lnclude a variety of: - Execute Resulting Machine Code buffers, flags and work areas which, at execution time, -control the creation of. when a SAS DATA Step program is written. the -'DATA Step ""module"" must be int'egrated the desired output. The following is a partial list of the more important within the structure of the SAS System. This integration is done by the SAS actions taken by the SAS Supervisor Gaining a more complete during the compilation of a DATA St~P! Supervisor~ understandi ng of what the Super'V i sor does and how our ""program"" is controlled by it - Synta)< scan; - Translation from SAS source co",Sugi-89-04 Zeid.txt
"A SURVEY OF TABLE LOOKUP TECHNIQUES FOl!. TIll! SAS® SYSTBM Jame. I!. Johnstone, ARCIPSG Craig Ray, ARCIPSG RGUIIli 1 SAMPLE DATA POk PIlIMAKY AND LOOKUF .m.ss L INTRODUCTION i'llDIlIIlI rl:U: ThIs paper .,......IS · variety 01 ~ to ooIve C'II1t:_r 'I'raruIaat.t..c= rtl.a table lookup applkations In the SAS system. Table lookup <an be loosely defined .. the acquisition 01 additional T~ rZ:<ltl.!!:actiOll VlIolu-e Diltlt/Time S~t:t'pe- CUB-toal!ll: InIonnation from an amdlJary or p;muneIer file based on the .,... I . I· I. ot.."" ~"";U:J MILOEJ ~!!1JEIID) value or wlues of -one or more variables contained :In a C'rRMnPE) IC'USUD} IDATETDIEI ., Motivated by software ~ primary /iJe. 9:'Q.'OoO ""G.50 0(01)01 !lOOO 89-001151030 cnmIidera~ alternative solutlon& within the framework of 22.0C 1.10 13910H51-1):;1, l211 "" <l211J the SAS .,.._ are presenled primatily in terms of the· 131lo01l:::;:U}1I0 22.""00 1.10 1211 "" G2173 479.0{)o 02 23.95 891l115lO41 021'13 0000 number _of operations involvod in ocquisItion 01 the desired -47.fiO 89(l-1151130 0000 952.0~ "" .otl-OO""l """""",,t. SompIe 00<1. for esch of the approoches, II1dr relati.., 93.;S 89Q1151133 0000 1819.00 21 00001' n _gths and weoknooses, and guldefines for selection are 0.13 00007 2113 B901151133 2.50 n 0.13 S901151lj .. 2.50 OOOCI 'JUS presented. Considerations of mainlel>anCe, complexity, and start-up COII1s are also di8cussed- l'erfotmance characleristics oblained for the various aI.... """"tlves on dl/fen!nt platkmns ranging from PC II> mainframe .... beyond the scope 01 !hiO paper. The ....,......,t inlmmation and guidelines """",sentOO the mmbination of two relllted papers l'reviousty !1""""""'ted cus"""""""" CllST'ClM!:R m AOOu33 (oek= 1 and 2) willt some additional specuJations and ,Cr;S'I'AIXIItI (Cl'JSTIOI mnsideratlons. "",...=- !Hl MAPLE ST ·· BURBANK, CA -(lOOal OI}O~;n 1:13 ElM OR' J APPLE ,rALLErY, CA OZZIE lIELSON 8.310 ::IUNSE'!' BLVD., WBS'l HOLliYlIIOOD. CPo. 02113 TAB BUNTER JI. DEFINITIONS ICaO MOISO DP. ·· i",Sugi-89-05 Johnstone Ray.txt
"(:apabdities that aTe Abstract available: through the use of advanced format techniques :allow the SAS programmer to address Ia[""ger~ sys.tems- Past and present SUGI confe-cences have offered ~ wealth related concerns: how to increase the overall of papers covering the use of SAS user-defined formats for maintainability of a SAS-based system by concentrating on tab~e lookllp. separating program data from program rode. Ue tenet to Mastery of this simple but powerful follow (which is not unique: to SAS programming) ca.n be programming technique is a crucial step towards. achieving fluency in SAS progmmming and systems design. Yet nO :simply e~pressed: previous SUG. papers and no SAS manuals have gone beyond presenti.ng basic techniques and truly plumbed the depths of the immense potential of the FORMAT GET THE DATA OUT OF YOUR PROGRAM procedure, Most people respond to that :Slogan with confusion: they This tutorial bridges that gap. It shows how yon Can think that there .is. any data in their program. All the don~t extend your use of the basic PROC FORMAT table lookup data that they know about is in SAS data sets. However, technique into virtually any larger SAS SyStem application. when they look carefully at their program. they finally in ways possibly not dreamed of even by the origioal come to see a different kind of IIdata. 1I but data designers of FRoe FORMAT. Specifically, PROC nonetheless: long lllfJCk$ of IF/THEN/ELSE logic. checking FORMAT-b:ued table lookup techniques",Sugi-89-06 Kretzman.txt
"u.n.- ....11: o.r.ral ~II! 'ftU!"" .. IW.o- (IISD) rut tcr' Idft' S~tl...s _~! .-ftII: rau, IDI'1I Ddl t.... t _tRI. tlIe1:Jpa J; . . . . .~ ·· u..a 1tIGIIC!. bJt. ~y ball · lIitIIc trPI- 11: RI'OI' ate npr.. .D .... iIII.1J6083.J 11.05 . . cri'CJQl nlu OIl! ....... S ·.e1$ ~d.H5 bLH _ _ _ ·· nH ~ ~ -- .... ..... J.il'tur- &No DOt ....... 1i1u tbo _ ditt...-t · ~l' ............... '"" ..... .,."""", · ,. .... · · · ...... "" ..... 311.200 · , · , .... , · n lI · · ,. ...... · · .... 1'51.050 · · · 20 l'J.I:KI ...... · · · w."""" .... "" · r · · ItImtolr .J. r:t. . ."" a..I'50 "" ...... · · ,. .... '!'!I""""I AnI U.i_rl:ity 10 '.lSO · ,."""" · CtlU. . . t'utiQIL '1'1: , ...... · · 1 .... ...... '0.5'50 .s_ :110 u.mt u.. rull.l't;l Clll'tabl,. ell!. co t:ba I:Ir lK;I""lnoi Gf , ..llin.g . . ooll ........ hooo Galll. . L~ ~ nlat~ 1mr III !I......l!:]' r- -wle t.o u.. .,."" bf t:bII hew tar · t.ll ud attu fOl: dI. 'Jrst chil'cy . - . i l ~.11 <U..~ ... 1aU.GI'I.~ 11 aft.c'bid th1.a I:.1JIi' toW :tar- agc., ~ froa tboo ~ of 'illa. "" ~ It. Wt.'UN of U. l'alllJlog abjlet.. ~ ~ U.tllJl publllMd · ......,1 . . . . . . . hlltalbm c..ll_ p,QII..Ul:)~ .. r,~'I:I.. ullIIlIl H11l1ltl . . . Gbta.UI.II! by ~ p:;ephlllud co.pul ..... ......... .u: .a ut.u. :evnaaar · .qh't tie 1nbI'.~tiDt ~J' ~~ wbkb . . . 'W1tb . . . .J1aU,f ttl 'M I:r;U: -u u.. ~ Uk9. if GIIIUIIQ cwl4 :Iwft UHd 1IIIIIt tM r.IliU .. .unt lbe S.lS S7R-. tM d!oft (flu1.t · ..""... :nat _1.1 1.1m.... ~ b _ !Ila 41roeeuy- ~ ~n:. IWX GUI 01' .AKIn. :IiJIeII thaN ~ .. _ltiJll,a 1IIIJIIPKi_ :1:111' ~ 1fIt~~ (corncU,y) ull not lIDrt5e1eno.~ H01""t~ 'IOJ. 5~ I n: QllU.., Pdlli.Dld l1'I 13, M. 0i:tcII:I.-' IDn~ pp. 5-Ot-5OIi. 42  .. ..... ..., coom<U·· '!'he PI'p9"". of t.bb t.at4rhc'l to h e.or. aMid_ill prop.!;U."" of t:'OIIt.rnt-·· so.& _:I.. .- _ t _ l y Ullm ~ ~. 'JC9IIP1 QI c.IU'.utS Kill of t:hII _ oi fift -.-.pl.. ~ UM.~-t:l. ~:\.~ t(ll' tIRt wittl '. t, ..."" S, thII ggett1c:latl ..1111 tr _ _t;., J....w:3 ~ ~La1 conttutl cal.ll11! o:",Sugi-89-07 Freund.txt
"ANALYSIS OF COVARIANCE; KULTIPLE COVARIATES Depa~bment ~nsas S~ate George A. Rilliken. of Statistics. University ., 'n P~t There are many experimental situat.ions whel:e ., morA than one covariate is measured on each <2l "" experimental unit. In these cases the model for ."" each treatment is Y1j - ""'1 + PnX Uj + P 12""21j + ··· + P 1k""k1j + '1j .;. j - l.2.~ .. ,n i i - 1,2 1 "" , ,t, (1) where X-pij denotes the -value of"" the pth ·, covarh. te on the ijth expe.rimental Wlit~ at '"" denotes the intercept of the ieb treatment's re~ression ~pi surface. denotes the s10pe in the ';"" direction of the pth covariate for treatment 1. and it is .assumed. that E ij I ~""ll!.·L ~ 2 j - lI2 ···· lni~1 - lI2 1 · · · l t are Ud N{O,IJ). The equation in (1) Is that of a k-dimensl~nal plane in k + 1 dimensions which is assumed to adequately describe the data for each trea~ent. Estimation 2 The usual regression diagonostics should be applied to each treatment's data to check for The lea$t squares estimates of the parameters model adequacy. The treAtm~nt v~rianC~A should of model 2 can be obtained by fitting the model be. tested for equality. When there was only one in equation 2 to the data as ~ (x'x)-~r~ covariate. the analysis of covariance consisted - or by separately fitting model$ t of comparing several regression lines. In the of the form ~i - Xi~i + ~i where multiple covariat6s case, the analysis of CQvarianee consists comparing several regression 1x 2i1 ~~~ )l;j,:f1 X planes or hyperplanes, 1 '1H1 x212 ~.~ """"IZ -, · 112 , r. = x There .are lIany forms these models can take on just like ~ltiple linear regression models. Y~n. , ;X:2:tn,"" ~ \.in., , K. 1in The models for ihe treatments could be a PQlynomial function of one independent variable Either way, the least squares estimate of is ~i aB 2 k -1 Y1j - ""i + .flUX1j + P i2 X1j + ... + PikXij + 'ij' (11: 1 '11:1 ) 11:1 :<1 · 11.1 - where the analysis of covariance would be comparing these polynomial regression models The estimate",Sugi-89-08 Milliken.txt
"o~ the set of' indices T = Here the sum ranges (1,2,12,3,13,23,123). The ma.ttices., V1'1 may be written Th-e pu..rpose of this tutorial is to review the basic in Kronecker product Corm as in Hocking (1985). concepts of variance component estimation with par- ticular refer"",,~e to methOlh available in SAS. In ad- A mixed model arises from (3) when we assume, dition, we shall introduce some diagnostic. ideas which for example, that factors one and two are hed and can he wed to examine the data and the model as- factor three .is random. In this case, the model may sumptions. These ideas will suggest a new estimation he written as in (3) except that the sum of the first procedure. Numerical examples .are used 10 illustrate four terms may be expressed as ui,~, the mean of the the basic concepts. (i1 i2)th factor combina.tion. (In c.ert.a.in a.pplications, .some oC the q,r may be assuIDed to be .zero as in the 1.",Sugi-89-09 Hocking.txt
"has been unavailable to many users beCause they did not know database concepts and terminology. Now the Version 6 SAS/ACCESS~ to databases while still L -Ia.l1 ~lDr Inter1aces provide transparent access maintaining the database security. This paper presents an e)(am- pie thatshaws how Version 5 SAS/ACCESS interfaces to data· bases provide users with database Informatioll. A new lIttikl~ Dnuiptv~1; , - .;:ruh .,rocedure, the ACCESS procedure, is the key to this process. ~ IC~...h· :5Il~ Vi""~1 - -JI>iD Ott-lblltl .cupl. fius ~ 3 UptI;d1 -III"" THE L & M WINERY \ - KmH !l3lMh 5 - puoho!<ll n-ett7 Pin""""o-. The L & M Wmery. wlth locatlons In 8M FranCisco, California and Cary~ North Carolina, has three master' files. A SAS data set -oon- tains- manufacturing and other basic information about the 10 wines it current~ markets. An IBM«l DB2"""" -database contains the results of a wine tasting extravaganza. Th'rteen jud9i'S were asked to taste !;tach of the winery's 10 wines and rate them trom 1 (highest) to 5 -in -each of three categories: taste, aroma, and ooor. Sates Information is stored in an IOMS/R· database. In the YOu will note that the :screen also allows the vintners to create future, the winery may have other databases or master files, or the- key to Version 6 access to da1abases. Another descrlptot8 - the currant mast&!' files may be migrated to another format. option allows them to create sal views. Descriptors are mem- bers of a SAS data set that are created by a new procedu",Sugi-89-10 McCrorie.txt
"view an image at all angles. For example, a statistician may want to interactively view a surface The use of high-level, three-dimensional PO) from several rerspectives before producing output, graphics modeling and animation systems has or a scientist may want to illustrate the interaction historically been used almost exclusively by of very tiny things like molecules or bacleria. A graphic arts and the broadcast industry. A new graphic artist may want to add depth and heighten wave 01 usage is emerging from several different, the impact of a slandard data-driven business relatively unrelated applications with a need to graph by adding a sense of depth, lighting, create realistic 3D images for visualization. With shadows, textures, and backgrounds. With true 3D, this technology, designers and engineers are able the user is no longer a painter of flat surfaces, out to promote a better understanding of ideas and a sculptor. processes. The",Sugi-89-100 Springer.txt
"SAS/Graph"" soflware through PROC GMAP and PROC GREMOVE provides an excellent way to produce choropleth maps for county, state, regional, or other boundaries. However because PROC GMAP draws adjacent polygons independently and as a resuh draws common segments between areas twice, it is not normally possible to choose different line types such as a dashed line for state boundaries, a dash·dot--dash pattern for intematlonaJ boundaries and so forth. This paper will explore the combination of PROC GREMOVE, PROC GMAP, and the SAS annotate facility to produce US regional maps with state boundaries drawn only once in a dashed line type. The technique will produce maps closerto what cartographers prefer, Figure 1 A typical PROC GMAP output and it can be applied to any regional type map.",Sugi-89-101 First.txt
"A SAS' Look at Geogtaphic Information Systems Steven 1. Subicllln. Miller Brewing Company What is a Geograpbic Types of Mapping Systems Information System (GIS)? · Geographic Information Systems (GIS) - Analytical A system that displays geographically based data upon · Automated Mapping and a map for interpretation and Facilities Management decision-making. Systems (AM/FM) Not everyone agrees on what a · Computer-Aided Design ""true"" GIS is. Different Systems (CAD) - Detailed functions meet different needs. Maps · Resource Management Systems 1\ Apnll989 Pg.20f22 II April 1989 Pg.3of22 607 What differentiates a What distinguishes the GIS? Geographic Information System from simple mapping? A GIS will allow the map itself to be used as input for the next A simple mapping system data or graphic request,ie show integrates data and a map to me the highest per capita produce a ""statistical map"", e.g. income in those states by U.S. Map shading states with county. more than 10 million people) The output map becomes the The map is the final output. input for other data requests. Pg.4of22 \I April 1989 \I Apnl1989 Pg.50f22 60B  GIS Issues What makes up a Geographic Information System? · Costs · Databases of information map and data storage (e.g. demographic) keyed by geography. technology · Maps to match your system development geography (i.e. county maps, zip code) system maintenance · Software to manipulate the · Display CRT's, Plotters, data and the map for display. Resolution, Quality, (i.e. SAS* System) Hardware/Software · Some ""intelligence"" to · Functions classify data intervals. · What useful purpose will a GIS serve? Pg.70r22 Pg. 6..e22 II Al""il 1989 11 Al""iI 1989 609  GIS Functions Advanced Functions · ""Cut and paste"" data based graphic options i.e., · Ability to statistically inquire population within a ten mile different map levels of data a radius of a city. · Create statistical map · Mouse-drawn boundaries or indexes i.e. Wealth as a function of income, cursor",Sugi-89-102 Subichin.txt
g package is 10 dis· X Y. ~ ID play data geographically. Mapping is a powerful presentation format in that the results of analyses NY dependent in geography can be conveyed in a -0.16911 0.271997 36 visual rather than tebular format. However. maps -0.16864 0.271322 NY 36 are olten ove~ooked as a presentetion tool be- -0.16894 0.269488 NY 36 NY cause they are difficult to create. -0.16904 0.267882 36 . (etc.) The original AUTOMAP system was developed and presented at the SUGI-1984. It has U.S. and . world mapping capabilities and was used by The response data set contains the ID variable and analysts at Eastman Kodak Company to display the variable to be mapped (the response variable). sales terrttory dats and the results of consumer For State/County maps the ID is the F1PS code; surveys. World maps. the ID is pre-assigned in the SAS Wond Map Data set. The system required knowledge 01 SAS and specific answers to prompts. Alter training. ana- lysts were reluctarrt to use the system as it was Response Data Set: Sales Tax by State difficultto rememberthe system requirements. J.Q SALESTX STATE Now converted to SAS/AF®. the system allows greater flexibility lor users. A novice with no SAS 36 NY 0.07 experience can produce complex maps. 37 SC 0.04 38 ND 0.05 Automap is a user-friendly front-end to SAS/Graph 39 OH 0.06 Proc GMAP. It allows the user to create U.S. State/County and World/Regional maps. This paper discusses the components of the system: · Create a Map Response Date Set,Sugi-89-103 Johnstone.txt
"ENHANCING TIlE VISUAL IMPACT AND ClARITY OF GRAPHICS OUTPUT USING TIlE CUSTOMIZING POWER OF THE ANNOTATE: DATA SET Karen lacy Helsel The £AS/GRAPH · ANNOTATE: data set is the most It is obvious from this example that with any powerful and flexible tool available to SASjGRAPH significant number of observations it becomes programmers for customizing their graphics output. virtually impossible to determine which symbol Through the use of this feature, graphics output identified in the legend refers to which line. can be made more readable as well as more explanatory in nature. The ANNOTATE: data set One option fully available without accessing also allows presentation in the exact format an ANNOTAT£# data set is the suppression of the desired for an application when the default format individual symbols, thus plotting only the lines may be inappropriate or inadequate to fully themselves~ However, a more complicated example describe the data in the manner desired. where there are numerous lines of similar line The examples presented herein are designed to patterns renders this option less than successful. introduce the programmer to the basic features of Also, if one is constrained to a monochrome the ANNOTAT£: data set. They also offer a environment, such as publications, offering sampling of its diverse capabilities within the different colors is not a viable option. context of the enhancement of the default output The graphics output of Figure Ib is only one of certain procedures, namely PROC GPLOT and PROC of the many possible solutions to this problem GMAP, although the techniques presented can be using the Annotate: data set. Plotted here are applied to any SASjGRAPH procedure. All of these lines with differing line patterns which have been applications use the actual data values to ennanced through the addition of descriptive determine details such as the placement of labels, labels at their endpoints. labels such as the and the text they contain, so they are da",Sugi-89-104 Helsel.txt
"YOU TOO CA1II PRODUCE AND CUS'l'OHIZB COHPLEX GRAPHS USING THE ~ FACILITY AND THE GSLIDB PROCEDURE Wlm RELEASB 6.03 OF SAS/GRAPH,a. SOF'l'WAlU! Ron Lovel1 J New zealand Department of Sooial Welfare The more complex graphs were quite tedious to Several years ago I developed a hand draw as some of them have several hundred low-key statistical report ser_ outll.ne ies for annual publication which data pointe to plot and the plot had to be begun of the on A3 sized paper then photo-reduced a number of provides a five year moving win- G.rapb.icu times as different layers of l""abelling were dow on New Zealand juvenile ""ask typed on. offending statistics. The series presents each year's statistics By the time it had been on juvenile offending in an accessible format so that those with an interest decided to convert the Why Use in them can readily see whether, relatively graphics in the report for SAS/GRlU'lI and machine production, the speaking, the latest fiqures from the Department Why of Social welfare$s operational statistics Department had acquired a Release 6.031 represent an increase, a decrease, or some other number of packages offer- change in pattern over those for previous years. ing aome form of gy:rhics software. Symphony and Open Access!K) were available on PC along with Quite different pictures emerge when one looks~ the dedicated PC graphics packagee Harvard\A} say, at court appearances for different aqea, at Presentation Graphics and Microsoft tR ) Chart~ appearances by boys, or by girls, or by Maori youngsters as opposed to non-Maori ones. There About to be installed on our graphics PCs was Release 6.03 of SAS/GRAPHfR ). is interest in change over time as well as in relativities between these groups, so the task As a researcher, all the graphics work I had of presenting an overall picture in a compact done had been PC based and of one of two types: and accessible way is not as straight-forward as it might at first. seem. ~ick on-soreen graphs a8 an analYS",Sugi-89-105 Lovell.txt
"100 X 100,130 TITLE ,"" project management-at-8-glance con-capt The was developed to provide a communication graphic which could ."" visibly provide the managers of several departments with an overview of all active projects. All the major 'milestones are predefined tor simplicity. The detail "" between the milestones was also eliminated for clarity. The chart was designed to show multiple projects in a compressed format. Eight projects and 12 milestones can be shown on each page of Ihe chart. The Base SAS® package was utilized as the programming "" tool. The SAS/FSEDIT® product was used for dala entry. The data for the report was stored in an IBM TSO sequential "" flat file. SASIGRAPH's@ annolate tools are used to create "" the layered project management chart. The SAS system was chosen because of its strong ability to handle dates and custom generated graphics. '"" '""130 Y "" 0,0",Sugi-89-106 Anderson.txt
"The compiler implemented the C language as described in the This paper describes the major features of the SAS/C® compiler then definitive book on C, Kernighan and Ritchie's The C Pro- and library and discusses the development history oftha product. .gramming Language: Because the compiler was implemented for The enhancements in the current production release are outlined. IBM 370's, it included many features that were thought necessary Some possible enhancements for future releases are described. for that architecture and for programmers who were used to working In that environment. The foliowing list describes some",Sugi-89-107 Hunter.txt
"orithms 3 and 4 are tile new indexed algorithms. For each If your programs are written in C and you use the SAS/C® com- switch encountered in the source file. the code generator ana- piler. there are a number of ways to make your programs run lyzes the size and execution time that would result from each faster. This paper addresses ways to generate more efficient method and chooses the best method. For switches with a small code and then discusses how to use ClIO efficiently. number of cases. one of the first two methods will generally be used since the overhead of table lookup is not justified. For a IMPROVING CODe EFFICIENCY larger number of cases, one of the indexed algorithms is used for aU but highly sparse switch statements. However. these algo~ rithms do require one table entry for each value in the switch Use the Global Optimizer range (the difference between the lowest and highest values in case statements). Thus, it is advantageous for you to reduce the One of the easiest things you can do to improve the effICiency range of your switch statements if possible since you can save of your C code With Release 4.00 requires no code changes at a lot of table spacetllis way. If you have one or two case values all. Release 4.00 01 the SASfC compiler includes a Global Opti- very different from the others. you might' want to test for them mizer that performs optimizations such as merging common sub- separately or handle them at the de f aul t label {which is not part expressio",Sugi-89-108 Bradley.txt
"CHARACTERISTICS OF SYSTEMS APPLICATIONS Traditionally. systems programming for the IBM® 370 has been Categories of Systems Applic.tion$ performed using assembler. This is because systems applica- tions require a language that provides efficiency, control over the Traditionally, systems programming for the IBM 370 has been environment, and access to. system data. and sefVices. On UNIX* performed using assembler."" Because there is little literature or type operating systems. the C language is the systems program~ training available on writing systems applications, it is useful to ming language because C has features that make it suited to sys- attempt to characterize these applications. The following catego- tems programming applications. With the development of C ries of systems applications can be considered: compijers for the 370 environtruJnt. it is desirabie to write 370 sys- · exits from operating system components, such as VT AM tems programs in C in orderto gain the programming and mainte- or JES2, or from other software, such as RACF or ISPF nance benefits inherent in a high-level language. This paper addresses using C for 310 systems programming applications, · extensions to the operating system. such as user the problems involved. and some possible solutions to those supervisor calls (SVes) or new eMS commands ' problems. . · low~level applications, such as shared file servers or performance measurement toots, which require direct",Sugi-89-109 Ammondson.txt
"more knowledgeable in thia area. rhe fallOWing PROC AOBEXT example extracts the personnel number of each employee cur~ There are two new interface products for Version 5 users, renDy investing in collectible automobiles. SAS/ACCESS'lnterface to ADABAS· and SAS/ACCESS· Inter· face to DATACOM/DB"""" _These interfaces give vser.il an easy An easy method of getting acquainted with PROC ADBEXT is to way of retrieving information from ADABAS or DATACOM/DB execute the procedure in full-screen mode. A series of panets Is and using the SAS· System to do analysis, ""'Porting, and grapi1s used to prompt the user for information about the data extraction from the DBMS data. The procedures provide a way to automate process. Elltering full-screan modoa can be accomplished by the extraction and analys18 of DBMS data as well as a way of pro- entering viding ad hoc information. p~O-c: Ildbe:lt; rV:liI;",Sugi-89-11 Franklin.txt
"is incompatif?le with loadm, but you can initialize a standard C function pointer and then assign its value to the ---ilsm pointer. The SAS/C® compiler provides a productive programming envi- ronment for the development of effICient C programs. Together Calling programs in other high 1evellanguages from C is another with the IBM® products ISPF and DB2:"" the application developer useful SASIC extension, for Version 1 of 082 does not support has a powerfUl combinaUon with which to deliver interactive user C as a host ianguage. However, the examples in ""this paper fOClJS dialogs and SQlno database applications. For the future. SAS/C on using assembler as the host language. The advantages of and Systems Application Architecture"""" (8M) expand the poten- using assembler are that the communication of structures tial 01 these products' by enhancing the portability of applications between the C main procedure and assembler routines is developed with them, straightforward and that a SASjC tool is available for translating assembler structures. known as DSECTs, to C structures.",Sugi-89-110 Hayes.txt
"hat would be better spent expanding the features of the SAS system for our current users. This resulted Version 6 of the SAS@ System has been success- in 'delays between the same version of the product fully hosted on a wide variety of architectures. In shipping on various machines. One significant rea- order to. accomplish this feat} SAS Institute has es- son for the delays was the necessity for each host to tablished a general philosophy of devdopment along know in-depth what pieces to put together in order with some specific guidelines to ease certain prob- to construct the final system. lems that have occured during the-development ef- fort. Another major problem was the lack of a stan- dard version of PLjI for all the machines. Even This paper describes the basic approach. taken in though there is an ANSI specified PL/I Subset G this effort. Specific topics to be addressed include that we attempted to follow, many of the compil- limitations of C compilers and the C language} ex- ers lacked certain features or implemented a feature ploiting machine features, multi-ma<:hine product differently. In addition, the PL/I language is inher- confignration1 and a general overview of the sys- ently -machine dependent in its specification of data tem layering. Special emphasis is given to how the types based on numbers of bits.. Lastly) many new SAS System avoids a ~least common denominator' machines were being introduced that did not have a approach to hosting and in'stead is able",Sugi-89-111 Toebes.txt
"Conversion of Running SAS® Software from OS to VMS~ on a Local Area VAX~ Cluster M. Gary Haskin & Ronald L. COpp A B S '1' RAe T data entry screens under SAS 82.5 were no IDore than ordinary SAS datasets which could be read by any normal SAS program. These recently ""normal It datasets were converted to transport Boots Company has The format, shipped to the U.K. installed a local area VAXcluster for the over the link, entry and statistical analysis of clinical and ""imported"" as any other dataset. The This system features a relatively data. SASjFSP0 procedure FSCONV Was then used on the larger system to convert the catalogs small host node with the SAS system installed only on satellite workstations (VAXstationN simultaneously in to version 5 form under OS. This operation was only possible for catalogs 2000's). This paper presents the experiences in the pre-version 5 format. In all, over in designing and establishing the VAXcluster thousand five hundred files of SAS two and the benefits which have arisen from it. programs, SAS datasets, and SAS screen Some problems and solutions in transfer~ing SAS datasets and data entry screen catalogs catalogs were converted to run on the OS system. over a transatlantic data link and conversion from an IBM to VAX environment are discussed. After six months of testing, it was determined that while the link performed well for infrequent file transfers and short~term ***************************************** interactive computing sessions, reliability for day~to-day work on a continuous basis was Response time was not a not adequate. problem for the data entry personnel using subsidiary of the Boots The U. S. SASjFSP since they were entering data in Company. FLO in 1985 performed all of its screen units. Statisticians and programming statistical analysis using SAS on a relatively small IBM 4381 system operating staff, on the other hand, were spending most of the time in text editors preparing SAS under eMS. Clinical data entry and an",Sugi-89-112 Haskin Copp.txt
"CMS SAS software Development. This paper describes a CMS REXX nThe SAS companion for the CMS exec for the SASe System using the Operating System.... 11] describes VM Batch Facility. The VM Batch several methods to develop SAS Facility allows a job to execute in applications using VM/CMS. Since batch mode on VM/CMSfreeing the SAS version 5.18 is still basical1y programmer to develop other pro- a batch orientated system on CMS. I grams/applications. will describe the .... traditional"" way to develop CMS SAS application. The :",Sugi-89-113 Gleason.txt
"SOFTWARE CONVERSIONS (WITHOUT ULCERS!) By Judith H_ Mopsik, ARC INTRODUCTION The third type of conversion concerns the development of an application using PC/SAS and then The challenge of converting current SAS'"" production applications to porting of application to a mainframe or new hardware and software platforms, as minicomputer environment- for production runs. Thi s approach has been we11 as to the new vergiQn 6 release of demonstrated to be very useful since the SAS system, is now upon us. W':'1ile development costs and time are some SAg production systems have already considerably less on a dedicated been converted from version 5 to version microcomputer than On 2. shared, 6 on the PC. the majority of SAS users are still r-unninq mainframe and mainframe system. Since version 6 has many new features that the current minicomputer applications under version This paper will present approaches 5~ mainframe version 5 does not support, a for successful1.y meeting the conversion program that has been fully tested in challenge. PC/SAS will not necessarily run successfully on the mainframe. OVERVIEW A fourth type of conversion takes place when a production system is moved to a new- machine. This has always been The most common conversion situation will be to move current a cha11enge to computer programmers. applications from version 5 to the new While the version of the SAS system may not change. the operating system version 6 of the SAS system on the same computer, under the same operating procedures, system editor, and system While this appears to be the system. naming conventions do change, and this easiest transition to make, three results in a major conversion effort that may be difficult to estimate in important questions stil.l need to 'be addressed: terms of resources required to complete Such the job on time and within budget. o How do you approach the an ""opportunity"" was presented to the conversion in an orderly ARC staff on two occasions this past fashion?",Sugi-89-114 Mopsik.txt
"separately and to sequence. The next figure shows the structure of a typical modular system, !n which a main routine controls sys- ,he fult macro facilitv provides SAS® users with an extremely tem execution and calts the appropriate subroutines: powerful programming tool. It allows for conditional execution of. DATA and of PROC steps. creation of parameter-driven appliea- . tions. pas~ng SAS variables across steps, and much more. Unfortunately, the full power of the macro faciUty is not available I in some operating environments. These programmers need not I I MAIN I ROUTINB 1 despair. SAS code can be wrltten to simulate SAS macros using base SAS software available on all operating systems. This paper pres';iits an gy;:a::r:ple of e. SAS macro-based sy~tem developed in a VAX'"" environment and draws some c.oncit.!sicns ; on how SAS software. used as a programming language, can be lSUBROutlNEi ISUBROUTINEI lSUBROUTINE! just as powerful in a partial macro environment as it is in a full I I I I I I macro environment.",Sugi-89-115 Septoff.txt
"g environment fa.ced by the uset of modern networked workstations. This paper 'Will describe some of the implications of the Over the next five years there will be a marked networked environment and how the SAS System movement toward distributed and workgroup based can be adapted to take advantage of this trend. computing. The economies of scale offered by net- worked workstations ensure that they will become Distributed Data Processing (DDP) is a set of the preferred method for software develQpmcnt and teehniques for off-loading processes from a central- ized processor to satellite processors. It is hased computing in generaL Large centralized proces- on the communication of data and process control sors will continue and even grow in use, but as re- sources available in a network as opposed to classical information hetween -processors. This technique is generally used when there is a need for geographi- time shared uses. Prototype development 1 ad hoc queries, and highly interactive applications will be cally separated users to have their own computer re- 'moved to the workstation, leaving the larger ma- sources. Distributed computing is characterized by chines for compute-intensive and high-volume I/O many proeessols connected by a network, and can applications. (Examples are large simulations and be based on either centJ:alized or decentralized ad- transaction processing.) ministlative conbol. The networked environment is hased on DDP techniques. Most of these techniques",Sugi-89-116 Zeigler.txt
"The MVS Data Library has been completely redesigned to support the I/O access features of the Version 6 SAS System and to improve the Host interface to MVS Data Management facilities. I/O device independence, multivolume Library support, and improved DASD space utilization and I/O performance are all provided by this architecture. The new Library structure is designed to be consistent with IBM's direction in System Managed Storage as well as providing a platform for future MVS SAS data management features. This paper will discuss the new architecture and provide examples of how it overcomes limitations in the existing· MVS SAS Data Library implementation. NOTE This document covers the Version 6 MVS SAS Data Library design. Some of the capabilities presented may not be delivered in the first release of Version 6 SAS Software for MVS. Such capabilities will be noted as they are discussed.",Sugi-89-117 Bowman.txt
"fIRST TIME USER EXPERIENCES USING THE SAS/Ce COMPILER Keith A. Carter. OClC Online Computer library Center. Inc. Klln.II_,nn ""t""lU"""" Abstract: 1:01I1'1I:U""""11011- aI!CTIOI!. 'f-M·.'"" . $o"".e~ -et''''IITIliIll;. l ... · .. ~., Thts paper dtseusse$ first time l,lser expe- o.""e(:', eO""""lI:ftll. 1tI""\ilT-OUTI'IIT SECTIQII, riences on the IBM ma1nn-ame. The apectftc 1'1.1!-1:""""TItO~. ltI""eaa that wi 11 be covered are: l_Q·CIINTliOl. ............. ...........""'.. IIAT ... OJ'I'I$IOII, ""'IUt SfCTl(I"". l1nklng Mult1-1anguage programs n . . . . . . . . . . . . . . . ., ··· u .~.H ~ Us 1ng trut $A$lC Oebvgger UII~""C. :U:CllOll Ollltt"",UtIOll a.'u ........... a.u . . . . . . u u .............. . ··· & ..... ~ ···· Dpt lmtzat ion ll""""""""f 1l.QTlOIi. Par-t1ng code and ANSI C Standards 7'7 .,,""""Ill I'll: ~121i). 1'''lIe.ou'', VH'UlII"" vlnc .u"""" ·· , '\:I01-111-U"",,& ·· on"",IIov ·COBOl: A1""IRIIo.~T WIH! IIotTl!flWIIoT£ CASI!, .""""all '.a, Clll!- -t;!J.~C· IIUIIC; ...... .u ..,a"" 1 lmklng Ml.l!tllanguage Programs OIS""~AV »COIIlH, Al .... A · · T wITH A~~-U"""" ·· CAsl!> .""-I!U1. CU'"" """"OIl""AM. Uuge of the JNDep option: The INDep compHer cpt10n he two U$es; fll-lSt (stola.K) 'tJtClu~& Is to allow C code to be called directly IIIMCUIO. (C1V'I!.ij) IOIIICl""O': (sTII11 .... ) fran other h1gh~level languages, Seeond. 15 J.T 1;011l:(ca'""!!l:-j to allow C code to exeelolte in the abnnee of COlA"" .CO.IlI!C, of the C runtime llb~a~y_ If,T . , ,.-j; calll~ .... IHUq-.""TflV .. alln 111 - Compl1e all C code that may be called from · 0, CIQ.It£cq:: I '( .. "" "" <\0' ; the other language with I~p and l1nkedH ,++) !> normally, whether- the function is named callt!!e(ll:! · le""u} Tau""PI!.,cDlltl!cljllll, malnO not. ""OIl! Of"" PRUIT'(-I!XIT .. 01llT .. CDI,C '''""I: , UT""'Il~lot; e code compl1ed wtth INDep can be called .*........ C COMPILED vCl ............ frem FORTRAN, COBOL, PlJ, or any other language that uses standard IBM linkage U""""It""""""TI~"" conventions. 11-1111"":'''''0 "". l/~ .>IlL ""0110 l: SOVIt",Sugi-89-118 Carter.txt
data library engines that create and access data in a format that is maintained by SAS institute. Examples This paper discusses the concept of the data library engine as of the native engine are the base engine and the it relates.to applications in Version 6 of tile SAS® System. The compatibility engine. The base engine is the default structure of the Multiple Engine Architecture (MEA) is described. engine that is shipped with a partiCular release of the The data library engine is examined. with emphasis placed on the SAS System. The compatibility engine is responsible types of engines and examples of their use. Special consider- ations are made in relating these topics to the eMS environment. for acceSSing an earlier form of SAS data sets. Also discussed is the,Sugi-89-119 Page.txt
"Designing a Full-Screen SAS' Interface for Your IMS Database Eric Brinsfield, SAS Institute Inc., Cary, NC The sample CLtST in Figure 1 shows the minimum f6Qulremeots INTRODUCTION lor starting the SAS System, SASIDMI software. and SASIDU software. The aflocatlon requirements will diner, depending upon With \he SAS/IMS-DUOinterface, you can access your IMS data- whether any of these libraries are in linklist or not. This example base ..ing Ihe DATA slap or PROC DUTEST. Using Ihe DATA also assumes that the SASJDMlload modules are in the SAS load step. however, offefs the' programmer more control over the ILbrary. To minimiz~ the &iZ6 of the CliST for tills preseEltation, i01\eracijon """"tween \he SAS system, \he iMS systam, and .he symbOliC variables are not used extensively. Note thattlle alloca- end-usef'. In addition, the DATA step Interface to the IUS system tions for IMSACB and IEFRDER are to a DUMMY data se\. Ch_ meshes Willi with SASJDMIO software, the DATA step interfaC& with your IMS DBA for instiuctions on these allocations. 10 ISPF. Within a single DATA step, you can read and updale an IMS database and slmultan..,.,.1y pIQmj>l\he user .. th ISPF pan- els, whfle utHiling tempotary or permanent ISPF tables. DEVELOPMENT TECHNIQUES This tulorial demons"" ..... how SASJlMS-DL/I, SAS/DM!, and Tha axample CUSTs (DMICALEN, DMIDEMO, and SASDMI) .11 SASIAFO software can work togelher to provide an effective full- start the SAS System and immediately 9)c9CLlte a SAS program screen apptication for use with IMS databases. You learn when to place you in a particular application. When d91Jeloping appltca- 10 use SAS/DMI or SAS/AF oofIware and how they compliment tlons or learning, however. you may want to start in the display aach othar. You also see how to begin devek>pment with manager. To do this, can program SASDMI without providing any SASJDMI. software and how to us. ~ with the SAS Display Man- souroo input, as shown in the example CUST in Flgl,HfJ 1. The ager System",Sugi-89-12 Brinsfield.txt
"Cary, NC A conventional _program is usuaUy involved with data storage, ABSTRACT COO1putation. and reporting. It is difficult. if not impOSSible, to understand the logic of a particular application by examining the This,paper is a 'general survey of the field of Artificial Intelligence code alone. (AI) and concentrates on basic AI techniques, expert systems. and natural language processing. It begins with a definition of Al An AI program, however. usually has a definite separation and compares it to conventional data processing. A few,of the between a set of rules (knowledge base) or generaltogical state- various application areas using AJ techniques are discussed and ments and a processor or engine that operates on those rules. methods of representing knowledge and reasoning -using that lhiS separation provides a means by which the ""how and why~of knowledge are Introduced. Some of the tools and problems asso- tM' operation of an AI progr.am can be presented to the ·user. AJ ciated with AI research and development are alsO discussed. programs also typically deal with implicit, incomplete. and -noisy data whereas a conventional program operates with explicit and This paper emphasizes those areas of At that are currently under complete information. investigation at SAS Institute, particularly the research effort that will culminate in SAS/EQL'"" software, a natural language query system that enables users to access data using only English. AI APPLICATIONS The field of AI, which",Sugi-89-120 Malkovsky Maxwell.txt
"Pan-Yu Lai, The Upjohn company knowledge-based expert systems t have been INTRODUCTION developed extensively and successfully in many areas such as lUedioine t chemistry I geology, and mining. statisticians and non-statisticians currently have a fairly large number of The British Society's reliable, powerful, and well-documented Computer special~st Group has proposed a formal statistical computation packages to definition as: choose from and SAS system is one of them. It not only provides very extensive An expert system is regarded as the statistical analysis procedures with embodiment within a oomputer of a explicit outputs but also offers complete knowledge-based component, from an data management tools. Owing to its expert skill, in such a form that powerfulness and user-friendliness, SAS the system can offer intelligent is becoming one of the ~ost popular packages in both industry and academia. advice or take an intelligent Anyone with some experiences in SAS and decision about a processing function. A desirable additional a set of manuals oan use the system to characteristic, which many would analyze data and produce the final fundamental, consider is the statistical report without knowing much capability of the on system, about the statistical concepts in the demand, to justify its own line of procedures. But without thorC?uqh reasoning in a manner directly understanding of these procedures, there intelligible to the enquirer. The is great risk on inappropriate analysis and consequently wrong inferences. One of style adopted to attain these rule-based characteristics is the alternativQs would be seeking he.lp programming. from statistical consultants but it is costly and they are not always available. It says all of it but I like the shorter So it would be the best if we can definition proposed by Max BraMer: incorporate statisticians' expertise into programs and develop a statistical expert An expert system is a computing system so that the users can be guid",Sugi-89-121 Lai.txt
"arch otdinary production systems., the antecedents of rules are fulfilled when Abstract a consistent mapping is found of facts in the global data base to the ~ressions constituting the antecedent. The rules are of arbitrary Classifier systems are parallel, rule-based machine learning systems. They are one member o-f a broad class of adaptive systems length. can have considerable internal structure, and are-capable of that includes neural networks. economic systems, and ecologies. Such eipressing negation, and complex Qr- and and-ronditions. In a simple systems invulve a lafge number of diverse units that interact both classifier system. on the other hand. a rule is a word two times the competitively and cooperatively and that change over time so as to length of a m~. The first half of the rule is the antecedent and the adapt to their environing conditions. Oassifier systems have been second half is the consequent. The rules are words from the alphabet used, with varying success.. to model the induction of expert knowledge {0,1.#}. '#' is refered to as the wildcard symbol. required to regulate gas pipeline transmission, discover scheduling heuristics. and model idealized animal populations. This paper is an The inference engine or control system has three essential introductory discussion of classifiel' systems. It briefly discusses their constituents. (a) a matcher. (b) a ftIter. and (c) a rule executor. In stmcture. inherent problems, and Stltne alternative approaches: to pr",Sugi-89-122 Lutomski.txt
"decided to combine all the contractor information. oreating the Contraotor Information System. We found the best way to control this system was by using This paper preseots the Contractor SAS! AFQl! The SAS/ AF menus make the Information System. a menu-driven computer system easy to USe by both the system system for the United illuminating Company, administrators and the users. an electric utility located in New Haven, Connecticut. Too System integrates the UI Contractor Insurance System. a PC-based THE SYSTEM Expert System using VP-Expert<l> (an Expert System shell) and dBASEIII PLUs<!>. with the UI Contractor Rates System. using the SAS<I> The Contractor Insurance System is a mlcro- system. This system provides an easy based system. It consists of two parts, the access to all authorized personnel for expert system and the database. An expert coocking the contractor'. insurance coverage system is a computer program that is and current billing rates. The interfaces designed to capture the knowledge and between these three technologies show that decision making capabilities of an expert and Expert System and database technologies make this knowledge available to others. Our combined with highly interactive systems built expert is the Direotor of Purchasing and with fourth Generation software such as the Stores. The knowledge that is in our eKpert SAS system. can be effectively employed to system is tOO amounts and types of improve productivity. insurances. The specific amounts needed depends on the types of work to be done by the oontractor. VP-Expert is the software",Sugi-89-123 Lawton.txt
"Tony Lewis, lIAGA GOAL: During the analysis of each eogagement, it Management Assistance Corporation of America was desirable to have a single code, from which (MACA), in contrac t work for the United States it would be possible to describe the entire Army Air Defense Artillety Board at Ft. Bliss, series of occurrences within an engagement * Texas, has been using s.AS'software to automate While it was always possible, using a series of the scoring of air defense weapon tests. if-then logical statements, to retrieve Weapons testing, and the scoring of such test- li.ke-circumstanced data from the database, it ing, operates under a highly complex set of rules set dowo by a myriad of Army agencies. was also cumbersome.. In order to circumvent In addition, testing agencies are under heavily this, the practice was to have the analyst who enforced deadlines to produce reliable scored had examined a particular presentation assign a results for each weapon test.. Development of result code to it, known as its ""score."" Thus: a code of ""oc"", for instance, might mean: automated scoring techniques has often been t_ attempted in more traditional languages, but these had proven to have excessive development ""system detected target withio required and insufficient flexibility for use in a raoge using radar, tracked him to wi thio engagement range, correctly identified tightly regulated testing schedule. him as hostile, tracked 'With infrared. and fired while the target was inbound, To re801va these problems t MACA and the Air Defense Artillery Board used tre FORMAT procedure but intercept occurred after the loss of a defanded asset."" to turn the progranming of long and complex sets of rules into simple table lookups. The trouble with analyst assignment of these codes was that a certain amOtmt of interpreta-tion JW:KGROOIlD: invariably crept in, and some mistakes were made. It was necessary to automate this process to Air defense weapons tests are usually avoid inconsistency. diVid",Sugi-89-124 Lewis.txt
"Data gathered via scanners is processed by Nielsen and others for resale to interested processing of Nielsen Scantrack data gathered on clients. Vendors of scanning data, generally offer items sold in stores using laser check out scanners. This information can be very useful for it in various value-added formats including aggregation across brand names, markets, and marketing research. store chains; typically including fnformation relating to advertising activity. As delivered, the data is in the form of a hierarchical file on tape. In order to manipulate the data for analysis, relate it to other corporate This paper deals with Nielsen ""store level"" data data, and handle database functions, such as which includes item sales and advertising backup andupdate, an application was developed information by store within market areas. The data is provided on tapes at 4 week intervals with to transform the information to a relational all information aggregated by week. (table-like) format usingSAS software. Data Format The overall process and techniques involved are discussed along with hierarchical-to-relational Scantrack data is delivered as a hierarchical file. transformations in general. In this case hierarchical means· that the file consists of several record types. Data fields on What Is Nielsen Scantrack Data? differing record types do not necessarily have analogous meanings and many record types have Scantrack data is gathered from retail check out unique field layouts. As a s",Sugi-89-125 Miron.txt
"FUEL FOR THOUGHT Application Developmmt Using SAS® software: A case study Bruce Leister,- System Development Officer, Corporate Transport Departmen~ State Electricity Commission of Victoria. - Background interface, as well as its 'quick' user The Stale Electricity Commission of Victoria operates a large mM response compatible mainframe, with TSO as the main operation system fur 'mall appli_. There ... approximatdy 1,000 TSO ...,.., The driving progmns behind ISPF PL/I & CLIST: Pl/I was used for its speed of cxeQ.tion SAS "",ftware has been used ""idUn die SECV .in<:e 1981 for end- user computing, prognunming 1001, and eapacity planning. AU the above tools a110w easy cloning of code, thus reducing A number of small systems have been developed over lhe years ~ development time. either as prototypes, or as final systems. utilising SAS software as dIe main dala Jll'OC""S'ins language. Prototyping is also easy, as the screens can be designed, coded and WRS Work Reponing System conftrmed while the proces~g code is still on the drawing board. A project _Idng task aJJocation and timesheet recording system, used internally 10 Information Sy...... Dept (ISD). The system is slruCtured around ISPF menus & functions which either submit a batch SAS jot to perform processing or clisplay a Information Sy""""ms Department's COO ReportiDg Sys_ EO report -dataset or ISPF table (output from a previous SAS job). Collects information on services provide to clieClt departments. pmduces ""'PO'"" and _ersJ!le data 10 die genera1ledger for chargmg. The SECV uses a datil dictionary of aD data elements. screens. and files. thus all stored variables are of the fonn D15205. etc. which is Interim Purchase Order System IPO meaningless without the c.orresixmding dictionary. Some of'the A system 10 automate and speed the generation of purchase variables used are listed below: orders throughout the SECV. SAS software is used in the report/order generation only. D15206 - transaction' unit price D15205 - pro",Sugi-89-126 Leister.txt
"CLARIFYING HIGH-VOLUME SMF DATA FROM MULTIPLE DATA CENTERS TO PROVIDE CUSTOMERS WITH MEANINGFUL INFORMATION Linda Sampey - GTE Data Services, Inc. FOREWORD In this paper, , will frequently be using the word ·procedures, and the old system was unable to handle 'customer"", while meaning three distinct groups. I this. It was decided to purchase a system to process hope the meaning will be clear by context. Here the SMF data, and build the other portions of the are the three: Mainframe Billing system around it. After evaluation, we purchased the MICS system from A Since most of this paper concerns the GTE Data Services Mainframe Bilflng system, what was then Morino Associates (now Legent). and ""customer"" first means our Revenue decided to run it centrally, In the Tampa Data Center. Accounting department. This customer is our The SMF records are now sent daily to Tampa from Program Office, our daily contact, the sorce of the other data centers, and a daily network executes all good data, our nemesis, and our partner in upon successful receipt. This networK contains the the continuing enhancement of our jobs that edit, sort, merge, collate, rate and audit the billing systems. billing units, and produce datasets. The monthend jobs handle aging of the files, error correction, B. The second use of the term customer covers proration, and combine the data from the nine data centers for biUing. all of the Intemal departments that use the data that our system collects. They are customers for whom we provide reports, OBJECTIVES special datasets and flat files, and look up odd bits of information for special requests. The major objective of any billing system Is, of course, accuracy. While implementing this plan, we had two C. The third use of the word customer is in the secondary objectives in mind: most traditional sense: the one to whom we assign a numerical identifier, the one whose 1) using the most efficient techniques for the name and address is placed in our tables, quanti",Sugi-89-127 Sampey.txt
"Expectations for a Fourth Generation Language Darius S. Baer, IBM Corporation Abstrad grew out of a desire on my part to understand why I found some software tools to be very productive while others caused me great pain and agony. A fourth generation language (4GL) is identified by Shouldn't we, -as users, have some input as to the ils ability to provide fronl-end processes for the types of languages we use and how they will work? end-user or programmer who needs facilities for What can we reasonably expect trom a computer data Inputtoutput, data management, report presen- language to best meet our computing needs? tation, graphics, or statistical analysis. These proc- esses are often compiled procedures and functions Users of computer languages often do not think that are invoked when needed by the user. The about the expectations they have for that language extent 10 which the services and facilities are sup- until iUaiis to meet one of those expectations. This plied by the 4GL differentiate it from third gener- paper will address the expectations lor components ation or high level languages such as COBOL or of a ,fourth generation language (4GL) in order to FORTRAN. These services and facilities allow the assist end-users, data analysts, programmers, man- programmer to specify what he want. the system to agers, and others In their declsions of which lan- do rather than how to do it. We may expect a 4GL guages to use and/or how best to use an assigned to provide Improved programming productivity (a language. As we contemplate six of the maior areas shorter development cycle), reasonable system per- in which a 4GL might be used, we may ask to what fonnanee (as measured by batch or interactive extent the language can do that work lor us. Those response times)~ Increased function, much greater areas include: e8s......' ......., exlendlbllity (within and oulside the 4GL), ftexibilily to handle different applications, · Data input malleability to individual l!!x!l!..",Sugi-89-128 Baer.txt
"Data Base Management Techniques To Ensure Project Integrity Su san CiIIt!Jlbe 11 U.S. Environmental Protection Agency Jeffrey Finkeldey Computer Sciences Corporation IIITRIlOOCTIOII im:orrect value Or mean could ultimately cause a recommended limit to be too tight or too lax. The Drinking Water Research Oivision (DWRDJ The location, phase, and date fields are also of the Risk Reduction Engineering laboratory, important because of the vari ations they can u.s~ EPA, participates in numerous cooperative cause on the concentration value. Among the var- research projects with various utilities, ious uses of the data are reports of actual data universities, and firms. These studies produce values, statistical correlations, and graphic representations and comparisons. Many of these large amounts of data which are used in the studY of drinking water treatment technologies. Over outputs are routine. and so are ·production , the years, OWRO has had the opportunity to see jobs. Most of the graphics, however, are the positive and negative si des of data base written as needed, due to the changing require- development and use with regard to project man- ments of the project managers, and· newly agement. Prior planning can negate major evolving theories, etc. problems at later development stages, while a lack of it can double or treble the amount of Anyone involved in data base management work to be performed in the long run. This paper knows the importance of planning ahead to wi 11 relate some of the authors' experiences achieve maximum efficiency and durability of the while pointing out some of the management tech- system. DWRD went through an extensive planning niques to include and avoid when developing a stage before its data base management system research project. ever went into use - with over 500,000 records, they caul d not afford ""at to. And the system has maintained its usefulness for nearly 10 OVERYIEW years, without a major rewrite or upgrade. With The object of a",Sugi-89-129 Campbell Finkeldey.txt
"ion code trom the most recently executed PROC or DATA step. This makes detecting the confticting Ioc::k error much easier. If a PROe or OATA st-ap fails to execute because of a con- SASfSHARE~ softwarl;l allows two or more users to update a Hieting lOCk, &SYSEAA is set to 8 nonzerO val,,"",. So you simply SAS- ~ta library simultaneously. The key 10 SAS(SHARE soft- server, which per- test &SYSERR after the program step of Interest and, if it Is non- ware Is a separate SAS execution caJled the forms read and write operations. on- behalf of the users who are zero. handle the error in some appropriate manner. However, this method stili only works for Interactive appfications. When it is ruo- sharing a library, When a read or write request from a user COfI- fticts with ongoing activities of other users, the serv&f reJects the ning ooninteraclively, tile SAS System gOEIs into syntax-check mode when the error is encountar'ecI and subsequent steps are requilst and the Usaf'S PROC or DATA step does not ex6CtJte. not executed. SASfSHARE software itSelf offers no way to avoid these con- flicts. However, sites licensing SASjSHARE software can use exits from the SAS System to implement SAS source statements AVOIDING THE CONFLICT lila! enable a SAS program to check t.,.. conflicts before lIley 0CCUf or tQ wait until the required data set is available for process- Since the idea of de1ecting the conflict after it has occurred and ing. These statements enable a SAS programmer to preserve the",Sugi-89-13 Perkinson.txt
"RETRO-ENGINEERING A SAS® REPORTING SYSTEM FRONTEND Brent Turner, City o f New Y o r k I n c l u d e d tn P A Y G Y C L E p r o c e s s i n g is a series of twelve S A S programs which had ea^h a c c e s s e d a s e q u e n t i a l -file p r o d u c e d by P M S , c a l l e d t h e P a y C y c l a E x t r a c t F i l e Th« Financial Infornation Services (PCEFJ. PCEF is a comprehensive A g e n c y ( F I S A ) o-f t h e Citv of N e w Y o r k h a s b e e n c r e a t e d as a r e q u i r e m e n t for f e d e r a l repository for all employee data s u b s i d i e s U s e d t o a s s i s t t h e C i t y in p e r t a i n i n g to p a y r o l l p r o c e s s i n g . The meeting its financial obligatians. SASH p r o g r a m s e a c h r e p o r t u p o n some These subsidies had i n i t i a l l y been a s p e c t of P C E F w h i c h 4s u s e d to m o n i t o r r e q u e s t e d by t h e C i t y in r e s p o n s e to i t s the outcome of the PAYCYCLE. A fiscal crisis in the mid~1970·s. FISA preliminary examination of these has t w o p r i n c i p a l f u n c t i o n s , w h i c h a r e : programs had revealed opportunities to reduce t h e processing t i m e , which had b e e n over f i f t e e n h o u r s , b y m o r e t h a n 50 · to p r o v i d e financial information percent. e n a b l i n g m u n i c i p a l a u t h o r i t i e s to budget f o r s h o r t - and l o n g - t e r m cttpital e x p e n d i t u r e s ; · to tnanage t h e payroll for t h e IH.E. PRDBI,Ei1 m u l t i p l e a g e n c i e s of the city of H e u York. The o r i g i n a l P C E F S A S r e p o r t p r o g r a m s h a d not been designed as a system! further, To f u l f i l l t h e s e -functions) FISA e m p l o y s they h a d n e i t h e r b e e n w r i t t e n b y t h e same c o m p u t i n g h a r d u a r e M h i c h i n c l u d e s an X B H person nor even at the same t i m e . Each SOB^f r u n n i n g in p a r t i t i o n e d modei a n d program had been written as a standalone an I B M 3 0 a i ,",Sugi-89-130 Turner.txt
", Lovelace Medical Foundation Bryan D. Thompson, Lovelace Medical Foundation Abstract the blood was examined by the CFC, the ini- tial series of files were sent to the EASY88 The Lovelace Medical Foundation (LMF), [4] custom made PC system where an inte- a non-profit research organization, needed gration analysis program determined, among to prodnce quality-control rcports from com- other things, the percentage of fluorescent plex files generated by a personal computer cells in each preparation and stored the re- (PC) controlled Computerized Flow Cytome- sults. The size and names of the files var- ter (CFC). The CFC analyzed blood samples ied with the number of patients. Though the of persons who mayor may not have been files were of varying lengths, each section of exposed to toxic chemicals. The LMF Com- the analysis was marked within the file by a puter Facility decided that a quality-control special key phrase, denoting what value was report generator using a C program and SAS to follow. The LMF Computer Facility de- [1] on LMF's MicroVax II (/.VAX) running termined the best approach to produce the VMS [2] was the most practical solution be- weekly quality control reports that NIOSII cause, once the programs were written, the requested was SAS because: CFCresuits could be shipped, analyzed and 1. Automation the persons .involved in stored on the Il VAX with one invocation of the blood analyses could invoke a single a BATCH command. SAS was chosen because BATCH command to",Sugi-89-131 Kring Thompson.txt
"MANIPULATION Before you can- use SAS software to prepare Your operating system can supply you with valuabJe information that will enable you to your data fof' analysis or use a SAS procedure make effective decisions in planning and to analyze your data? you must first get them into a SAS data set. To accomplish this, the managing your data center resources. This DATA statement begins the OA TA step and paper focuses on accounting records generated provides a name for the data set"" the INFILE in the VSE environment by IBM's spooling statement identifies the external file containing control system, POWER. The purpose is to your accounting data, and the INPUT statement demonstrate coding techniques of the SAS identifies the data variables. language in evaluating the accounting data. The techniques and information discussed are applicaMe to all IBM mainframe operating Inputting Start I/O data for multiple devices systems. within one execution requires array processing. The variable EXSIO contains the length of the Start I/O table. The length of the table is",Sugi-89-132 Ludwick.txt
"Exploiting SAS® System and DCl System Features to Replicate an MVS CLiST Management Reporting System under VMSTM Casey H. Cantrell and Douglas G. Wahl INTRODUCTION PROBLEMS ENCOUNTERED CONVERllNG FROM MVS TO VMS DSRA's decision to migrate most data processing activities from an ffiM® mainframe to a smaner and slower in-house Our conversion from a mainframe (IBM MVS) environment machine was not met with enthusiasm by most of our SAS® to an in-house DEC MicroVAX n presented a variety of users. Not only were we required to learn an entirely new problems to the progranuningstaff. Mostobviously,ourSAS operating system; we also had to convert code written forthe code had to be rewritten to run under VMS; we aiso had to resource- ""abundant"" mM environment to the resource convert CUST driven systems to DCL driven systems. In ""restricted"" DEC® MlcroVax II. Although originally ap- changing from MVSweno longer had access to the powerful prehensive. . as the migration proceeded we began to SAS MACRO factlity.lnaddition, we found that the size and appreciate the power ofSAS in the V~TM ~viro~~ ~ speed of our madJine meant that computer resources were particularly its power when used in conjunction WIth Digttal more. prectous. Jobs took longer 10 run and consumed a Command Language (DeL) procedures. We discovered that relatively greater percentage of the CPU. At the same lime, we could approximate code initially written for the full SAS as the volume of work increased, we _wanted to build a MACRO facility and by using DCL command procedures, system lhat would enable non-technical personnel to do we aiso brought to our system additional capabilities not many of the tasks previously left to the programming staff. possible on the mainframe. ADVANTAGES OFA COMMAND FILE DRIVEN This transition included the conversion ofa mainframe-based SYSTEM SAS production menuing system: the #Dealer Re-port- .ing/Database Management System"" or ""'DRSY · As we By redeveloping our system within the co",Sugi-89-133 Cantrell Wahl.txt
"ngly, pharmaceutical companies are in order to look for toxic effects in man. As evidence attempting to enhance productivity by expanding the of safety is accumulated, dosages are increased to scope of their clinical information systems to embrace therapeutiC levels. In Phase II, the drug is tried for the non-traditional users such as: investigators, in-house first time in human volunteers with the targeted clinical staff, and FDA reviewers. As these systems disease. Sample sizes are small, and information is become commonplace, companies are confronted gathered concerning the appropriate dose and regimen to use to obtain a therapeutic effect. Once with the prospect of having up to five different sufficient Information is gathered and hypotheses computer systems, each with incompatible data about the drug's efficacy in various indications have structures: a remote data entry system; a database been formulated, large scale Phase III testing in human management system for traditional date entry; a volunteers begins. clinical data review system for use by in-house clinical staff; a statistical analysis system; and a computer The research process can take five or more years. assisted NDA review system (CANDA). Throughout the process additionai information is This papar describes the emerging features of SAS gathered concerning the safety of the drug in both software, including Version 6 enhancements such as humans and animals; the stability 01 the drug (how screen control languag",Sugi-89-134 Rosenberg.txt
"SAg. APPUCATIONS IN THE HEAL1HCARE INDUSTRY J. Jon Veloski, Jefferson Medical College nf Thomas Jefferson Universily William J. McDonald, Blue Cross & Blue Shield of Delaware, Inc. ABSTRACf 6. Both the volume of data and diversity of A review of the proceedings of the past SUGIs reverus users within many healthcare organizatious steady growth in the use nf SAS software throughout the create a need for powerful, multi-purpose healthcare industry. This paper summarizes applications software. nf SAS software to collect and manage patient medical data, drug salety data, insurance claims data, and other In order to provide an overview of representative healthcare data, Also highlighted are ways in which some applications of SAS software in this industry we reviewed of the unique capabilities of SAS software have been ru;ed the published proceedings of the meetings of the SAS creatively to address the broader issues of quality control Users' Group International (SUGI) since 1983. What in medical care, financial analysis, statistical analysis, and follows is a S\I1IlIl1arY of selected papers drawn from these healthcare policy analysis. Current applications under proceedings, as well as several current applications that development and plans for the future are descrihed. we have been involved in, which illustrate a few of the ways in which SAS software can be used to taclde challenges in the industry. Six important factors might explain why SAS software has been and will continue to be an indispensable tool for the PDq; Safety Data/ainical Trials development of inoovative information systems in the As evident in the list of references provided at the end of healthcare industry; this paper, there have been substantial uses of SAS The changes that arise from continuous 1. software for data reporting/analysis as well as data growth in medical knowledge and technology management in pharmaceutical firms. There, SAS demand flexible information systems that software is regarded a",Sugi-89-135 Veloski McDonald.txt
"x steps: 1. The concept of strategic marketing planning has become Analyze the Situation of paramount imponance within corporate marketing Assess and determine the needs of and opportunfties open to a company wfthin a program~. Marl<eters must rely heavily on analytical tools broadly defined customer base. These are for proper execution of profitable programs. The SAS System Is a useful tool to increase the efficiency and the ""where are we now?' questions. effectiveness of your marl<eting coordination and analysis. 2. Set ObJectives. The strategic marketing function is comprised of specnic Determine how the customer base should be segm~ed, and develop a picture Of what analysis components. Use of the SAS System within each of these functional marketing components is emphasized. market success looks like in each segment Examples of system components are used to illustrate the of the market ·· the ""where are we going?"" time-savlng features and increased effectiveness available questions. to market analysts through use of the SAS System. 3. Evaluate Alternatives. Look at eaCh product segment individually, Companies trying to become more market oriented are accomplishing the task by changing the way they think and determine the market distribution about their products and seflfices and more importantly concepts, strategies and plans to meet the changing the wey they make decisions about the direction objectives within each market segment. Then The new decision for those products",Sugi-89-136 Evans.txt
"Using the SAS System to Generate Bibliographies from a Large Data Set Prepared by: Mark A. Crook, OCLe Computer Library Center, Incorporated O~ine Introduction example). In most cases, a selection OCLC (r) Online Computer Library decision-could be made about a record Center maintains the largest online without having to completely parse its database of bibliographic information contents 1 the record would simply be in the world. This database, the written to the output file with a PUT Online Union Catalog, represents a INFILE statement for further processIng ~ unique source of information from which extensive bibliographies can be Processing efficiency is attained derived automatically using specially by employing random sampling datasets designed computer programs to retrieve, wherever possible and using the DATA format, and print bibliographic records NULL statement when doing record according- to users· specifications. selection or manipulation. The In this paper I will discuss (1) combination of these two techniques the application of the SAS (r) software leads to a significant reduction in the to problems of data retrieval and amount of computer resources required by formatting specific to the OCLe most of the information requests~ , internal bibliographic record format, However, there are some requests that (2} the challenges of interfacing this require a full scan 'of the databaset In machine-readable output to various such cases, the SAS code is streamlined printing devices, and (3) the benefits to do as little record manipulation as and shortcomings of the cornputer- possible and placed in the input queue assisted approach to bibliography to be run overnight. Usually, a complete scan of the OCLC database requires about compilation~ two hours~ By using these SAS routines Background the Information Services project was able The impetus for using the SAS. to provide 24 hour turnaround time on an system to assist in bibliography IBM (r) 3090 running MVS XA for",Sugi-89-137 Crook.txt
"SAS® IS WATCHING YOU: DEVELOPING AREFUND FRAUD DETECTION SYSTEM WITH THE SAS® SYSTEM Linda McClamrock, REI Background datasets were the only feasible answer, and so combined multi- ple data steps, sorts, summary, means, freqs, prints and charts REI (Recreational Equipment Inc.) is a nationwide retailer of all into one jobstream. recreational equipment and clothing, with 21 retail stores and an international mail order operation. We sell $200 million a year in I convinced a couple 01 local stores to key non-member returns high-quality, high-ticket merchandise, and our reputation is buitt data into a CIGS enlJy screen initially intended for use by our on our commitment to customer service. Part of this commit- Mail Order division. This screen gives each customer with a ment is an extremely liberal returns pancy; if the customer Is return a unique 10 number and retains their address, phone, dissatisfied with merchandise purchased at REI, we give a cash etc. The stores entered the data daily and, when combined wtth refund regardless of the state of the merchandise or the lack of our member sales data, it provided an audit trail for all retums. a receipt. At month-end, tha fun started. Returns transactions were Tbe Pl1)blem separated from sales and sorted by customer number. Since a store hands over money so easily, refund lraud ~me our Mail Order division can traCk their own customer sales and artists move in. loss prevention experts estimate retail returns returns pretty well, I excluded Mail Order, foreign, and commer- fraud to be roughly five percent of total retums, which adds up cial accounts in this first step. I wanted to use Proc Summary to three quarters of a million dollars a year to this company to analyze each customer's returns, but at two million members alone. Returns fraud is less risky for the thief than outright the dataset was too big. So I passed the data through a count- shoplifting, since you don'! need to leave the store with the ing loop to pull",Sugi-89-138 McClamrock.txt
"suppo rt which compu ter model s to This paper descr ibes a menu drive n At nment al site inves tiqati ons. enviro techn ical inform ation system develo ped prese nt, TIMS is avail able in two using at Roy F. westo n Inc. (WESTON) Each confi gurat ions. mainf rame macro s and the integr ating SAS· config uratio n utiliz es highly effect ive and 6.03 Relea se PC SASe softw are packag es as major compo nents of follow ing produ cts: SASjAF ·s , SAS/BA SE- 1 SAS/F Sp· design that are all interl inked within The and SAS/STAT~ A new tlprod uct ,SAS/G RAPllo one system (Table 1) _ base data combi nes pment "" practi ce has been initia ted appli catio n Develo manag ement , data entry , stati stica l to develo p a PC TiMS. The key issues of analy sis, repor ting tools and high the adapt ation of a TIMS applic ations on resolu tion graph ics into one system . By the micro enviro nment are the -selec tion as the sole host softwa re of a host langua ge packag e, size of the using PC SAS packag e we were able to maxim ize system applic ation and system perfor mance . perfor mance . The SAS System has been the softwa re of choice for statis tical compu ting power I and now more types of PC SAS softw are are availa ble, such as: SAS/A F, SASjFS P,",Sugi-89-139 MacDonald Yeh Kreamer Medvid.txt
"ntiservations exist. Each observation contains e)(pense informa- tion and the database covers ten years. If the data am broken SYSTEM 2000~ software offers users of the SAS~ System a varl~ down by areas of responsibillty such as department, data set ety of options to Improve processing per1Ofmance. CASD utilIza- me(Qing and. most llkely, a separate SORT procedure step tion. arid USElf access of their SAS data. A tutorial approach is before the merge are required each time users want to combine usEI'd to shOw how SAS Institute's SYSTEM 2000 Data Manage- data from multiple dap.9.rtfr't.ants. COnverSely. if the data are kept n'lent Software can be used as a storage vehicle for SAS data 1n a Single, large data set, then each tlme a department report to give 1he SAS user aU of these enhancements and more. is requlred, every record within the SAS data set must be .read in order to create an appropriate subset of data.",Sugi-89-14 Carpenter.txt
"og o ABSTRACT entry) so that the origin of the data CCN, Inc is a health care management can be traced in the verification phase company that initiates and manages PPO's and once the data is appended to the (Preferred Provider Organizations). master file. This activity involves the input of med- ical claims, data in order to provide the clients with contracted rates for each o VERIFICATION individual claim and to provide the company itself with data to maintain the Six phases of verification checks are various networks of providers of care accomplished: and to ensure the privacy of contracted rates with the providers of health care I} on-line checks available through the from competitors. SAS/FSp® FSEDIT screens: Using the SAS® System as a ""front-end"" o REQUIRED fields must be filled before leaving the observation processor of large volumes of health care datal received in paper form and various o MINIMUMs and MAXIMUMs are used electronic media, has allowed our as checks on gross errors, e.g- company to guarantee high quality, outpatient billings greater than error-free data for use by 'traditional $20,000 SAS® data analysis tools. Using SAS/AF® o FORMATS and INFORMATS on date and SAS/FSP@ software data entry- fields automatically verify personnel are prompted, through various valid dates means, for correction of errors. Each data entry technician is responsible for 2) on-line checks available through the validation of his/her own data prior to use of format tables: release t",Sugi-89-140 Smeby.txt
"of Prison Terms Wayne B~ Abstract It managing and controlling the parolee. is the agency responsible for arresting Due to increasing workload and court (placLng a hold on) the parOlee and hence pressure the Board of Pr~son Terms was beginning the actions of revocat~on. The 1 forced to create an on-line statewide Parole Agent has the parolee held in a parole revooation tracking system in f~ve county jail and representatives of the weeks. Other products were considered l but Board of Prison Terms adjudicate the case~ SAS* was selected because we were famil~ar In short, in relation to parolees, the with i t and knew we could work quickly in Parole Division functions as the police and ~tr and because SAS/SHARE* allowed simul- the Board acts as the judge. taneous file updating by multiple users. During the mid-80's the number of A TSO CLIST SAS/AF* application was parolees revoked, i.e., sent back to prison implemented within five weeks which helped for parOle violations has dramatically increased from 23~214 in fiscal year 85-86 the Board of Prison Terms and the Califor- nia Department of Corrections meet their to 42,708 in fiscal year 87-88. The number of revocation actions has inoreased from legally 1mposed requirements to process a revocation hearing action within 30 days~ 1500 per month to 4000 per month. This reducing the parole revocation process from substantial increase put a strain on the an average of 70 days to an average of 32 ability of the revocation hearing process",Sugi-89-141 McCrea Finley.txt
"TRACKING AIR COMPlIANCE PEm.tT REVIEWS ~NGSAS/AF·SOFnNARE WD.UAM F. SIMPSON CONNECTICUT DEPARTMENT OF ENVIRONMENTAL PROTECTION ccntain the aforementionOO identifierS so thet data can ba merged INTRODUCTION i:1to a ccrrmon EO hformation System for whatever purposes de- sroo ~, when dacidi!v whether to (Tan! a particular COfll'8f1Y ar TheComecticut Depar1ment of EnvirQmJf1tai Protection (tJEP) air pclkltion construction permit, theCoo:missicoer may want to see f>!r CorrjJIance \.HI: lAO)) has irrpI«nentoo a """"""'Vehensive. inte- whether the OEP has any outstending erfcroement actions agam (Tatoo Envh:rmentai hformatioo System known as the EIS. The EIS is COI1l""ised of 1ITee (3) ~ - an Adm... strative Cortl:>o- ttis COI'!'I""'Ilyfor violations of other envirormental statutes Of reg.l- lations; this can ba aCCOl'Tl'lished by merging the enforcement com- non!. an A'r QJaIity Corrponent and a T""""""'ical C~ The EIS pliarre history files of the appropriate line Wts). Admi1istrative Corrponent contai1s T..k Traokrg and Purchase Req.Jest!Budget Subsystems. The Air Quality COfT!lO'lEl'1l contains The Permit Review Subsystem (see Fig.Jre 2) ccntains infcrma- an f>!r Qualty Data AcqJlsition and Handling Subsystem Ths Com- flO""<'ll handles all ambient air "",anly data as well as metoorolo;jcal tion on those source.s wtlch were constructoo after.l.Jne, 1972 ard, accad~ to the Air Regulations were r~ed to obtai""! data ooIIectad at rncritoring locations 1trOU(j1out the State. tt oper- ACU construction end operatng perrrfu from the OEP. Source.s in alas on both a real-tine basis as wei as storing data for CIlaiity existence in 1972 were not req.Jiroo to obtain pemiI:. but had to assurance editi-g and ar~ The T ecl-nical Corrponent i1cIudas ba registered with the OEP. These registeroo sources make up the a Pemit Review Subsystem, an Emissions h1ventory Subsystem, Enforcement Corr1JIiance Subsystems, a s.¢und Amendments buk of the Emissions h1ve->tory Subsystem point source dataset Whethe",Sugi-89-142 Simpson.txt
"TEX ABSTRACT In addition to generating such statistics. PROC PRot TABLES is ~ use~-written, user-supported TABLES also offers statistical comparison procedure that computes descriptive statistics, options~ lhe user can choose between several tests control against experimental groups. and stat""lstics (80nferr-oni~ William'S, Dunnet, Stu- generates a report-quality table of the statis- dent), define the Significance level, request a tics and test results. one- or two-tailed test, request computations on ranked or raw data, and specify a control When compared to the use of PROCS MEANS or GlM combined with a PROC PRINT or a DATA _NULL_. group for comparison with experimental groups. PROC TABLES had these advantages: everything These test capabilities compare to those avail- is done in one step; table is report quality; able with PROC GLM. labeling columns is easier; statements are simpler; statistically-significant differences The most significant time-saving feature of are automatically marked in the table. PROC PROC TABLES is the fact that a quality table is lABLES had these disadvantages: footnotes, generated directly from the procedure; no added user-defined formats. and the missing option do printing procedure or data step is necessary. not -function; triple-spacing is mandatory; the There are a couple of non-standard format procedure is not validated by SAS® Institute. options available: STACK and FORMAT. Through the STACK option. up to 10 lines of variable labels can be sp",Sugi-89-143 Gerend.txt
"USING TIlE SAS!'FSLETTER PROCEDURE IN MACRO TO PRODUCE QUALITY LETTER. OUTPUT FORA SALES AND MARKETING DEPARTMENT Phyllis D.ltJrdan-lohnson, The Bureau of NatimullAffairs, Inc. Morgare< L. Molnm, The Bureau uf NatfaMlAjfaln, Inc. INTRODUcrrON TIlE MACRO AND TIlE ALGORITHM Macro The Bureau of National Affairs, Inc., located in Washington, D.C., is a publishing concern which The system incorporates the use of SAS macros to~ retrieve the data weekly, reformat the name provides information services to professionals in business, tax, legal. labor. environment and safety and address variables into mixed case (a refined fields. The Sales and Marketing department has letter mode), and print letters for customers whose forty·five day trial period has come to a a data processing group, M3I...keting Information close. The fIrst macro, ""Spidet'., retrieves the Systems, which uses the SAS!9programming lan- guage in an MVS environment. SAS is used for account information of the active records coded the reporting and management of sales and for the 45 day free trial we are tracking, and stores it in a temporary dataset. The second marketing data essential in decision making. macro ""IDetin#l merges the name and address Several months ago, our unit began experimenting with the SAS FSLETIER product, as a means of data with the temporary dataset. Following this, the macro ""Advlet3"" extracts the records that have merging subscriber files with advertising and promotion letters. With the aid of our Systems had the free trial for more than 35 days. updates the permanent dataset and calls- the macro Support Department, we have been able to create ""Mease"". ""Measel! converts the data to upper and formatted letters which satisfy a very discriminat- ing copy department. The system has replaced an lower case and prints the appropriate letter. See antiquated manual operation which was used to Appendix A for the macro code. send personalized letters to prospective BNA customers who were receivin",Sugi-89-144 JordanJohnson Molnar.txt
"TlIEIMPORTANCEOFDOCUMENTATION Stanley Voynar Metropolitan Edison Company WHO SHOULD DOCUMENT ABSTRACf The theme of thispaper, as y.ou can tell by the The SAS SYSTEM is a powerful system for tide, is the importance ofdoeumen~ ~ SAS Information ~ent. It provides an cxce1lcnt ~ams and systems. In this paper,1 Will ~lain platform for the easy development of decision support ~tems. u~ the aatabase ma:rtagement faciliues and Wby I believe documentation is necessary and m some cases mandatory. Full Screen PrOduct, the SAS SYSTEM makes building systems $0 ~ that it puts system development into the hands oftlie end user. The end user IS now in the position of controlling bisfher own information INTRODUC!10N resources. Before [ get too far along, I want to point out how we have been u:Sing the SAS system. The SAS system The SAS System enables the end user to build is a huge system and serves a wide spegrum. of users. complex applications previously obtainable only from a At the Metropolitan Edison Company Information Center. dedicated MIS depaftment. aniJ it allows these systems we use SAS as a P.t:ogramming language to produce ad hoc to be built in a fraction of the time it would have reporting from niainIcame systems ana as a programming taken using COBOL or ADF (IBM's Application laDguage to ~lop departmenU!l decision support Development Facilrtj'). systems. This: paper stresses the unportance or documentation in reference to those two areas. Unfortunatelv, the average end user hasn't been e~ed to system deVelopment standards, programming However. the documenting facilities of SAS are not limited to those areas. 1:1ie concents present in the standards, dOcumentation standaxds, system life. Documenting Yom Programs section work with any PROC cycles, or source code reviews. Therefore the quality or Data step Coded. of end user produced systems can vary significantly. Oualitv thf~Qut the Metropolitan Edison Company The following sections will tell you who should document. wh",Sugi-89-145 Voynar.txt
"RESEARCH INSTITUTE SHERRI JOYCE KING, BUSINESS RESOURCES GROUP, Inc. LAURIE BURCH, BUSINESS RESOURCES GROUP, Inc. STAN ALTAN, THE R.W.JOHNSON PHARHACEUTlCAL RESEARCH INSTITUTE In the cours. of choosing the final formulation and storage condition, the ABSTRACT pharmaceutical formulator may have also placed a number of additional lots of drug Drug stability analyses obtained during the with alternative formulation andlor research phase are based upon assay values packaging components on long-term obtained from a number of lots of drug, which are stored under various conditions stability. These lots often have more in possibly several different package long-term data than the flnal lots and can configurations. Analysis of data is an be used to answer a number of questions Iterative process, Involving the pooling of with regard to the effect of formulation parameters within and across different and package differences on the stability of strengths to yield as simple a model as the product. Typically, all of these data possible. Shelf life, expiration date, and are presented to the statistician for use release limits are estimated for specified in determining the shelf lif., expiration conditions based upon the final model. dating period, and product release limits. STABLE, a full-screen menU-driven system, Drug stability analysis is therefore based was developed at PRI - Raritan using upon assay values obtained from a number of SAS/AF8, SAS/GRAPH$ and the MACRO lots of drug, whic",Sugi-89-146 Buck King Burch Altan.txt
"A TEST SCORING PROCEDURE USING THE SAS® SYSTEM Charles Vachon, Universile Laval Jean Hardy, Universile Laval A flexible procedure should INTRODUCTION scoring enable multiple key for one set of answer As a fourth generation language, SAS is sheets. That means ability to change currently used in information centers order of response's choice, order of for various tasks. In recent years, a items, weights and scoring scheme for variety of test scoring and item analysis each item as well as subtest structure. programs using SAS has been developped The multiple keys will be used when more (Chilko & Smith, 1986; Gregory & Cody, than one form of the test is administered 1988; Leblanc & syren, 1988; Rich, 1983; within a sample. 1984; Widaman & Hays, 1986). The most interesting part of these programs lie in But flexibility are not the sole requie- their ability to perform item analysis. rements of an efficient scoring procedu- But none of them offer a truly flexible re. It should also be powerful. In one test scoring routine. For example, the instance, the user needed to score 8,000 ITEM procedure in the supplemental answer sheets in a single day and produce library (Chilko & Smith, 1986) allows basic statistics on the sample. It is not only one key (one set of correct answers rare to encounter tests with up to 200 for a set of answer sheets) I no weights items, the maximum allowed by most for items and no alternative to standard optical scanners. These constraints scoring scheme. should be addressed. information system performing basic Since scoring is often performed in An test scoripg and item analysis was coordination with the registrat's office currently ~n use at Universite Laval. in university and colleges, an interface Although very efficient, this PL/l system with database management systems (DBMS) can be necessary. The ability to write a was exceedingly difficul t to debug, enhancements were nearly impossible and rectan9ular test file is a minimum limi tations prev",Sugi-89-147 Vachon Hardy.txt
"An Integrated EnYlronmentallnformation System (ElS) Implemented with Base SAS', SAS/FSP·, SASI AF*, and SAS/OR* Leonard Bruckman, CT DEP, Air Compliance UnIt RIchard Sol. CT DEP, Air Compliance UnIt The Correcticut Department of Envi'crmental Protectkln (OEP), Air Technical Component Corrp'ance lXlit (ACU). is currently des\1ling and irrpIernenti1g an integated ErvircrYnentaJ Informatkln System (Elst The EIS is c0m- The Tecmcal Carporent (see Fi~e 5) is currantly COOllfised of prised of tlTee major CO!T'jlO!leI'lts: Tecmical corrponent; Adrrdris- eiglt (8) cperatklnal subsystems- Rve (5) edditkJnal subsystems are trative corrponent; and A< Quality c~ (see Flg..lfe n The in various stages of development The aforementklned subsystems Teclrical C(l!)""!Xll'ltl is cOITl""ised of eiglt subsystems wtich are are used by tIT"""" (3) of the four (4) major sectklns wtich COfTlI'ise used for managing the teclrical aspects associated with thereg.lla- the ACU. the T_ I Services Section. the Enforcement Sectirn, tcry role of the ACU The Actninistrative CCJrf1:lonent is C<lI1'1""ised of and the New Source Review/ Actninistrative Enforcement Sectioo two major subsystlirnS wtich are used for tracking all major tasks and monetary resources associated with the Air Pr5gam The AT The 1hirteen(13) subsystems witHnthis ~ were all deve!- Quaity ~ is C<lI1'1""ised of two subsystems. One subsys- qJed with the Data General (00) version of SAS. SAS/Base was tem is used fcr the collection. storage. and retrieval of real time initially used to build the SAS datasets. The SAS datasets COOllfisi:1;; meteorological and air "",ality data. The other subsystem is used fO( these subsystems w«e then reed with SASIFSF so that cus- the storage and retrleval of processed data which has been refined torrized screens ooud be developed fe< editing and browsiv SASI and edited. This subsystem is also used for the storage of non- FSF-FSIlETTER was extensively used in order to generate the contirurus data wtich is coll",Sugi-89-148 Bruckman Soj.txt
"ADVANCS: AN AUTOMATED DATA VAUDATlON AND CORRECTION SYSTEM Jessica Bondy. Medical Computing Center Dennis C. Lezotte. Medical Computing Center Julie A. Marshall. Dept. 01 Preventive Medicine and Biometrics University of Colorado Health Sciences Center SKIP PATTERNS embody another kind of inter- THE PROBLEM variable dependency. in which the value 01 one (or more) vanables determines whether or not a In large. long-term research studies. validating and correcting data can become extremely second variable (or. more usually. a set of variables) should have missing data. A respondent cumbersome and resource-intensive. Indeed. with children. for example. may be required to assuring that data are correct may well take more answer some questions about those children; an time than analyzing those same data once they are answer of ""no children"" means that the following ·clean"". To improve the efficiency of data cleaning. questions should be blank. In general, skip researchers have tried to detect errors as early as patterns can be said to describe combinations of possible. by checking the data as they are entered. values which are logically impossible. using screen-based data entry. While screen- based data entry is a useful and appropriate tool. it A way of OVERRIDING RANGE CHECKS is generally cannot provide all of the checking and needed in order to increase the effectiveness of correction needed to guarantee clean data. This those range checks: to use range checks to detect paper describes an automated data validation and implausible values. as well as impossible ones. If a correction system which solves several of the user cannot override a range check when outlier problems of screen-based data cleaning. data is encountered. he must specify ranges wide enough to accommodate any conceivable value. thus losing much of the power and purpose of the LIMITATIONS OF SCREEN-BASED DATA check. Ideally. a data cleaning system would notify CLEANING the user of data exceeding a range",Sugi-89-149 Bondy Lezotte Marshall.txt
"Building Macro-based Systems Howard Levine, Levine Software Systems IntroductioD Why ""se them? SAS Macros give systems developers the ability There are several advantages to using building to build easily maintained and sophisticated blocks instead of having each programmer code systems that can be built quickly and easily with the SAS® System; The key, of course, is to everything himself every time he is building a system. Some of them are listed below. make extensive and thoughtful use of the macro language. · It is easier to simply invoke a macro rather than re-write the code every time it is The macro language is well-suited for needed. generating repetitive code and for conditionally executing code. In addition, the use of Expert coding that beginning SAS parameters allows even greater flexibility. programmers could not understand can be Therefore, macros can generate standardized used by everyone just by in'loking the macro code tbat is made more flexible by using written by the expert. parameters_ Flexible macros are useful as building blocks fOT systems. Such macros can · Changes to systems can be accomplished by be used in a variety of situations by changing making fewer coding changes - change one parameters such as input and output data set macro rather than all your programs. names, variable names, date ranges, and various selection criteria. More simply. well · Programs are easier to read and understand designed macro. with parameters are good because macros become a user defined system building blocks. language. It is a higher level language than the SAS program which is generated from the is critical when building macro-based It macros. This is true in the much same way systems to build macros that are useful that the SAS System is a higher level building blocks for writing other macros and language than PL/I or C. SAS programs. There are essentially two types of building blocks: Tools and Applicalions. Some Exampl!}s A too I is a macro that can be n",Sugi-89-15 Levine.txt
"Thlspaperdescribes the creation and storage of user-deflnedviews of physical data, .s Implemented by various components 01 the SAS® System_ It addresses both the similarities and differences among: 4feb72 IPO 1000 paul 7284 · VJews created using the features of the native database 1000b76 1200 PUB 7734 mary management system (DBMS). CGR 7654 24sep68 fred 875 · VIews created using the ACCESS procedUfe to associate SAS 19oug77 TNO names and other information with data stored in an external tom 7791 960 DBMS such as ORAClE®, System 2000®, or IBM's OB2~. MKT john 15may74 7602 1375 · Views created using the SOt. procedure, SAS Institute's Implemeotation of Structured Query Language (504. PROC The Roedrace Table records information about employees who SOL Is avaHallIe with Release 6.06 oIthe SAS System. have participated In IocaJ running events: The SAS System Is developing ""database ability"". Indexes, WHERE clauses, SAS data set compression, and PROC SOL are examples of $AS Instftute's efforts to upgrade !he database·like faeRies available to the SAS user. The SAS/ACCESS~ family of paul 52:21 cary roadrace products opens gateways to more and more externai databases. cary roadrace 32:21 mary There Is a Jot of common ground among these diverse database old reliable 42:07 mary systems. This paper focuses on the abRity to establish user views of data stored in some database structure. It Introduces the 22:11 cary roadraee tom similarities and differences between the views provided by",Sugi-89-150 Kent.txt
"form are available in SAS data sets which exist to record the individual This paper describes the use of claims as received from the field. SAS to prepare duplicate letters used These files are used to record all per- to offer secondary material, held in tinent data on each claim and are then the field, to prospective buyers. The used to prepare a broad spectrum of system-makes use of data held in exis- reports to analyze out performance in ting SAS data sets created to record the field with regard to defective ma- customer quality problems and one spec- terial. ial data set dedicated to buyer infor- mation. The existing SAS data sets are Since the information is all avail- searched to find the observation deal- able somewhere¥ why not use it for ing with the material and then codes these transmittal letters as well as are entered to indicate which buyers the analysis work already being are to receive the offering. The pro- handled? gramming replaces handwritten letters and extensive copier work. At this point, the only thing miss- ing was the data concerning potential",Sugi-89-151 Nail.txt
"COMPARISON OF 1HE QPRINT PROCEDURE WITH 1HE PRINT PROCEDURE Jane Whitner, Syntex Introduction Ann Daly, Syntax until the first r rows of all panels have been This paper compares the QPRINT PROCEDURE with printed. then it prints the second r rows of the PRINT PROCEDURE. Both procedure, print out the first panel. and proc~eds in this way until SA~ data sets. ~ut th~y are intended for all panels have been printed for all observa- different purposes."" PROC Print can give a tions. PROC PRINT does the same. However, you quick look at the data with hardly any prO\lram- can have PROC QPRINT print the first panel for ming effort, while PROC QPRINT wa, designed to all observations, follow~d by the second panel prepare report quality data listing,. PRoe QPRINT provides greater flexibility and control for all observations~ etc. by specifying the option ROWS=MAX. You cannot do this with PROC over the layout of the printed output than does PROe PRINT, however, it lacks a few of the PRINT. PROC QPRINT also gives you some control features that PROC PRINT has. PROC QPRINT has over how the panels are positioned on the page. Each panel is centered by default t but 11 statements and 34 options that can be used with i.t and combined in various ways to make it if you specify the ALIGN option the widest very versatile, but they also interact with panel will be centered. and the other panels will be positioned so that any 10 columns will each other making it impossible to predict what the results of all valid combinations will be. be aligned for all panels. The EQUALIZE option This paper presents some of the more useful will make all panels the same width. You can aspects and some of the idiosyncracies of both even print all variables for each observation in wrap-around fashion by specifying ROWS=WRAP. procedures. This is the most efficient way to print large Features Available with PROt QPRINT to Aid in data sets with PROC QPRINT, but it is hard to formatting listings read. PROC PRINT ad",Sugi-89-152 Whitner Doty.txt
"A GENERALIZED EDITING PROCEDURE FOR QUESTIONNAIRE-BASED DATA USING THE SAS SYSTEM Lance W~ Cameron, NIOSH Lawrence R. Catlett, NIOSH will either direct the questioner to the INTRODUCTION I. series of smoking-related questions or will cause those questions to be Developing p~ogrammatic procedures for skipped. This is referred to as skip validating questionnaire-based data can patterns. be very complex and time-consuming. We will describe a procedure using PROC Because the sequence of responses FORMAT and a general purpose macro to follows different pathways depending accomplish this objective. In addition upon the response to particular gate to generalizing the process, the questions, editing questionnaire data procedure does not require high-level tends to be more complicated. A program programming expertise. which edits questionnaire data must do three things. First, it must indicate when data is missing but should be I· BACKGROUND I present. Second, it must indicate when data is present but should be missing. The reliability of any scientiTic And, third, it must indicate when the research is ultimately only as good ~s data is out of range. the accuracy of the data being analyzed. The National Institute for Occupational One could establish special program Safety and Health (NIOSH) conducts .logic to aCcommodate the 'Skip pattern research in a number of areas focusing arra.ngeMents to each unique on causes of occupational injuries, questionnaire, but this process would illnesses and diseases. Much of the quickly get very complex and would data used for this research is collected require fairly sophisticated through the administration of A better alternative is to programming. questionnaires to study participants. develop a general method for review of all Questions such that the three above- NIOSH recently initiated a study which mentioned editing requirements are involved collecting laboratory and accurately carried out. We develop one questionnaire data. Two of t",Sugi-89-153 Cameron Catlett.txt
"Rosofsk¥, Massachusetts Department of Public Health Robert A secoad technique could be to Slll'Ply only P!xiblem staten.mt the new data in text form and read it in using lNIUI'~ 'Ibis transaction Although Sl\S software provides very powerful oolumn and/or formatted means of developing summary and inferential dataset is then sorted for use in an UPDATE statement within a subsequent statistics, the use of SAS in batch mode l:M'A step. Assum- presents some limitations in easily updating Sl\S ing that tha 1lASE.Ml\S'l'ER dataset ia already in dataset:s with corrections and charqes to data. sorted order by m, the following exanple illus- trates thin technique: In sane applications, transaction ::rec:ords can be used to update a dataset on a scheduled basia. SUch situations usually have a uniform set of nM'A T.RANSACl'; variables which are chan;Jed in value. An mFIIE TRANS; mrur example ia the classic payroll application where 101-4 values for year-to-date wages, taxes witheld, CITY $ 5-14 etc. are regularly made. '[he use of the UPD1\TE data step statement in the Sl\S system ia opti:mll @20 FIl1S'I2\GE 2. for such an awlication, as only those @25 (DIAGI - 0lAG6) (4.) observations and variables which require chan;Jes are affected. l'rogra!ts can be developed which rarely chan;Je over time, far those variable """"""""'"" that are updated change fairly infrequently. DATA BASE.MASTER: 'Ihe:re are SOIl'e applications, however, Where. UI'D.l\TE B1ISE.Ml\S'l'ER 'ffil\NSACr chan;Jes need to be made to different variables BY ID; fran one time to another. fuis can occur be- cause tha data ialater fuund to be smply incor- 'Ihi.s method.. however.. makes the task of creat- ing the raw te><t data file a tedious one of rect or far other reasons. One technique that entering tha correct data in the =rrect col- can be used in these applications to chan;Je such data ia to create specific Sl\S code in a program umns. Erro= are highly lil<ely while perfonning this data ent.l:y ""freehandu even i",Sugi-89-154 Rosofsky.txt
"Education Institutional Researchers at each SSHE Abstract university oversee the submission of stu- dent enrollment and other information to the Office of the Chancellor. They respond state System of Higher Education univer- sities provide student enrollment data to on common formats, those of the U.S. De- one host university. The data are trans- partment of Education's center for Educa- tion statistics (CES) and Office for civil ferred in common format from the 13 dif- ferent computer systems to the host via 9- Rights (OCR). From the CES, the Integrated Postsecondary Education Data System (IPEDS) trk magnetic tape. eMS files of student forms are important. collectively, these data are created by reading the tapes with formats focus the data collection effort DITTO I an IBM@ utility_ These files are of the Institutional Researchers. edit checked via programs invoked under Version 5 SASjAF@ software. Those passing edit checks are written to SAS@ datasets. Problems o The SAS data- sets are used to generate summary information which is reported to The Director of System Research and Plan- state and federal agencies. state System ning could not effectively support the universities are also accessing this infor- Chancellor with analysis of enrollment and mation under Release 4 eMS via dialup other information. When the Board of modems to the host computer. Each uni ver- sity userfs PROFILE EXEC automatically Governors or the Pennsylvania Legislature asked the Chancellor questions",Sugi-89-155 Lahr.txt
"MODELING POLICY IMPACT Daniel R. Bretlleim, KPMG Peat Mruwick Step 2 - Coml'nte Payment Amounts INTRODUCTION To assess the impact of policy changes, H>e payment Polieymaket's ore becoming increasing4> aware of the amount fOl' each case was eompllted under two role that Decision Support Systems (OSS) can Pla.Y in estimating the potential impact of policy on payment scenarlos: constituents, clients, or other segments of -sOciety. Current This pricing approach was based on The capability to model ""what-i£"" scenarios euables Ule reimbursement methodology and policyllUlkers to examine the impact of poliey payment policies in use duriJ:lg' the alternallves prior to implementation, thereby historical fiscal year. increasing tile likelihood thal enacted policy will have the desired effect. Having reeent4> participated in tile Revised This pricing approach re-prieed each development of such a system~ I have Mme to apP"""".clate the relalionship between readi4> available CASe using the new methodology aod informalion and the decision-making process. revised P88Dlent policies. The SAS· Syalem was a major component of a DSS developed for use in modeling policy alternatives for a Step 3 - Compute Statistics stale Medicaid program. The department had recent4> developed new rates for the reimbursement of .'palient hospital services provided to Medicaid Hospital charge, reimbursement amount, and case recipients.. A number of poliCies were Qhanged or frequency were compoted using a PROC SUMMARY adopted in the development of this revised system. with the following three CLASS variables: Decision-makers were _interested in assesshlg the net impact of Hie policy chmtges and tile contribution of each policy to the overall reimbursement to bnllvidual Category - 1 Hlrouglt 4 (as described above) hospitals. - '¥t or 'N' (see Note 1) Outlier Statns Third-Party Status - 'Y' or 'N' (see Note 2) APPROACH statistics were computed by hospital for each of the two pricing scenarios aod output to in",Sugi-89-156 Bretheim.txt
"TRACT insurance rates and many other events that generate major economic investments New high tech methods of capturing by Federal or State agencies, taxpayers, traffic information generate very large large and industries, construction quanti ties of raw data which must be investors. checked for accuracy and put into standard format before being made ""Information"" is an end product of a available fer analysis an~ research. qua.lity of the product The process~ depends on the gathering of accurate, This paper describes the modular representative, sample data to analyze, methodology developed by the Washington synthesize and eventually apply to the State Department of Transportation solution of practical problemsw (WSDOT) to shape a powerful SAS traffic database updated monthly with data is a very dynamic, Traffic, itself, gathered electronically at various interactive collection of field data. locations statewide.. Program modules With field data we can not control the allow for jUdgement and intervention at multitude of variables as is recommended appropriate stages of data reduction, for research in a laboratory setting ~ diagnostic procedures, and for SAS to However, against a background of what may remove equipment malfunction detect and look like chaos we can still follow many errors .. of the rules of good research design to gather data for highway planning_ The process illustrated uses data from permane""t recorder stations th~t operate Even the casual observer can detect",Sugi-89-157 Hertzog Cowan.txt
"IlANUFACTURlltQ IlEASUREMENTS ;USING SAS. SYSTEMS CRAPHICS, TEMPLATE, ANI) THE ANltOTATE FACIlITY Linda Scott, GE Neutron Devices ·· Kay FavelJ, CE Neutron Devices ·· l_. . . ................. . ., . The Manufacturing Measurements Report is a ... .. ......, <C""UT._ ,- """"..,,- ....''''''~ "", graphic report generated monthly for Gf Neutron ~ ·· ,,... ~."" .. Devices (GENO) management. Labor utilization, .....,,"" ...Uf. ....,_ ..... : ..;:: ~,,!:: :~: ~ ::: ~==~== schedule performance, and material are measured :==:==_ ; ;;:: and summarized for unit and subsection levels of ~:~; ~1~: ~I::: management. The report is utilized by the - :==:==- ~ ,.i;: s!:! :::: ~ ::! managers in each production area as a tool to i::: ::: :'::':! :1::: :_; __ : ._--- give them an overall assessment of production ,.0 '"" .... _ .... :.~ ~ performance and progress. ·· :.2Y~ Y"".~T~.' Y_T_ - -...- - The data for this repor~ are generated on n_"""" .......... n-> ......... n _ """"""""""'"" n-..~ Honeywell, IBM, and Hewlett- O't._ Y_'ete, ..... <1"" - - - 'OVVoT, ""U1I.. 'U, ..... :;!r.: : ' Packard systems and are loaded onto a VAX··· """"o., - ..............rt: _ ,_, e.._ ...,.... _' .... ...... ~"" ~-."""" ~"",.""'t ~,~ system cluster to allow data manipulation and ==: ==_ - """"a>< : "";:! ~ ::: ~ '::! : \""1:: ~ graphics output. All graphs are stored in a SAS :::::! graphics I ibrary, and all templates are stored --~ ~1~:: ~==~==_ i:: ;,..::: in a SAS template catatog. This presentation --.!- ~== ~==;== ~=!==- shows how SAS graphics, both CPLOT and GCHART, --~==:==!== ~== ~==~==- and $AS templates are used to produce --:== ~== ~==;== ;==~==- infonmation (by section and subsection) and how ANNOTATE is used to show actual value and cost. CREATING TEMPLATES , Templates are created in Full Screen Editor. , , The template funetion is activated using PRO( CREPLAY. A library name must be referenced and a template catalog must be named. A directory for this catalog appears with alt templates in that catalog listed. Ind",Sugi-89-158 Scott Favell.txt
"Using the SAS® System to Improve Sottware Quolity Reporting Jon Bond IBM Corporation improvement in quality. a number of Introduction monthly reports are published. in addition to online co:rporate computer systems which SAS®I programs are used to cOllect data are available to look at various quality pa ~ about software quality which is transferred rameters. from external sources. 8AS ptogra.tru:: are also used to create graphical ~rts for In general"" programmers look for the ab~ management reporting. In additlOn, SAS sence o(""'problems"""" to achieve quality. A programs were wriuen to allow graphical bug/problem is ""an error. in a program""'.l programs to produce analysis lines for pre- Fot Que mutual benefit. and to spe;lk c1e¥ly dicting future trends and for detailed analy- sis. on the subject, quality is defmed here as an absence of problems. The use of SAS programs drastically reduces the time necessary to produce quality re- ports and helps to standardize trend pro- DiscolWers of probkms grams. The '""-customer'"" doesn't always discover that Mission of the IBM Boulder a computer program is not producing the expected results. A VALID problem can Programming Center be discovered by any of these three groups: The IBM Boulder Programming Center · FIELD (a customer) provides system architecture and develops · DEVELOPER (the development software to enable printing across the IBM group that wrote the program) system and printer product line. · INTERNAL (the group that supports The primary focus is: the progr.om). Operating environments for Systems · In addition, there are some problems which Application Arcllltecture (SAATM)l are classified as INVALID. · Advanced Funtion Printing (AFP) printers. Regardless of who discovers the problem. the computer program and it's documenta- tion are corrected. As these problems are Quality Improvement Objective discovered. monthly quality reports are generated which eventually work their way Each release of a software product has an o",Sugi-89-159 Bond.txt
"imagination of SAS users. Here ABSTRACT was a. way to store data in a docttmented. fonnat that was easy to use (at least for further SAS Basjc use- of SAS software in information work). Thus SAS software became a legitimate tool processing involves getting data inro SAS data for implementation of full information systems, sets, and using those data sets for rep(>rting and intended for Jong-term storage and rn.a.inte.nance of analysis. These functions are sufficient for complete, accurate, and verifiable data. Se<>res once-through jobs_ However. some additional of past SUGI contributions attest to this fact. functions are required when SAS data sets are used Still, no one has ever claimed that SAS software as the database core of an information system provides all the functions of a full database intended for long-term storage and maintenance of maintenance system. Designers of BAS information complete. accut'ate, and verifiable data. The systems must do some extra work to ensure that the system should facilitate verification of data implementation meets the requirements of the aecuracy. allow changes. additions. and deletions system. to the database, and provide a means to audit or document all such database updates. Getting data into a SAS dataset is usually straightforward. But an information system must This paper su.rveys a variety of techniques also provide a fUDction for maintenance of the used with both Version 5 and Version 6 SAS permanent database. The system should",Sugi-89-16 Rinehart.txt
"USING $AS® TO PRODUCE THE DIRECTORY OFTEXAS MANUFACWRERS Sylvia L. Cook Bureau of Business Research, The University of Texas at Austin number for the company, company name, plant Introduction name, street address or location, city or town in or near which the plant is located, mailing The Bureau of Business Research at the address, year plant was established, telephone University of Texas at Austin has published number, toll-free telephone numbers, Telex the Directory of Texas Manufacturers for the and fax numbers; name, titie, and telephone past 56 years. The 1989 edition of the number of the plant executive, purchasing Directory lists 16,329 companies that agent, and sales agent; and several manufacture in the state. The publication of the Directory is the culmination of a year- recordkeeping variables such as the year the long research effort to revise information on company was first listed in the Directory, the companies listed in the previous edition and edition year for which an update form was to collect information on new companies not last received from the company, and the date already listed in the Directory. The last three the data were last modified. The dataset also editions of the Directory have been produced includes a code indicating the action taken using SAS®. The data published in the when a form was last received from the Directory are kept in SAS® datasets and SAS® company: new entry added to the database, is used as a programming language to maintain last form received with changes, last form the data, to format the data for publication, received without changes, unable to locate and also to extract subsets of the data for company, company no longer manufactures, out of business, or company chooses not to be customers. This paper describes the listed in the Directory. Those companies mechanics of the system used. whose status codes indicate that they are not to be included in the Directory are deleted Data Organization from the database befo",Sugi-89-160 Cook.txt
"A pte(':ursor of Suney Processing in the S~ System at the Census Bureau Robert S. Lolu, Bureau of the Census Introduction 3) The United States Census Bureau is one of the largest The size of the survey was such that processing it data collection agencies in the world. Ever since UNIVAC I. on a VA)(!> 8700 would neither seem like hunting squirrels with an elephant gun, nor would it tax the the approach of the Bureau to electronic data processing has machine's resources to the. point of interfering with always heen to use large mainframe computerS. Because we other users, were pioneers, it was necessary to write much of OUT own 4) I would have the chance to analyze the process of software, as wen as design some of our own hardware. Until migrating data between a Unisys model 1100/84- the mid-1980s, our needs were still $pecialized enough that and the Demographic [SAR. (This was a project all this remained the case, However, computer technology is in itself. Even though software was available growing exponentially, and software is regularly being wriUen commercially for this purpose, the operating system which could replace many of the millions of lines of local of the Unisys had been altered to such a degree code ill use. This means that it is now a viable option for the that the mainframe portion of the software h3.d to Bureau to migrate some of its massive amount of data be customized by the Bureau's systems support processing to smaller, more mainstream machines with staff.) off~the-sbelf software packages. and in this way begiu to build a distributed data processing network. Storing the me as a SAS data set would greatly 5) reduce the time and effort involved in producing This movement toward decentralized, on-line processing, frequency counts which the analysts would use to together with the increasing user-friendliness of software in verify the output of the edit programs. general, has also meant that it has become much easier for tbe Census Bureau's analysts t",Sugi-89-161 Lohr.txt
"A CLINICAL lRlALS DATA MANAGEMENT SYSTEM FEAllJRlNG MUL1lPlE EDITING PHASES Mark F. Guagliardo, Biostatistics Center. George Washington University Kathleen A. Jablonski, Medlantic Research Foundation combination of interactive SAS products and a PC or INlROOUCTION mainframe database manager. However we are working This paper describes the mainframe component of a data under some common constraints: management system developed for a clinical trial ~f a medical intervention - prenatal ultrasound screening. A 1. Interactive $AS products may not be used on a key requirement of the system is that our statisticians regular basis on the data center's mainframe. There are should have easy access to information ""about the too many users for the computer resources available, frequency and status of <lata field erron. This paper will and interactive SAS causes too much degradation in focus on how the system creates~ within each data set, mainframe performance. a self-contained audit trail of error detections and cor~ctions. 2. There is no database management package on the data center mainframe~ The resource res.trictions that The study is called the Routine Antenatal Diagnostic apply to interactive SAS would apply to these also. Imaging with Ultrasound Trial - RADIUS Trial for short. Our goal is to determine if routine screening of low-risk 3. Centrally entered forms must be keyed into pregnancies with ultrasound can significantly reduce the mainframe text files using existing data entry software. rate of. prenatal and perinatal morbidity and mortality. For administrative reasons it is not feasible to enter the We plan to randomize 15,500 'ow-risk pregnant W<lmen centrally keyed forms into PCs in order to reap the into two groups - one group receiving normal prenatal benefits of a retational database manager or $AS Pc care With uftrasounds performed only when there is a products. medical indication for one, and the other group receiving the same care but with the addition of",Sugi-89-162 Guagilardo Jablonski.txt
"Building a scientific computing Environment Using the SAS® System Jody J .. Fromer development was never the intention of INTRODUCTION research data collection. Performing this new type of detailed data The Lubrizol Corporation is a analysis was painstaking and specialty cheJnical company comprised ultimately impossible. Therefore, we of several business units that use took a step back and revisited our chemical! mechanical! and biological data requirements by building a datal technologies to develop products for function, and process model for . diverse markets. To maintain its Research. The data model documented world leadership as a developer and all data entities used by research. supplier of specialty chemicals, It showed where the data originated Lubrizol is dedicated to a strong I and where it is used. The process ongoing research program. In 1987, model relates the data to the specific consolidated research expenses job fUnctions that creates, uses] and increased to over $61 million dollars. stores the data. The models developed Technical service costs I principally into the design of a newer, stronger mechanical testing to qualify foundation, geared toward information customers· lubricants for various analysis, not data gathering. This standards, were an additional $31 data-driven approach to systems design million dollars. was a drastic change in focus whose ramifications are still being felt in BACKGROUND the restructuring of the databases, and more importantly, in the In the early 1980'S, Management organization of the research effort as Information Systems and Development a whole .. (MIS) created databases to collect· formulation and testing data for MOVING FORWARD project management, project tracking, and reporting research activity. The The first multi-user, mainframe formation of a Corporate Statistical SAS system was called the Predict Services Department created a need to Formula Database. Its purpose was to consolidate historical data in the crea",Sugi-89-163 Fromer.txt
"U windows: ABSTRACT MENU windows designed with numeric selections are by far the This paper win describe various ways to trouble-sIloot Version easiest to develop with MENU entries. With numeric selections, 6.03 W/N' and SAS/FSP applicalions. Common problems fast branching is simple - for example, 3,2 means to' go to the encountered in the writing of an application and how to avoid second item on the third submenu. If you decide to use words these problems in the future will be discussed. AJso. how 10 or letters instead of (or along with) numeric selections you must avoid or eliminate common problems associated with the writing be aware of the following: of an SCL based application will be iilustrated. · abbreviations, especially single letter designations, may TROUBLE-5HOOTING SAS/AF APPLICATIONS cause problems · valid OMS or FSP/AF global commands (ex. STORE and SOME HELPFUL HINTS FREE) must be avoided. Use the SWAP command when building an AF application to The following examples demonstrate the problems that can be swap be~en BUILDwindows. The NEXT command will display encountered when non..numeric selections are provided. Any all open windows, including display manager windows. Place abbreviations that can be expanded to fit a DMS. FSP, or AF all entries for your application In one catalog. Then you do not global command wilt cause an ERROR message. For exampie, ha~ b>specifythe libref and oatalog namasan the ATTR panels. a user picks option A. the user would see the fol",Sugi-89-164 Berryman Grund.txt
"~SPOSE USING THE PROCEDURE'TO EFFECTIVELY PRESENT SURVEY RESULTS Emily Passino~ Department of Personnel~ State of Tennessee Karen Montefiori. Department of Finance and Administration~ State of Tennessee IHTBODUcrIQB In the CQurse of administering Employee Feedback Surveys to over 35.000 employees in 33 different state agenc±es¥ our office must generate individual summaries of the data for all levels of each organization. Each work group supervisor receives a report summarizing how his or her employees respon- ded; division managers receive reports summarizing the divisionts work groups; and each agency head receives an agency~wide sununary. The point of the reports is to stimulate constructive problem-solving at each organizational level. The survey covers a wide variety of work issues. including such sensitive areas as teamwork and supervi- sory effectiveness. The readers vary from those with advanced degrees to those without a high school diploma · · SAS software capabilities allowed us to meet the challenge to mass produce thousands of individual reports which would evable readers of widely varying sophistication to zero in on those aspects of the data which would be most fruitful to discuss. Specifically ~ PROC TRANSPOSE proved to be the key to generating results in ""plain English."" to highlight key survey results which would then be expanded upon in later sections of the report. SPECIFICATIONS FEATlJIiES Two PROC TRANSPOSE statements were used for The two Key features of PRoe TRANSPOSE this application: whicn maKe it tne proceaure of enoice for this application are {1} its ability to transpose ana FROC TRANSPOSE options: re-transpose a nata' set, an<:\. (2) tne fact tnat VAR variables; it preserves labels attached to variables tnrou~out tne manipulations. The options found to be useful were: PRoe TRANSPOSE rearranges a SAS data ;:;et so tnat observations beoome variables ana/or SASdataaet DATA ::: ·variables become observations. SuCh a trans- to name the set o",Sugi-89-165 Passino Montefiori.txt
"STRl1C'l'l1RED SAS COpE. A pc-ai4e4 ApproaCh Gary N. Griffiths, The Upjohn Company PUrpose of this paper INTRODUCTION The purpose of this paper is to Software production present some guidelines and software tools for the preparation of SAS Much of todayts software is developed with only the short-range benefit in programs. These guidelines and tools mind: meetinq an immediate production should aid the programmer in meeting deadline. While deadlines are both the short-range production obviously important l there are other deadlines and the long-range criteria long-range considerations which are of producing software which may be maintained, modified, and audited. equally important - - and frequently overlooked in the rush to meet the This paper will not attempt to present dreaded production deadline. universal guidelines for the preparation of code. Its SAS ItQuick and Dirtyn function, instead, is to provide ""food This short-range qoal often forces the for thought"" on some programming programmer to resort to what are guidelines which should be considered. sometimes called ""quick and dirty"" programming techniques. The result: a program which will accomplish the immediate task at hand, but will be STRl1CTl1RED BAS ceDE difficult (if not impossible) to maintain l modify or audit at some programming guidelines later date,. These guidelines may very well be different from company to company considerable time has lapsed and even different for divisions If between when program was within a company. But every unit the originally written and when it becomes needs to have some kind of guidelines necessary to maintain, modify or for the production of SAS source code. audit, it is even more difficult to figure out the logic and data flow of To illustrate the general structure of the ""old"" program. the guidelines, the paper concentrates Imagine the problem if the original programmer is no longer available~ on: ~) selected statements in the data step; and Managementis role manipu",Sugi-89-166 Griffiths.txt
"Using The SAS®- System For Error Identification And Resolution In Large And Complex Data Structures Herbert C Reynolds, Viar and Company. Inc. Donald P. Trees, Viar and Company, Inc. The SAS System As A Generalired Error Identification And I. INTRODUCTION ResolutioD System The occurrence of errors in data is one of the most serious Tbe utilization of SAS in developing a data quality assurance problems affecting information management and utilization. system has severa) advantages over using a procedural The identification and resolution of data errors is critical to language. The desired objectives for a data quality assurance any information management system. All data acquisition and control support system language in scientific areas and management efforts utilize some form of error detection include; or data editing prior to loading or updating information into a data base management system. o A user-oriented Ron-procedural language Ease of impiementation, extension and modification o The purpose of this paper is to discuss the use of the SAS system to support a general data quality assurance and o Availability of statistical procedures and functions Capabilities for dealing with missing data and o control system within a Jarge, complex data acquisition and scientific notation management effort. The application is in the area of o Facility for supporting effectively within the same analytical environmental data or data produced when system users of different expertise levels environmental samples are analyzed in laboratories to o Generalizability to other data and applications. determine the occurrence and concentration of pollutants and hazardous substances. The system was developed for the Environmental Protection Agency's Analytical Operations The fOllowing section discusses and demonstrates some of the SAS features and capabilities used for this particular Branch within the Superfund Program and the Office of application. These features and the general appr",Sugi-89-167 Reynolds Trees.txt
"The last 12 observations of data set VARS. In economic analysis of time series, it is often helpful to plot the data in order to ""4' MUG OBS DATE 11150 reveal underlying patterns. One type of plot ""54 is a tier chart in which monthly data for 6.' 265.7 saOl 197.0 295.' 157 ··· 279.1 2.62.4 8302 191.1 individual years are overlaid on one another. 158 8803 219.9 266.7 159 199.1 0.' A TSO batch job to produce such charts from 6.' 292.1 218.5 8804 2.61.6 ,.0 270.8 Z83.1 monthly data was developed. However/ in 8805 203.6 1.1 161 275.3 8806 ZOS.7 291.3 162 7.6 applications where many series need to be 293.1 217.7 8.2 1.3 8807 208.0 charted, this job must be edited repeatedly to 217.2 8308 207.9 239.0 16. 8.2 287.4 277 ·· 105 8309 208.0 7.' specify the chart parameters associated with 216.9 209.0 288.1 8310 160 7.5 ·· u each series. To fa.;:ilitate this procedure, 290.0 279.8 211.3 7.1 167 ··· 8312 298.8 283.7 214.9 ""8 SASiAF *,SAs/rsp * and SAS/DMI * bave been combined to create a menu-driven facility for DATE 11244 M380 OBS M320 ""278 editing and submitting these batch jobs. .. 540.3 8801 234.4 118.1 3'0.2 157 8802 395.0 233.8 552.2 119.4 15. ,",Sugi-89-168 FitzGerald.txt
"s used to create user-friendly front %do; ends to application system. It is easy to get StllIted creating %H (&_derton =%SI~) or '_dermn = %SIr(» '_dicey and linking together simple sereens, complete with validation AND =0 %Ihen of user entered responses. The true s!renght of SAS/AF, '%let _dcmnd : END; however, lies in its not so obvious advanced features. %end; -enter; Through the intricate application of numerous advaneed 'U fea~ entire infonnation systems can be driven from their AF front end. This paper will discuss a small sample of these features such as program code, design approaches, As an added feature, we allow the customer to branch utilities and problems that can be encOlmtere<i from the current screen to any previously displayed screen. The branching optinns are listed on the bottom of the screen as a number of action fielda. The code reviews these fields from lett to right and brancbes to the first screen selected, INTRODUCTION without any further validation. This eliminates the need to ensure that only one option is selected. If branching from a It doesn't take a lot of eaposure to SAS/AF before you screen is selected, all of the program logic under the screen wonder if you can do more thanjust create great looking must be bypassed. The code to branch to other screeris is screens and set attributes. Both the AF manual and the AF displayed below: course give just an inkling of AF's capabilities. These capabilities extend far beyond the simple entry and validat",Sugi-89-169 Naim.txt
"Creating the Extended Table Display Exlended tables are a feature of Version 6 Exlended tables, as with all SASIAF entries, must SASIAF. software. This tutorial describes the be created with PROC BUilD. To allow a requirements for their use, how to create a SASe PROGRAM entry to be used as an extended catalog PROGRAM ently Ihal can be used as an table, first edit a PROGRAM entry, then open the ext!)nded table, special features of screen control GATTR window and mark the special extended language (SCL) that support extended tables, and table attribute (Screen 1). the execution sequence for an extended table program. Three sample extended table programs ~ILD: GATTR ElWIPLE1.PROGRAM (E) (OIIIJanci __ are presented and discussed. )0 ----:-:-0:------ WIndow Name: Start row: col:",Sugi-89-17 Itano.txt
"zy"" Abstract Th is paper out lines the neces·sary At Mel the PROBLEM TRACKING SYSTEM steps il""lvolv'ed and the difficulties was initially designed in a (PTS) encountered in transferring a systeM siy:gle user environment .. The general a single user for desig~ed requirefflents looked like a perfect into a SAS/SHARE based environment application 'for an easy conversion system. to SAS/SHARE. The requirements to open, called Tor procedures Before shared access capability, update, and close problem tracking to be satisfied with users had tickets and also provide reports on waiting their turn to update data. status aYld trends.. In addition, The., full scope of the SAS data step requested that a date stamp users was then available for data valida- be put on records as they were tion, deletion, time-stamping, a.nd updated,' and another date-stamp be other types of variable Manipulation Monitor when maintained to. the B~t users' became restless, saying~ status of the problem. was changed. ""this is the 80's what about multi- To track who was actually using the user access?"" is an SAS/SHARE the user' identification of system, application that can be adapted to the person editing the record was existing code to solve thi-s problem. also to be included in the observa- Converting the editing portions of tion. IYI a SAS/SHARE environment, the system to a SAS/SHARE environ- a new can easily have a record ~ent is relatively straight f'orward. date and time stamp created i,n a retaining the e",Sugi-89-170 Murakeozy.txt
"ogram written as a $AS data step. It has proven to be a useful tool in keeping organized in an environment with many versions of programs used in similar OUTPUT applications. It compares versions of source code, producing a report of differences, either alone or integrated with a listing of Leaving aside for the moment the comparison Of multiple pairs of one of the versions. the old and new sections are shown either files, what OIFF does is compare an old version of a liSe to a new side-by-side (pamllel) Of one above the other (me'lled). Input version and produce a repOrt displaying the differences. For data can come either from two files, from a sequence of pairs of example, suppose we started with a short program which read as mes, or from two POS's with similarly named members. DJFF has follows: ~rved a variety of uses: as a programmer's tool. for LIBNAME SAVE · [J'; documenta:tlon, and in software validation. PRO!: PRINT DATA:SAVE.V!Sns: BY PATIENT; VAR VISIT PUlse S_Bf' IUW; BACKGROUND TlTL.E 'USTING OF VISIT DATA': When you need to know how two versions of a file differ. the RUN; choices of tools may be limited in your particular operating Now suppose we moolfy this to put in an 10 statement. environment. The key ability of any of these tools Is the abHity to realign the comparison after inserted or deleted Jines have been LIBNAME SAVE '!l'; detected. This requires searching ahead and deciding where the PROC PRINT DATA;;:SAVE.VIsns; changes end and where the unchanged t",Sugi-89-171 Clay.txt
"A HEMATOLOGY LABORATORY SYSTEM USING THE SAS(r) SYSTEM FOR PCs Joe~ Achtenberg, Washington University, St. Louis, MO M. PLlar Casanova, Washington University, St. Louis, MO This paper describes a clinical individual laboratory results for that hematology laboratory system using patient, (2) the ability to recall SAS(r) 6.03 on an IBM PC/AT with a direct previous lab records, add additional connection to an automated blood information, and update the patientfs analy~er. The use of SAS(r) permits chart, (3) the ability to retain rapid review of the on-line test results, permanent records of each test, and (4) inclusion of additional tests done to produce reports summarizing results manually and comments inserted by the from a number of samples over a period technician, almost instantaneous of time. transmission of the results to remote clinics, efficient maintenance of A first attempt at developing a historical patient records, and a wide comprehensive data management system range of patient and laboratory reports, around these needs, using one of the including gr,aphics. popular PC-based data management packages, was abandoned as too The system makes uSe of an cumbersome t inflexible, and slow, and a undocumented feature in SAS(r) version decision was made to begin anew using 6.03 which facilitates the communication SAS. between a SAS datastep and an external device, by providing a DOS-level device driver for the serial port and by providing a means for specifying device-dependent communication When it became apparent that the SAS parameters sU9h as baud rate, parity, and system would soon be available on handshake protocols. personal computers, the decision was quickly made to halt the efforts at This system is being developed at programming the system in dBase-III, and the Washington University Computing instead to implement the full laboratory Facilities, for installation within the records system in SAS. next few months at the Clinical Hematology Laboratory of t",Sugi-89-172 Achtenberg Casanova.txt
"ry quality control When the prob 1em wa s presented to system has been developed for the this consultant, only the summary Premium Entry units of Fireman's level reports were available to Line Fund using basic SAS and an in-house Management. line Management sug- SAS-based system. The Premium Entry gested entry errors. The initial quality control system has saved task was to capture the actual thousands of dollars by displaying premium entries to determine what policies which have been incorrectly factors were causing the irregular- entered. The developrnent of the iti es. Premium Entry quality control system is di scu s sed from a ca se study Corporate information specialists perspective. developed policy level information using standard COBAL 1 istings. The evi dence seemed to confi rm Premi um I NTRDDUCTION Entry errors. Because the data was not sorted or tied together, a Fireman's Fund, a highly diversified compl ete picture of the factors property-casualty insurance company, causing the problem could not be expanded into the profitabl e excess determi ned. property insurance market in recent years. Due to the uniqueness of the Having used SAS in prior problem product, the complexities of han- situations, this consultant reviewed dling the multi pl e reinsurance the problem with other knowledgeable entries and an aging Premium Entry information special ists. The sug- system, the Premium Entry function gested approach was to go after the located at four separate U.S. Premiu",Sugi-89-173 Ragnes.txt
"STRUCTUREDTE'3TDESIGNFORDATAQUALlTYCONTROL R. A. Whitfield, Quality Control Systems Corporation Human errors and omissi<fns have always boon It's easy to imagine many things that could go the most serious threat to the security and wrong with the data in such a file. It's also easy integrity of computerized data. Because they are to express, in English, rules that would test for so common, unintentional mistakes in these problems. In a division where the only recording or data input cause far greater losses paid positions are inspector, operator, clerk, and in the data processing industry than computer supervisor, any employee in a different position (such as a ""cler "") would be an obvious error. room fires or floods, or even deliberate fraud. Unfortunately, a preoccupation with machine Unless the employee is a supervisor, the number room sprinkler systems, off-site data storage, on- of regular hours worked in a week might properly range between zero (for persons 0 n site vaults.) passworded database access, and disaster recovery plans can easily obscure the vacation) and forty. Sick time should also range best security system of them all: a practical and between zero and forty hours. Overtime hours automated system for data quality control. might be limited to no more than half of the total scheduled hours in a week. In manufacturing, quality control means testing a product to see if it meets its intended design Allowable ranges of pay should depend on standards. In information processing, quality position. For example, the starting wage for control testing can also be applied to computer operators might be $5.75 per hour with a top data to insure that the data are valid and correct: wage of $S.50 per bour. Hours worked plus sick ""data validation."" Althongh data validation is time must always equal scheduled hours. No hardly a new idea, it can be quite cumbersome to overtime should be paid to supervisors or to accomplish using SAS®. In fact, it is an employees who",Sugi-89-174 Whitfield.txt
"CON'VERTXNG A ~&stDATA SET TO A FLAT 1'XLE: A SAS/AF SOFTWARE APPLICATION Hun9-Ir Li, Western Michigan university Pen-Yu Lai, The UpjOhn cOlllpany INTRODUCTXON computer. He/she will then be prompted for information about where the target SAS system is a very powerful package data set is located and to where the flat which can perform extensive statistical file be transferred. If there is no need analyses and q.ata management. it also has for extra processing on the target data the capacity to move SAS data sets among set.f the system will take over from there different environments such as TSO and and then activates appropriate links CMS or between mainframe and personal between personal computer and mainframe computer. Unfortunately not everyone oan and transfer the converted file to the access it. In our working experiences it desired destination in either way. A is qUite often that our clients want to filter file can be included in the codes do data management or analysis in SAS if extra processing such as subsettinq, system but then reqUest a copy of the adding more variables, formatting, and final data so that they can continue the labeling is needed before converting. analysis in other maohine and/or software This filter file can be existing files in packages in the future. To make it more personal computer or mainframe and/or be added interactively. The user can also complicated, sometimes data managements transpose the data set via filter file or or analyses are done in mainframe environment but personal computer would wait until he/she is prompted for more be their future working environment and information in this matter. These extra vice versa. In order to meet this kind of works and converting are done in demand, converting the desired SAS data mainframe whenever mainframe is either set to a flat file in the form of ASCII the source or the destination because the (for personal computer) or EBCDIC (for processing is generally faster than in personal comp",Sugi-89-175 Li Lai.txt
"I'C SASJGRAPH WORKSHOP: USING SASiGRAPH TO PLOT AND ANNOTATE DATA"" Rodney H. Strand. EERC, University of Tennessee, Knoxville Paul Kanciruk, CO2 Information Analysis Center, ORNL, Oak Ridge, TN IlL RESULTS AND DISCUSSIONS A Data and Programs Created l. INTRODUCl'ION The data used in this workshop were stored in the SAS data set Test,SSD. This data set contains the variabtes Total, Solid. Oas, At the request of workshop organizers for the Fourteenth Annual liquid, and the last two digits of the year (Year). The first SAS User's Group International (SUGI-14) conference, this program is a simple line printer plot of Total carbon for the years workshop was presented to allow SM users an opportunity to 1950-1986. A basic plOI with only two TItle statements. There have a hands-on experience with the SAS/GRAPH product on a are no axis statements. so SAS takes the variable name"" of 'Total' Personal Computer (PC). A similar workshop was presented at and ""'Year' for axis labels. The code follows with output in Figure SUGI-13. 1. For the purposes of generating a full page plot, Options PS..,,55 was used in Figure 1. This workshop, designed to serve the novice user of graphics., provided participants experience witb SAS on the Pc. Building Libname Co2 ""c:\<iasdemo'>$ession9""; on the capabilities in the Base SM product to plot and chart Titlel 'Carbon Dioxide Emissions'; information on a printer. the workshop participant learned bow to Titte2 'United States of America', customize the graphical presentation to a very high level of Proc P10t Data=Co2.Test; Plot Total*Year; specification and contro1 This paper summarizes the workshop materials prepared prior to the ronference. Participant-generJlted This output is the same output observed in the Display Manager questions and rode have not been included in (his paper. (OM) Output window of SASIPC. II. METHODS AND MATERIALS In the second program (plot2.SAS) a simple printer plot shows a plot of Total carbon and the contributions by",Sugi-89-176 Strand Kanciruk.txt
"ATHENA: AN INTERACTIVE LOAD RESEARCH APPLICATION USING MENUS, WINDOWS, AND MACRO TECHNIQUES Burtt Blodgett, Quantum Consultiug Inc. John Power~ Quantum Consulting Inc. suggestions about using the SUGI version of AlHENA, ATIlENA is an interactive SAS®-PC application developed please tum to the appendix at the end of this paper. by Quantum Consulting. A lHENA uses advanced macro and windowing techniques that integrate a complex series pf independent SAS programs into a coherent, user-friendly analysis environment. We offer this Interactive Posters · Athena Ml'lin Menu session as an example of our experience integrating a number of SAS·PC products in the solution of large data handling and analysis problems. Although this application s.r_.. .Fc>o::m..o. _ _ s..o ..p was developed for electric utility demand·side programs :~~~- such as load monitoring. marketing, and load research .~~ programs, SAS-FC users will find that the software _ s""OU-t<K'j' tecbniques used in AlHENA can he readily appfied to their own large data editing, validation and analysis problems. Traditional1y~ solutions to such problems have been implemented in a mainframe computing environment. :~~~I'"" However, A lHENA takes advantage of the growing power DUni!...tien . ~:;;- 0 - Pi>pl.y_ -0 of PC worlcstations to allow such problems to be solved on _ m __ lhnooLDDT _Vi"""",~t.o.od a cost-effective desktop system. · c.-.~~ A lHENA can be run on any DOS-based microcomputer capable of rumting SAS and supporting expanded memory. The purpose of a utility load research program is to gather In order to take fullest advantage of the software's information about how different customers of an electric capabilities, ATEENA should be run on a powerful utility use electricity. A growing number of programs are 80386-based workstation. One such workstation, on gathering information abont how residential and commercial which AlHENA was developed, is the Load Data Analysis customers use particular appliances and pieces",Sugi-89-177 Blodgett Powers.txt
"U. COOPERATIVE STUDIES COORDINATING CENTER. WEST HAVEN. CT is to point out the usefullness Qf BAT Purpose files as a programming tool in The purpose of this paper is to designing systems. Macro variables in review the linkaqe of application these three packages are also proqrams written in dBASE III PLUS and discussed. DOS refers to their macro l variables as replaceable parameters. the SAS System for personal computers. using the IBM Disk operating syste. The use of macros make a cleaner code (DOS) (Version 3.20) generated menus. with a more powerful and sophisticated The features in these software packages The SAS statements, PROC system~ that provide the programmer with the PRINTTO. WINDON. FILE. and %WINDON are ability to desiqn inte!active also reviewed. The features of these menU-driven systems are disoussed. statements increase the ease of system design. DOS~ Macro variables in dBASE III PLUS-. and the SASe System are Why System Was Developed discussed alonq with the SAS features of FILE. WINDOW. \WINDOW. and PROC This system was developed for a PRINTTO. These last two features are study managed by the Veterans new to Release 6.03. Administration Cooperative Studies Introduction Program Coordinating Center in West Haven. CT. The Study. I'Tteatment of Patients with AIDS and AIDS Related Ease. power. and simplicity these Complex 'l · is a double blind. controlled are the qualities of DOS Batch (BAT) files that allow for a custom designed clinical trial with 400 patients.",Sugi-89-178 Economou.txt
"A Menu-driven, Microcomputer-based Data Entry System Using Version 6.03 Screen Control Language Julie Smith Glaxo Inc. To determine if a £ie~d is X'd, a The interactive poster session statement like the followin9 is referred to in this paper (usually as used in a DO loop with index I: IIthis system"") is a modified version of a data entry system actually used ~ IF SDSNLIST{I} = 'X' .... ; in a clinical trial by Glaxo Inc. The data entry system utilizes However, it may also be helpful to hardware unavailab~e at SUGI (a set another temporary seL variable mainframe and laser printer) . equal to the value of the array Therefore, the interactive poster element and reference this variable session was modified accordingly. in later code. This paper will focus on the Screen = SDSNLIST{I); Control Language (SeL) used in the BACKDSN = 'X' ....· SAS/~SP(r) IF BACKDSN SAS!AF(r) and screens. As always with SAS(r) software, there are various ways to accomplish a task. 2) Array elements that are temporary This point is illustrated throughout variables with initial numeric this poster session. Macro language, values data step and procedure code, display manager interaction, and DOS ARRAY MSSVAR{*) MSBVAR1-MSSVAR4 interaction are features used in (126, 270, 266, 272); conjunction with SCL. The initial values are numbers that Using ARRAYs in SeL will be used in code that is passed to Display Manager. An example of the code that uses this type of array, used in a DO loop with an Several ways of using arrays are illustrated in this system. Some of index of I~ is: these are detailed below. Included SORTSIZE = MSSVAR{I); are arrays in Which the elements are: SUBMIT CONTINUE; FROC SORT DATA = ··· 1) AF screen variables of type ACTION SORTSIZE = &SORTSIZE; 2) temporary seL variables with initial numeric values that will BY ··· be passed to Display Manager for RUN; use in a procedure ENDSUBMIT; 3} temporary SCL variables with initial character values that are Note that SORTSIZE is the name",Sugi-89-179 Smith.txt
", C is a WEIll establishBd g8neral-purpose programming ABSTRACT language that can be usad In a wide vanety of botn large and small appllca~ons. Tho following are some typical u... for C In By des'Yn, the C languag.e is a flexible and powerful tool for soft~ tOOi1!IY's programming environment ware de~lopm&ltl C encourages modular progl'8.mtning and affi- oion~ portable awllcatlons. This paper ptOVides Introductory Operating sy.tam. baCkground on compilero. the C language. and how · task· AT&r Bell LaboratQries UNIX~ 15 writb!m In C, as are oriented tutorial approach to learning C was developed by com· a variety of other operating systams. bining compiler featul'e$ with C language -inatJ'uctiOn in a PC envl- Text proCessors ronJ1'lf3nl l'hiS paper also includes a dlscusston of how to bultd A ""ulllbef of commonly ayaila~8 text processors are and run 8 C program using the SAS/c;. Compiler. Student Edition writIBn ill C. Lattlce& '$ HighSlyle.... desktop publishing Colao referred to as lIIe Student Compiler). This example 11Ius-- package is a (ecen1 example. ""'afes how the tutorial can be used with the Sllldent CQmpier to provide an easy and effICient way to -team basic pOOCipies of C Compilers program deY8lOpment. The Lattice and SAS/C compHers are written in C. as an;t a number of oompi!ers marketed by Microsoft'"" BOrland, and othBf'vestdot's. WHY SHOULD YOU USE THE C LANGUAGE? Real-time laboratory or indu:strial data analysis s~ Because of the ability to generate efficient mach",Sugi-89-18 Merrill Stribling.txt
"QUERYING WITH SAS® SCREEN CoNTROL LANGUAGE A DArABASE BROWSING AND ExTRACTION APfUCATION K. W/US, FiOlA PHARMACEUncAL CORPORATION MARIA ANNE AsHER, ARC PRoFESSIONAL SERVICES GROUP PROGRAM STRUClURE INTRODUCllON This interactive poster presents a database query Figure 1 displays the structure of this application and the calling sequence. The major component of this and extraction application which was developed using the SAS Software System for Personal Computers. Ver- application is the Query and Extraction. The method used is based on Query-By-Exarnple, a technique that is sion 6.03 of the SASI AF® and SAS/FSP® products pro- usedinmanySQL(StructuredQueryLanguage)applica- vide us with Screen Control Language, a powerful tool for developing intelligent user interfaces for interactive tions. A fill in the blank table (Figure 2.1) is presented to the user for the purpose of capturing the criteria to full-screen applications. ThegoaJ of this application is to provide the novice user with an easy method of access- matched in the data extraction step. To aid the user in ing, extracting and manipulating data stored in SAS completing this table, a pop-up window (Figure 2.2) can datasets without possessing knowledge of the SAS lan- beopened which will display a listof variables available. The user can then select the desired variable from the list guage. to be placed into the query table (Figure 2.3). DATA LIBIIARY 2. 1 FIGURE BLANK QUERY TA8LE The data used in this application consists of clinical l....l.l<>ot_~ trials data collected using Case Report Forms (CRFs). For 1. _ _ t1P""1»"""""" ~tbanaboT,_to_~.,. u.... , -.ct.lWo _ (""1J4 1 ""., to p~ the purposes of this application, seven forms were cho- __ 2. _ _ to tI>oo --- -.1 UriAgo _ 'tfII>~, ~.hwd. co~ nuu_""....,U1It.1<o....""""... ,.... .......... _ . sen and separateSASdatasets created. In addition to the form specific datasets, two other datosets, the variable dictionary and dataset dictionary, are used. The variable dictio",Sugi-89-180 Wills Asher.txt
"USE OF THE SAS SYSTEM FOR A THREE-FILE APPLICATION OF PATIENTS. DONORS. AND TRANSFUSIONS: USE OF THE MERGE. FIRST. AND LAST STATEMENTS AND THE FORMAT PROCEDURE. ALFRED J. ANDERSON. CARDIOVASCULAR DATA REGISTRY. ST. LUKE'S MEDICAL CENTER. MILWAUKEE. WISCONSIN. SAS Data Steps Introduction The three separate files ace maintained This paper describes the use of the SAS as SAS data sets: system for a research project involving patients who received platelet 1. patient - PLATLET.PAT 2. Donor - PLATLET.DON transfusions. The success of a 3. Transfusion - PLA~LET.TRA transfusion depends upon the condition The tranfusion file is first sorted by of the patient at the time of the patient tD and transfusion date t~ansfusion (fever. infection, etc.). the number of platelets transfused. the (TTDATE). The FIRST and LAST Statements patient's ABO blood group and HLA type and a counter are included in the SAS data step and saved in the SAS data set and the donor's ABO and HLA type. A successful outcome is an increase in PLATLET.TRA. the patient'S platelet count at 24-hours following the platelet tranSfusion {platelet increment). PROC SORT DATA=TRANS: BY PATID TTDATE; DATA PLATLET.TRA: File Description SET TRANS: Three separate files contain the basic BY PATID TTDATE: FRSTID=FIRST.PATID; data~ These files are: 1. Patient file ~ containing patient LASTID= LAST.PATID; specific informaton inCluding IF FIRST.PATID TREN PATCNT=O: PATCNT.. 1: disease codes. age~ gender~ ABO and PROC PRINT; HLA type: 2. Donor file - containinq the donors VAR TRANUM TTDATE PATID PLNAME age. gender. ABO and RLA type; BLEED INFECT WEIGHT TEMP PRE SPLENO 3. Transfusion file - containing DIC SEPTIC MEDI MED2 INCIHR INC24HR information specific to each LYMPI FRSTID LASTID PATCNT DONID transfusion. including the DLNAME: patient's condition at the time of the transfusion. the number of TITLE 'TRANSFUSION FILE SORTED BY PATID WITH FIRST & LAST PATID '; platelets transfused. other blood products transfused~ the l~hour",Sugi-89-181 Anderson.txt
"A SYSTEM OF SAS MACROS TO PRODUCE KAPLAN-MEIER LIFE TABLES, PLOTS, AND STRATIFIED MANTEL-HAENSZEL COMPARISONS · James M. Boyett, The Cleveland Clinic Foundation Kirk A. Easley, The Cleveland Clinic Foundation A system of four nacros uses the theory developed by 1<'aplan am. Meier to p:ro:iuce life %I<APlAN_(AT_RISK,CENSOR,~, SUmmary am ClCaIplete life tables tables. ~,0lRSUNE=132) with estimates of starrlard error may be Confidence int:erval.s are easily printed. 'lhis macro generates Kaplan-!leier estimates generated U$.ln:J either the starrlard error of sugg_ of the sur:vival function an1 starrlard errors the 1<'aplan-Meier estimate as by cibservations grouped acoo:rdi.ng to for .Peto, Pike, et ala or Greenwcx:rl's fonnula. distinct values of the Sl\S variable ClASS. '!be system also a:rt:puts Sl\S data sets W!rlch One can collapse over lellels of ClASS to may be plotted usirq nFRX:: PI.CJI'f1 ani u~ oot:ain overall survival estimates. The An additional macro utilizes the GPlm"". results are contained in a S1>S dataset named Mantel.-Haenszel statistic to c:atpare bo:> l<APIAN_1.. survival adjusting for distributions stratification. '!his macro can also exxnbine 2 x 2 c:ontin:jency tables. 'lbese macros are easy to use, flexible, complement u:fH)C I.J:FEI'ES'l''' aul execute under a3 version 5 ani AT_RISK is a macro variable identifyirg the in the 6.03 microcc:up.rt:er env:i.ro.nnent. Sl\S tire at risk variable (or failure tire) code has also been written to i n p l _ these contained in the SAS data set SURIIIVAL. 'll:ls procedures _ VMS without 1!1aeros. failure ti.Jre value lIlIJst be an integer. cmsaR is a macro variable identifYing the censoring variable containad in SURIIIVAL. The val"".., of the S/\S variable CENSOR lIlIJst be am. all either 1 (Alive) or 2 (Dead) , The consulting sta:tistician often needs d::>servations for >.trlch the value of CENSOR is teclmiques to analyze the tire to occurrer>:Je not 1 or 2 a:te deleted before analysis. of sorre event or r",Sugi-89-182 Boyett Easley.txt
"Due to the fact that MACROs are a large. My second MACRO example does this. This MACRO complex~ self-contained language, within an contains a PROC TTEST and two MACRO variables in the VAR statement which will be used for ever growing software system, figuring out where and how to use them can be difficult. rep1atement. The MACRO is named EX2 and the Also. since there are always novice pro- variables VARI and VAR2 are identified in parenthesis. After the MEND statement, the grammers appearing each year. reiterating MACRO uses becomes necessary_ Therefore, variables that are -to be included in the PROC this paper will present four ways to put the TTEST are identified with the MACRO replace- MACRO language to work. The first example ment statement. This statement can be shows how to create a block of statements for written as many times as one needs and will inclusion in other areas of the job. The be executed that many times, so be careful. second example. demonstrates a repetitive variable replacement within a block of state- Figure 4 shows the MACRO EX2 program state- ments. The third example shows how to use ments. figure 5 shows the program execution of this MACRO, and Figure 6 shows some of the the %LET statement in the PROC step. Last, a use for the SYMGET statement will be demon- output that was subsequently created. strated. The examples presented attempt to do so in a simple straightforward fashion; EXAMPLE 3 USING THE %LET STATEMENT and when put to use they can become powerful. Occasionally. a programmer may come upon a situation where it is necessary to pass a",Sugi-89-183 Brown.txt
"MACPAGE - A SAS. MACRO FOR ENHANaNG REPORTS Kathleen D. Edwards. Burroughs We-lIeol'M Co. John Hen'Y King. Trilogy Consulting COfporation This paper des<:ribes a macro which allows the user 10 enhance In OS use: the presentation quality of SAS reports. SpedfkaUy, the macro IJFT23FOOl OD D5N = &&PRINTTO, UNIT =SYSDA. generates page numbers in a variety of styl~~ it differentiates zeros from the lettEr ""0"" by overstrikin9 the zeros with a ..,.., it DCh (RECfM = VBA.lRECl = 260, II hikes up the underscore to mimic the appearance of an BlKSIZE = 2604), II SPACE = (TRK, (10, 10», overstrike, and it allows for the adjustment of the top and left II margins. The top margin adjustment is similar to the SAS SKIP DISP=(MOD,?ASS) /I option. The macro uses PROC PRINTTO and a data step to IIFT24FOOl DD VOL: REF =: *.FT23FOOl j accomplish these enhancements. DSN='H23F001, /I DISP=(OLD, PASS) II The reports which use the page numbering feature can be generated by PUT statements. from procedurE calls or by a In these example filerefs, UNIT = 23 would be specified combination of these methOds. The pla<.ement of the numbers in the call to %MACPAGE. The important thing: here is that UNIT = 24 must also be defined to reference the can be right. left. Or' centef justified and can appear on any line of the page. The user can also define the starting page number. $amefil~. Some of the stytesavailable iru:lude: TARGET ::II pagep a character string target which %MACPAGE pagepofn specifies pofn will look for when positioning the numbers: on the a·p (where a is an appendix number) output pages. The target should be unique and must appear on ea(h page in the tine where the numbering The ma<:ro uses PROC PRINTTO and is called twke by the user. In text is to be pJa-ced. The special target CC can be the first caU, the user sets up the ""unit"" where the SAS output specified to cause %MACPAGE to look for the -carriage file is captured. In the second call. the user passes: parameters control characte",Sugi-89-184 Edwards King.txt
"Large data sets create special prob- lems for us as we stated above. We can- This paper describes a SAS (R) macro not process them in the usual manner, we which calculates and prints the basic have to find special ways to get around. statistics for BY groups without requir- See all references about how to deal ing the data set to be sorted. The macro with large data sets. For example, when is designed for very large data sets we need the basic statistics by BY when a sort by the BY variable(s) is groups of a large data set, we cannot very expensive. Using the macro the afford to sort the data set and run PROC I user can execute a PROe MEANS request MEANS. We must utilize PROC SUMMARY. with BY groups specified, without having However, PROC SUMMARY does not provide to sort the data set. The printed output any printed output and we have to ""dig of the macro is identical to that of out"" the necessary results from its out- PROC MEANS. put file which can be very cumbersome. The macro presented in this paper gives the user the convenience of a PROe MEANS-like description his/her of",Sugi-89-185 Felsovalyi.txt
"ansco Energy Company Diane H~ Goulding EDP Computer Services 5 ABSTRACT EXAMPLE SAS/SHARE software lets multiple users update The application system contains an FSEDIT the same SAS data library. However, if a DATA screen where users enter data into a SAS data step is needed to replace or add variables to a set. A batch job uses the entered data in SAS data set being shared, that DATA step must calculations to determine the value of other have exclusive control over the SAS data set. variables in the data set. The job must have This level of control is not available within exclusive control over the data set in order $AS/SHARE. How can all users view and edit an to rep 1ace it. When a user wants to run th i s up-to-date data set, while ensuring that a job, he can display all users currently program which replaces the data set can run active on the appl ication system. and send with exclusive control? We present utilities those users a message notifying them that which help solve this problem by allowing users exclusive control of the data will be needed to view their batch job status and to send by the job. Users are then prevented from messages to each other without leaving the updating the data set (which would cause application. Users can thus .notify other users unsuccessful completion of the batch job) when they need exclusive control to run a batch until the job has finished executing. job. Because users wi 11 -be locked out of a file when a batch job has exclusive contr",Sugi-89-186 LakeFester Ashbee Goulding.txt
"llcome Co. SOLUTION ABSTRACT What was needed was a programming fadlity that could prodw:e When generating reports;, one must often create listings and tables detailed and customized listings and that would be easy to mod/1y which require complex or tailored specifications_ The means to for sharing purposes. The partial solution was PRO<: QPRINT. By achieve 5uth iii listing may niK@ssitate a mOte adaptable SA$ facility reading the 5AS Te<hnical Report P-145 (Changes and thl)l'l PROCPRII\!T. Insuth C4ses. DATA_NULL_S ate often I.tsed to Enhancements to the Version 5 SAS System, April 1986) and customize listings and can produce impressive"" results. HOWEver, explorin.g the many powefful ilInd interchangeable commands DATA _NUll_S also require intricate work when minor available in PROe QPRINT we felt we bad found just what was modifiCiltions are neceS$O)ry, suw as adding another variable to the needed ....almost. listing Of changing a heading. An att~native $AS -facility that combines the sophistiQtion of tha PRoe QPRINT can be used In place of DATA _NUll_s in most listings and tables and uses PRO( PRINT-style syntax. However, a DATA ~NUlL_ wfth the ~easy to use"" features of PROC PRINT is disadvantage of USing PROe QPRINT is its inability to duplicate PROC QPRINT. certain actions available in PROC PRINT and in the DATA_NUll_. Spedfically, this is the ~BY variable; 10 variable option in PROe N PROC QPRINT is similar to PROC PRINT in syntax, but gives you greater control of thi:!",Sugi-89-187 DeMuth Huffman.txt
". Lockey. Department of Environmental Health, University of Cincinnati Medical Center, Cincinnati, Ohio Generally these data are immediately ABSTRACT transferred to the mainframe after returning from the field, for entry into a SAS data base. Although PC SAS can be used for very many The health history questionnaires are entered applications, sometimes it is necessary to directly onto laptops in the field, using forms move to mainframe SAS for data designed In dBASE 111+. The dBASE III + files management. For example, the data on the are subsequently converted to SAS data sets PC must be incorporated into a database using PROC DBF. These data are then editted residing on the mainframe. Often the PC is using SAS FSP. When a health history data set underpowered in terms of speed, memory, or is clean, it then is uploaded to the mainframe printer capacity. At mainframe sites using a 7171 protocol converter, the Micro-to-Host Unk SAS data base. Similarly, the other data are entered onto PC's, either in dBASE 1\1 +, or is not supported under OS SAS version 5.16. directly into SAS, using FSP. Eventually, all We are involved in large occupational health data are transferred to the mainframe for studies, and rely heavily on PC's for data statistical analysis. acqusition and entry. Hence, in order to upload data easily, we have developed a program which will output ASCII data from a THE PROBLEM PC SAS data set, and the statements needed to read the data back into OS SAS. The data Many",Sugi-89-188 Khoury Lockey.txt
"Berk Biostatistics, Ob/Gyn, Environmental HeaHh and Internal Medicine, University of Cincinnati Medical Center. Cincinnati. Ohio Rationale Abstract The main database is kept as a SASfile on the mainframe Serum glucose values are recorded four limes daily in an wtth a smaller SASfile, a subset 01 information, on the PC. ongoing clinical trial of management of diabetes on the It is preferable to store the glucose data itlleH in the lorm outcome 01 pregnancy. Until recently these values were of a SASffle within the main database; both for recorded manually by the (foabetic subject, key·entered convenience of maintaining the data lor the clinical trial, into the computer and subsequenfly submibed 10 the and ease of access for data analysis. Thus SAS was the SAS·based data·management system developed for this obvious chOice for managing the raw data from the study. In the last two years memory glucometers, as glucometers and subsequently merging the different well as hardware and software, to transfer the glucose pieces of information Iogether. values to a PC electronically, have bean introduced. Custom modems used with the memory glucometers transmtt data via the diabetic subject·s home phone to the physician's computer. Standard summary programs are available, but converting the files into a SASfile as part of the PC database makes available additional Purpose relevant data. Using SAS, transmitted data files are read in and edited, This program initially scans the raw data, whic",Sugi-89-189 Khoury Hertzberg Miodovnik Khoury Berk.txt
"_ I I I to Use SAS® System Options. Hsllolt Gsnnan. GTE LABORATORIES Inc. INTRODUCTION in parenthes.. _ the dataset (e.g. DROp.._ is AI best, beginning SAS® pmgrammern are only affects only Ihe DATA sIep or a briefly exposed 10 SAS system options. l11e 10pic I. (e.g. END- for Ihe INFILE usually not included in ittraductory SAS CCIUJ3eS. :: ....=='""""- only Ihat statament or sIep. Nor hasbeglnnaf. sys1Bm options been presenIe<I as a SUGI tuIorIal or Included In the Ibrary 01 sample programs supplied by the Instilute. ThIs psper _mpis 10 eliminabi this knowledge 'IlIClIum by HOW ARE SAS SYSTEM OPTIONS SET? diSCuSsing tIKI fcIlowing: Each product of Ihe SAS system com.. with Its own default options Dr both Interactive end _ modes znowing ::rour SAS EDvironaent. I:. (some productB have no system options.) Some A. Hhat a.r. BAS .y.t..e. opUon.? SAS -installallons tIC not Change theBe optiOIl$. However, most SAS sm.s tIC modify tIKI SAS system B. What are my current Q.fitfall1t BAS o~ns 10 oplimi<8 SAS usage or lim"" your acooss ay.t.AlIl optJ,cna? or _rces while rurv1lng a BAS Job. Recommendations on when and how 10 override a Hodif~iug ~DvirODaent. your BAS II. sije's defautt sjlSl8m option can be _ e d at many A. Bow do J: Bst BAS .y.t.ea optionsi' BAS Inslallauons. "" you \eel that )'0<1' company .hould change a defautt SAS option, lail<. H over with Xeviaw of ComaQU syst.&a options: B. your SAS installation repre_e. 1.. OpUom& t.hIlt .""f-£act botb stePIJ. 2. OptJ.OD:II t.hat. .£fact. IIOBt.1y WHAT ARE MY CURRENT DEFAULT SAS the DATA step. SYSTEM OPTIONS? 3;.. Options that affect your There Bra seveml reasons why you shouk:l know BAS )..09'- what Your CUrren! default $AS system opIlans are: al -I.. OptiODS that affect yaw: SAS Technical Suppon may need this Inlormation tn rIJPQrts. resolve 8 Jlf'IlbIem, b) tn learn wIlat $AS faatures and resources are enabled or disabled (such ·· Those wanting a more comprehensive version on Macro 0, Display Manege"", ""llo have a beller",Sugi-89-19 German.txt
"s OSII intended for end-users who wish to use Data Set Name ""PUT"" sta'tellents to generate reports. tMJt SEARCH do not want to spend a lot of tiDe Upper bound LINESIZE counting columns to Make sure everything STRUO fits nicely within the available space. SUrt - End of EI'IlID The macro takes the variables that 10 Variables the user supplies for the report and STRT calculates the BESTFIT within the 132 Start - End of EI'Il available coluans. henceforth; macro other Variables tBESTFIT was created. List of the SA~v.riables VARLIST that are to be in the Macro BESTFIT calls .everal other rsport in dete~ining the appropriate ~crOS TITLES coiumA locations of each variable. Thia Labels a~sociated with paper will discuss each of the sub-macros each sa~ variable in and how they interrelate to produoe e VAl/LIST abov·. nice formatted report. Below is an example of the values each of the above macro variables may INTRIlOUCTION hold , Generating reports using PUT UT O_AIlES, statements can be very tedious and time UT SEARCH:132, consuming. Often users plan what their reports look like on some kind of spread 'lET STRTIO:l, sheet that contains 132 columns so as to UT ENOIO:!. be sure everything fits within the 'lET STIIT:3, available space. If a user has a report 'lET ENII=5, ancompassiruj !Rany variables. more than one page may be necessary. It ft'Iore 'than UT VAI!LIST:SOC1IJ""INAI1E/IlIiADE/COUIiSEIAVG, one page is generated. 10 variables are .8 'lET TITLES:Sl!CIAl. SECURITY""NUI1IlERI goo",Sugi-89-190 Kreamer.txt
"The %LET statement is commonly used to slelina a same macro variable. For example, the following SAS® macro statements: macro variable and assign it a value. Some SAS(B) users may be aware of the problem that a macro variable is %LET NAMEI = Wei-wei; unresolved when called outside the macro where il Is defined. This paper presents two methods to allow users %PUT &NAMEI lives In Delaware.; %LET NAME2 = ReRing; \0 call %LET·defined macro variables anywhere they %PUT &NAME2 lives in Calilornla.; want and avoid the problem of unresolved macro %PUT &NAMEI and &NAME2 are sisters.; variables. Nina examples ara presented. One of tI1em is from tI1a SAS® autocall library. put 'Wei-wei lives in Delaware.', 'Reiling lives in California.'. and 'Wei-wei and Reiling are sisters.' in the",Sugi-89-191 Lee.txt
"MAKE A DATE WITI{ TIlE SA&'""SYSlEM William R. MacHose Pennsylvania Pow"""" & Light Co. Next 'We have to get the name of the month from Dates in report titles can ~ generated auto- REPDA'IE. This can be done with the PUr £\mction matically with SAS. This eliminates the need to and the WORDDATE9 format. modify programs each month or prompt for the appropriate date to be used. This poster demonstrates the use of the data step. the LENGTI! IDN NAME '"" 9; MON_NAME;M<REFDAlE, WORDDATE9. l; macro facility"" date functions. and date formats IDN_NAME;LlJFT(IDN_NAMEl; to build dated report titles. Now we have to add tbe year behind the month lNI'ROOOCfION name. Use the ]RIM ftmction to remove trailing The monthly report is probably the most conmon blanks on the month name and use the PUT function to convert the year to a five-letter type of business report. In order to genro-a te character string (one blank and a 4-digit year). a dated title for the report it is necessar,y to: 1. Generate the Date Words LENGlH DATEWOIID '"" 14; DATEWRD---'lRIM(MON_NAMEl IIPUf(YEAR,5. ); 2. Put the Date Words in a Macro Variable 3. Use the Macro Variable in a TITLE S1EP 2 - PUf. TIlE DATE IN A MACRO VARIABLE \oQ!IDS STEP 1 - GENERATE TIlE DATE IoQRDS In order to make this character string available in a title we must first put the string into a It takes several statements in a data step to macro variable. CALL SYMP1JI' is used in a data generate date words. First the appropriate step to make a macro variable. A RUN statement month and year must be calculated. Typically completes the data step. this is done by obtaining the current date and simply subtracting a month. The figure below CAIL SYMPUT( 'MAC_DATE' ,TRIM<DAIEWOIID»; shows different ways of calculating a tyO RUN; reference data for the prior month. DATA _NlJ[L_; RElmA1E=:roDAY( )-31; or »; RElmA1E=:roDAY( ) - DAY(WDAY( ~ - USE TIlE MACRO VARIABLE IN A TITLE Subtracting a number (like 3D has sane After the above data step nms. the macro It",Sugi-89-192 MacHose.txt
"A Robust Code for Producing Stratified, Blocked Randomizations Utilizing VMSTM Macro Facilities and the SET Statement with the POINT Option David Main, Fidia Pharmaceutical Corporation SOLUTION: PROBLEM: The system presented here is written to produce the desired randomizations using the elements. described below_ To design a SAS based system which produces a SAS file with N records with each record randomized to one of Three files with data specific to a particular randomization: several treatment groups or sequences of treatments. 1. MACRD.SAS The system has to have the following features: A file edited to contain SAS source code which assigns - Produce records for designs that are produced in one values to MACRO variables using the %LET statement. randomization (Le. designs requiring a second This file saved under a separate file name, serves as randomization based on response to a first stage of study documentation for each randomization; are outside of the system); 2.RAW.DAT - Randomize designs with both equal and unequal numbers of records in treatment groups; A file containing the desired types and proportions of exposure to treatment in the experiment. The flexibility -Suppon crossover designs (Le. designs with patients of this file allows for treatment groups with either receiving more than one of the treatments during the equal or unequal number of records; study); - Handle designs with single or multiple stratification 3. FORMAT.DAT factors~ A file containing PROC FORMATS used to document the treatment groups and strata (if any) in the design. - Allow the statistician to choose the blocksize of the randomization. One master source code (R1.SAS). This code contains The system has to produce a SAS data set of the the following features: randomized records for use in labeling experiment materials: DEFINmONS AND FILES FOR TWO RANDOMIZATIONS 2-Per:iod Crossover Design: I-Period, Unequal By use of %INCLUDE statements to insert %LEf statements from MACRD.SAS an",Sugi-89-193 Main.txt
"SPEE DY SEAR CHES USING EMBE DDED LINKE D LISTS Brit Minor , Ameri can Institutes for Resea rch ABSTR Acr List index: Howard and Pickle (1984) discuss efficient methods of A data set or format with 000 entry per distinct value searching large sorted data se1s. If the data sel can'l be sorted of a linked V1U'iable, storing the first record of the by the search key V1U'iables, an alternative is I<> store, for each master data set with \hat valoo: the entry into the record with a particular wine, the observation number of the linked list. next reeord with that value. This constitutes a linked IisI embedded within the data soL Access to scattered records is gained by looking up the position of the firsl matching record III. HOW EMBEDDED UNKED liSTS WORK in. sop......, index of values (e.g. a format), then nsing the links for direct access to the remaining rceotds of the subset. Ordinarily, a linked IisI is an epbemeral data structure ally relating addresses in memory. By an erahedded dyeamic The method is recommended for large static data sets linked list, I mean ooe in which the relations between data that are searched frequeJll\y, e.g. historioal data, since the items are retained as part of the data set. This use severely ooot of bulJding and storing \inks must be amortized over \imits t!'~ oper:mons nonnally done with linked lists, e.g. many searches. The method should be further restricted to dyeannc _ o n aad deletion of records. However, for searches \hat would net about 25% or fewer records: a simple slshle databases. this is not a problem. subsetting-IF is as fast or faster otherwise. When subsetting U% of a 10,566-record, 2O-V1U'iable PC.sAS (R) data set, In a SAS data set, \inked records are retrieved by linked list aceo.. was 40% faster than subsctting-JF· when random a=ss using the SET statement'. POINT = option. 63%. retrieving 4% of the records, the savings was abeut The pointer V1U'iable holds the number of the record \hat would 0""""'"" next in sequence i",Sugi-89-194 Minor.txt
"SAS~SAS/FS#YAND SAS/GRAPH~N ILLUSTRATING BASE EPIDEMIOLOGIC INVESTIGATIONS JANICE SCHAEFER, USC SCHOOL OF MEDICINE FLORA FUNG, USC SCHOOL OF MEDICINE DENNIS DEAPEN, USC SCHOOL OF MEDICINE INTRODUC'l'ION DATA BASE ADMINISTRATION The International Twin Study is an epidemiologic study of cancer and Exhibit I displays the development of the data base, from patient other chronic diseases, based on the idea that environmental causes might recruitment to analysis. be easier to recognize through a comparison of twins. Over 12,000 pair RECRUXT!!Bl!T of twins from the United states and Canada have been ascertained, mainly Paid advertisements are placed in as a result of advertisements in news- newspapers and magaZines in the United papers and magazines. Demographic and States and Canada to encourage twins diagnostic Verification is collected with cancer, multiple sclerosis or pair ~ for the TWins complete other chronic diseases to volunteer for this unique investiqation. questionnaires comparing their diets, A SAS medical histories, exposures and life- library and data set have been created enter store pertinent styles. Twenty three cancer sites, to and information about the advertisement lupus and multiple sclerosis are currently under investigation. program. The name of the newspaper or journal, descriptive information about All data base administration, report- the circulation and the population ing and analyses are p~rformed in the that it serves as well as the date and Base SA~is used in all SAS system. the cost of each ad are entered in the phases of the study, from advertising Advertisement data set using SAS/FSP. d~a and collection to analysis. SAS/FSP is used to enter the data from As soon as the twins volunteer for the all sources, and to edit and browse study they become part of the Registry the data. It provides safeguards such This is the basis for all data set. m~n~mum and as maximum values, future re.ferences to individual twins and requires minimal training o",Sugi-89-195 Schaefer Fung Deapen.txt
"DATA SHARING USING SAS/DB2'"" SOFTWARE ANDREW S. SCHLEGEL BARBARA E. LEE street lights, etc. The system needed to INTRODUCT !ON be upda ted by each of our 4 dt vis ions by numerous personnel. It also had t¢ be Since our company does not have SAS SHARE available to our 16 districts and various we have had to deal with the problem of departments with the most up to date data sharing by another means. In the past information available. The number of we were able to set up data sets for each records in the main- table would be around of our four divisions and alleviate some of 400,000 records. We determined that our the problem, As more systems were created normal SAS data sharing methods would not and th~ complexity of the systems greWt handle this type of system. So we proceeded this alternative was no longer effective~ to create DB2 tables to be accessed by SAS. A new solution had to be created to allow for data sharing within the SAS system. THE DBZ TABLES AND VIEWS DB2 was selected as the alternative when the SAS DBl product was brought in. The The following is a list of the DB2 tables initial concept we had for using this that we are using in our example. The product was a little naive. We intended to ac';.ual system uses 12 tables to maintain create our data files in DB2 and use SAS all of the different attributes of the CPR DB2 to access the data. The first attempt system. at this was to define our date: files as normalized as possible. We then tried to · Poles - This is a table with both history use ?SEDIT on the tables to update the and current information on the poles at data. Our first problem was how to update each location. dependent data or joined tables ~ We found out that only one table could be updated at · Grid - This table has the gdd numbers a time, and no views. Well, we were able and associated information about the to work around this problem as best we location in the field. We then tried to allow mUltiple could. updates to the same table. Look",Sugi-89-196 Schlegel Lee.txt
"COMPUTERIZgD DATABASE MANAGEMENT SYSTEM FOR CLINI)tL RESEARCH DATA USING SAS/FSP · IBM DMS PANELS, AND IBM VMT /SP REXX Maria H. Siu~ USDA, ARS, Grand Forks Human Nutrition Research Center LuAnn K. Johnson, USDA, ARS, Grand Forks Human Nutrition Research Center analyses at the Center. Beoause funding for Abstr'act: software was limited, it was therefore The base SAS software, SAS Full Screen decided to implement the MUSS using the data management capabilities of the SAS products. Product (SAS/FSP ), TBM's Display Management System (IBM/DMS), and IBMTs REXX System components: interpretatl ve command language can be used together to form a friendly, menu-driven The MUSS contains subject information files databa2e management system. A system can be and multiple Master data files. All files in designed that permits multiple users to simultaneously enter, brOWse, and print the MUSS are stored in SAS format to research data; that assists persons with facilitate statistical analyses {Figure 1). to generate computer minimal knowledge Ever Master data file has a corresponding Data dictionaries are used data dictionary. customized reports; and that allows programmers to easily access the data for to add new variables to t.he datasets. The data contain statistioal analysis. MUSS (an acronym for dictionaries essential Metabolic Unit Statistical System) was information about each field in the record, includIng a complete description of t.he item, developed to meet the above objectives at the its eight-character variable name, its out.put USDA, ARS. Grand Forks Human Nutrition iormat t and its unit of measure_ If a field Research Center. and is currently implemented contains a calculated value. then the on an IBM 9375, Model 60 running the VM/CMS formulas used are documented in the data operating system. dictionary. This paper discusses the struoture and function of MUSS, A series of REXX programs have been written the method used for which work with IBM/DMS panels (Figures 2 an",Sugi-89-197 Siu Johnson.txt
"trial report. While the development of the individual components is spread over a period of time, our TABSORT is a REXX and SAS system application that formal database locking and review process calls for at automates the collation of presentation-quaiity statistical least two complete runs to be performed, usually with tables for inclusion in clinical trial reports. It was created a considerable amount of deadline time-pressure. to complement a system of SAS report writer macrru whose output must be ""shuffled"" to form the jinished set The tables are organized so that a single variable is of statistical tables, a task that can take hours to presented in a series of tables, followed by another perform manualo/. variable in a similar series of tables, and so on. For instanee: TABSORT is noteworthy for the technique by which multiple CMS input files are logically concatenated in a Diastolic BP - Means single SAS DATA step. A REXX procedure verifies the existence at the input jiles, issues a series of FILEDEF Diastolic BP - Adjusted Mean Clange Systolic BP - Means statements, and writes several sections of SAS DATA step Systolic BP - Adjusted Mean Change code. Then the SAS part of the procedure is IWl, and the REXJ(-written sections are incorporated via The programs, however are necessarily arranged by %INCLUDE. 17ze resulting DATA step processes all of J table type. The abcve four tables would require two the input files as a single stream, using INFILE with the END option to control the transition between files. programs, one for means and one for adjusted mean change. Systolic and diastolic blood pressure, although originally stored as two variables on a dataset, would",Sugi-89-198 Wentworth.txt
"deviations of each observation from a target value, usually the mean of the This paper describes a SAS(r) macro observations in the series. The control which computes the weighting constant signal for the CUSUM -chart is the (w) of the Geometric Moving Average HV_maskH, a sideways-shaped V with its (Gf4A). An iterative least-squares vertex placed along a fixed distance procedure proposed by Hunter (1986) is from the 1ast plotted point of the employed to select w which provides the cumulative sums (CUSUMs). best forecast of observations useful in time-series, inventory control, and The GMA chart compromises between the quality control applications. Shewhart and CUSUM control charting schemes depending upon which weights (w)",Sugi-89-199 Alexander Macklin.txt
"· SAS Tutorial Session - Reading and writing Data to External Files Medica~ Dr. Ronald Cody - Robert Wood Johnson School demonstrate a point. Just out of New SAS users are often confused by curiosity, I asked if any of them knew the different ways SAS software can read what data cards were. None did! I and write data to external files. This started to feel very old.) You might ask is due to the fact that SAS programs can yourself, how does the proqram know when read and write many different types of the data lines end and the_remainder of data files~ For exa:JIlple, simple ASCII the SAS program begins? How does the with files are read INFILE and INPUT program know that the line ""PROC MEANS N statements, while SAS data sets two- ,use MEAN STD STDERR MAXDEC=2 J"" is not a line level SAS data set names and do not Qf data? Good r We knew you would figure require INPUT statements. This tutorial it out. It's the semicolon at the end Qf session will discuss several ways that the line. While we I re on the :subj act, SAS software can read and write a there are a few special (and ~are) cases variety of data types. The use of where we might run into trouble with temporary and permanent SAS data sets is this instream. form of data entry. discussed along with the advantages and Suppose we wrote the above program disadvantages of each. Included in this example like this; discussion are the importjng and exporting of <l,ata to Lotus spread DATA EX1:; sheets and dBASE files .. INPUT GROUP $ X Y Z, CARDS; CONTROL 12 17 19 EXAMPLE 1. Reading Data that is Part of TREAT 23 25 29 the SAS Program Itself. CONTROL 19 18 16 TREAT 22 22 29 This is the simplest way that a SAS PROC MEANS N MEAN STD program can read data~ The data lines STDERR MAXDEC=2; are incorporated in the program itself, TITLE 'MEANS FOR EACH GROUP'; following a CARDS statement. CLASS G)10UP, VAR X Y Z; DATA EX1; INPUT GROUP $ X Y Z; RUN"": CARDS; It might be necessary to use more CONTROL 12 17 19 than one line to write th",Sugi-89-20 Cody.txt
"A PROGRAM TO CALCULATE WEIGHTS FOR SPECIFIED SPECTEAL WINDOWS: A SPECTRA PROCEDURE APPLICATION Tim Arnold. University of Arkansas Ed Fryar, University of Arkansas This paper outlines the use of a SAS 1 system spectrum may provide the researcher with a good guess at the spacing of the two closest pCiaks"" A macro which calculates ,and inserts the numerical values of the weights needed in the SPECTRA pro- bandwidth larger than that interval will cedure. These weights are calculated based on obviously smooth over both peaks simultaneously. user specification of spectral window type, concealing the peaks. number of cbseryations, and bandwidth. Limitations of the Program Importance of Windows For prDgramrning purposes. only 160 weight The periodogram of a time series is not a values are used. This will give a reasonable ap- consistent estimator of the spectrum. However. proximation to the actual windows when the number by smoothing the periodogram with a filter of observations is small (400 or less raw data conventionally called a window, 'th'a filtered points; about 200 periodogram points). Weights series may become a reasonable estimator for a are calculated with the abscissa incrementing in steps of iln, (i=1.2 ·... ,80). This gives half of spectrum. There are two ways to do this: the window which is then reflected in the macro. 1. Lag Window The truncated sample autocovariance function is providing the symmetric sequence of weights passed through the Fourier transform using the needed in the WEIGHTS statement. If the number weighting procedure for the specified lag window of observations is greater than about 400 the type. program can easily be modified to calculate more 2. Spectral Window weights. The optimum solution would be to have The transformed data is filtered using the as many weights as there are points on the weighting procedure for the specified spectral perioaogram. However. these windows damp out window type. fairly quickly, approaching zero at'values I",Sugi-89-200 Arnold Fryar.txt
"A METHOD TO CAPTURE AND REPLAY SAS/GRAPH ON A PERSONAL COMPUTER Tim Arnold, University of Arkansas Edward Fryar, University of Arkansas Ghao-Chyuan Shih. University of Arkansas For those users who do not have access to SAS/GRAPH programs were it not for the GaPTIONS SASjPC*, the process of generating SAS/GRAPH* stat:emem: allowing the user to turn off certai'n images on a mainframe computer and capturing capabilities, Specifically the GOPTIONS statement necessary to obtain color images from these images for quick presentation on a personal the emulator is : computer is done in two stages. An IBM com- GOPTIONS DEV=TEK4027 NOGELL NOCHARACTERS patible PC with EGA monitor and a terminal NOCIRGLEARG NODASH NOFILLNOPIEFILL NOPOLYGONFILL emulation package with EGA capability is re- NOSYMBOL; quired. The terminal emulation software we have If these attributes are not tUrned off, the used is PC""PLOT(TM) from MicroPlot Systems_ commands entering the PC~PLOT environment conflict with themselves and the entering Major Steps graphics characters are not interpreted as an 1. The !erminate-and-Stay-Resident program image. SCRCATCH is loaded on the PC and the graphics/communication package is loaded. Connection is made to the mainframe and the SAS* Program Code graph or map image is generated on the EGA code from the TURBO Pascal 4.0 programs The SCRCATCH and DISPLAY2 follows. Note that the monitor. When the graphics image is complete. the program SCRCATCH is invoked with the keys last program, called TPTSR.ASM, is an assembler <ALT><HOME>. capturing the image on the screen to file used by the program SCRCATCH. To run these a diskette in the nAn drive. Each image file programs as discussed above, follow these steps: requires 112 kilobytes. Files names are 1. Use an Assembler to convert TPTSR.ASM into an object code file. generated within the program SCRCATCH, so users should either rename or make a note of the image 2. Place the object code file in a Turbo Pascal Unit. correspondin",Sugi-89-201 Arnold Fryar Shih.txt
"ginia ABSTRACT enters a single comnand (gennull) that eVOKes the Interactive system. SAS/AF takes Using PUT statements within the DATA _NULL_ over and prompts the user through a series data step, in conjunction with carriage of customized SAS/AF and SAS/FSp® screens control, provides a SAS® user con- ""l~imate where information is gathered regarding the trol over output when generatlng custom attributes of the display format. The user reports. This level of regulation is not is given an opportunity to select the data available when using packaged procedures set for output, enter up to 10 title state- such as PROC TABULATE. However, additional ments, select the variables to be displayed, expense is incurred to attain the power and and revise the SAS code before execution if fl exibll ity afforded. Typically, the DATA necessary. The entire process is supported NUll requires a certain degree of exper- by extensive error-checking capabilities tise -an increase in original prograIllTl1ng that provide helpful hints in the event of t time and because errors are also more preva- an incorrect or undesired entry. AlSO, fol- lent, additional computer time. lowing the help screens, a second chance to enter the information is provided so that The system we offer permits novice SAS users successful report generation is typically to easily generate otherwise complex and achieved on the first execution of the tedious title* header, and footer statements system. Finally, the resultant DATA ~UL",Sugi-89-202 Cannon Bullard.txt
"A way to realize a poster (33 11 x46 11 SAS/GRAPa'Software ) : Myriam COS SON Isabelle LAUNAY Biostatisticians RHONE-POULENC SANTE Centre de Recherches de Vitry 13, Quai Jules GUESDE 94403 Vitry sur Seine , FRANCE We're going to explain you a wax to LET'S NOW TALl( ABOU'!"" OUR TOPIC AN elaborate a poster with SAS/GRAP~Soft INTRODUCTION ABOUT GRAPHICS ware. Researchers have to explain their stu- Following points will be explained : dies results and the better way to do - Our surroundings this i8 to use graphics and posters. - An introduction about graphics Before coming to your computer key- board, you must take time to consider - the realization of the posters _ The material used {hardware; two factors : your aud'ence and what you - The conclusion wish your presentation to achieve. SOt f~rat of all, you must Know your audience LET'S TALK ABOUT OUR SURROUNDINGS How large is it ? How much does it know about the We work near Paris at Vitry/Seine in a subject '1 pharmaceutical human health research The reasons why this audience center. needs such information The effects of this information One thousand and three hundred scien- tists who are principally chemists, bio- on the audience logists, toxicologists and analysts make Set your objectives ~ researches into many fields : for ins- - What is the essential message tance immunologYt anti-cancer, analgesic you want this particular chart prospective toxicology .·. to transmit ? These people also use computers ror - Choose the right chart data management, graphics, statistical - Each ehart and diagram provide analysis, word processing and so on ... a specific kind of data compa- Moreover, we have a host computer raison - Take care to interpret data which is an IBM 43XX and other mainfra- mes like VAX 750, VAX 785, VAX 8200. On rightly not to misdlead your the host computer, are being softwares audience llke SAS,SAS/GRAPH,SAS/AF,SAS/FSP,NOMAD2 - Use the four following design prinei for data base management system, UDDH pIes",Sugi-89-203 Cosson Launay.txt
"A USEFUL GENERAL PROCEDURE FILE FOR PROC ARlMA Michael HT Dong, FDAl Yi Tscmg. FDAl In recent years, PROe ARIMA in SASjETS® tion data by means of the [A]uto[R]egressive [I]ntegated [M]oving (A]verage processes devel- has been used extensively by""the Food and Drug Administration (FDA) to forecast annually. for oped by Box and Jenkins. The stochastic models a lead time of 24 months, the quantity of each in this class are usually denoted by the mathe- of 20 or more controlled substances that are matical notation ARlMA(p,d,q). where p repre- used for medical or research purposes nation- sents the order of an autoregressive behavior, wide. Typical examples of these controlled d the order of differencing, and q the order substances are: amphetamines, cocaine, co- of a moving average process, all of which are standard features of a time series whose behav- deine, hydromorphine, meperidine, methamphet~ ior can be characterized by the ARIMA process. amines, methadone, mQrphine, opium, oxycodone. In practice, PROC ARlMA models the behav- and oxymorphone. This forecasting analysis re- quires that laborious and repeated efforts be ior of a user-specified variable that forms an made for model building, which is a process equispaced time series with no missing values. concerned primarily with relating a class of The model building process in this procedure stochastic ARlMA models to the time series at -is divided into three distinct stages, corre- hand. The underlying analytic procedure is sponding closely to the ones described by Box thus one that inevitably involves the process and Jenkins. These are represented by the IDENTIFY. ESTIMATE, and FORECAST statements of evolution, adaptation, and trial and error. In short, such a forecasting analysis entails that must be included in that order in PROe that 10 or more ARIHA models be specified sepa- ARIMA. Among other things, the IDENTIFY state- rately for - each of the 20 or more time se- ries on drug use. ment is used to bring in",Sugi-89-204 Dong Tsong.txt
"nik~ Saltimor~ ABSTRACT causes the noise characteristics for one monitored sigoal to change (e.g., a large variance,. skewness,. or sigoal blas) then the It has become common practice in nuclear power plants to install redundant sensors for SPRT provides a rapid' annunciation of that mOriitoring criticai physical variables (pres- disturbance. An example of the use of the sures, temperatures, radiation levels, etc.). SPRT for surveillance of primary coolant pump ThiS paper reports on the desi gn and testing operabi lay is presented us; og data recorded of an extremely sensitive component-operabil.., during a pump disturbance event that occurred ity surveillance algorithm that 1s based on during full-power operation in ERR-II. the sequential probability ratio test (SPRT). The SPRT technique, implemented in SAS@ soft- SAS software was chosen for this project ware. processes the stochastic components of because of the languagels powerful coding digitized signals from identical sensors on features and its abil ity to model prototype two or more components in an operating re- sys.tems quickly and cost-effectively.. All actor for detection and annunciation of off- experimental data employed in this investi- normal operation. Information made available gation were first tested for non-Gaussian from the SPRT can provide a reactor operator effects using the Ko1mogorov-Smirnov test with PROC SPECTRA. SAS macro lanyuage was with early identification of the incipience exploited in a param",Sugi-89-205 Gross Humenik.txt
"Index Your Book with the DA.TA. Step Language Jag A. Jaffe overOOard with minutiae, to follow and good indexing ~ics~ Indexing mechanics can be greatly facilitated by computer; a computer can also provide Faced with the high cost of indexing, the author dooided to write a program. to help him information that guides substantive decisions aoout the index as it moves through edit. The produce the index to a book. The high-level best Fe' programs for the job, meant for input/output features available in the SAS< r) professional indexers, cost several htltldred. DATA Step Language, along with other SAS System dollars. While magni tuies less than the cost of utilities, seemed well-suited to the task and, contracting the job out, I found even this too since his book was about the SAS System, it excessive. After all, I didn't need options for seesned the poetic way to go. '!he strategies and every occasion, just a minimal toolbox to help programs used are presented here. me get one job done t and several hundred is a lot of sushi. In contrast, the single public dOO\B.in offering I found (,.) -was very limi. ted, 'lhough it may not be true of the fashionable inadequate fpr my needs. No, there -was nothing for it but to write m:y anc:l famous, the average author, like the average artist or actor t does not expect to make a own program. living from hislher art, unless ""living"" means sleeping in the alley and dinirut at the dumpster. Authors' profit margins being just that, Though I also program in the C language I I marginal, i t is all the more important for chose the SAS System to implement the indexing 'Writers to limit those costs that publishers, in routines ( f ) f for two reasons. First, since my their omnipotence, thrust upon them. In the book was about SAS prograntni.ng, the idea of non-fiction world, one of these costs is index producing the index with. the aid of the SAS prepar&tion~ some cosmic malediction t System waxed poetic to my mind. Second, since I By typi",Sugi-89-206 Jaffe.txt
"T ture. See Bark (1984) and searle The purpose of this paper is to (1988) ~ The only completely general present a general method for the methods would appear to be maximum analysis of repeated measures data, likelihood, as implemented by BMDP3V, when the sphericity assumption holds, or generalized least squares following using PRoe GLM. This approach can be estimation of ~t and ~; by some method used regardless of whether there is (Searle, 1966). missing data or continuous independent With complete data, most major variables. The approach consists of a software packages have programs to model statement which includes a analyze model (1) ¥ including FRoe GLM random ·subject (or, in general, with the REPEATED statement, as long experimental unit) term. ESTIMATE and as there are no repeating covar iates. CONTRAST statements are used to test Wi th incomplete data,. PROC GLM can be hypotheses on between subject effects used to fit model (l) if a SUbject and to determine least squares means. term added to the model is and The method specifies what the declared RANDOM. The problem is that coefficients of the subject terms least squares means are sometimes should be in these statements. In determined by SAS to be non-estimable general, the parameter estimates are and the usual sums of squares some- approximately those which would be times do not test the hypotheses of obtained a generalized least from interest (Milliken and Johnson, 1984) ~ assuming that the squares analysis Milliken",Sugi-89-207 Kaiser.txt
"the sample size Is increased, We do not, Often in U'le evaluation of sampling techniques and hOwever. anticipate any slgnif;cant effect on Job performance by estimation procedures, it Is necessary 10 generate multiple random either Increasing or decreasing the number of strata, therefore we samples. A SAS@userwishlngtogeneratesuchsamplescandoso will consideJOO1y two leVels (H=5. 10). by using either SAS Macro language or SAS interactive Matrix (!\ 10 order to cover a sufficiently broad range of values of the Language (SAS/IM!. lhe question now arises as to which software is more appropriate to use. Using SAS macro Involves control' parameters, we will Investigate five different sample sizes multiple repetitions of Ule <lata step and multiple executions of the which correspond to sampling proportions of 1 %,2.5%.5%, 10%, output statement, while SASflML involves extensive subscripting and 20% of the universe (n/N). The numbers of samples to be = 10,25, 50, 100, 250, and 500 tn and manipulation of matrices. To determine which software is most generated were Chosen to be m appropriate, we will compare the two on the basis of efficIency, as the hope of being able to Investigate the functional form Of the cost measured by execution time, amount of region required, amount 01 curve for earn approaCl'l. We would like to know. for example, tf the 110 Involved and total computing cosl The end result of this study rate of cost Increase diminishes as the number of samptes Is will be the",Sugi-89-208 Leddon Bauer.txt
"A SASjAF® Software Application to Build Programs from Independent Modules Steven Ugh!, Sterling Research Group select modules accesses the lists maintained by the Introduction user and allows the user to indicate which modules are to be included in a user massage, along with the order in which modules will be placed wahin the program. TIle Research Data Management section ofthe The procedure to assemble user massage programs Sterling Research Group (SRG) uses a clinical informa- tion system based in CMS SAS ® datasets. These da, determines what modules have been selected and executes a procedure to assemble the files. tabases are used in analysis of data from clinical trials in development of new drugs. Updates to the data- bases are performed overnight and consist of three Adding or modifying entries to the system steps. First maintenance is performed, then new data is added. In the final step data are manipulated and Each user can create and maintain their own analysis data sets, used for programming purposes, are generated. The program used to execute this step SAS dataset wtth lists of databases and associated is referred to as the ""user massage"". user massage modules. Thedatasethasoneobserva- tion per database with information on up to ten mod- ules. Information for each module includes the file A user massage program consists of a basic name, the account name of the responsible program- module that is executed each time the database is mer and a field to help in setting the sequence of updated, and up to ten independent modules to pro- modules within the program. From the main menu the duce analysis data sets. It is often necessary to update user accesses the data set through SAS/FSEDIT only some of the analysis datasets for a given data- base. Each night different combinations of data sets screens to make additions and modifications as needed (Figure 2). are updated. Consequently, user massage programs need to be modified frequently. often on a daily basis.",Sugi-89-209 Light.txt
"Introduction to Arrays by Robert VirxiJe Independent Thacher and Consultant Overview DATA NEW; SET CITIES; IF BIRDS = . THEN BIRDS = 0; This paper explains the basics of derming and using an array. The information and examples IF BEES = · THEN BEES = 0; will be useful to the programmer ..mo is either IF FLOWERS = · THEN FLOWERS = 0; IF TREES = . THEN TREES = 0; unfamiliat with or confused by arrays. The IF SKY = . THEN SKY = 0; basics are simple enough that most programmers will begin to successfully use arrays immediately IF ABOVE = . THEN ABOVE = 0; IF LOVE = . THEN LOVE = 0; after readingtbis paper. Therefore, this program is a prime candidate for What III an Arra'fl constructing and using an array. A revised program would place an seven variables into an An array means 'll subset of the variables that array and then process an variables in the array. make up one observation of a SAS(R) dataset"".(l) A sample data set might consist of 11 variables, with 7 of those variables making up DATA NEW; an array. SET CITIES; ARRAY LYRICS BIRDS BEES FLOWERS (7) Variables within TREES SKY ABOVE WVE; $AS dataset CITIES: DO INDEX = 1 TO 7; IF LYRICS (INDEX) = STATE THEN LYRICS (INDEX) = 0; BIRDS } END; } BEES ) These FLOWERS This revised pro gram produces the same result, TREES ) variables but is more economical in two ways. First, the } make up SKY program is three lines shorter. Second, it ) an Array. ABOVE becomes very clear that exactly seven variables ) LOVE are being processed. Therefore, it becomes INDEX easier to understand and maintairi the second CITY program. (Note the difference if the array POP contairied 80 variables instead of 7. The second program would still contain six statements, By defining an array that consists of these seven although the ARRAY statement would be variables, the programmer can more easily and longer. The IlIst program, hov.ever, would add economically process the variables. Usually the 73 more statements.) array helps ..men all its variabl",Sugi-89-21 Virgile.txt
"SIMPLE MEDIATION MODEL Mediated or indirect effects play a major 8 role in social science theories. The existence of these effects indicate that the relationship between two variables depends on an intervening · variable. For example, peer influences may mediate the effect of intelligence on adult socioeconomic status. Joreskog and Sorbom c (1981) present matrix formulas for the calculation of indirect effects. Recently, Sobel (1982; 1986) derived matrix equations for the calculation of the standard errors of =a xb INDIRECT EFFECT indirect effects. The purpose of this paper is to present a SAS/I~ matrix program for the DIRECT EFf'ECT '"" c STANDARD ~R OF THE lNDlIU«:'f tfPEC'I' calculation of indirect effects and their standard errors. The program shows the versatility and easy use of SAS/IM~ for matrix The effect of the independent variable on the calculations, Because SAS software is widely dependent variable can be decomposed into a available, the program should be accessible to direct effect (c) and an indirect effect researchers who need to test the statistical through a mediating variable (ab). The significance of indirect effects. Program input decomposition of total, direct, and indirect can be obtained from any covariance structure effects for more complicated models has been analysis program. Output includes estimates of described (Alwin and Hauser, 1975; Bollen, indirect effects and their standard errors. 1987). Joreskog and Sorbom (1981) present Several examples are presented. matrix equations for the calculation of these effects.",Sugi-89-210 MacKinnon Wang.txt
"Using the SAS* System for Empirical Bayes Estimation and Mapping of Suicide Rates in California Beverly F. Martinez, Kung-Jong Lui, Marilyn L. Kirk and Joseph L. Annest Division of Injury Epidemiology and Control, Center for Environmental . Health and Injury Control, Centers for Disease Control ·. Pubh.c R01!a1th service, U.S..- Department of Health and Human Services., Atlanta, Georgia 303-33 METHODS INTROOUCTlON The. :,tatistical reasonng and ~ations of using In order to identify COU1ties that are most ... need empirical Bayes estination of rates are <isC1lSsed of suicide control and prevention services. we need thoroughly in lui, el al (in prer-ationl A brief a summary mortality index that has two desirable review of the methods bennd the SAS macro properties. F..-sl it must be relaNe. ie., it must f~W$. let Dxi be the nunber of suicides for a not be subject to too much random variation grven C01.M1ty x and a specified age-group i, Second. it must correctly indicate the refative Asst.Mtle a Poisson distooution for the number of magnitudes of sUcide morlaIity among the COlKltieS. Suicides 0xi with mean P xf'txi ~ where P xi is The crude rate. detr.ed as the total number of M· is the _ the mid-year population and deaths divided by the total pop<AatiM, is a -=- t Assume also X I - prior- a Gemma - ~""""lt\O. ra e. St..mO""W""Y ndex. but is not comparable ,between distribution for the age-specific rate M.. with counties with different ~tion age dstributions mean =y'Rj · It can be shown that the ~osterior The ~ rate is the tReIss, 1981). distribution is Gamma with mean number of deaths in an age group divided by the population in. that age group. A coIection of age- (Oxi ....... V£P xi ... l' specifIC rales gives more information than the II{ crude rate. but is not a summary i'viex. More This posterior mean is the empiicat Bayes estimate appropriatefy~ information can be sunmarized, using of the. age-speclfic rate for <:ou1ty )( and age- a weighted -average of the age-sp",Sugi-89-211 Martinez Lui Kirk Annest.txt
"Complex Survey Computations Using C James W. Mergerson u.s. Department or Agriculture APPENDIX. PROGRAM LISTING INTRODUCTION *' In some statistical applications, base SAS'"" software 1* Compule Inclusion Probabilities #include <Stdio.1D and SAS 1STATTM ate not good choices for #detine max 100 perfonning some typeS of statistical computations. *' msin 0 ( The C programming language is more than an adequate alternative for some statistical 1* INITIALIZATION AND INPUT in! Icntcapn,smn,nI,n2,n3,n4,o5; computations. This paper iIlustrares a type of statistical computation in which C is a much better int i1J2,i3,14J5; choice than base SAS'"" software or SAS ISTATTM. fioat plmaxl, pi[maxl; double suml,sum2.swn3.sum4; double templ,temp2Jemp3,temp4; nl=O; 112=0; 03=0: 04=0; 05=0; icnt=O; DISCUSSION printfC'en!er capn "");scanl(""%<!"" ,&capo); SUppose a sample is selected strictly pmportional to prinlf("" capn= %d "", capn); ptintf(""enler srnn ""); scanf(""%d"" ,&smn); the sizes of the S3IIlpling units and strictly without ptintf("" srnn = %d "", smn); replacement. Let ""i denote the probability that unit if (srnn>=l) nl_pu; if (smn>=!) n2=capn; Ui is included in the sample. Let D denote the if (srnn:=3) n3=capn; if (smn>=4) n4=capn; sample size and Pi denote the probability that unit if (smn>=5) o5_pn; Vi is se\ecled on the first draw. A genernl fonnula il=l; while (i1<=capn) ( [I) for computing ""i is presented below: printf("" enler p[%d] "")!); scanf(""%f',&P[il]); il += I; J + Pi 1: Pi1J(1-Pi)+ =pj ltj f* MAIN ALGORITHM *f i1, E 1 11=1; while (i1 ¢ : nl) { icnt++; i1 f! i surol=O.O; sum2=O.O; sum3=O.O: suro4=O.O; i2=I; while (,i2<=n2) { icnt++; lempl=O.O;' L L Pi, 1(1 - Pi, - Pi,) + ... + Pi Pi, /(1 - Pi) if (i2 != ill ( i1. E l i , .. I templ=p[i2]1(I-p{i2)); i,#i il;eI suml=suml+templ;] i, '"" i1. i3=1; while (i3<=n3) [ icnt++; temp2=O.O; if (i3 != ill { if (13 != il) ( L Pi, 1(1 - L Pi Pi) Pi, 1(1 - Pi, - Pi,) X X,"" temp2=p[i3]1( l-p[i2)-pli3]); i l -el ;3 E1 sum2=sum2+temp2*templ;}",Sugi-89-212 Mergerson.txt
"lU!PlU!S~IN(I COHPUTSlUlIBD TOJIO<IRAl'IIIC SCANS USXII<I TIlE GlIAP PROCSDUlU! IN SAS/GRAPH SOFTWAlU! A. T. Polis, NINDH, K. Foulkes, NINDS J~ Kobr~ New York Neurological Xnstitute and D. Bier .. Kichael Reese Hospit.a1 Medical center T. R. price, university of Maryland Hospital P. wolf, BostOD University Xedical Center patients were contained in the SDB Abstract: Computer tomography (CT) scan Manual of Operations (SDB, 1979). The information collected included: data have been collected from 1983 to 1986 on 1805 NINDS Stroke Data general medical history; history of Bank patients who were admitted to the onset of the stroke; initial one of four academic medical and follow-up neuro1ogical exami- centers. Due to compatibility nation: therapy; and outcome. problems among the CT scanning Neurological exams were planned to equipment at these four sites and be done on the fo11owing schedule, fiscal constraints, the horizontal although intermediate exams were CT scan images collected on each performed when necessary for the patient were represented pictorial- patient's welfare: 1) within 7 days ly using a coordinate qrid system of onset of the stroke, 2) 7-10 specially developed for this days; 3) 3, 6~ 12, 24, and 36 purpose. In order to visualize months after the stroke. lesions vertically across different CT scans were not required in slices of the CT scan picture, a the SOB, although almost all method of mapping lesions from the patients had at least one scan horizontal plane to the vertical during their hospital stay. All CT cans performed were included in the plane was developed. This paper will exhibit and SDB data base. Data collected describe the graphic techniques for include: the number of lesions: presenting the lesions in both location of the lesion; pathology vertical and horizontal planes~ and density of the stroke related Overview - stroke Data Bank; lesion/s. As the clinical centers The NINDS initiated the stroke could not directly record the Data Bank, a",Sugi-89-213 Polis Mohr Hier Price Wolf.txt
"Producing Muftiple Graphs Using Macros 60% Code Reduction Madelyn A. Remsburg U.S. Army Medical Research Institute of Infectious Diseases CAUTION: When a macro reference variable is SAS/GRAPH® used with macros improves included in a title or name statement, DOUBLE efficiency and reduces code in the production of QUOTES must be used. muttiple graphs. This technique allows the creation of template programs that become dynamic with the SAS/GRAPH® and SAS® are registered use of macros. The parts of the program that change trademarks of SAS Institute Inc., Cary, NC, USA. most frequently are represented as macro reference variables and modified, as needed, in one The views of the author does not purport to convenient place. An excellent data source to reflect the positions of the Department of the Army display and utilize this technique is in the research or the Department of Defense. and development area. Typical research and development data have several variables measured Madelyn A. Remsburg at specified time points. Normally, means and Armed Forces Medical Intelligence Center standard errors of all variables of comparison groups Automation Management Division are displayed graphically against each time point -- Fort Detrick generally as a simple plot: X·Y=Z. This is done at Frederick, MD21701-5004 the onset of analysis so that the researcher and (301) 663-7581 statistician may have a quick ""look see' at which variables should be examined more closely. 'Quick"" SOURCE CODE PROGRAM is the operative word. By use of macros, these %MACROMM; graphs can be produced, revised, and reproduced GOPTIONS DEVICE.EGAL COLORs,,(BlACK RED GREEN quickly and easily either on hardcopy or screan BLUE) ; display. UBNAME YY 'C:lMYUBlDATA'; zz. LlBNAME 'C:\MYLIBlGH'; HOW? Using PC SAS@ and PC 111l.El 'SAMPLE STUDY OF DRUG XX'; SAS/GRAPH® , this technique can be submitted FOOTNOTEl J=L *&SET""; interactively or batch. A source code template SYMBOLl C=BLUE V.NONE I.STD1MJT L.l program and a mac",Sugi-89-214 Remsburg.txt
"THE APPLICATION OF BASE SA$"", SA$ISTAT"", AND BAS/GRAPH"" SOFTWARE TO THE ANALYSIS AND PRESENTATION OF PHARMACOKlNETIC DATA Philip H. Schwartz, C.Ph., Division of Pediatric Intensive Care, Childrens Hospital 01 Los Angeles, School of Medicine, University of Southem Califonia and Departmont of Neuroscience, Brain Research Institute, School of Medicine. University of California, Los Angeles An important area of biomedicaJ research invotves the (Eq. I) description of the distribution of a drug in and the e6mination where C. is the serum concentration of MK-801 at time~ t. (t of the drug from the body. This Information provides the and J3 are the first-order rate constants and A and B are the clinician with valuable data with regard to the timing of drug concentration intercepts at 1=0. From these rate constants and doses and possible toxic complications of the drug (Please intercepts, standard pharmacokinetic parameters are derived see Gibaldi, 1984, and Bourne, et aI., 1986, for ,.lIiows). (See Glbaldi, 1969, 1984, Levy et al., 1969, and Bourne et al., Typically, the drug is administered orally. intralTlJscularly. or intravenously and serial blood samples are then taken and 1986). The equations for these are included in the program statements below. chemiCally analyzed 101' drug concentration. The tirne-course of the change in drug concentration in the blood is then All data handling and statistical analyses were done using analyzed mathematically (ThIs is what is usuaHy referred to as SAS' (SAS Institute, Inc., Cary, NC) under MS-DOS' (i.e. pharmacokinetics). This involves fitting the time-concentration SAS-PC). All PAOC output to tho OUTPUT window of the Display Manager System was saved to DOS files with the data to a mono-, bh or tri--exponential equation using non- fiLE 'pathname\filename' command and was subsequently linear regression analysis. The coefficients and exponents derived from such an analysis can then be used to derive read directly into the word proce",Sugi-89-215 Schwartz.txt
"FAST TRACKING FOR THE CLINICAL SCIENTIST USING SAS' SOFTWARE Arthur C. Singer, Wyeth-Ayerst Research Caroline M. Bobik, Wyeth-Ayerst Research AilS TRACT Clinical trial record keeping is The flrst of these panels lists the one of the most important aspects for investigating physician's identification the success of the study, as well as including the protocol number l his/her name l professional address, telephone being very time-consuming. The clinical scientist must monitor the progress of number! the study coordinator(s}! and subinvestigator{s}. the study at periodic intervals. This situation requires that information The second af the panels lists the patient's demography by protocol and concerning the investigating physicians, study coordinators, regional clinical investigator. Patient number l patient's initials , date of birth, and sex are associates, and the study patients be given in this program. These current assembled in an efficient manner for examples use previous patients who ~ere quick and precise information retrieval. transferred from one protocol to A certain amount of information can be another; therefore the panel contains monitored during a double-blind clinical trial. Keeping track of patient status the patient's previous investigational history. and study finances can be done by the clinical scientist using a combination A schedule of patient visits can be for a of basic SAS* software procedures. Much long-term study. predetermined Such a schedule is displayed in the of the information can be immediately third panel. It includes the patient!s scanned after sorting and outputting i t by study attributes. Legible output identification along with enrollment that does not require decodinq by the date proposed visit dates, actual visit l clinical scientist is a must. dates, and the difference (in days) between the tvo visit dates. Current patient enrollment is often requested by study monitors. Hardcopy, both in printed and graphic form, easily IN",Sugi-89-216 Singer Bobik.txt
"Fill in the required fields. and select the level of documentation desi:ri!d.. By using the 'Selection Mask' SASI AF®is without a doubt one of the sWg1e most and-'Screen Type' selectors you can choose to document important and useful additions to the SAS product and combInation of screens from one (1) particular to Une. SASJAF provides the ability to tie numerous the entire contents of the library. individual program modules into a complete ""user-friendly"" system. However. its btgggest Screen Index? shortcomJng from a program development point of view is the inability to provide full and complete 'ntis index provides an a1phabeticallJsUng of aU documentation as to the contents .of the SAS/AF selected screens and the page numbers on which they libraries. This paper presents a program developed appear. usmg the SAS system by the Operations Buslness Systems department at General Dynamicsl Convair Macro Variables Index? DMsion to solve this problem. LiSts all macro variables appearing on the lnput sections",Sugi-89-217 Sisemore.txt
"ants to identify kelp density data that were ABSTRACT in the interior of the kelp beds. There are several programming problems to Software was wrTtten using SAS encountered when dealing with polygons calCUlate the areas of kelp beds, and to of unusual shape. The polygons are identify kelp density data points that often digitized from published maps and lie within the borders of the kelp beds. reports and then associated with data This software calculates the total area from other sources. The resulting data are then summarized using SAS/GRAPH® of all kelp beds in the area, creates a variable identifying kelp density as (GMAP or GPLOT). Two of the more interesting of these problems deal with inside or outside these kelp beds, and area estimation and the determination of merges this data into permanent a interior points. database (Table 1). An example plot is provided as Appendix A that uses the Polygons generated from digitized database created in Table 1. This plot displays actual kelp forest borders with information are stored as a series of kelp labeled density locations sequential x, y coordinate pairs. There differently inside and outside of the is no information in the resulting data set which allows the programmer to ke.lp bQds. The total arQa of the kelp bed is output onto the plot using the determine if any given x,¥ coordinate pair is inside or outside of the ANNOTATE facility. The problem is, of course, polygon. compounded when the polygon has unusual METHODOLOGY -",Sugi-89-218 Smith Carpenter.txt
"goals is made during weekly meetings when each manager responsible for an ap- Response data for on-line CICS applica- plication system reviews the relevant tions is recorded at the transaction level, month-to-date response plot Most sys- classified by resource usage and response tems usually meet their goals, so very little time, and stored in a SAS® data base. Sub- time is wasted looking at data which basi- sequently, management oriented plots are cally says, ""everything is OKI"" When this is generated with SAS/GRAPH®, and PROC not the case, supporting data can be REPLAY is used to t::Ombine them in reports viewed on additional plots to gain further in- which draw attention to any non-com- sight into exceptional conditions. pliance with specified goals. This poster paper outlines the analysis CLASSIFYING TRANSACTIONS methodology, discusses the motivation for All transactions are recorded by The each type of data display, and provides sample SAS code and SAS/GRAPH output. Monitor® for CICS, which collects data in real time and stores it in compressed form. This is read daily by Merrill's MXG® code and stored in SAS data sets in the MXG Per-",Sugi-89-219 White.txt
"HOW TO TEACH THE SAS® SYSTEM TO WRITE YOUR NEXT SAS® PROGRAM William R. Greenwood, General Dynamics Steve G. Holson, San Diego Data Processing Corp. FILE OUT NOTITLES, Introduction IF N ~ 1 TBEN puT @2 ""PROC FORMAT DDNAME SASLIB; .~ A SAS® program which can write and execute a I @4 ""VALUE $CLASSES·: SAS® program is a very handy tooll n PUT @1 II I How many times have you wanted to modify an $3. CODE @2 existing program to meet new selection criteria or @5 IIIII @8 II_II add a new element to a SAS® Format Ubrary? How @10 many times have you wanted to modify Job Control @ll CLASS n I ... ; Language (JCll and submit the job based upon a customer's request? IF NOMOI'S THEN "";n ~1 PUT These changes can be done by the customer as an I @l ""RUN;""; interactive or batch job, without the customer RUN; needing to know how to code in SAS® or write JCl. The power of SAS FSP® andlor SAS Af® can also Results make the job easier, but is not a necessitY. PROC FORMAT DDNAME SASLIB; = This paper has three examples of programs which VALUE $CLASSES generate SAS® code, and a fourth example which tOOit 'SAS BASICS I I generates and executes JCL. Each has an INPUT '002 r '5AS FSP I file, PROGRAM, and RESULTS. In some examples 'SAS BASICS II ' '003' you may see an easier way of accomplishing the '005 1 'TIME SHARING OPTION (TSO) I results, but for clarificafion, shortcuts have been 1006"" '.JOB CONTROL LANGUAGE (JCL) , omiHed. '0011 'SAS GRAP 11 I RUN; Example 1 Example 2 Requirements Requirements Write a SAS® program which will build a PROC FORMAT procedure to load the classnumber with the Write a SASe!!> program which will create a class name into a Format Library. The procedure SUBSETTING IF. The SUBSETTING IF statement could be executed as an Interactive job or by a balch job. could be included into another SAS® program either as a MACRO or as a %INClUDE. Input Data Input Data SAS BASICS I 001 SAS BASICS I I 003 34?8~ 002 SAS FSP 42 005 TIME SHARING OPTION (TSOI 53687976 JOB CONTROL LANG",Sugi-89-22 Greenwood Holson.txt
write a MODEL statement specifing only a dependent variable. Using the OUTPUT This paper uses SAS* software to create OUT optinn~ a BY statement and L95M and U95M statistics the SAS System will a graphiCAl representation of a 95% confidence interval for the mean~ A put the 95% confidence intervals for the mean (dependent variable) into an output reference scale is printed at the top then confidence intervals (i-~--:) of data set. This new data set contains 1 observation for every observation in the appropriate langth are printed on separate lines with optional labels input data set. When the confidence intervals are actually printed only 1 attached. observation per BY group is needed sinca,Sugi-89-220 WildmanPepe.txt
"Color Coding Schemes Using SAS/GRAPH® Software Leslie Wort; National Demographics & lifestyles Inc. Introduction The saturation parameter will remain constant througbout the chart and is passed as any value from Many business graphics must show several shades 1 to 100. of one Or more colors on the same graph. The SAS"" HLS, RGB and Gray Color Cnding 'Schemes are The color bars will be labeled across the top with powerful tools for creating such graphics. Colors of the corresponding hue and down the side with the the same hue need to be discernable from eacb other corresponding lightness and saturation. The values while at tbe same time having a balance between them that appear here will be presented in hexad<:<imal that is maintained for each color cbange. numbers so the user can create a color name WIthout having to do any conversions. Using tbe color coding schemes to find the right colors can hecome a lengthy guessing game. The best way to choose colors is to have a list previously RGB Color Coding Scheme printed on your own graphics printer of the available colors (or at least some of them). The following The procedure is similar for tbe RGB color coding macros produce these color charts. system except that additional parameters are required in order that the user may cboose which color (red, green or blue) should remain a constant for the two Description dimensional color chart and which colors appear on the horizontal and vertical axes. Three macros are used, one each for tbe IlLS, RGB and Gray color coding schemes. These macros The first two parameters are the name of the coior, are far creating charts of from 176 (for the RGB which is to remain constant, and its value. The second two charts) to 252 (for the HLS and Gray charts) colors on parameters are for the row color and its starting The charts are labeled with t~e one graph. value. The row calor will be incremented by eight for hexadecimal numbers necessary to name the colors m each row for a total of 11",Sugi-89-221 Worf.txt
"WEIGHTED MULTICOLLINEARITY DIAGNOSTICS FOR LOGISTIC REGRESSION Brian D. Marx, LSU~ Department oT Experimental Statistics Eric P. Smith~ VPIkSU, Department oT Statistics (). ABSTRACT. X'X, has been examined a $ a diagnostic Logistic multiple regression is a tool to determine the ill-eTfects of special case oT the generalized linear multicollinearity on parameter model utilizing the logit link function estimation and prediction. Schaefer with binomial response data (NeIder and (1979 and 1986) has presented arguments Wedderburn, 1972). Maximum likelihood justifying the application oT estimation, via the method oT scoring~ multicollinearity diagnostics based on is commonly imposed to estimate unknown parameter ve'Ctor~ 2., in the -following XIX for logistic regression. However, further theoretical investigation (Marx, relationship: X f!. 1988) suggests that diagnostics should Iogit (H) be oriented toward the spectral Estimation and prediction problems, decomposition of X'VX. Multicollinearity similar to those of least squares diagnostics can be formulated among the multiple regression can arise in weighted explanatory regressor variables logistic regression resulting from which oTten yield more pertinent multicollinearity among continuous information Tor selection of a candidate regressors in the X matrix. Traditional multicollinearity diagnostics using SAS~ model. software, as presented in PROC REG~ may For the model not be relevant to logistic regression rl'::~i] ~/d!'"" ' (11,) since they are based on the condition OT = In = logit Further theoret i ca.l exami nat ion X'X. suggests that the condition oT the 1 define ""i = P(Y=lb:s.'i), ?5. · to be the i th !stimated information matrix, X'VX, where row vector or the N x (p+l) matrix oT = diag {n. (l-fr~)}, is more pertinent V continuous explantory variables (with a to .the logistic regression. This paper constant) and! to be the (p+l) x 1 presents weighted multicollinearity unknown parameter vector. The iterative diagno",Sugi-89-222 Marx Smith.txt
"ESTIMATION OF ERROR RATES IN DISCRIMINANT ANALYSIS BY BOOTSTRAPPING Jacque~ Delince t Agriculture Project, JRC European Communities European communities Javier Gallego, Agriculture Project, JRC error rates, using a fixed number (i~e~ b=20} of tndependant bootstrap training sets, obtained by sampling randomly Introduction the within category empirical probability distributions (which means Estimation of error rates in to draw for each category a random discriminant analysis has no unique sample with replacement of size ni from solution in the case of unknown the original sample). For the linear param9ters. Two estimators are proposed by Efron, sampl~ discriminant function with two the second being prefered if the number populations, Arnold !1981) gives five of bootstrap training sets is small. methods for estimating the probabilities on Both are based the results of misclassification, respectively; obtained by classifying the o~i9i~al sample with the discriminant rule based -e)(ac,t s><pression with estimation of the unknown 0 parameter, on a bootstrap training set. Both take -resubstltution, into account the number of times <h) -leaving-ane-out. each original data appears in the -Lachenbruch and Mickey's method, bootstrap training set: -Okamotols method~ Following this Quthor, the last three b ni * aT 1 ( i , j ) = ( lIb) E(l/ni) E (I-h) Q(x ,y ) methods give rather similar results, with some potential advantage to the 1 l~l 1 1 leaving-one-out method in the case of hOn normality. * n The main problem we see in the leaving- BT2(i,j) 1: 1: Ph (l-h) Q(x tY ) -one-out method one hag to is that h=O (b,l:h) 11 compute as many discriminant rules as they are data in the sample, which n-h h n becomes rapidly too costly in computer C <n-1) / n with Ph time. n Efron (1993) proposed a method based bootstrapping, rather similar on 3. to add the results of steps 1 and 2, theoretically to the leaving-ane-out, obtaining unbiased error rates with which but the number of estimation",Sugi-89-223 Delince Gallego.txt
"on Abstract: Diagnostic methods for discriminant analy- of the discriminant score,and the Mahalanobis distance sis are discussed. The equivalence with linear regression between groups. Some of his work is similar to the reo- is noted and diagnostics used in that situation are con- sults given below. sidered. It is shown that both the leverage and Cook's distance are functions of the linear discriminant func- We shall assume we are performing a two group discriminant analysis where the groups have a common tion and the distance of the observation from the group covariance matrix. The usual LDF arises if we assume mean. Some examples are given. multivariate normality of the observations, x, or if we find the linear function which maximizes the ratio of the Key Words: MahalanQbis distance, Cook's distance, between groups sum of squares relative to the within Leverage group stun of square. (see, e.g. Lachenbruch, 1975)_ Introduction: Au important component of a re~ The normality assumption ca:n be used when we con- sider diagnostic plots. In the following, we will let gression analysis is the investiga.tion of data. points which may distort the analysis because of high influence or un- usual values ·of the dependent or independent variables. This investigation may result in removing the unusual be the sample discriminant flUlction 1 where S is the sam- observation from the analysis or in giving it reduced weight. Similar concerns exist in two group Discrimi- ple pooled covariance",Sugi-89-224 Lachenbruch Wang.txt
"HANDLING MULTICOLLINEARITY KITH SAS IML@ SOFTHARE: RIDGE REGRESSION ON THE PC GARY WILLIAM CARR, NYNEX GERALD TLAPA, BELLCORE 1.0 Introduction. where (X'X) is the correlation matrix and is Analyses of economic data must consider non-singular. the likely presence of multicoll inearity. If b · {X'X)-l X'Y (5) one is interested in studyIng Gross DomestIc where (X'X)-l is the inverse of the Product {GOP) versus other macroeconomic correlation matrix. The solution b has the infrastructure components, multicollinearity following properties: wIll b. anticipated since components of the 1) It estim.tes B with minimized error sum infrastructure generally march 1n harmony with of squares irrespective of the distribution GOP. for example, many correlation studIes have function of the errors. shown a strong direct relationship between GOP 2) The elements of b are linear functions of and Energy. (1) In particular, this relatIon- the observations Yl, Yz. ""'Y n and shIp has been analyzed by Janosl and Grayson provide unbiased estimates of the elements wIth a.resulting R' l 0.9 in thirty-two of of B which have the minimum variances the thIrty-four cases studied. These results irrespective of distribution functions of were obtained by using a log-log model assuming the errors. constant rates of continuous growth. (2). Normal use of ordinary least squares As the number of variables increases regreSSion assumes that the input variables are within an econometric model, the concern with uncorrelated. In addition, the researcher wants multicollInearity increases since the as many observations as possible per variable to probabilIty that some variables measure similar insure that a purely random component will be phenomena increases. Presence of multicollin- less likely to affect inferences about the earity violates the assumption that the deterministic portion of the equation. Economic explanatory variables in a regression model are data, however, are often sparse. especially with not st",Sugi-89-225 Carr Tlapa.txt
.odel'aituations for nonlinear Measureaent error .odeI8~ First~ when the .odel is nonlinear in Measurement errQr aodels involve independent vari- either It and ~. but witb relatively few ables whioh are observed with error. These observations. Next. considerable attention will if they nonli~ar ar~ *cdels are said to be be focused on a aethod for a general .odel witb th~ variabl~s nonlinear in eitber independent or In both cases. observations~ large nu.bers of A~proa¢heG the unknown paraaeters. to PArameter computing procedures Rhich can be executed in esti.ation for nonlinear Measure.ent error .odels ou~llned SAS will be along with a brief discussion which can be i ...~le.ented 'Using the SAS® ll1yste. aM of some of the statistical issues in the on an E.phasis is iteratiVe presented. estimation. proeeOl;rre for implicit moo.cls with a lar.e nwaber observations~ of 2. Procedure for S1t&11 Ntmbers of Observationa As pointed out earlier. esti.ation for oon- I.,Sugi-89-226 Schnell.txt
"ESTIMATING STOCHASTIC COEFFICIENT MODElS WITH THE SAS"" SYSTEM atarles Hallahan, Economic Research SeIVic;e, USDA Abstract. written as One of the many assumptions of the classical linear regression model is that the parameter + .: ft , (2) y,; Bot vector & remains fixed over the estimation period. There are situations. particularly in econometric Bot lid (Bo,a1. modeling attempting to account for either structural change OVer time or differences across Equation (2) represents a model with random obseIVational units, in which it makes sense to intercept and constant slopes. Looking at the CLR allow for coefficient variation. As Keynes this way raises the 'luestion of why treat the commented in 1938, intercept differently than the slope coefficients, Le., why not let the slopes also vary across ""The coejJU;ients arrived at are apparently observations. With time series data. a common assumed to be constant for 10 years or for a larger assumption is that e, follows a [trSt order period. Ye~ surely we know that they are not autoregressive process. constant. There is no reason at all why they should """""".1 + u, , not be different every year~"" (3) e, = Attempts to cope with changing parameters lead D, iid (0,&"") and rp = E(e,c,.1l Johnston to comment (see 10, p. 410) : Since e, B~ SOl - equation (3) can be written = .....the capacity of econometric theorists to as 'invent' new varieties of models with cOlttinuous parameter varilltion tends to exceed the willingness (4) 13"", - 13.; </>(13.,>-1 - B.) + u"" and sometimes even the computational ability of researchers to apply them to real-world situations."" ""' iid (0,0,,). This paper discusses two of the many specifications of stochastic coefficient models So, 13"", (allows an AR(l) process. Generalizing to the slopes leads to the assumption that !!t also introduced over the past 20 yean; (witbout adopting a full Bayesian approach) and illustrates, (allows an AR(l) process. This is exactly the kind of assumption made in the Kalma",Sugi-89-227 Hallahan.txt
"Research Abstract efficient under a variety of distributional settings and for varying sample sizes. In Estimation of regression parameters by addition, they have been developed with an the method of Least Squares has certain well- emphasis on keeping the amount of computation known disadvantages when there are outliers to a minimum, thus making them very in the data. Regression techniques have been attractive and practical alternatives to developed that are resistant to outliers and other better known, and in most cases robust to violations of assumptions computationally intensive. resistant and underlying the usual regression model. robust estimators. However, these require an excessive amount of computation and are not readily available for The first class of estimator presented users of the SAS· system. in Section 2 is a ,set of approximations to the Theil (1950) and Sen (1968) estimator, SEN. The SEN estimator has been demonstrated In this paper two new classes of (see Johnstone and Velleman, 1985) to be one regr~ssion estimators are presented, The of the most efficient regression estimators first is based on modifications to the very effici ent Thei I-Sen estimator. It requires under non-normal error distributions. substantially less computation whilst However, it requires a large amount of maintaining statistical efficiency. Sampling computation, which may be partially responsible for it not being more widely from the complete set of pairwise slopes used. The second cl",Sugi-89-228 Adler.txt
"WHAT DOES R2 MEASURE? Steve Thomson, University of Kentucky Computing Center model sum of squares The coefficient of determinaHon, squared multiple total sum of squares . correlation coefficient, that is, R2, is perhaps the most The model sum of squares, SS(A,B), could also be extensively used measure of goodness of fit for partitioned into sequential sums of squares. One regression models. In my consulting, many people have possible partition would be: asked questions like: ""My R2 was .6. That's good, isn't SS(A,B) = SS(A) + SS(BIA). it?"", or ""My R2 was only .05. That's bad, isn't it?"". Thus where both terms on the right are squared distances, and many people seem to use high values of R2 as an index thus positive. The SS(BIA) is the sum of squares for B of fit, concluding that if R2 is above some value, they ""adjusted for"", or ""orthogonalized to"" A. So comparing have ""good"" fit, but that small values indicate ""bad"" fit. In the R2 for the submodel with only A's as regressors to the either case above, probably the best response is R2 for the complete model with A's and B's: ""Compared to what?"". R2 = SS(A) ,; SS(A) + SS(BIA) R2 SST SST One interpretation of R2 is as the limit of the A Clearly R2 has to increase as variables are added to the regression sum of squares divided by the limit of the total model (or at least not decrease). Also, note from the sum of squares. Or equivalently, it is an estimate of the amount of variation in observation means compared to geometry that 0 ,; R2 ,; 1. the variation in means pius the variation in residual error. This can be small even for models with small error, Or If the model Includes an intercept or constant term, tt large for models with large error. is particularly easy to adjust. or orthogonalize, to this constant, merely subtract the column mean from each column. Most analyses are performed on such I. Review: ""corrected"" models. One last simple observation from the geometry is that there are an uncountably infinite number",Sugi-89-229 Thomson.txt
"ed question concerning the GLM procedure Is, ""Why Is my contrast non· 9stimabler Ttlls tuIOriallays the oooossary groundwork for obtaining a basic understanding of the NON-EST message as p!inted by PROC GLM. It targets the novice user or site repr... sentetive who would like a better undB<Standlng 01 PROC GLM. Examples Hlustrate methods for determining appropnaw CONTRAST statElments. Included is a very basic discussion of the patametel1zation used by PAOe GLM. INTRODUCTION .Have you evar seen the following output n .. ........ "" ""ALW I.S p · ""I 11 and lhought. 'What does 1111. mean?' In most Instances, your Ii'st concern is not the meaning of the message but your failure to receive the desired contrast or comparison. The NON-EST message is produced for one of the following reasons: · You have made an error in specifying your CONTRAST statement. · You have requested a contrast that is non-estimable. ThIS primary purpose of this tutorial is to pregent a basic: methodology _for' wrtting 'Or CONTRAST statements. It begins wtth a thorough examination of PROC GLM a simple on...way design. This Iutoliel concl""dee with the specification of CONmAST .tatements for severall1ypotheses in a balanced two-facror design with interaction. The contrasts discussed In this tutorial are comparisons of means from balanced fixad- effects models. However. the methodology described can be applied 10 more difficult models. It Is not within the scope 01 this tuloflal to teach the statistical bacl<groun",Sugi-89-23 Fulenwider.txt
"A CONCISE AND EASILY INTERPREI'ABLE WAY OF PRESENTING THE RESULTS OF REGRESSION ANALYSES Leland Stewart, Lockheed Palo Alto Research Laboratories Stephen Senzer, Lockheed Palo Alto Research Laboratories Introduction Our interest is in problems where This paper describes a method of stepwise or all-subsets regression would presenting the results of regression analyses normally be used, i.e. it is suspected that that uses a graphical display of the posterior some of the independent variables will have distributions of the regression parameters. negligible effect, or equivalently, that some of the ais will equal zero. (In this paper, we This is an effecti va way of concisely say ""ai=o"" when ai is small enough that~ is communicating both the posterior probability considered to have a negligible effect.) that a regression parameter equals zero (i.e., the corresponding variable has no effect) and the posterior density of the parameter if it Presenting the Results of a Regression Analysis does not equal zero. This approach also allows the user to compute the posterior In Bayesian analysis knowledge and probability for each model in a set of possible uncertainty about parameter values are models and therefore to retain consideration expressed by probability distributions. Before of several or many models throughout the seeing the data this distribution is called the anslysis rather than to restrict attention to just one ""best"" model prior distribution. The prior distribution has the same sta tUB as other standard It is suggested that this method be assumptions such as normality, linearity, considered for future inclusion in the SAS* independence, etc., in the sense that they all system as a supplement or alternative to add information to the analysis of the data. currently used methods of displaying results The details of the prior that is used here can in regression analyses. be found in Stewart (1987). Example The joint distribution of the parameters, given the data, is",Sugi-89-230 Stewart Senzer.txt
"This paper describes a series of SASIlML® modules, designed to perform a type of discriminant analysis variable selection. Given a set of p variables available for use in a 2 group discriminant procedure, the method identifies all subsets of these variables with discriminant power not significantly less than the original set. The development work was done with version 6.03 of SASIlML under PC DOS. Repnrts generated by the program are designed to display the potentially large output in a concise form. Input required to run the program is minimal. The algorithm employed is based upnn the theory of coherent subsets, which may be used to increase efficiency in a search through all possible subsets. The modules have been designed to use the coherence principle as described by Ronald McKay (1976); that is in combination with a simultaneous test procedure employing Hotelling's T'. With slight modification, however, these modules could be adapted to implement other applications of coherence. I.",Sugi-89-231 Fehlner Bernstein.txt
"A SAS/IML® PROGRAM FOR RANDOMIZATION ANALYSIS OF DOSE RESPONSE CURVES Dean E. Nelson, CIBA-GEIGY Corporation consider a. randomized blocks design with m treatments and 1. INTRODUCTION n blocks each with m experimental units. Let Yki(t) be the response curve observed for the plot in the ktk block which Randomization analyses of response curves were intro- was assigned treatment i; k = I, ... , nj i = 1, ... , mj over duced by -Zerbe(1979a,1979b) for the completely random- the interval (a,b). We may then define the mathematical ized and randomized blocks design. The analyses provide model, the abiljty to test treatment effects over any specified in- terval. Computation of the exact distribution of the test ¢.;,(t) = p(t) + fJ.(t) + T,(t) + 'kilt) (2) statistic whicb would require evealuating every permuta- tion of the data is avoided. This is accomplished with an where ¢kji(t) is the response curve that would be realized a.pproximation using the standard F distribution with syn- if plot i were assigned treatment i within block k. Then, thesized degrees of freedom. p(t) is the overall mean response, Pk(t) is: the block effect, This- procedure is quite useful when the data do not l'i(t) is the treatment effect. and £1rj is the error curve as- meet the assumptions of parametric analyses or when each sociated with experimental unit j within block k. As in subject's data cannot be modelled with functions belong- the completely randomized design it is assumed that there ing to the same family in the aense discussed by Laird is no treatment by block or treatment by plot interaction and Ware(1982). Medical models applying these proce- and that the sum of the treatment effects is zero for all dures have appeared in the literature (e,g, Goldberg, et t E (a,b). The probability structure induced by the phys- 31.(1980); Albert, el al.(1982); Cbapelle, el aI.(1982); H;- ica.l act of randomi?:iation can now be imposed upon these all, el al.(1983)). mathematical models to yield stoc",Sugi-89-232 Nelson.txt
"REPEATED-MEASUREMENT DESIGNS: THE INTRICACIES OF THEIR ANALYSIS WITH THE SAS@ SYSTEM Jean Hardy, Universite laval in The REPEATED statement the ANOVA and Factor S, Altimeters GLM procedures, first introduoed in version 5, was a 9reat relief for data Subjects B4 Bl B2 B3 analysts faced with repeated-measurements designs. This statement permit analysis Sl 3 following an unprotected or protected 7 7 4 S2 univariate approach or following a truly 5 B 8 6 S3 3 7 mUltivariate approach. 9 4 3 3 84 6 8 S5 2 10 5 User's guide document with appropriate 1 S6 2 10 details the obtaining of ANOVA tables for 3 6 S7 2 5 basic designs (SAS Institute Inc., 1985, 9 4 sa 2 11 6 1987). Some authors presented examples 3 for more complex designs, including Fiqure 1. Data for a RM-.4 design covariance analysis (Freund & al .. , 1986; Meredith & al ~, 1988; Miles-McDermott & ai., 1988; Speotor, 1987). Figure 2 illustrate some of the results. But users need more than ANOVA tables while analysing repeated-measurements It shows both between and within subjects analysis ~ Only Greenhouse-Geisser proba- designs. They would like to get multiple bilities (G-G) are shown. The source comparaisons as well as analysis of interaction in factorial designs * Little named ERROR provide the subject effeot attention was given to these problems and while the source named FACT B*DUMMY this presentation illustrate how to get represent the interaction between sub- some of these results with the SAS jects and the repeated factor. system. ONE-FACTOR REPEATED-MEASUREMENTS DESIGN --~-------------------------------------- ANOVA SS F VALUE SOURCE OF o DUMMY 0.00000000 This is the simplest repeated measures ERROR 12.50000000 7 design, but definitely not the easiest to analyse. Figure 1 shows data used (from SOURCE: FACT_B Kirk, 1982, page 252). Difficulties arise DF ANOVA SS MEAN SQUARE F VALUE G- G from the absence of a between factor to 3 194.50000 64.83333 47.77 0.0001 put in the MODEL statement. The user Must add",Sugi-89-233 Hardy.txt
"monwealth University sequence. For examp Ie.. in the 2-period"" Abstract 2-treatment crossover, the possible sequences are AS and SA. Within the j'h time period. 2 · Crossover experiments pose unique problems with j "" p, it is possible that there are carryover respect to statistical analysis. Usually. the effects from treatments administered during statistician relies upon a mixed model analysis periods 1, 2, ··· , j - l . Usual1y we only of variance with terms for fixed effects, such consider first-order c,arryover effects (from as sequence, treatment, period, and possibly periodj-l) because (a) if first-order carryover carryover~ and terms for random effects, such as effects are negligible, then it is likely that subject nested within sequence. The mixed model the higher-order carryover effects also are analysis of variance results in a covariance negligible, and (b) the designs needed for matrix for the set of measurements on each eliminating the. confounding between higher-order experimental unit which is of compound symmetry. carryover effects and treatment effects are very It is questionable as to whether this assumption cumbersome and not practical. is valid, so that multivariate models which do not make this restrictive assumption might be In Section 2 we review some of the design more appropriate. However, the multivariate aspects of crossover experiments and in Section analysis of variance model, in which no 3 we discuss the mixed model analysis of structure is impos",Sugi-89-234 Chinchilli Elswick.txt
"ANALYSIS OF NONREPLICATED EXPERIMENTS WITH SASfIML® SOFTWARE Michael R. Emptage, Alcoa laboratories than or equal to 3. To show thiS, observe that there Introduction are bt observations in all. The various terms in eq. (1) use up the following numbers of degrees of Although a well-planned experiment should have sufficient replication to provide an estimate of freedom: llmn the variance, <J2, it is sometimes not possible or degrees of freedom even desirable to do this. For instance, true replica- IL 1 tion may be too expensive to be feasible. Altema- 1-1 'G ~ tively, in exploratory experiments it may be more b-1 X valuable to Include many treatments or treatment 1 combinations instead of only a few, replicated many t-2 a; 'l1 times, so that many possibilities can be investigated. b-2 In either case, the statistician is still left with the Subtracting the sum of these degrees 01 freedom problem of estimating the variance so that the sig- nificance of various effects can be judged. from bt gives (t-2)(b-2). As 10n\1 as t and b are at least 3 this number will be pos~ive, which proves In this paper we consider two-way treatment the above assertion. structures in which each of the two factors has at least three levels. Each treatment combination is The analysis of this model Is explained in Mil- observed only once, and we are confronted with the liken and Johnson (1989). One first calculates the analysis of such a design. residuals,Zli, from the additive model One possible analysis of such an experiment is (4) to assume that the interaction between the two factors is negligible, and to use the interaction term and forms the matrix Z of these Zij values. Then It is to estimate the variance. This may of course be a determined, up to sign, as the normalized perfectly sensible thing to do, but the statistician eigenvector of ll' corresponding to 1'1, the largest should certainly not make the assumption of negli- eigenvalue Of ZZ:, and ""f IS determined similat1y as gible inte",Sugi-89-235 Emptage.txt
"where Dl and D2 are diagonal matrices whose diagonal elements ate the eigenvalues of Al and ~, respectively. The testing of both the fixed effuts and random Since the number -Qf noru:ero eigenvalues of a symmetric effects in unbalanced mixed models (whieh include the random-effeds models) has relied on approximate procedures matrix is eql1al to its rank, and (i) rank (AI) = s; such as Sa.tterthwaite's approximation. These approximate (ll) rank (Az) = r; and (iii) rank (A 1+A2) = r+o-l; it is methods are often unreliable as discussed in Tietjen (1974) and Cummings and Ga.ylor (1974). possible to partition the vedor 2l into subvecl.ors whose variance-covariance matrices do not depend <m both "".~ and Khun (1989) derived exa<:t tests concerning the ul variance mmponents for genera.l random models that are However, they depend on the vaJ'iance components unbalanced with .respect to the last stage of their- associated associa.ted with. the interaction and enor terms, d!,8 and 072 , designs. Khun's article l'f:presents a generalization of the results introduced earlier by Khuri and Littell (1981) with respectively_ regard to the unbalanced random two-way classification model. An outline of Khuri's (1989) method is presented in Thomsen (1975) was then a.ble to obtain exact tests Seetion 2. A SAS software macro based on this method has been developed and is briefly described in Section 3. for the variance eornponents associated with the main effects, o!,8 ::: 0 (The exact tests derived by Ii, provided that a and 1.",Sugi-89-236 Gallo MacElderry Khuri.txt
"levels of the factors are ftxed. In _order to ease notation, 3x3 designs will be illustrated. Generalization to IlXb designs ~hon~d Methods used to test common hypotheses about factorial data be evident. It is presumed that a.t least one observatlQll IS vary over balanced and unbalanced designs. Various sums of obtaint!d for each cell and, in order to allow for error sum of ~ squares squared lengths of perpendicular projedions on the squares at least one cell has more than one observation. The estimation space - may be used. How th~ sums of squares, and cell siz; for the ith level of the row factor- and the jth level of the corresponding tests, differ depends on the degree to which the oolumn factor is denoted by n·"". In Section U usual hypotheses about the cell means are r~iewed and di:!scribed within a deviation in sample si~es distorts the estimation spaee. The ronsequences of this distortion, perceived through gwmetric geometric framework. In Se<;:tion III a. general principle. for eoncepts, are examined in this paper. Several methods of testing a hypothesis about the cell means is disc~ssed_. Varl.?us analysis are contrasted. sums of squares and testing procedures are explained m SectlOn IV_ These procedures are compared and discussed in Section V. I.",Sugi-89-237 Johnson.txt
procedures (Koziol. 1986); and 2) graphical vs inferential techniques. No single Assessment of multivariate normality is an procedure alone seems adequate for important and difficult problem for those identifying the many possible types of applying multivariate statistical methods. departure from multivariate normality. No single graphical or inferential technique Different procedures are more sensitive to alone seems adequate for identifying the particular kinds of non normality than others. many possible types of departure from An enlightening approach. although one multivariate normality. Therefore. this paper which should be viewed as essentially discusses four tools for assessing exploratory. is to construct a battery of tests multivariate normality. and presents easy-to-use SAS programs for their and plots. If all are indicative of multivariate' implementation. normality. one may consider it a reasonable assumption. If there are indications of,Sugi-89-238 Steiner.txt
"d to the kth Repeated Measures problems often have missing values which complicate the subject in the ith treatment group. analysis. Milliken and Johnson have These two error components are assumed presented a method for handl-ing these to be distributed independently type of problems in their book on the Analysis of Messy Data. This paper of each other, with the Sk(i} presents a SAS program that will do the analysis sU9gested in this book by using 2 ~ PRoe GLM and PRoe PRINTTO along with and the ijk N(O,a ). several MACRO variables. The output OUTLINE OF PROGRAM includes the proper F-tests for testing the effects, best estimates and The program developed here is based estimated standard errors for functions on a split-plot type analysis of of the parameters along with the repeated-measures data assuming that the approximate t-statistics, estimated covariance conditions are met. It is degrees of freedom and p-values for written to handle the case where some testing the hypothesis that the function data is missing but will also work for is zero. A numerical example is given balanced data. It uses two runs of PROe along with the SAS code that will GLM to determine the appropriate F-tests generate the output. for th~ effects and the approximate t-tests of the functions of the INTRODUCTION parameters of interest. For more detail on the formulas used to determine these Repeated measures designs have structures that involve more than one tests in the miSSing data case see Milliken",Sugi-89-239 Allen.txt
"able, whiCh you could caU ACTIVITY. jf SWIM~1, then 88Sign ACTIVITY-SWIMMING; if FISH-I. then assign ACTIVI"" Analyzing multiple response data with the SAse System is a diffi- TY-FISHING: and if SKI=l, then assign ACTIVITY-SKIING. [f cult task. This paper provides one method of produclng a multiple B'I1Y of the three variables js missing, you do nothing. However, _pon"""" report using the TAIlUlATE procedure' n>e problems In creating this variable, one observation for each response, Involved In generating such a taDle are presantec:t. Also. the data instead of tot- each respondent, is output. After doing this recod-- manipulations necess.ary for preparing the data for the lng~ the number of Observations !5 no longer equal to the number TABULATE procedure are discussed. Next, the PROC of respondents, and the second prOblem emerges, TABULATE statements needed to generate the report and the Iogk; behind the pe(centaga definitlons ara addressed. Special Another aspect of the multiple response dilemma is that you have considerations for handling 'NO RESPONSE' Qbservatiolls are a chQice of comparisons; you can oompare Individual response also discussed. frequenCies to tho number of people answering the survey (re- spondents) or to the total number of responses to the question.",Sugi-89-24 Keene.txt
"ig, North Carolina State University, Raleigh, N C March 14, 1989 Dd'i.ne 1 Abstract (7) This paper discusses a linear model with positiveddinite cova.riance matrix - not necessarily diagonal, and extend some diagnostics (8) that exist for the standard linear regression model to covel mixed models. A Diagnostic tool for Variance Components is pwposed. and H"", by: KEY WORDS: Variance Components, Diagnostics, Mixed Lin- ear Model, Maximum Likelihood. H w - V.. /0'2 _ ( Hn h"" ) h12' h,,/w - · - Diagnostics for Fixed and Random 2 (9) Effects Typically p ;::::; h n ,l or n and depends on the kind of perturba- 2.1 Diagnostics for Fixed Effects tioe and the model. as you will see later. (p;;;::: l) would meart no perturbation and would have the same signifkanu as ifw ::::; 1). Consider the model equation If H .... has an inverse, the MLE of a, say it"", is given by y:::.: Xa+ (1) IE (lU) where X i.s a known matrix, « a vector of parameters and E a The following theorem expresses the main result of this section. random vector with pd variance-covariance matrix V ::: q~H for 0'; > O. The estimation of a is a generalized least Theorem 2.1 some H pd and squares problem, with solution :::.:,a- it... (2) (X'H-'X)-'X'H-'e,eiH-'(y - Li) (11) 22 provided V is known. If V is unknown, it is customary tu replace h P(l-\,""'} 'moj it for some estimator V. £t'Mel and M;;;;: H-1X(X'H-1X)-lX'H- 1. where rut In this section, assume that H is known. Notke that (2) can 0::; also be wnUen = You have that",Sugi-89-240 Hurtado Gerig.txt
"ected value of · nonlinear function of the The statistical-model toolbox (SMT) is a SAS predicted variable and if the scatter in the macro system written in the Production Depart- sample is Significant, the conventional approach ment of Exxon Company, U.S.A_, that provides two can lead to significant errors. In this case; powerful capabilities: a systematic way to model it is preferable to model the popUlation in scattered data and to model calculated results terms of conditional probability-density 'that are based on the scattered data; and, a way functions (PDF's) that are determined by central to create and manipulate synthetic probabil ity tendency (""1ocationll) and by variance (""scale""). distributions in the absence of measured data. PDF's are also referred to as distributions or The Production Department uses these capabi1 i- statistical models. ties to address problems in petroleum reservoir description, where rock properties are Figure 2 depicts this statistical-model stochastic by nature. However, the tools are In a procedure analogous to approac~. complete 1y general and can be aPfl i ed to any regressl0n t the location and scale parameters continuous, numeric, random variab es. The most are estimated for normal (Gaussian) PDF's. The frequently used tool calculates expected values expected value of any function of the variable of arbitrary functions of one or two random is calculated by integrating the product of the variables. Other tools display distributions, fun",Sugi-89-241 Frankel.txt
"MONOTONE REGRESSION UTILIZING RANKS Ronald l. Iman, Sandia National Laboratories W. J. Conover, Texas Tech University BIVARIATE REGRESSION (1) y- a bx When analyzing the relationship between the + two variables in a bivariate random variable where (X,V), regression refers to the mean of Vas a function of the possible values of X. On a graph this plots as (y,x) where y - E(YIX-x). (2) The regression function may be estimated from a set of data if there are many observation paints, by taking a moving average of the and observed V values for a given window of X values. If there are not enough points in the a - (1 · b)(n + 1)/2 data set to estimate E(VIX-x) satisfactorily, (3) additional assumptions regarding the form of the regression curve are usually made, and the 3. Obtain a rank R(x.) for any value Xo of X as follows: estinated regression curve relies heavily upon these assumptions. The most common assumption (a) If xD equals one of the observed X,'s is that the regression curve is linear, so that let K(Xo) equal the rank of that X,. E(VIX-x) is a straight line function of x. More general assumptions include parabolic regres· (b) If x. lies between two adjacent values sion CUrves, other polynomial forms for the regreSSion curve, exponential regression cur- X. and X. where Xi<Xo<X"" interpolate between fheir respectiv~ ranks to get ves, and logarithmic regression curves. R(Xo). This ""rank"" will not necessarily A general class of regression curves is the be an integer. class of monotonic regression curves. This (c) If Xo is 1ess than the smallest observed includes all regression curves where E(VIX-X) X or greater than the largest observed increases as x increases, or where E(Y X=x) X, do not attempt to extrapolate. decreases as x increases. In any data set Information on the regression of Y on involving bivariate observations (X,Y) where X and Yfollow a monotonic relationship, the rank X is available only within the observed of X and the rank of Y follow a linear rel",Sugi-89-242 Iman Conover.txt
"FIELD RELIABILITY ASSESSMENT USING THE PROPORTIONAL HAZARDS MODEL Raymond V. Spring! U.s. Army Natick Researe!, Development and Engineering, Center Stephen A. Freitas, U.S. Army Natick Research, Development and Engineering Center },(I) ~ f(1) (2.1) 1. INTRODUCTION R(I) The regression model for survival analysis introduced in Cox (1972) was developed with applications for ""industrial where h(t)dt is approximately the conditional probability of reliability studie'J and medical studies"" in mind. While this fa.iluNl in (t, t+dt] given survival ttl time t. Chol<:ee for the form model has had a significant impact on the biomedical field, it or restrictions OD h(t) are usually done with the physics of bas received little attention in the Nlliability literatuNl. Only failure, aging characteristics or simple statistical convenience in recently has the mod4:!1 been used for the analysis of hardware mind. reliability {see BeDdell and Wightman (1985) and Benden et al The problem with the abo¥e approach is that often times (1985»). software reliability [see Bendell and Wightman (1985), actual field data may violate the underlying assumptions in that Nagel and Skdvan (1985), and Font (1985)] and repaiIable (,.. Mob« (1983)J. sy,terns [,.. Ascher (1983)J. The Cox model, referred to in the literature as the a. Items tested may not be totally indistinguisable; . Proportional Hazard Model (PUM). is most usefu1 as an h. The test -conditions may vary from item to itwl; exploratory technique which sheds light on the underlying c. A specific parametric model for the underlying structure of the data. As 8uch, it may he used to analyze data hazard fundion cannot be specified. that may prove insufficient or even inappropriate for more conventional ;;ma.lysi.$ procedures. This type of data is all too In contrast to the above, the PHM overcomes these common in real~wodd reliability applications. We illustrate the difficulties by relying on only one simple assumption. The only use of the PHM",Sugi-89-243 Spring Freitas.txt
"EXAMINING THE RELATIONSHIP BETWEEN SURVIVAL TIME AND TIME-DEPENDENT COVARIABLES USING THE PHSPLM PROCEDURE James E. Herndon n, Duke University Medical Center, Durha.m, NC Frank E. HarrEll Jr, Duke University Medical Center, Dttrha.m, NC using penalized maximum likelihood estimation. Given the particnlar pelULlty function chosen, this approach is equiva.lent to The PHSPLM procedure describes survival data using a. fitting a quadratic spline with knots at each uncensored survival parametric proportional hazards model where the baseline hazard time. Whittemore and Keller have estimated the baseline hazard is a eubic spline function with tails that are linearly restricted. using a continuous piecewise linear spline with knots at each Herndon (1988) has propooed this flexible hazard modd 8$ an unique survival time. Both Anderson and Senthilselvan's model alternative to the Cox model (1972). Properties of this model and Whittemore and Keller's model are limited by the large include: efficiency of estimation of cavariable coefficients and number of parameters which need to be estimated; hence, a survival probabilities, smooth survival curves, and ~nfidence simple formula for the survival and/or hazard functiiin cannot be limits for survival and hazard estimates, even when cavanables easily written. Ete,,,,u::li-Amoli and Ciampi propose the extended are time-dependent. In addition, it has been sh{)wn that the ""hazard regression model which inciirporates both the proportional use of the restricted cubic spline model when examining the hazards and accelerated failure time models. A quadrat.ic -spline erred of time-dependent covariables can :reduce computation time aftproximation with variable knots is used to approximate the by a factor of 213 over that of the Cox mooel. The pnSPLM baseline hazard fundioo. The drawba,ck of this latter model is procedure can fit the homogeneous restricted cubic spline model, that the estimation of knots requires considerable wmputation ignori",Sugi-89-244 Herndon Harrell.txt
"f Oklahoma Health Sciences Center Okl C't OK Il~ 1 y~ R B De 1 J U' . I a. r.. nr~erst~y of Oklahoma Health Sciences Center. Okla. City. OK "" Susan J. Ke~ny, Un:vers~ty of Oklahoma Health Sciences Center, Okla. City, OK J. Paul Costtloe~ UnlVe_fsl1ty of Oklahoma H4!llllth Sciences Omter~ Okla. City. OK ABSTRACT squares would inelud.e the Cauchy gradient or Nonlinear mod""el fitting bas become an area of steepest descent (Davies~ 1954), the Gauss-Newton actiVe research in recent decades and has been aided first-order approximation {Chambers. 1969), the ,reatly by the advent of high speed computinw;. modifications due to Smith and Shanno (1971),. Tabat. Implementations of the Gradient, Newton, modified and Ito (1975) and Hartley (1961, 1965), the Mal'<!.uardt Gauss-Newton, Marq,uardt and DUD methods for maximum neiahborhood (196:3), the Powell (1965) nonlinear regression estimation are readUy available method of seeants~ the Ralston and Jennrich (1978) in the NUN' procedure of the SAS(R) Institute. The method ot false position (DUD), and the Newton~ purpose of this paper is to compare the performances Ra.phson l\tecond...order approximation (Bard. 1974)~ of these five estimation methods when applied to a nonlinear Implementations of many of these sum ~ of ~xponentials model. A Monte Carlo regression techniques are readily available in simulation study was performed in order to assess sta.tistical computer programs such as the NUN the relative strengths and weaknesses of these in",Sugi-89-245 Cucchiara Deal Kenny Costiloe.txt
"Robust and Explor atory Analyse s Autom ated by Gerry Hobbs and E.lame s Harner West Virginia University 1. Introdu ction SAS data set. These are GEIDA TA, CHKSET, CHKNA ME, and VARLST. GE1DA TA fetches the SAS The Interactive Data Analysis System (IDAS) is a system of data set name from the user (with GEl) and initiates the = developed wi~ ~ SAS,:,"" environn:ent to calcu.hte checking macros. It also prints tbe varisble names in the selected statistical quantltles. The mterface Wl~ the user IS SAS data set up to the 132 byte limit of the buffer. friendly and forgiving of user errors. All req'.'ired CHKSE T checks whether or not the named SAS data set information for an analysis is requested and, if appropn.ate. a exists either in a permanent SAS data set library or in the list of possible responses is provided. Input is ch<7ked for tempora ry work library. It calls CHKNA ME which validity whenever possible. Error tlle!'s8.jles are pnnted if. determines whether or not the SAS data set narne (one or improper entries are ntade. The user IS gtven an .o~ two level) specified by the user is valid. V ARLST. the last to change or correct inpnt after each entry, even If It IS macro, creates macro varisbles which contain lists of all correctly verified. The system also remembers all entries variables, the numeric variables, and the character variables and thus the user only needs to enter changes. These in the selected SAS data Set. features, coupled with the .ahlI!ty to quit the system at any time, are the principal deSIgn lrems of interest to the user. Three macros are used for obtaining and verifying variable names, which subsequently will be used in the analysis. Certain principles underlie the programming design. These are GETCLAS, GETVAL. and WORDS . GETCLAS Individual macros typically pe:rfonn a single task in order to is used to get a single variable or list of variables. Contrary achieve modularity. The oQject is to isolate the code to the to the name of the macro,",Sugi-89-246 Hobbs Harner.txt
"Susan P. Duke, Independent COnsultant Anthony c. carpentieri, Independent COOSultent 1*******************************************1 The Wilroxon one sample signed-ranks test /* r:9Ill na:rre: wilcoxon.sas *1 is the appropriate test to use for a /* written by: A carpentieri */ cctt1pa.rison of p.3.ired data when the values & S Duke /* */ are ordered but not !lOlJl\3.11y distributed. written on: 05Apr89 /* description: uses the wilcoxon.inc file */ ('l1le paired t-test would be nore appropriate */ 1* if the data were distributed normally.) The to ca.lculate signal-ranks test */ 1* signed-ranks test can be used either in the IOOdifications - /* */ last llIOd ,OSl\pr89 one sanple case, where the null hypothesis */ /* is that the data is equal to sane constant, C, by : S Duke */ /* version :A /*******************************************/ Xi = C libnarre sassets of: \susan\sugi"" , /""Ver. 6*/ or in the paired two-sarrple case, where the null hypothesis is that paired data is ''wilcoxon~inc'' filenarre wilC()XQl1 ; eqlJivalent~ *libnarre sassets ""[)"" i /*Ve:r.5*/ *filenane wilcoxon *' [ }wilcoxon. inc"" '; /*VMS*I XiI = xU, This test is available in base BAS software %let indata = sassets.exl %let outlis = exLout in the UNIVARIATE procedure. However, the %let base = baseval p-value for signed-ranks is not one of the %let tenn = termval output paraneters available in PROC %inc wilcoxon ; UNIVARIATE. This OOccrre:s a problem when p-values are */ 1* needed for r~ guality sUImlaries that wilcoxon. inc */ /* include p-values. Three alternatives are this %include calculates the Wilcoxon 1* *1 signoo-rank test using the nmmal available if these p-values are needed in a 1* *1 SUI11lVilrY table: (l) the values can be edited approx.ina.tion (see Conover, 1980, P9's. */ /* into the output file, (2) the UNIVARIATE 280-285) outpJ.t can be read as input to obtain the /* */ p-values~ or (3) the statistic and it""s /* */ input */ 1* - macro variables probability can be calculated using the d",Sugi-89-247 Duke Carpentieri.txt
"HOW TO PERFORM JONCKHEERE'S TEST USING THE CORR PROCEDURE Richard W. Morris, Analytical Sciences Inc. E. Jaquelin Dietz. North Carolina State University INTRODUCTION Now consider the same data :rearra.uged in two columna with single subscripts on the y's corresponding to The Jonckheere test is a popular distribution-free observation number. test for the null hypothesia of equaJ treatment effects in a one-way layout. This- test differs froID the one-way Treatment Response analysis-of-variance and the distribution-free Kruskal-Wallis y, 1 test by having the -alternative hypothesis of ordered trea.tment effect$.. lonckheere's test is not available by 1 name among SAS statUitical procedures and as a consequence a SAS program has been written using a k number of data steps, SAS procedures, and the macro language (Huang and Roble# 1988). In this article we k present a simple method for performing Jonckhee:re's test using the KENDALL option of the CORR procedure. To compute Kendall~8 statistic for correlation between A correspondence between Jonckheere's test for treatment (x's) and response (y's), consider a pair of ya and (Xi' Yj), i < j. bivariate observations, (x., ordered alternatives and Kendall's test for correlation has long been known (Joncltboore 1954i KendaJl1975, p. 165). A""soclate a score with this pair of obserVations; 1 if Xi < Xj and Y. < Yi' 0 if either Xi = Xi or Yi = Yi' and -1 Indeed, the test usually attributed to Jonckbeere was if Xi < Xj and Yi > Yj' (Note tha.t in this particular proposed two years earlier by Terpstra (1952) in a paper application, Xi ~ Xi') The Kendall sta.tistic K is the sum of whose title refers to Kendall's test. Evidently, though, the scores over all pairs of biva.riate observations., Since the rela.tionship between these two tests has not been widely number of l's assigned is C, and the number of -l's exploited for computationa.l purposes. We first present the = assigned is D, K can be written as K C - D, the Dumber relations",Sugi-89-248 Morris Dietz.txt
"DETERMINATION OF POLYNOMIAL SUMS-OF-SQUARES CONTRAST COEFFICIENTS: AN APPLICATION OF MODEL REPARAMETRIZATION RESULTS USING THE GLM PROCEDURE Daniel R. Jeske, AT&T Bell Laboratories Donna Fulenwider, SAS Institute Inc. 2. Reparametrization Computations in 1. Introduction. GLM. Twa widely used parametrizations for a one-ra.ctOt ~t Y denote an n x 1 vector of random variables. model with quantitative levels tl , ... , tb are the Let X be an n x p matrix, a a p x 1 vector of following: parameters, W an n x k matrix and {3 a k x 1 k-' vector of p""arameters. Suppose that the mean of y Po + E Pn t , (I) ElY;j) can be modelled in either of the following 0-' alternative forms: + a;. (II) E(Y;j) = ""0 EIY)=WP (1) Here, i = 1,... ,k and j = I, ... ,ni' E(y)=X"",. (2) Some· hypotheses concerning differences in the factor levels !l.Te more easily formulated under (I), A necessary and sufficient condition for these two while others are more easily formulated under (II). models to be reparametrizations of each other is For example, it is clear under (II) that the that there exist matrices C and C'"" such that hypothesis of no difference between the lirst and second leveJ-effects can be expressed as x=WC (3) ""2· H.,: ""', = It is less clear how this hypothesis w=xc*+ would be expressed under (I). On the other hand, (4) the hypothesis that a (k - 2 )nd order polynomial sufficiently describes the response as a function of It is usually the ease that one of the parametrizations .being considered for a model is a ractor level is easily written down under (I). Namely, H.,: fh- , = o. Writing down this ful) rank parametrization. In this case, the hypothesis. in terms of the parameters under (II) is corresponding design matrix has a full column more difficult~ It is advantageous f therefore, to rank. Ailsume that W has a full column rank. It b. able to use both parametrizations. This follows from (3) that necessitates knowing how to transform a c= (w'wt'w'X, hypothesis formulated under one p",Sugi-89-249 Jeske Fulenwider.txt
"ISSIIOS RELATED TtlflNAlVZIN6 REPEllTED ~ DATA J."""" . F. Ptmder;··t, University Df FIDrid. :A,allGn 1;. Littell. UnlYt!'rBit-y'nf Florida INTRODUCTIIlN rest of the .UbjVCt6. one would probably t~e tha.t hlJ/!5h~ would alSo h.we me..asurernents guess em the high end <relative ""to the others) at the> There ~r~ many situations which require multiple other time points as well. Because t~e variance measurements be taken on each primary sampling of the difference of tHO pa5itively""correlat~~ p~r~n, a.nimal, plat of l~nd, uni t (Ie ... .g., random variable-o:; (&.g., two measurement""s on the ~anufactured p~oduct) in order to addr~55 the same subject) will have a smaller variance than research question of intla""rf!'~t-. Ttie~ could be if they were jnd~pendent (two different completely different measurements~ such as subjectsl, it is important to 3ckno~led~e the dimensions of size, weight, and/or response to correlatiDn structure of the data when sti~li, Dr they could be the same .ea~urement performing the statistical AnAlyses. taken at several time points ~. under diff~rent conditions. If different types of measurements have been collected at one point in time and it CATEGORICAL DATA _ _ VIlES is of inter&§t to treat the set of respons@s as an outcome veCtor variable (a5 opposed to 'a uni~ariate approach of analyzing each response In this sectionJ 5~veral methods which can be separately), it is necessary to use a"" analyze repeated measurement data which usgd to m.ultiv.ariate st"",Ustical technique- -- such 1;1.5"" are measur~d an a nominal or ordinal scale ar~ multiv.a.rlate an... 1yG-i &"" of varia.nce (I1ANOWU. discussed. ""Som~ techniqu£'G tak~ into fa~tor analysis~ cluster analysis, to name a considerAtion ""the ordinal natur-E of the data; On the other ~and, if the multipl~ fe~. other§ do not. Treating an ordinal va~iablg as .e.sur~~nt5 have been made nn the same if it were nominal fails to acknowledge an variahle, a~~ could use either a multivari~te or important structur",Sugi-89-25 Pendergast Littell.txt
"'he paired t-test is the standard statistical The general strategy to reduce confounding procedure for comparing the mean value of a bias.. especially in a nonrandomized com- quantitative response variable based on a parison study, includes matching at the pair-matched (1-to-1 matched) sample. study design stage, and/or statistical Not infrequently, ho~ver, the research situation adjustment~ either via analysis of warrants N-to-1. or N,-to-N2 matching rather covariance (2) or the Z-score method (3}, than pair - matching. Rosner proposed at the data ana1ysis stage. The relative a generalization of the paired t-test for the merits and implications of matching versus analysis of qu~ntitative data generated by statistical - adjustment as bias-reduction these matching schemes. Herein we describe techniques are well documented(4-7). two BAS programs to carry out the generaliza- tion of the paired t-test. The first program Quantitative :response data generated by 1-to-1 (GPI''l'BST) performs the test in accordance to matching (pair-matohing) of selected potential Rosner's procedure; the program handles confounding covariates (matching variables) data generated by the and are appropriately analysed by the paired N-to-l t-test(S). However, 1-to-1 matching may not N1-to-N2 matching schemes, and Nl and N2 may vary among matched-sets. The second be an optimal study design option if the proqram (GP'l'GRAF) provides a graphic display population of one comparison group is much depicting the",Sugi-89-250 Lee Lee.txt
"o a bivariate ABSTRACT normal distribution~ which is not robust for the model. Another necessary Examinat~on of the utilization of assumption that con£orms to parametric geographic space is of importance to such statistical estimators is the independence disciplines as ecology. social science. of observations. When this assumption is not met. variances may be underestimated and policy and planning. Characterizing and result in biased confidence intervals. the intensity of space use fram point data is central to this process. A harmonic Lastly, loci coordinates should be measured without error, although the mean estimator is one technique Ior estimating space-use, and is less biased amount of error encountered is dependent than other estimators which use arithmetic on the resolution of the grid system and means. A series of SAS programs have been data collection techniques used. Despite developed which read geographic locations these limitations of the model. the as Cartesian coordinates, identifies the harmonic mean measure of animal activity coordinates for the harmonic-mean, and provides a better esttmate than other projects a three-dimensional models developed for analysis of animal activity (Dixon and Chapman 1980). representation of the intensity of use (from the first areal moments). Application of the programs are The objective of this paper is to present a series of programs for analyzing demonstrated using locational data from research projects on bighorn sheep and s",Sugi-89-251 Layne Steblein.txt
"presentation. ·SAS is a registered trademark of SAS Institute, Inc., This pa.per describes some of the <;a.pabilitie5 of SAS· for the Cary, N C, USA. analysis of lifetimes of individuals, pieces of equipment, or systems when they are considered as whole units. 'Ve use a.n Accelera.ted Failure Time experiment to illustrate the capa~ References billties of the software to perform: nonparantetr1c and p~a n.R. metric model identification, model estimation and cOOcking, Cox, and Oakes, D. (1984). Analysis of Survival and a local jduentia.l analysis. We also comment on some Data. New York:· Chapman and Hall. desirable options not yet available in SAS·. Elandt-Johnson, R.C. and Johnson, N.L. (1980). Surviool Models and Data Analysis. New York; 'Wiley. 1",Sugi-89-252 Escobar.txt
"DENDROGRAM CONSTRUCTION A dendrogram is the standard graphical rep- Dendrogram Terminology: resentation of hierarchical cluster analysis. A method for producing SASIGRAPH enhanced den- Leaves · Objects that are clustered. drograms is described as an alternative to the TREE Branch - Cluster containing at least two Procedure. Using SASIGRAPH to produce dendra· objects but not all objects. grams provides the advantages of increased resolu· - Cluster containing all objects. Root tion and customization capability to make cluster Node - Any leaf, branch or root. analyses more clearly illustrated and more market- able. Construction of a SAS/GRAPH dendrogram EXamples of SASIGRAPH dendrograms are requires obtaining the height of each node and the reviewed including the study which spurred the order of the nodes such that no branches cross. The development of this technique. Also shown are height(vertical axis) is the value of the path length technique extensions such as Kleiner·Hartigan from the root. The order(horizontal axis) depends on trees. the clusterforrnations. The TREE Procedure gives all the heights of",Sugi-89-253 Buckner Lotz.txt
"MICHELLE: STATISTICAL GRAPHICS LI8RARY Dorothy H. Huang. Malfn1 S. Krtshnan, Grace C. Yeh IV. Q-Q PLOT: INTRODUCTION: 1. %QQPLOT is a graph program which utilizes SAS MICHELLE is a statistical graphics program macro l.anguage to generate a $AS ® code which, library consisting of programs that utilize the in turn, manipulate data and execute GRAPHIX. SAS ®macro language to generate SA~ statements It offers graphical method of comparing two which, in turn, manipulate data and execute treatment group results. The program is either SAS/GRAPH ®procedures or GRAPHIX. capable of processing multiple variables during GRAPHIX is a package developed at HRPI any given execution. that utilizes SAS® to generate CA-TELLAGRAFID commands. Its capabilities and related METHODOLOGY: 1. information were presented at SUGI 13. Q~Q plot is recommended when sample size This paper focuses on the extension of GRAPHIX of two treatments are approximately into MICHELLE and the addition of two equal. Let Y1l, "" ' J Ylnl be the library~ statistical graphics programs ·into the responses on nl subjects who received namely Q-Q plot and Boxplot. tree tment 1 and Y21, ... I Y2n2 be those on n2 subjects who received treatment 2 II. HISTORY OF DEVELOPMENT: in a randomized trial. MICHELLE was developed in response to the If nl<~n2, the ith,quantiles Qiyl and increasing complexity of the requests receiVed Qiy2 of yl and y2 are by the M:edica1 Systems Depart.lnent. MICHELLE's Qiyl = yl(i), ith order stat1stics of yl~ major component f GRAPHIX. initially written Qly2 = y2(1), the smallest value of y2, two years ago~ does most of the common and Qiy2 = y2(j) graphs, e.g .· line chart, bar chart~ scatter with j = INT(n2i/nl + 0.5) chart~ frequency oounts, mean graphs, etc. New features are still being added to GRAPHIX for i = 1, ... ~ nl. where the INT as needs grow. For instance. an algori thIn for function gives the integer portion multiple plots per page has been implemented of the value~ recently. Some of",Sugi-89-254 Huang Krishnan Yeh.txt
"though the mor~ general form is considered in Barlow and Prentice (1988). The conditional Residuals are often helpful in detecting probability that it was individual i who failed model departures. This paper compares two at failure time t j · conditional on the risk set residuals for the Cox regression model, the at that time is Schoenfeld (19S2) score residuals and the Barlow and Prentice (1988) integrated residuals, in · Tp ei Yi(t j } their ability to detect nonproportional hazards. ~TjJ Pi (t) - n Simulation results indicate that the Schoenfeld I Y.(tj ) e residuals have greater specificity. m~ The '""1 integrated residual does ~stimate the empirical The conditional eXpectation of the covariate at influence function, however. time j is Z. f 1.",Sugi-89-255 Barlow Fanchiang.txt
"p. VALUE ADJUSTMENTS FOR MULTIPLE TESTS IN MULTIVARIATE BINOMIAL MODELS Peter H. qestfall. Texas Tech University S. Stanley Young, Glaxo Inc. L Introduction The multivariate binomial model can be used observed-p-value for the given test. in a number (If important situations~ side effects This methodology is compared to the usual in clinical trails and tumor distributions in Bonferroni-style adjustments. it and is rodent carcinogenicity studies are tw(J prime demonstrated that B-onferroni-style adjustments Modern logistics allows for the examples. are grossly conservative in certain instances due collection and handling of multiple variables; to their failure to account for dependence between therefore. there is a need to account for the tests and the discreteness of the data. . multiplicity of testing problem. The approach we Results of bootstrap and permutation propose is to use statistical resampling to adjust resampling adjustments tend to be similar. p-values for multiplicity. thereby controlling the particularly for lat""ge sample sizes. The experiment-wise error rate. approaches are philosophically different: For example, two-year rodent in bootstrap resampling is prefererable if an carcinogenicity studies, there are typically 20 to unconditional analysis is desired (Upton, 1982, 50 tissues which are examined for occurrence of demonstrates that nominal and actual Type I errors any of several possible lesions. For a particular are closer to nominal error rates and that trea.tment group, the nwnber of occurrences of a statistical power is greater in the univariate part:icular lesion at a particular tissue may be two-sample case); while permutation resampling is modeled as binomial, and the vector of such preferable if a conditional analysis is desired frequencies may be considered multivariate (Yates, 1984, gives philosophical arguments for binomial with unspecified dependence structure. favoring the conditional approach). The same model may also apply to clinic",Sugi-89-256 Westfall Young.txt
"A PROCEDURE FOR THE ANALYSIS OF MULTIVARIATE BINOMIAL DATA WITH ADJUSTMENTS FOR MULTIPLIClTY P.R. Yestfall. Texas Tech University Y. Lin, Texas Tech University S.S. Young. Glaxo, Inc. CONTRAST 'name c' values; IIlTRO!)UCIION TREND f name l' values; A SAS procedure. called PRoe MBIN, has TREND 'name t' values; been dev-eloped to tabulate and statistically ADJUST_P options; analyze Multivariate BINomial data from FREQ variable; mUltiple treated groups. The statistical tests BY variables; provided by the PROC are ~inear tests in ilie proportions for a multivariate Qne-way ANOVA model with or without a blocking variable. PROC MBIN statement This PROe has been developed primarily to perform various statistical tests and to deal The options that can appear with the PROe MBIN with multiplicity problems that arise in statement are given below. rodent carcinogenicity studies. However. the DATA-SASdataset scope of the !'ROC is much more broad: it names the SAS data set to be used by PROe provides marginal non~adjusted analyses and MBIN. The default is the most recently created adjustments for multiplicity for a wide range data set. of applications involving multiple treated groups with multiv~riate binomial data. A large variety of statistical tests are OUTPVAL-SASdataset names an output the SAS data set containing provided for comparing different groups. The output consists of a collection of raw p- variable names, trend or contrast names. and all associated p~values. (one values for each test/variable along combination) corresponding with OUTRES-SASdataset multiplicity-adjusted p-values. The user may names the SAS data set containing information among a choose variety of possible multiplicity adjustments. from the resampled data sets when resampling is performed. The user may specify multiple between group linear contrasts for eaCh variable. This NOTAB PRQC covers the following as special cases: that not be requests tabulated frequencies (a) all pairwise contrasts (b) all",Sugi-89-257 Westfall Lin Young.txt
"SOLUTION OF ILLcPOSED INVERSE PROBLEMS USING B-SPLINES James E. Dunn, University of Arkansas (Fayetteville) Rum! Era, University of Arkansas (Fayetteville) model proposed by Twomey (1975) is Abstract. A refined technique is fresented to estllaate the true/article size d1stribution I~i(X)f(X)dx frODl an electrica aerasoi analyzer (EM) gen- erated histogram. Following the usual formula- £i (i=I ····· n). Yi = + (l) tion of this il1~po.(Ied, inverse probleJlt. kernel functions are used to account for the inaccur- aedes of classification into correct ""bins"" of i.e. , a Fredholm type integral r where the histogram. By choosinf to reprepresent the probability dens1ty function as a ~uired is a known probability density function, w~nghted sum of B-splirres, we have arrived at a usually re£erred to as the kernel, which method of recovering an estimate of the density reflects imperfect separation of the without need for use of numerical quadrature. Smoothness of the estimate is controlled by particles into their appropriate bins; balancing the fidelity of the fit against a f(x) is the true probability density function routhness penalty which is proportional to the to be estimated; integral of the square of the second derivative Ei ift an additive, random error which is of the recover-ed detl$ity. Non-negativity of the estimate is provided by use of quadratic prcr inherent in the i' th measurement. grallllling to solve the restricted lesst squares problem. Based on extensive data analysis J the Estimation of f(x) in the above is an 111- method of generalized cross-validation (GCV) posed, inverse probJeJI1 (O'Sullivan, 1985) in the appears to underestimate the optimal s1OO()thing sense that slight perturbations in the data, Yi) coefficient by about one order of magnitUde. may produce large changes in an _es timate of f(x). Crump and Seinfeld (1982) redefined Wahba's (1979) general solution of the FredhoUn 1. PHYSICAL MOTIVATION integral equation specifically to treat EAA data.",Sugi-89-258 Dunn Era.txt
"ANALYSiS OF THE PROPERTIES OF TWO BINOMIAL RANDOM NUMBER GENERATORS Susan J. Kennys University of Oklahoma Health Sciences Center J. Paul Costiloe, University of Oklahoma Health Sciences Center Andrew 1. Cucchiar8.t University of Oklahoma Health 8¢ienees Cl')nter INTRODUCTION ( P ( X - x-I J .. 1,000,000 < 345,982 <- P ( X - x ] * 1,000,000 ) Random number generators are used in simulation studies to produce sets of random variables that would be selected as one: of the random variates. arise from distributions with known parameters.- Simulation studies are conducted with these detasets Ten thousand random variates were selected in to test models of interest to researchers. Typical this manner from binomial distributions with examples of simulation studies include tests of the parameters N of 100, 500. 750 and 1000 and - 1r of assulllptions of 8. statistical model or formulation of 0.001, 0.01, and O.L A X2 goodness of fit statistic equations to. predict tbe rate of spread of a disease was obtained for each of the observed distributions within a population. Since simulation studies can to test the hypothesiS that the distribution is have important consequences for research, the binomial~ random number generators used to produce simulated data must be reliable. RESULTS The purpose of this paper is to examine the Our results indicate that the RANBIN function distributional properties of random binomial variables does not perform well When the expected value: of produced by each of two random number generators. the binomial distribution is smaU~ RANBIN produces The first generator examined is the RANBIN function an overabundance of values at the low end of the of SAS(Rl Institute Inc. The second generator is a distribution and a corresponding underproduction of derived procedure that uses a uniform random values at the high end of the distribution. RANBIN variable to' sample directly trom an expected binomial consistently produced significant X2 goodness of fit distri",Sugi-89-259 Kenny Costiloe Cucchiara.txt
"LARGE FILES AND COMPUTER IlESOURCES What is not very _ talked about in the u _ _ is, ""What do you Thi:i paper discusses the kinds of computer resources large-file pnxenin,g uses and bow to estima~ RlSOUl'CC requirements to avoid. do whcn you've done your best to·minimize size and maximize efficiency and tbe remaining file (or job) is nill huge?"" All failed jobi. The examples given IU""e specific '10 batch processing on IBM mainframes ruQning OS, but many of the principles apply to computer processing requires :space to sum: data, permanently or temponrily, CPU time for reading, writing and manipulating data, Qther processing milieux a:i well. The paper eOl;lcludes with an example illustrating some of the simplest. most frequently and a certain amouot of space (a ""region"") in the CPU (called mistm:detstood. and largest-impact way! 10 nxI.ucc resource we. memory or core) in which the comPl1ter does il:!i wud;:, After aU one ~5 careful planning and testing of efficient code~ jobs",Sugi-89-26 Mackiernan.txt
"Improving Performance in Statistical Analysis of Large Data Sots: Vector Processing of SIS G) 0.,,"" Brue. F06a:rty~ Euginoe:r:1Xlg/Scien.titie !i.tional SUpport COllter. IBM Corp. Leigh DlIum. SJ.S Ins.titute, Ine. Introduction Arraya (or nc't<lra) DIMEISIQi J.(n).B(n).C(n) hay. n e-lecent. Significant. progtess has heen made recently in the processing. of nume:ritally intensiv~ eomputing (or ""NIC"") programs. In many Set. up DQ l(lop. n 1~ DO 10 I applications in science and engineering supezcomputers au used stepping one el.ment to provide significant impEovements in job execution time. One of 6't · time the features that chart«;terizes supetwmpl1ters is vedor processing. of A(I} is ~hM .~ = D(I) 10 i(I) + C(I)*C(I) B(I) Thif uses'a ma.chine architednral extension of ""normal"" (S<alar) architecture to enhance performance of floating point wmputatioD. NIC progtams that are vedonzed improve uecutiOll time by fac- In vector processing, the FORTRAN code is WHtteD the same as totS of 1.2 to about 10, with typical speed-ups in the lange 1.S to 3. for scalar, but the compiler processes a Mod:. of observations almost Although most users .of the SAS system run .small jobs telative. to simultaneously, eonvuting the code to- this: most me applieatio~ thae are some users who havelong-runmng SAS jobs, some usas who have moderately long jobs they run quite DlKESSIO» i(n),B(n}.C(n) (SUI. as for scal.ar) often, anq some data processing, shops whieh have a need to redu<:e CPU utilization. Loop over I. but,by 8 DO 20 I n. 8 1~ SAS Institute and IBM have been exploring the need fot and ben~ elements at a time efits <If vc:ciorized SAS code among NIC users. These use:s are ld4. e1emonta .~ a t. MII(n.lt$-l) J DO 10 alr.ea.d.y usin~ a supercompuur and often have applications that time invohre statistical :analysis eithet m chei!king data ~surnpti()ns in =B(J) 10 i(J) + C(J).C(J) (Same as for scalar) a NIC model or in statistical analysis of a. NIC model output. An- otller use of SAS in",Sugi-89-260 Fogarty Ihnen.txt
"BALANCED DESIGN ESTIMATION Gordana Jelisavclc, NYNEX Corporation where Introduction 1. M{K)=bias matriX K=bias parameter matrix Explanatory variables in large linear e,.OlS estimator regression models are often significantly The expected value of BIK) is: correlated. E(S(Kll·M(KlB This problem, known as multicollinearity, Variance-covariance matrix is: causes low precision of the ordinary least Var[B(O]. o'[M(K)(x'xl-1M(K)' 1 (3) squares estimates of the individual regression The residual sum of squares 1s: coefficients which can lead to erroneous SSE(K).SSE.S'[N(K)'(x'x)N(KllS (4) \ nferenees . where: Frequency of the multicollinearity SSE.Sum of squared residuals for OLS problem faced by researchers in many fields and S.OLS estimator notably in the field of econometrics, keeps N( K).M( Kl- I generating a demand for alternative estimation I.a pxp identity matrix methods that ensure higher precision of pxp design matriX xlx~a coefficient estimates and consequently The total variance of coefficient estimates for contribute to an increased reliability of B(K) is: inferences. TVElK) ·· 'trace IM(K)(x'xl-1M(Kl'1 (S) This demand appears to be met by linear The total mean square error 1S: biased estimators the best known of which is the MSE(K).TVE(Kl.B'(N(K)'N(KllB (6) r1dge regression. where the second term represents the square of Unlike the ordinary least squares, the the bia.s:. ridge regress10n is not a fully automatic optimization procedure In that it involves a 3. The Theory of Balanced Oesign Estimation significant amount of judgment and inter- pretation skill on the part of the analyst. When multicollinearity Is present, OLS This problem, along with the regular ""bias estimator loses preCision. as certain elements aversion"" represents central argument against of trace of the inverted design matrix become the ridge regression. 1arge. The balanced design estimation overcomes If all variables in the model are this problem by Introducing a mathematically presented in",Sugi-89-261 Jelisavcic.txt
"time t. and has covariate value Zi' R. denotel the subjects at risk at tl:' and 6i ~ 1 if an event like death occurs at i and 0 The PHGlM procedure is a well documented,. otherwise. We assume that t1 $ ·.... ~ tN efficient and widely used program for flttlng and no ties are observed for the d events. the proportional hazards model in survival All covariates Zj are evaluated at the times studies. We have developed some new ti corresponding to risk set R , i extensions of the procedure which are useful in some applications to chronic disease epidemiology. One extension allows Two Simplifying Conditions covariates to vary over time and allows left truncation in addition to the standard right censoring. The other application allows In maximizing the partial likelihood, the estimation of the hazard ratio from a case- following quantities are needed in the cohort design. Standard variance estimation methods do not apply to this design, but we suggest. bootstrap procedure to estimate the variance of the hazard ratio and obtain confidence intervals. The proposed extensions are illustrated by worked example calculations of the contribution to the total from two data sets. score and sample information for each event time. Th. total score and sample information are then obtained by summing over their",Sugi-89-262 Pee.txt
"Auto.ated Analysis of Linear-Plateau Models Damon Disch, Pitman-Moore, Inc. a useful model, the estimate of B must differ Introduction: significantly from zero. Generally, this test In 1975, Anderson and Nelson introdu~ed a should be one-sided as B1 should be greater than series of regression models to relate the amount zero for ADG and less than zero for FPG. of fertilizer used and the yield response observed. These models are called linear- plateau models and are speeial ~ases of the Figure 1 piecewise linear regressions found in some applied statistics texts (for example, Neter and Examples of Linear-Plateau Models ~assetman, 1974 f pp. 313-316). Of particular importance to Pitman-Hoore. linear-plateau 5.0 models have been used by FDA statisticians to relate the dose level of a growth promoting drug to the response observed in such parameters as R average daily gain (ADG) and feed per gain (FPG) e (BVM, 1975, pp. 9-10). This report concentrates s on the four simplest versions of these models, P 4.0 models II, III? IV. and V. The models are ! i,' o /1/ described and methods of statistical analysis n ~/ are discussed. This report continues with a s f description of an aU{f,ated analysis of these e ,"" models using VMS SAS Release 5.18 code to 3.0~ implement the methods discussed~ The data are I I 1~0 I assumed to come from one or more trials possibly o 50 100 200 with blocking and other factors present. The number of replications may vary from trial to Dose trial, but each dose should have the same amount (observed at 0, 50, 100, 150, 200) of data within any single trial. Anderson and Nelson (1975) concentrate mainly on the case of Hodel III-1 uniformly spaced dose levels although the 1987 Model IV-l reference has some rules for non-uniform Model V-2 spacing. The code documented in this report A model IV consists of a sloping line from does not require unifo~m spacing or integer dose levels. The description of the models follows. the zero dose to a point between tw",Sugi-89-263 Disch.txt
"CONFOUNDING OF EFFECTS IN EQUALN DESIGNS: FACfORIAL ANCOV A ScottE. Maxwell, University of Noire Dame HaroldD. Delaney, University of New Mexico The analysis of covariance (ANCOV A) is often model. regarded as one of the least well understood and most To understand the role played by a covariate, we misused statistical techniques, at least partly because it will consider the simple case of a 2 x 2 equal n factorial combines analysis of variance and regression concepts. design. A full model for such data could be written as However, it is generally thought that researchers who Y i = 110 + JllX Ii + 112X 2i + Jl3 X3i + Jl4X4i + ei' master ANCOVA in the I-way between-subject design where X 1 is a dummy variable representing group can at least take solace in the fact that generalizing ANCOV A to between-subject factorial designs is membership in levels of the first factor, X2 is a similar straightforward, at least in the case of equal n designs. dummy variable for the second factor, X3 is the product For example, Kirk states that ""The analysis of covariance afXI and Xz and bence represents the interaction, and for a factorial experiment is a straightforward generalization of the procedures discussed in connection X4 is the covariate. For simplicity, we will assume that with a completely randomized analysis of covariance effect coding has been used. Because the design is an design"" (1982, p. 743). Similarly, Cliff states ""It may equal n design, Xl' X2' and X3 will be mutually be obvious that ancova generalizes to factorial and other uncorrelated. For this reason, when X 4 is not in the designs... When the group sizes are equal, one could staightforwardiy perform analyses of variance of these mndel, the totai sum of squares can be partitioned inteIl;epls (or, equivalently, the adjusted means]"" (1987, unambiguously into proportions explained by XI' X2' p. 285). The pnrpose of this paper is to show that the and X3' However, this simplicity disappears when X4 generalization",Sugi-89-264 Maxwell Delaney.txt
"COMPUTING THE STANDARD DEVIATION FROM A GEOMETRlC MEAN Daniel R. Bretlteim, KPMG Peat Marwick INTRODUCTION mean. The seven-step process outlined below was used for tllese purposes: TIle requirement to compute the standard deviation Compute the natur91logar<llIID of the charge 1. from geometric (rather than arithmetic) mean has fI. variable for each observation. been prompted by the desire to medel "" portion of the Federal government's methodology for reimbursing 2. Compute the mean of the log values for each hospitals for servK"""" provided to Medicare recipients. diagnostic group. The Health Care Financing Administralion (HCF A) h .. used this approach at; the mecllanism to identify 3. Merge each observation with the appropriate unusually higil-L""()st cases, known as outliers. The group mean. geomett'ic mean cluu'ge for each diagllosis-l""elated group (DRG) serves as .. benchmark to which multiples Compote the antilog of the group mean. 4. of the DRG's alandard devialion are added. The resulting threshold mual be exceeded for an individual 5. Compute the squared deviation of each case to achieve llouUieI.'lI status. These obseITations observation from the antilog of its gt'""oup are deleted from the data base prior to computing the meaH. average charge for each DRG. Sum the squared deviations for each grQUp. 6. Procedures available within the SAS* System for computing averages are based pdmariJs on the 7. Divide the sum of squared deviations by the arithmetic mean. The arithmetic mean is distinguished numher of observations (less one) in each from other seldom-used statistics sucb as the group. The square root of tltis value yields geometric mean, which averages the iOg'al'ithms of the sample standard deviation.. numbers and the harmonic mean, wWch averages reciproe~ls. F orttmately. ti,e SAS* System provides TIle statements used to accomplish these calculations tile flexibility Bnd data manipolaUon power to satisfy and (l<int tile results are displayed in Exhibit 2 o",Sugi-89-265 Bretheim.txt
"Expected Variation in Study-Specific Vaccine Efficacy Estimates . Allen W. Hightower, M.S. Claire V. Broome, M.D. lee H. Harrison, M.D. Interval width,is difficult to interpret Here we have Haemophilus influenzae type b (or H. flu.) is the most conflioting study results, wtth nearly all having wide common cause of serious bacterial disease in children under ~e: It is a completely different dis~e entity confidence intervals. Under normal circumstances, approval of a new vaccine is a tenuous process that from V1rallnllUenzae, or common flu, despite having a has to walk the fine line between the conflicting similar name. H. flu Is a disease that occurs almost agendas of government and nongovernment experts, exclusively in children under 5, while viral influenzae study researchers, and activist groups. The fact that a affects ail ages, but has its greatest Impact on the decision was going to have to be made using data elderly. Haemophilus influenzae disease, despite from five studies with discordant resufts promised to being relatively unknown to the general public, affects make life even nastier than usual for those involved. 1 in every 200 children before they reach age five. H. Quite naturally, each researcher was ciosely flu disease is very serious in nature. Forty percent of scrutiniziO!) the study designs of the other studies, as children with invasive H. flu disease devefop well as their own, for potential biases. There are meningitis, and 5 to 6 percent of all cases die, despite several potential explanations for the variation in the treatment with antibiotics. Among meningitis cases, study-specific vaCCIne efficacy estimates. First of all, 20 to 30 percent of the survivors have permanent there were several different study designs used. Each sequellae, such as blindness, deafness, or mental different method of finding diseased and undiseased retardation. These sequellae place an especially individuals Is associated with as own biases. heavy burden on the victim",Sugi-89-266 Hightower Broome Harrison.txt
"Assessing Capability of a Bivariate Process with Emphasis on Hole Location Douglas L. Berg Melinda J _De Coste Robert J. Nagel Hydra-matic, Division of General Motors Corp. Introduction l~ Figure 1.1 Capability of an industrial process yielding univariate data is usually assessed """",th the measures C p and C rk LSL USL where C _ (USL -LSL) 6u p- and = min{(USL -1'), (LSL -I'l} CpO 30' 30' Here, USL and LSL are respectively the upper and lower specification limits for the process. C p is an iDdicator of the number of distribut~ons of the process which could be = 1.0 Cp = 1.0 fit within the tolerance region (the interval (L8L, USL)). Cpk Cpk takes into account both size of process variation and the distance the process is from the nominal or target value. Figure, 1.1 shows a process which is centered and Figure 1.2 uses up all of the tolerance. In this case, C p = 1 and Cpk = 1. Figure 1.2 shows a process which is also cen- tered at nominal but uses up only about a third of the LSL USL =3 and C pk = 3. When encoun~ tolerance. Here, C p tering a process whlch yields bivariate data such as lo- rotat~ cation of the center of a hole Qr imbalance of a ing part, the practitioner is left with little choice but to sev~ analyze each variable separately. This approach has eral disadvantages. Any dependence among the variables = is ignored. Further] even if the variables are indepen- 3.0 Cp Cpk = 3.0 dent (which would be very difficult to verify in practice), confidence statements made about the individual vari- ables do not guarantee the same level of confidence for It is therefore desirable to consider both variables both variables jointly. In particular, if the variables are independent) (I - 0:) confidence intervals for each vari- simultaneously. This fact has, of COurse, been long rec- ognized. The idea can be seen at least as far back as the able combine to give a rectangle having confidence level a)2 < (1 - 0.), for 0 < < 1. While increasing the work of Shewhart(1931). J",Sugi-89-267 Berg DeCoste Nagel.txt
"A $AS* INFORMATION CENTER TOOL Wayne G. Maruska, Basin Electric Power Cooperative INTRODUCTION created data sets are stored, the user's TSO SAS* provides business professionals with a powerful information processing and management file (HYCAT) on which he or she can place in- dividual SAS/AF* applications and a TSO parti- tool. The only thing required of the user is to learn the relatively simple rules of the tioned data set (PROG) on which display $AS* language. Unfortunately this can be manager programs can be saved when the user threatening to users who are uncomfortable develops more expertise with the software. All of the file allocation takes place behind with computer software or tenminals. The problem is compounded when familiar hardware the scenes and is transparent to the user. and software are being replaced and the user After the allocation of the required files, is r~uired to learn new and unique applica- SAS* is executed with an initial statement tions. This paper will describe how an organ- that displays the main menu of the information ization took advantage of the features of center tool (Figure 2). By selecting the ap- propriate number or letter on the main menu SAS/AF* to develop a menu-driven end-user com- puting tool that overcame the fear of new screen, the user can activate the function that is desired. The ""Individual Application"" software and provided an easy transition to option is generally not used by the beginning the use of SAS*. $AS. USer. It was included in the main menu for advanced users who want to execute indi~ BUSINESS BACKGROUND vidually developed SAS/AF* applications through the Information Center Tool menu. Basin Electric Power Cooperative is a member- owned electrical generation and transmission supplier. It serves an area of more than FILE MANAGEMENT MENU 400,000 square miles in portions of Colorado, Iowa, Minnesota, Mont.na, Nebraska, North The file management menu (Figure 3) is dis- Dakota, South Dakota and Wyoming. The C",Sugi-89-268 Maruska.txt
"= physapp:""; put ""value $varlen""; Using the SAS System one can easily end: create an entry screen for the user to define ad hoc reports, to be output in ·· I II trim(name) II l l f line;; . simple ,columnar formats. The creation 11111 put (length, 2 · j II "" , "" , of such a system involves three steps: put line; 1) Creation of a SAS dataset which if eof then do; contains the variable names and I' ; II put lIother I ; variable lengths of the file to end; be accessed. This is done using the PROC CONTENTS procedure with return; the 'out 1 qualifier; run, 2) Creation of a format table from x 'sas physvar.dat'; the above-mentioned SAS dataset, to be used to access the lengths of the variables input by the user in order to properly format * Program Screen and Code the report; 3} Creation of a SAS/AF Program Ad Hoc Requests from PHYSAPP.SSD Screen with SQL-type appearance for input by the user of variables desired, any subsetting SELECT &selectl &select2 &select3 required (to include/exclude &select4 &selectS &select6 records meeting certain criteria), &select7 &select8 the sort order to be output and the title of the report~ WHERE &vall {AND /""OR;;-'-j--- The report requested is then displayed &val2 on the termi,nal for verification by the ( AND/:""O""'R'j--- user. The user is then queried as to &va13 _ _ _ __ &var3 whether or not a hardcopy version of the report is desired. This is &order _ _ __ ORDER accomplished through the use of another program screen that either prints the &he",Sugi-89-269 Smeby.txt
"TIiE ART OF TESTING PROGRAMS WITH AN EMPHASIS ON LARGE FILES Juliana M. Ma, Quintiles INTRODUCITON programmer time and/ or computing dollars. Any attempted· productiRII run, whlch must process an TlUs tutorial introdutES general testing strategies entire file, becomes a significant event Put another related to the problem of being convinced that a way, discovering a mistake after proce.smg a large program is ready for use. Although testing should· file does not make most people happy. Finding prob-' proceed logically, the procESS also requires imagina- terns in programs as early as possible by thorough tion and bas common pitfalls. Large file processing is and efficient testing becomes more important When emphasized since potential losses are greater if an machine efficiency significantly effects processing inappropriately tested program becomes a production time. and cost, the extra programming time spent version. Examples from both mainframe and micro- testing code pays off directly in comparison to the possibility of a wasted production run. In addition, computer environments are provided. the indirect advantages of reduced frustration when testing pays off should not be underestimated. The methods discussed are direc:ted toward program- mers, data managers, project managers, and anyone who does not like, or cannot afford, surprises after a TESTING STRATEGIES production run. Only basic knowledge of DATA step programming is I'SSUmed. Testing is presented as an The testing strategies described here range from important aspect of programming development. broad generalizations to specific coding tricks and pitfalls. The most important idea is to always, always, run a test program before a production run. Then LARGE FILE CHARACTERISTICS keep testing until you are convinced you can afford' to slop. (For a more scholarly approach to deciding Before discussing .pecial problems associated with large file processing; we must first attempt !D define when testing should sto",Sugi-89-27 Ma.txt
"THE COMPONENTS OF SAS/ASSIST: 6.03 lM Main menu: SAS/ASSIST software provides a menu-driven gateway to the powerful features available in the SA$«! System. The special- purpose windows and selection lists make it easy to genera1:e a report or produce a graph. Wflh SAS/ASSIST. you can perform tasks in the areas of data management, data analysis, and data presentation. SAS/ASSIST software is a comprehensive application written us- ing the SAS System as a toolbox, Because your own applica- tions can be hooked into SAS/ASSIST, it can serve as a platform for all SAS applications in use at your organization. SAS/ASSIST software is provided free with base SAS software.",Sugi-89-270 Roggenkamp Kramer Gagliano Erickson.txt
"l~ Figure OISTAR Hain Menu In December 1985, B.C. TelepJwltt O.fmpany implemented an in-house aeve/oped Office ltifOf71Ultion System (called OISTAR) running OR VM/CMS. l~e tks;gn _JOISTAR's OISTAR and Workbenches matrix mtnft system made it easy to add 1reM' fIUJ(:tions for Shortly after OISTAR was implemented, a fOCUS clients ming a common fornua. When SAS Institute relellSed-venion 5.08 with tfu! new SAS/AF* function.f and Workbench (based on InfoBuilcYs TALK series of prototypes a declMon WtU nuuk to put up II SAS programs) was piloted, Having all of the commonly Workbench <m OISTA R giving users a friendly interface to used tools and programs on one matrix menu proved to wphistic«ted tools. be very popular and our clients soon began asking tor Workbenches in our other supported products. We knew that Releaoo 5.0 of the SAS System would have",Sugi-89-271 Whan.txt
"only information on members of a specific area Time planning of projects for staff members of is available to the Lead Officer in cbarge of that area. the technical Services Area of Pittsburgh National Bank was done manually for the near capability was accomplished through the This future. In ·1983. the Bank joined PNC use of data files for each Since then, toe department Fitutucial Corp. individual operational area, ccncatenating them together has experienced a three-fold growth in support when necessary. staff members of the data center., Le., one of the three corporate data centers. Planning PROJECT PLANNING SYSTEM WALKTHROUGH for critical projects and individuals was impossible without automation. Canned time The remainder of the paper describes a number plann1ug software products were tried and none of steps that a manager would execute in order had the flexibility in database handling and to update and repcrt from the system. An internally customer reporting desired. developed system by the Capacity Planning/TSO Step Number Description Software subgroup was the best solution. Logon and CLIST Call 01 02",Sugi-89-272 Ivanschultz DeMarchis.txt
"WHERE Clause Processing This paper highlights the new features in release 6.06 of SAS! The WHERE clause creates a subset of observations for process- FSP software. These 1eatures include the use of the WHERE ing by the procedure. The WHERE clause is any valid SAS ex- clause with the FSEDIT procedure and FSVlEW procedure, ex- pression involving one or more of the variables in the data set. ample.of using SCL wfth PROC FSEDIT and PROC FSVIEW and Observations must satisfy the specified condltions to be pro· the use of the SCL souroe level debugger to assist in the devel- cessed by the procedure. The data set itself is not subsetted, opment process, The WHERE clause is available in the FSBROWSE, FSEDIT, FSVIEW, and FSLETTER procedures. A WHERE ciause can be specified at the invocation of the proce· dure or from the command line once the procedure is active. If",Sugi-89-273 LaChapelle Harris.txt
"A Quick and User-Friendly Comprehensive Front-End for the SASfGRAPH"" Procedures. Bob Day,S.A. Medical Research Council. Retha Keyser, S.A. Medical Research Council. INTRODUCTION 1. No end-userSAS® coding 2. Wide range ofSASlGRAPH® output It is the role of the Computing Centre of the South 3. Quality output, quick response African Medical Research Coundl CMRC) to Clear. interactive, ""PC_like"" Menus 4.. encourage the use of computers (mainframe and PC) 5. Flexibility/user-freedom throughout wherever they might prove beneficial within the 6. Error checking hefore SAS submission broad spectrum of medical research in southern 7. Retention of structured final SAS code Africa. One area of scientific computing yet to fulfill its potential appears to he graphics. To quote Donald Greenberg We, the developers, are academics who have adopted computers because of their proven ability (and ""If computer graphics is to have a role in improving the further potential) to enhance our research. It was to will future of our civilization, the real value be in its be expected, therefore, that our design methods application to science, engineering, and design."" would differ from those used by developers with qualifications in Computer Science. Before taking The influential 1987 report on ""Visualization in any langua~e considerations into account, we Scientific Computing"" stressed the following points simply apphed our general research protocol about the potential for computer graphics: development methods to this particular problem, i.e. we broke it down into ever smaller components and ""The gigabit bandwidth of the eye!visual cortex system devised solutions for each of them. We have since permits much faster perception of geometric and spatial heen told by suitably qualified people who have seen relationships than any other mode.,,"" ESIGSAS that ""it has a modular design using top- ""As a technology, Visualization in Scientific Computing down functional decomposition"". We were relieved pro",Sugi-89-274 Day Keyser.txt
"ACCESS TQ THE SAS(r) SYSTEM FOR BLIND OR PHYSICALLY.DISABLED PEOPLE Joel Achten~rg. Washington University, St. Louis, Me lc INTRODUCTION b. BlR PERSONS lUll! UJl§. IMPAIRMENTS ~ In this era of lIuser friendly"" software~ computing with SAS(r) system products is now Most of OUl: work to date has been in pro- truly accessible to just about everyone. With viding adaptations for those with visual impair- the introduction of the SAS/AF(r)~ application ments. Since most visually impaired persons can facility} SAS/ASSIST(tm), windows, and more, what learn to type, the problem a ·potential user faces could he easier? You pull up a chair to a sleek in using SAS is not how to get information into desktop computer, slip in a disk, flip the power the computer~ b~t how to verify their own input. switch, and a moment later a bell beeps. a menu and to read SAS s display of messages, menus, of options appears on a multi-color screen, you windows and output screens. The extent of vision tap a conveniently labelled key, and you're off loast of CQurse~ determines the degree of adap- and running. Sure, sometimes the manual is less tation necessary to make the system acces~ible. than clear but in most cases even an inexperi- enced user can be up and ~ning quickly. For exampl~, someone who is ""legaJlyl1 blind, but with some residual vision, might be assisted Think I1gain. This time imagine th.8.t you are by providing .a much larger than standard screen, blind. That multi-colored menu is no longer or by providing a means for enlarging portions availahle, and the welcoming ""beep"" is just an of the text (zooming) on the standard screffn. annoyance. Or imagine that you are paralyzed. For total blindness, however. visual displays Ordinary typing is a slow and tortured process must be replaced by auditory (synthetic voice) with a pointer held between your teeth; even the or tactile (braille) output. function keys are a major effort; and key combi- nations like CTRL-ALi-DELETE are simply out of",Sugi-89-275 Achtenberg.txt
"ion Abstract In a modern distributed processing PC environ- cau be slow and awkward, since the SAS system ment, situations arise where users may need to relies on extensive use of overlays and sub pro- access select portions of existing databases to grams. As an alternative to using the SAS system process or transfer data utilizing techniques not for those instances where less sophisticated data always best suited to the existing applications access and reportiug fuuctions were needed, we development environment. In the case of large developed a series of library utilities which allow SAS' data sets iu a local or network PC environ- direct access to SAS datasets from Microsoft meut, ·users may need to selectively retrieve or QuickBASIC. snbset data records to produce reports, new files, or transfer data to other applications. Often, Structure of Version 6 SAS Datasets in a PC such file processing requirements, although Environment possible to accomplish within the SAS system, may not, based on the situation, be feasible due The fir'st step in iuterfacing with an existing SAS to processing speed or system overhead dataset was to ascertain the exact structure of the requirements of a standard SAS application. data file. Since documentation is not availabie on the specific physical structure of the SAS Providing such file access capabilities to SAS datasets, extensive research had to be done. Mter datasets while maintaining fnll SAS dataset com- countless hours of trial and erro",Sugi-89-276 Gilles Sisemore.txt
"USING SAS® SOFTWARE ON A MAINFRAME TO RETRIEVE DATA FOR A PC Jude L. Naes. Jr., Emerson Electric Co. Edward B. Dailey, Emerson Electric Co. file can be electronically transferred to a PC INTRODUCTION and read into a PC application. Over the last five years, the use of personal The LOR system uses a series of SAS/FSP computers (PCs) at the Electronics and Space screens to define and run jobs that retrieve (E&S) Division of Emerson Electric Co. has in- da ta from the General Ledger. The screens are creased tremendously. Many of the popular data accessed through the Main Menu (figure 1). This base and spreadsheet software products are in menu is di splayed with a SAS macro. use. Until most of the data used recently~ in the pes was manually input from mainframe- generated reports. The time required to input data was reducing tbe productivi~ that is nor- mally gained from using a PC. In addition. data AHAl YST ....> JIJl!( IlAES ACTUAlS TIIROIJGH AUGUST 1986 integri ty was a potential problem. l£DGER DATA RETlU£VAL SYSTEM Using base SAS and SAS/FSp® softeare, we MAIN KIW deve loped a front-end to a la rge mal nframe da ta THE fOll.OWIKG Of'TlOMS ARE AVAILASl£: base that allows people to select and summarize data for their PC applications. The data is 1. OEFlIiE II ItEW JOIl. 2:. DISPLAY PREVIOUstY SAVED JOB DEflIlITIONS. written to a mainframe file that can be down- loaded to a PC. After the data is downloaded, H. HELP. it can be easily read by a variety of products, including Lotus"" 1-2-3"", dBASE Ill"", dBASE IV m , ENUk YOUP. GHOIC£ OR PIG;SS ENTER TO UIT SM. R:BASE®, Enablem and SAS software. BACKGRQUND The General Ledger is a large mainframe data base that contains the Division's accounting Figure 1 data. It is part of an Internally developed system, written in COBOL, that runs in a batch mode on an IBM"" mainframe computer. Much of the DEFINE A NEW JOB financia.l analysis done within the Division re- quires data from the General Ledger. Option 1 on the Main Menu is u",Sugi-89-277 Naes Dailey.txt
"If your application calls for an informat that is algorithmic in nature. and not table~drtven as the example above. then a user- written informat is needed. Most of the Institute-supplied infor- One of the more attractive aspects of the SAS® System is its mats are algorithmic. For example, the DATE informat that con- extend ability. If no available item can perform a desired function, verts ddMMMyy (for example, 01 JAN89) into a $AS date value then a new item can be written to fulfill this function. The capabif~ ity of system extension has been available almost since the SAS is algorithmic. since there is no table that matches an individua.l System's inception. This paper describes the features of the string with the proper value. Algorithmic i-nformats are written in a lower-level language such as C. product in Version 6 of the SAS System for system extensions, and offers an",Sugi-89-278 Langston.txt
"r A simple SAS program to look at stood. It is not unusual for several slightly a data base is shown below: different SAS programs to be written which do similar analyses. Often a PROC CONTENTS DATA~DBFISH.TRAWL; prototype program is developed and then PROe PRINT DATA=DBFISH.TRAWL (OBS=20); modified over the course of time into a series of programs. Perhaps all the a PROC This two line program does programs are the same except for differ- CONTENTS on a data base and then prints ent input data bases or analysis vari- 20 observations using PROC the first ables. The maintenance parallel of PRINT. This is a trivial program, how- programs such as these is very diffi- ever, even it would be a useful tool 1f If a change must be made in one, cult. it could easily work on any data base. then it must be made in all versions of A REXX exec was written (for both eMS the program. It is much easier to write and PC-DOS) which allows a master or and maintain one generalized program generic program to include dummy argu- that will satisfy all of the users'l ments. such as data base names, which needs. There are several methods of can be replaced automatically prior to either converting SAS programs into execution of the SAS program. boiler-plate or generic programs that can be used for multiple purposes. SAS PROGRAM DESCRIPTION macros and SAS AF are used extensively for this purpose. There is an additional A program written in REXX is used to need for non-SAS (yes, Virginia, there control the",Sugi-89-279 Carpenter.txt
"Effectively Grappling With Graphics Chris Potter Syntex. Laboratories, Inc. THE PUIlPQBE OF GRAJ>HJCS Introduction. - This tutorial is a coUection of GTaphics has been defined as the art of examples taken from my last two SUGr drawing. Recently, the use of computers baa presentations. changed graphics to a ""push 8 button - get a grapli"" simplicity that baa compromised tOO art A picture may be worth a thousand words, but portion of graphics. it is a Tar<) picture that can adequately describe a thousand word set. We often assume that a graph or plot of data GTaphics should be thought of as the will automatically CODVey our message. communication ofidl'as through visual means. However an inappropriate or poorly designed plot may raise more questions than it anawers. Effecti"""" graphics must be desiJmed to communi~ate. I b<>pe to show SOme of the ways that this communication can be aB8ured. GTaphics IIl8.y be used to: In this paper r will be discussing: Show the structure in the data o Summarize large amounts of data o L The Purpose of GTaphics. Demonstrats how thinJu; are connected o Steps for Creating a Chart. Show organizational re1atioDships 2. o 3. Rules for Graphical Integrity. Provide advertising o 4. Effective Chart Design. IUustrats training o 5. Using PROC GPLOT and GCHART. Communicate ideas o Display humor o Set' up a situation or feeling o Before continuing, I should mention an exceUent reference book on this subject: The Visual Display of Quantitative Information, by Good graphics should: Edward R. Tufte, Graphics l'res8. Several examples and definitions were obtained from o Show the data clearly this source. In addition _pies of typical o Display your conclusioll6 chart errors were taken from an mM reference Avoid distorting the truth o manual ""Pointers on Effective Chart Design"". o Avoid oi-n.am.entation Unfortunately I have no other information on Be interesting and aeathetic o thismanuat Sorne DQu'ts: · Don't let 80aware defaults determine the final ou~",Sugi-89-28 Potter.txt
"er VMS is rela- This paper presents a VAxnt /VMSTM command for tively straight forward, having to create a special pur- submitting SAS® jobs to be run in batch mode. VMS pose DeL file for every job you want to run can conunand syntax provides a flexible and powerful quickly become tedious. It is a not difficult to write a tool for specification of multiple SAS command files DCL program which will automatically handle the and allows the user to override default settings by the routine aspects of running SAS jobs in batch (see use of command qualifiers. Rhoads (1988». However, for the heavy SAS user Topics covered include processing SAS jobs in batch wbo may be running batch jobs frequently, a more under VAx/vMS~ the capabilities built into the flexible approach is to write a v AX/VMS command SASBATCH comrnand~ the nature of the VAX com~ which gives the user familiar with VMS syntax tbe mand language dermition (CLD) file for specifying a ability to use command qualifiers to override default command's syntax, and the VAX run-time library options. An example of such a VMS command, called routines used to obtain information about the com- SASBATCH. is presented below. mand line. SASBATCH Why Batch Processing? The format of command SASBATCH is: Although the interactive power and speed of SAS is J nruoo [, ··· ~TCH constantly on the increase~ as well as the DECnl VAX where name is the file name of the SAS command fue line of computers. there are still circumstances where to be run i",Sugi-89-280 Gibes.txt
"text file on disk or tape). Some SAS ® procedures have an option for outputting data or It will help to first define some descrlptive statistics into SAS terms and concepts before proceeding. We are interested in a two-step datasets, but many procedures do not .. Data can be read from the output file of scenario. The first step is the your SAS program, either during the execution of a program that produces some type of output~ The program, execution of the program or afterward~ which mayor may not be a SAS program, In eMS I program output is written to a writes the output to a (CMS or PC SAS) work file that can be accessed directly disk file~ in the same SAS program that generated The second step involves it by referring to DDNAME FT12FOOl in an the execution of a SAS program that INFlLE statement. The SAS log and reads the file written during the first listing files consist of variable Two examples will be presented. step. length records that are read in using In the first example, the two steps the LENGTH option on the INFILE occur separately I in two separate SAS statement together with the $VARYINGw. programs. The SAS log file produced by the first program will serve as the informat. The MISSOVER statement can be input file for the second SAS program. used if it is necessary to read blank lines in a variable record length file. In the second example, the two steps The INDEX and SCAN functions are used occur in the same SAS program. The SAS for parsing input lines, eliminating the listing file produced in the first part need to predict exact line and column of the SAS program will be read and locations. summarized in the second part of the same SAS program.",Sugi-89-281 LeBlanc.txt
"MODIFY on the command line of your FSEDIT screen, This comma~d accesses the FSEOIT Modification Menu, where With Screen Control Language (SeL) of Version 6 of the SAS® option 2 allows you to update your display screen and option System, the power of the FSEOIT procedure has gained a new 3 permits creation of SCL statements to controt execution perspective. ""This paper covers cross validation of variable val- during your session. Other options are availabfe for assigning ues, customization of messagea that can be provided to the end- special attributes to fields and specifying general information user, doubfe-entry availablity, and the use of CALL DISPLAY for about the session, including default colors tor the windOW, integration with the SASfAF@ software. value to be used for autosave, a modify password. and so on.",Sugi-89-282 Harris.txt
"9CON~ Using SAS/FSp® and SAS/AF@ Software to Manage User-Defined Formats <W ........ ~ !i Nancy J. Michal, FAMILY HEALTH INTERNATIONAL ,.,. 83~ 1. SAS data set library Introduction Family Health International and its affiliate Clinical 2. Conunand file directory Research International are conducting increasing 3. SAS data library containing user numbers of clinical trials studies. These studies re- dictionary system data sets quire continual monitoring, including examining data 4. Format library collected from case report fonDS and laboratory tests. 5. Format association code directory One of the advantages of storing the data in SAS data OvervIew of User DIctionary System sets is that researchers can examine their data using the Project End-User Prog~mer FSBROWSE procedure. The FSP screen can be de- , signed so that the layout resembles the case report SASd""~ fonn.Itismuchmoreinformativetotheend-userifthe I~-~ lnltlatlas ~I u.... formatted values (value-labels) of coded variables ap- Command tiles User DIctionary Dictionary pear on the screen. At FHI, an interactive system has System System ~I C UDSdlllota_r. been developed using SAS/AF andSAS/FSP software =u::.:bc.:~'-'..,_-'I / that gives end-users the ability to manage their own I......:..""-..... ... formats for the variables in a project This user inter- I Fonnat Aeaoe. eo. I face tool, the user dictionary system, allows users to j define formats and then associate them with variables SAS .ppRcalh:me in SAS data sets. Figure 1 There are several advantages to managing formats A programmer defines these items to the system through a user dictionary system. Once a project be- through the user fields in a SAS/AF program screen gins and the SAS data sets are built, end-users can format variables without having to waitfor a program- (Figure2). Theprogram portion of the program screen mer to write SAS code. Therefore, programmers are runs a SAS job thaI writes out DCL commands to an external file. Text substitutions",Sugi-89-283 Michal.txt
"Personal Computers lor review. Note: All the examples All of us who have ever had to modify a SAS® pro- in this paper have been pa;ed down to make them gram know that making one little change ""here"" can simple to understand. They do not represent a lull affect something we haven't anticipated ""there."" SASI system. AF® systems are particularly vulnerable to change be- cause 01 the complex relationship between screen vari- RECOGNIZING APPROPRIATE SCREENS ables, macro variables, SAS Variables, and, in Version 6, SeL variables, Making a little change ""here"" to a The decision to use dYnamic screen generation rather screen can have a devastating effect ""there"" in the than hard-coding depends in part on the likelihood that behavior 01 the system. a screen will need to change over the life of the sys- tem. The following three screens each contain a list of Within ordinary SAS programs, you can sometimes options that the user can check off. Each list 01 options avoid having to make oode changes by using table has, however, a different likelihood of needing change, lookup techniques. These techniques are widely rec- ranging lrom very little to very large. ognized to improve both efficiency and maintainability. Within SAS/AF systems, the same principle applies- _nl you can avoid making those little changes to screens by dynamically generating the screens rather than hard- coding them.",Sugi-89-284 Weiler.txt
"Designing Complex Applications Using SASIAF Screen Control Language Eric Klusman Federal Be..,... Bank of Ghi£ago Introduction. publications, policy briefings, and other This paper discusses certain presentation materials. issues related to the design of complex applications using the SAS system, version The main users of the LAN are 6.03, under MS-DOS on IDM-compatible the research economists, the technical personal computers. Now that the full BAS support staff that manages the hardware, System is available on PCs, our department software and data used by economists, the is moving from mainframe-based SAS 5.18 publications production area, and the to SAS 6.03 on a PC Token Ring Local Area managers of the department and their Network. By using examples and a assistants. This paper focuses mainly on summary, this paper will discuss the the research economists' applications needs. question of when in a LAN environment to design a J:!]I.m SAS application, using just The LAN is used for many the tools ofthe SAS System, especially standard functions, including data analysis, SASIAF Application Facility and its new using the SAS System, version 6.03 for PCs, Screen Control Language (SCL), versus and other software; word processing; when to design a mixed application, using electronic mail; personal calendars and . tools from outside the SAS System. group scheduling; and certain management and security functions, such as backups, previously provided for the department by Previous environment: mainframe. the central mainframe staff. Until recently, the department's These functions are implemented on a Novell 8FT NetWare SFT network automation focused on complex applications on a large IDM mainframe computer configured as Token Ring. Servers and the running TSO under OSIMVSIXA, with PCs typical workstation are 80386-based PCs. Servers provide approximately two used mostly for word processing and gigabytes of disk storage, while the typical terminal emulation. These mainfra",Sugi-89-285 Klusman.txt
"us to build a system which would be completely menu- driven. A second goal identified in the early. stages was to allow the user the possibility of creating customized reports by making choices on a terminal screen. Finally, statistical analysis, ranging from elementary to complex, was a major requirement specified by staff in the Department. ABSTRACT These reasons warranted SAS software as the main development tool, with 2 of OTEDS's subsystems written in dBASE m + (another system, being implemented now, was written with tbe SCL and made The Economic Development function in local extensive use of PROC FSEDIT and PROC governments has become more important in municipal FSBROWSE). The Department chose SAS software administration during this decade. The administrations because of tbe V""driety of statistical procedures avallable now have a powerful tool that will assist them in in tbe software and the exceHent report writing planning their economic development strategies. capabilities. The City of Ottawa's Economic Development staff More specifically, OTEDS is written primarily with make use of a municipal economic database and Screen Control Langnage, and the menus, help screens analysis system (""OTEDS"") to help them in their daily and program screens are designed under SASjAF and operations. Development of this system involved: SASI AF software and the Screen Control Lan~age SAS IFSP software. (SCL throughout this paper); numerous statIStical OTEDS is comprised of four major fu",Sugi-89-286 LeBrun.txt
"A macro variable list is a SAS macro variable that contains a list of words. Although these lists are only a special use of SAS macro variables, they can be very powerful. Users can parameterize a system with them, and the system can drive itself by extracting the words from the lists, invoking macros using each word as a parameter, and by generating other fISts for itself. This paper describes how macro variable lists can be used, and supplies several useful SAS macros that build and use lists.",Sugi-89-287 Whitaker.txt
"nes ABSTRACT and flexible access to any permanent SAS'"" dataset. This paper will illustrate a menu driven system that THE MENU ======="""""""""""" allows an end user to access, edit and/or produce reports from any permanent SAS""' dataset. Origi- The first part of the system, the menu, is produced nally designed for end users who are totally unfa- miliar with programming, use of the system has with %PUf and %INPUf calls stored in a SAS'"" been expanded to include all types of users. Pro- macro. grammers without SAS""' knowledge have found it helpful in accessing data stored in permanent SAS'"" »> PfRMANENT SAS DATASET HELP MENU <<< datasets for import into other systems. SAS'"" pro- grammers have found it to be a quick and easy 1. lISTTHEMEMBERS AND' OF OBSERVATIONS IN DATASET method to use to access SAS'"" datasets without a 2. LOOK AT ONEOFTHE MEMBERS OFTHE DATASET VIA FULL great deal of coding. SCREEN EDIT Through macro driven menus, the user can (1) list 3. DELETE OliE OF THE MEMBERS Of THE DATASET the members and observations in a dataset; (2) view 4. LIST THE CONTENTS (VARIABLES) IN A MEMBER and/or edit the contents of a dataset via full screen edit; (3) delete a dataset member; (4) list the 5. COPY A MEMBER OF THE DATASET contents (variables) contained in a dataset; (5) copy 6. RUN A REPORT FROM A PERM SAS DATASET a member of the dataset; or (6) produce a report from any permanent SAS'"" dataset. The report ENTER SELECTION OR X TO EXIT Writing option uses macros to give the user fi",Sugi-89-288 Miller.txt
"APPLICATION DEVELOPMENT UNDER SAS/SHARE® Peter Dillingham The Gates Rubber Company Additionally, we have found it much more productive in Abs!ract: terms of people and machine time to run as many of Our Since SASlSHARE'"" does not address catalogs at present, application programs in batch mode as possible, rather than it is necessary to allocate shared, multi-user SAS/AF® interactively. This means code must reside in a PDS with application catalog libraries wrth a ""disp~shr."" To quote appropriate JCl. Gates' SAS® system consultant Mike Gibson in ""Share and Share Alike"" (SUGI 1311988), Putting Code Where You Can Get At It: Individual catalog members, therefore, When MC&R application users sign on to the SAS system cannot be updated unless all server users under Server, their SAS system Autoexec files ""x allocate"" exit the SAS system, and the catalog library our departmental code library ""cic.advert.cnU"" using is re-allocated with ""disp~old."" ""deptcode"" as the filerel. Even the simplest 01 code - such as invoking a SAS/FSP® Fsedit data entry screen for our This poses a number of problems in managing and Creative Group's project management sysiem with maintaining complex, multi-.user, shared applications. In proc fsedit data~depUraffic Gates' Marketing Communications and Research Department (MC&R), we have solved the problem of screen =deptuserJraffic.traffic.screen; - inaccessible calalogs to some extent by placing all systems code in a separate partitioned dataset. Application is placed in ""deptcode;' membername(traledit), rather than programs are called from SAS/AF using ""%inc in a SAS/AF program. When a user selects the SASlAF < pdsmembername> "" and ""xsub <pdsmembername>."" menu option to edit the traffic dataset. SASlAF calls the This elevistes the need to have all users exit the SAS system above code with ""%inc deptcode{traffic)."" When the user in order to apply fixes or changes to application code. As is through editing the dataset, he is returned to his main an",Sugi-89-289 Dillingham.txt
"Changing PROC options or addHionai statements Changing the data The SASIGRAPH Annotate faCility allows the user to USing titles, footnotes, notes PROC GREPLAY can place multiple pictures on a enhance graphics created with SAS/GRAPH software. page This paper presents the basic concepts of the Annotate facility and introduces the audience to text placement, The Annotate fac~iIy allows the user to: symbol placement, line drawing, polygon construction, Place text anywhere on the screen map labeling, custom legends, and line types. Also Draw lines or other figures covered are SAS Institute provided annotation macros and advanced functions to allow complex labeling and Define polygons to fill and color Create custom 'free hand"" graphics freehand graphics. Place text or images on maps",Sugi-89-29 First.txt
"A System Approach tor the Storage and Retrieval of Inrormation in Clinical Trials Bee-Lien Chen em1 Patr1e'ia A. Majcb.er Hoechst-Rouasel Pharaeceuticais. Inc. Introduction POOl: Investigator information. An-efficient data strueture to store report description information on clinical studies has Key been developed at Hoechst-Roussel Pharmaceuti- Variable Data ll8IIIe field attribute Description cals, Inc. Information such ~ headings, titled, and format specifications can be handled as a PROJECT data dependent system. Such a structure has the Project number II Y PROTOCOL Protocol number tQl10wing advantages~ (8) the same information II Y INVEST is stored onlY at one place (b) only the n~es Investigator number II Y INVLAST sary pieces of intormation are stored (c) the Last name of the II C system that accesses the data is data indepen- investigator dent (d) the proc:e.s$ing and the outcome ot the roo.: system are data dependent (e) the descriptive Data record identification number inrormation ot the reports always matches the Key body of the report. Macros are provided descri- Variable Data name attribute bing the techniques that convert the information field Description into program code using the SAS® function SYMPUT PROJKEY and retrieve the information in macro variables Project code C Y using the SAS* function SYNGE!. of the 8 tudy ADMISS Number of the II II Description of the data structure admission record DOSAGE II Nwnber or the II Project information of clinical trials is dosage record divided into seVen major areas. The data for Number of the II OSPLASM N each area are stored in separate tables created plasma record and maintained by ISPF Dialog Management Servi- OSURIIIE Number of the- II II ces (ISPF/DHS). Table entries are retrieved urine record through their keys. A key is made up of one or more table variables and uniquely identifies 8 table entry. An utility in ISPF/DMS is used to POO;: Specifications of the- sample and assay create SAS® data sets from",Sugi-89-290 Chen Majcher.txt
"A SAse') Batch Program Tester using ISPF Jay A. Jaffe organizing and dC'lCU'Dentin,g any repetitive series tbreover, since the ""Tester"" of program runs. allows specification of several additional, .. ) Program Tester"" ~ The ""Handy runs on III-t preexisting data files (SAS format or external) ln8.inf:rsmes urder C6/MVS-TSO/ISPF. It preIBreS that the program may reference, and since the SAS jobs for batch subnission. and can both output and sequential docuuentation recording permanently record the output on-disk and keep a functions are optional, it may more generally be running chronological record of job :9ukmission, used as an easy program eubnitter for any and data files used. source files used. repetitive or related series of runs. Implemented as an ISPF dialog and. using the Written originally to help me debJih refine, ba.t.ch jo1::tstream. the ""Hardy SAS Program Tester"" and organize the scores of program examples used does not carry the overhead. of interactive SAS in my textbook about the base SAS software< 1) , and allows the user to move on to other tasks I've since applied the ""Tester"" to several of II;Y while the program is rurulin,g. Especially useful MVS/TSO SAS prograaming projects, with happy for testing SAS source code during development, results. it could be used for any repetitive program execution series. The system from the progt""8J'\llller' $. view consists two ISPF program of a driver TSO CLIST f The SAS Display Manager provides the- end-user ""skeletons"", and an ISPF panel definition. s. powerful methOO. of interacting with the SAS These are shown in Appendix 1. In the current System. Still. for many reasons (including both form. the system expects: some things: from the cost and resOtn'Ce limits) batch jobetream environment: (Il It must be executed from within rsPF t and the panel and skeletons must be processing is desired in many cases. Under OS/MVS t SAS jobs I:M.Y be 8Utmi t ted from aV$.ila.ble to the user' 9 ISPF session by the an online",Sugi-89-291 Jaffe.txt
"additional applications are set up when selections are made from the central This paper discusses integration of PCs menus. Each user has an individual menu and workstations into a SAS mainframe based computing environment. The charac- system Which can be modified to include direct access to often used applications teristics. components, and users of a as well as personal data 'and programs~ comprehensi ve SAS-based computing envi- If needed, many well-behaved non-SAS ronment are described. The appropriate roles for multiuser and single user com- facilities (including ISPF, TSO, or REXX puters are explored, along with issues of commands) can be selected from a SAS/AF portability, conversions and information menu, using the X statement. Upon exiting systems management. the called facility, the user is returned to SAS with macro variables and work files intact.",Sugi-89-292 Hutchison Wheatley.txt
"One Solution for Standardized Reporting and Easy Access to Complex Data Structures Using SAS® Macros by Paul OldenKamp Group Health Cooperative of Pugel Sound spouse's employer in addition to their own, and to Senior managemenl at Group Health Cooperative determine which record indicates the primary of Puget Sound was frustraled when they received reports from different sources that had coverage one must compare values in different observations. Inconsistent values. it'S a common complaint. To solve the prOblem a group called the Database Just documenting how to use the Membership and Development Task Force was formed to produce Billing SAS datasets and having the Information programming standards and to document definitions Center clients each code their own programs as of important measures used throughout the they had in the past would not work. It was just organization. It wasn't clear how the group could too unlikely that they would be able to write these do this. programs consistently and correctly. Something more would have to be done to insure that good At about the same time a new computer system to keep track of out customers(or members as they results could be produced. are referred to in a health maintenance organization that is also a consumer cooperative) What is the Solution? and to do most of our billing was coming on line. This would make counting customers much more difficult because the new system has a much more What needed to be done seemed straight· complex data structure than the old system. forward to me, The data structure was too Counts of customers are an important area where it complex~~make it simpler from the user's point 01 is difficult to achieve consistency. Many different view. There is a lack of standardization of departments produce counts for their own purposes concepts and measures--make one standardized and it is easy to have small variations in their way of computing these items so much easier than programs that result in sig",Sugi-89-293 OldenKamp.txt
"An Expert Systems Application for Selecting Statistical Techniques Ray Palmer. Institute for Health Promotion and Disease Prevention Research (IPR). University of Southern California Eric Yu Wang IPR. University of Southern California Oyde Dent IPR. University of Southern California mOSI, when the pIlUlet was unpolluted and heallhy · there was no such thing as the SAS® system. or an expen system for that matter. Yet the phenomena of Expen Systems is becoming one of the most potential growth area in computer applications. This is a branch of artificial intelligence that ranges in applications from geology. chemistry. and ABSTRAcr engineering to weather forecasting, investment ponfolios and psychological assessments (Edmunds. 1988). Yet the IPR-USC is a research institute that studies &he applications are unlimited. One need only to have a need. behavioral and sociological antecedents of disease. IPR-USC also implements and testS intervention programs designed to Essentially, an expcn system is a system that emulates a prevent the onset of disease as well as trains graduate and An cxpen system will -offer justifiable. human expert. post doctoral students. ""intelligent"" decisions using some kind of rule based system. With an ever increasing data base, managed locally by The process of building an expert system requires what is the SAS® system on a 386 based PC~Local Area Network known as knowledge engineering. which entails designing the system. the -demand for quick reliable interpretation of data software or programing existing software in which the end by non-expcns and those unfamiliar with the SAS system user win interact wilh. Inherent in this process are three has arisen. We have answered this need by developing an essential clement that 1 will explain in order (I) Expcn System designed around SASIAF®. The expertise (2) an inference engine and (3) a uset An cxpcn system is a computer based kno~kdge interface. domain that has the ability, through rule based proc",Sugi-89-294 Palmer Wang Dent.txt
"A META-DATABASE IMPLEMENTATION STRATEGY FOR DOCUMENTATION AND RETRlEVAL USING THE SAS' SYSTEM John Podgurski, University of Rochester screen data handling capabilities of SAS/AF and Introduction SAS/FSP software can make the documentation and retrieval system available to users who do Data about data (meta-data) is the subject of not have sophisticated programming skills. this paper. The lack of a means for creating meta-data and being efficient in its retrieval is Meta-data Creatjon seen as a problem. This paper is an attempt to bring together certain ideas about labeling and The beginning of the meta-data creation and documentation in order to identify the SAS retrieval process is with a codebook. Codebooks programming tools available to implement a are augmented record layouts about raw data meta-dalabase strategy for documentation and files. They contain information about variables retrieval. beyond the minimum needed to process raw data, The labeling information provides data The SAS* System makes available a wide variety processing decision makers with an of powerful programming tools. which can be understanding of the shorthand represented by combined to implement numerous problem variable names, solving strategies. These tools include labeling features. character string functions, SAS file manipulation, and user interface products, such Labeling information from codebooks can be incorporated into the directories of SAS datasets as SAS/FSP' and SASIAF·. This meta-database strategy is a synthesis of ideas for or dictionaries of other system files through the documentation and retrieval which can be use of programming statements. Means for efficiently creating SAS datasets from implemented due to the flexibility of these tools. codebooks will be discussed in some detail. Machine-readable codebooks are the primary No claim is made that this approach to creallng source of information about data. In a practical meta-data or its partial implementation will sense t",Sugi-89-295 Podgurski.txt
"em Modification Program/Extended is an IBM product designed 10 ins tali and modify Software distribution. target library members from the Functions are groups of related program products. But not all the software c(}me in SIMPlE SYSMODS. elements such as modules. source, and macros. SMP/E installable format. SAS makes the conversion of non correctivc user can install preventive, and SMPIE to SMPI£ illStaUatian easier. Many utility modification (0 the target and distribution librarics: Junctions that are needed for tile conversion art: SYSMODs are made up of MCS (Modification Control achieved through SAS code and PROC,'i. Statements). These control statements can be ++PUNCTION. ++PTF. ++USERMOD. ++VER. ++ICLIN. ++MOD. ++ZAP. ++SRC, ++MAC and so on. These may be 1. Introduction: headers \0 identify tile type of modific.uions, specify how the SYSMOD rela!es to other SYSMODs, module In any large in:;tallation there tarl he multiple IBM replacements. source and ma(,.'f(} replacements etc .· In Ihis contCK! SAS procedure SOURCE can be very mainframes and several software products at handy since it can print the contents of a library. or different versions and service levels. Manually managing and tracking the software al several levels process the directory of a library 10 be input for utility or other programs. route lhe members of a become more difficult as the sites become larger. Program I library to other program:;;, plint the nlphabeticat System Modification Extended (or SMPI",Sugi-89-296 Kanthan.txt
"FILE LOCKING FACILITY FOR SAS/SHARE® SOFTWARE BY Michael R. Gibson The Gates Rubber Company · ABSTRACf Are you using SAS/SHARE and the ""CDNFUCTlNG LOCK"" error message keeps bombing your batch jobs? Have you ever wanted exclusive control over datasets in your batch job? This paper will provide a method of locking datasets to gain that exclusive control when needed. The method uses a macro variable that is new to the SAS@ System version 5.18, but can be modified to run on any version. · INTRODUCTION At Gates in the Advertising Dept. we have a system that requires the user to submit a batch job for processing. The user, however, is still able to enter SAS/FSEDIT® on dataset(s) used in the batch job. If the user hawens to enter any dataset before the batch job can process it, the batch job gets the ""CDNFUCTING LOCK"" message and bombs. The macro described below is an attempt to lock all datasets used in the batch job so that NO user in interactive mode can access them. The secret behind this macro is the dataset READ password protection. Using the MODIFY statement of PROC DATASETS@, the macro changes the read password to LOCKED for datasets listed in the DSN parameter. · LOCKOUT USAGE There are five steps needed to use this method of locking files. t. Enter the macro code into your AUTOCALL®library or compile it before using. 2. Search your batch job for a list of ALL datasets you would like to lock and the libref of those datasets. You will needed to call the macro for each Iibref. 3. Call the macro at the top of your batch code to lock desired datasets. 1580  4. Add the datsset option READ=lOCKID to each referenoe to the locked datssets in the job. References will be those that read or write the datssets. Places to look are: DATAstep datsset names. SET, MERGE, and UPDATE statements. Any PROC statements that read or write. 5. Call the macro again at the bottom of the batch job using the UNlOCK=YES parameter to remove the READpassworo. This Is required to allow normal i",Sugi-89-297 Gibson.txt
"Downloading Code Today, laboratory instruments are being equip- Programs were the first to be transmitted from ped with personal computers for control and the mainframe to the PC using the FT/3270 file data acquisition. Data reduction once performed transfer method. by the mainframe eomputer is no~ being moved to the personal computer level for integration. A subdirectory for storing the programs. data sets and catalQgs was created with the follow~ This paper addresses procedures for downloading ing command. SAS* software, data sets and screen catalogs, It identifies the statements that need to be lID O:\BARS searched for, then modified or deleted. It identifies three main areas where code has been The JUMP key was pressed to aecess the main- replaced to take advantage of the enhanced frame and log on to the production ID. After features of the PC version. logging on, the JUMP key was again pressed and the following DOS command issued to tramsmit the SAS program file.",Sugi-89-298 Miller.txt
"An attempted ftmote submission without an active miCl'O~to~ A system Qf Screen Control Language (SeL) progra:rns. was hoat link opens the MICRO·TO~HOST window. The SAS® designed for the distribution and application of ~ sYltem system can distinguish an active link from an inactive one updates (ZAP's) via the micro-la-host link facility of SAS® as the M]CRO~'l'O~HOST window shows. The pl'ograml'Mr. Version 6.03. System Updates. pniodicaDy released by the Institute~ however, tannot make suc:h a test without opening that SAS are uploaded to. a tnainframe envi1'Onment window. It seems logical that an automatic maCN variable ~ith a description data Ht by the site representative. Usen should be available to test this condition so that greater are then able to download and apply the System Updates from a friendly. SASlAF® environment, control can be exercised if the user attempts a remote submisa;on without an active link. As this is not the ease we propose that the SAS Institute include -such a variable in a The paper highHghts the versatility of SeL and the relative future maintenance release. Another alternative for ease with which it can be integrated with other elements of the assessing a user's micro4o~host link status is scanning the SASt> system. The paper also suggest. improvementa: when SAS® Jog. weaknesses were encountered. The method of reading the SAS®log into a data set and then",Sugi-89-299 Brown.txt
"TAKING THE BEST ADVANTAGE OF SAS/GRAPH SOFTWARE'S GEOGRAPHIC INFORMATION SYSTEM FEATURES Invited Paper SAS User's Group Interrultionall4, San Francisco, California, April1J, 1989 fusented by J. Jacob Wind American Man.gement Systems Inc. Illitrodu~tioD: ""An' yo,. uperieftCedT HtI'R you ever been Experienced!"" -- J. HUIdrix ad_ OJIOLIN2W"",lUI PCH-LIJ11DH POTEHlIAL This paper is directed at ~perienced SAS/GRAPH .um HAL-...oRI! CQUN'fV, MARYLAN) who wish to BALTIIoIIOI'tI!!' aTY UlieflI of SASJQRAPIr. powed""1 mopping featlJru. We _ IWl COvet geographic fepTCsentatiou issues; various map type8 you can produce using SAS,lGRAPH such as area maps. locatioo maps. 8Ild maps.; problems you11 encounter when yOIJ ~ SASIGRAPH -~~-li~------- COIllOllI' I.'i' ~df,.. ·· lllUiTIC ma:pping tools; and many tricks of the 'tfolde you11 need to know. f-~,,,*Ht;1i;~r;-~~!~ ~',I\!oI!.I..J.jJUwill~ II '99. Geoggpbic ]nf~ System technology (GIS) is a ~ new focus Ijl :hlli!J(l,,-!;Ii~jn 101-Ul ia tbe enviroamental research community and eisewhere. SAS/GRAPl{ .~ L.,~ 1<~[,1 1j)f-'1I~ Ro1.' 'lJf.""ti~i V I. 133 software is a key 1001 to manage; and display ,geographic data. '-~ IUIl~o~ s<lIiJl 101-111 .\. f .....lIlIlti .... e l'~-Iro. :II.I~'""-III 'd2-·11~ 8 li.d.1 CIo, Contact the aulhor for conSullaliOD at American Management Systems. ~...!E.!.!!~~_E'2!~!'!:!...m.:::m ITI7 North Kent Street, AIIi_n, V~ginia 22209 (103) 841-6974_ Is .bc SAS S,.tem a GIS? ""If il looks liM j2 dd.fDtd U qlUJcks liie a duck, it's a duck_"" -- R.DaTman SAS Sysrem rools. fulrlll many GIS crirerla: Store -digitized geographic data (see eqmple 10 the right) o Pmduce maps and other geographic represenlatU.m$ Q Support digitizing new data o o Overlay maps of similar areas a GIS? Lotus 1-2-3 can draw maps as plets without Bbl is SAS mill,. symbols, but is 1-2-3 · GIS? No. Like 1-2-3, SAS· lock, two other imponant GIS feahlre5. SAS can'e o Edit a file of geographic data -simply by ""clickillg· a Une segment 01 point OI! .1",Sugi-89-30 Wind.txt
"This paper traces the steps necessary to convert a Release 5.18 SAS/AF"" application to Release 6.03 on the PC. The discussion includes the steps to dOwnlOad the application, compile PROGRAM screens, and make modifications to assure proper !~~~llt ~ SAS 'htJ l ·.hlH1 execution under Release 6.03. This paper also suggests ways S~ltct · SH d.t · · et ~l.t 1ot. to take full advantage of the powerful new language available with COfllP~H ~tHl$tl<"" eO\!<l[S {o"",~,ut~ Ir~qufru:r tull-screen products under Version 6. screen control language {reau wr ~hut I {Sell· Tutcnal hI!",Sugi-89-300 Horwitz.txt
"em based on previous The introduction of Screen Control responses, so the editor can verify this Language (SeL) with version 6.03 provides is how the interview proceeded. Third, new measures of control for those if it is necessary to change previous developing data entry systems with PROC responses, the backing up process should SCL can be used to check for FSEDIT. be done in. a way that does not allow specific values during data entry, rather than checking only within a given range. other inconsistencies into the data ~ The final product should be an observation Cursor control under SCL can provide for whose data values follow all the coding the conditional skipping of items, rather and skip rules specified in the than advancing one item at a time. interview, so that no additional data Values can be crosschecked for cleaning is required. consistency as they are entered, rather than waiting to find inconsistencies later in a separate DATA step. SCREEN DEVELOPMENT Customized messages can provide Screen development under FSEDIT combines instructions for specific situations, flexibility with ease of use. In screen rather than relying on standard messages modification mode, text can be typed provided by the procedure. exactly as it will appear when the Such tools are essential in developing appl ication is run. By turning NUMBER a data entry system for an interview ON in the editor, the developer can see how many rows of text will constitute one containing multiple skip patterns",Sugi-89-301 McEvoy.txt
"A In\TA MAHAGElfiOO' SYSTEH FOR RElIOTI! lIEDlCAL STlIDIES USIlIG TIlE SAS- BY'TEH o. Dwayne D. Oland, Timothy L. Cannon, David M. Warren, and Cene Nelson u.s. Army Medical Resear~h Institute of Infectious Diseases, fort Detrick, Frederick, MD 21101-5011 ASSTRACT The SAS® system is an integral part of an automated data management system currently being utilized to conduct clinical trials in foreign eountries. The system, ~oosisting of a portable microcomputer, an optical mark reader (OHa) and printer utilizes the SAS® system and dBASE III®+ to control the entry, fflaoagement, analysis and graphing of medical research data. The SAS® system provides statistical analysis, graphics, the abililY to perform on-site ra~domization, as well as an interface between the OMR and dBASE 1116+. The wide variety of tools offered by the SAS® system give researchers and statisticians the capability to perform more extensive testing~ monitoring and analysis of data at the actual site of the study. Figure 1: Data Management System BACKGltOlJlID optical mark forms which are scored with a standard #2 pencil. Forms are designed so they Effective collection, verification~ analysis and closely approximate the paper forms that are management of medical research data in foreign currently in use at the remote site (see Figure remote sites create a unique challenge far 2). The content and number of forms vary for members of the research community. In the past, each study which necessitates creating unique researchers collected data at remote sites Qn decoding programs for each form. This process paper forms and returned them to a central can be tedious and require large amounts of time com~u~er facility where the data was keypunched, to complete. In an effort to alleviate these ver1f1ed t and analyzed. More recently, problems, generalized template modules were researchers have deployed microcomputer systems written in the SAS® language to decode each of at field site~ to enhance the convenienc",Sugi-89-302 Oland Cannon Warren Nelson.txt
"the DATA step language is not This paper presents an ov~tview of the internals of the LL(l), but this is overcome by performing lookahead Version 6 DATA stept deseribing the various phases of to disambiguate certain non LL(l) constructs. the DATA step: compilation, resolution and code gen- eration, and runtime execution. The <:ompiler trans- Semantic analysis determines the meaning of the strut- ture based upon the context in which vatiables are forms the DATA step SAS sonrce code into an inter- mediate representation 'Of the sourcel along with data defined, input SAS data set information 1 external file tables describing the varia hIes defined, data set usage 1 information) etc. During the syntactic and semantic external file llsage} and other information detailing the analysis processing) data table information is created and/or updated and an intermediate (,ode representa- attributes of the DATA step program. The 'resolution and code generation phase operates OR the intermedi- tion is generated. The intermediate code represents. the ate representation of the DATA step program and the structure and meaning of the original source code. The data. tabli:s to resolve the types, attributes, and storage compiler performs optimizations upon the intennedi- requirements of variahles 1 to allocate da.ta. areas} and to ate code that is generated, reducing the overall size of the intermediate code used by later phases and also de- emit maehine code for each of the host environments. T",Sugi-89-303 Polzin.txt
"For example, the statement below allows both the ? to be used as delimiters. Reducing the amount of time and disk space required to execute program.s on the SASe System for Personal infile inl dIm:;:;'·:; Computers is a concern for aU involved. Various methods for reducing processing time, programming time. and hard Another method is to use the values from a character disk usage by using some of the new enhancements in variable as delimiters: Version 6.03 will be discussed. infile inl d1m=salesman; This paper begins with the",Sugi-89-304 Knox.txt
"BENCHMARKING THE SAS® SYSTEM, RELEASE 6.03 C. Brian Towey, Glaxo Inc. Like any good software product. the SAS System has The result is that PC buyers must make hard choices based many different uses. Each SAS application makes charac~ on price, perfonnance. and obsolescence rates, teristic demands on the supponing hardware. and a given One of the most important distinctions between PS/2 personal computer platfonn may be optimal for some appli- ~ations. but poor for others. Hardware upgrades may not architecture and classic PC design is in the system back- plane, or ""bus."" This is the master circuit board that con- Improve overall perfonnance On key applications; in fact, nects all the components in the PC and routes information the new hardware may be slower than the old. Application between them. Normally the sort of hardware~level detail benchmarks are the only reliable tool to help the computing that users could comfortably ignore, the PC bus has become manager decide what works and what doesn 'r. a major selling point-{)n both sides. The PS/2 line (Models 50 and above) is built around what IBM calls the ""Micro Background ChanneL"" This new bus arrangement does mote than change the connection for plug-in cards. Among the largely Some users: reJy on SAS software for intensive calcula- unexploited benefits are: the potential for co-processors to tions. as in time series analysis or three-dimensional graph- share the bus. reducing the workJond on the CPU; self- ics. For these users, a fast processor and quick memory are a must; a computer can't be too fast. Personal computers configuring add-in cards. a feature that eliminates the need for setting tiny switChes; and software-controlled priority (PCs) are within the acceptable speed range. but JUSt barely.' and only because they are devoted to just one user. and arbitration of devices sharing the bus. In contrast. the classic bus offers a huge supply of peripheral devices at low For users who run fulJ~screen applicat",Sugi-89-305 Towey.txt
"security of data - A PC not con- Abstract nected to a network or communications link is relatively safe against intruders. Data on disks After Version 6 of the SAS system was released can be stored in a safe. Tempest certified PC's for execution on the PC platform, we began a migration even provide protection aga.nst passive elec- of our the SAS System processing from centralized tronic surveillance. shared computers onto PCs 00 each staff member's Availability of Version 6 features - Since the PC desk. A number of deficiencies of the combined was the first platform for the Version 6 imple- PC/shared computer environment were identified. mentation, running there allowed users to avail During the past year we have begun to utilize the SAS themselves of the Version 6 unique features. System running under UNIX on a Sun Workstation as a shared compnter. The Sun has been integrated into a Friendly inted'ace . In addition to Version 6 features campus wide network and plays a critical role in sup- like Windows, the PC offers an expanded key- portmg our collaborative research because of the ease board, fast screen writing speed and a more with whic? it interconnects with other comp~ter sys- familiar environment for users already familiar tems. This move to the UNIX based workstatIOn envi- with other PC applications. ronment has been a productive experience and appears Our paper made tbe distinction between a per- tq position us well for the future. sonal computer environment where e",Sugi-89-306 Miller.txt
"Network options running SAS under HP-UX. RFA does not support: Douglas R. Austin ehgrp chown chroot docopy Isck mount Hewlett-Packard NFT uses the command dscopy to allow the user to send Objec1ives and receive files f-rom a non-UNIX system. NFT currently The following discussion is designed to give the SAS supports access to HP3000 Systems and DEC systems system user under HP·UX a technical overview of the running VMS. Direct access by SAS users to their files cn the VMS system should increase productivity by the user network environment that is available. This paper is not limiled to networks that include only HP-UX systems. It will and their machines. include services to connect to DOS systems, VMS sys- tems. OS syslems. VM systems. and other UNIX systems. SNA Products ARPA/Berkeley The HP SNA 3270 products allow varied levels of commu- nication between HP-UX systems and IBM systems run- as ARPA/Berkeley services are a combination of services ning and VM. There are five different products which range from IBM 3274 cluster controller emulation to. $ys~ from Advanced Research Projects Agency (ARPA) and the University of California Berkeley {UCB). ARPA services are terns which not only emulate, but allow direct file transfers for non-Unix environments in addition to HP-UX, and other and multiple sessions. These five products are: UNIX environments. UCB services are available for HP-UX and other UNIX systems. SNALink - Series 300 SNA3270 Series 300 ARPA Berkeley Gateway/SNALink - Series 300 Gateway/SNA3270 - Series 300 ftp rep Gateway/SNA3270 - Series 800 telnet flogin remsh Use of these services will allow the SAS user to migrate rsh (DOS) between their large IBM system and the HP-UX system, Applications which were written under as and eMS can be These commands fall into four areas. transported to HP-UX to take full advantage of the Version 6 enhancements. 1, remote logging' a. telnet Examples b. rlogin ARPA/Berkeley 2. file transfers between systems: telnet: telne",Sugi-89-307 Austin.txt
"Systenl with Version 6 8uppmt for workstations and personal computers is an excellent tool for distributed processing in a multivendor environment. With workstations and personal computers as nodes in a network, efficiencies can be gained by sharing data among users as well as processing SAS jobs on various nodes. This paper describes SAS software applications for submitting, routing, and controlling interactive SAS applications in a heterogenous network environment. DEFINITIONS While there are a number of different ways to describe what constitutes a network) this paper uses the traditional definition of a local area network (LAN). A local area network covers a limited geographical area where every -node on the network <::an <::ommumcate witll every other node requiring no central node or processor. (1) These nodes can be personal computers l workstations, minicomp-utersl and mainframes. Two network applications that provide transport services for SAS software will be explored in this paper. They are NFS and FTP. Both of these applications use the TCP lIP standard. TCP lIP stands for Transmission Communication Protocol/Internet Protocol. The name is derived from two standards originally designed by the Defense Advanced Projects Research Agency to interconnect the pleth.ora of different eomputer systerns owned by the United States government. TCP lIP has hecome a widely adopted networking standard and is available commercially from a number of different vendors. TCP lIP makes",Sugi-89-308 Betancourt.txt
"SAS System has arrived in the UNIX@ and derivative operating system environments. This arrival brings the computing, analysis, data management, and report writing capabililties SAS users expect, plus some added features that take advantage of the power of UNIX and derivative operating systems. This paper explores these new features. Introduction The SAS System under UNIX has expanded to incorporate many of the features of the UNIX operating system. Now} from within the SAS session! you can use the pipe device to send and receive information between a SAS session and operating system -commands. Also, you can instruct your SAS session to direct its I/O ·to the UNIX standard 1/0 files. These new features allow the SAS USel to easily incorporate output from most of the UNIX commands into a SAS session, PIPES The UNIX pipe facility funnels the standard output of one command to the standard input of another command. Example The UNIX command, Is) lists (to standard output) the names of the files in a specified directory. To count the number of lines in a file, use the UNIX eOlUlUand we -l. $ Is lists the names of files found in the current directory. $' we -1 temp counts the number of lines in the file temp. I ) facility. Let's combine the two commands with the UNIX pipe ( I we Is -1 sends the output of the Is command (the list of filenames) as input to the we -I command. We-I counts the number of filenames from the is· command and prints the answer to standard output) The SAS Syste",Sugi-89-309 Johnson.txt
"ion 6_06 macro faCility offef'll ""'. the SAS·System advances to meet ~ser needs and f~t~re the full functionality 01 the Version 5 macro facility in addition to jirections ·of the software industry. Version 6 of the macro facility "" the enhancements of the Version 6_03 macro facility to userS of 'Tlakes user-oriented features and enhancements available to ~.ers of all operating system environments, Mainframe users will all operating systems. appreciate the new debugging features and macro windows. Microcomputer users wi. enjoy the autoeall facility for establish- Facll~ The ....utocall for· Source I.evet Macro Libra"""" ing source level macro libraries. Minicomputer -users .wiD find applications much easier to develop w~h the full macro facinty The autocall facility allows you to store the S<JUrce code for your available to them. macro definitions in a file. associate that lile with the SAS s ..ssion or job. and then execute macros on a 'demand' basis withOut hav- Using spec~1c examples. the paper illustrates Ihe new features ing to include their source in your session or program. Consider and functionality aVallabie on all operating syslems. Users of the that you may have.an application. possibly menu driven. thai may Version 5 Syslem see a pnaviewof what Is ahead. Version 6 users execute from one to twenty macros based on user input or other see new feature. and learn new techniques for using the features implicit infonmatlo"". Before the autocall facility was available. it al",Sugi-89-31 Patrick.txt
"The SAS System for PCs as a Cost Savings and Development Tool for the Mainframe Stan Geiger Variable Annuity Life Insurance Company Introduction 1. The flat ASCII file takes up less room on the PC and is a smaller file,thereby CPU time is saved because SAS With the development of higher speed microprocessors is not invoked to read data. and large capacity hard disk drives the SAS system for 2. The dataset method alleviates the need to read a flat personal computers has become a powerful tool for infonna- file into a SAS dataset on the PC. tion gathering and reporting. Many applications written for lf the extracted dataset is small, which is usually the the mainframe can be transported to the PC environment. case in our testing, the SAS dataset method is better. The However. there remain certain applications which until microcomputers can process as fast as a mainframe, must flat file extraction provides a cost savings, by decreasing CPU time. This flat file extraction method is used if a large remain on a mainframe. The processing of targe datasets is dataset is required. still not time efficient for the microcomputer environment and must be run in the mainframe environment. Much of the 'There are several ways to decrease download time. One testing and development can be done using 8AS 6.03, way is to change in the micro-to-host signon script the thereby, saving time and money on the mainframe. This MAXI option to: MAXI 1024 This increases the size of the download packet from the paper deals with V ALIC' s mainframe applications in a PC default value of 512 bytes to 1024 bytes. This will increase environment. This use of SAS 6.03 saves both cost and time in processing. Areas to be discussed include: speed, but. you must be careful no.t to make the value too large because data can be lost in transfer. By experimenting · Extraction and downloading of test data. with the size of the packet you can detennine what is the · Editing data for efficient and thorough testing",Sugi-89-310 Geiger.txt
"AUTOMATING THE PROCESS OF DOWNLOADING SAS DATA SETS TO THE PC Bruce Nawrocki, GE Capital Mortgage Insurance Introduction which incorporates the SAS macro language. Program listings are included at the end of this The [nfonn.tion Center at GE Capital Mortgage paper. Insurance supports about 50 people who use SAS sofnvare on an IBM 3084 mainframe and personal Batch Flies computers~ Most people have an IRMA card and terminal emulation softw'are in their PC. These SAS The AUTOEXEC.BAT file on the user's PC was users often want to download small SAS data sets modified to automatically load the tenrunal emulation from the mainframe to their PC. Once the data is on software in resident mode. In our case, we use an their PC in a SAS data set, they may also want to IRMA card and emulation software, but this could move the data into other software packages, such as work with any terminal emulation software. We did a spreadsheet or database, for further data have to be careful about memory limitations, manipulation. however. Resident software may not leave enough memoty for SAS software on the PC to work The SAS micro·to·host link gives the SAS user properly. We were lucky that the IRMA resident the ability to download mainframe data to the PC. software could co·exist with SAS software within the Although the downloading procedure is fairly 640K memory limitation. Other emulation software, straightforward, it involves many steps. Downloading such as IBM's, may require you to have a PC with requires that the user be familiar with a variety of Expanded Memory. mainframe and PC software, not to mention all the different error messages they may see. fn addition, A menu system was set up with batch files that most PC users don't download data very often .~ would change the directory to the correct one and perhaps once or twice a month. For someone who then run the SAS software. An AUTOEXEC.SAS file downloads data On a regular but infrequent basis, was installed in that directoty w",Sugi-89-311 Nawrocki.txt
"UP, UP AND AWAY WITH PC UPLOAD Pater Dillingham and Michael Gibson The Gates Rubber Company Proc Upload is one of the SAS'"" system's most useful and redirecting the output to a file ""docuscan.dir"" in the currently active sutrdirectory. This provides us automatically with a powerful procs for personal computers, Wnh Proc Upload, multiple external files, for example, can be uploaded in a list of the file names to be uploaded, which will be accessed single step to a mainframe partitioned data set for inclusion by the naxt block of code, and editing in SASlFSf'® Fsletter, or simply as a backup, The data _null_ step reads ""docuscan,dir"" as an external Recently at Gates, we decided that several of our product file, Since the DOS ""dir"" command puts out several lines 01 text that we do not want - ''\A:l1ume ,,;' ""Directory"",;' ""166 catalogs should be computerized which previously had Files.,,;' etc. - the variable ""ext"" is user to check to see been produced by hand, and that the data should reside if the input line contains a valid file name, The other two on our mainframe, These catalogs were text intensive wrth variables created with each iteration of the data step, ""file"" a great deal of technical matter, Rather than key the text by hand. we opted to have the textual matter optically and ""ifile': are used to create respactively the pds member scanned. This was accomplished by an outside supplier name for a TSO allocate statement and the ""infile"" using a KurzweillXerox 4000 ICR scanner. The result was expression for proc upload, This is accomplished with the a number of ,floppy disks containing mu~iple ASCII text files two ""put"" statements shown. The result is a text file with names such as ""Pagel011lsd' for a text page from ""Up2m!"" 01 executable SAS system statements such as the a major catalog, and ""Supp4Zasc"" for a page from a following, which are ""included"" and ""remole submitted"" supplement to lhe mainframe with a ""dm"" command: The first step in getting the floppy di",Sugi-89-312 Dillingham Gibson.txt
"defines a subset of data from the table described by the master descriptor file. You choose this subset by This paper describes an application that integrates new features selecting particular columns and specifying the of Release 6.06 SAS' software. Access to database tables is dis- subseHing criteria that the data must meet. cussed, focusing on the ACCESS procedure. Combining data from database tables with SAS data sats by using the Sal proce~ SubdescriptOf files provide a security feature by allowing some dure is then highlighted. The interactive report writer, the columns to be ~jnvi$ibie. ~ if certain co1umns are not defined in the REPORT procedure. is discussed. showing how data can be subdescriptor. the user has no way of knowing they exist Several grouped and analyzed in various ways. A user application is then subdescriptOfs can be defined for each master descriptor file, presented using screen control language (Sel). an enhancement providing a way to give different users different columns to to SAS/Af"" and SAS/FSP' software. access.",Sugi-89-313 Sarisky McIntyre Roach.txt
"Keeping Data Integrity In Large Corporations _ Martin J. Godkin, Electronic Data Systems ---.. - -_ .... INTR~O~DUC~noN~~.~__~~~~ I .. _ .. .c..-;\ ... Many large corporations can be ol'lJllnlzed Into t- / ,- two categorIeS. People providing me cenlratlzed ,r... / support of me corporation as a whole, me SAIl' I corporate &tall, and the people who concentrate ........ ""'- on me dlfler_ products that create tne going concern, or me divisional &tails. The corporate 1_ employ_ ... me organization as a Whole, Lg] while me divisional amplov- are concentrating ,;;::-r--:"""" on melr particular area and product. In my case, I work with me corporate ataft, and one of the functions we provide to the divisional and CGijiiii- . corporate organtzatlon Is to process survey data · SAl! ea..o- ,./ DalaHt ""'. CofporaM that IS COlleCted. Out job Is to organize and - -- """""". .'"" _... ':"" u..r. . process this data Into a SASe dataset, to be .' , 1 .,..,. accessed by elteryone In the corporation. The OMsion. u- following paper describes how our business p _ _ raw data files Into production SASe ............. to datas_, and then deals with me prOblem 01 usera wanting away to use data from the dataset in PC applications, without having to write SASe fiQIft 1,~....,.~ ..... code. We will describe the process, tne problem InCI IN COlUiDnt twougt\out tie COIpCIf~ that evolved, and tha SASe utility program used management along with supporting recommendations as a solution. from the analysts. The idea 01 having one group organize, clean, and produce the SAS® dataset for everyone in the corporation ensures data integrity It is the policy of the corporate staff programmers to throughOut the corporation at all levels. (Seelig. 1). process marketing survey data and organize this raw data into a SAS® dataset. The raw data file consists 01 THE PROBLEM alphanumeric characters that represent respondents' answers to a survey. When processing large, detailed During the last few years with the emergence",Sugi-89-314 Godkin.txt
"The SAS language was already in use at Lockheed when the system Lockheed Engineering and Mana- development started. Programmers gement Services Company (Lockheed- EMSCO) is under contract with the and scientists had been using the language because of its powerful and Environment Protection Agency (EPA) to provide data verification for easy-to-use data manipulation and statistical capabilities. portions of the EPA - National Acid precipitation Assessment Program. This work involves Quality Assurance Although numerous SAS applica- / Quality Control (QA/QC) of data tions were developed, they were not from different laboratories. integrated into a single system. Originally the process was performed When it was decided that a system using a number of computer programs, should be developed, the SAS lan- as well as some manual operations. guage was considered at first for the following reasons: using SAS* products, a system has been developed to automate most SAS products are capable of o of the process. The system allows processing a large number of users to create, modify, and verify complex records. acid deposition survey data. This system has been used successfully, o The Fourth generation language and because of its general struc- features of SAS products allow ture, can be adapted to future sur- programmers to enter pseudo- veys. code in many instances. This means more time is spent to",Sugi-89-315 Lau Silva.txt
"ersity School of Medicine DATA QUALITY CONTROL FORMS ABSTRACT This paper describes the Data Quality Upon receipt of a batch of data forms, Control Reporting System for a multisite receipt control information is entered clinical trial using paper data collection into a forms inventory file of the main- frame computer (sea Constantine, et al., forms. The system beqins with a Data Quality Control Form (DQCF) completed by 1987). This file consists of a record for Data control Technicians as they identify every form completed on every infant. potential problems with the data 001- Each record consists of fields for the ~ection forms upon receipt. The DQCFs are infant identification number, form number, entered into a microcomputer dBASE III* date form completed, date form received, database before they are sent to the sites and some special. status codes. for resolution. After a site responds, the resolution is entered into the DQCF After the appropriate data have been database~ Using SAS**I the dBASE I I I entered into the forms inventory file, database and mainframe forms inventory Data control Technicians review each form file are integrated and a variety of re- according to a form-specific list of ports are produced. The reports are sent visual check specifications. Whenever a to the sites as part of a comprehensive problem or error is detected, the Data feedback system to monitor and reduce data Control Technioian initiates a Data collection errors~ Data collected over a Quali",Sugi-89-316 LeTendre Shing.txt
"First Place Best Presentation of Data - Color Richard Baumann Networks and Information Services ARGO The accompanying SAS/GRAPH output is generated each week in the corporate telecommunications department at ARCO, a major oil company based in Los Angeles, California. The purpose of the graph is to provide a quick means of assessing the activity on each of the telephone lines associated with the corporate modem pool. The modem pool is a shared resource which is accessed by several hundred personal computer users in the building. currentlYt the modem pool consists of fifteen phone lines for all users. The graph depicts modem calls as bars of color overlaying the time lines corresponding to each of the several modems each day of the week. To the left of each modem line is the five-digit telephone extension assigned to that Data calls that are placed over the company's own network modem. (ARConet) are represented in green, and those that go out over the public telephone network (accessed b¥ dialing 9 first from the company telephone system) are shown 1n red. The graph permits ra~id detection of two types of problems -- first, that a modem 1S failing. In this case, it will show no activity from the time of failure onwards4 The second type of problem is simply traffic congestion. The graph enables a quiCk assessment of the number of modem lines that are in use at any one time. As this number begins to approach the number of lines that are available, the graph shows parallel activity bars on all modem lines within the day's grouping for that point in time, and the indication is thereby made by the graph that the modem pool should be increased in number of modems. The sample chart was created on a SElKO Instruments OSCAN laser hardcopier with a Lasergraphics interface. Each week's chart generated on this device is examined at the weekly modem pool management ~eetinq so that through SAS/GRAPH, the group is able to stay on top of modem problems and pool capacity management.",Sugi-89-317 Baumann.txt
"First Place Best Presentation of Data - Monochrome Daily Perlormance Report for Tuesday, February 14, 1989 Kaison Yen Blue Cross and Blue Shield of the National Capitol Area This graphic report was generated from a compiled multiple system data source; SMF t RMF f TSO/MON, and CICS monitor. It is a daily report which is used by our menagement to see how the data center is doing overall. It is important to senior management that this is a simple one-page (two- small pages) This report can only be compiled graphically with report~ the use of SAS language. The M.onitor YP1~D for CICS YP13SASl YP13SAS2 Graphs Graphs Replay Generator Daily SMF Performance YP12D RMF Report TSO/MON 1686  DAILY PERFORMANCE REPORT FOR TUESDAY, FEBRUARY 14, 1989 Z O N E - l : 06:00e.rTl - 16:00pn""l ZONE-2: 16:00prn. - Ofl:OOnr.n. ."" CICS STATISTICS SYSTEM TRANSACTIONS AVERAGE SERV- MINS AVA I L- DOwn RESPONSE ABILITY ABILITY lOa 24089 0.55 0 ATMS 100 100 DISOSS 100 57£37 0.33 0 Blue Cross 228792 lOa 100 0 O. 15 NOH""-FEP laO F£P 544306 100 0.22 0 Blue Shield lOa laO 0 0.15 FLExx 4 328836 0 0.50 100 FLEXX 8 73164 100 of thf:: Notl0nol C.:Jpit.:J1 Area 66757 laO 0 100 0.49 FLExx 9 FLExX A 0 54 88517 100 0 100 CPU UTILIZATION FLExx B lOa lOa 20895 0.07 0 a FL(XX C laO 27657 100 0.26 laO TOR 0 15716·42 0.72 100 SYSTEM lONE -\ ZONE-2 STATISTICS TSO TOTAL RESPONSE SHORT ZONE MEDIUM LONG AVERAGE MAXIMUM ALL TRANS RESPONSE RESPONSE RESPONSE USERS TRANS USERS CICS 645 16.7 ZONE-l 251328 0.46 0.07 0.23 103 140 3.29 ~ 74.8 T50 39.0 0.31 ZONE-2 53671 7B a> 0.16 2.09 0.Q4 12 Q) --J BATCH STATISTICS 20NE-1 ZON£:~· J08 ZONE-2 201'1E- ) 1 TOTAL a EXEC TIME T I ME !NPUr J08S CLASS JOBS JOBS 464 A 0;02:29 0:00.04 594 130 0:00'04 0;05:54 44 B 45 I 0:00.34 0:05.54 C ~1 256 6 325 0:38:1.3 238 243 0; 0 l ' 30 U 0 I. I I F I I "" 0:00:00 G 4 12 0;00.0.3 0:00:06 5 '1 69 M 0 0:29:57 38 43 5 0;00:21 p I I 0:08:26 ::;1 0;06:01 18 S 49 17 I 0:00.44 201 0: 10.05 T 30 4:0·~:4.3 10 0: 0 1: 02 2I U 31 v 1I 1I 2 W 2 "" 0 09 4",Sugi-89-318 Yen.txt
"First Place Most Creative Use of the Software - Color Red Run Watershed Future Land Use Master Plan SAS/GRAPH' Mark T. Stetz EA Engineering, Science, and TechnOlogy, Inc. The SAS G~aph featured represents one of several figures compiled for an environmental assessment report of the Red Run Vater Shed prepared by EA Engineering, Science, and Tecbnology,Inc. for the Baltimore County Department of Public Yorks. Through the USe of five key X,Y coordinates included in the map data sets, all figures were produced using essentially the same simple program. Initially, an arbitrary, yet easily definable point on most map sources (based on longitude and latitude) near the lover left corner of the vater shed boundary vas chosen as a (0,0) reference point. All map sources used were digitized relative to the scale of (1 inch _ 10 arbitrary map units _ 200 feet] for consistency and ease ~f editing. The water shed boundary, str~am system, and major roads in and around the area t were digitized from county blueprints (the vater shed extended over 19 separate blueprints) using an Altek AC 90 Digitizer and an interactive FORTRAN program vhicb created an ASCII flat file on the VAX 11/785 containing a pen up/dovn code and the X,Y coordinates on each record. These files were then read into permanent SAS annotate data sets with the pen up/do,"",n c.odes converted to the annotate MOVE/DRAY functions and XSYS,YSYS values of '2'. The border around the figures served the dual purpose as a border and more importantly as the referencing coordinate system for the annotate data. Using the five border coordinates (the fifth coordinat~ to close the rectangle) as the initial map data set, base maps using the annotate information were produced on vhich, for some of the figurest the scientists could hand draw information to be presented in the report. These base maps, as veIl as the other map sources used, were digitized using a similar FORTRAN program which also output a user- specified integer vari",Sugi-89-319 Stetz.txt
"""TWO OR THREE NEAT THINGS YOU CAN DO WITH SAS-SOFTWARE"" Frederick: Pratte.-, Abt AS'5ociates Inc. By almost any standards,. the SASti system can be This program was designed for test considered a Fourth Generation Language. 4GLs, purposesi but it demonstrates a typical enough as they are usually termed, free the programmer kind of i;lpplicatiOli. The inltial data step reads in from dependence on detailed pl""ocedura£ a set of variables; for testing purposes, the algorithms and from complex data typing and program uses card input. Figures '2 and 3 show the structures. Instead, they substitute modular input and output data sets~ The body of the bulldlng blocks and data dictionaries that allow for program takes place in Data step ""TWO.· The more straightfol""ward and hopefully less e.-:ror function of this program is simply to compute the prone code.. percentage change between current the observation and the previous observation. The One of ""the a.nnoylog requirements of third array ""\In contains the 26 variables on which we genel'""ation programming languages is the necessity wish to compute percentage changes. Array nL n to specify in advance, at compile time, the size of holds the 26 values of previous observations; all the arrays or lists that will be used in the notice in statement 25 that the aLa array nee-d's to pl""ogram.. This is also true for the base version of be r~tained because otherwise it will be reset to 5AS. This constraint places a very real limitation miSSing each time the SET statement is on the flexibility of the code developed. The executed.. The ""P"" arrc~.y at line 26 holds the difference between CQmputers and living computed percentage changes. The loop at intelligences is that (ideaHy) the latter shpuld be statements 21 through 24 repeats the computation able to modify their behavior to accommodate c;lf the 26 percentage change variables, which are changes in external circumstances, while the equal to 100 times the difference between the former a",Sugi-89-32 Pratter.txt
"First Place Most Creative Use of the Software - Monochrome Leslie Wor! National Demographics & Lifestyles Within our corporation there is a great deal of use of julian dates. We needed to see a whole year's worth of dates on one page. We were able to use PROC CALENDP.R and shrink all of the twelve graphics onto one page but the numbers became. too small to read (see additional .graphic}. By creating a custom calendar, different fonts and sizes of text allowed a much more readable graphic to be produced. An added benefit was the highli9hting of company celebrated holidays. It has become a popular calendar for all computer users within our corporation. The program consists of a FORMAT statement for the annual holidays, a data step for the calendar grid and a main macro which produces annotate data sets for each month, sets together the two data sets and creates twelve monthly graphics in an output graphic Then using PROC GREPLAY and a previously designed library. template, all twelve graphics are placed on one page. 1. For the FORMAT statement, each holiday is included in yyddd format to produce a formatted value of one to signal the program that a holiday is being plotted. 2. The gridplot data set consists of a CARDS statement and lines of input to produce an annotate data set of the month grid and the days of the week. 3. The OPUT macro is called from within the main macro and outputs observations to the MNTH annotate data set. The main macro is called ~/i th one parameter, the year in 4. .. yy format. It then calculates the julian day to start with for the month and determines which day of the week to start on. The month header is output and beginnin9 values for the y coordinate is set. Then it loops through the rest of the days of the month and outputs two labels for each day. One for the day and one for the julian day. It highlights the box in grey if a holiday is encountered.. One data set is produced for each month and then appended together with the GRID data",Sugi-89-320 Worf.txt
"a percent sign (%) or ampersand (&), it passes control !o the macro processor to see if it can be resolved ""The internction between SAS macro mde and ~J.rogrnm ito SAS stateDl!'nts. or POrtiOIlli of SAS statements. statements makes SAS macro, particularly , curt to t can -help to think of the macro processor as a SAS debug. If an error occurs in a SAS macro, it could be code generator. in the macro code, in the SAS code generated by the macro, or even in SAS code preceding the macro. SAS Processing TIris tutorial will present a step-by·step, 'cookbook"" approach to debugging a SAS macro. Topics. to be progral Statements SA S oovered ioclnde: · A vel)' brief review of SAS macro processing Macro Tokens (& %) ('what happens when"") Word · First clJeCkX to resolve common problems · Guidelines for determining wbere the problem Scanner lies: in macro code or SAS code · Useful SAS system option> and statements for --- debugsing, with explanations of output generated l' Macro by options SAS Code · Other resources, to learn more about writing SAS Code Processor macros and a""oiding errors TIris tutorial is intended for anyone who writes (and therefore has to debug) SAS macros. Compiler Macro Variabl es",Sugi-89-33 Westerlund.txt
"PROC QPRINT: A UTILE KNOWN AND UNDER-UnU'ZED SASIB GEM Ray Pass CQlumbla-Presbyterlan Medical Cenler Example I·A oxbibits many of tho enhanced formatting capobilitieo that QP1UNT prorides. N<>tioe the ·-AlTRlBurns·- heading tbat """"""'"" tho 'IlIriablo Ml'G-CARGO. This comes from the ',·ATIRlBurns-r In ApriJ,l986, SAS InBtitule qoiedy insc<ted anew PROC """""" base SAS software. llOIDOly PROC QPRlNT. 'l'h<te was a notice in SAS in the code. The XPAN» uptloo tells SAS 10 expand the first and last 'ComMIUIicatioru and a few s.ess.i0llS dealing with Q~ were Iield at clwactersin the label ('-' in th;"" examp..) 10 theleogth of the span. The sum meetiDgs. but DO fw'IIla announcement was II'l8de to the various beaIiog is """",,/eOed by default but could loa"""" been right or leJljLJStifi<d moc as wen. Two ID variable$ am used (MAKE & MODEL) with one SAS Community. The,.,.wt '"" that thote exists an alI<mative to PRINf whk.b is fat superior. btnOOI widely known. Up.., IB1d including headin&· (AUTOMOBll.Il) instead of theu own Yamame. pan of base SAS sofIw........ tho 5.16, QP1UNT _ _ (HEAD=8LANK). Also,:chea:is me CCIIltinUOUS underline. doCmneDtaI:ion WM only indnded in SAS T~c1uilcal Report: P-l46. yoo.,.. ChaAg~8 and E~s 10 tM Version 5 SAS S,sum. This is the SAS Sf""""""' wlDcb _leo ""'"" to be included In QPRINT, in a .'panel"" ofoutputbcfore breaking for lhenextpan.el This is done probably the maio reason Ib""tho JII'OC""dore is little bwwn. I n _ sum 5.18, QPRINT will be included in tho with theGLUEoptitm. II=, the program was instructed '"" keep MPG· Suplementa1Library. with -CAROOonlhesameliDe,andthenrocmuinuewilhORIGIN,IMPORT it! thoSUGl SoppJ""""""""a/ Li/muy U...·8 Guid<. The8e docu...._ and Iho PREFl-PREF2S variables m the next part of the outpu.t Notice aMirjonalp1)Cedurei Breflhippedwitb baseSAS softwate. butmdbe how All of tho PRIll' variahlos are referred to (PREP:). This triel: may not irulependendy _ Once they are, tbey are osod in ""'Y SAS Instiwto progmm""oopide base SAS softwa",Sugi-89-34 Pass.txt
"= E'RXnlOl<i!: PIEllSm:: THE PICKY MI\Nl\IEt WITH THE step>en A. Hatper, Inte<'l'ecbnoJ.ogiea Group FREQ: ~ame a variable whose value rot rQdJlct i on represents the frequency of the observation PROC TABULATE can be uSed to Create & cross-tabulation tables in up to three WEIGHT: Nam~ a variable whose value dimensions: page, column, and row~ represents the weight of the Within each of these dimensions, the observation .. data Can be further subdivided throuqh the use of crossing (or nesting) One important difference between operation$~ This tutorial wi11 present Tabulate ana some other procedures in a series of examples, building from the the SAS· system is that all of the very simple, single-column report, all variab~es Deing used by Tabulate must multi-co~umn, the way up to a complex, be named on one of the .statements multi-raw· report with customized above. In qenara1. t~is means inc~uding formattinq. This paper does not purport the variable on either the CLASS or VAR to cover all of the very extensive statement. capabilities available in the procedure, but does present some of the Qyervj ew of TabJllate kevwOrda most useful ones. Tabulate makes use of a number of overview of TABULATE statementS keywords for calculating statistics and totals. Tabulate makes use of the following statements:. ALL: Specia~ classification variab1e used to calculate a total for whatever FRoe TABULATE: This is used to start variables it is crossed or concatenated the procedure, and set Bome general with. This is illustrated in examples defaults <e.q. the general format of below~ 9-16 the cells). PCTSUM: Used to calculate the TABLE or ~A8~S: This is the most percentage that one summed value complex of the statements, and the key represents of another summed value. to llsing Tabulate~ Through correct use This is illustrated in examples 11-16 of the TABLE statement, you can below. construct a wide variety of.tables. CLASS: The CLASS statement is used to PCTN: used to calcu1ate the percen",Sugi-89-35 Harper.txt
"A Xaero to Separate Records Znto output Dat.sets By Date And Create Dataset Names With Date As A Part Michael J. Schilling, Burlington Northern Railroad AJlSTRACT On the ""'MACRO statefflll!!'nt tne input mac;m variable$are- Pro..,id~iI M,acrotowlvethedilemma ofhowto-tlnd data defined. in 'SAS"" GOO'slik-e history files. With file names like . Dateformatt(J~u~a$part-C)f XXXXXXO l-XXXXXX99, how do users find records with FMT .:: DATE date$ if""l-ti1e rang!!! -of January 1 ~ January 30,19881 the outputdata'5et name, i.e., .MONYVS. yields JANSS In the capacity Management Group, we work with the = The- input SAS dataset.s ddnam~. output recorc:ls generated by computer software monitors. IN DO ~ ffl-(lnitr)r$ are continuously producing records that contain date and time stamps. Each day we run eruact The input SAS filename. IN FilE programs that gather up the monitor records- that have be!!!n .I!l(umujated and creatil!' a $@ri@$ofSASdataS8t$that .Pf@fixtoO be appended to the date OUT DO to (reate the outpLlt SAS dataset have a name in the format XXXXXX99, where XXXXXX is some unique name and 99 is a numer1cvalue that namil!'. represenu one generation of the dataset name. Ea-th day history rnaint~nanc-e routines roll the -generation numbers The variables in the output $AS BY UST such that 01 represents. the most current generation~ 02 the dataset that will be used in the next oldest,. etc·. This i-s common practice and from a P'ROC50RTtoeliminat@dupli(.ate re.:otds. mainten;a.n(@-standPQint, wanes wondertullywell. Th. SAS prO(:&dure PRoe FREQ sotW5 the probl@m of This is where the issue addressed by the subject Macro getting unique dates. DAle is a SAS variable in the- input arrives on the scene. Let's look at thissituatioll from a ·User's"" ~~(l:rve. I wOldd like you to meet Our user, Tip data-set.1hevariableDATEmustbeaSASdatevalue. The E. Call. Tip would like to access some of the recor-ds in -our PROC FREQ has been set up to creat@an output SAS dataset and no print. The o",Sugi-89-36 Schilling.txt
"USING BASE SAS@ AND SASfGRAPH@ SOFTWARE TO MANAGE DASD unLUATION AT THE UNITED STATES rnFORMATIONAGENCY Neil Lehrer, CAeI, Inc. INTRODUCTION · Application disk space growth -- Two line graphs that show changes in disk space usage over time for the The United States Information Agency (USIA) Computer current top five users of application DASD, including Center uses a SAS-based graphic reporting system to unused disk space. One graph is sealed in percentages (see figure 5) aod the other is sealed in absolute tracks, manage its DASD. The USIA Computer Center is an IBM MVSjXA mainframe computer center in allowing USIA to monitor chaoges in its DASD Washington, D.C. that provides services for USIA person- availability over time. nel and missions around the world. Applications include batch administrative systems, such as payroll and aocount- HOW DOES IT WORK? ing, on-line CICS and TSO systems, and end-user access and reporting. pail)' Process USIA uses CA-CA-ASM2~ (a Computer Associates Although USIA does not use a computer services oharge- package) to manage its DASD. CA-ASM2 is used by the back system, the Computer Center management still needs to monitor and manage its DASD resources in computer center staff to perform backup, archiving, and order to meet the CUrrent and future DASD needs of the other DASD maintenance chores. CA-ASM2 also has a Center and its clients. The DASD reporting system was reporting capability that can extract data about DASD aod designed to satisfy management's need for DASD utiliza- print reports or output information to a data set. USIA tion information presented in a cleart non~tecbnical way. executes a two-step batch job (see figure 6) everymorning The DASD reporting system uses the Computer Center's that uses CA-ASM2 andSAS to capture the data necessary disk management system to extract the initial data, base for the historical reports. Two physical sequentiai data 8AS software to manipulate it, and S~GRAPH to sets are appended to each",Sugi-89-37 Lehrer.txt
"A SAS Macro Based VM Coaputer Utilization Reporting System Gregory C. Steffens Two purposes of monitoring and give a great deal of d@t~iled utili~ation statistics which is not reporting system utili2ation are to available anywhere else and is determine when the limits of hardware essential in getting a complete picture capacity will be met and to determine of :system utilizati""on. what the computer resources are being used for. These goals of capacity The accounting data reports overall planning and cost allocation can be system utilization all the time. Thus addressed by reporting the utili2ation reporting this data routinely can alert statistics collected by CP in the you to significant changes in system accounting records. Other data are utilization and can report utilization essential 'in fully understanding system over very long or short time frames. I ~tili2ation but the accounting data is report utilization at le~st every month an excellent overall first look. I from the accounting data which shows: have developed a set of SAS macros that 1.) utilization by month for the twelve make the reporting of this accounting month period ending the current month, data a relatively easy tas~. These 2~} day by day utilization for the macros are used to produce a set.of cu~rent month, 3.) utilization by monthly performance re·ports which are working unit (cost center or line of reviewed by systems people and high business) and 4.) utilization by each level management as well as to produce project Of application for t~e current ad hoc reports as needed. month. These reports can help estimate how far in the future hardware capacity will be reached, who is using the system and when it is being used. I. The SOurces of Dat""a of System Utilization These reports are generated by a ·set of general use SAS macros which report accounting data collected by SAS monthly. There ate three data sO~Ice5 which report system utilization: l~} the real The reports on the accounting data can",Sugi-89-38 Steffens.txt
"SAS* SYSTEM PERFORIIANCE COMPARISONS ON MAINFRAME, MINICOMl'UTl!RS, AND MICROS Luz Torrez, DRC Inc. Tony J. Cincera, DRC Inc. Several objectives were detailed for AIISTRACT this project~ First. the hardware This paper is presented to review the system needed to be easy to administer. p~rformance of the SAS system under requiring no significant addition to d~fferent operating environments and support staff other ~han the research hardware configurational Systems staff's normal abilities and available reviewed include the following: time. Second, the system needed to- Mainframe--IBM* 3090/MVS; ·minicomputers-- include a full screen and very flexible IBM 9375/CMS, DEC* 8530, 8250, 3600 and editor to facilitate the many SOurce Microvax III and micro computers, AST* code changes necessary to customdze 286 Premium and ALR* 386/ both running each modeling project for each client's DOK 3.3. different data format and research questions. Third, the system (hardware OPEHATIHG ElIVIROlIMElIT OVERVIEW and software) needed to provide a high The computing requirements at Demogra- level of up-time and reliability given phic Research Company (DRC) require the scheduled project deadlines. Lastly, large on-line database manipulation and the system needai to be responsive in the long-term offline storage. DRC located multi-user. multi-task environment in in Culver City, California, is ; research which DRC operates. consulting firm involved in the analysis of direct mail marketing industries. IIARIlWARE CONFIGORATIOl!IS DRC's client. include the larger direct The requirements and objective for the mailers of catalogs, subscr~ptions in-house system led to the $~lection of financial instruments, and other p;oduct systems from IBM (due to the similarity offerings. Client information consists with the USC system) and DEC (given the of millions of individual records existing Microvax II). The various containing mailing names and addresses specifications for the different systems along with",Sugi-89-39 Torrez Cincera.txt
"Perfonnance enhancements running the SAS system under HP-UX Doug Austin, Hewlett-Packard John Hall, Hewlett-Packard PURPOSE SYSTEM CONSIDERATIONS The purpose 01 this paper is 10 discuss some of the hardware configurations and system softw'are parameters available to The Series 300 has card slots and configuration capabilities the SAS user running unde< HP-UX. The topics discussed 10 support m""~iple 110 cards and disk drives. The 300 will should give the system administrator guidelines. to change allow you to mount a second (or more) dri\le at a mount and modify thel:!' sy.stem to enhance and maximize. their use point in the file system. This mount point must be a directory of the SAS system under HP-UX. and it is usually a dfrectory a1 root IEweI. For an application such as SAS the two most Ilkety chOices are fuser or lu5en;;_ OVERVIEW This mechanism will aUow increased performance and better HowIeil-Pockard current1y has two series 01 HP-UX systems- use of available dlsk space. The number of djsks and how They are the series '300 and the series 800. The series 300 is they are mounted is unseen to the user and is a decision based on the Motorola 68000 architecture. The serles 300 which must be made by the system administrator, consists of several model. rrom the 310 10 the 370. The The Series aoo slso supports multiple 1/0 cards and dis,"",. models are siightly different In terms of processor speed. memory, Installed options, and the physical layout 01 the In addition to the options available on the 300, the 600 also hardware. The series BOO is based on Hewlett..packard's $UPPorts disk partitioning_ Disk partitioning is a software RiSe based archHecture. The seriBS BOO alao consists of mechanism which breaks the disk up into smaller sections. severaf models whlch have differing options and perform- These sections (partitions) are logically separate and flies ance levels. These models start with the 825 and end with cannot cross those boundaries. Thus, you have a gro",Sugi-89-40 Austin Hall.txt
"A WOIlKLOAD CHAlIACTl!B.lZATION TIJ'lORIAL FOil. ON-LINE SYSTI!HS Ellen N. Friedman SRM Associates, Ltd_ representation of the workloads comprising the lntroduetlQ11 system. This tutorial describes a methodology for applications. !he areas The workload characterization process characteri~ing on~llne requires a representative sample veriod and to be addressed in this paper include: the type Qf information required for profiling the relevant performance measurement information for analysis. The time varying nature of workload applications, the specific data requirements for resource usage, and the dependencies upon each of the subsystems presented, the data particular workload .Ix and arrival rates which collection and anal~1s products available for impact sy&te~ performance must be considered as examining th~ performance of theGB applieations part of the charaeterl~ation process. and considerations for determining the resource For KVS systems. resource consumption requirements fUL new systemB_ information can be determined on a performance The presented here are based on ex~les group basis from RKF/SMF data. Average resource cOn$ulting studies performed for several profiles can be constructed for each companies in the financial and banking region/performance group in terms of their industries. The examples were chosen to relative usage of GfU. 1/0 and memQry services. a broad range of applications executing rep~esent By examining graphs of these ave~age resource in different environments and employing unique profIles over time, we can determine which time software architectures. We will discuss a periods to use as a sample for a more detailed distributed CICS Funds Transfer application from characcerization analysis. In the lDMS case the hankIng industry, and an IDKS/CV application study, we discuss the use of these graphics as from a financial company. part of a general data gathering a~d knowledge The question then becomes, is the workload acquisition process whic",Sugi-89-41 Friedman.txt
"cribing ABSTRACT the design and use of expert systems in This paper oescribes our oesi9n and the jomputer performance evaluation implementation of ;m expert system for area . Addi tlonally, several expert computer performance evaluation (CPR). for systems computer performance evaluation have become commercial~Y We explain objectives in designing an T~REE, expert system for CPE ·. 6xplain why a available de.g., CA-ISS specific expert system development MINDOVER/MVS · the DASD Advisor , and Advisor IO ) ~ shell was selected, describe the MVS Clearly, expert systems technology is playing an structure of the expert system that resulted f>::om the design. ano provide increasing role in computer perfor.mance examples of the rules comprising the evaluation .. expert system. An operational version of the expert system implemented for We decided to explore the use of expert systems technology in our business IBM's MVS1370 and MVS/XA is briefly (Computer Management Sciences Inc.. is described. l a consulting firm specializing in the computer capacity management field.). Wa the expert IlITRODUCTION examined systems commercially available in the CPE An expert system is a computer program However, none of these met our field. that emulates the way that people solve needs. In 1987, we began an effort to problems. Like a human expert, an design our own expert system for CPE. expert system gives advice by using its own store of knowledge that relates to OBJECTIVES IN DESIGNI.NG EXPERT a part",Sugi-89-42 Deese.txt
"the 3380. This trend has had an adverse effeet on the space requirements for data librar-ies whtch contained a large number of small This· paper compares and contrasts the external ·members. The followiog example Ulustrates the- performance and storage man.agement type of wasted space problem that can occu r in a Version 5 SAS dot. library. characteristics of the: SAS Versions 5 .and 6 data library implementations under MVS. Performance compa-risons of data set toading, Simplified Example of Member Layout data set reading, and directory management in a Version 5 Library functions are. presented. Also included are . compari'Sons of libr;ary space requirements under Track ------------- seve ..a~ scenarios and some discussion of tuning Member A: 1 AAAA considerations specific to Version 6 Ubraries. l'IelllberB: 2 B8B-BBliB 3 BBBBBDD 4 BBB Member c: cC .5",Sugi-89-43 Squillace.txt
"Performance of the SASJDB2tm Interface J. WiUlam Mulle. BGS Systems, lac. Creation and tlCCU5 ofDB2 tIma is becoming a majorC07JCef'lt 0{m(pfJ ;nslallatiOl1:r as neW applU:utions are CrEtlta Of c1d applications are amvmed to utilizf' 1M rt!/atimral data base /eatr.m ofDB2 The ,ability-to QlticktjllCCe.u data resident in DB2 krb/espacu and taPte,s fQf'.fl~ and reporli1lg purJICI8eS witlwut reqr.Wing knowkdgt a/SQL tmd DB2 programmilfg tedmitp.U!S is &l dl!.finlb16 capobiJity1m-/hotl DB2 inJto.lltUions. We will discuss !he temits ofmeasul'emenu from urilhatitm of 1M SASfDJJ2 lnwfact! and IUIIl' of die PROC DB2E.XT and PROC DB2LQAD capabilities and perjomwnce experiences u.sing some 01 the capabilities of fill! ;Jlwj'«t. SAS data sets or nIcs are stored in OS d£lita sets on a onc or many basis. INTRODUcnON The ~r I1ru.s bas the option oC crcatinga ·data base' consisting of mlllny SAS data sets. or files ot spreading the 'data base' over many OS data DaUt base !;)'Stems have evolved {rom simplistic bases using flat files seb. to be combined later based npon PI""OCCSSJng requirements. and alternate indexing schemes to what can be. extreme.~ complex stt~d.ures. Hierarchicalstrudures, s.uch WI tho6e llnplemwted mIMS, With DB2 and the re!.utionaileclmolQgy, we.see a dilIerent perspective. can be ememely complex and diffieu It to understand for the individual Data is ~tOl""ed in data bases composed of table spaces which may thatjUSl wants liJ extract data and do rqJortiog.inm05lcases.lhcpmn contain one or more tables (:so-und famililU?), Data in iii table is ofbeooming a data bm;e programmer just to-do reporting is not a. \'iable organized with rows of named data variables. The data wrjables may alt.ernati'ie. _ be character or of vanom; numeric farmall!.. Data hues, table spaces and fables musl be defined or 'dropped' \lia specific SQL inmructioruo Imroduct.ion of relatiQDallecbnology bas simplified data bMe struc- tures and, in some case&; simplified the progrwnming:aspects",Sugi-89-44 Mullen.txt
"DBDltIlDIDIIG 'rBlI ROLES 01' TIIB SAIl. SYS'l'BK AlII) A DA'l'AIIA8E KIIlIAGBIIBIIT ST8'l'BX :or CLlnCAL IlBSEloRCII Ho~dbrook, Mark J. Genentech, Inc. »""traot that is important in evaluatinq this problem is presented and discussed. Although the SAS system has a great deal Finally, there is a discussion of the of breadth, it lacks depth in many impact of the future enhancements which areas. In Clinical Research the demand have been announced to the SAS System. for a full featured database management This paper does not present the solution to the problem. The solution will vary sygtem is sufficiently great that frequently both the SAS System and a accordinq to your particular situation and will not neces~arily be the same at database manaqement system are utilized. While most database ~agement systems any two locations, even if they are produots lac~ the SAS system's using the s~e database ~anaqe.ent analytical and graphical capabilities system. What is presented here are the they overlap greatly in terms of their criteria to evaluate in arriving at a data manipulation and report qeneration decision. capabilities. The question then becomes A1though I have attempted to make this which product, or possibly both products, should occupy the middle paper as unbiased and as generic as ground that can be served well by possible l in terms of the database management system, it will still be either. biased by .y own bao~ground and li.itad A reviaw of the two products shows that by my ranqe of experience. I have been a significant overlap usually exists in programminq with the SAS System for the areas of data manipulation, data several years and my-experience and manaqement and report generation. To knowledge of database management systems decide which product to use for these is much more limited. currently within purposes you will need to look at the clinical Research at Cenentech we use a which runs VMS. We use the SA!> specifio capabilities of your database VAX 8800 Sys",Sugi-89-45 Holdbrook.txt
"nd ABSTRACf download software, and happens to know someone in Accounting who knows ahout the End userromputing can benefit from strategic Accounting Department extract. These informal planning. A useful approach is to break the data paths evolve out of real needs on the part process down into 3 components: end user data of users of corporate data, but do not necessarily analysis, corporate data management, and the represent the most efficient methods or reflect channeling of data from the corporate database longer term goals. to the user. The role of SAS Software and the potential of SAS MEA (Multi Engine Much effort has been devoted to getting a handle Architecture) are discussed in this context. on these informal networks, beginning with the original, mainframe based, Information Centers, through the rapid ascendancy of pes, where the Information-Center became a one stop support· INTRODUCTION consnlt""training department, to the vogue of dispersing Ie functions throughout the user Many data management schemes begin by community. The situation is still evolving. regarding data as a valuable corporate resource, as indeed it is. The analogy between ""hard"" Of current interest is the relationship between . assets, like physical plant, and data is a useful. the end user and the corporate database, like other assets data requires repair and inspired, in part, by relational database maintenance, security, amI, perhaps, periodic technology; a prime example being mM's DB2. overhaul. T",Sugi-89-46 Miron.txt
".;.g oodebooks IUld writing ~ <lata ;""put _ - can be automated aDd integrated to reduce programn:Ung time and elTOn. This a.utomation .-nd int~on can 'be; achieved wiog a. Inlonnatlon SAS program v.bich generates oodobooks .. wcll .. SAS code. muu. Sad! a program is caOed · rode gcucmt'"" IUd appfu:otloo .... foui important advantageo: 1) Varililble names I'r<IgnunmjDg time is red...,.,d. Data iDj?ut pr<>grtUD6 ...,rain pn'cisoly IUd automatically tb<: 2 Variable des<ttpdon il>farmaJicm in the CO<TeSpooding oodobooks. 3) Em:trs in. INPUT !Jf""""-cifiCaMn are avoided. ~ Doru.....latl... Coh.ullb. lpecification 4) CboDge< in oodeboolo; (e.g. a dccisIDn to .... a""""'"" ;""pol ficJd for · ~ variable) ore made quicldy with INPUT lIe<ord .pedlleatlo. specifications recalculated autotuaJicaOy. Keypancl>lo.. Doauoenlallon The system uses only base SAS software and an ASaJ text Ke)'poD<bIDg, Documeo.latlon Cod1a.g iDfo.rmatioo file. ColWIUI B.Dd line INPUT .specifications arc CQIIlfJlIted in the SAS system based on field ',yidth s,pecificacions.. The output of the: SAs code generator consists o( a codebook and a m.atchiag SAS data input program. of variable (chata«el' Ot UUDle-ric), the fae.ld width. :necessary to The ~tcm was developed IUld initially used by the author <ode all oossible values, the input specificatio.. (line, col....., at l'be hwitute for HeaWi Promotion and Disease Prevenlion and/or informat), and the range of acceptable values. Research (IPR) at the UDiversity of Southon",Sugi-89-47 Green.txt
"Product. Division of GE Plastics Waterford N.Y. 12188 Abstract Thi. article will demonstrate a system for producing high resolution graphics PART·MASTER CALC interactively using SAS/ACCESS, SASjGRAPH , PART-NUMBER-OOI and SAS/AF products. A discussion of IDMSIR CAS· BOH·AREA Logical Record Facility (LRF) and ClISTS will also be included. PART-PlANT NPO lolA ASC PLANT ·COO E·OIO The recent release of SAS/ACCESS IDMSEXT procedure which incorporates the 'where PLANT -LOCATIOM clause' feature ,available through the VIA IONS/Re LRF, enables the SAS programmer to CAS-BOM·AREA access the IDMS database from within a SAS b.tch job or on·line interactively. The PLANT-USAGE benefits of this new rele.se are that NPO MA FIRST applications which previously h.d to run off batch COBOL extract files can now be made USAGE· TOTALS interactive saving computer resources and VIA improving the quality of the d.ta for the CAS·INV·AREA user. I will attempt through the use of the following example to outline the steps required in order to develop an interactive Using the on-line subschema compiler (SSe application using SAS/AF , SAS/ACCESS , BASE from ENTe) the following code was used for SAS AND SAS/GRAPH. creating an IDMS/R logical record. for more information on creating logical records using LRf refer to Cullinot's Logical Record Facility Database Administratgrs Guide. D""finlng the Logical Record for the Usage 1ll8.:r11 _,t.')oCI~ -..- _ _ u-..wO~or _ _ H _ _ !0II2Sl. ~ ~ .... IlIICLIIoUA:DIlllr:",Sugi-89-48 Leet.txt
"MB CHEMe this paper demonstrates the OTHER CIlllMA powerfu.l combination of the SAs/DB2 interface.. SAS/AF and the SAS lII.acro- language"" It exemplifies the use of these three tools to greatly simplify the data gathering process which usually proceeds deeper analysis. In this program an AF screen is used to collect and validate data gatherinq parameters.. These parameters are then embedded into a complex series of SAS/OB2 queries to produce a SAS dataset for further analysis.. This embedding process is virtually impossible without the code generation ma~ro facili ties of the SAS lan.guage. System Requirements Create Main M.enu Continue This program is an outgrowth of three relatively simple customer Behind the screen is a moderately req1.lirement.s. Our customer wanted to complex: validation and ,input program written using til logic and AF macro be able to: 1) use screened input to build a 'complex but routinely run"" set variables. This logic allows the of DB2 queries, 2} load the results customer to enter information anywhere on the screen. Columnar input does of those queries into a SAS data.set for further analysiS t and 31 save the not need to be contiguous for it to be 1n addition, the -correctly received. qenerated queries for future reference, manual edi tinq or customer is protected from submitting resubmission should the generated a blank screen as input and blank dataset become corrupted during columns are flagged using macro analysis. to avoid variables processin",Sugi-89-49 Fitzgerald.txt
";()tnbine:s the ftElxlbility of the SltuCtured BIPBOSS auery Language (SOl)wltll the power of tile SAS· System, Release 6.06. The SOL procedure uses SQl to create, modify. and retri_ data from SAS data sets and 'liews derived from those data sets. You can also use the SQL prooedure 10 join data Vi-rg-lnioll .Belich '"" s6t$ a,pd views with those frQ.m QthiII' databaSe management :sy$- ,"" Cit1 OCean telT1$ Ihrougll the SAS/ACCESS·softwarelnterfaces. This paper Ocun CIt1 '"" CIeSCI1bes some of the advantages and ways of using ti1e Sal 1Ut..iGgtn '01 !eln4q.e-r , . procedure in SAS programs. This session takes a task-oriented '"" ii=ilbBrap S 1IJllIIIin!JI:.g.ll 5111oa.5:roap approach in krtroducing the sal procedlJll3 to SAS users and In IIlrtle .Beach ''""., "", "" Cbulestllil IIaJl.Iqll'r s'howing them how to use tI'le pn)¢edul'B to write more efficient nltsttp ctlar-l.ston programs with the latest release of the SAS System. You will notice that the structure of a table is very similar to that. OVERVIEW OF SQl of a SAS data set A row ts equivalent to a SAS observation and a oolumn is equivalent to a $AS variab5e. Because an SQl table The SOL procedure Implementa the Structured Ouery Language and a SAS·data 6et are 80 near1y Identical, a tabla is cons.d6red for Version 6 CJf the SAS System. SOL i. used by many 01 tho Ii SAS data set in the SAS system. database systems that the SAS System interfaces wH:h through lis SAS/ACCESS software, such as 082- and RdbfVMS:- Sal SOL can be u~ In",Sugi-89-50 Johnston.txt
"necessary to change them· is included in the discussion. General, rather than specific, This paper describes some of the new SAS® guidelines for setting these parameters are given database performance tuning features and provides because an application's data requirements and guidelines for their use. As is true with most the computing environment in which it runs vary performance options, many of these featUres greatly. It is due to this variation that the improve the utilization of one resource at the guidelines presented here are not guaranteed to expense of another. The benefits and costs of each produce the described benefits in all cases, The new feature are examined. All of these features best performance will be achieved by are optional since the system provides defaulls. experimenting (tuning) witllthe parameter values. Actual examples of performance improvements using the new features are given. These examples The SAS Usage Notes application is used to are based upon the SAS Usage Notes data set, demonstrate the performance improvements and with which you may be familiar. additional resource costs. Performance and cost are measured for individual resource utilization",Sugi-89-51 Clifford Beatrous Stokes Mosman.txt
"Database Interfaces under the Version 6 Engine Architecture ' Emily P. Wallace, SAS Institute Inc., Cary, NC _ut J=-or the last seyeral SUGI conferences, you have been hearing to work.with a small portion of the data so you need a way to sub- the Multiple Vendor Arcllitecture (MVAl and the multiple set it. Another significant problem is the security of the data and the- impact on the parfQrm.a~ce for other users of the database EH'tg:ine conoopts of V-arslon 6 of the SA$8 Systam that make·data access transparent. Thus far. we have implemented four data- system; bas, engines and developmeot Is underway on other cbItaba$a engines, so you CBn see that the engine architecture has become In. order to solve these problems, we have created the ACCESS procedure. Its job is to capture all of the Information needed to a reality. These new intarfaces provide much more functionality and fl.axibil~ty than their counterparts 1n Version 5 of the SAS Sys- aOQEJSS a database. This information can inctude such things as tem. the name of the da1abase, the- -password and the other options needed to uniq....1y Identify the database. II also allows you to The VerSion 5 Interfaces are generalty procadure-6tyle Interfaces specify- the elements of the database you want to work. with and with each database hav~ its own set of procedures that bring give them SAS names that will be meaningful to you. You can ,pacify a where clause- to subset the records retrieved so that the da.la from tf\a Database Management System (DBMS} into a you work with only the portion of the datal:Jase that you -need, SAS data set. You can run the SAS procedures against this copy of the DBMS data to perform your analyses Q( produce your Before we ·Iook at PRQC ACCESS in more: detail, we need to reports. If there are procedures thai update the database, they generally use SAS data sets as input for the updatas. Both the define two new terms. master descriptor and subc1esGrJptor. A eKtract and updata pr'Qcedures are v",Sugi-89-52 Wallace.txt
"HBS-QUERY: PAINLESS AND EFFICIENT DATABASE ACCESS Using the SASo Sys!em, REXX and XEoIT Under CMS BanyFeidman, Harvard BUSiness School seemed to me obvious that it would have taken much HBS-Query i·· general·access data retrieval tool that less time if I had gone direetiy to print sources and uses the SAS System for data manipulation and XEDIT input them by hand into a worksheet. and REXX under CMS for managing user interaction. Th"" principal goals of this paper are to review the Sutprisingly~ design of HBS-Query, outline the techniques employe<! this is a common state of affairs at many Perhaps it endures business schools across the to create a basic but effective windowing environment COWltry. as much because those who_ have ""paid their dues't are in Ibe CMS opemting system, demonstrate a simple not anxious to reduce the l'barriers to entryil for those searclt session, and d""""""ribe CONVERT, a procedure who have not as due to various commercial and tech- to enable SAS mainframe dalasets to be moved into nological issues that seem to conspire to keep Ibings J'C.spread.heet fOrmat wilbout the use of SAS-PC complicated. From a library perspective, however, this was a very undesirable situation. BACKGROUND Our e~perience with the new PC-based CD-ROM products was that if information was easily available, Baker LIbrary at Harvard Business School established many more people would use it. The truth of the its Computer Research Program five years agO in order to provide library expertise in the p\ll""CbaSe, main- matter was underscored later when I beard · faeulty tenance:~' use and analysis of genera1~purpose economic member speak at a meeting of a tremendous ""frustrated and financial research databases.. This was the result of demand"" for information which was not visible because those in need had learned not to ask. In some was the both the reluctance of Ibe sehoo]""s Department of Computer Services to become deeply involved in Ibe situation started to resemble the stere",Sugi-89-53 Feldman.txt
"da-scriba 'ttte bahind-thll;t-Soanes processing in SOL terms. as it the data were relational after all. If you are an Sal developer but Structured Que'll Language (SQL) is a powerful tool lor relational not a databatle expert, ttlls analysis should help you understand database query expression. That is what it was designed fOf. But what yot.I can expect to happen whan you write an Sal applica- many developers want to use SQL for l1oofekitional databases. tion for nonre!ational data. This paper idElntmes potential pttfaHs Speciallnter1'aoo software between the SOL COde and the data- that any Interface software faces. You can evaluate the behavior base is required because SQLhas no knowledge of hIdden Infor- of your interface in 'these areas. mation in the database. This paper describes, in Sal terms. sal queries are made against some issues that can arise when An Example a nonrelatklnal database. SUppose you work lor a hypOIhetical software company _",Sugi-89-54 Barrett Craig.txt
"TRACT Given this scenario and the announcement by SAS Institute of the beta release of the SAS/ACCESS Managing the utilization of Cullinet's Interface to IOMS/R, a pilot project pl an was Integrated Database Management developed to address the two requirements System/Relational (IDMS/R) database areas is outlines above. typically one of the database administrator's most time consuming responsibilities. Although PHASE J - AREA UTILIZATION AND REPORT various detail reports are available to provide GENERAT ION the DBA with a status or 'snapshot' of the This batch subsystem consists of two batch current database area utilization t the need exists to track area growth over time. A assembler programs which process the IDMS/R graphical representation which allows analysis Central Version glObal Device Media Control of trends and forecasts will assist the OBA in language (OMCL) to load area utilization statistics into an IDMS/R database. These avoiding ""full area"" situations. These situations can cause processing against IDMSjR programs are automatically submitted nightly to database areas to come to a halt. the MVS operating system internal reader. This presentation discusses the implementation The first assembler program processes the of an on Application Development System/Online global DMCL load module for a particular (ADS/D) graphics application, the Area Central Version to compile a list of current Util.ization Management System. which util izes areas~ act'ive database Thus t",Sugi-89-55 Austin.txt
"You can explicitly assign an engine name to a library by using the discusses Ille data library engines Ill.. are available under This _ LIBNAME statemenL 1n Version 6, the UBNAME statement bas VMSnl fOf Version 6 of the SAS® System. A discussion of engines in several new options available. One of these is the name of the engine to generaJ is presented, along with a discussion of the .specific engines be associated with this library. The genenU form of the UBNAME available to the VMS user. Assigning engines to libraries and examples statement in Version 6 is of using engines are described. This paper also discusses engine COOlp.,ibility issues and future directions of engine design fur VMS. LmNAME fibre;{ <engine> <pirysicailJalne> <engine opIimts:>; where",Sugi-89-56 Colbert.txt
"SAS GOES TO WALL STREET : PRoe ARDfA AND 'rHE DOW JONES STOCK INDEX ~t .Joaeph £arb,.. 1.oyob Unlverdty Jt:av.n :r ......~. tmt_u1ty or ~!<l.p Sdd K. Zekav.t. lDyola Hary.ount llnivauity 'the purposa of dlt. paper i . ~ ifl""'Ut1Pt4 _ 1 _ n Q of t:h.o The primary factora that intI.......... rita _ _ t M' ""toek fld .... and &'to"". __ l»W J _ llduatd.l f.ge o;>.t1tlg t.be l'I:t)(; ARIHA l""r<><>elture. thOlrefb..... C<»It'uite it>4t:u · ·re tho .... vttl-<h at'f.ct ~ dh<:,mmI:f>d A urdva.ri&te .ARlKI. -.Gel of the Dow"" .lone· ·tock index is develo~d val.... of the c . .h flows r ....ltin& £ro. holdI"", the .. toela. thus """"Ir. 1"" the f:(:nl: p.rt <;If ~ ..... Al.lilA. ~l. of"" the St..sndard ~ the pr!lIoeil'al ..,.. _1<:, :r.et:pt'. ~t 1'!\tI00d tf) M i_"";11';.1:,,4 . n thOI _ y aupply, _tional iuClle. the f.te of inflation, the rete of .l'oor'. and the New Yon CoIoposite stock tl1dexes .ra also ·· u..Ud lor ~1aon. FiDlr,"",,""U U-a then ulCl.ll.ted. it\U;r..t .nd. tlu> f~rol.l 4oIIoUcit. th .. re ..... """"""ta1nl.,. .. thfOl; f...,l:o"""" wicb . .y have an eff.ct on ""toek pdcea and til.... the tr.dexe., For .Mapl. ""ther t.po.t_t facton lIVIlb ... Ol'EC prlc. chII~c., tl'Ie III tlMt aocon4 put of t:he p.1'*f, ... AillKA Yl:&lI.IIfelr t'\m¢Uon W>4el i . pr._ted. ""'1n& th. _ Y s""'JIlIly K1 as tIw tapat _des. Intepal illUrNlti_l >:knelt. u.t.:roaeional anlS .~._te .11 .ff.. ct the f;O thh neUOl1 of"" tht' P ..... "" u UuI .... <;If dW: ""ro_-conel""Uot; .e<;>e\l; 1W.t""kII<:' tl;l . _ u:tent. f'M tha fI""tl'.:> ·· f)f Mvolop1.n& AJtlKo\ tr_fer funct1 ............ 1.......111 eom:entr.u 01'1 the .fo...... ~i ...... d .t'tmet:!on (ca). ..,,,11_101 as · ....a.l ""option ..... r PIIDC AlUM. While J,o:o:·,J.nkine. Mthodl two. bean """"""1'1'7""4 .xtendvdy ""'i""6 daily...."" aacroee-onoaie v""dabl... The f.ct that tiHlR an the prt=ijMl variabu$ wich Influen<:~ exp.l:ud ¢Uh flw$ llIpl1 .... dwot they _thly Uta, thu p&\HIr ""'·· """""",.....:1 data. in orur to take &<tvantag. o! aaer _ _ ie variab-l.s .mi",Sugi-89-57 Earley Sweeney Zekavat.txt
"SAS/OR· SOFTWARE AS A DECISION SUPPORT TOOL FOR THE PC Charles Ray Walters. SAS Institute Inc., Cary, NC SAS/OR software also has procedures for scheduling and managing the resources for projects. creates sCh.edules that PROC CPM SAS/OR Software brought pow~rful tools for satisfy st::uctuxal relationships among E?roject building decision support systems to the PC activities using only the resourCeS budgeted for environment. Specialized optimizers for a project. PROC NETDRAW draws the project mathematical programming solve assignment network on full screen, line printer. and high PROC problems# mixed integer progl:ams, networK flow resolution graphics hardcopy devices. models with side constraints, and transportation GANTT graphically displays the calculated problems. Project management procedures are project schedule and its current status also provided to plan. control. and monitor projects. using all these output modes. Combining SAS/OR tools with other tools of the SASe system provides everything needed to build effective decision support systems. These decision support systems have the power to solve a wide range of managers' resource allocat ion and project scheduling problems. Formerly SAS/OR pxocedures solve general linear programs available only on larger systems, these tools and mixed integer programs. Optimizers exploit have been fully implemented on microcomputers. special structures in the models including: special order-ed s-ets, imbedded networks, pure networks, transportation networks. and assignment networks. The optimizers integrate nr.l'RODUCTlOO with other SAS System colJlponents, giving users all the tools needed to build a custom decision Management problems may now be solved using the support system. operations research tools of SAS/OR e Software for micxocomputers. The software allows the manager to explore distribution models, Linear programs solve for values of variables systems~ production resource allocation called decision variables. The",Sugi-89-58 Walters.txt
"Da~a Processing and Analyzing Consumer Panel Charles F. Hofacker The Florida S~a~e Universi~y CVALUE Coupon Value (ii' any) FEATURE Item on Fea~ure? <1=Y~O=N) This discussion covers ~he processing and DISPLAY I ~em on Di spl ay? (1 =Y , O=N) aggregaLion of consumer panel diary data PRICBC Price Cu~ Cif any) and brie~ly in~roduces how such da~a can be used La describe a markeL using ~he Frequant.ly Lhe i'i.rst. sLep in analzying SAS sys~em. The discussion begins WiLh panel dat.a is to decide which UPCs are of an'inLroducLion to panel da~a and Lhen primary intere~t.~ Once this decision has covers some daLa processing ~echniques. been made. one can use ~he SAS dat.a st.ep Next~ Lhe discussion Lurns LO ~he kinds LO ext.ract a subset of t.he panel records o~ inferences one can draw aboUL which involve 'lhose upes. Such an households in Lhe markeL. and Lhe ki~ds exLracLion is easily achieved~ as we see of inferences one can draw abouL each o~ below; A ~inal seCLion focuses on Lhe brands. more advanced Lechniques. which are PROC SORT DATA=ORIGINAL.PANBL OUT=SORTED: illusLra~ed by building a produ¢~ space, BY: UPC : DATA UPCS : Inl.roducLion INPUT UPC @@ : CARDS ; The level or aggregation or a saL or da~a 1000010000 10000t0001 1000010002 in large parL deLermines the Lype of 1000010003 9000010001 inferences which can be drawn from LhaL DATA EXTRACT ; In general. high levels or daLa data. MERGE SORTED UPCSCIN=WANTED) aggrega~ion~ such as weekly sales to~als. BY UF'C ; permi~ only Lhe mosL general types 01 IF WANTED model building. As an example, one can DOLLARS = UNITS*PRICE bqild a roarke~ response model which predic~s share as a func~ion 01 unit We begin by sor~ing ~he panel da~a. price using weekly scanner data. Then~ a DATA SLap reads in t.he variable UPC. These upes are the ones which we There are a saL of impor~ant questiohs. are in~eres~ed in grabbing from ~he however. which cannoL be answered at such sor'led panel da'la. The second DATA s~ep a high level of aggregaLi",Sugi-89-59 Hofacker.txt
"How to Establish a Forecasting System Using SAS@ Software Joel Fingerman Roosevelt University Chicllgo, Illinois INTRODUCTION Sales To produce business and economic forecasts require Y mw::h more than simply a comput<:r-based foreeasting model. Good businesti fQrecasts depend (In reliable, consistent data, clearly identified and estimated forecasting tbooties and models, thoroughly documented foreeasts and forecast confidence intervals, and ooostant monitoring of the forooasting system and its forecast a.eeuraey. All of these steps ""in the forecasting process can be aided aQ-d automated by various SAS! products. It is the intent of this paper to demonstrate how SAS products can support all the The forecasting problem then is to determine an steptJ in the forecasting process; from data collection and underlying pattern in the time series and extrapolate out that checking to forocast moni.toring and updating. series for new, future periods. Sales THE DATA y AU qilaIltitative fore<:asting methods require quantitative There are basieally two types of quantitative data: data.. random sample data and time series data. Random Sample Data Random sample data, also <alled eonametri< or cross- I sectional data. in business forecasting are a representative sample Y of observations of related economic data. A typical example is Methods of forecasting used fur time series data are the relation between sales volume and advertising. Data are PROe FORECAST or PROC ARIMA. ooUected on Sales Volume history and the <:on-esponding Advertising Dollars, Media Ratings~ etc. are also collected. In the language of for~ting, Y, usually denotes the dependent Combined Econometric and Time Series: Data variable to torecast, in this case Sales, and X denotes the independent variable, Advertising. Thus, the dataset would be Econometric data coUecl.ed over time combines both of the form types of data. Sales Advertising Advertising Sales Period Y X X (time) Y Xl Yl 1 X, Y, 2 X3 3 Y, X, Y, 4 X, Y, Th",Sugi-89-60 Fingerman.txt
"SAS® Macros and a SAS/AF® Menu System for Reading COMPUSTAT® Files qhristian Vye, University of Rhode Island Craig Dickstein, Blue Cross/Blue Shield OVERVIEW There is one major difference in the order in which macro statements build the SAS code The University of Rhode Island subscribes to as well as a few minor differences that ste~ the Standard and Poor's COMPUSTAT® II from updates to the data file over the years. financial database. The files are arranged on seven standard labelled tapes: 1) the Annual To understand the SPYR macro and our local Primary, Secondary and Tertiary files, 2) the change, let us divide it into 7 parts, A Quarterly Primary, Secondary and Tertiary through G. These parts are defined by the files, 3) the Annual Bank file, 4) the comments in the code: Quarterly Bank file, 5) the Over-the-Counter file, 6) the Industrial Research file, and 7) A - this section includes the %MACRO statement and the first the Prices-Dividends-Earnings file. Seven INPUT statement, which has the comment 'Input the SAS® macros are available to read the tapes. Company-Level Fields' The macros generate a SAS data set for each B - 'Generate if statement based on selection cmeria, if given' C - 'Read the Data for 20 years (Years per Record)' file. Additionally, a SAS/AF® menu system D - 'Generate an If statement if Segyr and/or Eodyr given' has been provided which creates typical SAS E - 'Process Data for a year if that Yoar is accepted' jobs and submits them for Batch processing F - 'Generate an END statement if a DO given earlier' by the IBM® 4381 mainframe. G- 'Generate a KEEP statement if Select was specified' and the ""'/JAEND JUSTIFICATION In our version of the SPYR macro, the order of the parts is A, C, D, E, B, F, and G. Section The tapes contain large amounts of data in B was moved after section E so that all real binary format, in arrays, and in variables are defined before they are used in character fields. SAS, the most widely used the subsetting IF statement",Sugi-89-61 Vye Dickstein.txt
"ESTIMATING TIlE TRANSLOG FUNCTIONAL FORM AND CALCULATING ELASTICITIES WITH STANDARD ERRORS: AN APPLICATION OF TIlE IML PROCEDURE Gary S. Klonicki. N.C. State University that are estimated. given the summation ABSTRACf relationships listed above. The Translog functional form is frequently employed in the estimation of consumer demand TESTING FOR SYMMETRY equations, yet the Translog ean be difficult to use in practice because: (1) the data must be Testing for symmetry requires that the system be adjusted in order to estimate the system around estimated in both the unrestricted and restricted forms. For non-iterated methods impose the S- some data point (usually the mean), (2) a system of noniinear equations must be estimated, (3) matrix of the unrestricted model on the restricted restrictions of symmetry are imposed and must be model, then compare the statistics labeled tested, and (4) expenditure and substitution OBJECflVE*N: (OBJECTIVE*N(fu1I model» - (OBJECTIVE*N(restricted model» is distributed elasticities must be calculated from the Translog as a Chi-square with degrees of freedom equal to parameter estimates. The first three are normally done within SAS, while the fourth is more likely the difference between the number of free done be hand or via some other software, such as parameters in two systems. For interated BASIC. The objective of this paper is to: (1) estimation methods the above test is not valid. However, one ean still calculate a test statistic. as detail estimation of the demand system. and. more importantly. (2) show how PROC IML ean in Gallant(l987). with the following PROC IML code: be used to calculate elasticities and their standard errors from the parameters. Our example considers a demand system with six consumer PROC IML; USE SUNREST; /*This is the var-cov matrix of goods. the unrestricted system created using the INTRODUCfION OUTSUSED= option*/ READ VAR{EQI EQ2 ... EQnJ INTO SUNREST; The Translog functional form (Christensen. CLOSE SUNRES",Sugi-89-62 Klonicki.txt
"'Gross National Product' represents the total value of prOductiOn over the period. However. the variable 'Inventory' most likely represents the estimated cost of a stock of goods at Release 6.03 of SAS/ETS software is available for pes and for the end of the period. Sun and HP Unix systems. It includes all the procedures of Ver- sion 5 plus several significant enhancements and one entirely PRoe EXPAND can handle serles whose values are observed new procedure. as beginning~of~period values, period midpoint values, endwQf~ period values, period totals. or period averages. The This paper reports on the new features in Version 6.03 of SASI OBSERVED= option is used on the CONVERT statement to ETS Software and reviews work: now in progress on new features specify the observation attributes. for future release. For example, to distribute Gross National Product to a higher fre- THE NEW EXPAND PROCEDURE quency you could use the statements shown in Figure 3. Conversion of time series to different frequencies and the ability pxoc expand data""'qtrly out""'lIIOnthly fro1l\>tqtr to,,-lD.onth; to automaticaUy interpolate missing values in time series were the id date; two features most frequently requested by SAS/ETS users on the convert qnp I observed .. total; $ASware Ballot. The new EXPAND procedure is both a comprete 'tun; tool for collapsing or expand-ing time series to any desired fre- OBSERVED~ Figure 3 The Option quency, and a missing value interpolation procedure. PROC EXPAND can a",Sugi-89-63 Little.txt
2.1 HOLTZMANN DISTRIBUTIONS with many degrees of freedom subject to conflicting For atoms in a fluid in thermal equilibrium at a finite constraints is a combinatorially explosive problem. This paper will review an approach to these types of problems temperature. the probabilily of any given configuration (a) is determined by the energy function E(.) and the Boltzmann based on a analogy to concepts in statistical mechanics. A distribution: SAS version of the algorithm is used to solve the Traveling Salesman Problem. These techniques have proved to be useful in VLSI design and are the basis for several Neural -.!ff{:2 e Network algorithms currendy being used to solve AI problems. Applications and limitations of these teclmlques Prob(a) are reviewed. I 1.0 INTRODUCTION. -E(r) A typical optimization problem requires that some objective e kT (AllX) function be minimized or maximized over some N dimensional space. If the N input parameters are conduous variables the solution technique usually involves some form k is the natural constant relating temperature to energy. The of hillclimbing. The combination of inpat parameters are denominator represents the set of all possible configurations. varied so that the solution search continues uphill or down hill in a favorable direction. These techniques are sometimes referred to as gradient descent. 2.2 THE METROPOLIS ALGORITHM These techniques may get trapped in local minima whlle These principles have been used to simulate thermodynamic,Sugi-89-64 Smith.txt
"D-optimal or A-optimal SAS/QC software provides a broad range of statistical tools for designs and is intended for situations where a standard design quality improvement of products, processes, and services. This paper describes ways in which these ~ls can be applied auQ (such as a factorial design) is not a.ppropriate. For example, PROe OPTEX might be used when resource limitations restrict highlights enhancements that are available ia Release t.03 of the number of runs or when some combinations of factor levels SAS/QC software for microcomputers and workstations. cannot be run. The OPTEX procedure is also U$eful fot studying designs interactively. Introduction Statistical methods have played an increasingly important role in the field of industrial qnality control during the 198&. To The ADX macros provide researchers with interactive remain competitive, many American companies have initiated programming facilities for standard design applications that programs in statistical quality control (SQC) or statistical combine the above procedures with tools in SAS/STATR process .control (SFC). often as part of much broader software and the SAS DATA step. The ADX macros can be organizational changes. used to construct fraciional factorial designs; two-level screening SAS/QC software provides a wealth of statistical and graphical designs (Plackett-Burman designs); ort.hogonal, rotatable central tools that meet the needs for analysis, management, and composite response surfa...:e de",Sugi-89-65 Rodriguez Bachteal.txt
"Performance Function for Aircraft Production Using PROC SYSNLlN and L' NOnn Estimation Kimberly J. Le Bouton, McDonne""ll Douglas Corporation The first factor, production strategy, per- Problem tains to overall policies that have affected production. for example, to meet wartime Throughout the past forty years, the efforts, the federal government told air- learning curve has been the accepted fech- plane manufacturers the number of pJanes nique to analyze manufacturing labor costs to be produced daily. Design or production of various produds. The underlying of commercial aircraft was an owed only if assumption is that rabar hours expended It did not interfere with the much needed per unit win decrease as the production of military aircraft. Still today, airplane man- same-type units increases. The learning ufacturers have had to change manufac- curve Is a model used to predict the turing practices to meet stricter FAA relationship between the amount of labor regulations while attempting to increase hours expended per unit and the number production to meet the demands of opera- of units produced. tors who are replacing their aging fleets. The traditional learning curve is an expo- The second factor is work force experience. nential function which takes into consider· Because the number of aircraft orders has ation the following: number of units fluctuated throughout the past forty years, produced; average cost per unit; cost of the experience levels have also fluctuated. The first unit produced; and a constant repres- mosf obvious example of a fluctuating enting the relationship between average experience level is during World War II cost per unit and units produced. The when women, with little to no manufac- function is converted to a logarithm for turing experience, were needed to help ease of interpretation. produce planes to meet the war effort. During the years of limited aircraft orders, Applications of the learning curve have the experience level of work force",Sugi-89-66 LeBouton.txt
"IMPROVING TIlE OUALITY OF SURVEY DATA: WESTAT'S COMPUTER ASSISTED CODING AND EDITING (CACE) SYSTEM Dr. James E. Smith, Westat, Inc. Dr. David L Bayles.. Westat, Inc. continual analysis and monitoring of the production process Thousands of research surveys involving hundreds of thousands of respondents are conducted every year in the in order to prevent tbe introduction of errors in the first place and improve data quality. There has been a shift United States. The results of these surveys influence business strategies, public POlicY decisions, and in many toward quality' improvement by continual process other ways feed our information.hungry society. monitoring and a shift away from quality control by product inspection. But what can we say about the quality of these survey In order to apply the modern methods, fixed tolerance data? Recently, a senior technical official at the U.S. limits are replaced by ~action limitsll used to monitor the Bureau of the Census bas said that ""as the survey world production process.- Action limits define the range in which currently exists, the concept of quality of survey data is not clearly defined and is certainly not measured well."" 1 Thus, variation in some measured indicator of the production process is acceptable. If the indicator goes outside these we are used to addressing questions about the quality of our limits. actions are taken to identify the source of this automobiles, our workforce, and even our quality of life, but variation. Unlike fixed tolerance limits, the action limits are we are not so familiar with questions about the quality of our survey data. not used to gauge the product already made, but rather to monitor the ongoing processes that make the product. DATA QUALITY In order to apply modern quality improvement methods it is necessary to understand the processes that Of course everyone wants quality survey data. But, produced the data. It is necessary to understand how the quality Is one of those concepts. l",Sugi-89-67 Smith Bayless.txt
"labs. The use of designed experiments and quality control techniques has increased dramatically in recent Clearly, this job. needs the assistance of modern years throughout American industry including the computing systems and soffware. Four years ago Aluminum Company of America (Alcoa). With this the statistical group at Alcoa laboratories brought comes increasing demands on statisticians to plan the SAS system on site by purchasing base SAS® project strategies in these areas. Effective and software and SASlGraph® Version 5 for VMS""'. concise communications with managers, scientists, Since that time we have added SAS/AF®, engineers, and technicians are essential. This paper SAS/FSP®, SAS/OC®, SAS/ETS® and SASIlMl® describes one project at Alcoa laboratories and how soffware to our VAXTM system and fifty licenses for SAS software is used to help statisticians fuffill the various aspects of their job's requirements. PC SAS® software. In addition, we have used SASIAF to create a special menu system to make lihe use of SAS software easier for non-computer",Sugi-89-68 Blazek.txt
"choice of that multiple depends on three facLors; (1) the degrees of Two-sided tolerance limits should be used to set freedom of the standard deviation, (2) the limits on a certain proportion of a population. percent of the population you wish to cover All too commonly. researchers use the mean plus (called coverage), and (3) the confidence you or minus two standard deviations to cover 95% of want to have in your limits (called lambda). In a population's values. This covers our example, if the degrees of freedom are 19, significantly less that 95% if the mean and and we want to cover 95% of the values with 99% standard deviation are estimated from the data. confidence. the k-factor is 3,221. Tolerance limits are used in many aspects of Tables of k-factors are not found in many text quality assurance and assessment of the books and may have large gaps in both coverage repeatability of laboratory values, Tolerance values and degrees of freedom. If you need a limits for normal distributions, though, require non-tabled k-factor or want TLs to be computed the use of the non-central t distribution, which as part of a report program, then you-will need is not available in SAS. This paper provides a to be able to compute the k-factors within a SAS MACRO for computing those limits using the Wald- data step. Wolfowitz approximation. COMPUTING TOLERANCE LIMITS If the data is not normally distributed, nonparametric tolerance limits should be used. To compute normal TLs exactly. the non-",Sugi-89-69 Browne.txt
"NARROWING THE COMMUNICATION GAP: EXPANDING THE INFORMATION CENTER <---> CLIENT CONNECTION Dusty Teaf Sandra Robinson The University of New Mexico Introduction Perhaps it is time to look outside our own In- formation Center area for direction. The buzz The 1980s have ushered in a new meaning and word for the 1990s- is ""connectivity."" In com- importance to the roJe of consulting and training puting, ""networking"" is the way of the future. in the information and consulting ,business. As This will be true in all areas- of computing in- the need for Information Centers expan<.Js, and cluding consulting and training. the demand for our expertise and services as computing consultants explodes, often we fail to A recent su rvey of senior information managers allot enough time for introspection concerning the done by Dr. J. Daniel Couger (1989) of the roles we have designed for ourselves in relation University of Colorado found that one of the top to the computer user community, As we adjust five human resource issues of the 19905 is the to our roles as dispensers of information and transfer of more information systems tasks to the solutions., many of us also become dependent on user f while adjusting traditional information our clients' dependence on us. Some of us have systems roles toward that of facilitator. The new become a bit too comfortable in our positions of role of the I nformation Center consultant of the ""great information gurus"" --the keepers of the 19905 will be that of mentor and facilitator rather magic solutions"" so to speak. As Naomi Karten than guru. We also need to become networkers (1987b) points out, sometimes it just becomes too in the true sense of the -word. We must make tempting to keep all that magic for ourselves, our users independent of us by connecting them to enjoy the rewards of indispensability. How- to the people and materials they need~ encour- ever, many of you more weathered and harried aging independence in finding their own so.- (or .",Sugi-89-70 Teaf Robinson.txt
"new information about the SAS The Eastman Chemicals Division (a System. division of the Eastman Kodak Company) has hundred active users. seve~al SAS~ 3. Encourage sharing of ideas among SAS Educaiing these users and keeping them users. informed of new developments would be impossible without a strong support This p.per will explain how Act as a vehicle for soliciting user structure. 4. an in-house user group serves as the feedback. foundation of the support structure. Many educatIon needs are satisfied throogh regular user group ~eetlngs WHO'S 1M CHARGE! which are devoted to exploring topics in There are two basic approaches to an in-depth manner. New developments running an in-house user group. One and product evaluation information can approach says khat, since it's a ""user"" g~GUP~ the users should run the show. be covered in the same way. The other approach says that, since the ""user"" has a primary job function other Information will be shared about than that of w~iting SAS programs, some specific user group meeting topics, and central figure should run the show. advertising methods. Additionally, While the former approach works very information about a sample program well fo~ SUGI, the ECD SAS user group lib~a~y will be provided. This paper will b9 useful for anyone sUPporting th~ takes the latter of these two approaches. End users graciously agree SAS System or with a desi~e to sta~t up to present topics and share program an in-house use~ group. ideas but the main responsibility for keeping the group going lies in the Information Development Center (IOC).",Sugi-89-71 Habich.txt
"AN UNOFFICIAL OWNER'S MANUAL FOR USER GROUP OFFICERS AND THE NESUG EXPERIENCE CONTINUES. Hallett German. GTE Laboratories Inc. Ray Pass, Columbia-Presbylerian Medical Center Lowell Mercier, Boston University School of MedicIne Overview This paper covers two distinct topics. Tile first Is · Some user group officers reaching this point may '""how-to"" guide 00 running a user group and the leave data processing completely because another second is a look at the past, present. and lulure person didn't offer 10 help. When the offioer leaves, activities 01 NESUG (NorthEast SAS® Users many groups just lall apart or spend years Group.) . reorganizing. The key is to never let your group get ensnared in this trap. Some methods to avoid the I. The GenUe Art of Running a User Group. trap Include: * have e1ections at 1east once a year Congratulations, you are or about to become a local or regional SAS user group officer. This paper gives .. fOni a st~:d.n9' c01Dllli.tt.ea for Sharing some useful tips on how to survive this responsibi1ity and grooming future responsibility, and landmlne. to avoid along the way. offi.cers. It is based on the five years that the lead author has actively worked as chairperson of the Boston $AS * Beek suppoxt from your re9io~ SAS Users Group and Northeast SAS Users Group. group or sales-office if available. Both ean provide ideas, speakexs, Those interested in specific meeting-techniques, and moral support, and much- more. what a $AS regional group Is should refer to Gennan's SUGI 12 and 13 talks. The first half of 1fl1s If however, you are krtee-deep in this trap what do paper completes German's SUGI ""User Group you do? Trilogyl< by synthesizing the two previous talks. * mee~9 cal1 a special of your group to discuss the present situation saying that the group will not Survival Techniques continue to exist unless someone e1se helps to carry the 1oad. It has been our obServation that after 6 months to a year ""on the job"", many user group offlOOf's fall",Sugi-89-72 German Pass Mercier.txt
"· the SA.serl System? A.nother View What lS Jag A. Jaffe inhouse advisor has had to explain some of the basic elements of SAS data processing. The SAS(r) System involves people in different This paper suggests an approach to teaching ways ~ To explain adequately the richness of the the most elementary aspects of the SAS System in SAS System requires empathy with people's neE'l:ds~ such a way that the listener gets: a finn. The ""user"" applies the SAS System to various groundwork from which to operate. Put another practical problems. The ""progrananer"" may tackle way r this paper presents the outline of an more complicated problems., assist users, or introductory or ""pre-basics"" unit, if you will, develop systems that assist users. The of an elementary SAS course. The approach is ""manager"" concerned with utility and is nothing more nor less than an attempt to tackle efficiency. This article describes an the question ""What is the SAS System?"" in a orientation approach for trainers and manner that speaks to the needs of the learner. consultants who have occasion to introduce people to the SAS System. It is the author's experience that in tutoring novices in the SAS System, it pays to consider SAS consultants and trainers, and experienced who the learners are in terms of their needs. SAS users who act oocasionally as advisors to To this end, it is helpful to think of SAS others 1 are often faced with explaining how the novices as falling more or less into three SAS System operates to persons who are very new nonexclusive categories. S/he ~ the to it. The ""user"" is well-called. system to meet an end~ 'lbe BAS user is typically Everyone who has played the novice's tutor has experienced the difficulty of suumarizing 'What a data. analyst {let's leave out the ""users"" who the SAS System is and what it does. '!he may perform data entry, etc., under guidance of diffioulty is based in the complexity of the an analyst), who has an application for the System. And despite the SAS m",Sugi-89-73 Jaffe.txt
"SAS* END USER TRAINING: WHAT IS AVAILABLE AND WHAT CAN BE DONE Michael T. Marselle - Merrill Lynch & Co. Why SAS* Training? case? How do you change the cha:nnels? The simplest answer to that question is... ""So you don't have to be the sole SAS programmer for your entire Wait gets better... company, their families, friends, and neighboring cities!!! What if you are using PC's with communications software to emulate a terminal? Maybe you need to have Its nice to be the resident SAS software expert in your a training session about PC's-. and communications company. I know, there is a good feeling of power when software.·· and modems··· ugh! everyone comes to you for SAS' software help. But why not assist the end user community to do some of If some, or aU of the above conditions exist, I recom- their own programming. Let them use SAS software to mend that an ""Intro to Data Processing"" class be get exactly what they want. Let them customize arepot4 designed. taking into account your company's com- or massage some data. Believe me. those end users will puterenvironment. It should explicitly explain about the still call you for help. I am sure that as soon as they want type of terminals and/or PC's that they will be using. some help. or some kind of report - within seconds your An ""Intto to DP"" class should show hew to logon, and phene is ringing. more iroponantly, how to logoff! For PC terminal emulation. you need to provide detailed instructions on So we begin to see ... how to use a modem and communications software. You may need to explain how IRMA and FORTE cards The Importance of Training. work. Another important item that demands some time It is iroportant to train your en<! users. This will allow is keyboard differences between an ffiM tenninal and a them to become creative and get the roost out of the SAS PC. For example, where are the PF(program function) software, or any product. Getting the most out of the keys located, let alone what they do. SAS software co",Sugi-89-74 Marselle.txt
"TiTlE is As SAS Institute approaches a new era, it becomes increasingly OPTIONS NOTEXT82; important to develop software applications independent of oper- TiTlE C=RED H=2 F=SIMPLEX ""ext'; ating system or SAS version. This paper introduces statements and techniques available with current releases of the SAS® Sys- tem to accomplish this task. As an example, the UBNAME state- Arrays ment. currently available with Version 5 of the SAS System. can be used to create applications independent of operating system An array is used to process a group of variables (either character commands. Since this statement will also be available in a future or numeric) as a unit This is an often-used feature of the SAS release, using it now can reduce code changes later. DATA step. Version 5 introduced a new type of array: the explic- Itly subscripted array. This type of array was introduced to replace the older version used with Version 82: implicitly sub-",Sugi-89-75 Painter.txt
"· after the procedure name bas been scanned but prior to its invocation (to check for procedure authorization) 'The StaufonJ Data Center has installed code to utilize one of the user exits which are currently defined in Technical · wben a SAS library is accessed Report Y-I08: User Exil Facilities for the SAS System Ver- sum 5. Our exit produces a local SMF recoId type when a at the eod of a procedure (for step accounting) · SAS PROC or DATA step is invoked in MVS batch orTSO. after an 1NFILE record has been read 'These records are in tum analyzed with SAS. This paper summarizes the difficulties we encountered in implementing at a number of places when using SASISHARE® the exit. what we have been able to learn about our SAS user · community from the data, and what additional data we 'The implementation discussed in this paper maires use of would like to have but does not seem to be available. only one of these exits, the step accounting exit, however the",Sugi-89-76 Genis.txt
"ssed Abstract affects these criteria but I believe there are steps that can be taken by the SAS two years as an After internal programmer that can simplify the matter. Information Centre SAS* consultant I My ulterior motive is to lay the have seen SAS code written by scores of Some were new to different programmers. groundwork for SAS programming standards that the Information Centre should SAS programming, while others had years of experience,. expect from any SAS routines that they will be expected to maintain~ have been thinking about what makes a I '""GOOD"" SAS I?rogram.. a SAS How should It is my opinion that most of the SAS be written so that it is program programs written by Information Centre users can be generalised into readable, understandable, and easily four maintained? steps: read and select relevant data, sort that data, summarise the data, and I found it easier to describe the things produce the report(s). There are that constitute IIBAD"" techniques rather various ways to accomplish this using SAS software as the following table may than define a formula for generating ""GOOD"" SAS code .. illustrate~ Other sorts, summarisations, and reports may he needed in one program. I plan a ""tongue-ia-cheek!! review of ""tec-hniques"" I have encountered, followed by my ""'rules of thumb"" for generating what 1 consider reasonably How to build a wBAO u SAS program. ""GOOD"" SAS code .. This wi'll not be an exhaustive discussion of ho~ SAS software products The following should be",Sugi-89-77 Densmore.txt
"Introducing New Documentation for the SAS· System Helen Wolfson, SAS Institute Inc., Cary, NC Brenda Kalt, SAS Institute Inc., Cary, NC This paper introduces our new dOCumentation and shows how INTRODUCTION· the documentation for base SAS software answers the needs you have expressed. The Publications Division at SAS Institute Inc. produces docu~ mentation for all software products in the SAS System. Over the past two years we have planned 8 major redesign of our software AUDIENCE dooomentation, both in roment and in appearance. This paper describes the kind of documentation the Qivision plans to pro· Each type of book is imended for a different audience. WhUe we duce for future software releases; it also shows how we are recognize that our audience 1s very diverse indeed, for our pur~ implementlng the plan in documentation for base SAS'* software. poses, we divide it into three categories. In the definitions that follow, ""new"" means new to the SAS System. Documentation in Version 5 New computer-naive users In Version 5 and earlier releases, SAS software documentation do not know how to write SAS programs (or any centered on the user's guide for an individual product. Examples computer programs), but they are willlng to learn. include the 8AS User's Guide: Basics, Version 5 Edition, the SAS They already know how to use a terminai and how to User's Guide: Statistics, Version 5 Edition, the SAS/GRAPH User's access and use software. In addition, they have GUide, Version 5 Edition, and so on. The user's guide for a proo- access to help (books, courses, and humans). uctwas sometimes large and was oriented primarily toward refer- understand the concept of a computer file, and ence, with a Quick-reference card bound in. The same book recognize a need to use SAS software. contained instructional examples to teach you how to use the New computer-literate users software. This approach worked weN when the SAS System was do not know how to write SAS programs, but have smaller,",Sugi-89-78 Wolfson Kalt.txt
"tion ABSTRACT For OS 5.18 you specify: OVer the years the SAse System has evolved from a SAS OPTlONS('optionl oplion2 .. :) single environment to a multi-environment, multi-version system. Consequently, major new advancements have For PC 6.03 you key: been introduced to simplify and improve the way we interact with the software. It may be a sign of the times, SAS -option 1 -option2 but our desire to access information residing on a variety of environments is on the rise. The level of consistency Also, as you might expect~ there are also differences in between the different environments and versions is the options you can specify. These will be discussed extremely high. Still, confusion exists, especially sinc;;e below. some statements, commands, and/or conventions may not work when transported between environments. This PRIMARY WINDOWS paper presents areas causing concern when transferring skills between a multi-environment, multi-version SAS The interactive Display Manager sesslon appears. Now System. In addition, guidelines are presented to minimize you are going: to see eIther one more or one tess window this confusion. than you are accustomed to seeing, depending on which environment is new to you. os SAS Display Manager INlllODUCTION contains two visible primary windows--log- and Program E<litor--with the third primary window--Output--hidden This paper discusses some of the stumbling ~ocks when behind these two. The Output window comes to the trying to port one's SA$ sof",Sugi-89-79 Lafler Bedinger.txt
"THE CASE FOR GUIDELINES: A SAS® SYSTEM STYLE PRIMER Frank C. Dilorio, COmputer Sciences Corporation Organization INTRODUCTION This paper addresses these and other issues Whether subconsciously or by slavish devo- as background to a discussion of SAS program- tion to published documents, most people adhere ming guidelines. It is divided into two sec- to a set of rules when writing even trivial tions. The first discusses standards and pre- applications. This paper presents a set of sents the argument for their replacement by programming guidelines suitable for a variety programming aid~, or guidelines, It also dis- of SAS applications. It emphasizes that their cusses the features of the programming environ- successful use requires consideration of user, ment which make the guidelines vital or super- program, and system contexts. fluous. In the second seetien we discus's a set The successful use of guidelines also re- of-SAS-specific program design criteria. quires that variations in individual style be Both sections are equally important: sensi- respected. This suggests that the traditional tivity to the background and environmental call for standards may not be appropriate. The context of a guideline is just as important as positive impact of guideline use can be Sig- its rationale and statement~ nificant, especially in SAS-dominated environ- ments. I. STANDARDS AND GUIDELINES An Example Standarda Let's begin by posing a seemingly simple problem to' some _userS! add two numeric vari- The enumeration of program design standards ables across all observations in a SAS dataset has long been part of the system design litera- and display the result. ture. Ideally, their implementation ensures Even though it sounds straightforward there the same solution to a problem will be imple- can be a surprising amount of variation in the mented by different programmers. The con- programs. A casual user might use FROe MEANS formity of approach fostered by standards im- or UNIVARIATE.",Sugi-89-80 DiIorio.txt
"Improving SAS® System Support at a Large Site Bruce Gilson. Federal Reserve Board 8ert Shankman, Federal Reserve Board Introduction Steps to Improve SAS Support This paper describes the steps taken to improve SAS I. Establish an ill-house SAS User's Group. system suport at the Federal Reserve Board. We be- lieve that these steps can be implemented at many H. Develop tu II-screen menus to simplify interactive large sites. SAS use. III. Publish an In-house SAS User's Guide. Specialize SAS consulting responsibility by prod- IV. uct V. DetermIne the appropriate level of consulting ser- vices. Characteristics of a large site The characteristics of a large site vary, but might In- Glude :::o:everal of the foHawing: I. Establish an in-house SAS 1. Many users. User's Group 2. Diverse applications. · Report writing. A SAS Board User's Group {SAS/BUG) was formed at · the Federal Reserve Board and meets five times per Full-screen data entry. year. The agenda includes any of the following: · Production tape jobs. · issues are dis- Common user problems and · cussed, Econometric modeling. · · etc. Suggestions are made to improve the effective- ness of SAS. · 3. Many SAS products .used. New releases of SAS and new SAS products are discussed and demonstrated. Testing and cutover dates are coordinated -with the users, · SASJETS:tl · · SASIFSP. Users give demonstrations/talks on interesting applications or techniques. · SASIDB2TM · SAS/AF'I) Some consultants may be discouraged from forming. a User's Group at their site because they do not expect · etc. to find users willing to make presentations. At the Federal Reserve Board, presentations at the meetings 4. Users located at multiple sites. are planned as tollows: 502 · A pre-SUGl meeting is held in February or March. II. Develop full-screen menus to Users plannil)g to present papers at the SUGI simplify interactive SAS use meeting: preview their papers at this SAS/BUG meeting. A ""dress rehearsal . . presentation of a paper is usef",Sugi-89-81 Gilsen Shankman.txt
"This paper describes support techniques used in the these projects must be developed quickly. We, have Alcoa Technical Center VAXNMSTM environment for made significant impact on project schedules Wlt~ the the SAS System. SAS/AFTM, the SAS"""" product for ability to quickly create data entry screens With a developing menu driven applications, was used to menu driven front-end. This ability has also allowed develop custom menu systems wnh an easy to use us to develop prototypes that show the .feasibility of a interface. Online VMS help has been provided for software system before we begin a (arger SAS software describing site specific information as development effort. In many cases, the prototype well as the SAS HELP facility. A VMS bulletin board becomes the basis for the production system. is available for user comments and the dissemination of information. In addition, a method for monitoring SASCourses the usage of SAS software has been developed. Adequate training is necessary to introduce new users to the SAS System. Courses in SAS software are offered three times a year. We have developad and",Sugi-89-82 Martin.txt
"will deliver superior performance but will Obviously cost more. A good configuration for most users is to equip either machine with While the SAS® System for persona! computers will run on a 1 megabyte of EMS and a 1 megabyte disk cache, Effectlveness PC/XT"""" or compatible with 10 megabytes of disk space and 640 of a math coprocessor depends on the type of jobs run. K of RAM, it is not recommended. This system will deliver extremely sluggish performance and will have little work spa.ce available. This paper recommends two machines for running the PC COMPONENTS SAS System and discusses how to configure each of these to achieve the kind of performance with which you will be satisfied. It is important to understand the weaknesses of present day PC systems in orner to understand how to configure them. The prin- cipal problem is the inability of PC OOS to allow more than 640K",Sugi-89-83 Brumitt.txt
"Standard Operating Procedure in the Creation, Maintenance, and Quality Assurance of SASTM Programs Wendy London and Bucky Walsh Phannaceutical Re~ch Associates, Inc. Programmers have the responsibility to ensure that the programs The survey. shown in Figu:re 1. requested that each programmer they create are accurate. efficient, and easily understood by estimate the average amount of time spent on each of the tasks. others. To assist programmers in obtaining a common A recommended distribution of project programming time which understanding of this responsibility, a company might employ a employs ""top-down"" methodology is shown in Figure 2 in standard {)perating procedure (SOP) for programming. addition to the survey results. Pharmaceutical Research Associates (PRA) has deyeloped such Figure 2 an SOP for programming in base SASTM software. Distribution of Survey Results (N= 18) versus Recommended Project Programming Time "",~~~---=---~===---, An SOP provides consistency among programmers -- consistency which is necessary when programmers must work together as a team and communicate on the sante level. An SOP sets the standard over time -- while programmers may come and go within a company. the unifonn rode wrinen can be picked up by successive programmers and easily maintained or revised. The guidelines provided to programmers in this sample SOP address; o code fonnatting and file naming; o problem assessment and design prior to writing the code; o thorough testing; User Design Write Debug Test DOI'.:lJmOl1t Maintain Project Tasks o time roanagement; {) adequate documentation; Svgg&$todT/nw SuMJ)' fle1WIl'I .. _ o an overall standard for an individual programmer's On the average. the surveyed programmers estimated they spent improvement. almost twice as much time writing the source code as they did designing or testing the programs. Almost as much time was Why should an SOP be necessary? Programmers want to have estimated to have been spent debugging the code as test",Sugi-89-84 London Walsh.txt
"d or not, reduce Possible Standal'rls confusion and prolong the useful IWe of a prografll This paper Same as the f~ename and the Reref presents a d14!C:klist of topics to be considered if an individual or dataset created from it. Let filename organization wishes to develop a set of standards for SAS eJrtensian tell you what kind of file k programs. The topics covered are naming conventions. is rather than create new names for compatibility issues, documentation, visual style. program logic, files of a different type. and systems of programs or steps. The emphasis is on using Consider letting particular columns standards as an educational tool, rather than as a set of rules. Variables signify aspects of variable. For example, starting calculated var- iables with an underscore. PURPOSES OF STANDARDS As a default, truncate unless you will Abbrevtations To help bring into focus the points on the checldisl. we will pick lose Important endings. e.g. two general goals: procluctivity and learning. INTERCEP not INTERCPT Long..term productivity usuaRy goes down as the speed of programming goes up. The focus should be on extanding the Same as stem of the varialjes in the /vrayNames useful lila of a program by making ~ more maintainable, and by array, plus underscore. e.g. broadening Its usefulness 10. addkionaJ people other than the ARRAYX_X1-X7; original programmer. To this end, standards should reduce Same as option name, e.g. confusion. make errors more unlikely, and make programs ea",Sugi-89-85 Clay.txt
"The SAS Institute supplies son routine SORTI and sort interface routines for SyncSort-, VMSORT"", PLSORT"", and other sort utilities as part of Release 5.18 of the SAS® System for VM/CMS. As Tulane Computing Services licenses both SyncSort and VMSORT, it was necessary to decide which sort utility to use as the default with the SAS System under VM/CMS in Tulane's environment. Using Release 5.18 of the SAS System installed under VM/CMS, four sort utilities were compared: VMSORT, SyncSort, PLSORT, and SORTI. Datasetscontainingfive integervariablespercase and 100, 1000, 5000, 10000,50000, lOOOOO,or250000records were sorted. The parameters examined include: Virtual time (VTIME), total time (TTlME), and Start I/O's for the SAS job execution; CPU time and main memory used for PROC SORT; and CPU time and main memory used for PROC PRINT. The results for PROC SORT CPU time show that SORTI is slower than VMSORT, SyncSort, and PLSORT. There is no statistically significant difference between VMSORT, SyncSOIt, and PLSORT. The results for main memory used for PROC SORT show that VMSORT and PLSORT address memory as required up to a data set size of approximately 10000 records; and then they access approximately 1300 kilobytes of memory. SORTI and SyncSort routinely access 1300 kilobytes of memory regardless of son size. Methodology",Sugi-89-86 Nunez.txt
"Uploading source code otten helps consultants at the Institute SAS Institute continually strives to provide thE:! best possible tech~ diagnose a probtem. Once you have obtained a tracking number, oieal support to its users, The recent addition of the Online Cus- either by calling or by tracking a problem online, you can upload tomer Support Facility (OeSF) is another step the Institute has a file USing the OCSF. This capability reduces the turnaround time taken to provide excellent support. This paper discusses the ser~ necessary when mailing files to the institute on physical media vices provided by the OCSF and supplies the information you such as tapes. You can similarly download a file provided by the need to get started, consultant handling your tracking number.",Sugi-89-87 Sims.txt
"want your system CQrtfigured and how you would like the DESOview system options set. The Performance Setup options The ability to muttitask is fast becoming a necessity in the world control the amount of processing time DESQv1ew allocates to the of personal computers. The virtual mode of the 80386 mlcropro- foreground and background tasks. Since the task processing cessor has made multitasking viable. This paper discusses how time can be altered dynamically, it is probably best to accept to run the SAS System for personal computers under OESOView DESQview's default values for these options. 386. Microsoft"" Windowsf386, PC-MOS®1386, and VMf386~ Creating the DESQv!ew 386 Program Information File for the",Sugi-89-88 Maddox.txt
"e price/performance ratios have lulled many analysts and programmers into believing that program efficiency is no longer important. Yet excessive resource usage is usually the ultimate cause 'of poor online response time, l~mg batch turnaround, and inflated computer cnargeback bills. It is risky and expensive to rely on hardware upgrades to solve these problems, _and system tuning is limited in its effect. Programmers must go onE step farther by practicing application tuning. The SAS® System has grown far beyond its beginnings as primarily a statistical analysiS package. Many installations now develop major applications written in the SAS programming language. Although SAS software promotes structured code, users often -put too little effor-t into finding and applying other resource-saving techniques. This paper outlines several uses of SAS code that yield savings in CPU time~ memory usage, I/O processing and disk storage. Specific examples and results of their use are presented. 1. [NTRODUCTION proves that as r'esource consumpti-on increases, elapsed processing time increases exponentially. The processing speed of mainframe computers and When utilization climbs above 80%t the rate of the capaci ty of storage subsystems have degradation is alarming. incr'eased at incredible rates over the past two decades. It is often noted that today's Attempts to resolve system bottlenecks usually personal computers are more powerful than the follow one of two courses. The first of these ma",Sugi-89-89 Lodter.txt
"USE OF SAS PROC COMPARE AND AUTOCALL TO REDUCE THE CODE NEEDED FOR A SAS SYSTEM BY 15% Arthur H. Hensler The Firestone Tire & Rubber Company, Akron, Ohio~ BACKGROUND beginning of a section being compared and OBS can be used to limit the comparison Last year I received a 16,000 line to a given number of lines. SAS system from an end user. The system PROC COMPARE only prints the first came with no documentation, but a list of 20 characters of any variable which proposed modifications. A 27 member differs from 1 dataset to another. Using 4 variables displays differences more partitioned dataset contained the code. The code did not use macros, and the code than 20 characters into a line. in each partition was run from a separate After reviewing the output from PROC job. COMPARE, change spacing and Upon examination, I found many large capitalization and insert blank lines to sections of code that appeared similar~ make the 2 versions of code as much alike Before making any changes, I decided to as possible. When all changes have been made, the differences left are the determine how the system worked, and to provide complete documentation. The best differences between the two versions of way to do this was to break the code down the code, which can be included in the into smaller, more manageable chunks and macro formed from the code. document each of these4 I planned to convert the EXAMPLE USING PROC COMPARE s~m11ar pieces of code into SAS AUTOCALL macros# The two datasets below containing and to use the partitioned dataset as the AUTOCALL library~ In order to do this, I SAS code will be compared and a macro anyl needed to find the differences (if written which will do the work of both. in the similar pieces of code. Working this manually proved to be too time ED!T ---- TSOTDJ5~SASCODE.DATA(SAS1) - 01.01 ---- consuming and error prone, so I generated COMMAND ""'""""'''''> the automated method of following ****** ******************** ..******* TOP OF DATA comparison using S",Sugi-89-90 Hensler.txt
"style stands to gain more from improvements in the maintenance process, and it is this style we want to employ. Nevertheless, The growth in size and complexity of the SAS® System has made even the ''reactive'' style can benefit from improvements such as the task of maintenance more difficult for the System Administra· an automatic system of record keeping. tor. This paper describes an automated system for managing the maintenance of SAS@ Software, and discusses the installation Introducing Automation and use of such a system. improved speed, attention to detail and accurate performance of",Sugi-89-91 Ward.txt
"Harvesting Iufor.ation - Data Cleanup and Analysis Techniques Gary F. Plazyk. CDP A.T. Kearney, Inc. Introduetion Data analysis strategy: What will you get out of this paper? This is a summary of the strategy we will be examining in this paper: An overview of how someone else uses the SAS® Know your data! System. Carefully review your input records. A methodology and some time-tested techniques for analyzing data, whether from a client~ or Read raw data into a permanent data set, from another organization within your own creating corrected and derived values in standard form. company~ I'll emphasize SIMPLE techniques for extra~ting Do a preliminary analysis, using PROCs VALUABLE information QUICKLY. But don't let the CONTENTS. CHART, MEANS, PRINT, and PLOT. simplicity of this approach fool yOUj we're going to use some basic SAS procedures as tools Perform data cleanup4 to help us turn boring numbers into exciting information. Just try some of these techniques Perform additional analysis. and you'll find out how powerful they are. Your background: Data Analysis Techniques I'd like to talk primarily to the new SAS users I'm going to begin with some analysis techniques here at SUGI. You've probably taken the you.can use right away, and then come back to introductory SAS courses. You may even have some the DATA step to look at some detailed cleanup background in another programming language - techniques. So, let's assume we have our data either on a mainframe computer using COBOL or already in a SAS data set. FORTRAN or PL/I. or on a PC using BASIC or Pascal or C. You may have learned how to use SAS to read files t write reports. print checks. Use PROC CONTENTS to document your processing: or do complicated statistical analysis. But what isn't mentioned very often is that SAS lets What's the first thing we should do when we read you LOOK at your data and see its overall our data in? Run a PROG CONTENTS after creating structure. That's what makes SAS such a p~werful eve",Sugi-89-92 Plazyk Kearney.txt
"Using DATA _NULL_ and STOP ~tatements to Ease the Transition to the SAS System Robert Saxe, Independent Consultant Many programmers learned programming using Basic, Forttan. or similar ~ prior to exposwc to SAS. The adjustmeut to SAS Examo le Program can be confusing at first. Two problems are an insufficient under- standing of the flow of control whicb the SAS Supervisor imposes on **··**********""'**....**********""""',..**..,,***""***""******** the DATA step. and confusion between external files, SAS data sets, PiWGRAM NAME! MAJOEMO. SAS and arrays. PURPOSE: SAS PROGRAM TO DEMONSTRATE SIMPlE Foo.TRAlUBASIC-STYU: MATRIX USE DATE: 9/21/88 SAS can easily be made to act more like. it traditional language, with AUTHOR: ROfIERT SAXE. {Z13} 665-6598 the use of the DATA NULL statement and the STOP statement. *******-****-**********************_......*-******* ; These statements prevent SAS-from automatically creating SAS data Of'HONS NOOAT NOCENTfR PS:Z4 tS.:8Q; sets and from executing the implied OUTPUT;RETURN; sequence TlTLE <DEMONSTRATE FatTRAHl8ASIC~STYl£ Us( Of SAS ARRAYS'; at the end of each data step. *NG SAS DATASET NHOED; DATA _NlIll_; SAS Data Sets. The SAS Supervisor creates a SAS data set by default in every data step that has an INPUT, SET, UPDATE, or ARRAY MATRIX (10,6]; MAAV Ra.tTOT [lG]; MERGE stalement. Programmers wishing to transfer skills learned ARRAY CotTOT [6); in otbCf ~ may find this a distraction at first. While learning how SAS uses arrays and external fdes, which are common to other *READ THE INPUT DATA. H\JM3ER Of ROWS AHa COll.MNS ARf languages, it may be he1pfu1 to stop SAS from its automatic creation ON THE FIRST 'CARD,' IN FlflDS 1·5 AHD fHQ. THEN THE DATA MATRIX fOlUJ.lS. IN 3-COUlMN FIUDS; of SAS data sets. Usc of the special reserved data set name _NULL-"" in the statement ""DATA _NULL.;- accomplishes this. INPUT filUM 1-5 NCOl &-10; '""READ NUMBER OF ROWS AND COLS: Flow of ControL In Fortr~ Of' similar lan.guages $ucb. as Basic. flow '*READ",Sugi-89-93 Saxe.txt
"dard, although it does not follow a strict interpretation nor is it implemented on a particular level of GKS. The standard was used The DATA Step Graphics Interface, or DSGI, enables you to call to provid~ a recognizable interface to the user and, because of the graphics subroutines used by SAS/GRAPH!!> software during its modularity, to allow for easy enhancements to the interface tha DATA Step or in a screen controllanguaga (Sel) application. without the side effect of converting programs between versions. You access the graphics system by using function and subroutine Because of its reliance upon the standard, OSGI uses many caYs. In the DATA step. you may have already used the SUBSTR terms that may be unfamiliar to the SAS u~r. Thm:>e terms have function to co1iect a substring from wIthin a string. DSG! uses a foundation in the GKS standard. function calls similar to the SUBSrn function to accomplish its goals. You can use DSGt to write a custom graphics application or proto-type in conjunction with all the power of the programming USING DSGI statements accessible by the DATA Step. This paper describes the DATA Step Graphics Interface and the commands used within Here is the usual order of logic flow when using DSGI: it. Some terminology of the Graphics Kernel System (GKS) is cov- ered because DSGI is based on GKS. This paper also shows 1, Initialize the graphics environment some examples using the DATA Step Graphics Intertace and ex~ains certain features and techniques used in the examples. 2. Open a segment that collects the graphics primitives that you are going to iswe.",Sugi-89-94 Walker.txt
"Using SAS/GRAPH.. Software on a Local Area Network Gregg Ledford TeJmigraphics, Inc. GATEWAY TO tnST INIRODUCfION Within IBM mainframe computing environments, much progress has been made in the area of LANs. IBM's Token Ring has recently doubled in market sbare and will contilme its momentum to become the LAN standard topology for most IBM customers. 8AHXiE Mainframe graphics support on the Token Ring is a SERVER strong requirement, particularly when converting from 3270 coaxial communications where host graphics Figure 1 Local Area Network bave been supported for several years. With most companies ntigrating towards the LAN, tbe discussion of using SAS/GRAPH software on the LAN becomes Benefits of Using a IAN an important issue. There are many benefits of using a LAN. The The most common methods of communicating with the host include using a LAN gateway product or the primary applications that are used on tbe LAN IBM 3174 controller. Both of these metbods can be include the following: used to access SAS/GRAPH software from the bost to the Pc. Other important LAN issues discussed include obtaining graphics hardcopy from devices · File Sharing attached to the LAN, such as plotters and laser · Electronic Mail printers. The LAN hardcopy is of importance to both · Printer Sharing IBM mainframe and PC SAS/GRAPH software - Gateway to Host users. Other issues relating to the topic of using · Others SAS/GRAPH software within a LAN environment are discussed during tbis presentation. There are many different types of LAN hardware on the market today. The largest percentage of LANs in WCALAREA NETWORKS use today are based on Ethernet technology. This is very popular with DEC VAX users and workstation vendors. The second largest percentage of LANs in A Local Area Network (LAN) consists of both hardware and software which is used to connect use today are based on the IBM Token Ring various workstations, peripberals, and other devices technology. The ffiM token ring technology i",Sugi-89-95 Ledford.txt
"c image from your PC to mainfr.une SASIGRAPH' may be possible eveo if the graphi<3 package used does not directly support such an inted'ace. Most popular PC graphics packages provide intetfaces betweeo other PC package. through image exchange file. or metalile.. An metalile ;. a file of generic _bing commands generated by one graphics package that can be read by another graphics package and translated into the ori- ginal graphic image. Example, include VDI (Virtual Device Interfuce)' DXF (Drawing ElI£hange File)' and CGM (Computer Graphics Metafile)'. _hie. package and the importing graphics package must .apport the same metafile format. Currently SASIGRAPH does not The exporting support most popular metafile fonnats (I hear version 6.0 may support CGM). Another format which can be used for image exchange is tt.e Hewlett Packard Graphic Language (lIPGL)s . If we exported a graphic image in HPGL fOllIlat to a file, then process that file with a SAS program that mimics an lIP- plotter, we would have a fWlCtiOnal image exchange interface or mttafUe. Introduction Severn1 months ago. one of our users asked if we could include some PC graphs. into a mainframe based reporting system, This wouW require the ability to import graphic images from Harvard Graphics6 running on PCs to our IBM? mainframe for inclusion in' batch generated reports. There was no direct interface between Harvard Graphics and SAS/GRAPH, so we decided to write our own. Harvard Graphics 2.1 exports a graphic image",Sugi-89-96 Fazzino.txt
"Developing Device Drivers with the SAS"""" Metagraphics Facility David G. Ball, Oak Ridge, TN Y-12 Plant* described at SUGI 12 (Ref. 4). Extensions, presented in this paper, offer SAS/GRAPH users access to additional features of OISSPLA's drivers. The Metagraphics faCIlity enables SAS programmers to develop specialized device driver.. This peper briefly describes the software. which offers extensive control in The number of ways of sloring graphics output has increased greatly since SUGI 12. For Instance, a CGM handling graphics output. Practical experience gained by driver in all releases of SAS provides a more Huniversal"" using the facUity Is discussed with special attention' given 10 problems encountered. Sample applications Include a medium for transporting graphiCS output across systems and to various device.. Since the OISSPLA metafile has driver lor a 36-in. color Versatec plotter that automatically been used lor this purpose at our s~e, there will be a posttions the plots on the pege, an interface from transition period even after another medium is established. SAS/GRAPH on a personal computer (PC) to a OISSPLA metafile on a host computer, and a Version 5 Computer As pointed out in Ref. 5, CGM, offers a means for SAS/GRAPH output to be ported to PC graphics soffware; Graphics Metafile (CGM) driver. however, competibility problems may stili arise when vendors support different parts of the CGM standard. Infroduction The Metagraphics facility, introduced by SAS Institute with Despite a strong trend toward use of local plotting devices, the release of Version 5, allows users to write intelligent such as a laser printer attached to a PC, cases remain drivers for graphics devices. tt offers eldensive control where PC SAS/GRAPH is output to an expensive when creating a custom device driver. Users can take centralized plotting device. One way to do this would be advantage of a device's hardware capabilities such as pie, to upload a graphics catalog. but that will no",Sugi-89-97 Ball.txt
"· output destination and format In Version 6 of SAS/GRAPH® software, many graphics options and parameters used by device drivers are stored in device eata· .. hardware capabilities log entries. By modifying extsting device catalog entries or creat~ ing new entries, you can tailor driver output to your needs without · rows and columns specifying a long set of GOPTIONS for each driver. This paper describes how to use the GOEVICE procedure to manage device .. promptcharacters catalogs, create new entries. and changf!! parameters to obtain · orientation of the graph. desired output. Many of these are parameters that can also be specified on a",Sugi-89-98 McConnell.txt
"The primary special purpose p~ots. The production of report quality gra- approach ~s alternative to the this phics in an efficient manner is very ANNOTATE facility which allows even more important to most analysts. SAS/GRAPH® flexibility, but is more difficult to and especially FROe GPLOT have a number master. points addition technique The of options and added features that allow is quickly and easily applied and allows the user to construct high quality plots the user to gain a large amount of con- qUickly and easily_ trol without the need to master either ANNOTATE or MACRO. Occasionally, however, the user may need APPROACH to create a plot with requirements that do not match the built-in features and options. When this happens, the pro- Primary control of the graph portion of GPLOT plot is through the use of grammer must reach into the proverbial a SYMBOL statements. bag of tricks. There are several tech- These statements tricks that can be used to niques or allow the user to connect pOints and enhance plots produced by PROG GPLOT. specify the character to use when plot- Many of these can be easily and quickly ting points.. All of the figures used in applied even by a new or less exper- this paper make use of various aspects One of the more ienced programmer. of the SYMBOL statement. When the user useful of these techniques (even for an adds points to the plotted data set and experienced user) involves the addition controls how they are plotted using SYMBOL statements, even",Sugi-89-99 Carpenter.txt
"will help you debug those problems that slip through anyway. The Macro facility is a very powerful tool in SASa programming. By the same token, it can cause some STARTING OFF RIGHT: powerful and, at times, intimidating WRITING BETTER MACROS errors. As macros become more complex with increased programmer skill, it An idea for a useful Macro is becomes more and more important to born. The company Macro whiz (the one form a system for writing macros that who was sent to the course) sketches avoids a~ many pi tfal1s as possible. it out on paper, then sits down and Debugging must become more sy'stematic types in the code for the Macro. The and orderly to avoid wasting time and next step should NOT be to test the computer costs. Macro. There are a few steps which This paper outlines some simple should be taken between writing and methods for ensuring that macro code testing which can greatly increase is as clean as possible before testing efficiency and lower cost. testing, as well as methods for testing and debugging macros efficiently and quickly. Modularity",Sugi-90-02 Hubbell.txt
"The Version £ OATA step processor manag<!s the working storage This tutorial- updates- a talk given at previous SUGis that discussed areas- used- by the- DATA step program. Under Version, 5, a variety the functions of the SAS""'supervisorduring the compilation-and -exe- of work areas. buffers, and flags were created and used tocontroi -eution of aSAS OATA step program. Under Version -6 of the SAS execution time processIng, Under Version 6, much of the wor1<. that System, the SAS supervisor provides interface -5efVices at a higher -was-previousl-y-done-at execution -ttme-is'handled-thr-ough the gener- level than before, and its primary actiVity in this oontext is to deter- at~on. of· machine code- speifie-to· t-he-f(d(.lt~oo& beWt~. periln:r:led 8I'ld. mine whether a DATA or PROe step is being invoked. Once is discussed- in- Optimi-zatioR- of Executable tmage later in this invoked ·. the DATA step controls its own environment during-both paper._ln this w.ay.', perior.marlce.is. improved:since:the.logieal; evalua- compile and,executiorr-phases, This- tutoriatpresents alcgical model tions are- perfurmed- at compile- time-once-, and not at execution time- describiflg-both--the--compile-and -execution time actions of-the DATA fOf every' ihptJf observatlbn~ The' strucrure- of the' internal; work areas step processor. has also been changed substantially. In Version 5. the Program Data Vector (POV) was malntalned as a contlguous storage area for aJI the variables rererenced' in- a DATA step- program. fn Version 6, tile",Sugi-90-03 Henderson Rabb Polzin.txt
"For many applications nothing will need to be changed to run an This paper addresses two main issues. The required changes for application conversion from Version 5 of the SAS"" System to existing application under the new release of the software. Although the file structure within the SAS System has changed, this change Release 6.06 is addressed first. Next, selected new features avail- has little impact on the compatibility of existing Version 5 SAS pro- able in Release 6.06 of the SAS System that are not required for grams with Release 6.06. Unfortunately, there is no simple rule that application conversion but can enhance the application in terms of applies to every existing application. Exactly what and how much efficiency, maintainability, or required development time are dis- cussed. needs to change in current production applications depends on the application and the operating system. The following sections dis- cuss three different scenarios.",Sugi-90-04 Thornton Boling.txt
"USING THE STORED PROGRAM FACILITY Joy Reel SAS Institute, Inc. Cary, NC INTRODUCTION the PGM= on the DATA statement. For example, DATA abc; For a number of years, users have asked for the ability to compile their SAS program-s and SET xyz; run production systems from the compiled version of the code. In Version 6 of the SAS (more data step code) software, we have added the capability to do just that. Already available in Release 6.03, now Release 6.06 for MVS, CMS, and VMS RUN PGN=STORED; offers this capability to mainframe and mini computer users. The Stored Program Faciltiy The DATA step is compiled and stored in a SAS allows users of the software to develop file in the work library under the name applications and produce a version of DATA STORED with a member type of PROG RAM. It steps which will execute faster and therefore is a SAS data set, but with a very special reduce the overall cost of running production structure. It can be manipulated with PROC systems. DATASETS or PROC COPY, but it cannot be used with procedures such as PROC PRINT or PROC MEANS. DATA STEP PROCESSING Note that the DATA step does not actually run The SAS System DATA step consists of th ree at this point. Only the compilation is done and different phases of processing: the compiler the code does not show up on the SAS log. To phase, the code resolution and generation run from the compiled code, simply supply a phase, and the execution phase. The code shortened or abbreviated fprm of the DATA resolution and generation phase operates on the step using the PGM=pgmname on the DATA intermediate representation of the DATA step statement. program and data tables produced by the compiler to resolve the types, attributes and DATA PGM=STORED; storage requirements of variables, to allol;:ate RUN; data areas and to output the machine code required in the particular host environment. There are several options available to you to . The execution phase supports the execution of allow for programs to be",Sugi-90-05 Reel.txt
"A STUDY IN REPETITION RESULTING IN A UTILITY MACRO FOR SUBSTITUTION H. Ian Whitlock, Westat This is one form of repetition. Each array statement is INTRODUCTION like the others; only the array name and the prefix change. Aha! It could be handled in a %DO - loop, A utility macro, REPLACE, is presented which can help avoid repetitious macro code. It will be discussed i.e., it can be controlled by rewriting the offending code. (Note: %ARRAYLST generates a variable list in in the context of one of the programs which motivated which each variable name consists of a prefix followed its development. As a by-product of discussing the macro, various macro functions will be reviewed. In by a year/month in the given range. But what %ARRAYLST does or how it is coded is really particular, the quoting functions %NRSTR and irrelevant to the problem of interest: controlling %UNQUOTE are demonstrated in a context which repetition.) makes them a natural part of the macro facility. The macro REPLACE is used to write a sequence of lines which are alike except for the occurrence of one FIRST ATTEMPT - AN INTERNAL SOLUTION sequence of characters. An important feature is that macro calls and macro variables are resolved after A first attempt might be to set up an array of macro replacement when %NRSTR is used in the call. For variables V1 to VB representing the changing part of example the call: the line. Remember the Ith element in the array is referenced by &&V&1. Thus we obtain: %REPLACE ( LIST~ FIRST SECOND THIRD, %LOCAL I VI V2 V3 V4 V5 V6 V7 V8 TARGET= %NRSTR ( IF 0 < XXXX < 10 THEN %XXXX;) /* INITIALIZATION */ %LET VI BN %LET V2 CITP will produce the code: %LET V3 CMDT IF 0 < FIRST < 10 THEN %FIRST ; %LET V4 DITP IF 0 < SECOND < 10 THEN %SECOND %LET V5 NOCT %LET V6 IF 0 < THIRD < 10 THEN %THIRD ; OMSG %LET V7 RPCD %LET V8 STMN /* MAKE ARRAY STATEMENTS */ THE PROBLEM Consider the following segment of code (taken from %00 I = 1 %TO 8 ; the motivating program shown in FIGURE 1 at the",Sugi-90-06 Whitlock.txt
"DATA REDUCTION AND SUMMARY STATISTICS IN THE DATA AND PROCEDURE STEPS EFFICIENCY CONSIDERATIONS Michael Hein, ARC Professional Services Group Judith Mopsik, ARC Professional Services Group PC/386, 2Smhz, under MS-DOS, using SAS 6.03 INTRODUCTION (referenced as PS) One of the most common data processing tasks is the calculation and summarization of descriptive statistics. Selecting the best MicroVax II under VMS, using SAS 5.18 (referenced as VS) SAS technique requires the evaluation of several factors: IBMl3090 under MVSlESA using SAS 5.16 (referenced as What summary statistics are to be produced; MS). For the purpose of this paper, efficiencies were measured against How large the data set will be and how often the calculations methods not platforms. Factors such as how a system is ""tuned·, will be required; the version of the operating system, and the number of What the skill level of the programmer will be; simultaneous users, would bias any comparisons between platforms. In addition, we often do not have a choice in the What hardware platform will be used in conjunction with what platform we have available, but we always have a choice in the operating system and version of SAS®. approach we select in solving a given problem. Depending on the statistics that need to be computed, there may METHODOLOGY be many ways or only one way to produce the results. PROe UNIVARIATE. for example is the only Procedure that calculates The summary statistics produced by the Procedures SUMMARY I medians, quartiles and modes. However. if the task is simply to and MEAN are common outputs of any computer process. In the compute the means of subgroups of observations, the examples that follow, each process started with identical input Procedures SUMMARY, MEANS, TABULATE or UNIVARIATE can data (see Figure 1 for the PROC CONTENTS describing the two accomplish the job; or the calculations can be handled in the Data input data sets used) and was required to generate a SAS data set with onl",Sugi-90-07 Hein Mopsik.txt
"file to the list of parameter files. The system will automatically add the new file to the parameter file maintenance window. This struc- ture ensures flexibility and ease of maintenance. Screen Control Language (Sel) is a programing language that pro- vides functions and routines to control fields on windows and screens to manage the windows and screens that make up an appli- MENUS cation. With Sel, the SAS"" programmer can · perform real-time cross-validation of variables In any interactive application, menus are used as the mechanism to access the functions of the system. SCl, used along with · control the application and interact with the SAS System SAS/AF'"" software, allows for several types of menus. This section illustrates some of those menu types and explains the positive and · control access to, and obtain information from, SAS data negative aspects of them. libraries MENU Entries · control communication in an application. Through MENU entries within SASfAF software, the programmer · control error handling and provide messages specific to the may build menus that provide lists of selections to users. Chosen application selections are accessed through additional MENU entries, PROGRAM entries and so on that navigate the user through the This tutorial demonstrates that Sel provides the power and flexibil- application. MENU entries require that no SCL be written in order ity needed to build all types of applications, from simple programs to execute the user's choice; a select option is used. MENU entries that accomplish a few tasks to sophisticated SAS systems. however do require that the user provide a selection value. PROGRAM Entries",Sugi-90-08 Septoff.txt
"&&&&&&&&&&SAS -- RESOLVING THIS AND OTHER SAS® CODE CHALLENGES Warren Repole, ARC Professional Services Group Michael Hein, ARC Professional Services Group Veronica Fasullo, ARC Professional Services Group Kita Garrido, ARC Professional Services Group Puzzle 3; User·defined macro functions Puzzles are a source of learning and amusement lor millions of people worldwide and have been for centuries. Crosswords, You are coordinating a round-the-clock interactive data collection anagrams. math problems and geometrical puzzles serve as both operation implemented through SAS software. There are six 4- recreation and tools to sharpen reasoning and vocabulary. In hour shifts each day: midnight to 3:59 am, 4 am to 7:59 am, 6 am this spirit. this paper presents a series of questions which to 11 :59 am, noon to 3:59 pm. 4 pm to 7:59 pm, and 8 pm to 11 :59 demonstrate the variety of the SAS software available and the pm. Each shift is divided into four 1-hour functional segments: power and complexity of the SAS system as a processing set-up and preparation. primary data collection, secondary language. The puzzles below are a cross-section from the whole (follow-up) data collection, and wrap-up and reporting activities. SAS system with examples concerning functions, macros, options, formats and combinations of these and other aspects of When an employee logs into the computer system. the software the software. We hope that the techniques demonstrated in the must automatically determine which function should be active at puzzles and solutions below will give you tools which are useful in that time of day and execute the corresponding part of the all facets of application development. Therefore, to follow a interactive system. centuries old tradition involving people and puzzles, enjoy and learn. Using SAS software macro capabilities. how would you implement a solution? Puzzle 1: Titles and footnotes Puzzle 4: Macro variable resolution You are producing a simple PROC PRINT listing",Sugi-90-09 Repole Hein Fasullo Garrido.txt
"1.2 SQL Overview The use of relational database technology is growing rapidly. IBM'S relational database, Structured Query Language (SQL) is used to OB2, is widely used in large IBM mainframe communicate with 082, no matter what installations. systems developed using language, be t~at COBOL, ~AS/9B2 Software, relational technology are primarily used for etc., is used 2n the app11cat10n. The . data reporting and analysis. These functions statements that comprise SQL are grouped 1nto are normally performed by high level the following categores: languages such as the SAS System. SAS/DB2 Software is the interface between the SAS Data Definition Language: includes the System and DB2. Users should be aware of statements CREATE, ALTER, and DROP, which DB2 performance considerations prior to perform utility-type functions on DB2 running a SAS/DB2 program to extract the data objects. ' required for reporting and analysis. This paper will use SAS/DB2 software to examine Data Manipulation Language: includes the DB2 performance issues. statements SELECT, UPDATE, INSERT, and DELETE. Th~ SELECT statement is used t? extract data stored in DB2 tables and 1S the most frequently used SQL statement. UPDATE, INSERT, and DELETE statements ar~ 1.0",Sugi-90-10 Brown.txt
"NEW ARCHITECTURE Converting the philosophy of productivity from words into books for Release 6.06 of the SAS'"" System marks the beginning of a new era for SAS documentation as well as for SAS software. SAS Institute Release 6.06 meant moving away from the way books were written in Version 5. We had to evolve a new architecture for the library. started with a philosophy stating that books are not just infonnation, they are productivity tools. Finding that SAS users are diverse in their needs, we developed a new library architecture, one that pro- Version 5 Architecture: All-Purpose User's Guides vides two types of book for learning tasks and one type for looking Our previous documentation centered on a ""User's Guide"" for each up features. product. This book tried to be aU things to all people. For example, for a given feature of base SAS software, you might find a descrip- As the library has grown, the task of selecting documentation has tion, an example, and some footnotes about how the option differed grown more complex. New services are planned that will make this on different operating systems. task simpler. For the future, we intend to continue to improve the quality of documentation by writing new books, involving users in As products and featUres were added and the SAS System spread evaluating them, and exploring new technology for online access to new operating systems, the amount of information per feature to infonnation. grew, and so did the difficulty of using the documentation under the old architecture. We noticed two contradictory trends:",Sugi-90-100 Gough Gargan.txt
"information easy for both novice Knowing information in teday's time-squeezed, communications- and experienced SAS users. For tt1e SASle Compiler, Version 5, crammed society is 01ten less important than knowing where to find and Version 6 master indexes, a code of up to five letters is assigned that information. Indexes, as pointers to information, have become to eact1 document. Codes relate logically to the documents they ref- our quick references to the world. Without them, we'd be hard- erence; for example, in the Version 5 index, the SASlOW User's pressed to locate an unfamiliar street, find a good Italian restaurant Guide, Version 5 Edition is coded OR. while on vacation, or even resole our shoes at the leather repair shop in the newly opened mall. Numbers following tt1e codes indicate the page or pages on whict1 the information appears. Hyphenated numbers mean tt1e referenced For information about SAS software, you'll find everything you need information continues over -a range of pages. in SAS Institute's four master indexes. The master indexes-to the SUGI Proceedings and to documentation for Version 5, Version 6, SUGI master index entries list the year of tt1e Proceedings and the and the SAS/C"" Compiler-are your maps to the SAS System. Used page number of the referenced information, separated by a colon. effectively, they enhance your computing power by directing you to Updated version master indexes also follow tt1is form, separating information quickly and accurate",Sugi-90-101 Editorial Services Group.txt
"ONLINE CUSTOMER SUPPORT FACILITY ACCOUNTS SAS Institute's Online Customer Support Facility is a free bulletin board·type system that the Institute uses to provide 24-hour com- Regular users of the Facility need a pennanent account. You can munication with customers. The support facility's main purpose is register for an account by entering the following responses after to provide technical support. The following technical support-related dialing in: services are provided: FIRST NAME: NEW · ability to track problems LAST NAME: USER · access to aU production zaps and corresponding Usage Notes SITE NUMBER: 00000000 · access to problem alert letters PASSWORD: NEWUSER · ability to upload and download files associated with After logging in as new user, you are guided through a questionnaire outstanding problems or questions. that asks for your name, phone number, site number(s), and com- pany name. Since many companies have more than one site license, Other services that are not directly related to technical support are you can register up to three site numbers. Once you have provided · ability to view training course schedules the information in the questionnaire, your account will be available a within 24-hours. You will be asked to choose password for future · ability to order publications log ons the first time you use your new account. · ability to browse Institute-related announcements. For users who need access to the Facility immediately or users who log on infrequently. a guest account is available. Enter the following In addition to a general overview of the support facility, this paper responses after dialing in: gives several tips that will help SAS"" Software Representatives and SAS Software Consultants effectively use the Online Customer FIRST NAME: GUEST Support Facility to provide on-site support to SAS users. LAST NAME : ACCOUNT",Sugi-90-102 Schleich.txt
"The Process The process is outlined in figure 1. The first step is to SASIGRAPH® is an excellent tool to graphically summarize access the VAX computer using the Macintosh as a data. However, customizing a graph (positioning labels, terminal. Then using SAS/GRAPH and a device driver (an adjusting spacing. etc) can be tedious and difficult. One attribute file). a text file is generated that contains drawing option in SAS version 5.18 is to use the ANNOTATE = utility. instructions (a metafile) for the graph. The metafile is but even an experienced user can find it difficult. An downloaded to the Macintosh as a text file. On the alternative is to generate the basic graphics code on the Macintosh the META application translates the drawing VAX® using SASiGRAPH, then download this code to the instructions into a graph {saved as a PICT file}. Finally the Macintosh®. The graphics code can then be converted to a graph is ""polished"" in MacOraw and pasted into a Microsoft format compatible with a Macintosh graphics application. word document This conversion is accomplished with an application developed by SAS Institute, Inc. called META. Once the Figure 1 graph is on the Macintosh, customization is a matter of point and click. The graph can be incorporated into final papers and printed easily on laser printers. Access VAX using communication",Sugi-90-103 Whiteside.txt
"COMPARISON OF SAS/GRAPH* WITH OTHER MAINFRAME GRAPHICS SOFTWARE LeRoy Bessler, Miller Brewing Company leu ·· means extra-cost item SAS/GRAPH TELL-A-GRAF IBM dominant market SAS System most Context part of collection of force in general-purpose popular data analysis graphics specialty tools, computing some of them unique tool in the world SQL/DS (in QMP'); SAS/SQL-DS""; DATA Data Sour"""""" DB2 (in QMF""); SAS/DB2""; CONNECTION""; FOCUS (in FOCUS); FOCUS extract; FOCUS; external files; external files; external files; typed-in data typed-in data; SAS files typed-in data mainframe only mainframe, mini, PC: Portability & not PC all ""saIIle"" language Compatibility may be fastest may be slowest Speed non-IBM: complex or extremely wide extremely wide Hardcopy Device impossible; extra cost compatibility compatibility Interfaceability rigid syntax; User Interface somewhat forgiving; menus, fill-in-the-blanks screens, Display Manager, ""English-like"" or command-file and online help conversation, (lCU: Interactive Chart submission, or command-file Utility) or line-mode entry submission no yes yes Batch Processing results always ""useable"", Adequacy of Defaults results may be unuseable results may be unuseable not necessarily elegant very good SAS experience needed Novice/Occasional Use CUECHART"" excellent no no Programmer's Tool no, Annotation Graphic Editor yes yes, PINPOINT"" yes no no Maps yes no Plot 3 Numeric Variables no interactive interactive or batch Graph Catalogs IVISS MANAGER"" graphs imbedded in Text/Graph Integration graphs linked to graphs linked to DCF"" text, or linked to PROFS"" note PROFS"" note PROFS"" note can invoke CMS & TSO ""hot_key"" access from pre-defined ""stencils"" Special Features commands and other QMP'; no data (CUECHART""); software from SAS; tabular presentation mapping needed ""BY processing"" (TABLES"") VBAR--must Annotate best implementation Labels at Ends of option; but, if HBAR, not simple HBAR--automatic Bars in Bar Charts of option always NN.NN%: may Pie C",Sugi-90-104 Bessler.txt
"OVERVIEW OF SAS/GRAPH(R) PROCEDURES AND FACnxnES Vincent Tillman, Tennessee Department of Revenue the name implies, charts and plots. However, these Using non.SAS/Graph Techniques graphs are output using normal ASCII characters, for instance, the bars in a bar chart are simply rows of Proc Print; Proc Tabulate; Proc Freq ; __ _ asterisks (*). The graphics procedures of SAS/Graph Most SAS"" output is based on a SAS procedure. In require output to devices that display, plot, or print images some sense, all output is graphic in nature. Tile objective in a true graphics mode. The SAS/Graph procedures all in producing presentable output is that it be easily read start wtth the letter G, for Graph. Thus, the SAS/Graph and the message be apparent. Several features in the counterparts of Chan and Plot are GChart and GPlot, non-Graph side of the SAS system help. Many of the respectively. features of SAS/Graph are simply extensions of basic SAS SAS/Graph procedures get their data from a SAS dataset statements, adding options for posttioning and color. Options specific to these procedures allow the frequencies, sums, groups, etc. to be determined by each Titlen 'text'; Footnoten 'text' ; procedure. So there is usually no need to pre-process the SAS software allows mling and footnoting output wtth up data before calling the graphiC procedure. to ten lines of text. The procedure output is adjusted to fit on the page between any ttties and footnotes. The area for Outputting SAS/Graph output follows this sarne rule when outputting to a screen or other graphics device. A tttle remains in Format; Label; effect until a lower numbered tttle is submitted below it The Label; and Format; statements affect SAS/Graph The tttle thus effects output of procedures which follow tt. output just as in normal SAS procedures. The Label; A tttle will affect a procedure above tt when tt falls before statement replaces a variable name in the output. A the Run; statement or the next Data; or Proc; stat",Sugi-90-105 Tillman.txt
"This talk describes a set of SAS macros which provide the Logo is a computer language designed to make computing ability to draw with the SAS/GRAPH® ANNOTATE facility easily accessible to young children (Papert, 1980) in an using the ""turtle~relatrve"" drawing commands of the Logo educational setting. Part of its appeal is an extremely simple yet flexible graphics component, called ""turtle graphics"". language, rather than absolute X·Y coordinates. This makes drawing much easier for many types of figures. However. Logo is actually a descendent of Lisp. and was designed to provide powerful programming features for Another key feature of Logo is recursion, which also experts as well as novices; see Friendly (1988). simplifies many graphics procedures, Since the SAS data Logo Turtle Graphics step has neither local variables, nor recursion, it is hard to some things that are very easy in Logo. However, SAS macro variables are local variables, and recursive macros Contrast the SAS.GRAPH annotate DATA step above which model Logo procedures can be defined. A variety of with the following command in the Logo language: Logo-like designs carried out with SAS/G RAPH are REPEAT 5 [ FORWARD 50 RIGHT 72 I illustrated. This command. entered interactively to the Logo system, causes a pentagon to be drawn on the screen. The Logo",Sugi-90-106 Friendly.txt
"is accomplished in the Template Design Screen accessed through PROe GREPLAY. The The TEMPLATE facility in FROC GREPLAY is user designs a screen or plot which designed to display one or more graphs on includes one or more panels. Each panel a single screen or page. It is possible contains a graph or plot which was created to position the individual graphs so as to at some previous time. produce a collage which creates the overall desired effect. At first glance Each panel and graph has four corners, many users find using the TEMPLATE although Rooth (1987) showed that this is facility difficult, however, a simple not strictly true, and are denoted as basic understanding of the relationship of lower left, upper left, upper right and the plot to the template coordinates makes lower right. 'It is important to remember the creation of interesting and unusual that these are the corners of the graph as displays quite easy. it was originallY created. The corners are placed on the plot or screen using the Directed toward the new and intermediate coordinates designated in the template user of PRoe GREPLAY, this paper explains design, see figures 1 and 2. in simple terms the steps required, from perception to plotting, for the creation of a tailored template. The primary --.. -- ,00."""""" . examples used to illustrate the process {O,l00J ... include rotating within a template, zooming in on a selected portion of a graph and pasting the enlarged graph e within a second template. A",Sugi-90-107 Carpenter.txt
"If an Axis is Too Long for the PAGESIZE=, LlNESIZE=, HSIZE= or VSIZE= Options ·.. PANELIZE Routines Warren Repole Jr., ARC Professional Services Group Introduction Following is a general description of the plan used to divide up an axis. (An illustration is also shown in Figure 1.) For purposes of this explanation, we will use a bar chart application. Using the SASID System to produce bar charts (histograms) or scatter plots with character axis values can be troublesome Pretend that all bars are printed on a continuous sheet of when there are too many values to be placed on a single axis. paper of great length with a small margin on each end of Sometimes a procedure will adjust the output, lor example, the sheet between the printed bar and the edge of the printing lick mark labels vertically or switching VBAR charts to paper. HBAR charts. In other cases, the axis is truncated or an error indicates insufficient dimensions to produce the output. Cut this long sheet into pages no longer than the desired size making certain that the cuts occur between bars. The PANELIZE routines were developed to systematically split a single chart or plot into multiple pages based upon the Voila!! A ·panelized"" chart. underlying data and custom options including GROUP= and BY- variables. The maximum number of bars or character tick marks When dealing with side-by-side charts produced by specifying per page is the basic parameter. The algorithms addressed in the GROUP= option, the individual group values are treated as this paper are appropriate for procedures in both base SAS bars in the above representation. In this way, no group will be (PLOT and CHART) and SAS/GRAPH® (GPLOT and split between two separate panels. GCHART). It should be noted that an option is available in PROe PLOT in Terminology the PC environment that can produce plots that span physical pages. The HPERCENT option generates a single large plot by placing sections of the output on successive pages which can To clari",Sugi-90-108 Repole.txt
"run. Global variables are The Executive Financial DataBase of Bowman GraySchool of Medicine of Wake Forest University has evolved into a system containing over initialized and formats created. 7,000 entities, with over 5,000 graphs produced yearly. To aid in the %PUTSYM - (Fig 4) Data step access with the point option is used to development of the system, SAS!APt, SASIFSpe, SAS GrapbtD and the read observations in the ""batch"" dataset one at a time. Several CALL SAS Macro Languagee were used. A process for generating graphs in SYMPUT statements output the values of the macro variables used in the background was added to aid in the work. later steps. Introduction: ""EXTRACT - Obtains the data needed for the selected year range. The Executive Financial DataBase of Bowman Gray School of Medicine %PREPARE - Processes the data pulled by %EXTRACT and calculates of Wake Forest University has evolved into a system containing over the maximum and minimum values, etc. to be used in subsequent steps to 7,000 entities with annual data elements dating from 1954. Over 5,000 format and scale the graph. graphs are produced each year, which provide strategic information on funding sources and usage, research and development, salary and budget. %ANNOf ATE - Determines the placement of the line labels and outputs the annotate data set used by the GPLQT procedure. Originally written in interactive Fortran, the system was implemented using SAS Software in 1987. Several enhancements were added, %PLO",Sugi-90-109 Phelps.txt
"A BLUEPRINT FOR INTERACTIVE PC-BASED APPLICATIONS DEVELOPMENT Aiman M. Zeid HAY Systems, Incorporated INTRODUCTION factors, these steps take different shapes and priorities. For instance, imagine dealing with two hypothetical Developing a soltware application system is clients, A and B. Client A spent a great deal of time probably the most challenging and rewarding task in a defining system requirements, data sources, and the Data Processing career. Software developers have a long expected output from the system being developed. All list of issues and problems to consider and resolve. The these dffferent essential elements have been reviewed contents of this list, however, vary depending upon the and presented to the developers by client A. Client B, on size of the project, the type of the application, and the the other hand, has a vague idea about what he wants and language used. among other factors. The intention of this depends on the software developer's assistance in paper is not to provide this long list of issues, nor to defining these essential elements during the process of recommend solutions for those problems. The intention, developing the software. Clearly, the process of defining however, is to discuss and highlight some common topics the system requirements, the first step in systems specific to any interactive PC-based software application development, is much more significant and time development effort using the SAS® system version 6.03. consuming in the case of client B compared to client A. This tutorial includes the following topics: Generally, the following steps will be included in any t. General and essential steps in developing a PC- approach to the process of systems development: Based system DEFINING THE SYSTEM REQUIREMENTS 2. Hardware and Software requirements What exactly are we trying to accomplish? Is ~ one 3. Overview of the SAS system files and or two types of analysis? Or is it a list of ten or twenty subdirectories reports? Maybe",Sugi-90-11 Zeid.txt
"USING SAS/GRAPH SOFTWARE TO DETECT MEDICAID FRAUD Terry Allen. Utah State Bureau of Medicaid Fraud 191 East 6100 South Salt Lake City, Utah 84107 FIGURE 4' (GPLOT) This type of line The Utah Bureau of Medicaid Fraud graph allows us to see when interesting is charged with pol.icing frQ.ud and abuse changes occur in a providers medical in a $250 million a year state medicaid It also pinpoints a ti~e for practice. system. This syst.em processes investigators to target in their approximately 100,000 claims each month. Figure 4 shows that a investigation. In the past, the sheer volume of claims major change occurred in either the precluded effective analysis to detect provider's medical practice or her specific fraudulent doctors and billing practice around August 1987. fraudulent methods. SAS/GRAPH software effectively presents masses of FIGURE 5, (GCHART) After comparing all observations in a single visual, making pediatricians with their peers we it possible to detect fraudulent trends targeted seven, or about three percent and to compare medicaid doctors with of the total, for more investigation. their peers. Using hundred-percent bar charts we compared the targeted three percent with their peers. A very dramatic difference shows up in the graphic at the extended EXAMPLES and comprehensive levels of service. In this case three percent of all pediatricians were responsible for about FIGURE 1: (GSLIDE) Here is general eighty to eight-five percent of all information on established patient office code billings in the two highest office visits. procedure codes and levels of service. maximum charges allowed by Medicaid. The services range from ""minimal FIGURE 6' (GPLOT) This scatter plot service"" where a provider might give a shows the number of hours for which an shot or take someone's blood pressure to individual psychiatrist billed medicaid ""comprehensive service"" where a provider each day for psychotherapy. We might spend an hour or more with the naturally become inte",Sugi-90-110 Allen.txt
"When it was realized that the results from PROC GCHAAT were not adequate, an ANNOTATE= data set was cre- This paper describes the steps taken to create unusual ated. Both methods and their limitations are described vertical bar charts for a set of data using an ANNOTATE= here. data set and PROC GANNO. The Questionnaire Creating bar charts with the SAS/GRAPH® PAOC GCHAAT is straight forward if the data, and the output desired, fall Students in different years of a professional college within PAOC GCHAAT'S capabilities. PAOC GCHART creates were asked to respond to a 53-item questionnaire vertical bar charts by summarizing one or more vari- which used a 4-point scale. Two examples of items ables from a data set. The bars onthe chart represent were: categories or discrete groups of one variable. The I usually set out to understand thoroughly the project described in this paper required one bar chart meaning of what I do. for each observation with the values of fourteen vari- ables represented by bars. When proc gchart cannot I like to play around with ideas of my own create the chart requiredANNoTATE= data sets are good related to what I'm studying. alternative. The scale options and values were:",Sugi-90-111 Wallace.txt
"., April 3, 1990 J. Jacob Wind and Jeff VanGorder. American Management Systems. Inc. ABSTRACT POLYGON MAPS We use SAS/GRAPH software to develop Geographic Information System (GIS) tools for federal and state environmental agencies. Chor<) Map of EPA's Toxies Release Inventory (TRl) In this paper, we illustrate BAS/GRAPH maps, including 3-Ds, and Total Releases and Transfers by County in Tennessee show several special techniques. We demonstrate an interactive mapping ~ystem using SAS macros and SAS/GRAPH tools. We also discuss pitfalls you are bound to enoounter. This paper draws on our previous work, ""Taking the Best Advantage of SAS/GRAPH Software's Geographic Information System Tools,"" SUGI 14, San Francisco, 1989, and ""Using SAS/GRAPH Software to Integrate and Analyze Environmental Spatial Data,"" with R.W. Matheny, Best Contributed Paper, SUGI 13, Orlando, 1988. !lII1 ,.' THllUS~NDS or ~ Las 0·1 A Good GIS MUST Provide These Features: Il!l!i'"" 116.125.112 · Store Geographic Base Files - Polygons - e.g., County and State Outlines - Points - e.g., Facility LatitudclLongitudes - Line Segments- e.g., Rivers and Streets Prism Map of the Same Data · Store Attribute Data · Produce and Print Maps · Catalog, Store, and Retrieve Maps SAS Provides These Features Quite Well A &a11y Good GIS SHOULD Provide These Features: · Overlay Maps Automaticaliy · Support Digitization of Printed Maps · Edit Base Files Interactively - Click on a Change to Save it into a Base File For These Features",Sugi-90-112 Wind VanGorder.txt
"calls, and spend more time working The ability to respond quickly to on machines, and less time driving customer needs is a key element to the around on the roads. The ability to success of any service-oriented do ""more work with less people~, organization. Given that a good network means that some of the Customer of roads exist, selecting optimal branch Service Engineer (CSE) workforce may locations to minimize physical distance be freed up to perform other work between a service organization and its where a manpower shortage exists. customers will benefit both the customer and the service provider. 5. Employee job satisfaction is increased In that CSE's would prefer The present paper employs SAS/GRAPH* to to spend their time working on the examine the geographical relationship challenge of machine repair, rather between customer service branch locations than driving a van or an automobile. of Digital Equipment Corporation (DEC), and the distribution of service call The bottom line is that optimal siting is volume within the northern half of the a ""win/win/win"" scenario for the State of New Jersey. A visual customer, DEC, and the employee. presentation of the data aided greatly in detecting less than optimal branch The problem is then twofold: locations I and in helping upper management understand both the problem l (l) Identifying optimal branch locations and some proposed solutions. with respeqt to customer needs, and (2) Communicating the nature of the problem, as well as some possible",Sugi-90-113 Wederich.txt
"SUB SETTING AND COMBINING SAS' MAP DATA SETS TO PRODUCE CUSTOM MAPS Susan J. Slaughter. Consultant STATES data set uses the US Postal Background Service's FIPS codes for an id variable. The id variable may have Sophisticated mapping capabil- different names. For example, in the ities set SAS/GRAPHl apart from many STATES data set it is called ""state"" other graphics packages; yet using while in the CANADA4 data set it is these maps is. for the most part, called '·province."" like using a series of black boxes. PRoe GMAP. The mapping procedures: Segment is an arbitrary number GPROJECT. GREDUCE. and GREMOVE are that is shared by all the points that some of the most inscrutable proce- form one continuous polygon. In the dures in the SAS arsenal. It needn't STATES data set each state has its be this way; understanding a few own segment number; in the CANADA4 concepts can enable you to flexibly data set each province has its own and creatively manipulate maps. segment number. Using only the map data sets Not surprisingly, the x and y that come bundled with SAS/GRAPH you can map the us with its individual coordinates indicate location and can be expressed in two different ways. states and counties, and Canada with If the map is unprojected, then x and its provinces and census districts. y represent latitude and longitude Many other map data sets including measured in radians. For projected international boundaries and US maps, x and yare expressed in units census blocks are available from the internal to SAS. The difference SAS Institute and from other compa- between these two ways of expressing nies. x and y coordinates turns out to be extremely important. The SAS/GRAPH manual includes examples of how to isolate an Some map data sets contain a individual region such as a state or fifth variable, density, with values group of states, and how to remove from 1 to 6, which can be used to boundaries between states creating reduce the resolution of a map. larger regions. Howeve",Sugi-90-114 Slaughter.txt
"put on a single ~ useful to understand some of the basic attributes of a page is a powerful and efficient presentation tool but graphic page in SASjGRAPH and how these features are unfortunately is often difficu~ to program. This discussion hardware device dependent (terminals, plotters, laser addresses several aspects of the methodology and printers, etc.). A graphic page in SASjGRAPH is made up problems of image distortion associated wtth programming of a series of rows and columns that form a grid-like these types of graphics usin§. SASjGRAPH- software. pattern made of cells. Each type of graphiC display Techniques presented in SAS documentation and at device has its own default grtd pattern. Regardless of the previous SAS Users Group Intemational (SUGI) type of display device (terminal, printer, or plotter) the conferences have discussed various methods including the smallest addressable display unit is the pixel. For plotters use of SAS procedures PROC GREPLAY, PROC GPLOT or other devices that display vector-based images this is overlays, and the use of the SASjGRAPH Annotate facility. sometimes called the plotting unit. The combination and Creating a page of mu~iple graphic output is especially position of pixels on a page form the graphiC image. challenging when using graphics generated from different Information about the number of pixels and the resolution procedures (GCHART, GPLOT, G3D, etc.). of the graphic grid can be readily accessed through SAS/GRAPH hardware in",Sugi-90-115 Mitch.txt
"MAKING MORE WITH LESS - INVENTING THE THREE-DIMENSIONAL PIE CHART USING RELEASE 5.18 OF SAS ® SOFTWARE Elizabeth A. Werth, Texas-New Mexico Power Co. INTRODUCTION %MACRO XLABS; %***,... GET USER INPUT *u** ; %GLOBAL PCOL PPAT CLINE XPCT YPCT Our company was looking for a way to show OTHER; graphic data in a three·dimensional pie chart without purchasing additional software. Our computing DATA NULL; environment included Base SAS®, SAS/GRAPH®, FILE TERM NOTITLES; both version 5.18 for CMS and Base SAS®, CMS CLRSCRN; SAS/GRAPH® for personal computer. A Hewlett . PUT @20 'ENTER PIE·COLOR PIE-PATTERN Packard 7550A plotter was connected to a PS2/50 PIE·OUTLlNE·COLOR' ; IBM personal computer. Communications software RUN; enabled file transfer between the PC and mainframe. %INPUT PCOL PPAT CLINE; DATA NULL; FILE TERM NOTITLES; PROGRAM INPUT PUT / / @20 'SPECIFY PIE SIZE IN X·DIRECTION(PERCENT)'; User instructions are 'put' to an IBM 3192G RUN; terminal. A line of information (items are separated %INPUT XPCT; by ,/') for each pie slice (label for the slice, slice size DATA NULL; in percent, slice color and pattern) is entered at the FILE TERM NOTITLES; terminal. Error checks insure that total percentage of PUT / / / / @20 'SPECIFY PIE SIZE IN slice sizes doesn't exceed 100 and that four parameters Y·DIRECTION(PERCENT)'; are input for each slice. RUN; %INPUT YPCT; %MACRO GETLABS(SET,INFO); DATA NULL; %***** GET USER INPUT U*-. ; FILE TERM NOTITLES; DATA&SET; PUT / / / / @20 'SPECIFY LABEL FOR LENGTH SLINE $ 50; REMAINING PART OF PIE '; FILE TERM NOTITLES ; RUN; CMS CLRSCRN; %INPUT; PUT @1O 'CONSULT SAS·GRAPH MANUAL %LET OTHER = &SYSBUFFR; ON VALID OPTIONS' / %MEND XLABS; @1O 'FOR COLORS, PATTERNS, TITLE HEIGHTS AND' / User inputs are captured from the system buffer and @lO'SEPARATE MULTIPLE ENTRIES stored as global macro variables. Code excerpts to WITH A SPACE.' / capture and store input are : @lO'YOU MAY USE SPACES OR QUOTES WITHIN A LABEL'/ %MACRO GETVAL; @1O 'GIVE SLICE",Sugi-90-116 Werth.txt
"· General Parametrics Videoshow~ Display System Users of SAS/GRAPH@ software in Version 6 of the SAS"" System will find that most of their programs developed for Version 5 applica~ Version 6 of SAS/GRAPH software also provides native device driv- lions will run without modification. However, a number of new fea- ers for use with the IBM 4224 graphics printer under the OS/MVS tures have been implemented that expand the capabilities of the and VM/CMS operating systems. These native language drivers software. Along with these new features, Version 5 to Version 6 mean that graphics output on the IBM 4224 will be possible without compatibility issues will be discussed. the use of GDOM. For MVS sites, SASWTR cannot be used to spool graphiCS produced using the IBM4224 driveL An alternate spooler, such as VPS or JES328X, must be used.",Sugi-90-117 Poindexter.txt
"NEOVISUALS tul SOFTWARE: YEAR ONE AT THE UNIVERSITY OF GUELPH Anthony R. Mackay, University of Guelph This presentation is on videotape and Sciences has produced an instructional chronicles the developments which took videotape on the mathematics of wave place <;I.t the University of Guelph motions and the SUGI 15 tape contains following the introduction in 1989 of the excerpts from this. NeoVisuals 3-D modelling and animation package. As some SUGI attendees will be unfamiliar wit_h modelling and a~imati.on Many of the colleges at the Guelph campus technologies, a section of the tape were quick to realise the potential of contains a short tutorial on the this new addition to the software library modelling process used in the canine and started utilising NeoVisuals for motility study. Details of a proj ect making videos for presentations, for investigating low cost urban housing is research and for teaching purposes. also demonstrated. Excerpts from some of these projects are As NeoVisuals has become i~tegrated into reproduced on this SUGr 15 presentation tape and an overview of some of these the mainstream of computer graphic undertakings now follows. simulation over the months, the animators at Guelph have gradually built up an Initially considered a tool primarily for object library which contains many useful research, it soon became apparent that it everyday objects which can be called up also showed great promise as a teaching on demand and used many times. A aid and this encouraged lecturers and selection of these is shown. students at the University School of Landscape Architecture to begin using it On the lighter side, the tape contains an to produce animation sequences as course exci ting opening sequence depicting project assignments. planetary motions and collisions. This should appeal to astrophysicist and The first opportunity to use the software science fiction fan alike. Similarly, for ""production"" research came when a the closing shots comprise sever",Sugi-90-118 Mackay.txt
"Future Directions for NeoVisuals® Software Rick Edwards. SAS Institute Inc., Cary, NC INTRODUCTION video animation system. Additionally, the functionality of NeoVisuals will be used for other new products as well In the summer of 1988, SAS Institute, as providing new graphics capability Inc. acquired a three-dimensional for the entire SAS system. modeling, rendering and animation software company called Neovisuals, The objective of lhis paper is to Inc. Based in Toronto, the company highlight the first manifestations and its software propelled the of this union and provide glimpses Institute into an arena of programming into the longer range plans. In doing that is one of the growth areas of our so, we will discuss the history of industry. Recent organi2ational NeoVisuals, the efforts of the past changes combined with the constant year, the immediate directions of the evolution of graphics workstations and coming year, and the goals for the terminals have made the qUestion, years following. Due to the fact that ""What is the future direction of names for the upcoming products have NeoVisuals· ?"", very timely. This not been chosen and/or registered. paper will address that question as names have been selected to label them thoroughly as possible. We are and will be written in lower case to working at this time to add this indicate their unofficial status. excellent software package to the NeoVisuals will still refer to the other fine products of the SASe current stand alone product. system. Within the next year, there Sas/vista will be used for NeoVisuals will be two new SAS products derived migrated into the SAS system and from the current stand-alone software. sas/graph+plus for a hybrid SAS/GRAPH As work continues into the future, and NeoVisuals product. additional products and enhancements will follow, which will benefit the NeoVisuals product as well as the HISTORY entire SAS system. There is a possibility that some of Neovisuals, Inc. (NVI) was founded by Steve",Sugi-90-119 Edwards.txt
"Effectively Using the FSEDIT Procedure Howard Levine, Levine Software Systems Introduction Introduction to Proc FSEDIT Proc FSEDIT is an extremely useful procedure for editing SAS data sets interactively. Use of In order use a procedure effectively, it is the Screen Control Language (SCL) with version 6 necessary to understand what its options and of the SAS® System makes the procedure much statements are and what it can do. Only points of more powerful. In this paper, I will cover the interest that I feel important will be covered. following points; This is not meant to be a substitute for the procedure documentation in the SAS/FSP@ Users' Introduction to Proc FSEDIT Guide. Proc FSEDIT Options The following points are the distinguishing features of Proc FSEDIT: Proc FSEDIT Commands Used for editing SAS data sets in a Full Proc FSEDIT Screens - Basic Screen mode Using Formats and Informats - Basic Is observation (or record) oriented Restructuring data for easier editing Allows validation of fields (limited in Version 5) Using SCL Allows extensive validation and cross validation of fields (Version 6 SCL) The most important thing to remember with any Calculated fields can be displayed (Version interactive editing technique is that there are 6 SCL) three basic characteristics that 3re desirable. editing should be qui c k, e a s y, and The Full screen editing is a minimum requirement accurate. Any data editing programs should be for an effective data entry program. This allows judged on those criteria. for easy editing and entry because the end user can fill in the blanks for new data and type over Quick editing is desirable because it saves data that needs to be updated. Fields for each people time. This is particularly true for variable are set up, so keeping track of column experienced data entry personneL numbers is not necessary as when inputting .data Easy editing is desirable because it reduces into a text file. training costs and encourages people to filJ in FS",Sugi-90-12 Levine.txt
"CONSTRUCTION The application of three-dimensional graphics has The most common use of external data is to evolved into two distinct categories: images based on reconstruct an object electronically. NeoVisuals ideas, concepts, and imagination; and images based on software achieves this in a variety of ways. Let's first data from tangible, measurable objects. This paper look at the three standardized format file types that addresses the processes involved in the second area; can be read directly into NeoVisuals software: IGES, CGM, and FEA. Then, we will examine the importing data into NeoVisuals software whether that information is used to recreate an object, change how manipulation of NeoVisuals software data files to it looks, or move it. Initial Graphics Exchange accommodate nonstructured data. Specification (IGES) and Computer Graphics Metafile (CGM) format files are discussed, as well as methods IGES for importing unformatted raw data for visualization. IGES stands for Initial Graphics Exchange Specification, a widely used standard for representing three-",Sugi-90-120 Hagen.txt
"Writing Efficient C Code for Optimizers Oliver Bradley, SAS Institute Inc., Cary, NC Today's C oompilers are highly optimizing. When you use such a sure (unless it does cross-module analysis); it has to compiler, many of the traditional ways of hand-optimizing your pro- assume that external variables are aliased. gram no longer apply. But don't expect the compiler to do it all on · Avoid using static variables. its own. There are many things you can do to help an optimizing These are not as big a problem as external variables but compiler speed up your program. This paper discusses some of can still cause deoptimization. If you call another function, those things. Most of these techniques apply to any optimizer, and the optimizer has to assume that static variables might be the paper discusses these first. Then I'll move on to some tech- changed. This is because C allows recursive calis, and niques that are specific to the SAS/e'"" and Lattice'"" Compilers that therefore, the other function could call back to the present we market. function, and it could change the variable. Note that these techniques apply specifically to C. Some of them · Avoid heavy pointer access to unchanged values. may apply to other languages, but every language has its own rules. A value accessed through a pointer is automatically aliased The techniques also assume a highly optimizing compiler - not all since the optimizer normally has no idea where in memory it langLiages currently have such a compiler. is. Such values have to be reaccessed from memory if something might have changed them since the last access. This is particularly inefficient if several levels of indirection TECHNIQUES Tl-IAT APPLY TO ANY OPTIMIZER are involved. Thus, if your program makes heavy use of pointer access to values that do not change, copy the value Avoid Aliasing or values to a local (auto) variable (and don't take its The optimizer does best when it has the most information. Consider address, of course!). By d",Sugi-90-121 Bradley.txt
"Writing an 80386 C Compiler for the SAS® System Glenn Musial, SAS Institute Inc., Cary, NC I NmODUCTION · LS 31 This paper discusses the development of a C·compiler for the Intel 80386 microprocessor. A brief discussion of the evolution of the EAX 80386 Is given, followed by a description of the 80386 register and instruction sets. From there, the C compiler's view of the 80386 is EDX presented with emphasis on the features of the chip that make it attractive to a large-scale application such as the $AS system. In ECX addition, comments on the future of the 80386, including operating system targets and processor evolution, are presented. EBX EVOLUTION OF THE 80386 ESI The first member of the 8Ox86 family to gain wide acceptance was EDI the 8088/8086. Presented as a 16-bit processor, the 8086 used a segmented memory architecture to maintain source level consis- EBP tencywith its &-bit forerunner, the 8080A (for example, every 8080A instruction could be translated into an 8086 instruction). While this ESP compatibility eased the transition from the 8-bit to the 16-bit PC, the segmentation concept proved to be a fundamental and limiting EIP ,.flaw in both the 8086 and its successor, the 80286. Some major drawbacks of the 8086 chip were addressed in the EAags 80286. While the 80286, a programmatic superset of the 8086, could be run in 8086 compatibility mode, it also introduced a privi- leged mode of operation that provided for memory protection and Figure 1: 80386 Flat Model Register Set process control management. By using a virtual-to-physical mem- ory mapping scheme, the 80286 running in privileged (or protect- ed) mode could exceed the 1 megabyte memory limit of the 8086 and directly address up to 16 megabytes of memory. .The instruction set for the 80386 will be very familiar to developers used to working with the 80286. Opcodes from the 80286 translate However, the software overhead required by the segmented archi- directly into 80386 opcodes. The 80286 8-bit ma",Sugi-90-122 Musial.txt
"T inessential ways of various features of the machine architecture (for example, the size of ints or size of ThiS paper deals with issues encountered in porting existing C pro- pointers). grams to the mainframe environment Following a discussion con- cerning what it means to say that a program is portable, this paper · Class 4 contains programs that take advantage in emphasizes program features that are likely to inhibit portability to inessential ways of various features of the host operating and from the mainframe. system and file system (for example, the format of file names, the maximum length of file names, or library functions specific to that compiler or operating system). THE MEANING OF PORTABILITY Potentially portable What does it mean to say that a program, or a body of source code, is portable? For most practical purposes (and portability is a practi- · Class 5 contains programs that make use of certain cal concept), this means that if you have written and debugged the common, but not universally available, library interfaces (for program so that it runs correctly on one system, when you compile example. UNIX curses or XWINDOWS). and link the same code for a second system, the program will (with- out modification) run correctly on that system as well. Thus, portabil- · Class 6 contains programs that intentionally take advantage ity is a relation among a body of source cocle and two computer of features of the machine architecture (for example, the systems. The two",Sugi-90-123 Merrill.txt
"This paper explains how the STORAGE command in the SAS/C"" Report specifies that a summary use report source level debugger may be used to debug a storage overlay should be generated if no overiays were ABEND in a C program. The command format is described. Some detected. fundamentals of heap and stack storage management by the SAS/C run time library are introduced. A general technique for debugging If neither Check nor Report is. used, the default is Report. storage over1ays is explained. Term specifies that the output is to be written to the terminal.",Sugi-90-124 Hunter.txt
"ters as ABSTRACT well. More recently (largely as a result of the quality and success of the SAS/C"" Compiler) the language has seen significant use on This is a conceptual introduction to the C programming language, mainframes as well, and you can expect to see this trend continue. concentrating on those features of C that are likely to be regarded as unusual or to be problematic for novice users of the language. The paper is oriented toward answering the question: ""What infor- THE C PROGRAM MODEL mation will be of aid to me in learning how to program in C?H C is a bit odd among programming languages. It falls into the general category of a ~high-Ievel, general-purpose language, but at the INTRODUCTION D same time it offers features that give it the power of a low-level lan- guage such as assembly language. It is not possible in a brief paper to introduce all of the features of C or to provide a reasonable tutorial on how to program in C. Rather Historically, C was developed as a systems programming language than simply providing a list of language features and a descript ion for the purpose of implementing the UNIX operating system on small of C syntax (which is expertly done in any number of books), I am computers. Since it was a language designed primarily by one or offering what might be thought of as a conceptual introduction to two men (rather than by a committee), it is a fairly minimal language the C language. In this, I will be guided by the questions in terms of the",Sugi-90-125 Merrill.txt
"a constant character string in C is already treated as a pointer. SAS/C"" Compiler products provide a powerful and flexible environ- This technique produces a parameter list consisting of a list of point- ment for the development of C programs. Extensions to the ers. However, the to operator can be used only on arguments that ANSI C language described in this paper make it easy to develop are variableS or array elements. This can be inconvenient if you need applications that take full advantage of IBM"" products such as to write many calls whose arguments are constants or expressions. GDDM""· and ISPF. To provide a more convenient way to pass such arguments, the SAS/C Compiler supports the at-sign (@) operator. The @operator",Sugi-90-126 Wiersma.txt
"The Impact of Machine Architecture on the Implementation of the SAS® System Larry J. Noe, SAS Institute Inc., Cary, NC the architectural details of the machine. These portions are INTRODUCTION dynamic loading, dynamic linking, tasking, numeric formatting. The responsibility of each of the host development groups at SAS and code generation. Many of these sections require total Institute is to implement a host-dependent layer of code that rewrites when moving to new architectures. provides low-level services to a portable supervisor. Each host The UNIX host development group is currentiy investigating a group is generally responsible for one architecture and one large number of architectures from a variety of manufacturers for operating system. The UNIX® host development group is in the release 6.07 of the SAS System. These architectures include unique position of having one operating environment running on Motorola MC68000'"" and MC88000'"" Sun Microsystem's many different architectures. Differences in machine architecture I SPARC® · MIPS Computer System's MIPS, HP- Precision can have a major impact on certain areas of the host layer. The Architecture, Intel3861M and Inte1486'"" , IBM® POWER primary areas affected by these differences are dynamic loading architecture, IBM 370, and National Semiconductor 32532-. and linking. Other areas that are also affected are tasking, Release 6.03 of the SAS System is available on HP-PA. SPARC, arithmetic, and code generation. This paper discusses in detail and two MC68CXXl-based systems: the HPOOOO/300 series and each of the affected areas of the host layer and the impact the the Sun-3. In working with such a large number of vastly different architectural cflfferences have on their implementation. architectures. we have come to recognize the architectural and C compiler code generation features that have the greatest effect on SAS System implementation. PORTABILITY OF THE HOST LAYER The SAS System is divided into three layers: the",Sugi-90-127 Noe.txt
"filename raw2 'firstlev.raw.datax' disp""old;I'connect to input ' I This paper focuses on the available external file capabilities of filename olltl 'firstlev.out.datay' mod; I'connect to output'l Release 6.06 of the SAS"" System. This paper emphasizes the fol· data x; I' SAS DATA step ~ unit of work 'I lowing new and improved features: infile raw2; open input I' 'I file out1; open output 1* *1 · dynamic allocation through the FILENAME statement input; read 1* *1 put _infile_; write I' '1 · concatenated data sets run; I ' both files will be closed when finished "" · PDS considerations Consequently, the body of this paper is logically structured around the four steps. However, there are exceptions to this four-step · sequential use of POS members structure, and they are mentioned whenever possible. · ability to aocess VSAM data sets CONNECTING AN EXTERNAL FILE TO THE · ability to update ISPF statistics SAS SYSTEM This paper discusses these features by defining external files to the SAS System with the FILENAME statement and using external files To make an external file available to your program, you must tell in the SAS DATA step through the INFILE and FILE statements. Fur- the SAS System where to find the file. This was traditionally done thermore, this paper addresses additional external file features, by connecting a fileref or DDname to an external data set through including accessing VSAM files and VTOCs, MVS windows, the a TSO ALLOC statement or a JCL DO card. The fileref was then FILENAME= option, and the FILEVAR= option. used throughout the duration of the SAS session as a reference name.",Sugi-90-128 Ghosh Heffner Landis.txt
"instructions. To provide access to data spaces, the ESAl370 arch ... tecture defines a set of 16 access registers for use in implementing IBM·S· powerful Enterprise Systems Archltecture/370- provides a new address translation process. Each access register contains many new capabilities for system and a!'P'ication software. The a token that identifies an address space or data space to which a exploitation of these capabilities in future releases of Version 6 of program has addressability. The architecture pairs each access reg- ister with a general register. A general register contains a data the SAS- System under MVS will offer enhanced function and per- address wHhin a space In the range from 0 to 2 gigabytes. Together, formance. an access register/general register pair positions a data reference along two dimensions. The access register positions data reference",Sugi-90-129 Hayes.txt
"conversation is a connection between a local and a remote SAS SAS/CONNECT affords users connectivity between numerous session. operating systems and hardware configurations to allow remote There are two detailed examples following the discussion of the SAS processing and data transfer. This paper discusses some major features. The examples were designed to illustrate the of the more effective ways to use the SAS/CONNECT product to power and functionality of the SASJCONNECT product. Also, a help automate and simplify access to remote data. brief discussion of some of the areas being researched for future enhancements to the SAS/CONNECT functionality and connectivity is provided with a short example illustrating a small",Sugi-90-13 Garner.txt
"ground Transparency, which controls whether or not the graphics This paper describes the enhancements to the user interface in Ver- plane Is visible through the text plane. In addition, the IBM 3179GI 3192G terminals have limited support for programmed symbol sion 6 of the SAS"" System that are specific to the MVS and VM graphics-specifically, they have two loadable programmed symbol operating systems. Definitions of the various types of 3270 text and sets (a 3279G has six loadable sets). graphics terminals lead to a discussion of the device drivers used by the SAS System and the characteristics of each driver. Special device support for the IBM'"" 3290 and 3179G/3192G terminals with SAS 3270 DEVICE DRIVERS an attached mouse is described. Also presented is a complete list of mainframe-specific SAS system options and global SAS Display Manager commands. Common User Access features in the Text SAS System are described, and numerous hints are provided for The SAS System has two 3270 device drivers for text: a non-EDS interacting with the SAS full-screen windowing system. driver (SASVUN) and an EDS driver (SASVUE). The EDS driver is always loaded by default when the full-screen system is initialized. If the device is not queryable or it is determined by inspection of",Sugi-90-130 Herold.txt
"onvert your Version 5 SAS data sets to Version 6 fonnat since that information is not maintained under Release 6.06. The advantages and disadvantages of converting Version 5 SAS data libraries to Version 6 format are discussed under a variety of Full password support is not provided in· Release 6.06 of the operational circumstances_ Tools for converting the different file SAS System. There is no support at all for passwords for types are presented with appropriate examples illustrating Version 6 SAS data sets, and support is limited for passwords for Version 5 SAS data sets. You can use passwords in connection mechanisms and ease of use. Conversion strategies are discussed with Version 5 SAS data sets wherever you can specify the with an emphasis on tailoring these strategies to your particular password as a data set option. This means that you can create site requirements. password~protected data sets in a DATA step and read them in a PROC step. You cannot, however, modify passwords with DECIDING TO CONVERT PROC DATASETS or copy them with PROC COPY. If you rely on SAS password protection for the security of your data, you are advised to keep your data in Version 5 SAS data sets. Depending upon the requirements of your application, conversion of the files within your Version 5 SAS data library It may also prove impractical to convert your Version 5 SAS may be required, impractical, or optional. data sets in another situation. This occurs when you have a Version 5 application",Sugi-90-131 Ripperton.txt
"The RT® will continue to be supported at roughly This paper is an overview of the implementation of the current level of software. Some enhancements the SAS® System under AIX'"", which is IBM will be made to the RT to allow it to interoperate Corporation's implementation of the UNIX® operating system and is the basis for Open with the other AIX systems, but generally the RT is Software Foundation's OSF/l'"" operating system. not covered in the family definition. The family My understanding of the history and direction of definition states that all three platforms will AIX development is presented. The features of conform to POSIX'"", X/Open'"", and OSF standards. Version 1.2 for the PS/2 and 370 has just been Release 6.07 of the SAS System and AIX that released and includes NFS'"", OSF/Motif'"", POSIX provide interoperability between AIX platforms and other UNIX and non-UNIX machines is reviewed. compliance, and support for the new Xstation product. Version 3.1 has been announced for the",Sugi-90-132 Burns.txt
"MIGRATING FROM PC-DOS SYSTEMS TO OS/2® SYSTEMS - HARDWARE CONSIDERATIONS By Dave Brumitt WHAT IS OS/2? and C78 program with which you may be familiar, except that the software to drive the board is now part of OS/2. OS/2 represents the first new operating system for the IBM® and compatible architecture LAN Requester - allows the PC to interact PCs since their introduction. The hardware has with a Local Area Network card. Like the outgrown PC-DOS sometime ago, and now Communication Manager, the software to drive OS/2 has arrived with capabilities to take the board is now part of OS/2. advantage of the more powerful hardware. Database Manager - OS/2 includes a What exactly is OS/2? OS/2 is in fact an Structured Query Language (SQL) database as entirely new operating system. Its first release is part of tts resources. The Database Manager based on the Intel® 80286 and above sets up this resource. processors when residing in an IBM or compatible architecture computer. There will be The resources required for Version 1.2 of other releases of OS/2 for other hardware. In OSI2 are: fact, OS/2 Version 2.0 will be released shortly, and it will be for the Intel 80386 and later Disk processors. Additionally, OS/2 will most likely be RAM Space released for other processors and other Version 1.2 Standard Edition 14.5 3.0 architectures. The Motorola® 680XO UNIX® machines and various RISC machines are good Extended Edition add-ons candidates for ports of OS/2. 2.0 10.8 Communication Manager LAN Requester .5 5.0 The point is that OS/2, unlike a myriad of other Database Manager 5.0 15.0 products such as Windows, Desqview®, Total for add-ons 8.5 30.8 VM/386TM and many others, does not work in Total for all Version 1.2 45.3 11.5 conjunction wtth PC-DOS. Instead, it replaces it altogether. OS/2 boots the processor from the UPGRADE PATHS TO OS/2 ground up and while it has many compatibilities with PC-DOS, that system is not required for OS/2. OS/2 is the only system for the 286 which It",Sugi-90-133 Brumitt.txt
"Migrating from PC DOS Systems to OS/2· Systems - Software Considerations Julie Maddox, SAS Institute, Cary, NC tions will execute in the compatibility box. Another limitation of the INTRODUCTION compatibility box is memory. The compatibility box actually boots up with less conventional memory due to the overhead of running This paper is presented to help optimize your CONFIG.SYS file. under OS/2. The compatibility box currently offers at most around Why is this necessary? The system configuration file has grown 500 to 525k of conventional memory. From this starting point, you from 3-5 lines under DOS to 20-25 lines under OS/2' OS/2 provides should subtract memory to load COMMAND.COM and any memory many options that allow you to optimize performance. This paper resident programs. In addition, the compatibility box does not sup- discusses the various options in the CONFIG file. Another concern port expanded memory or disk caching. when migrating from DOS to OS/2 is how to maintain your DOS files and how to continue to run DOS applications. This paper addresses The second altemative is to boot DOS from a floppy diskette. Boot- these questions. ing directly under DOS permits you to use expanded memory and disk caching. Furthermore, all of your DOS applications should exe- HARD DISK CONSIDERATIONS cute properly. The drawbacks are having to make sure the floppy diskette stays with the PC and having to reboot the PC every time Let's start with the hard disk. The first question to ask is do I need you want to execute a DOS application. to format my hard drive? To answer this question we must first find out more about your particular scenario. If your personal computer A third altemative is to install a utility that allows you to boot either is brand new and will be used to run OS/2 only, you should format DOS or OS/2 from the hard disk. Dual boot software is convenient the hard disk as part of the OS/2 installation process. because you don't have to have a DOS floppy disk",Sugi-90-134 Maddox.txt
"Getting the Most From Your Release 6.06 SAS Session under OS/~ Jeff McDermott, SAS Institute Inc., Cary, NC Introduction screen application, or text windowed application. Under OS{2, a SAS session can be invoked as a PM Display Manager System (OMS) session, ~lease 6.06 of the SAS rntcl""acUve line mode seasion, Clr non-interactive session. If you have System and OS(l.® were each designed with a multiple SAS sessions, each session may operate sharing the same exe- consistent user interface and program portability in mind for the operating cutables and system resources, but each SAS session processes indepen. system and application software. The SAS System's MultiVendor Ar- dentlyof any other SAS progrnms or simultaneous tasks. These sessions chitecture1M (MYA) platfonn running under mM® OS/2 gives the user can also share data through the use of the Ctipooard, named pipes, 00- a view of the graphical face of tomorrow's software. This paper focuses named pipes, and DOE, which are each discussed in later sections. on supported OS/2 features under Release 6.06 of the SAS System. osn applications can be opened portable Release 6.06 features, and compatibility issues between previous Additionally other non-SAS third party releases of the SAS System and Release 6.06. (limited by the present releases of OS/2 to 16 total sessions. including SAS sessions). Input and output can be shared between your SAS sessions and New Features for Release 6.06 under OS/2 other !oftware, depending on which OS/2 shared data features are support. ed by the third pany OS/2 application. Dl Presentation Manager (PM) will be the look of the SAS System under OS/2 and PM's features will be available under the SAS System's DiqJlay Presentation Manager Graphics Manager System (OMS). Initially Versions 1.1 and 1.2 of OSfl will be Since the SAS System nms WIder Presentation Manager, the display you supponed by the SAS System since OS{l. Version 1.0 does not suppon use for PM is automatically used as the",Sugi-90-135 McDermott.txt
"Supervisor The SAS· Multiuser InteractiVe System in Version 6 of the SAS Sy~ POWER tern allows an alternative to running the SAS system under ICCF. This approach enables the SAS System fuming in a single region VTAM to service multiple terminal users, workstation users, or both. Bene· fits include better memory utilization, increased capacity for interac- tive users, and faster response time. CICSIICCF This paper addresses the design considerations of the SAS Multi- user Interactive System. Induded are discussions of the manage- ment of multiple users, the VT AM- Interface, asynchronous processing. the relationship to CICS, and extensibility issues. SAS SAS SAS",Sugi-90-136 Valmassoi.txt
"Support group. The presentation is a joint effort of tl1e Host Systems Research and This paper provides an overview of sources of information for your Development Division and the Documentation Development Depart- SAS software with particular emphasis on working within your host ment and describes the combined effort of host developers, the publications group, and the technical support group at SAS Institute environment. The first portion of the paper describes the range of information sources you as a SAS software user have at your dis· to produce host-specific documentation and information resources that meet customer needs. This discussion shows the user how to posaJ. In the second half of the discussion, you learn in greater detail about the primary source of hardcopy information for the host oper- maximize the utility and versatility of Version 6 of the SAS"" System ating systems, the Host Companion. product by identifying where specific types of information are located with particular emphasis on host-specific documentation. The paper illustrates how the information interface and SAS soft- HARD-COPY DOCUMENTATION ware reflect the uniqueness of individual operating systems, while preserving the continuity of the SAS System across host environ~ Hardcopy documentation that contributes to successful work on ments. your host is available to you from two primary sources:",Sugi-90-137 Zullo Stribling.txt
"If not, then if it is a VMS logical name assigned with the VMS DCL DEFINE (or ASSIGN) command. use This paper discusses features of the external I/O subsystem in the physical specification that the logical name is assigned to. Release 6.06 of the SAS® System under VMSTM, The discussion focuses on host issues related to processing of X 'DEFINE MYFILE [OLDJLOGFILE.DAT; external (non-SAS) files, since previous SUGI papers have FILE MYFILE; discussed the processing of SAS data sets under VMS in detail. New features, host options, and performance tuning for filerefisa VMS logical name external files are discussed. [OLD]LOGFILE.DAT will be created If not, treat the specified fileref as a filename in the",Sugi-90-138 Hecht.txt
"One of the most common problems In debugging macro applications One of the most exciting features of Release 6.06 of the SAS· Sys- Is caused by developing and executing the entire application at tem under VMS* is the full macro facility. As VMS users take full once, then being overwhehned by the number of error messages advantage of the macro faclDty. It Is necessary for them to know and incorrect results. You don't know where to begin to fix the prob- how to efficiently debug their macro applications. This paper uses lems. You can avoid a lot of frustration by developing and debugging a hands-on approach to present debugging techniques and tools each module of your application separately. that are useful in macro applications running under VMS. The audi- ence for this paper is programmers who are familiar with the SAS Another good idea is to develop the open code first. then add the language and have a basic understanding of the SAS macro lan- macro layer around it. (Open code is SAS programming statements guage. that are outside a macro definition.) As you add the macro layer, add the simple macro code first, then the more complex macro code. This last technique is especially important for interactive",Sugi-90-139 Gilmore Helwig.txt
"Using the ADX Menu System for Taguchi Applications in Quality Improvement Dr. Randall D. Tobias, SAS Institute Inc. Box 8000, Cary, North Carolina, 27512. Abstraet Methods for improving product quality advocated by Genichi Taguchi emphasize the use of experi- mentation to design quality into a product or process. Many tools for the statistical design and analysis of experiments are provided within the SAS system, including procedures for fractional factorial and optimal design construction, linear regression and analysis of variance, and graphical display_ The ADX menu system provides a fun-screen front end to these facilities and was developed largely for quality engineering applications. The user is led through the process of designing an experiment, entering the data, and analyzing the results. Extensive help is available for the user with a limited statistical background. This tutorial overviews the ADX system and shows how it can be used in the context of two Taguchi applications, both to streamline the tasks of design and analysis and to provide addit.ional insights. 1 What are ""Taguchi Applications""? In recent years the competitive edge in industrial manufacturing has come to depend on product quality. In the quest for greater quality, engineers have looked progressively further up the manufacturing stream. Working with researchers at Bell Labs in the early 1980's, Genichi Taguchi made a number of recommendations for improving product quality at the product design stage; these have collectively come to be referred to as ""the Taguchi method"" for quality controL (See Dehnad (1989) for a historical survey.) Taguchi's programme involves experimenting with the design of a product to optimize certain characteristics while reducing their variation around target levels. The idea is to apply statistical methods to obtain maximum experimental information with minimum experimental effort. Taguchi's recommendations have met with considerable success. Companies have rt'p",Sugi-90-14 Tobias.txt
"the ability to specify the I/O engine that should be associated with a SAS library. Every SAS library must be associated with an engine Version 6 of the SAS System has a fresh, new look. Increased that is responsible for reading and writing the members of the interactivity and a ""point-and-click"" environment will help novice library. If an engine is not spedfied in the LlBNAME statement, the users as they create their first SAS applications. Expert program- SAS System attempts to determine the format of the SAS library. mers can also realize an increase In productivity due to the addition If the Ijbrary doesn't exist, an appropriate default or BASE engine of pop-up windows, added language syntax, and Increased proce- is chosen. dural functionality. In addition to the features currently induded in Release 6.06 of the SAS System, there are many interesting proj- Performance gains can be realized if the LlBNAME statement speci- ects scheduled for future releases of the SAS System under eMS. fies the location and engine associated with the SAS library. Speci- This paper discusses some of the current enhancements and future fying the fUemode of the library allows the SAS System to avoid projects scheduled within Version 6 of the SAS System under eMS. searching all accessed disks to find a specific library. Specifying an engine name avoids the overhead of determining the format of a",Sugi-90-140 DeBoskey.txt
"he complex linkedit process unnecessary. This paper discusses the SAS/C Interlanguage Communication sup- A multilanguage program is composed of routines written in two or port, concentrating on the proper use of data oommunication and ILCLINK. Examples using COBOL, FORTRAN, and PUt are pro- more high-level languages. Multilanguage programs are useful vided. because they facilitate · use of existing subroutine libraries INTERLANGUAGE COMMUNICATION ISSUES · migration of an application from one language to another Execution Framework Requirements · use of languages most applicable to a particular programming task. All high-level languages require that an appropriate execution frame- work exist prior to the execution of the program code. Normally, Writing and packaging a multilanguage program can be difficult In when a main program begins execution. the execution framework the IBM'"" 370 environment. The SAS/e"" Interianguage Communica- is created by a run-time library initialization routine. It is the responsi- tion feature minimizes the difficulties involved. This paper addresses bility of this initialization routine to do the following: the passing of data among multi language programs, with examples using COBOL, FORTRAN, and PUt. Additionally, because the link- · acquire storage for the run-time library and establish ing of multilanguage programs is an area for frequent errors, exam- addressability ples of using the ILCLINK utility are provided. · acquire storage for program va",Sugi-90-141 Ammondson.txt
"to SAS data sets only (the first type of file). All other types of files will have to be converted to Version 6 fOf111at before they can be This paper discusses what you should be dOing and thinking about used. This can be done using the V5TOV6 procedure. This paper as you develop and maintain Version 5 applications so your installa- does not discuss the details of the conversion procedure, but, tion can convert to Version 6 with a minimum amount of resources rather, the ways to prepare for using this procedure in the future. and problems. It is directed toward managers who will be adminis- If your applications consist of only SAS data sets, you will not have tering this conversion and technicians who will be responsible for to convert your data files until you want to take advantage of some implementing the conversion. The use of SAS· tools that can sim- of the new features of Version 6, such as indexing and data com~ plify this conversion process, induding the SAS'"" macro and autocall pression. facilities, and SASJDMI software is also discussed. HOW TO PREPARE APPLICATIONS FOR",Sugi-90-142 Janes Dietrich.txt
"converts files from Version 5 for- ABSTRACT mat to Version 6 format only on the same operating system. You cannot use it to move flies from one operating system or host to This paper presents a simple introduction to the new V5TOV6 pro- another. For information on moving files across operating systems cedure. It explains when you need to convert SAS"" files from Ver- and hosts, see Chapter 16, ""The CPORT Procedure,"" and Chapter sion 5 to Release 6.06, why you might want to convert a file even 10, ""The CIMPORT Procedure,"" in SAS Procedures Guide, Version if you do not need to, and when you should avoid converting. This 6, Third Edition, as well discussion of the transport engine in Chap- paper contains examples that illustrate how to perform a variety of ter 6, ""SAS Files,"" in SAS Language: Reference, Version 6, First Edi- conversions, ranging from the conversion of individual files and cat- tion. alog entries to the conversion of an entire SAS data library. VERSION 5 SAS· FILES AND THEIR VERSION 6 INTRODUCTION COUNTERPARTS Because Version 6 of the SAS System supports a variety of new features, the structure (or fonnat) of many SAS files has changed This section explains the relationship between files in a Version 5 since Version 5. The V5TOV6 procedure copies SAS files from a SAS data library and their counterparts in a Version 6 SAS data Version 5 SAS data library to a Version 6 SAS data library, changing library. In many cases, a Version 5 file converts to a Version 6 cata-",Sugi-90-143 Wolfson.txt
"Version 5 to Version 6 of the SAS System in the same host environ- ment. This process is accomplished by using the V5TOV6 proce- This paper explains which tools you should use to create transport dure, which is documented in the SAS Procedures Guide, Version files to move SAse data sets and catalogs in Release 6.06 of the 6, Third Edition. SAS System from one host environment to another. This paper also briefly addresses the topic of converting and transporting SAS data sets from Version 5 to Release 6.06. The examples in this paper Terminology for Transporting Files illustrate movement between the MVS and the VMS~ operating sys- This paper uses the following terms in the discussion of transporting tems, but the techniques discussed are applicable to other environ- files in the SAS System. ments. exporting is putting a SAS data library, SAS catalog, or SAS data set into transport",Sugi-90-144 Ressler Whittle.txt
"INSIDE SAS· CATALOGS IN VERSION 6 OF THE SAS SYSTEM Rebecca Perry, SAS Institute Inc., Cary, NC INTRODUCTION models, formats (on VMS~ Data General, and PRIMOS""), and A SAS"" catalog is a SAS file used to store a special dass of data objects called SAS catalog entries. Catalogs contain a variety of SAS/IMl""' storage libraries, are stored in catalogs in Version 6. entries essential to Version 6 of the SAS System. Some of the data objects maintained in catalogs are In Version 6, the use of catalogs is more widespread throughout the SAS System than in Version 5. Consequently, more catalog · formats generated by the FORMAT procedure entry types are supported in Version 6. · graphs produced by SAS/GRAPH"" software The V5TOV6 procedure converts Version 5 SAS files to Release 6.06 format. PROC V5TOV6 can convert an entire SAS data library, · function key settings a specific catalog within a library, or selected entries within a cata- log. For more information, refer to Helen Wolfson's paper, · letters produced by SAS/FSP""' software Converting Version 5 Files to Release 6.06 Files Using the V5TOV6 · default option settings. Procedure,~which will be published in the 1990 SAS Users Group International Conference Proceedings: SUGI1S. This paper describes the internal architecture of a Version 6 SAS catalog and presents options for optimizing the performance of a SAS catalogs have better integrity protection in Version 6 than in SAS catalog. Version 5. If a Version 6 catalog's integrity is questionable after a disk-full condition or an ItO error, the SAS System flags the catalog as damaged. A facility for repairing the damaged catalog is available. PARTI:SAS'CATALOGS layering of the SAS""' System SAS catalogs reside in SAS data libraries and have the library mem- SAS software is composed of three main layers. The applications ber type CATALOG. Like other SAS files, SAS catalogs have two- or procedure code is the top layer, the supervisor/engine code is level names, as in the follo",Sugi-90-145 Perry.txt
"eries of computer·generated questions This talk describes work in-progress on an interactive Sal Query that the user must respond to, the ~UERY window allows the user building environment for the SAS® system. It uses full screen to control the direction that the session takes. In other words, the menus and point-and-shoot concepts for selecting tables and QUERY window is non·madal- all the functions presented by the variables as it leads you through the construction of a query. interface are available without the user having to change modes. The constructed query can be run to preview the data selected, saved as program text for incluSion in other jobs, or saved as an SOL View fa use at a later time by other SAS procedures. The QUERY Canvas The QUERY window is invoked from the SAS Display Manager with the ""OUE,RY"" command, or by selecting it from the Background GlOBAlS pull·down menu. The first window that is displayed is the main canvas, where the user will paint his query. Sal (Structured Query Language) is a language for accessing data stored in tables. It is a non-procedural language that is implemented by many database systems on mainframes, minicomputers and personal workstations. The Sal language enjoys far greater applications portability than proprietary query languages due to its high degree of standardisation. Greetings: frOPl the QUERY Window ··· .mill F,,. Interactive Interfaces ...... Hatch Il'l Sal is an ""English like"" language, but it still has many stylistic",Sugi-90-146 Kent.txt
"in, Texas ABSTRACT INTRODUCTION CASE involves using computer technology to assist ThiS project was an experiment in a different the software engineering process. In general it approach to CASE tools. Many of the CASE deals with all phases of software engineering from packages currently available address only the requirements analysis, structured software design, smallest portion of a software product's life cycle; prototyping, code generation, test generation and namely analysis and design. Those that go beyond execution, source management. and product design and into implementation can only address maintenance. the least abstract types of applications such as data entry and validation, and report generation. The thrust of this effort was to develop some tools There are other tools that support the to analyze existing software in it's source form and implementation and maintenance phases, such as to build and maintain a knowledge base (called the source control mechanisms and make-like repository) representing the internal structure of facilities. These, however, treat the source as text the subject software. This information details all and do not consider the semantic changes or its named entities such as modules, entrypoints, implications on the overall design. The result is global variables, macros, etc. 1\ also details the that some current offerings cover the high-level relationships of those parts. The information in the design issues and others cover the logistics of",Sugi-90-147 Burns Rogers.txt
"Physical Pmcess Physical Phenomena & This paper discusses functionality provided by the SAS"" System and Sensors the VMS~ operating system that enables real-time or pseudo-real- time data collection. An abstract data acquisition system model is developed and discussed. The concepts established in the model ~---------------- are applied to the development of a prototype set of user-written Signal Acquisition OAT A step functions designed to support the DataMyte~ Corpora- tion 762 series data acquisition controllers. The resulting set of func- Signal Conditioning & Conversion tions represents a fully functional data collection tool kit. In the interest of setting the framework. for further development. the dis- cussion remains abstract and general except for those areas where specific interface characteristics are required. Controller and Communications Interlace",Sugi-90-148 Blair.txt
"Gracefully Handling Empty Files in the SAS® System Matt Kleinosky, Independent Consultant O.V. Hanger, Nielsen Media Research INTRODUCTION . . An example of the more extreme events caused by an This paper explores methods for gracefully handling empty unantiCipated empty fiJe can be seen in an example involving SAS files and data sets. In a multiple step SAS program, it is often nec- MACRO variables. If MACRO variables were to be created in the essary to provide for the possibility of these situations. The conse- first step and used in subsequent steps, the eHectof an empty input quences of ignoring an empty file condition could be as slight as a file is not so tidy. SAS program n.ming to completion and creating no reports or as severe as an abend in a production environment. The output from In Example 2 the macro variables do not get created in the the latter case could include a long list of confusing and, possibly. first step so all references to them produce the SAS error messages misleading SAS error (or warning) messages in the Log and abrupt that surely indicate the error. But there is less emphasis in the log endings in Data steps involving SET, MERGE or UPDATE. There on the step which created the errant condition. are several ways to provide for the possibility of empty files. The first approach involves detecting the empty file in the Data step which Example 2 - Source creates the SAS data set Another approach introduces a general- ized Macro, %EMPTYCT, that not only provides flexibkJ handling of empty files, but also can be used when a consolidated job summary DATA EXAMP2A(KEEP=X STRING1); INFILE INDD1; report of record and observation counts is needed. INPUT@l NUMI 2. @6 X 4. @11 STRINGI $6. ; IF N=l THEN DO; SOME EXAMPLES CALL SYMPUT('DIMENSN·,PUT(NUM1.2.)); CALL SYMPUT('STRLEN·, Example 1 shows a simple SAS job that encounters an PUT(LENGTH(TRIM(STRINGI )).1.)); un~xpected empty raw data file. Here the DATA and PROC steps END' which use the empty SAS",Sugi-90-149 Kleinosky Hanger.txt
"try can be formulated and solved as constrained network models. PROC NETFLOW in SAS/OR software (versions 6.03, 6.04 and 6.06) finds optimal solutions to such models. This tutorial will cover the following topics: · network modeling techniques, · the performance ofPROC NETFLOW, · new, undocumented or changed options in versions 6.04 and 6.06. Introduction Constrained network models can be used to describe a wide variety of real-world applications ranging from product inventory and distribution problems to financial applications. These models are conceptionally easy since they are based on network diagrams that represent the problem pictorially. This not only simplifies problem description but also aids in the interpretation of the solution. These problems can be solved with PROC NETFLOW in the SAS/OR software product. A network consists of a collection of nodes and a collection of arcs. The arcs connect nodes and convey flow of one or more commodities which are supplied at supply nodes and demanded at demand nodes in the network. Each arc has a cost per unit of flow, a flow capacity and lower flow bound associated with it. An important concept in network modeling is conservation of flow. Conservation of flow means that the total flow in arcs directed toward a node, plus the supply at the node, minus the demand at the node, equals the total flow in arcs directed away from the node. A network and its associated data can be described in SAS 2 data sets. PROC NETFLOW uses this de",Sugi-90-15 Kearney.txt
"te each This paper demonstrates a method of adding a combination of the classification variables. collapsing yanable to a data set. The collapsing vanable assigns multiple observations of a data set to 3) . Generate PROC FORMAT code, using the one group and allows summarizing the data set by denoting (or IndeXing) variable from Step 2 and the that . vanable. The vanable denotes specific collapsing variable from Step 1. comblnatlon(s) of any number of other variables. The method .reduces tedious programming to a minimum, 4) Use the same formula for a denoting variable making It possible to collapse a very large number of from Step 2 to create that variable on the main file. combinations into any number wanted. Use the format and the PUT function to assign the collapSing variable to the main file. The method uses a SAS@format and the PUT function. The code for PROC FORMAT is generated automatically. When executed, the format serves as a recode table, thus avoiding a list of ""if"" statements. It is How To Use the Method: als? unnecessary to sort the file, as when adding a vanable through a merge with another SAS data set. This paper will show an example of using the method when only two class variables are involved; however, Introduction: the same method can be used with many class variables and many levels. Grouping is sometimes based on similarity among the observations. Other times, often when the number of Step 1: Create the all combinations file. distinct combinations is ver",Sugi-90-150 Whitlock.txt
"SOLVING GROUPING PROBLEMS: USING THE POINT= OPTION Dalia Kahane, Westat INTRODUCTION Within the same tract, group ED with (2) least distant BG and vice versa. A grouping problem is one where a record needs to be combined with others, based on a size variable, Group ED /BG with ED /BG from least (3) usually within limits of some identification variables. distant tract. For example, schools with too. few students are combined w~h bigger schools w~hln the same state or For each state, an extract file of BG/ED level records county. The SAS'"" software option POINT = makes it was sorted by tract, BG number and ED number. easy to solve such grouping problems. Since BG number is missing for every ED record and ED number is missing for every BG record, this order The SET statement without the POINT = option lets the ensured that all ED's preceded all BG's in a tract. user process a data file sequentially, keeping variable values from only one record at a time. SAS software (See figure 1 for data.) offers various tools for keeping current the values from more than one observation. The LAG function, the Reading the file sequentially, the number of housing RETAIN statement and ARRAYs can help in keeping units in the BG/ED record is checked. A ""current some information from previous records available to pointer"" (CURRPTR) is created, indicating which the current observation. They are all, however, limited record is being processed. If the number of housing in solving certain types of grouping problems. The units in the current record is less than 25, the code LAG function keeps variables current only from a fixed searching for a grouping record is linked. ""Previous"" number of preceding observations. The RETAIN records are searched until one is found with 25 or statement causes variables to retain their values from more housing units. Similarly, ""next"" records are a previous iteration of the data step, but here again, searched until one is found with more than 25 housing only on",Sugi-90-151 Kahane.txt
"A SOLUTION TO UNIQUE MATCH-MERGE SITUATIONS Terry Lessmann Mutual of Omaha Insurance Companies PROBLEM SAse software cannot merge two data sets with multiple occurrences of the merge variable in both data sets. For example, a user may have a file containing zip codes and the state and county codes associated with each zip code, and a second file of manager names and their territories based on state and county codes. The user wants to merge the two files by state and county so that the final output will contain all the zip codes in a manager's territory. However, some managers share counties and those shared counties may contain more than one zip code. No matter how the user arranges the merge statement, SAS software cannot successfully merge the data so that each manager gets all the zip codes associated with his/her territory (FIGURES 1 & 2). SOLUTION A solution to the problem is to split one of the data sets of multiple occurrences into several single occurrence data sets. These single occurrence data sets are then merged with the remaining multiple occurrence data set. This is accomplished using a combination of FIRST.byvariable and a macro. FIRST.byvariable is employed to strip off the first occurrences of the merge variable in one data set and merge it with all matching occurrences in the second data set. The macro is used to continue this process until all records have been merged. 910  PROGRAM LOGIC The following is a description of the logic used in the SAS program named MACRO MERGE PROGRAM. To assist the reader, explanations and program code are presented for analysis: 1.) Insert the merge variable name into the macro variable MERGVAR. 2.) Create the data sets and sort them by the merge variable. 3.) A data step is executed to determine the maximum number of managers who share one county. The number of occurrences is kept in the variable named TOTAL and the highest value of TOTAL is kept in HIGH. After the last record has been processed, the value of HIGH",Sugi-90-152 Lessmann.txt
"CARDS: AN INVERTED LIST DATABASE CREATED USING SAS® SOFTWARE Luke L. Diamond, Cedars-Sinai Medical center INTRODUCTlQH A variety of information is collected and stored concerning each patient, which can be classified as Cedars-Sinai Medical Center, located in demographic, financial, clinical, physician and census los Angeles, California, ;s one of the largest private data. CAROS links this data together, organizing it in hospitals in the United States. With just over a a way that provides easy and efficient access. thousand beds, our facility admits over 50,000 patients annually. Providing data analysis. support for the Financial data takes the forn of transactions which management of the various CSHe departments has proven have been posted to patient accounts. Each transaction to be quite challenging. Both the volume and the consists of a dollar amount, a service code and complexity of the Medical Center's data have sometimes possibly a quantity of units (e.g. a number of days, made it difficult to present clear and accurate bandages, etc.). These transactions are lumped together reports. The SAS system has generally been the tool of into convenient reporting ""buckets"" known as choice for ad hoc statistical reporting at CSMC, departMents. primarily because of its ease of use and powerful number-crunching capabi 1ity. Census data only applies to inpatients. Each bed and nursing station the patient was assigned to is The hospital's operational data reside in various documented, along with the date and time the assignment databases and systems maintained by different took place. This data can be used to report occupancy departments throughout the institution. Several years levels of different parts of the hospital. ago, a project was initiated to combine data from the major operational systems and create one centralized Clinical data includes diagnoses and procedures reporting database. The Cedars-Sinai Analytical stored as ICD-9 (International Classification of Repo",Sugi-90-153 Diamond.txt
"o transfer SAS datasets There are a number of reasons to transfer SAS between different systems, between, say, a CMS datasets between an OS mainframe and a Pc. SAS mainframe computer and a pc. There are several provides PROC UPLOAD and DOWNLOAD to reasons why you may want to do this: facilitate this transfer. While UPLOAD and DOWNLOAD are convenient and relatively it's more convenient to use the PC for straightforward they are not as efficient in terms of processing system resources as native file transfer programs such as IBM's IND$FILE. This efficiency difference there may be output devices that are only can be significant when transferring large SAS available on the host system or on your PC datasets. In addition, UPLOAD and DOWNLOAD work via interactive SAS on the host system. Users your SAS based application may have with limited access to interactive SAS may not be outgrown the capacity of your PC able use UPLOAD and DOWNLOAD to transfer files. the source of your data may have changed. This paper describes an alternative method of There are a couple ways to transfer SAS datasets transferring SAS datasets using PROC XCOPY on the between systems. The most familiar is probably host end, and PROC COPY and LlBNAME with the the use of PROC UPLOAD and PROC SASV5XPT option on the PC end. Actual data DOWNLOAD. These PROC's allow the direct transfer is accomplished with the system native file transfer of datasets from one system to another. transfer program. This method of copyin",Sugi-90-154 Miron.txt
"like latec, but tor now, all we need ace macros to ABSTRACT do each of the three basic operations (In, Crunch, Out), and one more to keep an eye on everything_ The many nuances available to the SAS programmer can make macros seem daunting and haed to master. Let's start by coding the module for The In. We'll But in truth, a very straightforward path leads want this macro to offer a choice of valid options to a through the lahyrinth of percent signs and amper- system opecator, to accept input from outside, and to sands. At its end is a simple program which will sup- go for help to interpret what it gets from the CRT. port the three basic parts shared by all production computer systems - !be In, 1be Cruru:b, and 11)6 %MACRO MAINSCR; Out. Four uncomplicated macro modules tie together CLEAR; these three processes. %PUT %STR( MENU); In addition to Simplicity, this program maximizes the %PUT%STRO; use of SAS subsystems (for instance, FSP), to shorten %PUT %STR( ENTER TillS TO,); code and to'ease later maintenance chores. %PUT%STRO; LOG OUT OF RIGHT AWAY); %PUT %STR( QUIT, Q My emphasis will be upon code that the audience %INPUT REPLY; member can take away and use directly in hislher particular application. %MAINMAC; %MENO MAINSCR; Build a Production System in Take a close look at the code. MACRO MAINSCR and MEND MAINSCR seem to suggest the macro's limits. Anything set within a MACRO and MEND statement SASMACRO will not be acted upon by the SAS system processor. If you have program",Sugi-90-155 Beeman.txt
"iversity of Virginia Abstract What is FSCALC? This paper describes some SASe techniques used FSCALC is a SAS/FSP procedure that combines in an interactive financial reporting system developed the power of SAS programs with the flexibility of a at the University of Virginia for the twenty-two cost spreadsheet format. It can be operated in an interactive mode (similar to a Lotus 1-2-3""' session) centers in its Dining Services Division. By combininll applications of base SAS software, SAS/FSCALC"", or it can be invoked in a batch processing mode which uses the spreadsheet as a reporting shell or SAS/FSP"", and ROSCOE/DMF"" we implemented a hierarchial management reporting system that template. provides the following features: > Data extraction from the University's mainframe The Anatomy of FSCALC: accounting system into a SAS dataset; File Format Interactive and batch data entry into FSCALC > The FSCALC 'spreadsheet' really consists of five spreadsheet 'templates' using both base SAS separate files: software and SAS/FSP applications; name.CALC Contains spreadsheet shell (cell ""On-line' viewing capability of operating results > data type, format and other using ROSCOEjDMF panels and FSCALC attributes, Row/ Column headings); spreadsheet 'templates'; namc.POM Contains spreadsheet logic and Management reports presented in a three-level > formulae; hierarchial format by using an iterative SAS macro and SAS/FSCALC in batch mode. name. REPORT Defines the specifications for report format (",Sugi-90-156 Adams Seaman.txt
"EFFICIENT DATA SUMMARY A COMPARISON OF PROC AND DATA STEP TECHNIQUES Sandra D. Iverson, Corporate Cost Management Susan J. Slaughter. Consultant observations. The values of the Introduction variables were totally nested within one another. To verify that results One of the greatest strengths of would not be influenced by idiosyn- the SASl system is the fact that cracies of one operating system, the there are often multiple means to same series of programs was run using achieve the same end, and possibly the same data on each of two systems, the most common use of the SAS system an IBM 3090 running MVS/TSO and an is to calculate sums of data. Many IBM 3081 running VM/CMS. All alternatives exist for doing this, analyses were run under SAS version some of which are redundant, but for so we were not able to take 5.18, the most part each has a unique advantage of some new features under strength. The purpose of this paper verSion 6 such as the CLASS statement is to provide a guideline for for PROC MEANS. programmers in choosing from among myriad techniques the most efficient, and effective method based on the Results needs of a particular application. Tables 1 and 2 contain the The Programs actual results of the summaries measured in CPU seconds. To make it We evaluated four methods for easier to compare the results, Table calculating sums: PROe MEANS, PROC 3 shows rankings for each method. SUMMARY, PROC TABULATE, and a DATA Clearly, the two operating systems STEP with RETAIN and OUTPUT state- produced similar results. Also not ments. For each of these methods we surprising is the fact that differ- compared the effect of having one, ences are far more dramatic for two, three, or four BY variables. larger data sets, with greater One version of this program (the most numbers of levels of summary, and complex one with four levels of higher numbers of combinations of summary) appears in Appendix 1. data values. Programmers with small data sets and only a few levels of As mu",Sugi-90-157 Iverson Slaughter.txt
"USING SAS® ON A MicroVAX FOR A COMPUTER ASSISTED TELEPHONE INTERVIEWING SYSTEM Veronica Fasullo, ARC Professional Services Group Thomas Trumble, ARC Professional Services Group A Computer - Assisted - Telephone - Interviewing (CATI) system, However, CATI systems have two major disadvantages: time and designed and implemented by Atlantic Research Corporation, has cost It takes longer to prepare a CATI-based survey than to been used for four years to conduct fast response surveys. This prepare a paper-and-pencil survey. How much longer depends CATI system is an application of SAS Institute's Full Screen upon the complexity of the questionnaire and the amount of Product (SAS/FSP~) on a MicroVAX under VMS. The menu coding and editing required. In addition, CATI surveys are more costly because of the need to acquire computer hardware and to driven system is programmed in the Digital Command Language develop the necessary software. Furthermore, CATls require (Del) which invokes SAS routines to collect and eefit the data, as computer programmers to develop and maintain them, thereby well as produce standard reports and monitor system status. The system was designed to be user friendly. reliable and have good increasing personnel costs. screen response time. This paper will address the hardware The question then becomes how to weigh the advantages versus confguration, the sofbNafe implementation and techniques used the disadvantages. ARC decided to develop a CATI based upon to manage the survey. the following considerations: Efficiency. We knew that CATls were more eHicient than During the last decade, Computer-Assisted-Telephone- paper-and-pencil surveys. Survey management resources Interviewing (CATI) systems have supplanted the traditional were limited for our surveys and we believed that the CATI paper-and-pencil procedures for administering survey would help us maximize our limited resources (e.g., people, questionnaires by phone (8erry and O'Rourke, 1988). The purpos",Sugi-90-158 Fasullo Trumble.txt
"or alias feature identifiers) requires an extremely cumbersome dou- ble merge in which you must merge with one or more TIGER4 index records that contain repeated keys, which tllen have to be looked The U.S. Census Bureau is generating block level detail computer- up in the TIGER5 file. Tilis is okay for a transport format but obvi- ized maps as a part of the 1990 Census of Population and Housing. ously much too cumbersome to be left as the final applications for- The availabitity of such computerized files will greatly enhance mat graphical display of demographic data in govemment and bUSiness applications. Prototypes of these maps are available in line segment The bottom portion of Figure 1 depicts the structure of the TIGER form. SAS"" macros are presented that convert these line segments SOL. It helps illustrate the following key features of our new data into geographic polygons for mapping. Files are converted in a main- structure. frame session, and resultant SAS files are downloaded using the micro-to-host link, for polygon chaining and SAS/GRAPW process- ing. 1. pointer variables, (that is, variables whose values contain the ObServation numbers of other SAS data sets so that they can be used to access those data sets using the SET",Sugi-90-159 Blodgett McIntyre.txt
"GVTEXT vertical text GXAXIS. GYAXIS axes. SAS/IML"" software, an interactive matrix language, contains both a powerful set of graphics primitives and the ability to create cus- A set of commands is available for managing segments: tomized graphics routines using these primitives as building blocks. GOPEN begins a new segment. This paper explains how to GCLOSE closes a segment . .. use SAS/IML graphics commands for drawing primitives such as lines. circles, points, and polygons GDELETE deletes a segment from the catalog. GINCLUDE includes an existing segment into the .. use SAS/IML graphics commands for placing text on the current segment. graphics output GSHOW displays a segment. .. assign attributes such as colors, line styles, fonts, and fill patterns to graphics output INTRODUCTORY EXAMPLE .. generate advanced graphs interactively and incrementally For example, suppose you want to plot YEAR*FEMALE for popula~ using the primitives tion counts in the United States for the years 1950 through 1985. · arrange one or more graphs on the display device using To do this, you must first initialize the IML graphics subsystem: viewports call gstart; .. develop a toolkit of customized graphics routines using Set up the input matrices: SAS/IML modules year = (1950, 1960, 1970, 1980, 1985); .. save and manage SAS/IML graphics segments in a SAS 1* Data for females are in K units *1 female = 176, 91, 1011, 116, 1231; catalog. Open the graphics segment under the name POP_PLOT:",Sugi-90-16 Binkley.txt
"t Indianapolis Shu-Yeng Wong, Indiana Univ. data contained on the scanning sheets are BACKGROUND saved as a eMS file. A data file therefore may consist of more than one set of data. The test test scoring service has been provided to A scoring program must have some kind of the faculty members at IUPUI and to the mechanism to deal with the separation of data external users by the Department of Computing sets. Services since 1983. Originally the test scoring program was written in COBOL. running 2. The data sets may differ with each other in under DEC-20. However, developing a new the number of items, how they are to be program to replace the old one became scored, and the optional reports requested. necessary after the official announcement to The test scoring program must be able to remove the DEC 2060 in 1988. handle the differences among the data sets. INTRODUCTION 3. In order to avoid needless effort in programming and invalid statistical results, The new test scoring program has to produce the decision was made to take advantage of the three different outputs. Besides the printed proceduces supported by SAs or other authors output, which displays the students' test as much as possible and to put the programming score and some statistics, the program creates effort into the customized reports only. This a score file and a hilling file. The score consideration would result in the correct file consists of student's name, score, number computation and better quality report. o",Sugi-90-160 Rutherford Wong.txt
"to a The Occupational Safety and Health Act particular hazardous substance. The of focused attention on the 1971 model considers the dose or level of a possible overexposure of Gulf Oil's hazardous substance for an operator refinery workers to hazardous working various shifts on a refinery substances. A project team was formed unit during periods of time. The of employees from Gulf Management intent of the model is to remove Sciences, Gulf Research & Development variance attributable to a model factor Company's Industrial Hygiene Group and from the variance estimate for an the Information Sciences Division to operator's exposure to a hazardous investigate the matter and develop a substance in order to improve the statistical information system capable precision of the statistical statement of determining the levels of hazardous with regard to overexposure. See substances in the refinery environment. Figure 1. The model also illustrates dose distributional differences by Hazardous Substances at the Refinery attempting to pool variances across the levels of factors in the model. Major oil companies are in the bu~iness of refining gasoline from crude 011 and An initial set of noise exposure data employ thousands of persons to operate was collected at the Port Arthur and manage the refining facilities. refinery in Beaumont, 'Texas by the Refinery operators, especially those industr ial hygiene group. The data that work on units that distill formed a base case for testing the gaso",Sugi-90-161 Brodine.txt
"MANAGING A MULTI-USER SAS'DATABASE WITH VERSION 6 SASjAF' SOFTWARE: GENERIC TASKS Todd C. Folsom, Duke Power Company tion process. Hence the SAS/AF application INTRODUCTION provides for individuals to access their person- al subdirectory, but, unless they are also one Tasks generic to database management of three authorized updaters, they -are kept out include providing for data entry and data vali- of the subdirectories where the permanent data- dation, updating master datasets, making back- sets reside. ups, controlling access and keeping quality assurance records. All of these tasks are more The purpose of this paper is to describe complex when multiple users have to be accommo- how multiple users can be accomodated, how dated. However SAS/AF and base SAS provide many access can be controlled by identifying users to tools for accomplishing them. the system, how to identify source and destina- tion for datasets, how a rotation in updating There are three major areas of activity duties can be achieved, and how QA records can that have to be managed: 1) data entry and be generated. validation by many users, 2) letting the users generate printed requests to update (append) LAYOUT OF THE HARD DISK validated data to the appropriate permanent dataset, and 3) having authorized updaters The major separation to make in laying out supply information on the source and destination the directory structure of the hard disk is of the data to the AF application. It is good between the personal subdirectories of users and security practice to rotate the duty of updat- the subdirectories where data will be stored ing, so the-AF application should be able to (Fig. 2). The \DATA subdirectory contains the AF determine who is the next person in rotation application catalog, the format library, and and assign the job to them. This determination certain lookup files needed across the database. can be integrated with keeping track of update Subdirectories under \DATA contain the environ-",Sugi-90-162 Folsom.txt
"ed. with Release 6.03 SAS has achieved a near perfect Work on environmental problems has system. To be of value as a become so complex that computerized database management system for methodologies are needed to meet the environmental problems a system must environmental objectives of all support the following features. It studies. This system must be must allow hands-on use by engineers powerful, with a broad range in and scientists, by providing a analysis functions, yet be an user direct interface to computer models II friendlyll system. SAS was the which support environmental site choice of the application language investigations. for the development of this system by Roy F. Weston, Inc. (WESTON). At WESTON the use of computer This paper describes the evolution systems in solving environmental of the use of SAS as a database problems has been given the general management system for environmental heading of Technical Information problems into one integrated system Management Systems (TIMS). TIMS was using SAS Release 6.03 products. A initiated to develop a problem is detailed description given solving computerized methodologies describing a menu driven system and software for application to meet developed at WESTON using and the environmental objective of integrating SAS macros and the conducting site-oriented, following PC SAS Release 6.03: multidisciplinary characterization SASjAF, SASjBASE, SASjFSP, of hazardous waste sites. Work on SASjGRAPH, and SASjSTAT. TIMS began a",Sugi-90-163 MacDonald Kreamer.txt
"system~ as well as stand alone 386 microcomputers, and recently on a SUN· SAS software is an integral tool within workstation. Staff are able to perform the scientific community in the similar SAS functions on each machine. Mid-Pacific Region of the Bureau of WORKSTATION CHARACTERISTICS Reclamation. Principle investigators. analysts, and program managers are able to assess the Region's hydrology, water Components of a successful stand alone quality, and biological conditions unit include communications, access to effectively with SAS statistical and data, graphics, statistics, modeling, graphic software. The Regional Staff and report writing. Each of these attributes are described in detail. are using ""workstations"" to process data and information. Key elements of the Some components are what would be stand alone units include considered common since tools. The communications, data access, graphics, scientist or principle investigator can statistics, modeling. and report become self sufficient when unit is properly configured. writing. Paper focuses on the role and value of each component. The units A. Communications include 386 class microcomputers as well as UNIX' based systems. Mainframe computers are also being used and Communications can be in the form of the include the Bureau's VAX"" 8300, and following: E.P.A.'s I.B.M. computer system in North 1. Telephone Carolina. SAS software is available on each platform. Distributive data 2. Mail (hard copy) processing has proved to be cost 3. ""Sneaker - Net"" 4. Asynchronous effective in both time and money. 5. Synchronous",Sugi-90-164 Young.txt
"a local area network was not available CAMS - the CLearing Account Management System - has Thus, CAMS was constructed on three platforms: components in the eMS, MVS and PC environments. This paper will describe the business probLem solved by 1. PC: Cash Deposit System - a SAS/AF* based CAMS, each of its major components and how they system to capture check deposit informa- interrelate, and discuss some design challenges that tion which is uploaded to CMS were met. It also illustrates some of the techniques and tricks used to build the system and send data 2. MVS: Daity Accounting Scan - a batch SAS across environment boundaries. job to capture the accounting information from nightly processing and send to CMS BUSINESS PROBLEM 3. eMS: CAMS proper - to reconcile the PC and The Accounting Service's unit of Aetna's life Opera- MVS data and to maintain the file of tions department handles approximately 700,000 cash outstanding differnces items per year for individual life insurance policies. These items represent funds paid for claims, surren- ders. loans, refunds and dividends; funds received for premiums, contractual changes, Loans and miscellaneous I--~CAMS deposits; and transfers of funds between different DATA policies. A rigorous reconciliation process is CMS ACCOUNT NG required to ensure that these funds are properly lD DATA lD handled. Reconciliation of the flow of funds takes place within an accounting entity known as a 'clearing account', so named because every entry int",Sugi-90-165 Rickards.txt
"- A DECISION SUPPORT SYSTEM FOR MANAGEMENT ~!IS Birgitta Wagner, Volvo Car Corporation Kristina Hogberg, Volvo Car Corporation The Management Group already from the SUMMARY beginning put a number of requirements The MIS system is a system developed for for the system. They were: management within Marketing and Sales at *Easy to use Volvo Car Corporation in Gothenburg, *Availability Sweden. The project started in 1986 and *Valid information MIS has become a strategic product and a *Structured information. powerful support for management in their decision making. We have in MIS put We, who worked in the project also came together information from many different up with some requirements on our areas, for example sales, stocks, car Management Group. They had to consider: market development, finance and research *Risks/Possibilities of MIS as a coneept and we present this information in a clear *Use of terminals for information and understandable way complemented with retrieval many different graphic display *What information did they want to have possibilities. in MIS *Better decisions with a MIS system? The objective for the MIS project was: providing decision makers within Marketing In January 1986 management decided that & Sales with ""management information"" on a we should start the project 'work and the range of key areas and key markets. The guiding principle were to be: guiding principle in our work was to CREATE ORDER!! ""create order"". PROJECT WORK In the first place MIS is developed for our Management Group, but we have What methods did we use? gradually spread the use of the system and A work group was s~t up, consisting of we have today some 100 users. As we have a people both from the Information System considerable difference in computer department and from different line experience among the users, we have made departments. great efforts in keeping a uniform layout A steering committee was appointed. It throughout the whole system and also to was importan",Sugi-90-166 Wagner Hogberg.txt
"Aspects of LAN-Based Decision Support Systems Eric Klusman Federal Reserve Bank of Chicago versions of the SAS System on minicomputers and mainframes, Introduction mayor may not be present. ·Deci~ion support ~ystems"" refer to the persons and equipment This. paper discusses certain aspects of using the SAS System®, version 6.03, on a Local Area Network (LAN) of MS·DOS® org;;mlzed to prOVide supporting analytical materials to senior personal computers, in a decision-support work environment deCIS·lon makers. Typically this is organized as a staff area rather than line area. In .the ca~e. at hand, the decisions to be supported The author works in the technical support group of the Economic are monetary policy deCisions by the president of the bank and Research Department of the Federal Reserve Bank of Chicago. the board of directors. The departmenfs mission is to conduct economic research and analyze regional, national, and international economic trends. Decision support a~eas typically contain highly educated (MBA, MS, Ph~), highly p~ld ~taff. In this context, it pays to leverage the Findings are used to prepare monetary policy recommendations briefings, and publications. ' expensive la~or With Investme~ts in highly functional computer systems. While such staffs typically contain a few technophiles computer programming is tangential to the real job of th~ The department formerly used a collection of mainframe-based tools f~r data analysis (SAS System version 5) as well as for analysts. prepa~ng. presentatio~ and publication materials. As at many organlz~tions, the mainframe computers are heavily loaded and In th.e context o~ this brief paper, .ntuning"" refers to making ~he m~lnframe suppo~ staff con~entrates on maintaining and practlca.', focu~ed Improvements to eXisting equipment. It is easy to ach~eve Increased LAN performance by major capital Improving the large on+hne transactions processing applications. expenditures, e.g., by converting to fiber optic cabling.",Sugi-90-167 Klusman.txt
"epartment of Testing Services ABSTRACT THE FILE STRUCTURE Personnel in the registrar's office at Syracuse The data required to make enrollment University needed a method of informing the projections was stored in two systems, the schools and colleges within the University as Future Semester Registration system (FSR) to the demand for courses during the pre- and the Cou rse Maintenance Scheduling registration process. This paper will show system (CMS). The FSR consists of data how the SAS'"" System was used to project records, one for each student, which are final course enrollments so that academic units comprised of a biographical information on campus could make informed decisions segment, and up to twenty three course regarding the allocation of resources for segments (figure 1). additional sections of courses in high demand. Future Semester Registration Record ( FSR) This session will highlight: 1) efficient Bioll""'phicai S<lgmenl ( One Oc:c1mnce ) methods of accessing variable logical record I I I~:s~.1 co~~ . . . ==,='---' length data files, 2) the powers and flexibilities of the SAS DATA step, and 3) the creative Name SSN use of SAS procedures to aid in calculations. The paper will also touch upon how the Course Segrneru (Up 10 23 Occurarces J results led to the administration's realization of I R~~e~~ I ~:~ I CT~~ l-- the need for a more complex Demand Tracking System (DTS). Course THE NEED 1-_-1 Course Title L...::::::::::""""""-""""=--'-----' During the pre-registration p",Sugi-90-168 Storrings.txt
"dicate problems that must be taken care of immediately. ABSTRACT Because calls to the help desk are often transferred to another area of expertise, it is essential that the data entered from the initial call Tracking problems that arise in an Infannation Systems environ- route Information to the other areas quickly and easily. The ISTRAK ment is not a simple task but is very necessary to ensure a quality concept allows this. operation. Problems that should be tracked in Information Systems arise not only in the data center itself, but also in the areas of hard- The Data Center Operations department monitors and controls all ware communication and management infonnation systems (which aspects of system activity in the data center. The goal of the track- includes user services). All three areas need special attention, and ing system is to record any abnormal activity that occurs and to use though they differ in many ways, the basic tracking information is that information as a means of correcting a problem, finding any shared among them. Because of this, it is optimal to create a system trends in system malfunctions, and scheduling system downtime. that combines these areas into one Information Tracking System. Data are shared among each, yet they also contain information unique to their particular environment. It is also optimal to provide INTRODUCING ISTRAK a way for incidents to be routed from one area to another without leaving the data set. Accomplishing these tasks involv",Sugi-90-169 Perry.txt
"Step you are writing a computer program just as sure as if you were DATA Steps are: using a language like COBOL, BASIC, or C. SAS provides many features that make DATA Step o computer programs programming much easier than programming in one of the traditional languages. But, sometimes these o you are the author features mask the fact that you are writing a program at all! An understanding of how the DATA Step works, PROC Steps are: under the coversu, is essential for attacking complex Il o programs written by someone programming tasks and debugging. This tutorial outlines the special features and hidden functions of else the DATA Step and common DATA Step statements o you specify input and options in an effort to enhance this understanding. Since the DATA Step is a programming language it While conducting SAS training I have often run into gives you almost unlimited flexibility ... students who have used SAS for years without realizing or fully appreciating how the SAS system and the SAS DATA Step in particular really works. The SAS DATA Step gives you ... The distinction between DATA Steps and PROC Steps is not often clear. And the DATA Step is ... complete control of the often viewed as something a bit mysterious. computer The SAS system and the DATA Step function according to a strict set of rules. Once you **** understand these rules, DATA Step programming ""Anything you can do with a becomes less a matter of magic and more a material computer you can do with a skill and",Sugi-90-17 Miron.txt
"attention are discovered. These problems are documented in a Customer Issues Report and the This paper presents the conversion of a time-consuming process is referred to as Problem Tracking. Problems are manual reporting system to an on-line data collection routed by the survey administrator to various managers system with automated reporting and graphics. The involved in the program, via electronic mail (E-mail). project is a symbiosis of the SAS® System's statistical The disposition of the issue is reported by the manager and reporting tools with the Sybase® database, all in a and status is published bi-weekly at a meeting. SunOSTM environment. The preparation of the survey results took I week, after The system, ""SUN_Q"", collects the results of a monthly the phone calls were done. The preparation of the customer satisfaction telephone survey (recently dubbed Customer Issues Report took another week. The rest of ""customer delight"" by our 35 year old CEO). The complex- the month was spent on targeting customers to call and ities include: making the calls. Downloading selected survey sites from an Creale a ""New Automated"" System IDMS® database on a mainframe. Obviously what the users needed was a system that Collecting the data in Sybase® and passing it to would automate the reporting process! They gave us the the SAS® system. requirements: ... Passing off serious customer issues to a Obtain Monthly ~ment Data: In order to survey 10% sub-system for personalized handling,which",Sugi-90-170 Castell Desjardins.txt
"level reporting for all of the Corporation's three data centers. Service level reporting began at PNB in 1973 with 10 applications In the past, a bank's dependability and 25 customers and was may have been gauged by the size processed completely manually. and invulnerability of its vault. Today a large financial institution We now report on 253 on-line applications and 236 batch may just as likely be judged by its customers, especially its corporate deadlines to 163 customers. At the customers and affiliate banks, present time, failure reporting, daily based on the reliability of the & weekly project management, bank's data center. The bank's service level agreements, and computer handles inquiries, monthly service level reporting are records transactions, and transfers automated using the SAS® system. funds. It must be ""up"" as much as This system has proved to be an invaluable management tool in possible to keep the customers providing a higher level of service satisfied and allow the bank to keep the customers. Pittsburgh to our customers. National Bank has chosen to use the SAS® System to create an application to track all Data Center Why Report Service Levels? problems, monitoring ""down"" time, cause of outage, impact to customers, etc. This menu-driven · Reporting service levels requires operations and the customer base system uses SAS/AF"" and to come to a common agreement SAS /FSP"" for data entry and maintenance, provides availability via a Service Level Agreement. and service level reports for management, and also · Publishing the service levels incorporates FSLETTER to keeps the customer base informed automatically produce service level and provides a common document agreements for Data Center to be used when operations and customers. the customer meet. · Service levels identify specific",Sugi-90-171 Horne Messmer.txt
"1. Sub-minute response time on queries against a SAS data set containing 1.1 million observations and 86 variables. Most major companies have an enormous amount of useful information stored on their 2. Limited work file size so that the Miles mainframe computers. Due to a lack of TSO system can support the system. computer expertise on the part of most managers, however, this information can 3. A user interface that is flexible enough usually only be accessed via standard reports to allow a wide variety of data queries and or predefined queries. The use of SASjAF display formats. software can change this situation in that it can provide the power of the SAS® system to 4. A user interface that requires little users who are unfamiliar with the SAS back-up documentation and that can be used by language. people with low levels of computer literacy. This paper describes the Sales Inquiry System 5. A choice of either tabular or graphical that was written using SASjAF software. This display. system permits Marketing managers at Miles, Inc. to retrieve, summarize, and display detailed sales data by responding to the menu THE DESIGN OF SIS prompts. The user can retrieve and summarize on the basis of customer. date, product, Using these system requirements as a guide, product family, state, county, type of sale, SIS was designed using the following tools: etc., or any combination of the above. The information is then presented in either a SAS/AF. SASjAF software was selected as table or a graph. the user interface since it permits thc usc of menus and customized screens that guide",Sugi-90-172 Yates.txt
"STATLAB REVENUE SYSTEM Pamela G. Spurrier, University of South Carolina Establi~hed in 1977 to formalize the consulting efforts of the the employee code = 0) or to salary and fringe benefits using the appropriate rates for the specific empJoyee type. Statistics faculty. the Statistical Laboratory (StatLab) offers a broad range of consulting services to its clients. Fees charged for its services contain three components: In order to determine the appropriate facility charge sub- component rates as well as the appropriate salary and fringe a salary and fringe benefits component based on the benefit rates given the rate schedule date and employee code, an indexing scheme was developed. In the foUowing description, the employee-type salary and fringe benefit package; variable i, j and k are defined as follows: a facility charge component that is based on an annual i identifies the rate schedule. cost study aOO is composed of various sub-components; and, i= 1 to r, the number of rate schedules. an indirect: charge component that is based on university j Kjentifies the employee. pOlicy. j=1 to w, the number of employees. The report at the end of this paper contains a list of these components and sub-components. k identifies the facility charge sub-components. Athough the facility charge sUb-components and indirect k= 1 to c, the number of facility charge component are established once per fiscal year. the salary charge SUb-components. and fringe benefits component may change several times during a fiscal year. Staff cost of living increases usually are effectiVe July By arranging the facility charge SUb-component rates In an array 1 andlor January 1; faculty increases usually are effective October so that the first set of c rates correspond to those for rate schedule 1; graduate student increases are effective at the beginning of the 1, the second set of c rates correspond to those for rate schedule Fall semester; staff merit raises are based on employment date. It 2, ..",Sugi-90-173 Spurrier.txt
"SASe Software and the Single Research SCientist Mic Lajiness Introduction illustration of how sA1fl' can provide a In order to survive, the pharmaceutical variety of useful-functions that meet the industry must discover new chemical needs of scientists involved in the drug entities (NCEls), develop them and then discovery process. bring them to market. The development and marketing process involves obtaining approval through the New Drug Application (NDA) procedure which has been well GENERIC documented in previous SUGI proceedings (1,2,3). This-paper intends to focus on This system is one that meets a rather the role of SAs""'in the support of the drug fundamental need within the research discovery process at The Upjohn Company, environment and was developed in the early a U.S.-based pharmaceutical company. 80's. That need is for a general way to quickly and easily get data into a central Since the early 1970' s sAS8J has been an database system. The need at Upjohn was important tool to workers in the a method for scientists to enter summary pharmaceutical industry. The primary power data into the Cousin system with minimal of SAS®in the early years lay in its effort while being relatively bullet- powerhouse of statistical procedures that proof! Most research data are very quickly became a fixture in terms of NDA similar scientists examine novel submissions. SAS!\vas also used to analyze synthetic chemical compounds for a so-called pre-clinical data but the da~a particular biological activity. Typical entry and management features of SAS"">2 information may consist of 1) the registry limited its role. At that time SAsawas number of the compound, 2) the date of basically a statistical procedure library testing, 3) notebook reference, 4) with some ""other features"". It was really comments, and 5) biological activity not a major player in laboratory value. Examples of biological values automation and research information-based include ED50 values (an estimate of the pro",Sugi-90-174 Lajiness.txt
"DRIVER PROGRAM This paper presents an application of the SAS® The driver program consists of the macro calls system for the preparation of data in comparative necessary to invoke the macros described above. The bioavaiIability studies. These studies compare the rate MAUTOSOURCE and SASAUTOS= options must be and extent of absorption of a drug between two or more used to make the macros available from the autocall treatments. Examples of comparisons typically made library. Initialization of %LETs at the beginning of the include tablet vs. liquid, fed vs. fasted, and generic vs. program assigns values characteristic to the particular trade. Three macros are described and the end result of study to macro variables. Examples are titles, their execution is a permanent SAS data set consisting of compound, and type of fluid being analyzed. An key pharmacokinetic parameters such as area under the example of the driver program follows: concentration-time curve, peak concentration, time to . . peak concentration and half·life. *-*************************-******-************-************** DATB: MM/OO/YY ANALYST : KltA DRUG I ANYDRUG : BIOAVAILABILITY SYSTEM ........ ; USElUD.ANYllII.UG.an'L LIBRARY",Sugi-90-175 Antony Elstun.txt
"TRACT As can be imagined from the magnitude of information that must be collected, computer Increasingly, pharmaceutical companies are systems have long been a part of the drug attempting to enhance productivity by expanding development process. We call a computer system the scope of their clinical information systems to for the collection, retrieval, and analysis of clinical embrace non-traditional users such as: trial information, a Clinical Information System or investigators, in-house clinical staff, and FDA CIS. The three functions comprising the current reviewers. As these systems become common- concept of a Clinical Information System are shown place, companies are confronted with the prospect in Figure 1. Physicians who conduct clinical trials of new drugs transmit the raw data to the sponsor on of having up to five different computer systems, each with incompatible data structures: a remote case report forms (CRFs) which are then entered data entry system; a database management system into a database management system (DBMS). The for traditional data entry; a clinical data review data from the DBMS is transferred to a data analysis system for use by in-house clinical staff; a statistical package for statistical analysis and computer analysis system; and a computer assisted NDA generation of tables and graphs which are then review system (CANDA). incorporated into reports which become part of the NDA. Although a variety of products are used by This paper describes the",Sugi-90-176 Rosenberg.txt
"e CSTS was developed to aid those individuals responsible for the day-to-.day tracking of case record forms: Data Coordinators, The volume of clinical study case record forms which Data Entry personnel and Data Managers. accumulates during the life cycle of a clinical study can be considerable; the number of pages may vary from a few hundred It is important to understand that the Clinical Study Tracking t~ 10,000 or more. Identifying and tracking these individual System does not directly facilitate the data entry nor the analysis pieces of paper with a manual filing system can be time of the raw data to be found on the case record form pages. consuming and tedious, particularly when summary-level information such as a progress or status report is needed. BENERTS OF USING THE SYSTEM With the application of SAS® software products, bar code labels, and a bar code reader. a whole new array of benefits may Tracking case record forms with the CSTS provides users with accrue to those responsible for reporting on the location and a dramatic reduction in the time required to accurately report on status of case record forms, including: the status of clinical studies. The system eliminates the tedium of hand counting hundreds. if not thousands, of case record a dramatic reduction in the time needed to generate forms to determine the number of pages received from the study accurate periodic progress reports site for an individual subject or group of studies. This alone is a major product",Sugi-90-177 Bosch.txt
"THE PATrENT nrSCHARGE REPORTrNG SYSTEM Kathleen A. Jablonski, The Washington Hospital Center INTRODUCTION the old process was very time consuming. The new system reduced production time by A PC-based system for reporting half. patient medical data was developed using SAS software-, SAS/STATe , and SAS/GRAPHe software. The application combines SAS SYSTEM DESIGN database management, statistical analysis, reporting tools, and graphics A SAS database is created by running into one system. The system allows for PROC DBF DB3. This converts the dBASE rapid information retrieval and files into a temporary SAS dataset. The reporting. Many of the advanced SAS program checks for invalid records features of SAS are used including SAS such as duplicates, invalid data values, MACROS, Macro functions, and NULL data and patients whose status is unknown. steps. Corrections are then made to the dBASE database file. PROC DBF DB3 is executed BACKGROUND again. New variables such as length of stay are computed in a SAS data step and OVer 2,000 patients are discharged a permanent SAS database is created. The yearly from the General Surgical Services monthly summary reports are then at the Washington Hospital Center. Each generated. patient l s care is provided by one of four surgical teams. Each team is responsible The reporting component of the for entering information such as patient system was written using SAS MACROS. The diagnosis, surgical procedures performed, calling program sets up the file and discharge status into a database. definition statements, includes the Data entry is done by the physicians MACROS, initialize macro variables, and using a dBASE IV-based system. The invokes the MACROS. By modifying the surgical procedures and morbidities calling program, the system can generate reported are coded by a research analyst a number of different reports. There are into ICD-9 codes. Hospital charges for 17 macro programs which can produce up to each patient are also entered. 65",Sugi-90-179 Jablonski.txt
"ract My Introduction to SAS Software SAS software is certainly well known as an end user My last COBOL programs were written in 1977 under tool for the more casual computer user. Data processing staffs however can exploit SAS as a full these circumstances: featured programming language to produce both one- shot applications and full production systems. This Our company used two different data centers and communication between them consisted of RJE stations paper will concentrate on the features of SAS that make it an excellent tool for programmers. It will that appeared as card punches and readers to the two present a series of short applications that show how hosts. They were actually tape drives, but a lot of card SAS can fit in with the other languages used in your image data would be ""punched"" from one system and then ""read"" into the other system. shop and make the programmer's job easier. One particularly critical system was passing thousands Introduction of 80 byte records, but only using 20 columns of each record. This process took several hours and one night at 4:55 my boss told me that I needed to write two Working with both programmers and non-programmers programs. On the transmitting system I was to read 4 over the years, I have noticed that programmers are often the hardest to train and also difficult to get to try records, stack the used portions onto one 80 byte record that was now completely used before transmitting SAS software. An in-house programmer from a i",Sugi-90-18 First.txt
"All data for patient encounters in This paper describes the use of the our group model HMO are processed.on SAS System for PCs to transfer data Digital Equipment Corporat1on a from external sources and do Micro VAX 3600rR) (MV 3600). We management reporting. Discussion also maintain our online reservation will focus on the development of a system on the MV 3600. The MV 3600 decision support system in a large uses the VMS(R} operating system as health maintenance organization. a host to a MUMPS(R) operating Areas covered will include-general system and software. experiences and problems concerning the collection, processing and Encounter and claims data for our dissemination of information. independent practice association primary care physicians and all",Sugi-90-180 McCabe.txt
"AN INTERACTIVE FRONT-END FOR A DATA EDITING PROCEDURE USING SAS® WINDOWS Lawrence R. Catlett, NIOSH Lance W. Cameron, formerly with NIOSH The process of defining the acceptable ranges for each question, although simple and We have previously described a method for straightforward, is repetitive, tedious and validating questionnaire-based data using PRoe time·-consuming. These are the factors that FORMAT and a general purpose SAS macro.1 led us to believe that this application is an 'rhe method is descI.""iptive rather t.han ideal candidate for automation. Automation of programmatic and is able to effectively handle the data editing method must address several complexities such as nested structuC'es. issues: However. the method has two serious disadvantages: 1) manually defining and 1) Collection of information that describes coding the fo~ts is time-consuming and valid ranges and actions for each question; tedious and 2) writing the code for the macro calls is likewise time-consuming and tedious. 2) Determination of a format for a given Our review of the method led us to believe question; that much of it could be automated. We also felt that if the method were to be used by 3) Identification of unique formats; researchers, a simple. interactive front-end would be required. 4) Provision to allow the review/edit of previous input. In this paper we describe an interactive, user-friendly front-end to automate the 5) Compilation of all information required to generation of formats and macro calls. We use build the macro call to actually edit the SAS DISPLAY - WINDOWS and macro variables to data. create customized windows for data entry and use SAS to generate the SAS code for the 6) Creation of the actual SAS code for the necessary SAS FOHMA'l'S, as well as to produce FORMATS and macro execution statements. the SAS code for the edit program. In addition, we wanted the program to be This program was developed using an IBM/AT ""universallY"" usable by all SAS users. I.<~or c",Sugi-90-181 Catlett Cameron.txt
"OVERVIEW of SET, MERGE, and UPDATE Richard Alonso, Medical College of Virginia - veu The purpose of this presentation is to provide an If a similar dataset existed for data two as for data overview of the SET, MERGE, and UPDATE one, then these two datasets could be concatenated statements. It is not my intention to provide readers in data three: of this paper with any new or innovative uses of the SET, MERGE, and UPDATE, but I hope that data three; set one two; novice users will find this to be a quick gnide to the uses and differences of each statement and its Concatenation would cause data three to contain all options. These statements only work with SAS* inputs from all the datasets listed. If there are some datasets, so a11 datasets in this presentation and variables in one dataset that are not in the other, paper are SAS datasets. then missing values are used for the variables that are defined in one of the datasets. The SET has four basic purposes: it can be used for copying datasets, interleaving datasets, subsetting The SET statement has various options that can be datasets, and concatenating datasets. A SET used with it. These options are used for interleaving statement should always be followed by the dataset and subsetting datasets. name it references. Otherwise, the SET stands alone and the last dataset created is what is referenced. Interleaving is the process of combining datasets in SET can be used with either permanent or a sorted order. This is accomplished using the BY temporary datasets, or a combination of the two. A statement along with the SET statement. Two maximum of 50 datasets can appear with one SET conditions must exist for thls to take place: 1) The statement. datasets must be previously sorted. If not, use PROe SORT to accomplish this. 2) The variables listed with To copy a dataset, consider the following example: the BY statement must be present in the datasets that are being interleaved. Note that the PROe data one; input @1 name $10",Sugi-90-182 Alonso.txt
"THE SASe SYSTEM FOR pes: SOME SPEED SURPRISES Richard H. Browne, Texas Scottish Rite Hospital For Crippled Children I. INTRODUCTION value reliable to the third decimal place that takes a computer guru and several weeks to find out. Amongst PC SAS· users, no topic generates more intense Interest What I chose to do was correlate readily obtainable information on than how to get the most speed from your PC. The reason is a machine (e.g., microprocessor size and MHz, and the Norton SI simple. While a PC provides us with many desirable features over values) with performance on a SAS benchmark program. From a mainframe (e.g., instant access, autonomy, no additional cost those findings, you should be able to make some relatively for rerunning a program. etc.), pc'S are just much slower than informed decisions. most mainframes. Also, when a boss is breathing down your neck for a result needed in thirty minutes, ANYTHING that could make The third goal is to impart some SAS programming tips that may that PC run faster would be considered a godsend. save you a lot of run time in the future. I have endeavored not to repeat tips presented at prior SUGI's, but will not guarantee that Several SUGI speakers have addressed the issue of speed at past it hasn't been seen at SUGI before. SUGl's, some providing general programming tips suitable for mainframes or PC's (1,2,3) and some specifically for PC's (4,5.6,7). All of these have been excellent presentations and III. DEVELOPING A BENCHMARK PROGRAM should be read by PC users. However, they have not addressed the effects of combinations of add-ons (e.g., EMS, disk caching, math co-processor) across a range of MHz values. The game plan was to see how quickly SAS runs on a cross-· section of PC's configured in a variety of ways. Vv'hat I would like to approach the problem from the point of view of a characteristics should a good benchmark program have? SAS/PC consultant who has been asked: tt should use a representative cross-section o",Sugi-90-183 Browne.txt
"l provide more inform.a~ ABSIRACf tion when a SAS program is being written and debugged. To redefine the PROGRAM EDITOR window, type on its command Don't throwaway your old OOS programs. Integrate them easily into your SAS System. This workshop presents several appli- line; cations and provides attendees an opportunity to implement the integrated system. WDEF 1 1 11 18 and press the ENTER key. On-the command line of the OUTPUT window, type: INTRODUCTION WDEF 14 1 11 18 and press the ENTER key. This workshop was developed at the request of the organizers of the fifteenth annual SAS User's Group International (SUGI 15). On the command line of the LOG window, type: This workshop will demonstrate (1) the parallel nature of the Disk Operating System (DOS) and the SAS System, (2) how to and press the ENTER key. WDEF 1 21 23 58 configure the SAS System environment for current needs, (3) how to execute DOS programs from the SAS environment, and (4) how The screen is now, as shown in figure 2, configured to provide to assign Display Manager commands to two keystrokes. This more information in the LOG window as the SAS program is being workshop is designed with the novice to intermediate SAS System executed. user in mind. The SAS system not only provides the capability of performing ~~~~~~R--""t""""~-'-MC-~-->--------------------------------' statistical analyses and producing reports (both textual and N(lTil, Copyd'lllt(cl 19S:5,86.81 SAS In6titut@ Inc., Cary, NC graphical) on data exist",Sugi-90-184 Fraction.txt
"Tips and Tricks on Rearranging and Manipulating Data and Datasets For Efficient Data Processing and Output Generation Donald D. M. Tong, The Upjohn Company Thomas E. Schneider, The Upjohn Company Pan-Yu Lai, The Upjohn Company Efficient and effective data processing or output generation is for repeated processing). crucial in processing large data sets with many variables and observations. This means minimal typing, less data Example: A set of CARSALE data is given below: manipulation and programming. The SAS® language C~RSI\L~: !)A':'A provides many such tools, for example, PROC PRINT, PROC Phi a9 MEANS, etc., without the use of a VAR statement or with the use of implicit V AR statements X5 - X21 or SMALL_S - - LARGE]; Ibe BY statement; MERGE, SET, 1646 '""' and UPDATE for multiple data sets. The goal of this paper fQrmu,-~d (also session) is to provide additional tips, tricks and techniques to fully utilize the nice SAS® features. We want to group the sales and profit of the same size cars The techniques discussed cover four areas: together. l. Rearrange the default order of variables, Trick #1: Use RETAIN before SET will move variables to 2. Preserve the order of; observations after sorting. the left (beginning) of a data set. 3. Have multiple observations available for FSEDIT, DATA CARSALEI; RETAIN CITY YEAR SMALL_S SMALL] MEDIUM_S 4. Produce cross product, expansion, reduction and subset MEDIUM] .. ; SET CARSALE; of observations for multiple data sets beyond 'MERGE, AdvantageIDisadvantage: RETAIN is simple to use for a SET and UPDATE statements. few variables. Unfortunately, variables preceding the ones to be arranged need to be typed. It is also typing intensive for l. Rearrange the Default Order of Variables. inserting boundary variables, e.g., _I' _2' _3' "", etc. for Usage: In order to process variables in blocks with implicit processing data in blocks. (RETAIN SMALL_S - - variable name specification, i.e., X5 - X21 or SMALL_S - - LARGE_P; does not work). LA",Sugi-90-185 Tong Schneider Lai.txt
"SASI AF® , Other Version 6 Products, and SCL Can Help You Make a Presentation (and Test Your Country Music Knowledge) Julie A. Smith, Glaxo Inc. Introduction You can develop a CBT screen so that one point Is presented Why not break away from the routine flip charts. slides, and at a time. As each point is presented, the text is held on the ove,heads and let SAS® software help you make your next screen while you talk about the issue. You can hold the presentation? By using a combination of SAS Release 6.03 previous pOint(s) on the screen as you move to the next point and later products, with an overhead projection device attached so that the audience is able to see the relationship between the to your hardware, you can develop and deliver M informative, items better and so that the information is displayed for a interesting. and unique presentation. Instead of using the longer period of time. remote control for the slide projector, or fidgeting with the overheads, or worse yet, fumbling with large uncooperative A technique to enhance the presentation of text is to use a pieces of paper, you use the keyboard attached to the PC to bright color for the point about which you are talking. As the change the display. You have total control over what is next point is brought onto the screen, the color of all the displayed on the screen in front of your audience, just as you previous pOint(s) should revert to a less outstanding color. The would with overheads and slides. You will speak as the presentation of the points can be set to automatic, forcing the Infonnation Is presented and will be able to stop if necessary screen to change at a time interval set at development. This for questions andJor discussion. type of scrolling may be appropriate if do not anticipale questions or If you want to go through each point before This technique can be used on various hardware platforms or a coming back to detail each one. Or you can develop the combination of several platforms. The",Sugi-90-186 Smith.txt
"ment of EVAL as an ASSIST application The first step in linking an application to SAS/ASSIST is SAS/ASSIST"" software, currently distributed with base SASe software of the SAS System for personal computers, to tell ASSIST where to find it. This is done by editing (or gives applications developers a platform from which to use creating if it does not already exist) a data set called SAS/W software to build systems for end users. This SASAPPL in the SASUSER directory which indicates the example demonstrates such a system. SAS/ASSIST is used as catalog where the application is filed. Directions for doing this can be obtained by choosing APPLICATIONS from the a user-friendly front end for a forecast evaluation system. SAS/ASSIST Primary Menu, and choosing HELP on the next Full-screen menus guide a user into developing a processing menu that appears. request without needing to have a knowledge of SAS syntax. In terms of writing the SeL code to provide the front end Help screens and automatic validation techniques provide to the application, we found it easiest to adapt the programs assistance as the user pulls data in from SAS data sets, DOS files, or keyboard entry, and then chooses from groups of already included in SAS/ASSIST. While in general it is often more difficult to decipher someone else's code than to write forecast evaluation statistics, including descriptive measures YOllr own, in the case of the SAS/AF software used to develop such as mean square error, Theil forecast",Sugi-90-187 Friend Atkinson.txt
"a split-plot analysis. Unfortunately, these assumptions may not always be In order for a repeated-measures appropriate for a repeated-measures model to be analyzed by using the design because the lack of randomization methods for a split-plot analysis the in the time units usually causes the covariance matrices of the error terms successive observations to be for the time intervals and the subjects correlated. However, the standard within groups must satisfy the condition split-plot type analysis can still be of compound symmetry or the more general used if the covariance matrices of the Hunyh-Feldt condition. This paper measurement errors of the time intervals describes a SAS macro that will test a and the error terms of the subjects set of data for these conditions. It can within a particular group have compound handle any number of time intervals in a symmetry or satisfy the more general tWo-factor (groups over time) Huynh-Feldt condition. repeated-measures design. The macro uses PRoe IML to do the matrix manipulations A matrix has compound symmetry if it necessary to do the statistical tests is of the form for the hypotheses that the matrix of time interval errors satisfies these -+ +- conditions. I 1 I p p p I 1 I p p p 1 I I p p p 2 I I E a I I I I I 1 I ppp +- -+ This implies that the random variables",Sugi-90-188 Allen.txt
"sAS"" IIACRO FOR APPENDING CORRELATION AND REGRESSION STATISTICS TO THE PLOT OR GPLOT PROCEDURES PLOTCORR:A Erik J. Bergstralh, Mayo Clinic output dataset in PROC UNIVARIATE. Any Introduction: When examining the relationship between observations with missing values for two continuous variables (x,y) the usual either y or x are deleted prior to calculating the descriptive statistics. first step is to produce a scatter plot The Pearson and Spearman correlation using PROC PLOT or GPLOT. The is additionally coefficients are retrieved from the PROC often statistician CORR output dataset. The p-values for interested in examining the correlation the tests of the true correlation between y and x and/or the simple linear coefficients being regression of y on x. Also, descriptive significantly different form zero are calculated as statistics for x and yare often of We have found it useful to described interest. under the PROC CORR include some of these statistics on the documentation (see p. 869 of reference scatter plot when presenting results to 1). The simple linear regression In order to avoid the investigator. statistics are calculated from the and save errors transcription Pearson correlation coefficients. transcription time, we have developed a SAS macro, PLOTCORR, to sununarize the To use PLOTCORR one need minimally input only the name of the dataset containing relationship between y and x using a scatter plot with these frequently used x and y and the names of the x-variable statistics appended at the bottom. The and the y-variable. Optionally one can specific statistics included are the control the appearance of the horizontal mean, standard deviation, median and and vertical axis by defining the XAXIS x and y, the Pearson and range for and YAXIS parameters (Table 1). These correlation linear Spearman simple parameters allow one to define the simple linear and coefficients HAXIS, HREF and HMINOR (plus VAXIS, VREF regression statistics (slope, intercept, and VMINOR)",Sugi-90-189 Bergstralh.txt
"FILE AND PUT STATEMENTS David A. Larson, 'University of New Orleans The second PUT statement writes the respective variable values The p..irpose of this paper is to provide a basic introduction to the appropriately. The first instruction is to begin writing the value use of the DATA step fILE and PUT statements to generate reports of the cOlSlting variable (N) in row 4 (the row position after the as an alternative to prodJcing reports with procedJres such as PROC I ine skip) and coll.lm 4 (iil4). The N values are to be in colums 4 PRINT. and 5 (nunerical format=2.). The remaining variable values are written analogously. A hypothetical data set of thirty ;s used for expository ~loyees purposes. The variables included are: NAME, DEPARTMENT. GENDER, At this point we siq>ly state that just about any form of output GROSSPAY. NETPAY. and TELEPHONE EXTENSION. The CCfIlllete input data produced by PROC PRINT can be dupl icated with the appropriate DATA set is provided in Appendix Table I. step fILE and PUT statements. However, and more inportantly. it is possible to generate some report forms with DATA step progrClllllling The first step is to print out the data set using the default PRO[; ~hich ca~t be prociJced with PROC PRINT. for exarrple, our previous I>1I:INT settings. 1llustrat1on has in coomon with PROC PRINT that titles cannot be preprogranmed to change on a page by page basis (using If N = 1 OPTIONS lS=78 NODATE NONUMBER NOSTiNER; invol'll'es this I imitation). -- DATA EMPLOYEE; INPUT NAME $1-9 DEPT 11-13 GENDER $15 OUr next two exanples illustrate two fiLE PRINT options, the GROSSPAY 17-22 NETPAY 24·29 PHONEXI $32-35; HEADER option and the N=PS option. The first exaq:>le produces a CARDS; colum I isting male eoployees and their corresponding departments and telephone extensions. A second colunn gives the same PROC PRINT DATA=EMPLOYEE(08S=S); information for fenate enployees. This report form, which involves TITlE; whole page access, cannot be done in thi1:i DIiI",Sugi-90-19 Larson.txt
"Increasing the Value of Graphs Using the SAS· Annotate Facility Reggie Brett, Seminole Electric Cooperative, Inc. Abstract: Analysis of large amounts of data typically involves where they are converted to text strings for printing on the both summary reports and graphs. Combining the reports graph. In addition, other variables are created which contain and the graphs can sometimes simplify the analysis of the the coordinates used to locate the text on the graph. By data. The SASe system provides fiJ method by which text a including the ANNOTATE option during the GPLOT strings may be combined with SAS graphs. This method is procedure, we can reference the annotate data set and place known as the Annotate facility and is an option to the GPLOT the text strings on the graph. The data in the annotate data procedure. The goal of this paper is to demonstrate how, by set is illustrated in Exhibit 4. using the SASfiJ Annotate facility. text strings and numbers may be incorporated into a SAS graph thereby increasing its As the exhibit shows, the data from the summary report value and reducing the need for multiple reports. has been converted to text strings and is now ready for plotting on the graph. While developing the graph, a Background: macro was used to identify the various day types (Sat, Sun, etc.). This macro can be seen in the listing in Exhibit 5. At Seminole Electric a significant amount of effort is spent analyzing hourly demand data. Hourly demands are Each of the symbol statements is assigned to a defined as the amount of electricity a customer requires corresponding line on the graph. The symbol statement during a particular hour. This data is recorded year-round identifies the line type and the color for each of the lines and is used to bill customers and plan for future growth. plotted on the graph. The line types match the day of the month, that is, day 1 is ploUed using line type 1, day 2 is Each month, a summary report and a graph are plotted using line",Sugi-90-190 Brett.txt
"THE ANALYSIS OF DATA FROM 2 X 2 CROSSOVER TRIALS WITH BASElINE MEASUREMENTS Joe DiGennaro, Merrell Dow Research Institute William C. Huster, Merrell Dow Research Institute One remedy for this problem is to measure the outcome during both a 'run-in' and a 'washout' Kenward and Jones (1987, Statistics in Medicine. 6:911~ period. The run-in period precedes and the 926) have proposed a unified framework for the analysis washout follows the first treatment period. These of data from 2 x 2 crossover trials which include baseline baseline measurements as they are called can measurement:». Und_er this framework, a simple analysis provide a within-subject test of the treatment-by- based on ordInary least-squares (OLS) estimators was period interaction. developed and shown to be applicable whether the data were normal or not. Generalized least-squares (GLS) In an expository paper, Kenward and Jones (1987) estimators were also derived and shown to be related to have proposed a unified framework for the covariance analysis. The OLS and GIS estimators do not analysis of crossover studies with baseline rely on any assumptions about the covariance structure of measurements. This framework is based on a the repeated measurements. linear model for the expectations of the observations and uses either ordinary least-squares The OLS estimators can be obtained using the SAS (OLS) or generalized least-squares (GLS) procedure GLM (1985, SAS User's Guide: Statistics). The estimators. The GLS estimators are similar to the GLS estimators are a liHle more difficult to obtain using analysis of covariance. The OLS and the GLS SAS, requ~ing utilization of PROC IML (1985, SAS/IML estimators do not rely on any assumptions about Users GUide). The SAS code and output for these 2 the covariance structure of the repeated measures. procedures are presented using as an example analyzed the dataset in Kenward and Jones. A brief review of the linear model is presented in Section 2. The OLS estimators are",Sugi-90-191 DiGennaro Huster.txt
"SAS"" EARNS AN MBA: USING SAS IN THE MBA ECONOMICS COURSE Joseph Earley Loyola Marymount UniW!Tsity After gaining some experience in teaching the MBA Introduction business course, I realized that the solution to offering a challenging, rigorous course was to make the The purpose of this paper is to present reflections on theoretical concepts more concrete by combining the the use of SAS in the MBA required course in discussion of each topic with a statistically-based business economics. A discussion is presented empirical project. The principal mainstay of this showing how SAS has become an integral part of the approach was the use of SAS statistical procedures. teaching pedagogy. The author describes how SAS The ease with which the MBA students learned the has made it possible to offer an MBA business SAS system allowed us to use rigorous statistical economics course which is as empirically rigorous and methods far beyond what I thought would be possible challenging as the traditionally offered theoretical in a one semester course. course. The essence of the paper is that for every theoretical concept discussed in the classroom, SAS has made it Structure of the Course possible to add a practical statistical dimension. The paper presents a brief overview of the central topics The first step in implementing this approach was to covered in the course. It then discusses the various review some statistical procedures. Most students will SAS proced ures which are used in each step and how have completed a course in statistics by the time they they build in sophistication as the semester proceeds. reach the business economics course. A brief review For example, PROC UNIV ARIA TE, PROC MEANS of elementary statistical concepts was followed with a and PROC CORR are introduced immediately. PROC one-hour discussion of regression analysis - the main REG, PROC PDLREG, PROC STEPWISE, PROC statistical tool of the economist. Handouts describing RSQUARE, PROC FORECAST and PROC ARIMA",Sugi-90-192 Earley.txt
"An Exploratory Data Analysis Approach to Qualitative Response Modelling Using SAS/IML(R) and SAS/GRAPH(R) Software Merwyn L. Elliott Ross Hightower Caleb Chan Statistical Services Laboratory Georgia State University ABSTRACT: around"" the multivariate classification plot and A graphical exploratory data analysis view the relationships from various angles to alternative to qualitative response modelling is get a better ""feel"" for the data. PROC presented which can either be a precursor to or GREPLA Y is used to assemble graphs for more a replacement for discriminant analysis and efficient presentation (multiple graphs per logistic regression. In taking an exploratory page). approach, analysts have the opportunity to investigate their data through color graphics using multivariate plots and scatter diagrams BACKGROUND: in SAS/GRAPH. Underlying relationships, During the 1970's, the basic foundations for often overlooked in traditional confirmatory exploratory data analysis (EDA) were laid by modelling, can be discovered in a multivariate Tukey, Mosteller and others (See Tukey 1977). exploratory analysis. The basic idea in EDA is to investigate one's data to see what can be done before one As an application example, a data set measures how well he has done it. Hea vy containing both failed and not failed industrial emphasis is placed on looking at pictures to see companies and selected financial ratios is used. not so much what you already know but to The classification problem is to distinguish discover things about which you were between failed and not failed firms given their previously unaware. Rather than replacing financial ratios. confirmatory techniqucs,EDA procedures were proposed to be done side-by-side with Discriminating variables are selected using confirmatory techniques. Much of the early series of schematic side-by-side box and work in EDA involved univariate and whisker plots whereby the degree to which the bivariate analyses on small data sets without",Sugi-90-193 Elliott Hightower Chan.txt
"nce invoked the EXEC uses information provided by the user to create a SAS program (PVA$$LUE SAS), with a logical record In many statistical investigations accepting or rejecting a statistical length (LRECL) of 80 and a record format (RECFM) of fixed, on one's hypothesis is dependent upon the p-value attained by a calculated A minidisk. After the program has been executed the program test statistic. Many tables exist for specification of a critical value of (PVA$$LUE SAS) and the SASLOG (PVA$$LUE SASLOG) are a test statistic that is to be compared to the calculated test statistic; deleted from one's minidisk. Afterthe deletion of these files the disks if the calculated test statistic exceeds the critical value chosen (often used for processing noninteractive SAS are released and detached. based on a p-value desired and possIbly a number of other parame- ters) the null hypothesis is rejected. These tables can also be used If a test other than a Z-test, a T-test, a Chi-square test, or an F-test to find an upper bound and lower bound for p-values once a test is requested the EXEC will abort calculations. Calculations will also statistic has been calculated. An exact p-value cannot be deter- be aborted if negative degrees of freedom are entered. Negative test mined! Many SAS procedures report p-values to the fourth or fifth statistics are acceptable values fDr a Z-test or aT-test. In those decimal place and although four or five decimals are adequate for cases theteststatisticism",Sugi-90-194 Gilbert.txt
"the output data set, and added a value of 1.4'(highest x value minus lowest x value)/(number of grids desired for x Annotate = data set can be used along with PROCG3D to axis, in my case, 30). This is subtracted from the lowest x enhance the visual quality of three dimensional graphics. value as well. I found that PROCG3GRID, which will be Colors can be mapped onto the grid to represent countour used later, often did not include all points on the extremes levels, and annotate can place state boundaries on top of of the graph. This accomplishes that. The values are then the contour to improve visual quality of the graphic. converted to macro variables that are plugged in later on. The code used is given below.",Sugi-90-195 Hillstrom.txt
"The Bootstrap and Jackknife Estimates of Variance: Two Resampling Techniques Using Release 6.03 of SASjIML*Software Margaret G. Hirsch, Ciba-Geigy Pharmaceuticals Tamara R. FischelI, Quintiles, Inc. g. The bootstrap standard error of 1J is = iT b The bootstrap and jackknife rcsa.mpling proccdures are two The choice of B, the number of bootstrap samples, will useful methods for estimating the variance of a statistic depend partiy on the configuration of the personal that have been described extensively by Efron (1982 and computer this program is tu be utilized on. However, for 1986). This paper presents two algorithms utilizing Release most applications, bootstrap samples in the range of 50 to 6.03 of SASjIML * which calculate bootstrap and jackknife 200 or 300 will be adequate. estimates of variance. Some basic background theory for the bootstrap and jackknife are presented, along with a The J adknife Estimate of Variance description of the program code, an example using seat belt usage rates from North Carolina, and the actual program Again, suppose that we have observed data ~ = (Xl' X 2, code. F, and . .. , Xn) from the empirical probability distribution 0 = 9(Xl! X2! ... , Xn ). that we compute the statistic The Bootstrap Estimate of Variance F Assume that the empidcal pwbability distdbution assigns probability ~ to each of the Xi' for i=l, ... , n. ~ = (Xl' X 2, ... , Xn) Suppose that we have observed data = (p I. p 2,···, from the probability distribution F(p) p n, ) n - The jackknife estimate of variance is calculated by L: Pi = 1, where Xi has probability mass p .· Assume that ,""'h i=l 1 sequentially removing the observation and recalculating the statistic for which we wish to estimate the variance is 0. the statistic When the observation is removed, the o= O(Xl' X ilk Xn). 2 ···· , F, empirical probability distribution, is changed and the n:t is assigned to each of the (n-1) observations probability The bootstrap estimate of variance is calculated by utili",Sugi-90-196 Hirsch Fischell.txt
"following example: This poster presents a C function, SIGN IF, that can be x= 8.234; called from a SAS® program to return a value rounded to Y = SIGNIF(X,2); a specHied number of signHicant digns. The rules for rounding a number to n significant digns as implemented Y will be set to the value 8.2. by SIGN IF are: Details for compiling, linking and using a C funclion in a (1) Truncate the number to n digns, and treat the excess SAS program are provided in Ref. 2. digns as a deCimal fraction; The SAS function ROUND does provide some of the (2) If the fraction is greater than 1/2, increment the least capabilnies of SIGNIF; however, ROUND is more limited. significant digit; The ROUND function rounds a value to the nearest roundoff unit which must be supplied by the user. It is (3) If the fraction is less than 1/2, do not increment; difficult to specify one roundoff unit for dala with a large range. SIGNIF is designed to work with ranges of (4) If the fraction equals 1/2, increment the least numbers. significant digit only H n is odd.",Sugi-90-197 Horwedel Horwedel.txt
"data collected during phase one were used as input to the ARIMA procedure to produce an Computer capacity planners sometimes use . initial time series model. The data included regression to correlate CPU resource demand w1th 300 observations for accounts converted a natural business unit. With such an approach, (ACCOUNTS). peak CPU utilization {LOAD}, and load forecasts can be made on the basis of date. These observations produced a business units, which in turn can be derived nonstationary series. To obtain stationarity. from business plans. This paper describes an both the ACCOUNTS and the LOAD time series had approach using an ARIMA time series model to to be differenced once. relate the CPU load demands and the nat~ral business units. The model was developed in The model was developed in three stages order to anticipate changes in peak CPU demand corresponding to its functional components. (load) over time, given the planned conversion These stages were: transfer function analysis, schedule for a new application. The ARDMA intervention, and autocorrelation analysis. The procedure employs a transfer functi~n model.to first two components are deterministic in correlate load with the natural bus1ness un1t of nature, representing structural relationships. the application (accounts converted). an The last component is stochastic, representing 4 intervention model to quantify learning noise and seasonality. This model may be behavior, and autocorrelation to depict written in functional form as: Zt=Tt+lt+N t · seasonality. where Zt is the differenced t'th observation (i.e. LOADt-LOADt_l), T t is the transfer function component, It is the intervention",Sugi-90-198 Hubata.txt
"SAS® as Simulation Langua~e: An Application to Tunnel Construct10n Modeling Ronald R. MacDonald, Roy F. Weston, Inc. Shi-Tao Yeh, Roy F. Weston, Inc. Guillermo F. Salazar, Worcester Polytechnic Institute include the Geologic Module that I. Introduction defines ground conditions, the Deci- sion Module that selects and verifies a tunneling method for the specified ground conditions and the Construction The u.s. Department of Energy (DOE) Module that simulates time delays and Office of civilian Radioactive Waste time durations for condtruction Managemenment (OCRWM) is conducting activities. the studies related to the storage of nuclear waste. WESTON, as one of the The SASe functions provide the random major contractors, has provided lead number functions for generating random technical support to the DOE on the numbers from various distributions. CRWM Program since 1983. WESTON's This feature, together with SAS· file support to DOE/OCRWM includes the underground permanent high-level handling and report writing capability radioactive waste repository construc- allow WESTON to easily develop a SAS- tion cost estimation and scheduling. based computer simUlation program that is used to obtain preliminary estima- The construction of tunnels is one of tes of the advance rates. The SASe the key tasks in the development to the underground repository. program is also used to maintain WESTON's high Quality Control and Quality Assurance standards by computer programs have been used in SIM- checking values generated by the past to simUlate the tunneling SUPER's Construction Module. process. In most cases, the results of these simUlations are used to estimate The SAS-based simUlation program con- the variability of the rate of excava- sist of six modules: user selection tion and/or of tunnel costs. The main module, feasibility check module, geo- sources causing variability on these logic module, construction module, two important parameters are the univariate analysis module and r",Sugi-90-199 MacDonald Yeh Salazar.txt
"Programming with SAS® Functions, with a Special Emphasis on SAS® Dates and Times Ann Doty, Syntex Research Abslracl: How do I lei SAS® know my variable Is a Dale I Time? Although titled ""Programming with SAS® Functions"", this paper's main emphasis is understanding and utilizing SAS® Dates I Times. By using INFORMATS {instructions to SAS® on how to read your Based on questions, easy answers and examples, this paper will data). strive to explain (nformats, Formats, Date I Time calculations, conversions and SAS® Date I Time FUnctions. Examples"" Data Informl; Informat Dataa MMDOVY6.; Input datea; Cards; Whal is a SAS® Dale I Time variable? 122582; Stored as: 8394 It is a numeric variable which represents the amount of time which has passed since a specific time point. It has all of the qualitieS of a Data Inlorm2; regular numeric variable. Input Tirnea TimeS.; Cards; The number of days since January 1, DATES: 17:30:15: 1960. Stored as: 63015 TIMES: The number of seconds since midnight. Data Inform3; Input Dattima $; DATETIMES: The number of seconds since midnight, Cards; January 1, 1960, 29JUN57:04:15; Dattimb=input(Dattima,Daletime13.); Examples' Storad as: -79127100 The SAS® Date value for April 2, 1990 is: 11049 (# of days) (Remember to use delimiters and a 24 hour clock) The SAS® Time value for 10:30 A.M. is; 37800 (# of seconds) The SAS® Datetime value for April 2, 1990:10:30 A.M. is: 954671400 (# of seconds) How do I prinllhese variables oul in a readable fashion? By using FORMATS (instructions to SAS® on how to print your data): Examples' (note: the input values are SAS® Dates I Times) Whal is Ihe advantage 10 using SAS® Dale I Time Data Format1; variables? Input Oatea; Cards; SAS® Date I Time variables allow you the capability to do 2736; calculations and comparisons between Dates I Times. They also Formal Druea Date7.; offer you greater flexibility in the ways you can present (format) Put Datea; your data. Prints: 29JUN67 Data Format2; Timea=4793329; Put Timea",Sugi-90-20 Doty.txt
"ANALVZING AND REPORTING FIXED EFFECTS IN THE REAL WORLD Christopher S. McFarland, Harris Semiconductor In the semiconductor industry, testing another. The importance of test variability in IC test integrated circuns (IC's) is very important in that it can be demonstrated wnh the following examples. verifies that the product has been manufactured according to customer specifications. More than just A single IC device is tested thirty times on a simple measurement, testing IC's involves the one test setup and the results are plotted on a graph, collective use of many different hardware components as shown in figure 1. Because some true value can coupled together. To add further complexity, several possibl e set up combinations exist because each separate piece of test hardware has at least one duplicate. The obvious goal in any IC test area is to obtain accurate measurements that are repeatable over time using any combination of hardware elements. The truth of the matter, however, is that undesirable fixed effects (correlation problems) often exist between similar hardware, causing lack of accuracy and repeatability in the measurements. In this application, SAS software"", utilizing PROC GLM, , ,,, is used to analyze a statistical experiment in an effort ,,, , to identify and eliminate these undesirable fixed effects. The experiment varies combinations of three Figure 1 · Test Variability for one device tested 30 times different hardware components simultaneously and a split plot design is added to allow experiments of this be associated with that unit, and because type to blend harmoniously into the hectic production measurement error occurs, the resulting graph over time will depict a normal distribution of measurements environment. Termed a ""Factorial Experiment with around that true value. Because this represents a Split Plots"", such a technique would work well in any controlled situation where nothing in the setup environment utilizing high resolution measurement",Sugi-90-200 McFarland.txt
"st step is to create the numerator and denominator values using the SUMMARY procedure. A ratio table can be used to illustrate statistics for Second, calculate the ratios using those results. various studies including those done on health Finally, run the TABULATE procedure using the survey and/or research data. One study might calculated ratio. The result is a ratio table containing require a prevalence rate; another might need a ratio. one number in each cell; each number being In order to generate the numbers in table format, a equivalent to the number that would be created by a computation which is essentially a cell by cell division cell by cell division. must be done. I found the resources on this topic to be nonexistent. The purpose of this paper is to provide a resource for other programmers EXAMPLES encountering this problem. While it will not provide answers for all the tables one might have to do, I The records for the subpopulation of persons with the hope that it will give the user a basic idea of how to disease are on one file (DISEASE); the records for approach a ratio table. the total population are on another (PERSONS). The following examples show a portion of the code and the table produced tor the population with the disease, the total population, and the ratio of persons with the disease to the total population. BACKGROUND Health statistics, particularly those relating to diseases, are often presented in table format. The presentation may include the displ",Sugi-90-201 Muffett.txt
"An Automated, Intelligent Algorithm For GPLOT Procedure and PLOT Procedure Graphics Axis Scaling Marcia S. Murto, Lederle Laboratories - American Cyanamid Co. INTRODUCTION This graphics scaling algorithm was developed to solve a problem Rounding the end-point values had to be based on in the graphics display module of a large, automated the magnitude 01 the range, the value of the pharmaceutical data analysis system (TOXSAS). Users of numbers being rounded, and whether the minimum TOXSAS were not pleased with the default graphics axes being or maximum end point was being determined. produced by the GPLOT and PLOT procedures. The users Rounding had to maintaln the 70..£0% spread as cOl'1l'lained that the axes were cluttered, the end pOints not much as possible. ""nice\ and the graphs unpredictable. In some cases, the users The final end points had to allow for evenly spaced disliked the graphs enough to re-enter the data on a PC and use a major tick mar1<s. PC based graphiCS package to prOduce the output, an obviouSly inefficient remedy for a supposedly automated system. APPROACH When enhancements to TOXSAS were planned, a request was made to improve the graphical presentation of the data and to use The approach was to develop an algorithm that would calculate something other than the default axis values produced by the the appropriate end paints, find the value of the step (which GPLOT and PLOT procedures. Since a very large amount of data then determined the major tick marks), identity the appropriate was processed and this was to be an automated system, it was oot number of minor tick marks, and provide this information practical to process the data, have the user examine the data, automatically to the graphics procedure. Although the macro determine the appropriate graphing parameters, and then facility under VMS was limited, it did allow the creation of macro execute the graphics module. Although the users might not variables which were then passed for use in th",Sugi-90-202 Murto.txt
"utility for saving a copy of an image from a monitor; and, (3) WordPerfect has a utility to SAS/Graph· graphic stream files can easily be convert graphic output files to WordPerfect integrated into a WordPerfect 5.0"" document. An internal format. One of the graphic formats example from a document produced for the U. S. recognized by the WordPerfect convert utility is a Hewlett-Packard (HP) 7475 plot file. Environmental Protection Agency will be used to illustrate the procedure and the results of The first two methods mentioned above use integrating SAS graphics. The benefits of a raster (scanning lines that form the image). incorporating SAS graphics into a WordPerfect document will be discussed, as will several The resolution is only as good as the scanner or monitor producing it. The convert utility uses related issues. either raster or vector (directed line segment) images depending on the device's output file. The HP 7475 uses vector images which give a",Sugi-90-203 Neale Teberg Cordova.txt
"Station Using the SAS System to produce data ABSTRACT: Many organizations collect data on collection forms solved the problem, easily. specially designed forms for sales, orders, Data forms can be quickly produced In-house, invoices, research, or other use~. One ~ay.to the final product has a camera-ready generate such forms is to wO:k wlth a ~rlntlng profesSional appearance, and modifications are company, but th; s can be a tlme-consufln n9 and quickly integrated into the form. costly process. A more efficient way is tg produce the forms in-house using SAS/GRAPH GETTING STARTED GSLIDE procedure with the ANNOTATE feature. Rough drafts can be plotted quickly, Have available a working copy of your desired adjustments can be made, and a final form can form, either hand drawn or a copy of an be ready to use in a short period. The existing form you wish to modify. This will advantage of this process is to have control of expedite the form generation. Determine the further changes and modifications. size of the final form, then set SAS/GRAPH GOPTIONS HSIZE and VSIZE accordingly. Once a INTRODUCTION final form size has been determined, a grid template plotted at the same size is Field data collection forms are used to record essential. The grid template (figure 1), forest vegetation information at the plotted on transparency film. allows for easy Intenmountain Station's Forest Survey Project, overlay of the draft copy. ApprOXimate X and Forest Service, U.S. Department of Agriculture",Sugi-90-204 Rubey Waters.txt
"ration ABSTRACT There are several flavors of estimate of the ,riance of the sample mean which can be used assuming Sb and Ss2 are In sampling situations. we wish to be within a certain distance of known. If my represents the estimator of u above, then the simplest expression of the variance of my as given in Snedecor a population parameter with a certain confidence. It is often of interest to know, not only how many primary sampling units are and Cochran (1980) assumes sampling is from infinite needed, but also how large a subsample Is required. Many populations and can be written combinations of these sample sizes will satisfy the confidence statement To decide on what combination of these two sample (2.2) sizes would be optimal, cost must also be considered. A method is Illustrated in which variance components and where b represents the number of primary sampling units and s confidence contours are used to facilitate the sample size represents the number of subsampling units per primary decision process. sampling unit. I. INTROOUCTION ConfKtence Probability Possibly the most common question posed to a statistician is: Lers say we wish to be within d units of the true process mean -How large a sample do I need?- This question usually refers wtth probabiltty (I-a). This can be expressed as only to the number of primary sampling units. In many situations, however, it Is also necessary to estimate the number I < d)= (2.3) Pr(lllly· u l-a. of subsampling units to achieve cenaln",Sugi-90-205 Stead.txt
"Polychlorinated Biphenyls Information Management and Modeling system for the Unsaturated Soil Zone Jin9-Yea Yang, Roy F. weston, Inc. Sh~-Tao Yeh, Roy F. Weston, Inc. Frederick Bopp III, Roy F. Weston, Inc. using SAS0. In the output module, the 1. INTRODUCTION programmer can create a flexible report generator. The SAS® structure yields a fully modular program, and the developer can expand or modify the program easily to meet different needs and requirements Regulatory concerns and remedial actions of simulation. involving anthropogenic chemicals are driven to a large measure by the relative The model is a physically based simula- toxicities of individual chemicals and tion model of an unsaturated soil zone the risk of exposure of the public health that was developed to model the leaching to those chemicals. One of the major mi- of chemicals from a surficial soil layer, gration pathways available to those che- via infiltration of rainfall and trans- micals is groundwater, and the consump- port of contaminants through the unsatu- tion thereof by the public. spillage of rated soil zone. The model was designed chemicals onto exposed soil surfaces, the to simulate various fate processes in a leaching of those chemicals to ground- soil column: advection, diffusion, vola- water, and the migration of those leached tilization, adsorption and desorption, chemicals in groundwater to points of che~ical degradation or decay, biolo~i consumption by the public are, therefore, cal transformation, hydrolysis, catl0n the legitimate concerns of regulatory exchange, and complexation chemistry. The agencies! private industry and the pub- soil environment in the model consists lic. of three media: (1) soil-air (gaseous phase); (2) soil-moisture (liquid phase); Not all chemicals of potential environ- and (3) soil (solid phase). The fate mental concern are similar in chemical (transport or transformation) of a chemi- behavior, and, therefore, not all che- cals in the soil column depends u",Sugi-90-206 Yang Yeh Bopp.txt
"Determining sample Sizes Needed to Achieve the specified Confidence Levels - Binomial Distribution Approach Shi-Tao Yeh, Roy F. Weston, Inc. on some operating systems. WESTON has I. Introduction developed different variations of SAS~ code to suit different operating system requirements. The decision regarding which sample size to use in the sampling plan stage of a DATA F2; statistical survey is always important. ~L~~O~ 0.1: /* CONFIDENCE LEVEL: 1 - ALPHA */ Increasing the number of samples pro- vides more information on which a deci- BAILURE = 0; = STPRO 0.01: /* INITIAL PROPORTION */ sion on statistical inference can be PROPOR = STPRO: = made. As the number of samples is INCREN 0.01;/* INCREMENT OF PROPORTION */ = increased, the chance of an incorrect ENDPRO 0.05;/* FINAL PROPORTION */ PROBC = 1.: decision decreases; however the cost of DO UNTIL (PROPOR > END PRO) ; collecting additional samples also DO UNTIL ( NFAILURE > 10); 00 UNTIL ( PROBC < ALPHA ): increases. This creates a dilemma in PROBC = PROBBNML ( PROPOR, I , NFAILURE J; that too large a sample implies a waste IF PROBC < ALPHA THEN GO TO OUT; = + of resources, while too small a sample I I 1; END; diminishes the utility of the resources. OUT: ; OUTPUT ; The purpose of this paper is to describe =I + I 1; a SAs®program to perform an ""exact test"" NFAILURE = NFAILURE + 1; from which a sample size can be deter- PROBC = 1: END; mined to achieve a specified confidence NFAILURE = 0; = 1; level. I PROPeR = PROPOR + INCREN; END; RUN; II. Inferences About proportions and \MACRO VARLIS(N); VAR NFAILURE Exact Test \DO X=1. \'1'0 'NI LU \ENDI A statistical inference can be performed \KEND VARLIS; for testing whether a stated percentile RUN; DATA Fl.; of -the distribution attains a criterion. SET F2: Testinq if the pth percentile attains ARRAY L{5) Ll-L5: the cr1terion is equivalent to testing DO C=l TO 5; IF PROPOR = (INCREM*C) THEN L(C} = I if the proportion of samples greater END; than the criterion is less than (",Sugi-90-207 Yeh.txt
"using SAS"" to Create WordPerfect., Files Kathy R. Boussina AL2A Corporation Creating a WordPerfecte file in SASe One SASe program (WPINIT.SAS, automates the process of formatting WordPerfect- Initialization) sets up reports. SASe can write WordPerfecfe SASe variables that produce the functions that would normally be WordPerfect"" header and can also processed manually. When formatting provide the specific control takes place from within the SAS program sequences needed to implement this also alleviates the chance that data various WordPerfect- functions. might be altered and provides for a clear This program is written once and is audit trail when changes need to be modified only as functions are incorporated into reports. The following added. illustrates how to write WordPerfect files in SAS- but the technique could probably be adapted for other word processors. A WordPerfecte file always begins with a header containing control codes. This Example 1 shows the initialization program, WPINIT.SAS. header uniquely identifies the file as a WordPerfecte document. By examining the Example 2 shows a SASe program hexadecimal construct of the header, the series of control codes can be hard coded that creates a WordPerfect"" file, in SAS- and written at the beginning of incorporates several WordPerfect- functions and reports demographics what normally would be an ascii output file using the PUT statement from within the data. Data _NULL_step. Once this is done the file becomes a WordPerfect- document Example 3 illustrates the final and many additional Wordperfect functions product that would be printed from can be inserted into this file, for example, within WordPerfect·. centering, bolding, underlining and font size. The author may be contacted at: Kathy R. Boussina AlZA Corporation 950 Page Mill Road P.O. Box 10950 Palo Alto, CA 94303-0802 (415) 494-5667 1180  ~g~ ~ II ''''''II ,,"" I """"'11'-""'11 '''II """"'II """"'II '"" II'n, X,II, X.St, X.so. X,[6, X.OO. 1.19. X,Gt. X.Ol, X.OO",Sugi-90-208 Boussina.txt
"Organizing CMS Flies Using PROC SORT, REXX, and FILELIST J. Le 80uton, McDonnell Douglas Corporation Kimberly figure 7 exhibits our new file, TESTS DATA AO. Introduction The SAS program automatically creates this new file. Deleted files have been eliminated and new files allow space for a 38-character description. With the eight-character filename limitation in eMS and the file type often designated by the particular software package used, it becomes a chore sifting throug~ files Description of REXX Program in your FILE LIST trying to remember the function of each program and dataset. Most likely you have to edit The REXX program used for FILESAVE is an XEDIT each individual file to recall its purpose. Hopefully your macro. This program provides a help screen; saves a files have been well documented to aid in this process! copy of files in the FILELIST being observed; modifies the file for use in the SAS program; and runs the SAS A REXX XEDIT macro creates a file that pulls informa- program when a new FILESAVE file needs t9 be com- tion from your FILELIST and then leaves 38 spaces for pared to an existing FILESAVE file users to describe each file. Description of SAS Program This file is automatically updated to renect changes in the FILEUST without you having to remember which The SAS program is a very simple program which files were added and deleted. The underlying text reads in the new file created from FILESAVE when one manipulation is provided by SAS. The SAS program already exists. It compares the old FILELIST listing includes the use of the MERGE statement and also the with a new fiLE LIST listing and automatically updates SORT procedure. the new FILESAVE file. How FILESAVE Works Summary · Agure 1 shows our·FILELlST. FILEUST is an IBM You can make many changes to this simple REXX product that displays information about CMS files. XEDIT macro to make it more useful for your particular You can use XEDIT subcommands to manipulate environment. For example, our i",Sugi-90-209 LeBouton.txt
"· SAS Tutorial Session - Working with Arrays Dr. Ronald Cody - Robert Wood Johnson Medical School I. Introduction rather than five, the size differential would have been more obvious. Now to SAS(r) arrays are a facility that explain what we did. First, the form of can reduce the amount of coding in a the array statement we used is: data step. Although often thought of as an advanced programming tool, there are ARRAY arrayname[n] sas_variables; many applications of arrays that can be easily mastered. This talk will demon- (where n is the number of elements strate some of the more common uses of and sas variables is a list of SAS SAS arrays. In the simplest form an array is a list of SAS variable n~mes. variables) We can use an array to replace multiple The statement begins with the word lines of SAS code where the only changes ARRAY, followed by an array name. Valid from line to line are the variable names array names meet the same cr iter ia as used, The original implementation of SAS variable names. However, an array ARRAYS prior to Version 5, used what is name may not be the same as the name of called implicit subscripting. We will a variable in your data set. Following discuss this older form of arrays later but for now, we will concentrate on th~ the arrayname, in square brackets {in PC/SAS, {} brackets may also be used), explicit form. is the number of elements (variables) which the array is to represent. An asterisk n*"" may be substituted for this II. Using an Array to substitute a SAS number if you do not care to do the missing value for 999 counting yourself. (Note: I almost always use the form [*] since I do not We will start off with a simple count too well.) Finally, following the example. We have a data set where a number of elements, is a list of SAS value of 999 was used to represent a variable names. The SAS variable name missing value (probably coded by an SPSS conventions - and -- may be used as well programmer). Our goal is to change all as the re",Sugi-90-21 Cody.txt
"ute This file assigns the SAS program TRANSEXEC.SAS (Fig. Abstract 2) to automatically run when SAS is called. tNCLUOE 'CICOMSO [FREEKAN.SUGl]TRANSAS.SAS' The Departnlent of Clinical Data Management at Merrell Dow SU8MIT on Research Institute is using SAS software in a VMS environment to Fig. 2 maintain SAS data files for clinical trials. In order to process large amounts of data into listings and tables for reports to the Food and Drug Administration, these files must be transported from the VAX TRANSEXEC.SAS calls another SAS program. TRANSAS.SAS to an IBM mainframe computer. This SAS/AF application was (Fig. 3), whim sets up the libnames needed to run and actually developed to automate the transfer of the SAS data files from the starts up the application. VAX to the IBM. Using information entered into AF screens designed for the project, this software system writes command files in VAX Digital Control Language (DCl) and IBM JCl to control1l1e LlBNAME ONE 'SYSSLOGIN:'; LIBIiAKE CODES 'ClCO!lSO, [FReEKAN .SUGII'; transfer. These programs are automatically submitted to run in LIBNAM£ DIlUGDAT 'CI CD!lSO, I fREE!lAN I ' ; batch mode on the VAX and the IBM. A transport data set is PIlOC DISPLAY CATALOG~CODES. TR,/\,NSIB!I . !lAIN ,tlENU; RUN; created from SAS files and transferred to the IBM via an RJE con· Fig. 3 nection. On the IBM, a two·step job runs, first creating a transport format data set using the IBM utility IEBGENER, and then new SAS data files using PROC XCOPY. The",Sugi-90-210 Freeman.txt
"DEVELOPING RELEASE 6.03 SAS/Af'D APPLICATIONS AS A STATISTICAL TEACHING AID L. M. Harschnitz, Dofasco Inc. L. A. Abell, Dofasco Inc. Introduction regression. experimental design, measurement system analysis. and statistics for maintenance. These courses are all methods courses which vary from three to six Dofasco Inc., located in Hamilton, Ontario, is Canada's days in length. largest integrated steel producer. The company's steel operations in Hamihon employ approximately twelve While the mathematics required at the basic level is thousand people and produces over four million tons of minimal. the advanced courses require much more flat rolled steel products per year. In the early 1980·s. sophisticated tools for analysis. The choice of the SAS like most North American manufacturers, Dofasco found system for data analysis has led to the development of that ti had to begin to improve qualtiy at a much faster a 5 day SAS Basic Skills course. rate than it had in the past. In order to do this, Management realized that ti had to provide new tools for the employees to work wtih. The obvious choices were Developing an Application as a Teaching Statistics and Statistical Process Control techniques. To Aid promote the use of these techniques, a statistical and statistical process control training program was developed. SAS· software was chosen as a data Why Develop an Application analysis tool. When using the SAS System as an analysis tool, some As this training program developed, several version 6.03 computer and SAS programming skills are required. For SAS/AF applications were wrttten for Personal Computer those who are non-programmers, the learning curve to workstations that have 640K of main memory. These acquire these skills can take a considerable amount of applications are used to enhance the training program time and effort. This can be especially difficult ij the and ease teaching burdens. This paper gives an student is also taking a course in an analysis topic such",Sugi-90-211 Harschnitz Abell.txt
"lip R. Khoury, Cardiology, Children's Hospital Medical Ce~ter, Cinci~nati . Vicki S. Hertzberg, BiostatistiGS,_ Environmental Health, University Of.CI~clnn.atl Chih-Yu Chen, Biostatistics, Environmental Health, University of Cincinnati Richardus Ross, Neonatology, Pediatrics, University of Cincinnati Ideally the statistician/programmer is involved in setting Abstract up the spreadsheet or database, but with the ease of use of the packages, laboratory personnel often take on this task. This means that although the spreadsheet looks easy The spreadsheet format for data collection mirrors the to read for the researcher it is not in analyzable format. In thought processes of the basic scientist and thus its use is order to produce both interim reports, and in readiness for prolHerating in the laboratory setting. This has given final reports, a reliable, efficient, and easy method had to laboratory personnel a great degree of 'control' over their be created to take the data from this entry mode to ready data. The difficulties now posed to the statistician are to aecessability for sophisticated analysis. find a reliable, efficient way to translate data from the spreadsheet format into an analytical format. The specific Rationale problem posed to us involved taking data of a longitudinal nature from the laboratory to analysis. The final form of the' database needed to be a SAS Data are currently entered into LOTUS 1·2·3 but need to database on the mainframe for easy access to both P",Sugi-90-212 Khoury Khoury Hertzberg Chen Ross.txt
"SAS- Manos For Source Program Tracking John Henry King and Donna S. Goldstein> Burroughs Wellcome Co. This paper describes a macro system designed to reduce Examples confusion over the origin of output. It is primarily designed Ex 1. For procedures that produce printed output, use the for eMS SAS users and for jobs submitted to OS from eMS. Using the macro system, output can be annotated so that one FOOTNOTE option in the macro call, e.g. themacrocall: can easify determine the origin of the source program producing the output, and the date and time it was run. %J0810(FOOTNOTE) Specifically, the macro traces the eMS Userid. the eMS generates: minidisk file that created the output, and the date and time FOOTNOTE ""USERIO(FILENAME) 04/03190 11: IS"" the output was produced. Output from SAS procedures. PUT statements, and SAS/GRAPH8 can be annotated using this system composed aftwo EXECs and a SAS macro. To initiate the source program tracking system, users must In this example the user supplies the option FOOTNOTEn. where n = 1 by default and may take on values n = 1 to 10. The modify their SAS ""EXEC and write a QUERYCON EXEC to communicate with VMBATCH0. Changes to the EXECs are JOBfO macro generates a footnote that is lEFT justified. A made once, and saved permanently, on the user',s minidisk for useful strategy is to place a macro call of this form at the future use. beginning of a program. Because footnote statements are The following changes should be made to the SAS EXEC: global statements. all subsequent output is annotated with the JOBIO output string. replace: Ex 2. For graphics procedures, use the GRAPHICS option in the parse upper ARG ARGSTRING with: JOBIO macro call, e.g. the macro call: parse upper ARG fn others '(' options if fn = ""then sysparm = · , %J0810(GRAPHICS,HEIGHT = 1.25) generates: else sysparm = 'SYSPARM' fn NOTE MOVE = (0.0 IN, 0.01 IN) replace: F=SIMPLEX H = 1.25 'SAS' ARGSTRING with: C=BLACK ""USERIO(FILENAME) 04103190 11: 11""; 'SAS' fn others",Sugi-90-213 King Goldstein.txt
"Data validation is all too often the Quick and Dirty Visual Checks forgotten step in the process of data analysis. To spend so much time Many data files have a record length researching the literature, planning a study, less than or equal to 80 columns, which collecting data, and analyzing data without makes it easy to view such a data file on a extensively checking the data invites terminal. Even if the record length is disaster. This paper presents some ideas greater, the file (or a portion of a very large on how to make data management, file) can be viewed on a terminal screen. specifically the step of validating data Table 1 lists 10 visual checks that can be accuracy, a little less painful. Included are quickly performed on an external data file. simple diagnostic techniques, and a These checks are not guaranteed to head description of two programs that can assist off all problems, but hours of aggravation in the process of checking and cleaning (and a lifetime of embarrassment) may be data. avoided by spending ten minutes to actually look at the raw data. There are users who do reams of analyses, later find a small",Sugi-90-214 LeBlanc.txt
"USING SAS SOFTWARE TO DEVELOP A CLINICAL STUDIES STATUS SYSTEM H.·Jean Ueverman,·Parke-Davis Research Division INTRODUCTION Security System Pharmaceutical companies conduct many clinical studies on a It was anticipated that many users would be interested in the variety of drugs simultaneously. At any point in time, studies at information contained in TOSS. However, only a subset of that different stages of development and summarization require group from the Technical Operations Section would actually be coordinated staff effort across departments. The tracking _ allof editing the database. Therefore, it would be necessary to add a these activities and staff responsibilities can be confusing and security system to monitor the users. frustrating if there is no mechanism or tool available 10 organize all pertinent information. Staff may spend needless valuable time and effort trying to determine the status of project activities. Working Prmotype This paper describes TOSS (Technical Operations Status System). A driving requirement for the system was that a working prototype a software system developed at the Parke-Davis Research Division was needed as quickly as possible. Therefore, it was necessarY to maintain status information on clinical study progress. TOSS to have a software solution that included tools to encourage rapid executes in SAS 5.18 under 150 in an MVS environment. The system is currently being tested and used by the four departme~ts development. which make up the Technical Operations Section: Clinical Data Management, Biometrics, Clinical Programming, and Medical TOSS SYSTEM DESIGN Writing. Based on the requireme~ts described above SAS 5.18 was chosen as the software package to use for this application. The REQUIREMENTS combination of SAS/AF, SAS/FSP, and SAS macros would provide the tools to develop quickly. test, and put a system into The requirements for TOSS were as follows: production for department managers to use and review. The TOSS databaSe-c",Sugi-90-215 Lieverman.txt
"COMPARING TWO FILES Humberto Mendez and Peter Russell Instituto de Nutricion de Centroamerica y Panama (INCAP) The topic of this Poster is the comparing of two ASCII files using the SAS system. Much of our data processing work involves the correccion of data files. These files are external ASCII files rather than SAS system files because some of them are quite large, with more than 50,000 records, and because many of them are heterogeneous - a case may have a vary tng number of records and a record may have one -of several possible formats. Unlike other data anal isis packages SAS has no trouble handling these files. After we make corrections in a file, in whatever manner., we wish to assure ourselves that all of the corrections were done correctly and that no other changes in the file had been inadvertantly made. We do this by comparing the original file with the new one. We present two programs to perform this comparison. The first program is extremely simple, can handle very large files, and is fast; but i t works on the assumption that there is a strong correspondence between the two files: the first record of the first file corresponds to the first record of the second file, the second record of the first file corresponds to the second record of the second file, etc. The second program is more complex, but i t does not make the it may assumption of a strong correspondence between the files - be that records have been added or delteted in the middle of the original file or that this file has been sorted in order to perform operation~ a merge This second program does require that each record in these files have one (or more) field(s) which identify it; the program compares records which have the same ""identi flea ticn This program takes more time to run and uses more to '"" memory because i t creates a temporary SAS file for each ASCII file and then sorts the SAS files prior to a merge operation for the comparison .. This is the first program for comparing two fi",Sugi-90-216 Mendez Russell.txt
"This project was undertaken to automate the data-handling To start our program we first define some variables: for a large epidemiologic dental caries study. In this study, many raw data sets wHh numerous variables are %Iet path=c:\work\sas\cpred; created from clinical exams In the field. Using the SAS· libname io '&path'; X statement wHh a rerouted DOS dir command, a list of %Iet master=dmfs89; the input files is generated and then fed into maCros wHh the SYMPUT routine. A master SAS data set is then The DOS path is stored In the macro &path and the SAS created using a %00 loop. This data set has a data set that we will create will be stored in &master. A considerable number of variables which characterize the SAS data library reference, io, is also established. These dental state of the mouth. The PROC CONTENTS variables will be used throughout the program and are procedure Is utilized wHh an out option to generate a list defined at the top to facilHate changes for use of the of these variables that the SYMPUT routine uses to create routine wHh oIher data sets and in oIher studies. macros for repetHive analysis. Again a %00 loop is used to pertorm repeated execution of a procedure for different variables. Using these methods, both data set creation Data Set Creation and the analysis reqUire a minimum of user Intervention. After the inHial setup, the following command is given to the Display Manager:",Sugi-90-217 Murphy Proskin Leverett.txt
"Displaying the data set of inhial Problem Discussed: Interfacing main program variables for user frame SAS applications at sites without modHication whh PROC FSEDIT and a SAS/AF"" or SAS/ASSIST"" applications customized SASIFSP data entry screen; development software. 3. Converting the user modified initial program variables to SAS macro Intended Audience: Beginning to variables using simple data step intermediate SAS programmers who must 'CALL"" statements and ""SYMPUT"" functions, and; develop applications without SAS/AF or SAS/ASSIST software. 4. Customizing the applicalion whh the converted macro variables as Suggested Solution: Interfacing SAS necessary. applications using SAS/FSP data entry NYSDOT has successfully used this software in combination with the SAS technique to Interface single screen macro language. applications as well as small menu driven systems. While no substitute for SAS/AF Benefits: Allows users to customize software, a SAS/FSP interface employs portions of the same SAS Screen Control program/menu variables in a format that Language used to drive SAS/AF and conceals application code, displays SAS/ASSIST software and is far superior detailed user instructions and provides to ""hard coding"" an application. The basic input error trapping capabilities. application programmer may display detailed on-screen instructions, create menus, and establish basic input error Outline: trapping capabilhies without learning I, INTRODUCTION ISPF or exposing program code or m",Sugi-90-218 Perry.txt
"~~\) P4P<59 AMULTI-SITE DATA COLLECfION AND ANALYSIS SYSTEM BASED ON THE SAS' SYSTEM [fA-."" Ray L. Ransom %~ Allen W. Hightower CO-ts:m Brian D. Plikaytis (Listeria) are collected from each hospital and entered into a case Overview report form file. A tracking system for laboratory isolates sent to CDC forms the lab isolate fde. In both industry and government, information systems that Cases of H flu under five years of age are screened for play strategic roles in virtually every aspect of program operations enrollment into a study of the effectiveness of a new vaccine. have become increasingly commonplace. -At the Meningitis and Information needed to screen cases and to conduct the interview Special Pathogens Branch (MSPB) of the Division of Bacterial from CDC is entered into the H flu vaccine study case screening fde. Diseases at the National Centers for Disease Control (CDC), such Information on potential control subjects for this study is entered systems have been in use since 1983, gradually replacing the function into the H flu vaccine study control screening fi1e. The study is of more traditional systems of voluntary disease reporting. Prior to conducted by phone from CDC, where the information is recorded this time, voluntary reporting systems were used to monitor trends in on questionnaires that are keypunched. mortality rates, resistance to antibiotics, and demographics of the Cases of listeria are asked to participate in a study of food cases of the diseases of interest to MSPB. Important studies often preferences. A single screening fde is used for both cases and used cases reported in this way. controls. This study is conducted by phone from CDC, where The new information systems are hospital-based since the information on the questionnaires is keypunched. Additionally, the diseases that MSPB has responsibility for (bacterial meningitis, contents of the refrigerator of consenting listeria cases are shipped Toxic Shock Syndrome,listeriosis) nearly alway",Sugi-90-219 Ransom Hightower Plikaytis.txt
"somw ¥OI iii 01 mvous USUS AI IftlOOOC'lIOK TO SlS/GiAPII HElL BOWARD, IlARRIOTT <DRPOIlATIOII (course notes and text) are an excellent entry into the details of SAS/GRAPH and the approach new users How would you like to take qraphics an inteqral part of your should take. everyday reporting? A picture is still worth a thousand words and· tables, and SAS/GRAP!! allows user-friendly In reviewing the Proceedings frol past SUGI (SAS creation of presentation and infor.ation qraphics. This USers Group International) conferences, I was tutorial illustrates silple, logical processes to lOve frol alazed to find few papers addressing the new or mllber crunching tabular reports to elphatic, concise nervous SAS/GRAPH user. This tutorial will open up graphical displays with no pain! It will address the basic the possibilities for using SAS/GRAPH for basic details of SAS/GRAPH that will enable the user to take a reporting and heyond, and provides a synopsis of quick transition frol base product reporting facilities to basic laterial frol the Color Graphics I course. qraphics procedures. Katerial frol the Color Graphics I course taught by the SAS Institute will be presented throughout the body of this paper. The Color Graphics I course bases its exalples on infor.ation about an office products cOlpany with two divisions: a laDufacturing division with 2 Flipping through the SAS/GRAP!! Users Guide gives you a vivid production facilities, and a distribution division indication of the exotic, brilliant and lagical things you consisting of 6 distribution centers. Data is can produce with this product. Closer scrutiny of the code stored in 5 SAS data sets representing hints at a degree of difficulty that clouds the new user's laDufacturing production, laDufacturing inventory, ability to visualize his problel and data in those forlS. distribution inventory, and orders shipped and orders received at each distribution center. This The lissing link or bridge into the qraphics world COles d",Sugi-90-22 Howard.txt
"FORMATTED TABLES: SAS® MACRO PROGRAMS Will Sullivan, Merrell Dow Research Institute Sharon Haney, Merrell Dow Research institute Harvie Chang, Merrell Dow Research institute Gary Stephens, Merrell Dow Research institute Trt is the effect due to study treatment ABSfRACf Period is the period effect PROC GLM and PROC FREQ are two SAS® procedures frequently utilized to analyze data collected from studies Em>r is the residual error. sponsored by pharmaceutical companies. SAS macro programs were developed that produce concise tables which display the analysis results generated by PROC CLM and PROC FREQ for a response variable that has TYPE III sums of squares are used for the F-statistics. replicated measurements on a single page. These programs eliminate transcription errors in the The error term used. in testing the sequence effect is the construction of summary tables and enhance productivity. Biological examples will be used to mean square of the random effect of the experimental display the tables. unit nested in sequence. All other tests use the residual 1. INTRODUCfION error. The PROC GLM statements are as follows: In the conduct of a clinical trial, many response variables are measured when a patient is seen by an investigator. For example, in an asthma study, an investigator might I' PROC GLM; ADD ""BY VARIABLE"" FOR record FEYl' PEFR and FVC measurements at specified time intervals and rate symptoms of breathlessness, REPliCATED MEASUREMENTS 'I sleep disturbance and overall benefit using a categorical scale. In the analysis of these data, the same model is CLASS EU SEQ TRT PERIOD; frequently used for variables of like types. The PROC eLM output for continuous variables would be printed MODEL RESPONSE:SEQ EU(SEQl TRT PERIOD; on two pages for each response variable and the test results for each categorical variable would be printed on TEST H:SEQ E:EU(SEQl/HfYPE:3 ETYPE=3; more than one page. As a study design becomes more complex, the magnitude of the _response var",Sugi-90-220 Sullivan Haney Chang Stephens.txt
"mail could have been sent free, if a stan- dard had been set for campus addresses. Related Abstract to that was the problem of mail being addressed A mailing list database is an important com- incorrectly; that is the post office had preferred munication tool for any organization. Often maintain- methods and we were not following them. Finally, ing this type of database in a mainframe environment secretarial printers and micros were being tied up is considered too complicated to be done by clerical while labels printed. Often these printers would staff. However, using SAS/FSP® the University of jam and labels would be wasted. North Carolina Highway Safety Research Center (HSRC) has developed a menu-driven system that is The Solution relatively easy to use by most support personnel. Our challenge, then, was to develop a system that The system includes the ability to add, delete, would address the problems stated above, by and modify records, as well as output mailing labels. combining all files and standardizing our mailing Tracking capability is managed through an ''Update procedure. The solution would provide a Report."" Backup master files are generated before · menu-driven and easy-to-use system new datasets are created, and fifth generation masters · way to eliminate duplication are automatically deleted to reduce wasted storage · system with centrally located databases space. Finally, labels are generated in several different · means to document edits and updates ways usi",Sugi-90-221 Williams Fischell.txt
", A. H. Robins Company Wayne Cannon, A. H. Robins Company Chris Bullard, A. H. Robins Company David Martinez, A. H. Robins Company within each program individually. ABSTRACT This was a time-consuming and tedious The maintenance and documentation of task. data-editing programs have been The Clinical Data Coordinators had no greatly simplified by the creation product for tracking the editing of a menu-driven system called Program process. Programs were hand 1isted Manager/Document Producer (PMDP). and checked off as editing was com- This system, which uses SAS/AF soft- pleted. Additionally, under the old ware, allows the Data Coordinators at A. H. Robins to eliminate repetitious procedure, documentation of the pro- programming tasks by utilizing PMDP grams for a project was manually screens to modify a set of editing compiled and typed. These documents programs. PMDP generates a document 1isted and described each SAS pro- for archival purposes and a program gram used to perform edits. The use of manual documentation procedures directory for departmental use. increased the chance of overl ooki ng Using PMDP has significantly reduced a program for inclusion in the track- ing procedure and in the Data Base the programmi ng time per project and has eliminated a time-consuming Release Document. process. Several procedures performed by Data Coordinators involve four repetitious BACKGROUND tasks: The Clinical Data Coordinators at · Generate a set of editing programs A. H. Robins are r",Sugi-90-222 Wright Kish Cannon Bullard Martinez.txt
"MANPOWER, PERSONNEL, TRAINING, AND QUALITATIVE ANALYSIS SYSTEM (MPTQ): A SAS® Software-Based Application to Satisfy DoD Requirements Alman M. Zeld and Robert A. Butler, HAY Systems, Incorporated 1.0 INTRODUCTION a user desires should be the primary factor in selecting a particular machine environment. Manpower, Personnel. Training, and Qualitative Analysis System (MPTQ) is an interactive SAS software application 3.0 OVERVIEW system. The MPTQ system was developed by HAY Systems, Inc. to perform Manpower, Personnel, Training, and Qualitative As in any interactive menu driven system, the MPTO analyses. As a result of a bill passed by the U.s. Congress, the system was deSigned to be a user-friendly system operable by MPTQ analysis is performed by the 000 and the 000 prime any analysis team. The SAS/FSP product was used extensively contractors on a variety of weapon systems. This type of in collecting, editing, and browsing all data files. Ample analysis provides the weapon system developers and the instructions and guidance were built in the system. The SAs/AF Manpower and Personnel Integration (MANPRINT) staff with the product was used in designing menus and screens to capture the capability of conducting a timely analysis to study and support user's requests throughout the analysis session. the impact of the design recommendations on the Manpower, Personnel, and Training requirements. All the 000 branches The MPTO System incorporates four computational require weapon system developers and designers to provide this modules; manpower, personnel, training resources, and cognitive type of analysis to show the MPT future requirements and the requirements. All the Data files required to run MPTO analysis cognitive requirements for those personnel who would be are stored as SAS data sets in a central SAS data library. Each operating these new weapon systems. module uses appropriate data set(s) from the SAS data library along with user inputs and assumptions to establish par",Sugi-90-223 Zeld Butler.txt
"THE GLIM PROCEDURE: AN INTERFACE TO THE SAS""' SYSTEM P.M. Grambsch, J.L. Kosanke, T.K. Therneau, D.J. Sebaid, A.R. Zinsmeister, H.S. Wieand, K.P. Offord. J.J. LarsonKeller Mayo Clinic SPECIFICATIONS INTRODUCTION The following statements are used with PROC The GLIM procedure (PROe GLIM) provides an GLIM: interface between SAS and the GLIM package (Generalized Linear Models) available from the PROG GLIK options; Numerical Algorithms Group of the Royal MODEL dependent - independents/intercept Statistical Society (ref. #1). The GLIM option; package implements a significant subset of the ERROR - error distribution/scale option; methods found in the book NGeneralized Linear LINK - name of link function; N Kodels McCullagh and NeIder (ref. #2). by CLASS - list of classification variables The models fall into a general framework of ~i-E(Yi) - r(Xi P), where XiP is the linear (""factors""); WEIGHT - weightin&-variable; predictor found in ordinary linear models, f is FIXBETA varname - value varname = value '"" a function such as exp or log, and y is assumed OUT - dataset_name options; to have a probability distribution from the POUT - dataset_name options; exponential family. Fitting is done by maximum PARMCARDS; statements for the GLIM program likelihood. -ID variable list; Two methods of interface are provided with BY by variable list; this procedure. The first method is appropriate The MODEL. ERROR, and LINK statements are for standard GLIM models, where the distribution required, or alternatively. an ID statement with is one of: Gaussian, binomial, Poisson or gamma PARMCARDS. and the function linking the mean and linear predictor (f- ) belongs to the power family or, FROC GLIK Statement for the binomial, is one of cumulative normal, The options below can appear in the PROC inverse logit or log log. In this method, the ·GLIM statement: interface appears to the user very similar to DATA - SASdataset any procedure of SAS/STArs software. The user names the SAS data set containi",Sugi-90-224 Grambsch Kosanke Therneau Schaid Zinsmeister Wieand Offord LarsonKeller.txt
"ANALYSIS OF COVARIANCE: REPEATED IfEASURES AND SPLIT-Plur DESIGNS George A. Milliken, Kansas State University INTRODUCTION experimental units larger than the one on which the covariate is measured. There is an estimate Repeated measures or split-plot designs involve sev~ral sizes of experimental units of the slope from all modelS for experimental units larger than the one on which the covariate (Milliken and Johnson 1984 chapter 5). The was measured. The estimates could be combined covariate could be measured on any of the sizes of experimental units. The size of the into one estimate in the same manner as experimental unit on which the covariate is combining inter intra block estimates in an incomplete block design. measured must be considered when constructing the covariance model in order to obtain an When constructing an appropriate covariance model, the covariate term is included with the appropriate analysis. The models and analyses of the models differ from experiments where the segment of the model corresponding to the size covariate is measured on the large size of of the experimental unit on which the covariate experimental unit than when the covariate is is measured. The following example is used to demonstrate the case when the covariate is measured on the small size of experimental unit. This paper presents an introduction to the measured on the smaller size of experimental analysis of covariance by describing a case for unit for a model with two sizes of experimental split-plot designs with two sizes of units. experimental units. Specifically. the situation EXANPLE: The data set in Table 1 contains data from discussed is a model with the covariate is people who were given a blood pressure drug to measured on the the subplot or smaller size of determine the effect on tbeir blood pressure. experimental unit. There are two levels of Their blood pressure was measured once a week analysis, the between whole plot analysis and the within whole plot analysis.",Sugi-90-225 Milliken.txt
"COMPARISON OF DIFFERENT PROCEDURES TO ANALYZE AN UNBALANCED REPEATED MEASURES DESIGN Gilda P. Pareja, CATIE Introduction 1. measuring a number of subjects only once. A repeated measures design with no factor at the between-subject level can There are six types of subjects be analyzed using the univariate depending on the particular combination approach and a two-way classification of two measurers that measured the (Winer, 1971), or the multivariate subject. These types are shown in Table approach with the repeated measures 1, crossed by the four measurers A, B, being the multivariate dependent vector C, and D. (Cole and Grizzle, 1966). The occurrence of empty cells and the consequent Table 1. Types of measured subjects and unbalance complicates the analysis for number of subjects measured of each the two approaches. type (n) (x indicates the subjeot was measured by the measurer at the When using the univariate approach, heading of the coluJIlIl. a blank missing data can be handled by using means he/she was not). SAS/STAT * GLH procedure and Type III or Type IV sum of squares, depending on the Type of n Heasurers particular model (SAS Institute, Inc., subject B A C D 1987). When using the multivariate approach, situations with missing data 1 34 x x have been handled by deleting all the measurements for a subject with missing 2 x 27 x data. Use of maximum likelihood procedures avoids this loss of 3 x 27 x information. Its implementation was made available for statistical packages users 4 29 x x in the 1988 release of BHDP **, with program 5V (Schluchter, 1988). 5 29 x x This paper analyzes anthropometric 6 25 x x data collected in a field study using an unbalanced repeated measures design to compare the two approaches and another simple univariate approach made possible Approaches for analysis 3. by the simplicity of the design. The goal is to estimate differences between levels of the within-subject factor and 3.1. Simple univariate: Method 1 to test whether these",Sugi-90-226 Pareja.txt
"ALTERNATIVE PARAMETERIZATION FOR ANOVA MODELS USING SAS Robert M. Hamer, Virginia Commonwealth University Introduction: The General Linear Model M is a p by I :::: p full column rank matrix. The General Linear Model (G LM) is specified as In many linear models, X' .\ is of full rank, and . hence we may use (X'X)-1 in place of X'X-. Y=X{3+< Many linear models may be formulated in many al- where, ternative ways, or parameterizations, leading to differ- ent model matrices, and different parameters. In gen- Y is the n by p response matrix, eral, anything we can do with one formulation we can X is the n by r model matrix, do with any alternative formulation, although it may he more difficult. (3 is the r by p paralneter matrix, < is the n by p Np(O, 2;) iid error matrix. We call f3 the ""Parameter"" matrix, or the ""Pri- mary Parameter"" matrix, because its elements are the This model subsumes all the usual univariate and primary parameters of the general linear model we are multivariate ANOVA, regression, and ANCOVA-type fitting. Sometimes we may wish to take linear combina- models, as well as many other models (such as canonical tions of the elements of the primary parameter matrix correlation and discriminant analysis), depending on using the two previously Inentioned matrices, L, and the elenlents of X, /J, and resirictions on E, /3, and the = M, forming e Lj3AJ, the ((Secondary Parameter"" elements of X. matrix. We fit this model to data and do two things: = For p 1 (one dependent variable, i.e., Y has only 1. Estimate the elements of {3, and column), all four of the comInon multivariate test 2. Test hypotheses ahout the elements of {3. statistics reduce to the usual F statistic. In this dis- cussion, we will focus for the most part on the model Estimation and Hypothesis Testing matrix, X, and the matrix, L, that takes linear combi- nations of the rows of the parameter ma.trix. For most f3 and :E are, The formulae we use to estimate of the discussion, }'J can be conside",Sugi-90-227 Hamer.txt
"April 10, 1990 3 Estimation of Parameters and Hy- 1 Abstract pothesis Testing This article discusses and proposes a procedure for the analysis of the univariate linear regression model with known general positive Since var(w} = O'~I, most of the results of the standard regression definite covariance matrix with SAS/STAT software of the SAS model hold under (3), in particular the estimation of f3 can be System. Estimation of parameters, hypothesis testing, estimation accomplished using the least squares criterion applied to (3) ,which under constraints and collinearity and influence diagnostics are re- leads to the Generalized Least Squares Estimator (GLSE) with viewed. An example is given to illustrate the procedure. solution KEY WORDS: Linear Regression Model, Collinearity Diagnos- tics, Influence Diagnostics, Positive Definite Covariance Matrix. and variance The Model 2 (5) Consider the model equation j3 is in fact the BLUE (Best Linear Unbiased Estimator) of {3 . y=Xf3+ E (1) Also :s: n, f3 a vector ,of _, (z - Qti)'(z - Q;3) where X is a n x p known matrix of rank p = u unknown parameters, and a random vector with E( E) :::: 0 and pd n-p ~ (positive definite) variance-covariance matrix V :::: O';H for some (y - x;3),H-'(y - X;3) H pd and lT~ > o. In this article we assume that H is known (6) 0'; n p and is an unknown parameter. The common assumption of the regression model is to consider H :;::: I, but in this article we relax is an unbiased estimator of lT~ · Under the a",Sugi-90-228 Hurtado.txt
"l Abstract Method During recent years life-style segmen- A random sample of roughly 4,200 consumers tation (psychographies) has been a re- was interviewed (face-to-face), producing search topic of increasing interest in 4,077 completed and usable return- developing appropriate marketing strate- questionnaires for subsequent data- gies and target marketing. analysis. Each respondent had to answer about 200 In a research project, sponsored by the Danish Tourist Council, a sample of 4,000 questions with regard to his/her holidays, vacational and tourist behavior, respondents was interviewed with regard to their vacation and tourist behavior, attitudes, and preferences. attitudes and preferences. The questionnaire contained questions The data from the section with psycho- about geographics, soeio-demographics, graphic variables were factor analyzed. behavioristics, and psychographies. preliminary cluster analysis; of the raw- data matrix (observations x factor scores) The essential part of the questionnaire indicated that the data structure might be was the section which contained the plagued with outliers. psychographic questions - because it was Then another cluster analysis was con- the information from this part which was ducted (Anderberg;s nearest centroid used as input for the subsequent factor sorting) with the aim of detecting out- and cluster analysis of the respondents. liers. It was suggested that an ; optimal; or A few of the questions used (actually: ;true; clusteri",Sugi-90-229 Schmidt Merser.txt
"discuss: all were Abstract originally oriented towards providing output rather than providing a pure means of data manipulation. Over recent The SAS System may have had its roots in allowing years, though, and increasingly since the advent of Version statisticians to do data analysis, but that's now only one of 5, the SAS System has vastly extended the capabilities of the areas in which it excels. For most of us 000- the!>e and other procedures, making them truly useful statisticians, our principal reason for using SAS software is programming tools. Systems are now being developed with the ease and flexibility it provides for simple, 000- SAS software that really have little or nothing to do with statistical data manipulation, aggregation, subsetting, and statistical analysis Der se. transformation. So in my view, one of the largest pitfalls for the SAS This beginning tutorial will examine a few common ways newcomer lies simply in learning to integrate, quickly and of working with some basic SAS System procedures which effortlessly. the most bas,ic of the building blocks that the produce output data sets that can then be manipulated SAS System provides: data steps and simple procedures. further. Detailed but generally applicable examples will Most beginning and intermediate SAS programmers have a show you how to work more effectively and quickly with reasonable amount of difficulty arriving at an effective data manipulation procedures such as the FREQ, mix of data steps and",Sugi-90-23 Kretzman.txt
"PERSPECT: EXTRACTING PERSPECTIVES FROM SUPER-ENCODED DATA Vincent P. Tillman, Tennessee Department of Revenue not only answer a question on a random topic, but knows Overview whether the question is even appropriate to the topiC. 'How tall is a light?' makes no more sense than 'What PERSPECT is a facility for extracting more conceptual color is an inch?' Information from an exhaustively categorical data encoding scheme. The facility was written using the The mind imposes its network structure to facilHate tasks SAStR! macro facility and those procedures available in like sequencing, priorHies, and sentence construction. base SAS software on Personal Computers.' The mind is, in a sense, a relentless research tool that PERSPECT allows the user to decode data that has been sciences the wo~d about H. It can invent new dimensions encoded ineffectively. The resutt is the creation of a list of and readily place objects In tt. Wtth imagination, even the codes wtth a corresponding array of decode values that height of light can be conceptualized, the color of are more conveniently employed in statistical research. distance, and other such koans. 2 Encoding for digHai processing often means coding numbers. While this makes sense in the computer's SIC and UWASIS wo~d, tt easily becomes esoteric outside that wo~d. Two cases will help illustrate the phenomenon of super· In addHion, researchers often find that computerized data encoding, and tts enigma The first example comes from has been encoded in great detail, but wHh a flat design. the field of economics (specifically, industry, business, The detail Is more an inventory than a description. This and other enterprises). The Federal Office of Management presents a dilemma: uni-dimensional data in a muttl- and Budget has published the Standard Industrial dimensional world. The codeset may be defined and fully Classification (SIC) Manual. Much research is focused on documented, but the task of analysis is greatly aggravated the",Sugi-90-230 Tillman.txt
"Number-of- App1ications- In Version 6 of the SAS'"" System, the lML procedure replaces the Programmers MATRIX procedure. This paper briefly explores some of the enhancements of the SAS/IML"" software product over PROe 15 6 MATRIX and offers insight into their effective use. Induded in this 2 7 discussion will be 20 10 12 4 · interactive processing of statements 16 7 · treatment of character matrices and missing values Although_ the examples that follow illustrate the- new features avail- · external-file input and output able in SAS/IML software, the power of these new· fel$res goes beyond, What is_ shown here . .. data-management capabilities · module definition and execution INTERACTIVE PROCESSING OF STATEMENTS · storage' and retrieval features D4iJRFJg'~; SASllMl. smtwm:e- is aft' if1teFadiye matRili lBfT9wage-. .. statement generation and -ex-ecution execution, it IS interactive at the statement level, which means that each statement -is executed as soon as -it -is Submitted. This enables .. winoo¥t aM .display features- you to;ootain. restJJts- and diagnostic. iflf;Qf.'I:llation: immediately-. If, there is an error, -ali you -need too-do -is correct the pr:oblem- and· r.e-emer · graphics capabilities. the statement; you do not need to resubmit the entire program. This interactivrty is especially helpful when first writirJg -an application -and This paper also briefly -discusses the -MATtMl procedure and -how for debugging. An example of an interacti're""sessiOnin wfli<:h we it can be used to, aid in the conversion at PROC MATRIX code to -cr:eale_ matrices tbat 'co(ltain -the -data for, ·cur -example is snown in PROC IML syrmoc Display 1. proc iml;",Sugi-90-231 Woodward.txt
"NONPARAMETRIC ESTIMATES AND CONFIDENCE INTERVALS FOR THE MEDIANS AND DIFFERENCE IN MEDIANS BETWEEN TWO TREATMENT GROUPS Rodney Wong. Syntex Research Res(~,""H""ch Reiling Lee, Syntax INTRODUCTION can be specified in the ME[)IAN proce- 1. dure. If omitted. the defaults are Although nonparametric tests for the used. median or difference in medians are DATA = SAS data set commonly used (such as the sign test, Wilcoxon signed rank test. or Wilcoxon rank sum test), the associated esti- Specifies the input SAS data set. If DATA = is omitted, the most mates based on data coming from a continuous distribution, are not. recently created SAS data is used. Three SAS macros - MEDIAN, MEDSYM, and MEOIFF - have been written to compute ALPHA P ~ these estimates, and thus offer a useful addition to the nonparametric The default ALPHA is .05. A two- analysis routines. sided 100 (l-p)% confidence coeffi - cient is computed, and a confidence The I~odges-Lehmann estimation proce- interval with a confidence leval dure, Lehmann!, provides a unified as close to the confidence coeffi- approach for obtaining estimates cient as possible is selected. associated with the sign. signed rank, ROUNDERR E and rank sum tests. These estimates ~ are. respectively, the usual sample median (sign test). median of the is used to adjust the confidence Walsh averages (signed rank test), and intervals when there are ties in the data, Lehmann 1 , (page 185). median of the pairwise differences between the two groups (rank sum test). The intervals are expanded by +1- £. If ROUNOERR :;;;: is not In addition. two-sided confidence specified, the value of 0.0 is intervals for the median and pairwise differences between medians are also used. computed. 10 :;;;: variable II. THE MEDIAN MACRO PROCE~YRE If 10 :;;;: is used, the first eight MEDIAN is a SAS_ macro procedure characters of the variable speci- which computes the sample median and fied are used to identify observa- an exact two-sided confidence interval tions",Sugi-90-232 Wong Lee.txt
"UNBIASED ESTIMATORS OF SHRINKAGE FOR CHI SQUARE MEASURES OF ASSOCIATION Richard F. Haase, State University of New York at Albany Users of regression analysis are (Fisher, 1940; Hirschfeld, 1935; Kendall well schooled in procedures for & stuart, 1973; Kshirsagar, 1972; Gilu1a ""shrinking"" or adjusting the least & Haberman, 1988), in the biometric squares sample value of R2 which is literature (Gittins, 1985; Williams, known to be a biased overestimate of the 1952) and in the psychological population value of p2 and that sample literature (Cohen, 1988; Knapp, 1978). values of R2 should be corrected for In the remainder of this paper we shall ""shrinkage"" as a routine part of the (a) review the basic canonical data analysis (Olkin & Pratt, 1958; correlation problem and its solution; Pedhazur, 1982; Wherry, 1931). It seems (b) review the r x c categorical to be far less well known that association problem and its standard sample measures of strength of solutions via X2 analysis, and discuss association derived from ~2 tests of it's corrolary canonical analysis contingency tables are equally subject solution; and (c) adopt a method to overfitting. A brief perusal of suggested by Cohen & Nee (1984) to several introductory, intermediate and derive the expected values of several advanced statistics textbooks popular in least squares measures of association the behavioral sciences reveals that which provide the basis for deriving most, if not all, authors make no shrinkage formulas for four common mention of the potential bias in measures of association in the measures of strength of association multicategory, two-way contingency table associated with ~2 tests (e.g., situation. We conclude with the results Glass & Stanley, 1970; Hays, 1973). of a monte carlo study of the efficacy Although many texts are clear about the of the corrected estimators. fact that measures such as the phi coefficient and its square (~2) are The Canonical Correlation Problem simply Pearson product-mo",Sugi-90-233 Haase.txt
"I: ~ The Jonckheere- Terpstra test is a non parametric test Uuv = 4l(Xiu,Xi'v) for ordered alternatives that is not currently available i=1 j'=l in the SASTM system. This paper reviews the use of where the Jonckheere-Terpstra test and presents an algorithm ifa<b I that can be used to calculate the Jonckheere-Terpstra ={ 0.5 if a = b 4>(a,b) test statistic and its asymptotic p-value. The algorithm o if a > b is written to be Tun in VMSTM but could be easily generalized to run in a macro environment on other Then the test statistic is defined as follows: operating systems. The advantages of this algorithm .\:-1 k k = u<v U·· = u=I v=u+1 U·· L LL J over previously presented methods for calculating the .1onrkhccrc-Terpstra statistic using the SASTM system For small samples, this statistic should be compared are discussed. to tables to find the level of significance (see Lehman, 1975 for tables). For larger samples, define KEY WORDS · J-E.(J) Jonckheere, Terpstra, Nonparametrics, Ordered Al- J = (VAR.(J))1/2 ternatives Under the null hypothesis, this can be rewritten (Lin,",Sugi-90-234 Bailey.txt
"Computation of Variances of Functions of Parameter Estimates for Mixed Models in GLM Ramon C. Littell and Stephen B. Linda University of Florida 1. Introduction There are three subjects at level H and two subjects at level L. Measurements (Y) are made on each sub- ject at three time phases 1, 2, and 3. The data are Estimates of functions of parameters in linear mod- presented in Table 1. els may be obtained from the ESTIMATE statement in PROC G LM. The standard error and hypothesis test produced by the ESTIMATE statement are cor- Table 1. Data used in Example 1. rect for fixed effects models. However, when fitting OBS TIlT SUBJ PHASE Y mixed models, the standard error produced by the ES- 1 1 7.15 H 1 TIMATE statement may not be correct. This is true, 2 2 1 15.30 H for example, in many split-plot and repeated measures 3 1 3 13.25 H applications. 4 2 1 5.61 H 5 2 2 18.00 H A special class of estimable functions are least 6 2 3 12.18 H squares means, also referred ""to as adjusted means, 1 7 5.58 H 3 which may be obtained in GLM from the LSMEANS 2 8 15.81 H 3 statement. GLM allows some flexibility when fit- 9 3 9.33 H 3 ting mixed models by providing the E= option in 10 1 L 1 6.98 the LSMEANS statement, by which an effect in the 2 16.11 11 1 L model may be specified as an error term for calculating 12 1 3 10.35 L standard errors and hypothesis tests of least squares 13 2 1 5.03 L means. However, an appropriate error term is not al- 14 2 16.12 2 L ways clearly evident, and may not be available as an 15 2 3 9.56 L effect in the model. For example, in a split-plot model, no effect in the model is appropriate as an error term for computing the standard error of the mean for a A statistical model is given level of the sub-plot treatment. The CONTRAST and RANDOM statements can be used along with the ESTIMATE statement to de- where Yijk is the response from SUBJECT j in level i termine the correct variance expression of estimable ofTRT at PHASE k, functions of parameters (e.g",Sugi-90-235 Littell Linda.txt
"fference between theoretical statistics and applied statistics is that in the former a probability model is 2 Estimation Method. taken as a given starting poin~ whereas in applied statistics The BOXCOX macro uses the notation and estimation a model is often selected with the aid of the data"" (see [10J.) technique as described in Draper and Smith [6], 225-235. Write the transformed model as: After selecting the variables to be included in a regression = X/1 + £., where Wi = y;{).,) ,i = l,n ~ model, the functional form needs to be determined. Linear model specification may involve a transformation of the variables in the model so that the errors are independent. andXisnbyk. normally distributed and homoskedastic. The Box·Cox Here, we're assuming that the ~'s are not transformed [f family of power transformations encompasses log A is such that £. is Nffi, all), then the likelihood function transforms, square roots, reciprocals, and no transformation. A SAS macro, BOXCOX, has been can be maximized to determine the maximum likelihood estimators (MLE's) for f1. aI, and >.. The log likelihood written to estimate the power parameter 1, perform a modified Anderson·Darling test for normality of the is: L(I!,~,a' I y,x) = -n/210g(2~) residuals, graph the residuals via a frequency polygon, - n/210g(a') perform Ramsey's RESET specification test and calculate -'ha·'I:P' - XC), <1"" -XJ!.) elasticities for the OLS, log-linear and transformed models. +(~ - l)Llog(y.). 1. Introduction. As des",Sugi-90-236 Hallahan.txt
"Program to generate Atkinson's and resistant envelopes for normal probability plots of regression residuals. Rafael Flores"" Instituto de Nutrici6n de Centro America and Panama (INCAP). Virginia F. Flack- University of California at Los Angeles (UCLA). Introduction Normal probability plots of residuals have been suggested as tools to evaluate the normality assumption for regression residuals and they can be used for detection of one or more bad data values (Daniel, 1959). The extent that these problems can be detected depends on the data set and the investigator's interpretative skills. Draper and smith (1981) insist that to gain experience in making decisions on normal probability plots, the user should train himself using sample plots of different sizes similar to those provided by Daniel and Wood (1980). The magnitude of the residuals' fluctuations are a function of the location of the design points for the regression. Atkinson (1981) introduced a simulation-based method to produce a reference set of fluctuations for these plots and therefore, provide guidance as to what sort of variability can be expected when one is using a normal probability plot of regression residuals. BMDP (1987) implemented this method of placing envelopes on the plot in its P2R program. The idea of using simulation as an aid for the interpretation of a particular residual plot is to give the statistician a basis for comparison of the observed plot with an ""expected"" plot, where that comparison is derived from residuals from an appropriately chosen error distribution. Flack and Flores (1989) studied the envelope's stability properties and joint residual vector inclusion levels, as well as alternative resistant techniques for creating envelopes. They recommended one of these resistant versions that showed good stability and good sensitiv~ty to outlying residuals. This paper presents a SAS' program that does both Atkinson's and resistant envelopes for normal probability plots of regression re",Sugi-90-237 Flores Flack.txt
"shington state University J.R. Alldredge, Washington state University J.W. cotton, university of California, Santa Barbara other treatments an equal number of ABSTRACT times in such squares. Wagenaar A general approach is presented (1969) presented a simple method of which makes possible the analysis of constructing such balanced n x n any repeated-measures Latin square squares for all even values of n. design, balanced or unbalanced, with a These so-called ""digram-balanced"" view towards obtaining estimates of Latin Squares possess certain carryover effects (also referred to as optimality properties in that the residual treatment effects), as well separability of the estimates of the as direct treatment effects. ""direct"" treatment effects from the Specifying carryover as a residual treatment effects is greater in such designs than in those not ""classification"" variable enables the adjusted sum of squares for a test for possessing that property, but it is direct treatment effects and for not necessary to have such structure carryover effects to be obtained using to estimate carryover effects. The standard SAS specification statements approach to be presented here involves in PRoe GLM. Differences between the the use of standard SAS specification means of the treatment levels and the statements and differs sharply with carryover levels are readily that of Skalland and Skalland (1984), determined using the LSMEANS whose SAS code relied heavily on the statement. The approach may",Sugi-90-238 Ratkowsky Alldredge Cotton.txt
"RESAMPLING-BASED MULTIPLE TESTING Peter H. Westfall, Texas Tech University Youling Lin, Texas Tech University s. stanley Young, GlaxQ Inc. Centering is consistent with the bootstrap 1. Introduction philosophy but inconsistent with the permutation philosophy. Accordingly, PROC At the 1989 SUGI 14 conference, we MTEST centers continuous variables by presented theory and SASe software (PROe default if BOOTSTRAP resampling is MBIN) for the analysis of Hultivariate requested, and does not center the BINomial data with adjustments for variables if PERMUTATION resampling is multiplicity (Westfall and Young, 1989; requested. Either of these defaults may Westfall, Lin, and Young, 1989). This be overridden using the CENTER and article presents the culmination of the NOCENTER options in the ADJUST P theory and software development begun in statement. - these articles. In particular, the theory The main benefits of using resampling and software have been expanded to allow methods to perform multiplicity continuous variables. The SASe software adjustments are (1) all correlation has been renamed ""PROe MTEST"" to' reflect structures are incorporated into the the facts that (a) the data is not adjustments, and distributional (2) restricted to binary, and (b) the characteristics are incorporated into procedure handles a wide variety of adjustments. In the continuous case, Multiple TESTing applications. benefit (1) is most important, while in Since PRoe MTEST subsumes PROe MBIN, the binary case, (2) is very important of the options discussed in this many when some variables have low incidences. article are described in the previously The resampling method accounts for all mentioned SUGI articles. Readers 14 types of correlations, whether they are unfamiliar with some of the terms inter-variable correlations in a discussed in this article may consult multivariate analysis, or inter-test those articles. correlations, such as when all treatments False significances may easily occur are",Sugi-90-239 Westfall Lin Stanley.txt
"DATA MANAGEMENT PROCEDURES FOR LARGE AND SMALL PROJECTS Juliana M. Ma, Quintiles INTRODUCTION Data Exploration While data exploration is related to descriptive This tutorial presents ideas related to using data management procedures to explore data before doing statistics, the ultimate goal is different. A set a extensive analysis programming. Both mainframe and descriptive statistics (average, maximum, minimum) microcomputer environments are covered. The is designed to provide a statistical profile of the data examples include a simple situation and two types of being considered. The results of data exploration ""large"" projects. (range, list of values) validate data documentation. For instance, if a format or data dictionary imply that The methods discussed are directed toward only four valid values exist for a variable, but five different values appear then appropriate action is programmers, data managers, statisticians, and needed to discover where the fifth came from. anyone who likes to know what to expect from a dataset before defining analysis programs. Only basic knowledge of SAS programming is assumed. The Documentation techniques described apply to all versions of the SAS system. Documentation comes in many fonns. Programs should include internal documentation, in the form of comments, in addition to external documentation of TERMINOLOGY the output (TITLEs). Datasets also may have internal documentation, using variable labels or INFORMATs, in addition to external variable descriptions or data Large File Characteristics dictionaries. The first question associated with large file processing is the definition of large, whether raw files or SAS datasets. A basic characteristic of programming with EXPLORATION STRATEGY large files is that meaningful advanced knowledge resultS in more efficient project data management. The The basic goal for data exploration is simple: use actual number of observations and/or variables minimum programming effort for maximum depe",Sugi-90-24 Ma.txt
"Performance of Multiple Comparisons in Repeated Measures Designs Under Nonsphericity Steve Thomson, University of Kentucky Computing Center Despite the arguments of some statisticians multiple PROCANOVA; comparisons. usually following a significant F test. are a CLASS SUBJ WITHIN; popular way to compare three or more means. MODEL RESPONSE = SUBJ WITHIN; Traditional multiple comparisons, as available in SAS® as MEANS WITHIN I TUKEY REGWF; options to the MEANS statement in PROC ANOVA and PROC GLM. are derived under the assumption that errors will provide valid multiple comparisons under sphericity. are stochastically independent. This is virtually never appropriate for repeated measures analyses. However, when sphericity does not hold, the multiple comparisons given by SAS do not, strictly speaking, If the covariance matrix of the repeated measures control Type I family-wise error, as has been pointed out has equal variances and equal cQvariances then the by Maxwell (1980). Mitzel & Games (1980), and covariance matrix is said to have compound symmetry Keselman (1982). The first two papers, and Keselman & and the usual ANOVA F-tests are valid. More generally, Keselman (1988) include simulations with empirical Huyhn & Feldt (1970) and Rouanet & Lepine (1970), estimates of farnilywise Type I error. However each of showed that the usual F-tests remain valid when the these simulations involves covariance matrices whose covariance matrix, ~, of the repeated measures displays largest variance is 10, 20, or 30 times as small as the spheriCity, i.e. ~ = if I + g it + i gt, where I is an largest. Perhaps such an extreme ratio of variances is identity matrix, i a vector of 1's, g a vector of arbitrary not unusual with cognitive measures. though one might components. Under spherical error, one can use the suspect that 20 or 30 is a bit unusual. But it does seem usual results relating linear and quadratic forms to show to be atypicai of many other biological measurements that con",Sugi-90-240 Thomson.txt
"""Estimating Standard Errors for a Proposed Survey"" Sam Slowinski and Hank Leddon Board of Governors of the Federal Reserve System Introduction: ANNUAL RATE OF DEPOSIT TURNOVER The Federal Reserve Board conducts a NOW Demand Yr Month MMDA monthly survey of debits (withdrawals) to demand Accounts Accounts Accounts and savings accounts. The survey provides 13.4 6.7 88 599.9 July estimates of turnover rates, the ratio of debits 15.1 681. 6 7.2 August to deposits, which indicate the rate of movement 15.6 6.9 September 642.9 of money through the economy. The present survey 639.8 14.9 6.7 October panel is a stratified random sample of about 280 14.3 November 643.3 7.3 insured commercial banks. 699.1 16.3 8.4 December A refinement of the present survey was 16.7 89 January 713.7 8.9 proposed. In particular, more reporting detail was requested, with each deposit account type It can be seen from this table that the split into personal and nonpersonal accounts and turnover rates for regular cheCking accounts are the dollar volume of debits to these accounts many times larger than those for the innovation reported over the entire month. The committee accounts. The rate for NOW accounts is roughly twice the rate for MMDAs on an annualized basis. reviewing the proposal posed the following The proposed survey to obtain monthly data sampling question: What standard errors could be expected in estimates of turnover rates for the on the distribution of debits among two types of proposed items, assuming various sample sizes? agents, consumers (personal) and others Thus we wished to compute standard error (nonpersonal) is founded in economic theory. estimates of personal and nonpersonal turnover The opportunities, motives, and behaviors of rates for survey panel sizes of n=200, 250, 300, consumers are distinct from those of other types 350, 400, 450 and 500, while preserving the of agents such as businesses and governmental nature of the stratified sample design. units. Background: The",Sugi-90-241 Slowinski Leddon.txt
"The Bootstrap In this paper, PC SAS/IML® modules are developed which Another approach, which has the benefit of being less calculate percentile method confidence intervals and costly, would be to use computer simulation to replicate the vanants. The modules will work on distributions of study. A Monte Carlo simulation would employ a random parameters generated by any Monte Carlo technique, number generator to create experimental replications. The Including the bootstrap. bootstrap variant uses the observed distribution of the data to generate the population distribution.",Sugi-90-242 Pasdirtz.txt
"and f i is the regression model evaluated at x i' Let Wi' i = 1,.,.,n, be apxp matrix with elements a2t /afJrafJ s' r,s ::: 1, ...· p. These Wi Interval estimates for nonlinear parameters using the linear are compiled into a nxpxp array W (Bates and Watts, 1980). The approximation are sensitive to parameter curvature effects. The ab th ""column- of W is the ab th second derivative vector Wab with adequacy of the linear approximation (Wald) interval is determined elements a'Lt JafJaa9 b , i= 1, ... ,n. All deriVatives ale evaluated at using the nonlinearity measures of Bates and Watts (1980), and the maximum likelihood estimate of e, denoted 9. Clarke (1987b), and the profile t plots of Bates and Watts (1988). These curvature measures and profile t plot calculations are . e ® The development of the linear approximation confidence implemented uSing the SAS/IML and SAS/NUN procedures. region involves a planar assumption (the expectation surface is flat). This assumption can be checked by the use of the 1.",Sugi-90-243 Kugler Lee.txt
"lly effec- ABSTRACT tive. If you are conducting an equivalence trial, there Is an approach This approach is inconsistent with the intent of an equivalence trial. within the Neyman--Pearson theory of hypothesis testing that refor- In an equivalence trial. you are interested in a difference In a single muates the hypotheses. with equivalence of treatments as the after· direction only, that Is, when the experimental treatment happens to native rather than the null hypothesis. This approach swaps the roles of the type I and type II errors. It also means you can explicitly be inferior. control the probability of making the more serious error of finding A second approach that is consistent with the intent of an equiva- no difference In treatments when in fact the standard Is superior. lence trial is to state the problem as a one-sided test. In this case, Most clinical trials comparing two treatments are conducted to deteonlne H one treatment Is significantly different hom the other. you can state the hypotheses as The traditional approach to this problem tests the null hypothesis A: 1ts > 1te versus H : 1ts !51te . that the success rates for the two treatments are equal against a two-<lided afternative that they are not equal. However, equivalence The usual test statistic is the normal approximation to the binomial given by trlals are conducted with the intent of showing that two treatments are equally effective, that is, showing that an experimental treatment Is as good as, but no",Sugi-90-244 Ashton.txt
"X and Y data points within SAS. The data points X2 and Y2 of one trapezoid must Using the LAG function of base SAse software to implement the be renamed as the X1 and Y1 valUes of the subsequent trapezoid (to the right Trapezoidal Rule, concentration-time or 3imilar x-ycoordinate data de5Cfibing a along the X axis). The LAG function pertorms this function by retrieving the value curve can be integrated to detellTline the total area under the curve (AUC) values. 01 a variable from the previous observation. Thus, data from two observations can A series of trapezoids are created and the area of each is summed to give the be used in the calculation of a new vanable. In the case of calculating the area of approximate total area. This routine may be applied to any two dimensional data a trapezoid, the following fonnula can be used: set. The simplicity and relatively small margin of error associated with this method ARfA::: «(TIME -LAG(TlME» * (LAG(CONC) + CONC) / 2 ; make it preferable to other AUC calculation methods which require more The resultant AREA variables created for each observation may then be summed information. using PROC MEANS Of PROC PRINT with qualifier. ..",Sugi-90-245 Rogers Tippitt.txt
"USING THE INTERACTIVE FEATURES OF PROC REG by Rudolf J. Freund Texas A&M University April 4, 1990 BACKGROIJ)ID ""."" IRTERACTIVE MODE DI THE B!GIlIJIlliG · · · Jtep' An intar...:t1vlI analysiS consists of a SIS .e.sioll, in wbicb subait to a regression -.l.}'1Iis. 'lila we SAS$ 1fOU14 11 pert'Orlll prQ9rilll at a statistiOll.l analysis are pertorlMd oae at a tiJQ. EadI step _y proqr. . would consist of a PRIX REG cpt.J.ODS for !f*:i.al with be 11 SIS PROC. or a part: of a $AS PROC, whose results are displ.ayecl stot.tisUc:s. an otJTPIJT stateaent tor produc:ilIq dia9DQltlc: stati.ties, {o11o...:l. by other proc:edures sw:h as PRDC PLOT to further exaaWr.1I the results. ~ In order to interactive analyses naKible, esped.a.lly tor 1IIOr0!l regranion analyses, SAS In.stitute n.5 lDOdit1ed PRIX REG to .11_1 slll:mitted. and so on. This proclln is c:alle:l. the BATCB ...se 1s still qui.ta popular. req-ression analyses are often not strQo;tur«l and willi 1IoveYU. · deletion or addit1on. of variUllas in the mocIe1 iJultead of ~. require 1IIaft1 iterations be!we ... s;atlstactory analysis 1s tt.. Boatcb !!lOde can beoxIe quite lienee a reqressiOl1 u~ tiaa II deletion of obseJ;'VlltiOllS u a stap, and especially i t turnaroWld of individual proqrPlS is not consUllLl.nq, q\lid<. and · plottinq variables dlaqnostil: statistics as step it. (without invoking PRIX PLOT). power Incrw.sed ava.l.u.b111ty of coarputinq full screeD data aDd tor a _n effective interactive IIIOde ot data cUspla~ can be USe:! Each of these steps call be imIokad in pcact1c:;!.lly any order. lO1I.ieh is ana.l~is. certa.inly very eonvenJ.ant. BUT it can bIIcoIM: confusinq. SllS is .. r""""l'ist .. r..:! trad-.,k of SllS Instl.tute. 1393  . ""'"" PAGE 6 STARTING THE SESSION Assuming the SAS data set has been created. iJlplement PROC REG, !IJtG; PROC TIlE EL\MPL! MODEL GAS DElfS MY INC VAL; r 'l'lIe data c:oncern varubles relate;! to 9asolllle consumption in the 48 'l'hll RUN 5t""t-..t tells the SAS SySt .... to ru",Sugi-90-246 Freund.txt
"Elf Exploration, Inc. Bernard Couderc, Elf Exploration, Inc. One of several valid parameter comparisons ABSTRACT used in decline analysis is a plot of monthly production rate of oil or gas versus time. In This paper presents a SAS/AF@program general, the engineer defines the production catalog designed to allow engineers to estimate remaining recoverable oil and gas trend for the well by drawing a ""best fit"" line through this plot. An extrapolation of reserves for a developed petroleum reservoir. the defined trend from the most recent produc- Production decline curve analysis and three tion date to a point in time where no oil or decline curve models are introduced. SAS/ GRAPH@, SAS/AP, and the SAS@ procedure PROC gas remains to be produced (rate:O) provides REG as applied to decline analysis are de- the basis for a reasonable forecast of produc- scribed. The program presented allows engi- tion of remaining hydrocarbons from that well. neers with no knowledge of SAS programming to In practice, an economic limit based on the manipulate the regression procedures and input forecasted price of oil or gas and the oper- data to quickly and accurately examine several ating cost of the well is used as an endpoint valid models for petroleum production decline for the extrapolation. The ""best fit"" line drawn by the engineer graphically approximates analysis, generate production forecasts and a linear regression over the data, with time estimate remaining recoverable petroleum the indep",Sugi-90-247 Bice Wallis Couderc.txt
"require that all new research project proposals contain an estimate of the number of experimental units needed to meet the Estimation of sample size by considering power is a concept familiar to many researchers and statistical consultants, but is sensitivity of the research objectives. It appeared to be virtually impossible to answer this question for every new project using rarely used. Most avoid the tedious calculations. Recently, existing methodology. Consequently, something had to be O'Brien (1986) and Sanders (1989) have demonstrated how the developed so that the researchers could calculate a realistic SASfD data step and PROe GLM can be used advantageously to number on their own, and at the same time broaden their make these estimates. This paper demonstrates that an AF understanding of power. application, which takes advantage of Screen Control language (SeL). simplifies this process and makes it more convenient for There were several ways to help the researchers answer the users to calculate power. question of how many experimental units were needed. The first method discussed was to write a ""manual"" which would contain 1.",Sugi-90-248 Schneider McLean Sanders.txt
"ed to place the strains into groups (Pielou, 1984, 8AS Institute, 1985b, A goal of numerical taxonomy is to group organisms based on Sneath and Sokal, 1973). With PAOe CLUSTER, SAS software physiological data, RNA sequences, and results from DNA homol- provides a number of methods such as group average linkage, weighted average linkage, centroid, and furthest neighbor(or single ogyexperiments. The results of cluster and principal component analysesaretypicallydisplayedindendrograms, similarity triangles, linkage) and allows the input data to be either coordinates ora matrix and principal coordinate plots. These graphs can assist in the of dissimilarities (SAS Institute, 1985b). The most common method interpretation of the results and in the delineation of the organisms used is the unweighted pair-group method using arithmetic aver- into possible taxonomic groupings. The results of two cluster ages (UPGMA) or group average linkage (e.g., Austin and Priest, 1986, MacDonell and Colwell, 1985a, MacDonell et al., 1986, analyses using different sets of data or different cluster methodolo- gies can also be compared graphically. SAS<3 and SAS/GRAPI-P Sneath and Sokal, 1973). Group average linkage isrecommended by Pielou (1984) because it is an ultrametric method (each cluster software have a number of procedures which perform the data pairare joined monotonically and are free of reversals). The process analyses and produce graphs (e.g., PROC CLUSTER, PROC starts with each strain in i",Sugi-90-249 Jacobs.txt
"tract demonstrating the manipulative powers of the procedure: The PROC SUMMARY procedure allows the user to obtain statistical analyses on data obtained from a permanent, or working storage, SAS data set. SAS Variable Description This tutorial presents the basic concepts of using the procedure through examples. Using sample A billed dollar amount REVENUE code followed by output produced through the (A numeric in dollars & cents) procedure (printed using PROC PRINT), the reader may use the examples to see the cause and effect Weight of a shipment WEIGHT of most options of the procedure. (A numeric in pounds) CITY Originating City of shipment Introduction ( A character value) PROC SUMMARY is one of the procedures that Originating City's State ST should be included in every SAS programmer's ( A character variable) toolset. It offers many features for obtaining and manipulating simple statistical output for both the The number of boxes, pallets, PIECES or cartons in a single shipment neophyte and experienced programmer. The (A numeric variable) purpose of the procedure may be summarized as follows: The date of delivery DATE (A character variable) * To compute summary statistics for specified levels of subgrouped Weighting factor FACTORl (A numeric variable = .1) observations. The resulting statistics will be assigned to new variables, while the old variables are dropped. Case 1: The 'Slightly Simple Summary' example: To produce a SAS data set for use with * Syntax: subsequent dat",Sugi-90-25 Boyden.txt
"ion to making a comment on ABSTRACT inteIpretation of the graphical results. It is useful to have full control of the ploning of I. Data Inpnt : error bars when displaying statistical data. For example, a problem often arises in overlay plotting of two or more curves which iJlustrate mean The main macro expects observations consisting response and confidence intervals over the same set of group identifier, abscissa value. response mean, of abscissas(""times""): the confidence intervals may and response interval half-length (e.g. one standard overlap leading to graphic clutter and/or ambiguity error of the mean). For the typical situation in which in inteIpretation. An algorithm which removes such the data consist of groups of (x,y) pairs where x is, clutter according to well defined mles and enhances say, time and y is, say, response with a third class interpretability is described and i11ustrated. variable, say, dose in each observation being a group Implementing the algorithm entailed development of identifier, a preliminary step is to use PROC code to plot the data using PROC GPLOT in MEANS to get the mean and standard error of SAS/GRAPH which leads to other benefits. response at each time and dose. Disclaimer: Although the research described in this 2. Algorithm for removing clutter: document has been supported by the United States Environmental Protection Agency through contract At any given abscissa there are several number 68-02-4450 to NSI Technology Services intervaJs(",Sugi-90-250 Shaw Most.txt
"for what to plot and how to plot it. Chapters 2 and 3 discuss graphical methods for univariate data. Chapter 2 describes This talk presents an overview of methods for statistical methods for portraying the distribution of a single variable, graphics covered in my forthcoming book. The SAS® System including histograms, stem and leaf displays, boxplots and for Statistical Graphics. In particular, I i1lustrate the design dot charts. Chapter 3 focuses on methods for plotting and implementation of custom graphic displays for: theoretical distributions and for comparing an empirical data distribution to a theoretical one, including quantile-quantile plots, density estimation, and diagnostic plots for asscssing · symmetry transformation plots symmetry of a distribution. · scatterplots, enhanced with marginal boxplots and concentration ellipses. display of additive fits and residuals for two-way tables. · Exploratory methods and graphical tcchniques for · scatterplot matrix for multivariate data. bivariate data are described in Chapter 4. These include simple scatterplots, labelling observations, enhancing a scatterplot with marginal boxplots or confidence ellipses, and",Sugi-90-251 Friendly.txt
"rkansas (Fayetteville) Abstract. The effectiveness of procedure NLIN of a SAS data step. is explored when the parametric model is de- fined only implicitly in terms of systems of The performance of relative1Y,siml?1e ~Ilte ordinary differential equations. Algorithms for gration routines in this NLIN app~1ca~10n IS the numerical solution of these equations are benchmarked here, using pharmacoklnetlc examples incorporated into the procedure. Timing for a from Ralston, et a1., and Ramsey and Anderson 4'th order Adams-Bashforth-Moulton predictor- (1984), as well as an example with environmental corrector method proved to be superior to that applications. No attempt is made to evaluate given by a 4(5) Run~e-Kutta-Fehlberg approach other existing software. such as BMDPAR, ~AUSS for 3 or more equatlons. Examples are drawn from SimGauss/Optmum, or appropriate IMSL routln~si pharmacokinetics and adsorption chemistry. this is for the SAS user who, out of necess1ty or preference, chooses to remain in that envir- onment. Execution times reported ~ere corres- I. INTRODUCTION pond to interactive eMS SAS, VerS10n 5.18, operating on an IBM 4381-R14 using YM/SP HPO This paper unabashedly draws on work pub- release 6.0. lished by Halston, et a1. (1979), under nearly the same title, in connection with development of BMDPAR. We hope to be excused from some small 2. USER REQUIREMENTS f1agiarisms. since the situation treated here is 1dentical in most respects to that considered An initial, dominat",Sugi-90-252 Dunn Smith.txt
"t as a functio n of the ABSTRACT input variabl es. are often intract able. One reason for simulat ing a stochas tic proces s is to obtain an estimat e for some Formul as are availab le for the steady state parame ter of interes t. In the queuin g contex t analysi s of Poisson ian queues {i.e. where the for exampl e, the parame ter may be the averag e waiting time of a custom er in a queue. This input and service time distrib utions can be statisti c would be estimat ed from observ ations modele d or approx imated as Poisson , Gamma, of custom er waiting times in a simulat ion. Obtain ing valid interva l estimat es, howeve r, is Er lang or similar distribu tions}; such formula s not straigh tforwa rd becaus e observ ations are not are genera lly limited to the momen ts of the indepe ndent. Conseq uently, it is difficul t to determ ine in advanc e how many observ ations to custom er waiting time or line length distrib u- make so that a confide nce interva l of a desired tion. In non Poisson ian cases or where interes t width may be obtaine d. This paper describ es the implem entation of lies in distrib ution quantil es (i.e. median s or one proced ure for obtaini ng valid interva l estimat es for a parame ter. Once such estimat es quartile s)., simulat ion is genera lly require d. have been obtaine d, the simUlat ion may then be Once the simUlat ion has compile d and run, like termina ted. The method used is the regene rative method (Igleha rt, 1978), which takes advant age the",Sugi-90-253 Greene Jones.txt
"THE DISTRIBUTION OF GRONBACH'S C07,ICJENT ALPHA FROM THE CORR PROCEDURE OF SAS SOFTWARE Andrew J. Cucchiara, University of Oklahoma Health Sciences Center, Oklahoma City. OK 13190 Susan J.Kenny, University of Oklahoma Health Sciences Center, Oklahoma City, OK 13190 J. Paul Costiloe, University of Oklahoma Health Sciences Center, Oklahoma City, OK 13190 AJlSTRACT earlier versions of SAS software is given in that same table. Cronbach's coefficient alpha has been added recently to the UnfortunAtely, researchers are presented with Cronbach's CORR procedure of SAS software. This index of reliability is coefficient alpha with no means for interpretation. The statistic described as an I!8timate of the correlation between two random hu been characterized as an estimate of the correlation between samples of items from a universe of iteIIlB like those in the teat, two random samples of items from A universe of items like those yet no p-value is provided in order to test the departure of the in the test, yet no p-value is provided in order to ascertain the statistic from a null hypothesis of no reliability among the items departure from a null hypothesis of no reliAbility among the test of the test. Unfortunately, researchen can Dot make valid items. Clearly, some indication of the distribution of Cronbach's inferences without an understandin& of the distribution of such coefficient alpha would be helpful in understanding the utility of statistics or tests for their interpretation. this metric. The purpose of this paper is to examine the distribution of The purpose of this paper is to examine the distribution of Cronba.-;b's coefficient alpha. A Monte Carlo simulation study Cronbach's coefficient alpha. A Monte Carlo limulation study was conducted by computer generation of item data sets was conducted by generating item data sets possessing varying possessing varying levels of reliability and applying the SAS levels of reliability and applying the SAS procedure CaRR procedure",Sugi-90-254 Cucchiara Kenny Costiloe.txt
"SAS® Commands from the CMS Command Line Chapman Gleaso n, U.S. Depar tment of Justic e, Washi ngton, DC Keywo rds: REXX, eMS, SAS, SAS EXECS pass the ddnam e (file 3) type) and file name (SAS Abstr act data set name) to SAS and PROC FSEDI T. This paper descr ibes metho ds on how System s Appli cation Archi tectur e This simple conce pt is the basic REXX can be used to develo p power ful buildi ng block for the CMS exec SAS proced ures from the eMS Command SASPROe whose opera tion will be line. A REXX exec called SASPROC descri bed next. will be descri bed in detai l showin g how you can extend the SAS langua ge Using the SASPROC exec to the CMS enviro nment . The SASPROC exec allow s the Introd uotion follow ing SAS proced ures to be execu ted from the CMS command line: In a CMS enviro nment a SAS progra mmer frequ ently wishe s to CONTENTS 1) FSEDIT/FSBROWSE or otherw ise proce ss DATASETS 2) the conte nts of a SAS data set or FSEDIT 3) SAS full screen catalo gue. The FSLETTER 4) usual way of doing this is rather FSBROWSE 5) tediou s, you either : FSCALC 6) FSPRIN T. 7) Use XEDIT and key in a 1) filede f and PROC FSEDIT The comma nd list can be extend ed into a SAS source code (A BUILD with very little effor t. file or command would be usefu l for SAS/AF Listed below are sever al users ). enter an intera ctive SAS 2) ways a user would use the exec to sessio n in Displa y Manag er FSEDIT a CMS SAS data set. (DM) and key in the filede f and PROC FSEDIT From the eMS comma nd line, eMS statem ent. syntax : An exper ienced progra mmer sees this FSEDIT BOTH022 LADOT E tas~ as exceed ingly redun dant, borlng and easy to cure with some From the eMS comma nd line, SAS progra mming in REXX. REXX syntax : (Restr ucture d Extend ed Execu tor) is a command and macro progra mming FSEDIT LADOT.BOTH022 langua ge whose syntax is much like the SAS data step langua ge, but From the CMS comma nd line, whose functi on is much like the SAS promp t mode: macro langua ge. Gleaso n in sev",Sugi-90-255 Gleason.txt
"values will be calculated for each level. This will In this paper a proeed ure for developing a allow sampling from a certain segment of the menu driven system of random sampling using population, as well as for comparing the sample base SAs'"", SAS/STAl"", and SAS/AP' is with the population. The program computes the minimum described. The system was developed on an IBM sample size required for the sample mean to fall 3090, CMS, running SAS Version 5.18. A within the given allowable error and confidence companion system was also developed for the PC level and draws the default sample. The user can using SAS-PC Version 6.03. also specify a sample size to obtain an additional sample. If the defauft sample size is larger than",Sugi-90-256 Mehta Bern.txt
"search in all fields. This paper illustrates ways to customize clinical trial reports with little programming or editing efforts as well as to automate the production of a series of reports. Although written in the context of clinical research, the general approach to tailoring and mechanizing report production described in this paper is applicable also to other research disciplines. INTRODUCTION 1. EXTRACTING CERTAIN INFORMATION Usually in clinical research, many studies are performed FROM SAS@ PROCEDURES FOR on a single product and there is a need to generate a RESTRUCTURING THE OUTPUT series of similar reports for the product. These reports generally have a similar format, with certain relevant Statistical procedure statements generally output pieces of information extracted from statistical listings in a pre-defined format. In addition, some procedure output. Producing such customized reports statistical procedures do not output all the statistics can be a labor intensive task because such information into a file. To obtain those statistics for customized cannot easily be output from procedure statements or report writing, one can use PROC PRINITO to route DATA _NULL_ statements. Sometimes, one has to type the output of a SAS@ job into a different file and in the relevant information in a specified format, and a then read from the file the necessary information for second person has to read and verify it. Still the end producing reports in a specific format. Since PROC re",Sugi-90-257 Tsien.txt
"e containing the desired data In today's changing DP environment, selection criteria are linked up greater emphasis is being placed,on with the Assembler software as well providing users with tools allowlng as the SAFARI masterfile to yield them to perform functions tradition- the requested sub9roups of data. ally handled in a systems department. Preparation of thlS code, however, As a result, there is a need for soft- is a tedious and time consuming ware products that facilitate the process. The logic involved can be development of these end-user, complex and there are numerous applications. The screen deslgn coding details to consider. In capabilities of the SAS/AF software addition, syntax validation is only for PCs along with its error handling available for certain portions of the facilities and dataset manipulation code. As a result, coding errors are functions make it a strong candidate easy to make. for systems of this nature. When extract jobs abend as the This paper addresses a real-life . result of coding errors, they need business problem that was solved wlth to be- fixed and rerun. SAFARI It beg~ns SAS/AF software for PCs. processing time is expensive; hence, by presenting a background descrlp- reruns are costly. To help alleviate tion of the business environment and this cost and to reduce the time the existing problem. It then moves needed to prepare code files, an on to outline the stages of system Application Generator was developed development highlighting f",Sugi-90-258 Fine.txt
"Cary, NC SAS/ASSIST - - - - - - - - - - - - - - - - - - - - - - - - , ABSTRACT Specific features of Release 6.06 of the SAS System are highlig,ted through a Marketing Information System (MKIS) case study. SAS/ASSIST""' software is used by sales and marketing profession- als in developing applications that require virtually no knowledge of SAS language syntax:. SAS/ASSIST software activates several other Institute software products in this MKIS example. THIRD MILLENIUM PERIPHERALS Third Millenium Peripherals (TMP) is a subsidiary of Worldwide III Incorporated. We manufacture laser disk peripherals for mainframe UTILITIES and supennini computers. We earned $2.3 million on $21.5 milrlOn of revenue in our last fiscal year. TMP is a small operation with plans for steady growth in selected markets. Place cursor on your selection and press the enter key. marketing department consists of four sales representatives OUf Screen 1 Task Selection Using SAS/ASSIST Software and a sales manager who dabbles in marketing. There are four basic objectives of the department: ... select data source and variables ... · Identify market opportunities. SAS/ASSIST: Select variables - - - - - - - - - - - - - - - - , Select the variables to be used. Sell with intelligence. To select or deselect, place cursor and press ENTER. Use OK to save selections. Cancel to return without saving selections. Maintain solid customer relations. One variable Response form is: · Inform the corporate mission. Two variables",Sugi-90-259 Senger Roach.txt
"The infonnation and reports generated by PROC COMPARE have This tutorial introduces the new prOCedures available In base SAS"" changed dramatically. Many new options have been added to con- software for Version 6. Special emphasis is placed on the new trol the detail in printed reports, the listing of observations and vari- V5TOV6 procedure for converting Version 5 SAS files to Version ables, and the content of output data sets. The reports generated 6. New features added to base procedures are also discussed. _ are much more informative and easier to understand.",Sugi-90-26 Driggs.txt
"An Online System for SAS® Information Exchange Using SASIAF®, SASIFSP® ,and SASISHARE® Software Julie A. Smith, Glaxo Inc. evolved out of a personal need but was already established as Introduction a system on ""s own. I had previously created a menu-driven This paper describes a menu-driven system developed to system on the IBM mainframe that allowed users to access the facilitate the exchange of SAS information at a large company. Usage Notes for the mainframe and the PC. The PC Usage The system, called the SASINFOX System, is designed to Notes are disbibuted on diskettes, as is the rest of the allow SAS users to update personal information about software. However, not every user wants or needs the Usage themselves and their usage of SAS, to access the Usage Notes datasets on his/her PC. I had a great need to access Notes. to track in-house problems being handled by the these notes as I was developing a data entry system under Technical Support Department of SAS Institute, to exchange Release 6.03 and was having problems with transferring data information related to the conversion to Release 6.06, to share through the RLlNK2. Therefore. I felt that transferring the user-written macros, to share programming tips and Usage Notes to the mainframe would be the best solution. The techniques, to keep informed about the In-House and Local other components of the SASINFOX System evolved out of SAS Users Groups 1, to access information about SAS training, needs of the user community that I felt could be satisfied by to provide feedback to the administrator of the SASINFOX inclusion in the system. I hope that the SASINFOX System will System, and to produce online and/or hardcopy reports be the central, comprehensive repository for company-wide regarding any of the above. SAS-related information. Conception of the System Components of the SASINFOX System As a new employee with a large pharmaceutical company in User Information Component which SAS users were using the softwar",Sugi-90-260 Smith.txt
"A MANAGERIAL APPROACH TO TRACKING STAFF ASSIGNMENTS USING SASI AF* AND SAS/FSP* SOFTWARE William F. Simpson, Jr. Leonard Bruckman Connecticut Department of Environmental Protection AB~TRACT As it was the responsibility of the ACU Director to manage all of the ACU State and Federally funded programs, a majority of the assigrrnents were recorded by and issued from the Office of the As any manager knows. keepng up to date on the progress of staff assigrnents is hopeless without using some organized approach to Director using the TTIS TASKS subsystem In some cases, such as applications for permits to construct and operate sources of air oversee that too many things aren't 'falling th-oug, the cracks'. ills paper will describe a SASIAf' menu driven application whch tracked pollution, the tasks were initiated by the Enforcement Control Group and tihen tracked by the Director's Office in the PEFMTS subsystem staff assigrnents in the Connecticut Department of Environmental Protection Ar COIl'pHance Wt A M<XJElJN3 subsystem. to track ambent ""vlact modeling analyses. and a STATE OODER subsystem. to track ACU Enforcement activi- ties, were other modules contained in this system The major features of this application include the use of SAS/FSP' 'PROC FSEDT' to irjlut and update nformatil pertaiOOg to each Typically. there were from 250 to 300 active tasks baing ildividual assig:ment. the use of SAS/FSP 'PROC FSlETTER' whch enabled the Dr-ector to generate memos when new assigTnents tracked in the TASKS subsystem from 200 to 250 active tasks were beng issued or jf returned assigrnents were considered in- baing tracked in the PERlvlTS subsystem. some 150 to 230 active corrpIete. automatic generation of memos for assigrrnents consid- tasks being tracked"" the STATE OODER subsystem and about 20 active tasks being tracked in the MODELlN3 subsystem at anyone ered late based on assigned due dates. tracking of dates when the time. status of each assigTnent has been changed. and printin",Sugi-90-261 Simpson Bruckman.txt
"A m:x;IW1MER5 TOOL USING SAS/AF'lM SOFlWARE Sanly O. Iverson, COrporate Cost Management roRlDSE: To give progranuners a ma.mframe tool ~ (b) POOGRlIMS: 'EDIT that can be used to save time: spent writing adhoc on the CClIlD.1lo?lIr XXXX. ~I ~. This application creates JCL ani line and enter. To get the inpub statements for standard file SAS editor lines, type 'NUMSi ON'. layouts. create the screen you want the user to see usl.n:J macro There are several benefits for usi..rq this method variables where you want the for creatirg members of a Pl:6. user to fill :in ans>oerS. Make the length of line equal to Time ~in;Js. By creating a silrlple 1. the length of the rnaxinum SAS/AF application you can avoid excessive key strokes :involved in string you will want to enter. creating a Pl:6 with standard JCL arrl 'lYPe 'fill-' on the ccmnand input statements. line and position your cursor :in the first column of the rON 2. Variable name st:an:1ardization across where you want to split the data sets. :input screen and the program. 'I.be ability to generate ccmments on 3. On the next line type '= = specific variables. Progl:aJl1merS can =LIBREF', this marks the easily upjate this ccmnent section and beg:inning of the member you thus have a central area in which to keep track of data variations. 'Ibis will are creat:ing :in the Pm you reduce tine spent checld.rg data bave allocated to the LIBREF. At this point you can type PROCEtURES : I INCllJOE UBREF' on the cx:mnarrl line, if you have Allocate a ~ential dataset to hold 1. preallocated a member you want the SAS/AF'IM catalcques. You can do copied :in to use as the this by gettinJ :into the Display Manager prototype. ~ '= = =' on the and typ:ing: last line to close the section and put it :into the Pm. Edit TSO ALI.DC F(TOOILIB) DI\( 'USERID.GENElUC.AFl'OOL') the program using ## and # to NEM CATAL TRACKS SPACE 10); RUN; invoke oon::litional execution. PROC IIJIID C='IOOu.J:B. 'IOOl.CAT; RUN; (aprxlx 4-5). 'Ibis will take you t",Sugi-90-262 Iverson.txt
Customizing the FSVIEW display The FSVIEW procedure provides a variety of commands to cus· This paper discusses the use of the Release 6.06 SAS/FSp® tomize the display. A summary of these commands follows: FSVIEW procedure to develop end user data entry applications. VAR Some topics to be discussed are: displays a subset of the data set variables (procedure invocation statement). · Comparing the FSVIEW and FSEDIT procedures ID defines 10 variables to be displayed · Customizing the FSVIEW display (procedure invocation statement). · Using formula entries to create enhanced displays Using Screen Control Language (Sel) in formula entries · DROP drops variables from the FSVIEW display. · Accessing SAS/AF® entries within FSVIEW redisplays dropped Variables or defines variables as SHOW · Using the WHERE processor within FSVIEW either 10 or scrolling variables. · Sorting data within FSVIEW MOVE redefines display order of variables. · Creating new data sets within FSVIEW Modifying the behavior of FSVIEW by setting the control level · FORMAT associates formats with a displayed variable.,Sugi-90-263 Bass.txt
"DISK INVENTORY AND CONTROL SYSTEM, A REXX TOOL FOR THE MANAGEMENT OF SAS ® DATA BASES UNDER CMS Arthur L. Carpenter California Occidental Consultants Key Words Often, the responsibility of the maintenance of the data base(s) cannot be eMS, REXX, Interface, Data Management, left to the individual programmers or Inventory users. Many times individuals lack the training and/or motivation to take the time and effort necessary to keep the data Introduction bases from falling into disrepair. The result is a tangle of data base threads Imagine a large data collection proj ect that, like spaghetti, become increasingly where several types of data have been convoluted as they evolve and change. collected over a number of years in as many as a dozen different task areas. Generally speaking, data bases are either Further complicate these conditions by designed before being created or they using multiple subcontractors and by evolve without (or sometimes in spite of) changing them in the midst of the project. a prior plan. Planned data bases have a Add spice by changing the sampling and number of obvious advantages, such as control and documentation, however this project objectives during the course of the study. Implement the data entry and control is achieved at the expense of management using poorly trained and increased rigidity. Data bases that are constantly changing personnel. And create not particularly planned, on the other ove~ a hundred and eighty data bases using hand, are at times more flexible, but widely varying data collection techniques often impossible to control. and consisting of a variety of internal structures. Add to this growing nightmare Data bases that evolve often start small a low budget (naturally), a need for total and are easily managed by a single user. data traceability and final SAS data bases Over time (sometimes a short time) they suitable for use in litigation. grow, become more complex, and lose their individual identities as they are merge",Sugi-90-264 Carpenter.txt
"nt Why EasyBCS Abstract The EasyBCS program was developed under a contract This paper describes EasyBCS, a microcomputer that Boeing Computer Services (BCS) has with the program designed to totally insulate the user from Federal Aviation Administration (FAA). The FAA has a learning any of the multitude of products required to number of statistical databases that have been create, submit, execute and retrieve a job on a mainframe computer. EasyBCS, aided by extensive accumulating data for years. Some of those databases have been placed on the BCS timeShare computer so tables describing the mainframe database, walks the user through the creation of his job with ·point-and- they can be widely accessible to a large audience. shoot"" menu selections. When completed, EasyBCS will BCS has found that when they are training users they automatically translate the user's request into SAS"" or use most of their class time teaching the users about System 2000"" code and submit it to the mainframe for System 2000 and SAS, about the BCS timeshare execution. When the job has completed, the user may installation, and about the mechanics of TSO. Even either browse the output on the mainframe through when they finally get to the details of the databases EasyBCS, send the output to a selected printer, or themselves, they must present large binders of download the output to the microcomputer. The user information showing the fields that are available for each interacts only with EasyBCS. EasyBCS doe",Sugi-90-265 Burch.txt
"· A facility for building customized, menu-driven front- This paper will address setting up and maintaining a ends to these saved output and applications. financial applications development environment using SASjASSIS~ software as well as developing financial · Access to methods for communicating and dis- applications using this environment. A discussion on tributing the results of these analysis to others. the use of SASjASSIST software to front-end base DESIGNING A FINANCIAL APPLICA- SAS®. SASjFSp®, SA~A~, SASjETS®, SASj TIONS WORKSTATION CALC"" and SASjGRAPH software for providing so- lutions to common financial applications needs is in- By looking at our requirements for a financial applica- cluded. Wherever possible, turn-key solutions avail- tions system we find that most of the basic access, able in SAS/ASSIST software are used thus keeping management, analysis and presentation capabilities programming to a minimum. can be handled by SASjASSIST. The other functions we need for our system are present in Release 6.06 of",Sugi-90-266 Hopkins.txt
"A cross-reference listing program for ~AS softwa.re®: ma.cros Pa.u) A. Thompson~ Ph. D. sta.n-d a. macro. Introduction Finally, it is impor'a.nt. to list m&ero variables in a. way which allows the programmer to determine alternative SpelliD!! One problem which I have consistently ha.d in using SAS soft- wa,re IIla.cro:! liCl'l in the doc;umcnta,ion or IHud macro:!. Speci:f'- which must be COllected in order for the macro to perform ically. in setting up projects l I have often found myself with correctly. macro :files of 1000, 2000 a.nd up to 5000 lines long. Such files are difficult to work with, hard to conceptualize and oner- Initialization. Macro variable initializa.tion can ta.ke place ous to mt, beca.use macro files have certain requirements not in several wa.ys. Macros can be defined with parameter ""d- prp.sent in sta.nda.rd files. iles. A ""%LETII' statement can be used to set up Ii. macro va.riable with & certain value. ~SYMPUT"" and ""'SYHGET"" state- Debugging macros. Debugging ma.cros iti generally dif- ments can be used to 1ra.nsfer values in a.nd ou1 of macro ""a.ri- ficult, even when STHBOLGEI a.nd IIPRIIT options are cho- abies. Initia.liza.tion of macro va.riables can be a very useful sen. -In fact, the use of SYMBOLGEI and HPRIIT can make technique, but it is sometimes difficult in large progra-ros to understanding macros more-difficult. This is beca.use these determine if a.ll macro ""a.riables have been initialized. When options print macro langua.ge after the macros ha.ve been in- considering tbe listing of a. macro file, it is important to de- ~erpreted. Some of the impoda.nt execution code, inv\~lving termine if tbe variables ha.ve been initialized, and where this ""XIF'"", ""loo"" and the other process control macro structures, h&8 been done. is not priDted in any case. When running macros} you do not want to see aU of the possible bra.nches for the code. Systems of macros When &lchiving code for printing and storage, and especially Locating ID.aCrOS",Sugi-90-267 Thompson.txt
"Oregon ABSTRACT Similarly. there is liUle sense in tieing up a PC for hours (or days) running a large statistical analysis when a sha.red SAS Institute has yet to announce any firm plans to port the mainframe will often have abundant horsepower to handle just SAS System* to NeXT* workstations. Nonetheless, a NeXT those sorts of CPU-intensive jobs. workstation can serve as an excellent platform for developing VAXNMS· (or other mainframe) SAS System code for remote The PC version of SAS atte~s to explott this philosophy by execution. giving the user the option of either processing SAS code locally using the SUBMIT command, or processing SAS code on a The combination of a strong windowing environment, display remote mainframe SAS host using the RSUBMIT command. In a PostScript support. a built-in athemet interlace and copious perfect world. this approach would allow the user to elect the slorage eapacny bundled on lOP of more-or-Iess BSD 4.3 UNIX"" best mix of local and remote resources to achieve his or her make development of SAS System code on the NeXT for objectives in a timely and cost effective manner. remote execution on another mainframe quite easy. Unfortunately, in my experience, the happy symbiosis The author's experience with use of a NeXT as a remote code envisioned between the PC version of the SAS System and the development plaHorm for SAS and SAS/Graph"" on a VAXNMS mainframe version of the SAS system often breaks down. For system is outlined, and some SAS·from·a·N",Sugi-90-268 StSauver.txt
"S System supplies the PMENU facility for the windows This paper describes the new PMENU procedure, which defines included in the system. With PROC PMENU, you can create action PMENU faCilities for windows created with SAS· Institute software bars, pull-down menus, and dialog boxes for the windows you products. The paper presents a simple introduction to building define. In most cases, building and using PMENU entries requires action bars, pull-down menus, and dialog boxes. the following steps: 1. Use PROC PMENU to define the action bars, pull-down INTRODUCTION menus, and other features you want. Store the output of PROC PMENU in a SAS catalog. Note: The PMENU Before you can use the PMENU procedure, you need to understand procedure produces no immediately visible output; it simply the SAS System's PMENU facility. This facility is provided for SAS builds a catalog entry that can be displayed later in a user- windows. The PMENU procedure allows you to create PMENUs for written window. windows that you create using the WINDOW or %WINDQW state- ment with base SAS software or using SASI AP or SAS/FSP"" 2. Define a window using SAS/AF software, SAS/FSP software. software, the %WINDOW statement in the macro faCility, or the WINDOW statement in base SAS software. The PMENU Facility 3. Associate the PMENU catalog entry created in step 1 with The PMENU facility is a menuing system that replaces the command a window by using one of the following: line as a way to execute commands. It is t",Sugi-90-269 Whittle.txt
"Now, note that PROe REPORT can be used to create basically the With Version 6 SAS"" software available to all platfonns, the REPORT procedure will be the first choice in report writing needs same report with just as little effort. for all SAS programmers. This tutorial emphasizes the functionality libname in 'o,sid.your.libruy'; of PROe REPORT, by comparing and contrasting its report writing proc report data=in.boats; capabilities with those available in the PRINT, QPRINT, and run; TABULATE procedures and the SAS DATA step. +OUTPUT _________________________ ------------------------ IFile Edit View Globals Help",Sugi-90-27 Andrews Patrick.txt
"of type VIEW. This paper discusses how data set features such as compression, Sal views, deleted observations, and WHERE clause processing Deleted Observations affect results from certain Screen Control Language (Sel) functions In Version 5 of the FSEDIT procedure, the DELETE command sim- in Version 6 of SASI AF"" and SAS/FSP"" software. The Sel functions ply sets an observation's values to missing. The observation is still discussed include LOCATEC. CUROBS. FETCHOBS, FETCH, accessible, but the values are gone. To remove deleted observa- A TTRN, NOTE, and POINT. tions from the data set, you need to execute a DATA step. With the Version 6.06 engine, the DELETE command marks the",Sugi-90-270 Carpenter.txt
"Our group's SAS database naming convention is as follows: As SAS® programmers, how many times do you have to key in: RATE76.SAS.qqqqqqqq.tttttt PROC CONTENTS DATA=DDNAMEo_ALL_ NODS; RUN; where How about: RATE =====> Rates Department file s====> output bin number 76 T50 ALLOC F(DDNAME) DA('MYID.MYFILE.DATA'); SAS ==:~=> identifies it as a SAS database Has keying in the same code over and over again in one =====> database qualifier qqqqqqqq interactive session ever irr~ated you? Well, you are not =_s:=> database type tttttt alone. (1) for personal databases: At one point or another, all programmers are irritated by such RATE76.SAS.AA16.DATA repit~ion. These Irustrations often happen during interactive where sessions when the programmer is debugging his code or DATA ======> database type when he is doing some analysis on existing data. Many 01 AA76 ======> database ~lifier theselrustrations can be eliminated by minimal planning and coding. (2) for system databases: By establishing standards and naming conventions-and RATE76.SAS.GASBILL.LIBREF adhering to thelll-i>rogrammers can develop generic mac- where ros that minimize the amount 01 typing. These macros can be ======> LIBREF database type shared by all programmers in a group that lollows the same ======> GASBILL database qualifier standards and conventions. This paper shows how standards, conventions, and macros (3) for project or data request data bases: can save keystrokes. RATE76.SAS.ACAP.DATA =3> project database RATE76.SAS.DR246.DATA ==> data request database",Sugi-90-271 Alicante.txt
"Fun and Games with the LENGTH and LABEL Statements Stan Sibley, Sibley Enterprises, © 1989 Variable Labels variables themselves, of course -- an interesting thing happens. For those Good programming style veritably requires common variables, SAS keeps the value from the data set named ~ in the MERGE the labeling of variables in SAS® data sets. statement, even if that value is mjssing. Not only does an adequate label tell more One wonders where the data went, until about the variable than its eight-character realizing that the culprit is a variable in the name does, but that label can be used by numerous SAS procedures to identify what last-named data set, the value of which is the variable represents in the analysis. sometimes -- or maybe always -- missing. PROe PRINT, for example, can easily be Unlike merging data however, SAS follows used to prototype -- or complete -- most a different rule for variable labels during a forms of reports, using perhaps temporary merge. SAS' ""program data vector"" or labels to neatly identify the columns (refer PDV, which contains information about the to the PROe PRINT LABEL option for variables in a DATA step, such as variable details). There may even be room in the name, type, length, format, and whether forty-character label to explain what the the variable is to be kept or dropped, also variable values mean (so a SAS format keeps a label if one is available. But it is isn't needed to do that) or when the satisfied with the first non-blank label it variable was last updated, or briefly how or gets for a variable, regardless of the label why it was created. Labels help document in any subsequently-named data set. (A the information, so others with access to LABEL statement, of course, can override the data -- your users, your successors, or any available label.) So there is a other partners in crime -- may immediately hierarchical order demonstrated here: have a better understanding of the variables in the data set or maybe even 1",Sugi-90-272 Sibley.txt
"DATA TEXT - SYNTAX. ~ There are many useful things you can do In each of the examples that I'll dis- with SAS* DATA steps to handle text files such as source code, reports, or cuss, the text can be viewed as state- ments that have data embedded in a more small control languages or setup files or less complex data structure. To that you might invent. This paper extract the data from the text, you must suggests why reading and writing text deal elements with that you don't en- with SAS is useful and illustrates basic techniques with examples that range from counter when you are extracting data from a conventional data file. Text reading JCL to processing setup files usually has different statement types that control batch programs. SAS fea- (some of which you will want to tUres that would make text-handling even discard). Each statement type may have easier are suggested. its own unique structure: I usually want to put each statement type in its own",Sugi-90-273 Smith.txt
"Table Lookup Without a Table Joseph A. Damico - The Ohio State University Introduction to an externa~ file. In this case, however the data to be written form a VALUE statement to be used with a SAS PROC Graduate students, faculty members. and computer center FORMAT. In figure 2, you can see the SAS code required to staff al The Ohio State University sometimes present our create this VALUE statement. consultants with difficult dais manipulation problems. This paper presents two examples of such problems. Figure 2 These examples have several elements in common. First, both DATA lINE1; involve very large data files with hundreds (or even LENGlli VAL $20.; thousands) of observations. Second, each observation in the VAL ='VALUE SIREDAM'; data file contains one or more variables which could be DATA _NULL_; SET lINE1; FILE FMT; considered pointers to other observations in the same file. PUT VAL; Third, one or more tables must be created from the original DATA ONE; data set, so that a table lookup can be implemented in the INFILE IN DATA; processing of the data. INPUT ID NO SIRE 10 DAM 10 WEIGHT LENGTH' EQUAl: ~=' ; - - , Example 1. livestock Data QUOTE: .... ; DATA _NULL_; SET ONE; FILE FMT; The first example concerns data on livestock breeding. For PUT (ID_NO EQUAL QUOTE WEIGHT LENGTH QUOTE) each animal, we have an ID_NO, theSIRE_ID, the DAM_ID, and (5. $3. $1. 8.1 8.1 $1.); a number of descriptive variables. For the sake of simplicity, these descriptive variables are labeled WEIGHT an~ LENGTH. (The actual data contained many descriptive Step 2: Use %INCLUDE to create the table. variables, rather than only two.) In this example, the pointer variables are SIRE_ID and DAM_ID. Thus, the ID NO This part is easy. Figure 3 shows the actual SAS code used of a particular animal may appear later in the file as the - as well as the expanded version of the code (based on the SIRE_ID or DAM_ID of another animal. The sample data in data shown in table 1). figure 1 illustrates this id",Sugi-90-274 Damico.txt
"act Unked Action Fields The use of choice groups with extended tables is a new feature of SomGtimGS the applications developer can make the display read- Version 6.06 SAS/AF software. A choice group is a list of mutually able by asSOciating an action field with each field in the choice exclusive items that users may select. Extended tables are dynam~ group. The action fie'ld and associated field are linked action fieldS ie tables that display information. This paper will discuss program- (LAF), and should be thought of as a single station within a choice ming techniques for generating dynamic selection lists to combine group. The action field in a LAF can be a radio button or check box the features of choice groups with the features of extended tables. that is automatically filled in when the choice group station has been The discussion will include a more extensive definition of choice activated and the choice group given a value. A radio is defined groups and extended tables, an explanation of how to set up choice by specifying a choice group name to mUltiple pairs of LAF's in the groups and extended tables in a SAS/AF PROGRAM entry, and same choice group, and a check box is defined by specifying a examples of Screen Control Language (Sel) programs that are unique choice group name to each LAF. Radios should be used easy to maintain and make applications more user-friendly. for mutually exclusive selections, and check boxes should be used when more than one item can be sele",Sugi-90-275 Ragland.txt
") The technique of using PROC FORMAT DATA NULL 00 llrrIL(LASTREC) with the PUT function for file lookup has been well documented in SUGI SET &LOOKUP (KEEP=&KEYVAR) Proceedings. The technique uses the ENJ):;;;LASTREC ; _CNTR+l ; macro %MAKEFMT to create a PRQC FORMAT CCNTR=COMPRESS (PUT ( CNTR, 6. )) ; from a lookup file. A PUT function, which resolves the format on the basis CALL SYMPUT( 'V': :_CcNTR,&KEYVAR) END · . of the value of the key variable, then CALL'SYMPUT('ENTRIES',_CCNTR) constructs a non-key variable in the main file. STOP RUN; A simple extension of this technique is to generate the format so that the PROC FORMAT ; value of the PUT function can be used VALUE $&FMTNAME as a boolean operator in a subsetting %00 1;1 %TO &ENTRIES; IF The subsetting IF statement. "" &VV&I II::;"" 1 "" statement is then used to retain in %END ; the main file only those records which OTHER=""O"" occur in the lookup file. RIIN The technique lends itself to a wide %MEND MAKEFMT range of applications and often is the most efficient technique available. A The DATA NULL reads the key variable further advantage is that once generic from the lookup file, writes the value %MAKEFMT and %TESTIF macros are of the key variable to a macro written using them is trivial. Thus at variable for each observation, and each installation a technical counts the number of observations in programmer could write the macros and the lookup file. The PROC FORMAT provide novice progranuners with resolves the macro varia",Sugi-90-276 Krasner.txt
"· the tasks that can be performed with SAS/ASSIST software SAS/ASSIST® software provides a menu-driven, task-oriented interface to the most commonly used features of the SAS® Sys- · the SAS/ASSIST interface tem. This interface makes it simple to perform tasks in the areas · application development features of SAS/ASSIST software of data access, data management, data analysis, and data pre- sentation. SAS/ASSIST software is designed to serve the needs · some fundamental technical aspects of the software of users with many different levels of expertise. · setting up SAS/ASSIST software for an individual user SAS/ASSIST software was constructed using tools available to · setting up SAS/ASSIST software for a department or site any user of the SAS System. Thus, the software can be cus- tomized to meet the needs of a particular site. Tools to aid in · customization of SAS/ASSIST software application development are included as part of SAS/ASSIST · support issues and future plans. software. THE TASKS THAT CAN BE PERFORMED WITH",Sugi-90-277 Roggenkamp Kramer Kumar.txt
"First Place Best Presentation of Data - Color Peter Stowe United Technologies LARSON-MILLER PARAMETEE PLOT OF CREEP-RUPTURE DATA The accompanying Larson-Miller parameter plot was produced by one of a series of SAS programs for analyzing creep-rupture data. These programs perform functions such as creating and maintaining datasets, merging existing datasets and sorting, printing and plotting individual datasets. All hardcopy output from these programs is 8 1/2 X 11 inches in size and of quality suitable for publication (the accompanying graph was produced in a larger size for this exhibition only). The programs are designed to run on eMS and are intended for use by individuals with virtually no knowledge of file edit- ing procedures, SAS or the VM operating system. The dataset management program, for ex- ample, places the user directly into the FSEDIT environment with a modified screen containing detailed instructions for adding, duplicating and changing records as well as moving through the file. All programs are controlled by an EXEC2 routine which prompts the user to select options from a menu. A basic understanding of both creep-rupture testing and parameter analysis is required in order to understand the accompanying graph. A brief description of each follows. Simply stated, a creep-rupture test is one in which a test specimen is held at constant TEMPERATURE while a continuous steady load (STRESS) is applied and the TIME to either RUPTURE or reach a predetermined amount of permanent deformation (CREEP) is measured. The creep-rupture test is analagous to a weight suspended from an attachment by an elas- tic band. If left in this suspended state for a long enough time the elastic band will permanently stretch and will eventually break. Creep-rupture tests are frequently run at extremely high temperatures and can last hundreds (or thousands) of hours and, as a result, are quite expensive, The cost of material procurement and specimen preparation alone can easily e",Sugi-90-278 Stowe.txt
"First Place Best Presentation of Data - Monochrome Vincent G. lannacchione Research Triangle Institute The ""Black Holes· of Power Decisions about the size of a sample are often based on the probability of detecting a pre-specified difference between the proportions of two subpopulations of interest. This probability, known as statistical power, depends not only on the size of the difference, but on the proportions themselves. For example, a difference of 0.1 is easier to detect for subpopulation proportions of 0.2 and 0.3 than for proportions of 0.4 and 0.5. Thus, to graphically depict the detection capability of a given sample size, three dimensions are necessary! one for each subpopulation proportion and one for the difference between the two proportions. The accompanying graph portrays these dimensions by superimposing diagonal lines of equal differences onto a Cartesian plane of all possible pairs of subpopulation proportions. Differences between the pairs that lie in the darkened area, or ""black hole"", will not be detected; all other differences between the proportions will be be detected with the specified statistical power and level of significance. With this format, the changing size of the detectable difference between the proportions is quite apparent, especially for small sample sizes. As the sample size increases, the size of the ""black hole"" diminishes, reflecting the increased detection capability of a larger sample size. 1580  Sample Size per 3ubpopuluUon=40 Sample Size per Subpopulation=20 p, p, Sample Size per Subpopulalion=160 SamplE' Size per Subpopululion=80 p, p, The ""Black Holes"" of Power Differences between two subpopulation proportions, P, and P"" will be detected outside the darkened area by two equal-sized samples with a power of 0.90 and a level of significance of 0.05. 1581  /'"" Program to generate source data set for power graph *1 OSS SAMPN P2 PI POWER ALPHA DEFF 1* Dataset user:[vgi.sas.power]pZs.prog ""/ 3 options linesize:.80; 1 20",Sugi-90-279 Iannacchione.txt
"Effectively Grappling With Graphics Chris Potter Syntex Laboratories, Inc. THE PURPOSE OF GRAPHICS Introduction - This tutorial is a collection of Graphics has been defined as the art of examples taken from my last two SUGI drawing. Recently, the use of computers has presentations. changed graphics to a ""push a button - get a graph"" simplicity that has compromised the art A picture may be worth a thousand words, but portion of graphics. it is a rare picture that can adequately describe a thousand word set. We often assume that a graph or plot of data Graphics should be thought. of as the will automatically convey our message. communication of ideas through VIsual mean8. However an inappropriate or poorly designed plot may raise more questions than it answers. Effective graphics must be designed to communicate. I hope to show some of the Graphics may be used to: ways that this communication can be assured. Show the structure in the data In this paper I will be discussing: o Summarize large amounts of data o Demonstrate how things are connected L The Purpose of Graphics. o 2. Steps for Creating a Chart. Show organizational relationships o 3. Rules for Graphical Integrity. Provide advertising o 4. Effective Chart Design. Illustrate training o 5. Using PROC GPLOT and GCHART. Communicate ideas o Display humor o Set up a situation or feeling o Before continuing, I should mention an excellent reference book on this subject: The Visual Display of Quantitative Information, by Good graphics should: Edward R. Tufte, Graphics Press. Several examples and defmitions were obtained from o Show the data clearly this source. In addition examples of typical o Display your conclusions chart errors were taken from an IBM reference o Avoid distorting the truth manual ""Pointers on Effective Chart Design"". o Avoid ornamentation Unfortunately I have no other information on o Be interesting and aesthetic this manual. Some Don'ts: * Don't let software defaults determine the final output. * D",Sugi-90-28 Potter.txt
"First Place Most Creative Use of the Software - Color Paula Mercer National Institutes of Health Similarity matrices are used extensively in microbiology and taxonomy. The aim of scientistc viewing the graphical displays of these matrices is to identify clusters or areas of close similarity. A similarity matrix is symmetrical, so when it is analyzed, the symmetrical half is discarded. resulting in a triangular shape. These triangles are usually represented two dimensionally in black and white. often on a line printer using characters of varying density to represent the similarity values. When I was asked to create a three dimensional color representation of a similarity matrix, I tried various plotting programs with the common result that the crucial relationship between the similarity value and its position in the base of the matrix was lost or obscured. Using the PRISM statement from PROC GMAP, I was able to produce a three dimensional color coded representation in which that relationship is clear. 1 then used the CHORO statement to produce both a two dimensional image using the same color coding and a monochromatic design using pattern densities in black and white. When I tried PROC GCONTOUR on the data, I found that it also identifies areas of greatest similarity. To use PROC GMAP, I designed a gridded square to use as the MAP data set. The number of small squares making up the map depends on the number of elements in the input data set selected by the user. I then used the similarity values from the input data set to form the RESPONSE data set. The similiarity values determine the Z values and color coding in the prism display, the color coding and the pattern density in the two choro displays, and the colors in the contour display. The program that produces these maps is interactive. The user selects the input data set, the colors and patterns desired for each level, and the orientation of the three dimensional display. The program contains defaults, so that",Sugi-90-280 Mercer.txt
"First Place Most Creative Use of Software - Monochrome William Kahn W.L. Gore and Associates SEVEN SHUFFLES This code demonstrates what happens inside a standard 52 card deck as you shuffle it seven times. Persi Diaconis has suggested a standard riffle shuf- fle can be modeled by a random sized cut, followed by dropping of cards from each cut into the new deck with probability equal to the proportion of all re- maining cards in the cut. It is rather interesting to watch the cards interleave each other. After one shuffle the order of each cut has remained unchanged, hut the two cuts are now interspersed. Diaconis has suggested it takes approximately six additional riffle shuffles to have a deck which can be considered random. In industrial mixers this process of cutting and interleaving a batch of ma- terial is actually implemented. Over-mixing is bad because of degradation of the material and desired high throughput. This simulation gives us a physical sense as to what is happening inside the mixers. There is also a certain direct esthetic grace associated with the plot, and so I have reproduced it sans axes and description. With this low visual distrac- tion we are better able to feel the geometry of mixing. 1590  Seven Shuffles The position of each card in the deck vs, The Seven Shuffles The nUInber of times the deck is shuffled Bottom ordinate value shows original positions HUFFLE ~ 01 <0 ~ 20 15 25 35 50 55 <0 JO 45 pas  This is a SAS program whieh graphieally shows the effect of proc sort; by cardid shuffle pos; shuffling a deck of 52 cards. *The PROC GPLOT is quite standard, the only trick being the Data Step: This DATA step uses the algorithm of Persi Diaeonis to *relabeling of the 8th shuffle as the Oth shuffle riffle shuffle the numbers 1 .· 52. It performs this proc greplay nofs; stochastic shuffle 7 times, cumulatively. The array igout gsegi cards has these 8 orderings of the deck in its 8 delete SCIENCE ART; eolumns. We output the position of each of",Sugi-90-281 Kahn.txt
"Changing PROC options or additional statements Changing the data The SAS/GRAPH Annotate facility allows the user to Using @es, footnotes, notes enhance graphics created with SAS/GRAPH software. PROC GREPLAY can place multiple pictures on a This paper presents the basic concepts of the Annotate page facility and introduces the audience to text placement, The Annotate facility allows the user to: symbol placement, line drawing, polygon construction, map labeling, custom legends, and line types. Also Place text anywhere on the screen Draw lines or other figures covered are SAS Institute provided annotation macros Define polygons to fill and color and advanced functions to allow complex labeling and Create custom ""free hand"" graphics freehand graphics. Place text or images on maps",Sugi-90-29 First.txt
"SAS/ASSIST The first thing you see after beginning The SAS/ASSIST environment is easy to use your SAS session is the Version 6 SAS and is available for use by novice as Display Manager System, which serves as well as veteran SAS System users. The the interface between you and the SAS advantage of SAS/ASSIST is that SAS code System. Getting around in the display is automatically generated for you. To manager is easy, but you may find use SAS/ASSIST simply type ASSIST at the yourself moving a hit slowly at first. DOS prompt. Once in SAS/ASSIST use the This ~s quite natural since you do not Tab key to position on the desired know what commands and special keys are function or option and press ENTER. available to move you from window to Figure 1 displays the SAS/ASSIST Primary window and to make your selections and Menu and its many options. Each option entries. will be presented in the following sections. This paper presents Version 6 features A$::nST: Prl-.-"" _ _ _ _ _ _ _ _ _ _ _ _ _ _- , that are useful for users and It programmers. also illustrates methods for improving user and programmer productivity. Topics include a detailed look at the display manager windows (program editor, log, and output), SAS/ ASSIST, global commands and special- purpose windows, saving window contents, defining and using programmable function (PF) keys, defining window attributes, and executing multiple commands4",Sugi-90-30 Lafler.txt
"resented in this ABSTRACT iutorial, then you can proceed to learn Screen .control SASIFSP (Full Screen Product) procedures provide conven- language (SCl) which will be covered in another tutorial. ient interactive facilHies for data entry and data presentation. While SCl requires that you wrHe code, it greatly enhances SAS/FSP procedures allow system developers and end- the capabilities of SASIFSP procedures, allowing you com- users alike to perform many of the same tasks that would plete control over your application. otherwise be performed by the DATA step. These tasks include: CREATING A SAS DATA SET · Creating a SAS® data set When you create a new SAS data set you need to define the · Getting data into a SAS data set variables that will be input. WHhin the DATA step, you can define variables using some combination of the INPUT, · EdHing data lENGTH, LABEL, FORMAT, INFORMAT, and ATTRIB · Producing customized reports statements. This tutorial will demonstrate the FSEDIT procedure, not A~ernatively, you can create a new SAS data set using eHher including Screen Control language (SCl). PROC PROC FSEDIT or PROC FSPRINT. Suppose you want to FSBROWSE and PROC FSPRINTwili be mentioned briefly. create a SAS data set containing a roster of your co-workers. You will learn how to perform DATA step tasks without writing The roster will contain everyone's name, phone extension, any code. All you will need to do is respond to prompts electronic mail id, and birthday. (A real roster woul",Sugi-90-31 Weiler.txt
"Real Men Do Use Menus: Developing Applications with SAS/AP Software Kenneth E. Johnson, Rand McNally and Company Introduction Screens created with PROC BUILD are stored in a SAS catalog, which is in turn stored in a SAS data library. The catalog has a SAS/AFe software is a powerful application facility for developing two level name (Iibreicatalog) very much like a permanent SAS user-friendly front ends to business applications. With SASfAF data set. However, the catalog name must be seven characters software you can provide easy. menu-driven access to SAse or less. family of software products. PROCBUILO Perhaps the greatest benefit of SASiAF applications is that they bring the power of SAS software to non-technical users. With The syntax lor PROC BUILD is: SASIAF, you can design menus and lill-in-the-blank SAS programs that can be used by end users with varying degrees of PRce BUILD ~=~ibref.catBlog; expertise with SAS software. Indeed, you can build an informa- tion system that can be used by those having no data processing Other options include: experience whatsoever. MERGE=catalog- catalog to be copied to the catalog specified in CAT= option The proficient SAS user and the SAS programmer will find there REPLACE - replace members in CAT= catalog with are other benefits of using SASIAF to fronl-end SAS software. same named members in MERGE= catalog One standardized front end can be used for many business SELECT name. type - selects screen to be coped functions. Generic SAS programs can be developed that will from MERGE= catalog to CAT:: catalog; if not specified handle many different tasks. The programs are only written all screens are copied once, with the end users supplying the information specific to their particular needs. SAS/AF also allows you to build custom When PRoe BUILD is executed, a directory of all screen entries computer-based-training (CBT) programs. Finally, programmers in the catalog is displayed. Information includes name, type, and analysts wi",Sugi-90-32 Johnson.txt
"Inc., Cary, NC Glenn H. Itano, The Fair, Isaac Companies, San Rafael, CA ABSTRACT +LOG---------------------------------------------------------------------- ,COlllllland I _~_> The FSEDIT procedure is used to create and edit SAS"" data sets 1>l>n."",e per"", ·s~saec.us606.li.bury2'; 17 I NOTE, Libraf i'!lU! ""as successfully usign~d a. follo ... , and prepare customized data entry windows. In Version 6 of 1 Englne, V606 SAS/FSP"" software, you can write programs using Screen Control <'hysical !I_me, SIISA!C.SAS606.LIBRAJlYl I , Language (SeL) to increase the functionality of the FSEDIT proce- , , dure as a data entry tool. , , , +------ -- --- -------- ------ ---- ------------ - - ------ ------ ------- --- -- INTRODUCTION +PROGRAH+I!OITOR ___________________________________________________________ _ leolllllland ~._, The FSEDIT procedure in SAS/FSP software is used as a data entry 100001 proc t ...dit dat.'perm.address scre.m.perm.myscrn; and data editing tool for SAS data sets. Using the FSEDIT proce- 100002 run, 10000] dure, you can create, browse, and modify a SAS data set in an inter- IOOOOQ 100005 active windowing environment. 100006 In previous releases, the FSEDIT procedure enabled the user to create a customized data entry window and perform simple data Screen 1 Invoking the FSEDIT procedure validation by specifying field attributes. These attributes enabled you to Indicate such restrictions as minimum and maximum values These statements initiate an FSEDIT session and pla",Sugi-90-33 Harris Carpenter Itano.txt
"oll bars ABSTRACf on the mainframe are character oriented, while the This paper describes the graphical and text user scroll bars exactly match the look and feel of Dec- interface to the Version 6.06 SAS Display Manager Windows on the VAX, and of Presentation Manager (DM). DM is the intuitive user interface for develop· on OS/2. This is accomplished by layering the DM ing and executing SAS® applications. The topics cov- software and allowing each host to replace only the ered in this paper include 6.06 features of: lowest layer of code so that the information can be displayed by its windowing system. Even though the · a discussion of the software layering of DM environment is portable, functionality has not been sac- · a discussion of the base windows in DM rificed. Performance is actually improved by taking advantage of hardware and software components na- · a discussion of new windowing fcatures tive to the environment. In this way, the SAS user gets the best of both worlds by receiving the look and feel of a particular host while also receiving the full feature INTRODUCTION setofDM. The SAS® System has 3 different modes of opera- tion. Each mode of operation serves an important pur- pose for the user. The first two modes are batch and THE THREE MAIN WINDOWS line mode. Batch mode operation provides for execut- Three main windows make up the DM environ- ing large non-interactive programs. Typically, these ment. These are the Program Editor, the Log, and the are computational",Sugi-90-34 Cates.txt
"The SAS"" Macro: An Aid to the User Robert E. Johnson Department of Mathematical Sciences, Virginia Commonwealth University, Richmond, VA23284-2014 A macro variable procopt receives a null string This paper is presented as a beginning tutorial on via a %let statement. The macro variable is used by the SAS"" macro facility. If you write your own code, placing it in the code where you want the string to either simple or complex then you may find the macro appear. In order to differentiate between regular facility nseful. The purpose here is to show you some of variables and macro variables, a & symbol is placed the fundamentals, share some examples, and start you on before a macro variable. In this example, procopt is to the path of learning more about the macro facility. It contain the desired options for the means procedure. should be understood that this tutorial does not present an exhaustive coverage of macros. Indeed, to fully A macro is resolved by substituting the string for appreciate and utilize the power of macros, one should the symbolic representation. For example, the above have mastered the art of structured progrannning. But code is resolved to: the rest of us can still find useful applications. Version 5, 5.16 or later, of the SAS"" System allows full use of macros under the CMS, as, VM/PC, data.bhe; <:ards,. and VSE operating systems. You will have limited use illputx 3'1568···79 under the VMS operating system. Version 6.06 should 2.#3 bring VMS into the fold. The macros presented here were tested on version 5.18, version 6.03 (for the PC), and version 6.06 (beta). RESOLVED · Applications Here is the same example with a non-null string Several macro statements and their applications assigned: will be presented in this section. The examples are small so to keep them manageable, but you should think big - imagine them in larger applications. The %LET Statement %lerpt9cppt.,·h.!p.ea!?-~t~~~r.]; ., 431.3..: Q'ii~j The %let statement is a macro statement wh",Sugi-90-35 Johnson.txt
"applicable to advanced C programming applications, including sys- tems programming. These features, such as communication with This paper suggests ways you can use SASIC'"" documentation to assembler programs and SPE (Systems Programming Environ- enhance SASrC program development. The paper begins with an ment), are also extensively covered in the documentation set. Sug- overview and orientation to the documentation. After you're familiar gestions for how you can reference this material and the material with what's available, you'll follow the development of a C program in the last five publications are noted in the final section of this paper. in tenns of .that documentation. The example program provides the However, since the intent of this paper is to paint out a basic basis for discussing how and where many SASIC features, libraries, ~view"" of the documentation for someone new to the compiler with options, and so forth used in the program's development are docu- a basic knowledge of the C language, these topics are not covered mented. Knowing your way around the documentation can help you here. take advantage of features such as the optimizer and debugger, resulting in more efficient SASIC applications. Information is presented in the following sections: This paper is directed towards new users of the SASIC Compiler · Understanding the Documentation under either MVS or CMS. It is assumed that you have a basic understanding of the C language at the application programming · Using the Documentation in Program Development level. The focus is on the documentation accompanying the SASIC Compiler and the compiler rather than the C language itself. · Getting Started with the Compiler · Pointers to Efficiency Tips.",Sugi-90-36 Stribling.txt
"Try it out. JMP Tutoria! SUGI 15 IMP must be experienced first-hand to appreciate fully. You can try it in the exhibit hall here at SUGL There is a video available, and we are working 00 a demo disk. by John SaIL © 1990 SAS Imtimte. illustrations from the 1MP User's Guide © 1989 The Data Table What is JMP? IMP presents the data table in a familiar spreadsheet grid, so you are always seeing your data. That is importanL h is not like a data base 1MP is designed as a statistical visualization tool. IMP's goal is to where you have to think of ""retrieving"" your data through inquiry analyze data in as graphical <u way as possible so that you can: procedures. Your data is the source of all the analysis, all the discoveries, so it is something that should be right in front of you. Too discover more long. we have had the data base tradition where you see the interact more prognunming. and the data is hidden. Welcome to the spreadsheet era understand more where you see the data and the programming is behinds the scenes. The visual presentation of the results is the key to doing all these The data table window has a very responsive control surface. Point and things better. click on a cell to edit iL Point and click on a column name to change iL Pull down a menu to transfonn it. Point and click on row or column With the data displayed graphically. you look. at your data and how headings to select them. Click and drag on a set of cells to select them. it carries the fiL You discover the patterns in the data, and which And then you can copy-and-paste. Click and drag on a column border to points don't fit the pattern. resize it. Double-click on a column to get and change infonnation. Inl~roct More. With point-and-click responsiveness, you can interact more with the data to explore its phenomena. With the results presented graphically. you can understand your statistics more. Since the tool is so easy to use, you have less resistance to analyzing data, more confidence to explore i",Sugi-90-37 Sall.txt
"Performance analysts and capacity planners keep management informed about how much work the system is doing, how well that work is being done, what problems exist in the system, and who has the problems. The information provided to management is backed up by a large volume of measurement data. Graphic displays are generally valuable for putting life into otherwise dull data and statistics. For computer performance evaluation (ePE) and capacity planning professionals, graphics are the critical media for communication to management. Good graphics speak for themselves. Graphics that present patterns that are readily interpretable by management also buy credibility for the analyst. The primary skill required for successful descriptive analysis and presentation is common sense, backed up by a good toolbox. SAS software is already the basic toolbox for CPE professionals. Many effective graphic techniques are easily implemented through descriptive SAS procedures. Other techniques are accomplished by using SAS procedures to create summary data sets and then to formulate reports by using SAS report writing and SAS/GRAPH capabilities. This paper presents graphic reporting methods that have been successful in the author's capacity planning work.",Sugi-90-38 Gantz.txt
"DB2TM PERFORMANCE MANAGEMENT: A STRATEGY USING DB2PM AND SAse SOFTWARE by Donald L. Baker Bell Atlantic When we brought IBM's Data Base 2 (D82) To address this problem in Bell Atlantic, into Bell Atlantic we recognized a need to DB2 performance tuners have taken on an monitor how it was performing. Since we were unfamiliar role. We are making specific already archiving data and writing reports on recommendations to Data Base Administration IBM's Information Management System (IMS) we (DBA) and application programming groups and following up the implementation of those were able to use that as a guide for setting up our DB2 reporting. recommendations. This appears to be the most Initially we planned to extract DE2 data effective way to achieve improvements in DB2 performance. directly from the System Management Facility (SMF) records. But (fortunately) before we The DB2 Accounting Trace data which we started development of a direct extraction use to support Programming may be divided into routine IBM offered the DB2 Performance different types: User information, which Because it would produce consists of the Authorized 10, the connection Monitor Product. type which includes; TSO, IMS, CICS, Batch, reports on the performance trace data as well and call attach. the name of the DB2 plan, the as accounting and statistics we decided to purchase this product. With DB2PM available DB2 system name, and the name of the job submitting the plan. it seemed to be more practical to capture historic performance data from DB2PM reports The user information part of the accounting record allows us to distinguish and let DB2PH handle the SMF translation. When we first began to collect DB2 data each individual process. We also use this information to relate jobs with their it seemed adequate to collect only the thread elapsed time, central processing unit (CPU) applications. Finally we use the user data to assign a type (batch, query, or transaction) time, the amount of DASD activity a",Sugi-90-39 Baker.txt
"lications listed in the ABSTRACT References section at the end of the paper. The Virtual Storage Access Method (VSAM) has had a VSAM DATA SET TYPES strong and popular career since it was introduced by IBM in 1973. It is the cornerstone of online applications such as IMS and CICS, and is widely used in vendor packages and There are three types of VSAM data sets the SAS Its flexibil~y and internal data batch applications. programmer may have to access: The Key Sequenced management have made it an access method of choice. Data Set (KSDS), the Entry Sequenced Data Set (ESDS), and the Relative Record Data Set (RRDS). Each of these Those who choose to use VSAM can significantly improve data set types differs in its internal organization. Thus, the their programs efficiency by properly managing the VSAM buffering strategy differs for each. It is important to know buffers. There is a specific methodology for determining how each type of VSAM data set is organized to what kind, and how many VSAM buffers to allocate to a understand how its buffering technique works. program. If used correctly, this buffering methodology will greatly reduce program CPU time and disk I/O's and lead The data in each of the three data set types is stored in what is known as Control Intervals (CI). A CI is the VSAM to better job turnaround time. term for a block of data A CI may contain one or more VSAM records or ~ may contain tree space. When a VSAM The SAS System allows programmers to load, read, and upd",Sugi-90-40 Raithel.txt
"scribes a program written in the SAS system which determines and profiles daily resource ubhz~t:on In terms of .hourly service unit consumption in an MVS environment. The program utilizes Mernll s Expanded GUlde (MXG) software as a frontend along with base SAS software, the SAS macro language, and SASIGRAPH@ software. Subsequently, each MVS installation is provided with a high-level view of actual system activity. per hour a computer system can deliver, but also I. INTRODUCTION monitor the measurement activities of the In today's dynamic data processing computer system in question. In addition, the environments, the most crucial endeavor facing difference between hourly type 70 records and the capacity planners of a computer center running on sum of the same hourly type 72 records turns out to IBM's Multiple Virtual Storage (MVS) operating be the uncaptured service among all the activity in system is that of providing decision makers with a the system. The belief here is that all unaccounted high-level overview of how well the installation is work presumably is going to the good of the system operating. The main obstacles to accomplishing an supporting functions such as paging, swapping, endeavor of this magnitude include an interrupt processing, 110, Systems Resource overabundance of raw data that encumbers M.anager (SRM) and service calls. ~'urthermore, efficient measurement of the MVS system and the WIth both measured and unmeasured hourly difficulty in producing trustwort",Sugi-90-41 Waldowski.txt
"The VMS operating system has the advantage and the added com- plexity of an operating system that is very tunable. That is, the sys- This paper gives a brief overview of the capabilities of the 2.0 tem manager has many choices that can affect the effiCient management and delivery of computer resources in both positive release of SAS/CPE"" software running under the VMS- operating system. Each of the possible sources of raw data is discussed sepa~ and negative ways. In addition to the hundreds of SYSGEN parame- ters that govern VAX performance, the system manager can also rately and in comparison with one another. A discussion of the limit specific users and queues in order to optimize resource utiliza- CPETOOL command and the CPE Menu System is included, along tion. VMS is also complex in terms of the raw data that can be gath- with examples of their use in data collection, management, and anal- ered for analysis of the system. ysis. Examples of the use of SAS/CPE reports are included in a short discussion of the basics of VMS perionnance evaluation. This added complexity results in a cost to the system manager: there are more warning signs to be attentive to, more tuning param-",Sugi-90-42 Rowles.txt
"Memory fragmentation control There is a set of options (also called superblocking options) which serve to control memory fragmentation. This paper presents information on tuning the These work by setting aside pools or SAS System in both interactive and batch modes superblocks for several classes of memory under MVS. Principal areas covered include allocations. These classes are for 1) the memory and program management, I/O portable supervisor, 2) permanent memory subsystem characteristics and performance, and which exists for the life of the session and 3) temporary memory which 'exists for the life of a performance aspects of some SAS System options. Architectural and implementation task or procedure. Each class has an option specifying an ISA or initial storage allocation differences between Versions 5 and 6 which amount and an OSA or overflow storage amount. must be understood to effectively tune the The default values for these options should system are also discussed. suffice in most cases and should be left alone. If you wish to look up these options, they are prefixed PSU (portable supervisor), VMP",Sugi-90-43 Squillace.txt
"INTRODUCTION TO CPE USING THE MAINFRAME AND PC by Bruce L Green Senior Systems Programmer MIB, Inc_ INTRODUCTION storage, based on memory, has increased sixteen-fold. The number of terminals have increased more than twenty-fold. This paper will provide an overview of computer performance evaluation at MIS using both the mainframe and personal CPE EVOLUTION AT MIB computer. MIS is a computer service bureau to member life insurance companies. At. MIS. we have two 3083-8 CPUs The capacity and periormance management process is gradual. At the time (1985) we installed MXG ® software (for running MVS SP Extended Architecture (XA): a sixteen-megabyte machine dedicated to the ""Online"" Search computer performance evaluation) to create our baseline system and a sixteen-megabyte batchlTSOlClCS machine. performance database (POS), the hardware configuration was Both systems run JES2 and VTAM. The CPE function is a task two 3031s (each a one ""mip"" machine) and the 64 3350 DASDs were all shared among both CPUs. H was found that with the of the Systems Programming group. There are approximately restrictions of channel and controller configuration, we had 50 application programmers here. MIS's production system is constant OASO contention. Also, as we observed, both the test written in assembler language and its data base was written and developed internally. Our MIS Data Base is a multi-volume and batch job CPU utilization had increased significanUy. The VSAM cluster that spans eight 3380E volumes. annualized increase in CPU utilization was predicted around 25% (January. 1985 System A and B average prime-time BACKGROUND , utilization: 65% and 35%, respectively. January, 1986: 85% and 70%). The end of the 1980s has signaled a dramatic increase in the Over the past year, the reduced price of PSl2s made an computer equipment acquisition at MIB. In 1980, MIB converted attractive addition to our CPE configuration. We were able to its RCA SPECTRN70 systems to two IBM 3031s and current",Sugi-90-44 Green.txt
"is add-on software that allows harnessing of multitask- ing/multiuser capabilities of the 80386 processor. (IGC recom- With the advent of the SAS· System on microcomputers, some mends that you estimate 1 Mb RAM per user. Because you will confusion has arisen about the best hardware and software for want to use the EMS option in SAS with VMj386, I recommend maximum performance. This paper discusses in depth two 80386 that you estimate at least 1~ Mb RAM per user.) VM/386 is a systems. The first is a 16·MHz machine with two 28-ms hard program that runs like any other piece of software. Therefore, drives; the second, a 25-MHz machine with a 14-ms hard drive. setting up the PC to boot without automatically invoking VM/386 Several other systems are included for comparison. Variations on will result in a standard DOS machine. This is termed the front the following setups are considered - math coprocessor CPUI end. When VM/386 is invoked, the PC operates in a MUT speed, EMS, hard drive utilization, operating environment (DOS· environment. For the testing done in this paper, the DOS funs 3.21. DOS 3.3 and VMj386TM), and disk caching. Typically, users plagued with poor system performance try to solve the problem were made in the front end. VMJ386 has the ability to turn off nodes which are inactive. This way, the remaining active nodes by purchasing a faster PC with more memory. In most instances, get a greater share of processor time. For our systems, we have this will not have the g",Sugi-90-45 Pabst.txt
"vices ABSTRACT The SAS Institute has ported a number of SAS software products to the personal computer environment. The SAS System Version 6 for Personal computers potentially offers an inexpensive and convenient interactive environment at the workstation level. However, the potential advantages of the SAS System for Personal Computers can be achieved only if you have a proper microcomputer configuration, use proper supporting software, and select proper SAS configuration options. This paper describes benchmark results illustrating the performance improvements that can be obtained using proper configurations, supporting software, and SAS configuration options. The first two ways to get better INTROPUCTION performance were accomplished by a We are computer performance and ""money"" solution. capacity planning analysts, often * collaborating to analyze the per- We purchased state-of-the art formance and capacity of large IBM hardware (at the time, the 386 mainframe systems. We use personal 20MHz hardware was the fastest computers extensively in our available) . projects: performing extensive * For our two ""main"" systems (the interactive analysis, developing PS/2 Model 70 and the ALR reports and graphs, writing SAS code FlexCache 20386) we purchased to be uploaded to the mainframes large capacity and fast (ESDI for execution, incorporating SAS technology) disks. We also output into word processors, using purchased an ALR 386/220 to use SAS/GRAPH to prepare presentations, as a back",Sugi-90-46 Deese Ebner.txt
"· Operating System (OS) Analysis: This paper describes a quantitative method for performing Com- puter Performance Evaluation (CPE) on the Apollo· token ring · CPU Usage network. This method describes the monitoring, analysis. and tuning of a dynamic, tightly coupled, Local Area Network (LAN) · Disk Activity using base SAS~ software. SAS/GRAPH!] software and the SOL procedure. As LANs grow, quantitative analysis is becoming · Network 1/0 essential to target future workstation acquisitions intelligently and to improve network performance and end user response · Virtual Memory Usage time. · Physical Memory Usage",Sugi-90-47 Bonham.txt
"· Provide for security using DBA and secondary passwords to assign specific authorities at the individual item level. The Version 6 architecture has opened up new ways to interface · Provide for Simultaneous update and retrieval access using the SAS'"" System to SYSTEM 2000~ software databases. This the Multi-User product. paper shows you how to take advantage of some of the powerful features of SYSTEM 2000 software. Such features include Coordi- · Take advantage of execution parameters to tune your Multi- nated Recovery, audit trail update log, Multl-User~ software, higher- User system. level language support through PLEX, security at the individual com- ponent level, and SYSTEM 2000's own native Self-Contained · Use Coordinated Recovery to ensure database integrity by Facility (SCF) languages. preventing partial updates. SYSTEM 2000 software can be used in conjuction with Version 6 · Use the SAS/ACCESS interface, SCF through the QUEST interfaces or as a stand alone data management software system prOCedure, and PLEX facilities to tailor your applications for that provides an easy and convenient means of rapid update and your needs. retrieval of data. SYSTEM 2000 ESSENTIALS",Sugi-90-48 Pitts Vance.txt
"SAS Structure Although the internal storage structures. of POSITION EMPNAME -(--Descriptor SYSTEM 2000® software and SAS® data files I differ, they are quite compatible in the SAS environment Interfaces are provided to ensure JOHN JONES efficient and accurate transitions from one to MANAGER JOHN JONES PROGRAMMER the other. This paper addresses the reasons SR PROGRAMMER JOHN JONES ~Data for choosing one form over the other and gives methods for migrating between a SAS data set and a SYSTEM 2000 database. REQUIREMENTS THAT INDICATE SYSTEM 2000",Sugi-90-49 Ashlock.txt
"query language, and a complete Multi-User- software facility for implementing real-time data sharing. SYSTEM 2000"" Data Management Software is currently available to SAS"" users on IBM'"" or IBM compatible mainframes only. Many SAS applications can take advantage of SYSTEM 2000 software Improved 110 Perfonnance options to improve processing performance, DASO utilization, and With Version 6 of the SAS System, all procedures now have a global access to their SAS data. With the availability of the option of WHERE, which enables you to avoid costly preprocessing SAS/ACCESS"" interface to SYSTEM 2000 software in Version 6 of data in order to subset your data for a particular procedure. of the SAS System, there are virtually no limitations on access to Although the specification of an indexed item in a WHERE option data stored in a SYSTEM 2000 database. This paper specifies is not required, utilizing indexed items can reduce resource utiliza- criteria that enable you to identify SAS applications as candidates tion required . to access your data. When you utilize the for utilizing SYSTEM 2000 software as well as the steps that must SASI ACCESS interface to SYSTEM 2000 software, you can gain be performed to accomplish the move of the applications to a data some additional performance improvements over the base Version structure based on SYSTEM 2000 software. 6 110 engine. In Version 6, all 110 engines enable you to specify multiple Boolean",Sugi-90-50 Carpenter.txt
"The transparent access of data from external databases is now a Below is an example of what PROC ORACEXT may look like in a reality under Version 6 of the SAS"" System. Multiple engine con- SAS program and the output from a PRINT procedure: cepts in the Multiple Vendor Architecture (MVA) bring increased PROC ORACEXT our:supply NAHE:'pele' PWD:'soccer'; flexibility and power to SAS users across many of the SAS plat- SELECT brandname, item, material, size_of.....item, forms. Under the VMS- operating system, two database engines color. price from inventory WHERE material"" · cotton' have been developed for Release 6.06 of the SAS System. The OR material. 'leather' SAS/ACCESS~ interface to ORACLE"" and the SASfACCESS inter- ORDER BY item, brandname. color; face to RdbNMS- enable you to combine the power of the SAS System with your data stored in these database management PROC PRINT DATA""'supply LABEL NOOBS; systems (DBMS). TITLE 'Inventory of cotton uniforms and accessories'; FORMAT price DOLLAR7.2; RUN;",Sugi-90-51 Underberg.txt
"AN SOFTWARE INTERFACE BETWEEN SASDAND ORACL~ Weilie Qian, State Information Center, Beijing, China Yuejin Chen, State Information Center, Beijing, China AESTRACf significant for those users to develop such an interface software, which can conveniently transform ORACLE table and views to SAS data sets, This paper introduces a SAS interface software or vice versa. developed under IEM MVS operating system. It provides SAS users with a way to access and Following will introduce three SAS procedures to analyze their ORACLE relational data base using satisfy these users' requirement. SAS software. 1. PROe ORAEXT ; This procedure is used to extract the data in ORACLE data base to create SAS data This software consists of three SAS procedures, set. To invoke the procedure, type all of them can execute in full-screen mode or in batch. PROC ORAEXT I 1. PROG ORAEXT ---- In full-screen mode, you can RUN, make choice to ORACLE tables and views, and the You then see the DATA ACCESS PANEL <Screen 1). columns you want to extract. A SAS variables Three fields will be input,the USERNAME field and can be the combination of several columns (include function operation). It also allows the PASSWORD field arethe identification to enter into ORACLE relationaldata base, it provides you you to operate on SAS variable name and its format, finally establishes the SAS data sets privileges to access data base. The OUTPUT SAS DATA SET field allows you to specify the name of you expected. the SAS data set where you want to store the 2. PROC ORALOAD ---- Creates and loads ORACLE extracted data, the SAS data set can either be tables, or insert data to an existing table, permanent data set or a temporary data set. The using SAS data set input. 3. PROG ORASQL you can perform any SQL 00\ClE IJml!FACE statements in interactive mode or in batch. DATA AOCESS PANEL ;:> PAGE s:RCU. Above three procedures were written with PL/I language. We use ORACLE's PRO·PLI product to operate ORACLE resources, use SAS p",Sugi-90-52 Qian Chen.txt
"FocusEZ: The User-Friendly, Full-Screen, Menu-Driven Utility for Using SAS® Software with FOCUS® Data Bases Stan Sibley, Sibley Enterprises ©1989 Problem: As originally written, FocusEZ was put together to simply invoke PROC Corporate data (or someone else's data) is FROMFOC to digest a user-supplied in a FOCUS data base, but you want to FOCUS HOLD file into a SAS data set. perform data analysis, management and When I heavily revised the product as I found it, however, I added the features reporting -- and maybe graphics -- with described above, and more. SAS products. Here's a solution: FocusEZ uses two important components: the first, of course, is PROC FROMFOC, available in the SAS Supplemental You could learn enough FOCUS to extract the data you want, then save it in a FOCUS Library, which is used as the data transformation engine. The second part, HOLD file. Altematively, you could have however, is a SAS macro which works someone knowledgeable in FOCUS do the work for you. You could then use indirectly with FOCUS to prepare a SAS PROC FROMFOC to read the data into data set containing information about SAS, being sure to give the procedure a information -- what fields are available, how they're organized and formatted, SAVE statement to avoid the default whether they're character or numeric, what FOCUS field names. internal form the numeric fields are stored -OR- Solution 2: in, etc. You could use a sophisticated utility to tell This macro, RDMAST (for ""read master""), you what fields are available in the takes advantage of the fact that FOCUS files are not self-contained, self-describing FOCUS data base, allowing you to select only the ones you want, sorted by any data sets, as are SAS data sets. Rather, available field(s), or none of them. The FOCUS stores its Qa1g in a hierarchical utility would write the FOCUS program data structure (usually a disk data set) and (called a FOCEXEC) you need to do the it requires a description of the data extraction and sortin",Sugi-90-53 Sibley.txt
"Interface Engines manipulate files that are specific to another vendor's software. The DB2 This paper discusses changes in the SAS'"" System interface to DB2~ engine is an example of an interface engine. between Version 5 and Version 6, with an emphasis on converting applications. The SAS/ACCESS8 interface to DB2 with Version 6 Engines are behind the scenes of the SAS application. The applica- indudes new features, such as the ACCESS and DBLOAD proce- dures and the DB2 interface engine to manipulate data in DB2 tion in Releasp, 6.06 can now access data in many formats directly without having to be concerned about the underlying format. To tables. In Version 5, SAS/DB2- software used procedures such as access data in a DB2 tabte, a special kind of view is set up. This OB2EXT, OB2UTIL, and OB2LOAO to access OB2. This paper is view is a virtual SAS data set that does not contain the actual data intended for users who have written applications for SAS/DB2 in values but instead contains a definition on how to get the data val- Version 5 and are beginning to work with the SAS/ACCESS Inter- face to DB2 in Version 6. ues when needed. Then the application just references the view, and the appropriate engine (in this case the DB2 interface engine) is selected automatically and is used to retrieve the data and present",Sugi-90-54 Klenz.txt
"OF SET RAW I-I~~-I""'~INFORMATION DATA As IBM's strategic product for relational databases, Database 2 (QB2H,,) excels by handling very large volumes of data, interfacing with on-line programming languages such as CICS, and ensuring data integrity DB2 SAS/DB2 SAS through automatic backup and recovery techniques. No other database product offers the benefits inherent Figure 1. Diagram of Information Delivery in DB2. ~ is recognized for its superb data management and reporting capabilities that facilitate",Sugi-90-55 Baer.txt
"per identifies some of the issues to consider when accessing your Data Base Management System (DBMS) through the SAS· L Version 6 database engines. Both SAS and DBMS performance SAS VIEW (X.Y) I I~ ENGINE Issues are identified throughout the paper. The focus of this paper DESCRIPTOR is on the current Version 6.06 engines: SYSTEM 2000: DB2; SUPERVISOR SaUDS; RdblVMS' and ORACLe l<requests) I<dala and return code) INTRODUCTION ~llrv~6~d~a~la~b~a~se--~-,~1 I USER L -______ The SAS Version 6 database engines provide transparent access - I engine DBMS to data stored in a user DBMS. With transparent access comes a performance cost, which can be measured in SAS and DBMS pro- cessing time. This paper discusses DBMS Indexing, DBMS locking, Figure 1 joining DBMS data, SAS WHERE statement processing, multiple access, SAS data set options along with suggestions on how to The key to Version 6 database engine operation is the view desaip- tune the database engines. The information provided will help you tor. This desaiptor contains the necessary SAS and DBMS informa- use the SAS Version 6 database engines more efficiently. tion for DBMS access. Given Figure 1, the processing flow would be The Data 1. The SAS System evaluates the PRINT procedure request The following SAS DATA step generates test data for the DBMS and notes the type of the DATA parameter. In this case examples in this paper: X.Y is a view descriptor. data Ai drop 1 It; 2. The SAS engine supervisor examines the engine identif",Sugi-90-56 Plemmons.txt
"EASIER USER INTERFACE WITH SET AND MERGE MACROS Cheryl C. Hammond-Puhl, U,S. Army Aviation Systems Command Introduction: will automatically pull in the appropriate data sets. However, the structure of the data sets did cause a problem here. Macros called SET and MERGE can be used to replace the Over the years, a large amount of data has been collected. It SAS® commands of the same names to make life easier for users is very inefficient for SAS to read data from 1977 to 1989 on every of SAS programs. At the U.S. Army Aviation Systems Command run When most users will select data from only the last two years. (AVSCOM) in st. Louis, Missouri, the Sample Data Collection (SOC) Hence, the files have been divided into archived and current data office collects data on a sample of approximately 850 Army aircraft. files. The year 1988 is our current break year. The archived data The SOC data base stores data regarding the maintenance and are placed in a SAS library called by the aircraft name attached to operation of these aircraft. The data can be used to stppol1 the characters 'BOO'. For example, AHG4ABOO.EV20. The current engineering studies. The focus of the SOC office has been to data are stored without the 'S88'. For exampte, AH64A.EV20. Due provide a data base of SAS files and a library of usable 8AS to this me structure, certain changes must be made to the code programs to the AVSCOM engineering community. Although we depending on the dates selected. For example. if a user selects provide printed reports on request, the focus has been to provide STDATE = 01JAN86 and ENDATE = 31DEC88, then data steps the tools for the engineer or analyst to conduct studies using the such as the following will be necessary: data base in a dynamic fashion. DATA TEMP; Using Macro Variables In SOC Programs: SET &AIRCRAFT.B88.EV30 &AIRCRAFT.. EV30; Standard SOC programs are set up with a set of macro BYCNTLNUM; variables at the start of each program. By changing the settings on IF&SELECT; t",Sugi-90-57 HammondPuhl.txt
"VERSION 6 COMPONENTS OF THE DB2 SAS/ACCESS INTERFACE The database engines introduced in Version 6 provide a way for SAS~ applications to easily interface with external database man- agement systems such as D82: Because the interrace is a ~black The SASI ACCESS interface to DB2 is designed to incorporate the box""to the application, it is difficult to know if the application is using Version 6 concept of Multiple Engine Architecture (MEA) . The sin- the most efficient method to accomplish its task. The goal of this gle engine architecture of Version 5 that required data to exist in paper is to provide a glimpse behind the scenes into the DB2 inter- a SAS data file before it could be processed by the SAS System face for Version 6, with an emphasis on choosing the best design has been replaced by the Version 6 concept of Multiple Engine strategies for different applications. This paper is intended for users Architecture. The DB2 interface engine is one of many engines (ac- who will be coding Version 6 applications using the SAS/ACCESS"" cess methods) incorporated by the Multiple Engine Architecture. interface to OB2. MEA was designed to meet several goals, including a transparent method of accessing data stored in the database management sys- tems of other vendors. The OB2 interface engine enables Version",Sugi-90-58 Jacobs.txt
"is a Sal SELECT statement used to retrieve data from the database. Unlike the SAS OAT A step, a query does A database consisting of Sal procedure tables (SAS"" data sets), not generate a new data set (unless included in a SOL PROe SOL views, and SAS indexes under Release 6.06 of the SAS CREATE TABLE statement). Rows retrieved are System has been established. The process of creating and manag· displayed in the SAS OUTPUT window. ing this Sal~ database is discussed. Creating tables and views is best accomplished by using a combination of PRoe SOL state- table ments and aSAS DATA step. In addition, creating indexes on exist- is a data structure that holds data. In a relational ing tables and normalization, or reducing data redundancy, are used database, a table is composed of rows and columns. In to increase performance and optimize queries. Table relationships the SAS System, a table is a SAS data set, which is are established by defining primary and foreign keys. An integrated composed of variables and observations. data dictionary is created to promote and enhance database man- view agement. Management of the database is provided for by queries, is a database object that is a logical representation of a including the operations of select, project, and join. Data definition table, group of tables, or any subSet or superset and data manipulation operations such as create, alter, insert, and thereof. Views appear to be identical to tables with the update must also be performed to define and fine-tune the data- exception that in Release 6.06 views are read-only. base. Views do not contain data. Instead, they point to data contained in other tables. Views consume only the space required to store their definition. A view definition",Sugi-90-59 Stranieri.txt
"MANAGING A MULTI-VENDOR DBMS ENVIRONMENT WITH THE SAS SYSTEN® Tim Feetham, Security Pacific Automation Company/NW Introduction discussed. Interfaces, will not be covered. A common estlmatefi\several years ago put the SAS Systerll'"" in over 70% of all IBM mainframe shops. was Computing Standards It frequently brought in for capacity planning and computer performance, but After a number of years of minimal use its use has often remained locked in the northwest, SAS software is within the tech support group. This growing within a competitive data paper explores ways of increasing the analysis software environment. Some productive use' of the SAS System for of the factors affecting its past lack of data base management and it suggests acceptance have been aggressive an answer to rigid standardization marketing by its competitors and a lack where it has formed an organizational of support at major northwest road block to maximizing software universities. SAS Institute's offire at productivity throughout the enterprise. Irvine has began to turn the situation around. However, some organizations in Software standards are generally the process of standardization have considered to be good things, but attempted to drop SAS software because there is a down-side to tool of their familiarity with other software standardization which needs to be packages. considered. Differences in training needs, continuity, software Computing standards committees can capabilities, data management, data make decisions for the organization access, user support, and maintenance that have adverse affects on the needs for different computing productivity they seek to enhance. environments will be used to show how These groups are all too often too the multi-vendor tool approach will homogeneous. If you have been in the enable an organization to take business for any amount of time you can guess the consequences of an advantage of more timely, applications programming task force comprehensive, and c",Sugi-90-60 Feetham.txt
"The marketplace of database products has been shaped L""vel 0 1"" QlPLOTEE NUn8E5t in large part by the leading academicians in computer science and, of course, by IBM. Once the relational technology came on the scene, the leading scholars were quick to embrace the idea. After all. hardware storage was getting cheaper and CPU power. once I ...... , isolated in massive computer rooms, was making its 100"" POSITION MITHIM COIlPANY 1'000* ElHICAJIOIIAL IIAOCQl:OUND 101""' POSITION TITLE way to the desktop_ Is todays technology leading 102""' DEPAIITI{£HT towards a relational model? 103* IlAfIACER POSITION TYPE 10-<0* 10S* START tl/lTt: 106""' END IlATE The purpose of this paper is to explain the difference between a relational and hierarchical'data structure and present a description of the characteristics that define '010"" EDUCATION Level 2 110. SALARY MITHIN POSIJION .. ,,"" SCllOOL 111""' PAl RATE these structures. Although the data structure is a part '012"" DECREE-'CEItJIf""ICATE 112'"" PAY SCHEDULE '013. DATE COIIPl.£TED 113"" EFFECTIVE DATE of the database design, there should be other 1"",""' CIlRItEkr D£l)Uc:TION "" ,,,. nUOR FlELO .. IS· nINOR FIEUl considerations when selecting the correct database management system. So how do you choose and what tools are available to Relational Data Structure make these decisions? The SAS System provides an In the relational model, tables are used to represe!1t the opportunity to take advantage of any data storage structure including flat files,",Sugi-90-61 Zuniga.txt
"Selecting, Inserting, Updating, and Deleting rows and columns of data from a relational database. SQL is also a data The use of relational database (RDBMS) technology definition language (DDL) for creating and and different levels of normalization (1st, 2nd, deleting database objects (table1s, views, 3rd, 4th normal data structures) is proliferating indexes, synonyms, etc.). Additionally, SQL is a throughout the data processing industry. RDBMS data control language (DCL) where user access to' systems are valued for their ability to maintain the database and its tables and views are granted the integrity of data, reduce unnecessary data (Grants). SQL is not a procedural language since redundancy, and provide maximum flexibility in it does not offer programming constructs such as retrieval. At the same time SAS@ software is logical sub setting with IF-THEN-ELSE or CASE established as the general fourth generation statements, or looping with DO-END, DO-WHILE, or language (4GL) tool for data analysis and DO-UNTIL programming constructs. SAS® Software, reporting. Clearly, the use of relational in contrast, does have a procedural language databases and SAS® software should be included component in the DATA step that supports logical in the ideal tool kit for systems development. and looping programming constructs. The library Use of the different and distinct forms of of SAS® Software procedures is internationally normalized data structures, within an RDBMS, accepted as one of the",Sugi-90-62 Johnson Cornejo.txt
"The challenge for a view Interface engine for a hierarchical database The first Version 6 SAS engine for hierarchical databases was built Is that the SAS procedures expect to process taibuJar data. A hlerar· for SYSTEM 2000"" Data Management Software. SYSTEM 2000 chy contains not one typo of record, but many, and the records software Is a hierarchical data management system for mainframe repeat in groups that V81Y in dimension. Furthermore. while each computer systems ruMing under IBM· MVS and CMS host sys- type of record is always related to at least one other type, not every tems. A hierarchical database represents one-to-many relationships typo of record is related to every other typo. A number of issues among data records at different levels. This paper describes how arise. What is an observation? What side effects does updating a to use Version 6 of the SAS System to define, load, query, and single record cause? What does it mean to delete an observation? update a SYSTEM 2000 database. How do you qualify groups of records? What happans if portions of the relationships are missing? The SASIACCESS Interface to SYSTEM 2000 software answers these questions in ways that sur...",Sugi-90-63 Barrett.txt
"stitute Inc., Cary, NC THE ACCESS PROCEDURE ABSTRACT Mary works for the headquarters of a national advertising firm. She The ACCESS descriptors are the link between your DBMS and the has been asked to collect data from each of the satellite offices to SAS System. When you create an access descriptor, you are produce a firm-wide marketing analysis. Although each office shares describing the DBMS table layout in a fon11at that the SAS System computer resources, each has chosen a different database manage- understands. Suppose you have an RdbNMS table ACCOUNTS as ment system (DBMS). Some have selected RdbIVMS7 while others shown in Table 1. use Oracle~ Mary herself prefers the SAS~ System. While Mary has Table 1 RdbNMS Data Layout for Table ACCOUNTS access to all the data she needs, they are aU stored in incompatible formats and will require a lot of her time and resources to combine Columns for table ACCOUNTS: into one DBMS. If she could only find a way to bridge the communi- Column Name Data Type Domain cation gap and bring them all together, she could produce the KEY NUMBER CHAR(8) reports she needs in minutes with the SAS System. NAME CHAR(35) NAME KEY CLIENT CHAR(8) With the release of Version 6 of the SAS System, Mary's problems ACCTREP CHAR(4) are solved. The new release features Multiple Engine Architecture, YTD_REV DOUBLE PRECISION designed to meet several goals including a transparent method of accessing data stored in the DBMS of other vendors. No longer is Constraint",Sugi-90-64 Moorefield.txt
"SAS Data Variables Each observation in a SAS data file contains one data value for each The architecture in Version 6 of the SAS'"" System has opened up new ways to migrate data from SAS data sets to SYSTEM 2000"" variable; that is, each column of data values is a variable. SAS vari- ables have several defining attributes. The attributes used by PAOe databases. It also provides a way to migrate data from other DBMS databases to SYSTEM 2000 software. This paper describes the DBlOAD to build a SYSTEM 2000 software item are declaration type, length, format, name, and label. process of taking existing SAS data sets, creating a SYSTEM 2000 database, and populating that database. Examples show how to There are two types of variables, numeric and character. The length create a database view, how to map data variables from a SAS data attribute is the number of bytes used to store each of a variable's set to that view in order to add complete new entries in the data- values in a SAS data file. A variable's format is the pattern the SAS base. or to append records to existing entries. Input is not limited System uses to display each value of a variable. The name is the to SAS data sets. Any view supported by the ACCESS procedure a·byte name that becomes the SYSTEM 2000 item name. If the in Version 6 of the SAS System can be used to populate a SYSTEM 2000 database. label option is yes, then the label name is used for the item name. Members Of Type Access",Sugi-90-65 Pitts Hiserote.txt
"LINEAR PROGRAMMING MEETS SASIAF Danielle L. Johnson Martin J. Collette INTRODUCTION The Gas ordering group at the Southern California Gas Company is chartered with the daily responsibility to secure the since the deregulation of the -natural least cost gas. gas industry purchases of gas from short term contracts have become a key supply Daily nominations of spot gas change in source for many utilities. At the the following way: 1) Response to southern California Gas companr . purchases of this gas are credlted w~th changes in the daily spot gas requirements, 2)Constraints on the saving rate payers many millions of capacity available on the transmission dollars. pipelines, and J)The availability of gas To aid in making optimal purchase supplies. The linear programming model decisions, the Operations Research and captures the interrelationships among Planning Models group at the so~thern the factors and finds the least cost California Gas Company worked wIth ~h~ sources of supply. Gas Ordering Group to develop a decIsIon support system. This system, t~e spot Gas purchase system (SGP) provIdes the THE SYSTEM user with an operations resear~h.tool to solve the problem with'out requlrl.ng any The spot Gas Purchase (SGP) System is mathematical knowledge. The interface primarily designed to give the users the uses SASjAF to create,a user friendly facility of running PROC LP without environment that provldes accesS to having to know anything about SAS, powerful mathematical tools. The Linear programming, or a matrix. This underlying engine of this- system is ~ system allows the analysts to be in a linear programming model that was bUllt user-friendly environment while creating the necessary data for the model which using SASjOR. reflects all of the possible constraints of the contracts or the network. Here is the Main Menu for the SGP System: OVERVIEW This system can be broken down into 4 The spot Market basic parts. spot gas is gas that is delivered under 1- Viewing the cu",Sugi-90-66 Johnson Collette.txt
". The top vote- getter in the 1989 SASware Ballot for SAS/ETS was ""Provide the ability to analyze variable rate mortgages."" The development of PRoe LOAN was the Institute's response to this request. The LOAN procedure can analyze variable rate, as well as buydown rate, fixed rate, and balloon payment loans. It can incorporate initialization costs, downpayments, and prepayments. Furthermore, PROe LOAN offers econoII1:ic comparison of different loans at different times during loan lives. INTRODU CTION In the process of obtaining a loan, you might have some of the following questions: · What are my alternatives'! · What would my payment schedule look like under different alternatives? · Can I afford the payments? · How will the different loans affect my taxes? · If I plan to sell in a few years, what would the outstanding balance be on my loan? · How much of the money I pay will go towards paying interest? And, after all, which loan is best for me? The LOAN procedure intends to answer such questions. Given any three out of four parameters (interest rate, life of the loan, principal amount, and periodic payment), it calculates the fourth one for fixed rate, adjustable rate, buydown, and balloon payment loans. Prepayments and costs at the initialization of the loan, such as downpayment, discount points, and other initialization costs, are incorporated into the analysis and comparison. Multiple loans can be processed and compared in terms of economic criteria such as after-tax or b",Sugi-90-67 Ege.txt
"This application of SAS/OR software was procedure involves finding an initial solution designed for Air Staff enlisted policy planners such that all goals are achieved to the degree as a decision aide in the complex arena of that no goal could be improved without detriment * military force management. By coding an to other goals. The OMs are then given the innovative goal programming algorithm in SAS opportunity to select desired values for each software, the domain of Operations Research * goal. The result of the first iteration shows a problems which can be modelled via the SAS/OR set of solutions indicating to the OMs how software has been greatly expanded. achievable each goal is and how sensitive goals No longer does the analyst need to limit are to each other. With this information, the his formulation of the real world into a model OMs revise their goal values. The next step consisting of a set of constraints having one begins by optimizing again under the modified single objectiv~ function. By sequentially formulation. This process continues until a calling PROC LP and generating various satisfactory solution is obtained. specially designed reports it is possible to Each ISGP iteration for a multi-criteria optimize numerous conflicting goals and problem with m goals will present one principal objective functions. solution and m auxiliary solutions. The The multi-goal programming procedure principal solution meets or exceeds the desired outlined in this project is Chin",Sugi-90-68 Crissey.txt
"activity-on-node method. For further explanation of the SAS/OR"" software provides several facilnies for managing crnical path method and for more references, see the projects and resources. This tutorial describes how to $AS/OR User's Guide, Version 6, First Edition. design a menu-driven system for managjng muniple tasks that are to be completed by several differeni individuals. The general syntax of the CPM procedure is Simple. Using the CPM procedure, the system tracks utilization of Many options are available to enable you to control the manpower, monnors project progress, and estimates processing. In order to have complete control and feasibility of starting new projects wnhin a given time frame. provide the most flexibility, the following program uses The system uses Release 6.06 Screen Control Language most of the available options. The complexity is wnh SAS/FSP"" and SAS/AF"" software to make entry of the hidden from the user of the system by a SAS/AF menu projects simple. system.",Sugi-90-69 Brinsfield.txt
"Map I. Ambulance Demand Zones The Reproduction of Ambulance Runs Program can assist decision making in the Chicago Fire Department by suggesting more efficient deployments of present am- bulance companies and optimal deployment of new com- panies as they become available. The output from the program pinpoints the areas of the city with the most demand for emergency medical services and areas where all incidents may not be responded to within five minutes. The program can test various locations of new ambulance companies before deployment, and examine the effect on coverage throughout the city. The areas that are under- covered. that is. not within five minutes of an ambulance company are also isolated in the output report.",Sugi-90-70 Barry.txt
"USING SASjOR* PROJECT MANAGEMENT TO PLAN AND MANAGE A MAJOR ELECTRIC GENERATION FACILITY OUTAGE Wayne Maruska, Basin Electric Power Cooperative tutes a revenue loss of between $43,000 and INTRODUCTION $639,000 for Basin Electric. The project management procedures in the In October 1986, as part of a conversion of its SASjOR * modules provide the capability to plan data processing systems to IBM, version 5.08 of and manage projects of varying complexity and SAS software was installed. In July 1987, the size. With the addition of the SASjAF* product, system was upgraded to version 5.16 and the co- this capability can be simplified for the user operative is currently using version 5.18. The co- through the creation of a menu-driven project operative has Basic SAS*, SASjFSP*, SASjAF*, management application. This paper will de- SASjOR* and SASjGRAPH*. Two people arc scribe one user's experience with this kind of ap- responsible for supporting the SAS* software; one plication. full-time and onc part-time. Included in the installation of the SAS* software BUSINESS BACKGROUND was a menu-driven SASjOR * prototype that SAS Institute developed. This prototype provides Basin Electric Power Cooperative is a membcr- SASjAF* menus and programs for each owned electrical power generation and trans- SASjOR * procedure, including project manage- mission supplier. It serves an area of more than ment. The current Basin Electric Project Man- 400,000 square miles in portions of Colorado, agement application was developed from this Iowa, Minnesota, Montana, Nebraska, North prototype. The application is used primarily by Dakota, South Dakota and Wyoming. The Co- the Plant Scheduler at the Antelope Valley Sta- operative provides wholesale electricity for 120 rural electric systems which serve more than tion. He is responsible for the planning and scheduling of annual outages for thal plant. 440,000 meler installations representing about 1.2 million consumers. Basin Electric owns and op- er",Sugi-90-71 Maruska.txt
"ROD MILL BILLET SURFACE QUALITY REPORTING SYSTEM John A. McNamara and L. Richard Woodyatt Bethlehem Steel Corporation, Bethlehem PA 18016 INTRODUCTION a ""heat"" of steel, will typically weigh about 250 tons when The Rod Mill Billet Surface Quality Reporting System that was developed for Bethlehem Steel's No. 3 Rod Mill was the refining is completed. This liquid steel Is cast into a designed to provide a mechanism for tracking and reporting solid shape in one of two manners -- continuous casting or on the surface quality of rod mill billets so that management ingot pouring. In either case,the molten steel is transferred could ensure production of quality rod products. The system to a bottom-pour ladle for movement to the casting area. In the case of the newer continuous casting, the molten steel was developed over the past two years and was designed is poured into a trough-like reservoir called a tundish that to fill the needs of the General Management, Quality controls the flow of the steel through a water-cooled Assurance and Operating Departments at both the Bar, Rod and Wire Division, which manages the mill, and the permanent mold which controls ns shape as H solidifies into Sparrows Point Plant, which supplies most of the billets. a continuous ribbon-like slab of steel which is typically 8-10 inches thick by 36-86 inches wide and may be thousands of The need for a reliable and comprehensive qualny monitoring system at this mill was particularly acute feet long if n involves the sequential pouring of a number of because the billets are sourced from both ingot and caster heats. In the case of the older ingot process, the molten steel produced at multiple locations. Even during normal steel is poured into a series of smaller ingot castings -- operation, there are multiple points for inspection, surface perhaps 2x4x8 feet. Each heat will produce about 20 Ingots preparation and rejection. This system was designed to which are reheated in a soaking pit and rolled down",Sugi-90-72 McNamara Woodyatt.txt
"terms this means monitoring the mean of the process random variables. A method of calculating the probability Many authors have discussed sequential mass function of the Wilcoxon signed rank statistic is discussed. The algorithm pre- statistical tests to indicate when a process sented, written using PROC IML, is based goes ""out of control"", i.e., when the process mean drifts away from 00 · Some of the au- on the work of Milton (1970). A brief sum- thors who have addressed this topic are She- mary of a newly developed error bound for whart(1931), Page(1954) and Lucas(1976). this algorithm is given. All of these articles center on the calculation For process control schemes based on of the Wilcoxon signed rank statistic, the cal- culation of the Awrage Run Length (ARL) n L of the scheme requires the evaluation of the Sn = n -;· (v(X;) - k), (Ll) W probability mass function of the Wilcoxon ;=1 statistic under a shift in the location param- at each time point n in the process. The eter. The application of the algorithm's out- components of this sum are Wn-j, the weight put to the calculation of ARL is shown in de- placed on the observation at each time point; tail. v(Xj), some condensation of the data vector = Xj (Xii, ... ,Xgj) observed at time point i; and k, a reference value. For a CUSUM pro- 1.",Sugi-90-73 King Longnecker.txt
"BETTER FORECASTING WITH SAS/ETS® SOFTWARE Bruce R Benseman, DSIR Applied Mathematics Wholemilk composition depends on the time in the This paper describes our experiences using the SASIETS software when forecasting for a large New cow's lactation cycle. In general fat levels in wholemilk Zealand primary producer. This company has an an- grow steadily from 4.5% in September to 5.6% in April nual turnover of $1300 million. And it faces large sea- (see Figure 2). Protein levels dip to a trough of 3.3% in sonal fluctuations in the availability and quality of its raw the November flush, but rise to 3.9% by April. These patterns also depend on the geographical region the material. The company saves thousands of dollars per day when we forecast these fluctuations better. We will wholemilk was collected in. For example, central Waikato comment on the advantages and problems of different collection regions like Te Rapa, Waharoa, and Waitoa forecasting models and SAS/ETS software. have higher fat and protein levels than southern regions like Reporoa. like whole milk supply, we have to forecast fat, protein, and lactose eight times. Once for the whole Problem Background company-the rest for the company's seven collection regions. This paper describes our experiences forecasting for a Unfortunately, wholemilk composition also changes large New Zealand dairy company. In the 1988/89 sea- from one season to the next. It depends on climate, son, the company had a record turnover of $1300 mil- farm management, and animal condition. For example, lion, despite a 7% fall in supplied milkfat. This turnover protein levels may vary by 7% from one April to the next. included $900 million from exported dairy manufactur- The company needs to forecast the fat, protein, and ing. In this season, the company manufactured about lactose levels so it can plan its production and financial 320,000 tonnes of milk powder, cheese, casein, and operations better. For every 1% increase in fat or protein b",Sugi-90-74 Benseman.txt
"SAS Institute Inc., Cary, NC ABSTRACT The OHAUS"" GT 400 Electronic Balance for weight measurements is another example of an interactive data-collection device. The GT 400 has an RS-232 bidirectional compatible interface. A simple trig- Since the introduction of SAS/QC"" software into the SAse System, gering command is sent from the host to the GT 400 to initiate the SAS Institute has received numerous inquiries concerning the use communication link. Once the command is -issued, data measure- of data collection devices with the SAS System. Because automatic ments are transmitted electronically through the RS-232 port. A data collection allows for rapid gathering of large amounts of data variety of operating parameter settings are available with the GT with reduced potential for human error, these devices have become 400. For example, the GT 400 can be configured to transmit data an essential element of quality control programs for many industrial at timed intervals once the balance has stabilized. and manufacturing sites. Combining the data.gathering power of these devices with the power and flexibility of the SAS System pro- vides an ideal combination for manufacturing sites interested in THE ROLE OF THE SAS SYSTEM quality improvement. The SAS System provides the communication link and data-capture To enable the SAS System to become a complete quality- interface between a host PC and both batch and interactive data- improvement tool, SAS Institute is testing Release 6.03 of t",Sugi-90-75 Maddox Fulenwider.txt
"Determining Weight Values for EWMA Control Schemes Using the ARIMA Procedure John C. Brocklebank, SAS Institute Inc., Cary, NC EWMA t = J..Yt + (1-J..)EWMA t_1 Introduction for O<J..::;1 , t= 1,2, ._ .. The exponentially weighted moving average (EWMA), introduced in the quality control literature by Roberts But since EWM-\ may be viewed as the forecast for y (1959), has recently received further attention as a a!time period t + 1, and denoted as Yt+ l' you can write process control tool. Two possible uses of the EWMA EWM-\ as include detecting shifts and forecasting the process. The nature of the process suggests which use of the EWMA is appropriate. For processes which can be modeled as random variation (white noise) with periodic shifts in the mean level, the EWMA can be more sensitive than the Shewhart chart for monitoring the process and alerting the user that a shift has Note that by repeated substitution for 1'1' 1'1_1' 1'1-2' _ , .. occurred. For processes in which the mean drifts over you obtain time and exhibit autocorrelation, the EWMA is useful for forecasting and control. A Shewhart chart can then be used on the forecast errors to detect sudden large 1-1 shifts when a nonstationary trend is present. EWMA I=YI.I=LW;YI_;+ (1-J..) IEWMAa ;=0 Practical use of the EWMA requires the user to specify a parameter. The optimal EWMA parameters for process monitoring produce the smallest possible out- where EWMAo is a starting value and the Wi are of-control average run length (ARL) for a specified shift weights in the process mean. See, for example, Crowder (1989), Lucas and Saccucci (1990), the EWMAARL function and the MACONTROL Procedure in SAS/QC"" Software: Reference, Version 6, First Edition. The choice of the optimal EWMA parameters for forecasting is based on minimizing the error sum of squares. See Box and Jenkins (1970), Hunter (1986), Alexander and Note that Macklin (1989) or Baxley (1990). The purpose of this paper is to evaluate the choice of 1-1 LW;+ (",Sugi-90-76 Brocklebank.txt
"TRANSFER FUNCTION MODEL FOR GLOSS PREDICTION OF COATED ALUMINUM USING THE ARIMA PROCEDURE Mozammel H. Khan Kuwait Institute for Scientific Research Introduction at subsequent times. In this paper, first the univariate time series The objective of this work was to investigate analysis was applied to the gloss degradation methods for using available test data to predict data and then the Box-Jenkins transfer func- the percentage gloss values of coated aluminum tion methodology was applied to forecast the exposed to open environment. Because of the gloss value. A multiple input transfer function uncertainty of the weathering data and a lack was specified to explicitly account for the of consensus over the reliability of the pre- effect of weather conditions on the gloss value. dictive value of the accelerated testing carried out in the laboratory, suitable mathematical model techniques were sought which would fit the existing test data and would make pre- Univariate Time Series Analysis diction of the gloss value at any specified fu ture time. A model in this case, is an alge- braic statement telling how the gloss value is Time series data refers to observations on a statistically related to time and the other perti- variable that occurs in a time sequence. The phrase ""time series analysis"" is used in several nent weathering variables such as temperature ways. Sometimes it refers to any kind of anal- and relative humidity. There exists two dis- tinctive modeling techniques: namely, ysis involving time series data. At other times it is used more narrowly to describe attempts 1. Regression Analysis to explain behavior of time series data using only past observations of the variable in ques- 2. Time Series Analysis tion. This activity is referred to as single series or univariate analysis. The underlying assump- tions is that the time sequenced observations in Regression method expresses the dependence of a data series may be statistically dependent as one variable on an",Sugi-90-77 Khan.txt
"kar Raman University of Notre Dame, Notre Dame, Indiana 46556 to allow for ordinary least squares on the following model: 1. Abstract The purpose of this paper is to demonstrate how to use (4) SAS0 to estimate a piecewise linear or higher order spline regression model. The method of estimation depends upon A A A Using the resulting coefficient estimates. a 1. bl and, b2, whether the join point -is known in advance or has to be the restricted estimate for a2 is given by: estimated and whether a linear or a higher order model is used. When the location of the join point is not known but some reasonable initial guess can be made. the Gauss- (5) Newton method may be used to search for the join point as suggested by Gallant and Fuller. For quadratic or higher These are the restricted parameter estimates for the original order models, the Newton-Raphson method provides a model specified by equations (I) and (2). useful alternative. These methods are easy to apply to piecewise regression models using SAS@ as demonstrated in this paper. 3. Case where location of X* is unknown but an initial guess is available. 2. Case where the location of the joint point, X*, is known in advance. Here we have the problem where X* is unknown and must be treated as a parameter to be estimated. One way to First consider the problem of a two-segment piecewise estimate this model is to see this as a nonlinear model and linear regression model when the point where the two lines estimate it using nonlinear",Sugi-90-78 Marsh Maudgal Raman.txt
and the sample or target mean vector is: This paper presents a new approach to bivariate qualtty control with the aid of a oomputer. It introduces the Andrews function and the function's characteristics pertaining to a standard control chart. A proof of the function is shown such that no Type I and Type /I errors will occur. Sample data from Sultan (1984) is used for illustration purposes and a few arbitrary observations are chosen to show the sensitivity of the control chart. Finally. the advantages of Andrews function control chart are outlined. where,Sugi-90-79 Chua Reiser.txt
"The CEI SAS Users Group became the Centerior The SAS'"" Users Group at Centerior Energy SAS Users Group in 1988 when leadership of the C6rporation. an electric utility headquartered in group was passed from the corporate SAS represen- Independence. Ohio. a suburb of Cleveland. has de- tative to a Steering Committee consisting of an in- veloped from a single location. one person in charge terim chairperson, an interim secretary, and several organization to a multi location, steering committee subcommittees. The first Centerior SAS Steering organization with approximately 200 members. This Committee meeting was held on April 20, 1988, and paper will discuss the evolution of the users group the following subcommittees were created: and its current organization along with its goals and 1. Presentationrrutorial is responsible for organiz- objectives. ing and running CSUG meetings and other spe- cial programming,",Sugi-90-80 Gerber Kominek Hamper.txt
"Institute Support for SAS' Users Groups Pamela Meek, SAS Institute Inc., Cary, NC Sally Roberson, SAS Institute Inc., Cary, NC In 1988. SAS Institute made a number of organizational changes After you have received the Starter""s Guide and read it over, the in order to bring us in greater contact with you, our users. As you first step in forming a users group is to get an idea of how many know, the Institute established three regional offices in the United SAS users are in your area or organization. If you are forming an States and a subsidiary in Canada. In addition, the Institute imple- in-house group, contact the SAS Consultant at your organization mented a formal support program for local, in-house, special- for names of other SAS users. Intemal communications channels such as company newsletters, electronic mail systems, or bulletin interest, and regional SAS"" users groups. The users group support boards are a good way to reach potential members. If you are form- program was a direct result of your requests for assistance in form- ing a local or special-interest users group, the Institute's users group ing and maintaining users groups. SAS Institute also wanted to rec- ognize the contribution made by SAS users groups at the local, liaison can give you an idea of how many users are in a particular area or share a common interest. regional. and international level. This paper will tell you more about our support program for SAS users groups - how we serve as a clearinghouse for information, help new groups form, provide meet- The next step is to survey your potential membership about needs ing support for existing groups, and support regional users groups. and interests. There are several examples of surveys in the Starter's Guide. If you are forming a local or special-interest group, we recom- mend preparing a cover letter and survey to mail to SAS users in Clearinghouse for Information your area. The Institute will then copy and mail your letter and sur- The pri",Sugi-90-81 Meek Roberson.txt
"e the first users group to take This paper describes the experiences advantage of the Consortium Training of the South Florida SAS Users Group offered by the Institute. Training in sponsoring a SAS* Basics course and classes will continue with PC SAS to a SAS* Macro Language course. The be offered in April 1990. The users users group organized and marketed the group has also promoted courses in courses. The Education, Marketing and Base SAS* at the University of Miami Sales Department of SAS Institute and Florida International University provided the speakers and course in January 1990. materials, collected course fees, and paid course expenses. Benefits to Members For the user community the courses allowed individuals to obtain training Training: they otherwise would not have received. The two courses targeted - Offers education otherwise unavail- different sections of the user able to them community: the SAS Basics course for novice programmers; the SAS Macro Increases the abilities of attendees Language for intermediate to advanced to program in SAS, thus making them programmers. more valuable to their companies For the users group the courses - Enlarges the number of SAS users at supplied the opportunity to provide their companies, thus increasing the members a visible valuable product importance of SAS and gaining them l which they could use to justify par- political leverage ticipation in the users group. It also helped sell the benefits . o~ SAS* - Provides a justifica",Sugi-90-82 Krasner.txt
"ADULT EDUCATION STUDENT TRACKING SYSTEM Margaret K. Schrempf - Health Information Reporting Company us to print SASIGRAPH output on a xerox mainframe printer. This · ABSTRACf: package was loaded on only one of four printers, so if the operator Each year our Information Center offers approximately 300 did not send the output to the correct printer, we did not provide courses and trains over 1800 users in both mainframe and PC our students with certificates! This happened more frequently than software packages. Our Information Center has a well developed we had expected. course curriculum which requires a series of pre-requisites. Con- The last problem that we had was the evaluations that our sultants with the Information Center would sometimes register students faithfully filled out. We did not have a database to enter students without checking the student's pre-requisites. This the evaluations into. Our Instructors after reading the evaluations caused a great deal of frustration and confusion for the students just dropped them into a box and they were thrown out in a year. and the Instructor. It was obvious that a new tracking system which It was obvious that a new Education Tracking System was includes, student history file, student course waiting list, course needed. roster, instructor updates for both attendance and evaluations, course scheduling. and reports, would need to be developed. This · System Design system has been developed using SAS/AF® and SAS/FSP®. My first task was -to analyze the current system, keep what I could and get rid of the things that did not work. I decided to put · Historical Background the entire system in SAS/AF® using all the power that the SAS® Each Information Center in every company does not perform base system provided wrapped up in menus using SAS/AF®. The the same functions. The Information Center at the City of Chicago next step was to design the databases that I thought would be was originally created to assist the end-user t",Sugi-90-83 Schrempf.txt
"Teaching the SASTM Programming Language to Programmers and Non-programmers Wendy London Pharmaceutical Research Associates, Inc. INTRODUCTION: This paper reviews our efforts at There clearly exists a need at PRA for instruction in the Pharmaceutical Research Associates, Inc. (PRA) in the SAS programming language. We decided to design our own series of classes for several reasons: designing and teaching of a course in SAS Programming. There was (and still is) a high demand/or timely instruction in SAS from a broad audience at PRA. The 1) We wanted to tailor our instruction so that programming experience of the employees who wanted to students would learn t6program according to the guidelines of PRA's SAS Coding Standard take the course ranged/rom none in any language to good Operating Procedure (SOP). SAS proficiency_ We attempted to address the needs of as many people as we could, as soon as we could, and to 2) We wished to emphasize the procedures and cover basic through advanced topics. The instructors of techniques most often needed in the work that PRA does. the course were SAS programmers and statisticians, most with no formal training in the field of education, and few 3) We wanted to have the flexibility to slow down with teaching experience. What a chal/enge! The whys, or speed up the classes depending on the ability hows, and whats of our approach to this challenging cask of the students to learn the materiaL are presented here. The input for the discussions of 4) We thought we could get more for our time and improvemenrs to the course was obeained from ehe money than could be provided by a training students' evaluations of the course and the opinions of ehe package from SAS Institute. instructors. Read on to discover why, with hindsight, we 5) We wanted to meet the challenge of addressing will probably divide the course into two levels in the future: the needs of non-programrners and programmers a basic series for non""programmers and an advanced in the sa",Sugi-90-84 London.txt
"CBT vs INSTRUCTOR-LED CLASSES Margaret K. Schremp! - Health Information Reporting Company a CBTcourse · ABSTRACT: There are several questions that must be addressed when Since the introduction of Computer BAsed Training (CST) as evaluating a CBT course. How for example is the information an alternative to Instructor-led classes, trainers like myself have presented. Will the user be presented with graphics and music in had to re-evaluate our Adult course curriculum. Has CST been every screen? Are colors used consistently. For example if RED is worth the cost? Does the user or student get solid data processing used to indicate an error, is that carried throughout the course? fundamentals? Do CST students perform better or worse than Will the CBT course allow sufficient review or paths? If the student students who take instructor-led courses? Should there be a does not understand a concept, be returned constantly to the same marriage of the two? \Nhere does CaT really fit in? This paper will screen? Does the course have exercises? If it does, where will the explore the oost of vendor supplied CST vs Instructor CST develop- student do them, on paper, interactively, or a batch job? Will your ment, CST course curriculum vs Instructor-led curriculum, and the site support that? lastly, will it keep the student awake so that they cost of PC based CST. Rnally this paper will discuss the effect of can learn? CST and Instructor-led training on our own students, and some of · LESSON3 the solutions that we think work. Vendor Software is not cheap nor does it come without a · Historical Background contract. Each Information Center in every company does not perform Maybe I was naive thinking that CBT could be inexpensive? the same functions. The Information Center at the City of Chicago How could companies stay in business? A rude awakening came was originally created to assist the end-user to produce ad-hoc to me as I read my first CBT contract. I would get X amount of reporting",Sugi-90-85 Schrempf.txt
The design goal Multiple Engine Architecture Release 6.06 of the SAS System represents provides the ability to access a variety of a new software design for the decade of the different types of files as if they are SAS 1990's. A number of major design goals and data sets. software re-engineering in Release 6.06 necessitate changes to existing education The fact that there now exists different offer-ings on the SAS System as well as implementations of SAS data sets represents suggest new offerings for SAS training a critical concept fundamental in any SAS programs. courses.,Sugi-90-86 Boling.txt
"nformation needs for today's corporations, some type of computing power is being placed on the desks of accountants, engineers, economists, managers, and administrative personnel. Although these employees are experts in their fields, many times they are untrained in the use of the powerful software tools available to them. Technical personnel used to be insulated behind closed doors, but now they are finding themselves on the firing line - at the front of the classroom. In order to survive, these new teachers must put away their core dumps and language reference manuals and learn to understand what motivates adutts to learn. Wnh this understanding, they can be successful in making their classroom experience rewarding for both themselves and the student. 4. Ability to verbally and visually present informa- A major challenge facing corporations today is how to tion so that the intended purpose is achieved. successfully train and support employees in the use of powerful software tools. U.S. corporations currently spend 5. Ability to gather information from and stimulate more than $200 billion each year in employee education insight in individuals and groups. , and support. The need to regain the competitive edge in an international economy, rapid changes in technology, a 6. Ability to communicate information, observations shortage of skilled labor, and continued deficiencies in our and conclusions so that they are understood educational system, will insure that this trend contin",Sugi-90-87 Stewart.txt
"Modular Course Design: Develop and Deliver a Technical Course Kim Burch, L. L. Bean Introduction job, chances are better that they have had experience in, or have an apt~ude for the subject. What is a modular course? Webste(s defin~ion of modular The Information Center personnel or the company's is ""constructed with standardized units or dimensions for flexibility and variety in use."" In that context, a modular experts for the topic can also provide insight about the course can be easily modified to meet the needs of audience. In that they answer questions all day, they know audiences with varying aptitudes, experiences and who needs help, what types of questions are most backgrounds. A modular course can be quickly adjusted frequently asked, and what level of experience the users to provide the information required for a particular situation. have. ff documentation is kept by people manning the A modular course is flexible enough to be broken into help lines, it is possible to use those records as a resource smaller training sessions. Also, technical updates or for many of the questions concerning the scope. enhancements can be made to a modularly designed course with ease. When a new concept is being introduced to the user commun~y as an add~ion to their current knowledge, what In today's business world, the people responsible for to teach can be easily defined. On the other hand, terms training. manning help lines and performing various other such as ""Basics"", ""'ntroduction"", or ""Beginners"" can leave technical support functions require as much structure as a course designer in a quandary when determining what possible in what can otherwise be a chaotic environment. topics to include in the course. How will the tool be used? For example, if you are planning a SAS Basics course, for This paper will provide guidelines for modular technical course design. Where do you start when developing a what purpose are people using SAS ... to write reports? .. course? What sho",Sugi-90-88 Burch.txt
"the material; one made a greater impression on me though, and earned my admiration. The assignment of teaching others is both challenging and exciting. There are a number of subtle factors Practice, practice, practice. The more you do involved in presenting information that c-an significantly something, the better you become at doing it. Practice affect your success as an instructor. presenting parts of your course to a coworker -- an experienced instructor is a good choice if you know Obviously, students must pay attention during one. If you have the equipment, make a videotape of instruction in order to retain the information presented. yourself and study it. Or present the course to yourself The following proven techniques for establishing in a mirror. Practice using your visual aids so you rapport, observing and interpreting students' reactions, learn to make a smooth transition from one to another. using classroom aids, handling difficult students, dealing with various personalities, and fielding questions give you the tools you need to meet any Know your audience. You can help students relate to the course material if you know who they are and what teaching challenge. Whether you teach in a classroom areas they work in. Give examples during class that environment or on a one-to-one basis, the tips offered relate the course topics to the students' day-to-day here help you teach effectively and help your trainees work assignments. Be careful though, if you have a assilmil",Sugi-90-89 Ussery.txt
", NC Abstract Invoking SAS/ASSIST software is easy. Users simply begin a SAS display manager session and then, based With SASiASSIST® software. getting started with the on your site's installment of the software, they either SAS System is easy, but it changes how you initiate select the ASSIST option from an action bar or issue new computer users. If you are responsible for train- the ASSIST command. You control which method is ing, this paper will show you how to help someone with used to invoke the interface. Once in SASiASSIST soft· ware, users can make selections by moving the cursor no computer skills begin to use the SAS System with SAS/ASSIST software. and pressing the ENTER key. or if they have a mouse. they can point and click. What SAS!ASSIST® software means for trainers? Here's a look at what users see when they first get into With Release 6.06. SAS Institute provides a valuable SAS,ASSIST software. Display 1 shows the Primary tool to help new users get started with the SAS System: Menu. SASJASSIST software. This interface between the user and the SAS System is a task-oriented, menu-driven .,, _____ · _____ ____ ·..· -.-.-.-·.·· --.----- , ·S'Sf'~SI~l···_··· ··~~ , windowing system. The primary goal of SASiASSIST , ."".."" ............ .. , , , ....... "" , , software is to provide the power of the SAS System "" "" , , , without requiring knowledge of SAS language syntax. , , , , SASi ASSIST software enables users to choose tasks ·· ,,,,., ...... ,, ·· , ···"""""".,,, ····",Sugi-90-90 Wells Ussery.txt
"eral-Audit accounted for one out of every five errors! Abstract Why is this error so common? Let me speculate User friendly programming should be the aim of briefly. all software development. The idea should We all do many things by habit. In fact, apply not only to application programs for the without habit we probably could not live verY end user but to the development of programming languages for use by application programmers. effectively--we would spend all our time However, developers have given relatively concentrating on trivia. However, our habits are not etched in stone. There seems to be a little attention to the ergonomics of programming languages--how do the thought pattern or sequence involved in most habits, processes of the human mind affect user and if something happens to interrupt that friendly programming? I start by describing sequence, there is a very good chance it will how a minor change in the use of the semicolon not be completed. Regardless of the provides ergonomic benefits to SAS programmers. theoretical basis for the behaVior, I believe I then follow with a potpourri of procedures I empirical analysis supports this contention. use, some of which are in direct conflict with Consider some examples: recommendations made by authors at previous SUGI's and relate them to my own general How many times have you left the keys in your philosophy of programming. We all have car's ignition? Compare this with the number constraints imposed upon us and cannot",Sugi-90-91 Foster.txt
"The Consultant's Ufe Is/Is Not a Happy One Tom Marx, Marx Social Science Research Inc., Cambridge, MA this vacation. I told my current clients that I was going to 1. What is Consulting Like? be gone for two weeks. 'A consultant is always looking for a job; said my father, a consultant for most of his working life. To consult full I also choose whom I work for, and negotiate my own deal time is to lack the security of a regular pay check. No with them. Much of the time I schedule my work time and matter how busy you may be as you start your practice, location as I please. Increasingly - as communications and no matter how long work is plentiful, I think it's technology has advanced - I have been able to carry out accnrate to say that there will come a day (often brought consulting projects in the office I had built in my home, on by yourself) when you will be hunting for a consulting either by modem to my client's mainframe or on myown engagement. PC (yes folks, the SAS<i!> System on a PC is fantastic!). Literally from one day to the next a consultant can go .Most of the work comes my way through a combination from being overbooked to underbooked. And when un- of an organization facing an impending deadline ,and no derbooking lasts long enough; financial problems ranging available staff to complete the job on time. When the from income shortage through bankruptcy result unless deadline pressure on the organization is high, they lay it you are independently wealthy. . on me. Usually, they also push me to keep my cost to them down, whether I contract the job at a fixed price or work Even the busy consultant is not immune to money by the hour. problems. You may badly underbid a fixed-price job. Your clients may refuse to pay you, either legitimately or The work itself I find challenging. Although much of the pretextually. They may find ways to delay paying you, software I write is sophisticated and difficult, I am also sometimes indefinitely. They may go bankrupt. I wo",Sugi-90-92 Marx.txt
"The Distribution of the SAS® System for PC's via a Mainframe Computer William G. LeBlanc, University of Miami SAMPLE programs were placed in their own INTRODUCTION subdirectories (BASE, STAT, GRAPH, AF, FSP) under the directory SAMPLE, the The distribution of the SAS® System second zipfile. The .exe files in the CORE, for PC's has proved to be problematic at our BASE, STAT, GRAPH, AF, and FSP site. Users are spread across three directories under the SASEXE subdirectory campuses, they differ in DOS skills, they were bundled into six separate zipfiles have different versions of DOS, they have (CORE, BASE, STAT, GRAPH, AF, FSP). different capacity floppy and hard disk The other 11 zipfiles were formed from the drives, updates must be periodically standard, SAS-created subdirectories: ZAPS, distributed, etc. In an attempt to overcome SASHELP, SASMSG, etc. Since two of the these problems, we have developed a subdirectories, SASTEST and SASWORK, procedure to distribute the PC SAS system contained no files, a one-line dummy file to our authorized users via our mainframe was placed in each so that PKZIP would computers. The entire PC SAS system was have something to compress, and later uploaded to our IBM® 3090 and VA)('""N8650 restore. mainframes. Authorized users with access to these mainframes are allowed read- In addition to these 19 zipfiles, the access to the system disk containing the PC PKUNZIP program, a .bat file that executed SAS system in order to download it directly the PKUNZIP program for each zipfile (a to their PC's. This paper describes the portion of which is shown below in Program procedure used to distribute the PC SAS 1), and a READ ME text file containing system in our IBM environment. This directions were included. A listing of the procedure also works in our VAX zipfiles showing pre- and post-compression environment. sizes is provided in Table 1. A copy of these figures was included in the READ ME file so that users can verify that downloaded files",Sugi-90-94 LeBlanc.txt
"means that in addition to working with SAS users, they review and write SAS documentation, test problem fixes, and interact with In order to effectively support the SAS· System at your site, you development staff personnel to promote future enhancements to must be familiar with the support services provided by SAS Institute. their product. This paper discusses both types of support available: · telephone support Telephone Support · the Online Customer Support Facility (OCSF). The largest portion of our support services is telephone support. You can reach a consultant to report a new problem or question Utilizing these services to their best advantage will make on-site from 9:00 a.m. to 8:00 p.m. EST. You can reach a consultant to fol- support more efficient. In addition, Institute supplied tools, such as low up on a problem that has been assigned a tracking number from the Usage Notes data set and the sample library, are discussed. 9:00 a.m. to 5:00 p.m. EST. The telephone number for Technical Support is (919) 677-8008.",Sugi-90-95 Painter.txt
"Solving 2,000 SAS® Problems a Year Help Desk Personnel -- Solutions Faster Than a Speeding SAS User Robert G. Hall. ARC Professional Services Group Catherine Schmitt. ARC Professional Services Group This paper discusses operating a successful Help Desk knowledge of the operating systems. They need to know those supporting over 500 active SAS users. We support users parts of the operating system that impact SAS, but they don't working on systems ranging from pes and Unix workstations to need to be expel1s. VAX mainframes. In our approach the help desk personnel try to Hardware - A help desk should have the same working identify the type of user and the nature of the problem quickly and environment as the users. The effectiveness of the support then tailor the response to the user. Responses range from brief varies directly with the help desk's ability to reproduce the users' explanations of SAS or operating system syntax to extended working environment. The hardware doesn't have to be systems analysis. extensive. It could be a terminal in a VAX or IBM mainframe The paper also discusses additional activities that may be environment. It could be a PC in a microcomputer environment. conducted during those periods when there are no specific It could be all of the above. The point is that you have to be able requests for assistance. These activities are designed to to sit down and work interactively with both SAS and the user. improve the general level of SAS support by developing Software - You must have access to the software used by your generalized solutions to problems and prototype systems using clients. This indudes not only the various SAS products that different SAS techniques and products. users will have, but also any third party software with which SAS users interface (network environments, database systems, A SAS help desk assists users in getting their SAS code to do etc.). Furthermore, you will probably need to have access to a what they want SAS to do. Ou",Sugi-90-96 Hall Schmitt.txt
"A SURVIVAL KIT FOR ACADEMIC CONSULTANTS OR HOW TO KEEP USERS FROM STEALING YOUR JOB SANDRA ROBINSON ST .GEORGE DUSTY TEAF The University of New Mexico INTRODUCTION were few and far between, and held all the Over the last year or so we have noticed a trend cards? We knew all the secrets and we were in related to software users that has us worried. great demand. It used to be that you could sit Some of you may have observed the same dis- in you r office and wait for panicked users to turbing phenomenon. More and more frequently, come to you and throw themselves on your we see that user services managers are looking mercy. We were able to maintain our mystique inside the organization when recruiting support by telling them we'd get back to them in a few personnel. Naomi Karten comments that ',.unlike days and they'd believe that it took that long. the early days when recruitment from user de- (Halliday,1989,p.26) Those days are gone. The partments was frowned upon by user management Information Age is encouraging users to get too or prohibited by corporate fiat, most companies involved in our business. It's getting harder now permit or even encou rage such and harder to preserve our image of software moves .... Filling openings with people from the expert. user community, in fact, may be one of the most effective steps an Ie can take to broaden its business perspective'. (Karten; 1989, p.20). But, Many people believe that customer service has they are not looking in the user community for been going downhill in the U.S. for years. As 'the cheerful biology teacher who knows we begin the 90's in the consulting field we need spreadsheets.' (Karten,1989,p.20) IC Managers to find ways to better satisfy our clients through are looking to recruit business savvy, techni- exceptional customer service. Dan Roberts in cally topnotch, extremely service oriented indi- a recent issue of Information Center magazine viduals. (Roberts,1989,p.22) says that the only way for IC's 'and th",Sugi-90-97 Robinson.txt
"SOLVING BUSINESS NEEDS AS A TEAM Roger L. Crouse, IBM Corporation discipline to accurately state a problem and sol- PAYOFF IDEA ution using the softwa~. Wuni!:: yet, u:sers may not have adequate experience in data management, Ideally, Ie staff members should fully understand which may result being inaccurate or lost data. all end-user computing enviromnents and users' Users seldom, if ever, have enough time to learn business needs. In tum, end users should have a how to overcome these risks. complete knowledge of the end-user computing tools avail- able to them. Obviously, such total An apparent solution to these challenges is understanding is impossible for each given their increased user dependence on the IC for application own job responsibilities and the time restrictions development. This would ensure that end-user they face. One solution to this dilemma is for Ie computing products are used more effectively, sol- staff members to join with end users to fonn a utions implemented more quickly, and the need for tearn dedicated to resolving conflicts and fmding training reduced. The design, implementation, and solutions to meet end users' business needs. This management of databases would be perfonned article provides guidelines on how to develop and more accurately and safely, reducing the amount of get optimum results from such a team. data lost. There are,however, long-tenn drawbacks increasing OVERCOMING CONFLICTS AND user dependence on the Ie. The IC's solution to a RISKS user's problem might be inadequate because the IC is relatively unfamiliar with the user's business area. The goal of the infonnation center is to work with Solutions might become less responsive as mOre users to help meet the organization's business and more users become similarly dependent. Users needs. The Ie offers alternatives that match these needs with end-user computing products. It also might not learn as much ahout the products and how they can be used most effectively in their ad",Sugi-90-98 Crouse.txt
"Establishing SAS* Software at a large Corporation William E. White. Commonwealth Edison Introduction Company Background At the beginning of 1982, Commonwealth Edison Commonwealth Edison is the largest nuclear utility in the (CornEd) had 11 users of SAS software, 9 of which were Non- United States with 12 nudear reactors capable of producing Computer Systems(NCS) users. By the beginning of 1990, 11,500 megawatts of electricity. It built and operated the first CornEd had almost 3000 SAS users outside of the corporate privately financed nuclear reactor in the United States in the late Computer Systems depanments. 1950's. In addition to its nuclear plants, CornEd has 10 fossil powered plants with 26 generating units and has many smaller Non-Computer Systems peaking units. The total electric generating capacity of CornEd Software Usage is approximately 22,500 megawatts. 300orN~.~m~b~.'~O~'~U~""~'~'__________________________--, This capacity provides a very reliable power source for the company's more than 3,000,000 customers, and 11.525 sq. mi. 2500 service territory which includes most of the upper third of Illinois and the city of Chicago. CornEd employes about 18,000 2000 people, approximately 6,000 of which are management. With the exception of clerical functions such as data entry, computers l500 and the use of computer software is primarily a management function. 0000 soa Unlike some other utilities, CornEd has a philosophy that a~-¢~~~~~~~~~~~~ corporate data should be readily available to all levels of its management. Except for sensitive data such as: payroll, billing, 1982 1983 1984 1985 1986 1987 1988 1989 1990 ! and personal HUman Resources Information, most data - SASI!!ISoflware - Any Soltware accessible via TSO has a universal access of 'READ'. Engineers at the stations, marketeers in the service divisions, and accountants in the general office can access the data that they CornEd has SAS software licensed on 2 IBM 30905* as need in order to do their norma",Sugi-90-99 White.txt
